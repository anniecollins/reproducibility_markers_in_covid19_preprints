Clustering Longitudinal Life-Course Sequences
using Mixtures of Exponential-Distance Models
Keefe Murphy1,2 , T. Brendan Murphy1,2 ,
Raaella Piccarreta3 , I. Claire Gormley1,2
1

School of Mathematics and Statistics, University College Dublin, Ireland
Insight Centre for Data Analytics, University College Dublin, Ireland
3 Department of Decision Sciences, UniversitÃ  Bocconi, Milan, Italy
E-mail: keefe.murphy@ucd.ie

2

Abstract
Sequence analysis is an increasingly popular approach for the analysis of life courses
represented by an ordered collection of activities experienced by subjects over a given
time period. Several criteria exist for measuring pairwise dissimilarities among sequences. Typically, dissimilarity matrices are employed as input to heuristic clustering
algorithms, with the aim of identifying the most relevant patterns in the data.
Here, we propose a model-based clustering approach for categorical sequence data.
The technique is applied to a survey data set containing information on the career
trajectories of a cohort of Northern Irish youths tracked between the ages of 16 and 22.
Specically, we develop a family of methods for clustering sequences directly, based
on mixtures of exponential-distance models, which we call MEDseq. The use of the
Hamming distance or weighted variants thereof as the distance metrics permits closedform expressions for the normalising constant, thereby facilitating the development of
an ECM algorithm for model tting. Additionally, MEDseq models allow the probability of component membership to depend on xed covariates. Sampling weights, which
are often associated with life-course data arising from surveys, are also accommodated.
Simultaneously including weights and covariates in the clustering process yields new
insights on the Northern Irish data.
Life-course data, exponential-distance models, model-based clustering, weighted Hamming
distance, gating covariates, survey sampling weights.
Keywords:

1

Introduction

Sequence analysis (SA) is an umbrella term for tools dened to explore and describe categorical life-course data. Specically, attention is focused on the ordered sequence of states (or
activities) experienced by individuals over a given time-span (usually at T equally spaced
discrete time periods). The goal of analysis is to identify the most relevant patterns in
the data. To this end, pairwise dissimilarities among sequences in their entirety are rst
assessed. Dissimilarity matrices are then employed to identify the most typical trajectories
using, in the vast majority of applications, cluster analysis.
Quantifying the distance between categorical sequences is not a trivial task. Optimal
matching (OM), developed by Abbott and Forrest (1986) and extended to sociology by
Abbott and Hrycak (1990), is popular among the SA community. OM is derived from the
edit distance originally proposed in the eld of information theory and computer science
by Levenshtein (1966). The OM metric assigns costs to the dierent types of edits, namely
1

insertion, deletion, and substitution. Typically, insertion and deletion are assigned a cost
of 1 while substitution costs are allowed to vary. However, specifying these costs involves
subjective choices, and may lead to violations of the triangle inequality if not done carefully.
Several proposals in the literature introduced criteria to improve or guide the choice of costs
in OM. Also, alternative dissimilarity criteria have been introduced to allow control over
the importance assigned to the characteristics of the sequences (namely, the collection of
experienced states, their timing, or their duration) in the assessment of their dierences:
see Studer and Ritschard (2016) for an excellent discussion. Even so, there are no results
proving that one procedure is superior to the others, and the choice of dissimilarity measure
remains a fundamental choice left to the researcher.
Given a dissimilarity matrix D, obtained from a set of sequences S = (s1 , . . . , sn ), where
n is the number of subjects, cluster analysis is usually applied to group sequences and to
identify the most typical trajectories experienced by the sampled individuals. Typically,
heuristic clustering algorithms, either hierarchical or partitional, are used. In many applications, it is also of interest to relate the sequences to a set of baseline covariates. Within
the described framework, this is solely done by relating the uncovered clustering partition
to covariates, using for example multinomial logistic regression (MLR). This approach is
questionable from a few points of view. Firstly, the original sequences are substituted by a
categorical variable indicating clustering membership, thus disregarding the heterogeneity
within clusters. This is clearly only sensible when the clusters are suciently homogeneous.
However, a clear clustering structure can often be obtained only by increasing the number
of clusters (often with some clusters possibly small in size). More importantly, suitable partitions do not necessarily lead to suitable response variables as input for the MLR. It thus
seems desirable to cluster sequences and relate the clusters to the covariates simultaneously.
To address these issues, we propose to cluster trajectories in a model-based fashion,
allowing the covariates to guide the construction of the clusters, rather than leaving them
exogenous to the clustering model. This permits to better understand if and to what extent
specic covariates aect the typical sequence patterns characterising each cluster. Modelbased clustering methods typically assume that the data arise from a nite mixture of G
distributions; Bouveyron et al. (2019) provide an excellent overview. In principle, any distribution can be used, though the term `model-based clustering' was popularised by Baneld
and Raftery (1993), in which the underlying distributions are assumed to be parsimoniously
parameterised multivariate Gaussians with component-specic parameters. Such models
have been recently extended to the mixture of experts setting (Gormley and FrÃ¼hwirthSchnatter, 2019) to facilitate dependence on xed covariates (Murphy and Murphy, 2019).
However, these models can be problematic when applied to dissimilarity matrices, either
due to non-identiability or because the input data are usually far from Gaussian. This
problem cannot be addressed by applying multidimensional scaling to D because the resulting low-dimensional conguration is also typically far from Gaussian. Notably, our attempts
to t non-Gaussian mixtures in these settings did not yield useful results.
Another popular framework for clustering categorical data is latent class analysis (LCA;
Lazarsfeld and Henry 1968)). Agresti (2002) shows the connection between model-based
clustering and LCA. Such models are nite mixtures in which the component distributions
are assumed to be multi-way cross-classication tables with all variables mutually independent. Latent class regression models (Dayton and Macready, 1988) are particularly
interesting, because their connection to the mixture of experts framework permits the inclusion of covariates to predict the latent class memberships. However, tting such models
is challenging when the sequence length, the number of categories, or the number of latent
classes are even moderately large, due to the explosion in the number of parameters.
2

For the reasons mentioned above, we model the sequences directly, via parsimonious
mixtures of exponential-distance models. Exponential-distance models typically depend on
a central sequence and a precision parameter in a way that relates to the chosen distance
metric. Mostly for reasons of computational convenience, we use dissimilarities based on
simple matching, in particular the Hamming distance (Hamming, 1950). This distance is
liable to suer from temporal rigidity, since anticipations and/or postponements of the same
choices in life courses are not accounted for. Hence, similar sequences shifted by one time
period may be maximally distant from one another. While misalignment is less of a concern
for sequences exhibiting long durations in the same state, we address the issue using weighted
variants of the Hamming distance, characterised by a range of constraints on the precision
parameters in the mixture setting. This leads to the novel MEDseq family of models,
which can be seen as similar to a version of the k -medoids/PAM algorithm (Kaufman and
Rousseeuw, 1990) based on the Hamming distance with some restrictions relaxed.
Our approach is illustrated using data from the 1999 sweep of the Status Zero Survey
(McVicar, 2000; McVicar and Anyadike-Danes, 2002)  henceforth referred to as the MVAD
data  on the school-to-work trajectories experienced by a cohort of Northern Irish youths.
McVicar and Anyadike-Danes (2002) apply Ward's agglomerative hierarchical clustering
algorithm to an OM dissimilarity matrix to obtain G = 5 clusters of these trajectories,
without performing model selection. Thereafter, they use MLR to relate the hard assignments of trajectories to the clusters to a set of baseline covariates. We instead cluster the
MVAD data in a model-based fashion, using the MEDseq model family, and allow the covariates to guide the construction of the clusters by assuming they inuence the probability
of component membership. Importantly, information is also available on the survey sampling weights, which are only incorporated in the MLR stage of the analysis in McVicar
and Anyadike-Danes (2002). While sampling weights can be incorporated into heuristic
clustering algorithms, such as Ward's hierarchical clustering (by weighting the linkages between clusters) or k -medoids, and subsequently in the MLR, one of the advantages of our
approach is that both the covariates and the weights are incorporated simultaneously.
MEDseq models, like standard SA heuristic clustering algorithms and LCA models, approach the clustering task from the holistic perspective of modelling whole trajectories, in
order to uncover groups of similar sequences. In contrast, a number of multistate models employing nite mixtures of Markov components (e.g. Melnykov 2016a; Pamminger
and FrÃ¼hwirth-Schnatter 2010) or hidden-Markov components (Helske et al., 2016) have
recently attained popularity for the analysis of categorical sequence data. Such models focus on modelling instantaneous transitions within the life course and on factors that might
explain the probability of experiencing them. As described by Wu (2000), this amounts to
a dierence between considering sequences in their entirety under the MEDseq framework
or as time-to-event processes under the Markovian framework.
The remainder of the article is organised as follows. Section 2 presents some exploratory analysis of the MVAD data. Section 3 develops the MEDseq family of mixtures of
exponential-distance models that account for sampling weights and allow potential dependency on covariates. Section 4 describes the model tting procedure and discusses factors
aecting performance. Section 5 presents results for the MVAD data, including applications of MEDseq models and comparisons to other methods. The insights gleaned from
the MVAD data under the optimal MEDseq model are summarised in Section 6. The paper concludes with a brief discussion on the MEDseq methodology and potential future
extensions in Section 7. A software implementation for the full MEDseq model family is
provided by the associated R package MEDseq (Murphy et al., 2019), which is available from
www.r-project.org (R Core Team, 2019), with which all results were obtained.
3

2

Status Zero Survey: MVAD Data

The term `MVAD data' refers throughout to a cohort of n = 712 Northern Irish youths aged
16 and eligible to leave compulsory education as of July 1993 who were observed at monthly
intervals until June 1999 as part of the Status Zero Survey (McVicar, 2000; McVicar and
Anyadike-Danes, 2002). The subjects were interviewed about the labour market activities
they experienced, distinguishing between employment (EM), further education (FE), higher
education (HE), joblessness (JL), school (SC), or training (TR). Each observation i is represented by an ordered categorical sequence of length T = 72, with an alphabet of v = 6 possible categories, e.g. si = (si,1 , si,2 , . . . , si,72 )> = (SC,SC, . . . ,TR,TR, . . . ,EM,EM)> . Notably,
the transitions HE
SC and TR
HE are never observed. The sequences share a common
length, the time periods are equally spaced, and there are no missing data.
It is of interest to relate the MVAD sequences to covariates in order to understand
whether dierent characteristics  related to gender, community, geographic and social conditions, and personal abilities  impact on the school-to-work trajectories. These covariates
are summarised in Table 1. All covariates were measured at the age of 16 (i.e. at the start of
the study period in July 1993), with the exception of `Funemp' and `Livboth', and are thus
static background characteristics. The MVAD data also come with associated observationspecic survey sampling weights. Each sample was weighted based on the rst state value at
age 16, and the `Grammar' and `Location' covariates (McVicar and Anyadike-Danes, 2002).
Table 1: Available covariates for the MVAD data set. For binary covariates, the event denoted by 1 is
indicated. Otherwise, the levels of the categorical covariate `Location' are grouped in curly brackets.
Covariate
Gender
Catholic
Grammar
Funemp
GCSE5eq
FMPR
Livboth
Location

Description
1=male
1=yes
Type of secondary education, 1=grammar school
Father's employment status as of June 1999, 1=employed
Qualications gained by the end of compulsory education,
1=5+ GCSEs at grades A-C, or equivalent
SOC code of father's current or most recent job as of the beginning of the survey,
1=SOC1 (professional, managerial, or related)
Living arrangements as of June 1995, 1=living with both parents
{Belfast, N. Eastern, Southern, S. Eastern, Western}

The MVAD data are available in the R packages MEDseq and TraMineR (Gabadinho et al.,
2011). As the data have been used to illustrate some of the functionalities of the TraMineR
1
package in its associated vignette , interesting features of an exploratory analysis of the data
can be found therein. However, we reproduce plots of the transversal state distributions in
Figure 1 and the transversal Shannon entropies in Figure 2, i.e. the entropies of each time
point of the state distribution (Billari, 2001). Note that the sampling weights are accounted
for in both cases.
Figure 1 shows that the number of subjects who found employment increased over time.
Conversely, fewer students were in training or further education by the end of the observation
period. Most students appear to have entirely left school within 2/3 years of the commencement of the survey. Interestingly, many students were jobless during the rst two months
of observation, possibly because this period coincided with the summer break from school.
Finally, while students only began to pursue higher education from July 1995 onwards, a
number of students had already pursued further education during the two preceding years.
Figure 2 conrms that the heterogeneity of the state distribution varies over time. In particular, the entropies decline after Sep 1995, by which point most students had left school.
1

cran.r-project.org/web/packages/TraMineR/vignettes/TraMineR-state-sequence.pdf

4

Employment
Further Education

Jul.96
Time

Jul.97

0.6
0.4
0.2

Weighted Entropy Index
Jul.95

Jul.98
0.0

Jul.94

0.8

1.0

1.0
0.8
0.6
0.4

Weighted Proportions

0.2
0.0
Jul.93

Higher Education
Joblessness

Jul.93

School
Training

Jul.94

Jul.95

Jul.96

Jul.97

Jul.98

Time

Figure 1: Overall state distribution for the weighted Figure 2: Transversal entropy plot for the weighted
MVAD data.
MVAD data.

3

Modelling

In this section, we introduce the family of MEDseq models. The exponential-distance
model is described in Section 3.1, extended to account for sampling weights in Section 3.2,
expanded into a family of mixtures in Section 3.3, and nally embedded within the mixture
of experts framework in Section 3.4 in order to accommodate covariates.

3.1 Exponential-Distance Models
For an arbitrary distance metric d(Â·, Â·), a location parameter Î¸ , and a precision parameter
Î», the probability mass function (PMF) of an exponential-distance model for sequences is

f (si | Î¸, Î», d) = P

exp(âˆ’Î»d(si , Î¸))
= Î¨(Î», Î¸ | T, v)âˆ’1 exp(âˆ’Î»d(si , Î¸)) ,
si âˆˆS0 exp(âˆ’Î»d(si , Î¸))

(1)

with the corresponding log-likelihood function given by

`(Î¸, Î» | S, d) =

n
X

log f (si | Î¸, Î», d) = âˆ’Î»

i=1

n
X

d(si , Î¸) âˆ’ n log Î¨(Î», Î¸ | T, v) .

(2)

i=1

Such a model is analogous to the Gaussian distribution (characterised by the squared
Euclidean distance from the mean) and similar to the Mallows model for permutations
(Mallows, 1957). Indeed, mixtures of Mallows models have been used to cluster rankings
(Murphy and Martin, 2003). We only consider models with Î» â‰¥ 0. When Î» = 0, the
distribution of sequences is uniform. For Î» > 0, the central sequence Î¸ is the mode, i.e.
the sequence with highest probability, and the probability of any other sequence decays
exponentially as its distance from Î¸ increases. The precision parameter Î» controls the speed
of this decay. Larger Î» values cause sequences to concentrate around Î¸ , tending toward a
point-mass as Î» â†’ âˆž. Notably, Î» is not identiable when all sequences are identical.
The log-likelihood in (2) is generally intractable, as the normalising constant Î¨(Î», Î¸ | T, v)
depends on Î» (and possibly also on Î¸ , for some more complicated distances), as well as the
xed constants T and v , and requires a sum over all possible sequences. With reference to the
MVAD data, for example, the computation of Î¨(Î», Î¸ | T, v) is practically infeasible because
there are v T = 672 possible sequences. Fortunately, however,Pthe normalising constant exists in closed form under the Hamming distance, dH (si , sj ) = Tt=1 1(si,t 6= sj,t ), in a manner
5

which facilitates direct enumeration and crucially does not depend on Î¸ . Consider, for example, the Hamming distances between all ternary (v = 3) sequences of length T = 4. From the
arbitrary reference sequence (0, 0, 0, 0), there is 1 instance of a distance of 0, 8 instances of a
distance of 1, 24 instances of a distance of 2, 32 instances of a distance of 3, and 16 instances
of a distance of 4. Therefore, Î¨H (Î» | T, v) = e0 + 8eâˆ’Î» + 24eâˆ’2Î» + 32eâˆ’3Î» + 16eâˆ’4Î» . Hence,
the normalising constant under the Hamming distance metric depends on the parameter Î»,
the sequence length T , and the number of categories v , and simplies greatly:
T  
X
T
T
Î¨H (Î» | T, v) =
(v âˆ’ 1)p exp(âˆ’Î»p) = (v âˆ’ 1) eâˆ’Î» + 1 .
(3)
p
p=0
Inspired by the generalised Mallows model (Irurozki et al., 2019), the model in (1) based
on the Hamming distance can be extended to one based on the weighted Hamming distance.
By introducing T precision parameters Î»1 , . . . , Î»T , one for each time
PT point (i.e. sequence
position), and expressing the exponent in (1) as dWH (si , Î¸) =
t=1 Î»t 1(si,t 6= Î¸t ) rather
PT
than Î»dH (si , Î¸) = Î» t=1 1(si,t 6= Î¸t ), dierent time periods can contribute dierently to the
overall distance, weighted according to the period-specic precision parameters. Thus, the
distance from a sequence to the central sequence under the weighted Hamming distance
becomes a sum of the precision parameters associated with each time point which diers
from the corresponding central sequence position. This allows modelling a situation in
which there is high consensus regarding the state values of some time period(s), with a large
uncertainty about the values of others, and can help to prevent sequences the same distance
from Î¸ from having the same probability. Returning to the MVAD data, the non-constant
transversal entropies in Figure 2 suggest that such an extension may be fruitful. The
extension requires rewriting the log-likelihood in (2) with the weighted Hamming distance
decomposed into its T components and the normalising constant (3) also modied:
" T
#
n

X
X

`(Î¸, Î»1 , . . . , Î»T | S, dWH ) = âˆ’
Î»t 1(si,t 6= Î¸t ) + log (v âˆ’ 1) eâˆ’Î»t + 1
.
i=1

t=1

Though other dissimilarity measures are available for sequences, we henceforth consider
only the Hamming or weighted Hamming distances. The Hamming distance in our setting
can be seen as a special case of OM with all substitution costs equal to Î» and no insertions
or deletions. The weighted Hamming distance is similar to the dynamic Hamming distance
(Lesnard, 2010), a prominent alternative to OM, in the sense of having time-varying substitution costs. However, the substitution costs in our model are always assumed to be
common with respect to each pair of states. Hence, the weighted Hamming distance corresponds to the Gower distance (Gower, 1971) with equally weighted states and equally or
unequally weighted time points.

3.2 Incorporating Sampling Weights
Sampling weights are frequently used for life-course data, as the data typically arise from
surveys where the weights are used to correct for representivity bias or stratied sampling
schemes. Following Chambers and Skinner (2003), the sampling weights w = w1 , . . . , wn
are incorporated into the exponential-distance model by simply raising every element of the
likelihood to the power of the corresponding weight wi .
A secondary benet of this extension is that it facilitates computational gains in the
presence of duplicate observations. Such duplicates are quite likely when dealing with discrete life-course data. Indeed, non-uniqueness can be exploited using likelihood weights for
6

computational eciency, by tting models to the subset of unique sequences only, weighted
by the product of their occurrence frequencies and their sampling weights (if available, otherwise wi = 1 âˆ€ i). The number of duplicates clearly lowers when considering both the
sequences themselves and their associated covariate patterns. In particular, all observations
are unique when there are continuous covariates. Nonetheless, in many applications  e.g.
the MVAD data (see Table 1)  the covariates are all categorical. Hence, exploiting occurrence frequencies in this manner can be extremely convenient. For instance, only 557 of the
n = 712 sequences in the MVAD data set are distinct.

3.3 A Family of Mixtures of Exponential-Distance Models
Extending the exponential-distance model with the Hamming distance and sampling weights
to the model-based clustering setting yields a weighted likelihood function of the form
" G
#w
n
Y
X exp(âˆ’Î»dH (si , Î¸ g )) i
,
Lw (Î», Î¸ 1 , . . . , Î¸ G | S, w, dH ) =
Ï„g
âˆ’Î» + 1)T
((v
âˆ’
1)
e
i=1 g=1
where the mixing proportions Ï„1 , . . . , Ï„G are positive and sum to 1. Thus, the clustering
approach is both model-based and distance-based, thereby bridging the gap between these
two `cultures' in the SA community.
The mixture setting naturally suggests a further extension, whereby the precision parameter Î» can be constrained or unconstrained across clusters, in addition to the aforementioned
possibility for the precision parameters to be constrained or unconstrained across time
points. Within a family of models we term `MEDseq', we thus dene the CC, UC, CU, and
UU models, where the rst letter denotes whether precision parameters are constrained (C)
or unconstrained (U) across clusters and the second denotes the same across time points.
Hence, all but the CC model employ dierent weighted variants of the Hamming distance.
Given the role played by Î» when it takes the value 0, whereby the distribution of the
sequences is uniform, it is convenient and natural to include a noise component (denoted by
N) whose single precision parameter is xed to 0. This extension can be added to each of
the 4 models above, regardless of how the precision parameters are otherwise specied. This
completes the MEDseq model family with the CCN, UCN, CUN, and UUN models. When
G = 1, the CC, CU, and CCN models can be tted. When G = 2, the CCN and CUN models
are equivalent to the UCN and UUN models, respectively, as there is only one non-noise
component. As the noise component arises naturally from restricting the parameter space,
we consider the noise component as one of the G components, denoted hereafter with the
subscript 0. All 8 model types are summarised further in Appendix A.

3.4 Incorporating Covariates
We now illustrate how to incorporate the available covariate information into the clustering
process, both to guide the construction of the clusters and to better interpret the type of
observation characterising each cluster. As is typical for model-based clustering analyses,
the data are augmented in MEDseq models by introducing a latent cluster membership
indicator vector zi = (zi,1 , . . . , zi,G )> , where zi,g = 1 if observation i belongs to cluster g and
zi,g = 0 otherwise. An advantage of the MEDseq approach is that it can be easily extended
to incorporate the possible eects of covariates on the sequence trajectories by allowing the
covariates to inuence the distribution of the latent variable zi .

7

The inclusion of covariates is achieved under the mixture of experts framework (Jacobs
et al., 1991; Gormley and FrÃ¼hwirth-Schnatter, 2019), by extending the mixture model
to allow the mixing proportions for observation i to depend on covariates xi . This is
particularly attractive as the interpretation of the remaining component-specic parameters
is the same as it would be under a model without covariates. For example, in the case of
the CC MEDseq model
" G
#wi
X
exp(âˆ’Î»dH (si , Î¸ g ))
f (si | Î», Î¸ 1 , . . . , Î¸ G , xi , wi , dH ) =
Ï„g (xi )
,
((v âˆ’ 1) eâˆ’Î» + 1)T
g=1
where the mixing proportions Ï„g (xi ) are referred to as `gates' or the `gating network', with
P
Ï„g (xi ) > 0 and G
g=1 Ï„g (xi ) = 1, as usual. Such a model can be seen as a conditional mixture
model (Bishop, 2006) because, given the covariates xi , the distribution of the sequences is
a nite mixture model under which zi has a multinomial distribution with a single trial
and probabilities equal to Ï„g (xi ). The distance-based k -medoids algorithm, though closely
related (see Section 4.2), does not accommodate the inclusion of covariates.
Incorporating covariates in `hard' clustering algorithms using MLR, as per McVicar
and Anyadike-Danes (2002), has been criticised because the hard assignment of extraneous
cases can negatively impact internal cluster cohesion and the MLR coecient estimates
(Piccarreta and Studer, 2019). An advantage of the noise component in MEDseq models
is that it captures uniformly distributed sequences that deviate from those in the other,
more dened clusters. Filtering outliers in this way lessens their impact on the non-noise
gating network coecients, thereby enabling more accurate inference and improving the
interpretability of the eects of the covariates. Moreover, the `soft' partition obtained
under the model-based paradigm allows the cluster membership probabilities for sequences
lying on the boundary between two neighbouring clusters to be quantied and the eect of
such sequences on the gating network coecients to be mitigated.
As per Murphy and Murphy (2019), the CCN, UCN, CUN, and UUN models which include
an explicit noise component can be restricted to having covariates only inuence the mixing
proportions for the non-noise components, with all observations therefore assumed to have
equal probability of belonging to the uniform noise component (i.e. by replacing Ï„0 (xi ) with
Ï„0 ). We refer to the former setting as the gated noise (GN) model and to the latter as the
non-gated noise (NGN) model. Gating covariates can only be included when G â‰¥ 2 under
the GN model or when there are 2 or more non-noise components under the NGN model.

4

Model Estimation

This section describes the strategy employed for model tting and some implementation
issues that arise in practice. Specically, Section 4.1 outlines the ECM algorithm employed
for parameter estimation, Section 4.2 discusses the initialisation of the ECM algorithm with
reference to the similarities between MEDseq models and the k -medoids algorithm, and the
issues of model selection and variable selection are treated in Section 4.3.

4.1 Model Fitting via ECM
Parameter estimation is greatly simplied by the existence of a closed-form expression for
the normalising constant for MEDseq models under the Hamming or weighted Hamming
distances. We focus on maximum likelihood estimation using a simple variant of the EM
algorithm (Dempster et al., 1977). For simplicity, model tting details are described chiey
for the CC MEDseq model with sampling weights and gating covariates. Additional details
8

for other model types are deferred to Appendix B. The complete data likelihood for the
model is given by
!zi,g #wi
"G
n
Y
Y

exp(âˆ’Î»d
(s
,
Î¸
))
H i
g
Lw
,
Ï„g x i
c (Î», Î¸ 1 , . . . , Î¸ G | S, X, Z, w, dH ) =
T
âˆ’Î»
((v
âˆ’
1)
e
+
1)
i=1 g=1

CC

and the complete data log-likelihood hence has the form

`w
c (Î», Î¸ 1 , . . . , Î¸ G

| S, X, Z, w, dH ) =

n X
G
X
i=1


zi,g wi [log Ï„g xi âˆ’ Î»dH (si , Î¸ g )
g=1

âˆ’T log (v âˆ’ 1) eâˆ’Î» + 1 .

(4)

Under this model, the distribution of si depends on the latent cluster membership variable
zi , which in turn depends on covariates xi , while si is independent of xi conditional on zi .
The iterative algorithm for MEDseq models follows in a similar manner to that for standard mixture models. It consists of an E-step (expectation) which replaces for each observation the missing data zi with their expected values b
zi , followed by a M-step (maximisation),
which maximises the expected complete data log-likelihood. The M-step is replaced by a
series of conditional maximisation (CM-steps) in which each parameter is maximised individually, conditional on the other parameters remaining xed. Hence, model tting is
in fact conducted using an expectation conditional maximisation (ECM) algorithm (Meng
and Rubin, 1993). Aitken's acceleration criterion is used to assess convergence of the nondecreasing sequence of weighted log-likelihood estimates (BÃ¶hning et al., 1994). Parameter
estimates produced on convergence achieve at least a local maximum of the weighted likelihood function. Upon convergence, cluster memberships are estimated via the maximum a
posteriori (MAP) classication.
The E-step (with similar expressions when Î» is unconstrained across clusters and/or time
points) involves computing expression (5), where (m + 1) is the current iteration number:


(m)
(m+1)
(m) b (m)
b
b
= E zi,g si , xi , Î¸ g , Î» , Î² g , wi , dH
zbi,g


(m)
(5)
b(m) , Î»
b(m) , wi , dH
Ï„bg xi f si Î¸
g
.
=P


(m)
G
b(m) , Î»
b(m) , wi , dH
x
f
s
Î¸
Ï„
b
g
i
i
g
g=1
Note that the weights wi in the numerator and denominator cancel each other out, leaving
the E-step unchanged regardless of the inclusion or exclusion of weights.
Subsequent subsections describe the CM-steps for estimating the remaining parameb (m+1) =
ters in the model. These individual CM-steps rely on the current estimates
Z
(m+1)
(m+1)
(m+1)
b
b
z1
,...,b
zn
to provide estimates of the regression coecients Î²
, and hence
g
(m+1)
b(m+1) and
the mixing proportion parameters Ï„bg
(xi ), as well as the central sequence(s) Î¸
g
b(m+1) . It is clear from (4) that the sampling weights
component precision parameter(s) Î»
(m+1)

can be accounted for by simply multiplying every zbi
by the corresponding weight wi .
Conversely, in the CM-steps which follow, corresponding formulas for unweighted MEDseq
(m+1)
(m+1)
models can be recovered by replacing zbi,g wi with zbi,g . The sampling weights for the
MVAD data sum to â‰ˆ 711.52, rather than n = 712 though the parameter estimates are
not aected by multiplying the weights by a constant value. However, to account for the
dierent characteristics of dierent weighting systems,Pall relevant subsequent formulas explicitly account for the sum of the weights, with W = ni=1 wi , so as to focus on the relative
importance of each case as a representative of cases in the population.
9

4.1.1 Estimating the Gating Network Coecients

P P
The portion of (4) corresponding to the gating network, given by ni=1 G
g=1 zi,g wi log Ï„g xi ,
is of the same form as a MLR model with weights given by wi , here written with component
1 as the baseline reference level, for identiability reasons:
log

Ï„g (xi )
Pr(zi,g = 1)
ei Î² g âˆ€ g â‰¥ 2, with Î² 1 = (0, . . . , 0)>,
= log
=x
Ï„1 (xi )
Pr(zi,1 = 1)

ei = (1, xi ). Thus, methods for tting such models can be used to maximise the
where x
expectation of this term
at each iteration to nd estimates of the regression parameters in
(m+1)
b
the gating network Î² g
and hence the mixing proportions via


b (m+1)
ei Î²
exp x
g
Ï„bg(m+1) (xi ) = P

.
(m+1)
G
b
e
exp
x
Î²
i g
g=1
(m+1)

When there are no gating covariates, the mixing proportions are estimated by Ï„bg
=
Pn (m+1)
(m+1)
âˆ’1
b
bi,g wi , i.e. the weighted mean of the g -th column of the matrix Z
. HowW
i=1 z
1
ever, Ï„ can also be constrained to be equal (i.e. Ï„g = /G âˆ€ g ) across clusters. Thus,
situations where Ï„i,g = Ï„g (xi ), Ï„i,g = Ï„g , or Ï„i,g = 1/G are accommodated.
The standard errors of the MLR in the gating network at convergence are not a valid
means of assessing the uncertainty of the coecient estimates as the cluster membership
probabilities are estimated rather than xed and known. Therefore, we adapt the weighted
likelihood bootstrap (WLBS) of O'Hagan et al. (2019) to the MEDseq setting. This is easily
implemented by multiplying the sampling weights wi by draws, for each of B samples, from
an n-dimensional symmetric uniform Dirichlet distribution. To ensure stable estimation of
b
the standard errors, B = 1000 is used here. To ensure rapid convergence, the estimated Z
matrix under the optimal model t to the full data set is used to initialise the ECM algorithm
when retting models to each sample with corresponding new likelihood weights. Finally,
the standard errors of the gating network coecients across the B samples are obtained.

4.1.2 Estimating the Central Sequences
The location parameter Î¸ is sometimes referred to as the FrÃ©chet mean or the central
sequence. The k -medoids/PAM algorithm, which is closely related to the MEDseq modbg to be the
els with certain restrictions imposed (see Section 4.2), xes the estimate of Î¸
medoid of cluster g (Kaufman and Rousseeuw, 1990), i.e. the observed sequence with minimum distance from the others currently assigned to the same cluster. This estimation
approach is especially quick as the Hamming distance matrix for the observed sequences is
pre-computed. Notably, this greedy search strategy may fail to nd the optimum solution.
However, it can be shown  for a single unweighted exponential-distance model based
b is given simply by the modal sequence, which is intuitive
on the Hamming distance  that Î¸
P
when dH (si , sj ) is expressed as T âˆ’ Tt=1 1(si,t = sj,t ). Thus, the parameter has a natural
interpretation. For more complicated distance metrics, the rst-improvement algorithm
(Hoos and StÃ¼tzle, 2004) or a genetic algorithm could be used to estimate Î¸ . Notably, the
modal sequence need not be an observed sequence. It is also notable that the FrÃ©chet mean
may be non-unique under any of the proposed estimation strategies.
For the G > 1 MEDseq setting, under
P the ECM framework,central sequence position
(m+1)
(m+1)
n
b
estimates Î¸g,t
are given by arg minÏ‘
bi,g wi 1(si,t 6= Ï‘) . Since this expression is
i=1 z
independent of the precision parameter(s), it holds for all MEDseq model types, including
10

bg is estimated easily
those which employ the weighted Hamming distance variants. Thus, Î¸
and exactly via a type of weighted mode, which is composed, for each position in the
(m+1)
sequence, by the category corresponding to the maximum of the sum of the weights zbi,g wi
associated with each of the v observed state values. Similarly, the central sequence under a
weighted G = 1 model is also estimated via a weighted mode, with the weights given only
by wi . Notably, to estimate the FrÃ©chet mean for a MEDseq model of any type without
sampling weights, one need only remove wi from these terms. Note also that Î¸ 0 does
not need to be estimated for the models with an explicit noise component as it does not
contribute to the likelihood.

4.1.3 Estimating the Precision Parameters
It is worth noting, for the exponential-distance model in general, with any distance metric,
that the method of moments estimate for Î» is equal to the maximum likelihood estimate
(MLE). This is because, for xed Î¸ , the PMF in (1) belongs to the exponential family with
b already estimated as per Section 4.1.2, Î»
b ensures that
natural parameter Î». Hence, with Î¸
b is equal to the observed average distance from
the expected distance of observations from Î¸
b
Î¸ , since the solution of


P
n
b exp âˆ’Î»d si , Î¸
b
b d)
d
s
,
Î¸
0
1X
âˆ‚`(Î» | S, Î¸,
i
si âˆˆS
b .
âˆ’
=
d(si , Î¸)

P
b
nâˆ‚Î»
n
i=1
si âˆˆS0 exp âˆ’Î»d si , Î¸
implies

P
b =
EÎ» (d(S, Î¸))



n
b exp âˆ’Î»d si , Î¸
b
 1X

d si , Î¸
b
b .
= d S, Î¸ =
d si , Î¸

P
b
n i=1
s âˆˆS0 exp âˆ’Î»d si , Î¸

si âˆˆS0

(6)

i

Under the Hamming distance, the value of the expectation in (6) holds for any arbitrary
b. Hence, with known Î¸
b, the MLE for Î» for an unweighted
reference sequence in place of Î¸
single-component CC model can be obtained as follows:



b dH = âˆ’Î»ndH S, Î¸
b âˆ’ nT log (v âˆ’ 1) eâˆ’Î» + 1 ,
` Î» | S, Î¸,

nT (v âˆ’ 1)
âˆ‚` (Â·)
b ,
= Î»
âˆ’ ndH S, Î¸
âˆ‚Î»
e + (v âˆ’ 1)
!

T
b = log (v âˆ’ 1)
.
âˆ´ Î»
 âˆ’1
b
dH S, Î¸

b. Recall that we only consider Î» â‰¥ 0. Since
However, this can yield a negative value for Î»
all distances are non-negative and typically not identical, âˆ‚`(Â·)
is negative âˆ€ Î» > 0 in the
âˆ‚Î»


âˆ’1
b > v T (v âˆ’ 1), with limÎ»â†’âˆž âˆ‚`(Â·) = âˆ’ndH S, Î¸
b .
case where the sucient statistic dH S, Î¸
âˆ‚Î»
Thus,
!



T
b
Î» = max 0, log (v âˆ’ 1)
.
 âˆ’1
b
dH S, Î¸

b < v âˆ’1 T (v âˆ’ 1), such that Î»
b > 0, the identity log(c (a/b âˆ’ 1)) = log(c) +
When dH S, Î¸
b is set to 0. When sampling
log(a âˆ’ b) âˆ’ log(b) is used for numerical stability, otherwise Î»
weights are included, following the same steps as above yields the corresponding estimate

!
T
W
b = max 0, log(v âˆ’ 1) + log P
Î»
.
(7)
 âˆ’1
n
b
w
d
s
,
Î¸
i
H
i
i=1
11

b can potentially be estimated as zero, the inclusion of a noise component in the
While Î»
CCN, UCN, CUN, and UUN models makes this explicit, by restricting one of the clusters to
bg,t = 0 âˆ€ t = 1, . . . , T . When Î»
bg,t is either estimated as zero or set to zero, estimating
have Î»
the corresponding Î¸ g,t parameter has no eect on the likelihood.
b(m+1)
The ECM algorithm is employed when G > 1, in which case the CM-step for Î»
under a CC MEDseq mixture model with sampling weights is given by
P P
n X
G
X
T (v âˆ’ 1) ni=1 G

âˆ‚`w
g=1 zi,g wi
c (Â·)
bg ,
=
âˆ’
zi,g wi dH si , Î¸
Î»
âˆ‚Î»
e + (v âˆ’ 1)
i=1 g=1
ï£«
!ï£¶
Pn PG (m+1)
T i=1 g=1 zbi,g wi
b(m+1) = maxï£­0, log(v âˆ’ 1) + log
âˆ´ Î»
âˆ’ 1 ï£¸.
Pn PG (m+1)
(m+1) 
b
bi,g wi dH si , Î¸ g
i=1
g=1 z

(8)

As per (7), this requires the current estimate of each component's central sequence. Again, as
each case has wi = 1 when there are no sampling weights, one need only drop the wi and W
terms from (7) and (8) to estimate the precision parameters of unweighted MEDseq models.
The expressions for the weighted complete data likelihoods and corresponding CM-steps for
their precision parameters are given for the remaining MEDseq model types in Appendix B.

4.2 ECM Initialisation
The MEDseq models share relevant features with the k -medoids/PAM algorithm based on
the Hamming distance. Indeed, MEDseq models dier from PAM only in that i) Î¸ g is
estimated by the modal sequence rather than the medoid, ii) Ï„ is estimated, or even dependent on covariates via Ï„g (xi ), rather than constrained to be equal, iii) Î» is allowed to vary
across clusters and/or time points, iv) a noise component can be included, and v) the ECM
algorithm rather than the classication EM algorithm (CEM; Celeux and Govaert, 1992) is
used. The C-step of the CEM
algorithm employed by PAM uses deterministic assignments
(m+1) 
(m+1)
, for which the denominator in (5) need not be evaluated.
= arg maxg zbi,g
zei,g
In other words, it can be shown that a CC model tted by CEM (albeit with conditional
maximisation steps), with equal mixing proportions and the central sequences estimated
by the medoid rather than the modal sequence, is equivalent to k -medoids based on the
Hamming distance. Therefore, we apply the k -medoids algorithm to the Hamming distance
matrix to initialise the ECM algorithm by obtaining `hard' starting values for the allocation
matrix Z. In particular, we rely on a weighted version of PAM available in the R package
WeightedCluster (Studer, 2013). This strategy is less computationally onerous than using
multiple random starts and in our experience also achieves better results than using Ward's
hierarchical clustering to inform starting values. For models with an explicit noise component, it is necessary to supply an initial guess of the prior probability Ï„0 that observations
are noise, and initialise allocations, assuming the last component is the one associated with
Î»g = 0, by multiplying the initial Z matrix by 1 âˆ’ Ï„0 and appending a column in which each
entry is Ï„0 . We caution that the initial Ï„0 should not be too large.

4.3 Model Selection
In the MEDseq setting, the notion of model selection refers to identifying the optimal
number of components G in the mixture and nding the best MEDseq model type in terms
of constraints on the precision parameters. Variable selection on the subset of covariates
included in the gating network can also improve the t. For a given set of covariates, one
12

would typically evaluate all model types over a range of G values and choose simultaneously
both the model type and G value according to some criterion. Thereafter, dierent ts with
dierent covariates can be compared according to the same criterion.
The Bayesian Information Criterion (BIC; Schwarz 1978) includes a penalty term which
depends on the number of free parameters. Notably, the penalty term in our setting uses
log(W ) rather than log(N ). Preliminary analyses (e.g. Section 5.1) suggest that this penalty
term is not strict enough. Indeed, approaches relying on parameter counts may not be fruitful in general for categorical sequence data, although this may simply be an artefact of the
weighted Hamming distance metrics employed. Nevertheless, the number of free parameters
in the BIC penalty term under each MEDseq model type is summarised in Appendix A.
We turn to silhouette analysis approaches to assess the quality of the clustering in terms
of internal cluster cohesion, where high cohesion indicates high between-group distances and
strong within-group homogeneity. Typically the silhouette width is dened for clustering
methods which produce a `hard' partition (Rousseeuw, 1987), and the average silhouette
width (ASW) or weighted average silhouette width (wASW; Studer 2013) is used as a model
selection criterion. However, Menardi (2011) introduces the density-based silhouette (DBS)
for model-based clustering methods. This allows the `soft' assignment information to be
used, which would be discarded when using the MAP assignments in the computation of
the wASW. The empirical DBS for observation i is given by
 0
zb
log i1
zbi
ci =
 0 .
(9)
dbs
zbh
max h=1,...,n log 1
zbh

c i is proportional
As observations are assigned to clusters based on the MAP classication, dbs
to the log-ratio of the posterior probability associated with the MAP assignment of observation i (denoted by zbi0 ) to the maximum posterior probability that the observation belongs
c i â‰¤ 1 âˆ€ i,
to another cluster (denoted by zbi1 ). Use of the MAP classication implies 0 â‰¤ dbs
with high values indicating a well-clustered data point. Ultimately, the mean or the median
c value can be used both as a global quality measure and as a model selection criterion.
dbs
We employ a version of this criterion which is modied in two ways, both to identify
optimal models and as a means of validating the chosen model. Firstly, we identify a set of
crisply assigned observations having zÌ‚i1 lower than a tolerance parameter , here set equal to
c i values of 1 and are excluded from the computation
10âˆ’100 . These observations are given dbs
of the maximum in the denominator of (9) for reasons of numerical stability. Secondly, we
account for the sampling weights by computing a weighted mean density-based silhouette
criterion (wDBS). However, neither the wDBS nor wASW criteria are dened for G = 1.
Greedy stepwise selection can be used to further rene the models, in terms of guiding
the inclusion/exclusion of gating covariates. We propose a bi-directional search strategy
in which each step can potentially consist of adding or removing a covariate or adding or
removing a non-noise component. Every potential action is evaluated over all possible model
types at each step, rather than considering changing the model type as an action in itself.
Changing the gating covariates or changing the number of components can aect the model
type, as observed by Murphy and Murphy (2019). While this makes the stepwise search
more computationally intensive, it is less likely to miss optimal models as it explores the
model space. For steps involving both gating covariates and a noise component, models
with both the GN and NGN settings can be evaluated and potentially selected.

13

A backward stepwise search starts from the model including all covariates considered optimal in terms of the number of components G and of the MEDseq model type. On the other
hand, a forward stepwise search uses the optimal model with no covariates included as its
starting point. In both cases, the algorithm accepts the action yielding the highest increase
in the wDBS criterion at each step. The computational benets of upweighting unique cases
and discarding redundant cases are stronger for the forward search, as early steps with fewer
covariates are likely to have fewer unique cases across sequence patterns and covariates.

5

Analysing the MVAD Data

Results of tting MEDseq models to the MVAD data are provided in Section 5.1. All results
were obtained via the associated R package MEDseq (Murphy et al., 2019). A comparison
against other approaches, including hierarchical, partitional, and model-based clustering
methods, is included in Section 5.2. A discussion of the insights gleaned from the solution
obtained by the optimal MEDseq model is deferred to Section 6.
Due to the weighting scheme used by McVicar and Anyadike-Danes (2002), all results are
obtained on a version of the data with the rst time point removed. Similarly, the term `all
covariates' henceforth refers to all covariates in Table 1 except `Grammar' and `Location'.
While Murphy and Murphy (2019) show that the same covariate can aect more than one
part of a mixture of experts model, and in dierent ways, removing the quantities used to
dene the weights eases the interpretability of the results.

5.1 Application of MEDseq
Weighted MEDseq models are t across a range of G values, across all 8 model types, with
all covariates included in the gating network. The noise components, where applicable, are
treated using the GN setting. Figure 3 shows the behaviour of the BIC for these models.
Similar behaviour is observed for the ICL criterion (Biernacki et al., 2000). Evidently the
penalty terms based on parameter counts for these criteria are not large enough. Values of
both criteria do not start to decrease until the number of components is very large and
models with too many poorly populated components are identied. Thus, both are deemed
inadequate as a means of selecting optimal MEDseq models. The k -fold cross-validated likelihood, a model selection criterion which is free from parameter-counting (Smyth, 2000), also
penalises insuciently (with k = 10 folds). The Normalised Entropy Criterion (Celeux and
Soromenho, 1996), on the other hand, identies a model with too few components (G = 2).
However, using the wDBS criterion (see Figure 4), and again discarding solutions with
too few components, a reasonable G = 10 UCN model is identied as optimal. Thus, the
performance of the wDBS criterion in this setting is found to be superior to the various
criteria described above. The same model type and number of components are identied as
optimal according to the wDBS criterion when the noise components are treated with the
NGN setting, and when the same analysis is repeated with no gating covariates at all.
Notably, the wDBS criterion yields the same optimal model in both the GN and NGN
settings, and the setting with covariates excluded entirely, regardless of whether the weighted
c values is used. Interestingly, G = 10
mean or the weighted median of the individual dbs
appears to roughly coincide with where the plot of BIC values in Figure 3 begins to plateau.

14

1

5

10

15

20

25

30

CCN
UCN
CUN
UUN
35

0.5
0.4
0.3

CC
UC
CU
UU

CCN
UCN
CUN
UUN

0.2

âˆ’180000

âˆ’140000

BIC

Weighted Mean DBS

âˆ’100000

0.6

CC
UC
CU
UU

40

2

5

10

Number of Components (G)

15

20

25

30

35

40

Number of Components (G)

Figure 3: BIC values for weighted MEDseq models Figure 4: wDBS values for weighted MEDseq models
across a range of G values and model types.
across a range of G values and model types.

In rening the model further via greedy stepwise selection, both the forward search (see
Table 2) and backward search (see Table 3) begin with the same number of components
and the same model type. Covariates used to dene the sampling weights are excluded in
both cases. Both searches converge to the same G = 10 UCN model with the covariates
`FMPR', `GCSE5eq', and `Livboth' in the GN gating network. Under this model, the
probability of belonging to the noise component also depends on the included covariates.
Notably, the dierences between the respective clusterings produced by the models including
no covariates, all covariates, and the subset of covariates obtained by stepwise selection are
b matrices
marginal. This can be seen by computing the inner products between all pairs of Z
at convergence. For all three pairwise comparisons, the result, when normalised by its row
sums, diers only slightly from the 10-dimensional identity matrix. However, the model
uncovered by stepwise selection yields both the highest wDBS value and highest BIC value.
Table 2: Summary of the steps taken to improve the wDBS criterion in the forward direction.
Optimal Step

Add `GCSE5eq'
Add `Livboth'
Add `FMPR'
Stop

G
10
10
10
10
10

Model Type

UCN
UCN
UCN
UCN
UCN

Gating Covariates

GCSE5eq
FMPR, Livboth
FMPR, GCSE5eq, Livboth
FMPR, GCSE5eq, Livboth

Gating Type

GN
NGN
GN
GN

Mean DBS
0.4699
0.4724
0.4731
0.4745
0.4745

Table 3: Summary of the steps taken to improve the wDBS criterion in the backward direction.
Optimal Step


10

UCN

Remove `Catholic'

10

UCN

Remove `Funemp'
Remove `Gender'
Stop

10
10
10

UCN
UCN
UCN

G

Model Type

Gating Covariates
Catholic, FMPR, Funemp,
GCSE5eq, Gender, Livboth,
FMPR, Funemp, GCSE5eq,
Gender, Livboth,
FMPR, GCSE5eq, Gender, Livboth
FMPR, GCSE5eq, Livboth
FMPR, GCSE5eq, Livboth

Gating Type
GN

Mean DBS

GN

0.4735

GN
GN
GN

0.4740
0.4745
0.4745

0.4717

These results are not sensitive to the dropping of the rst time point or the covariates
used to dene the sampling weights. Repeating the analysis above with these quantities
retained leads to identical inference on the number of components, the MEDseq model type,
and the gating covariates identied via stepwise selection. When repeating the analysis with
15

the sampling weights discarded entirely, the results dier only in that `Funemp' is identied
by stepwise selection rather than `FMPR'. Finally, in order to ascertain the robustness of the
results to a coarsening of the sequences, the analysis was repeated once more with the data
taken at six-monthly intervals. Again, identical inference was obtained. Computationally,
the ECM algorithm's runtime was not greatly improved in doing so. Indeed, the MEDseq
method scales more poorly with n rather than T (and also v ), as the number of weighted
likelihood evaluations for large data sets is more computationally expensive than the number
of simple distance evaluations required for long sequences.

5.2 Other Clustering Methods

0.35
0.30

Weighted ASW

0.40

0.45

To contrast the MEDseq results with those obtained by other methods, MEDseq models
with no covariates and all covariates are compared, in Figure 5, against weighted versions of
k -medoids, using the R package WeightedCluster (Studer, 2013), and Ward's hierarchical
clustering, both based on the Hamming distance. Finite mixtures with rst-order Markov
components, t via the R package ClickClust (Melnykov, 2016b), are also included in the
comparison. LCA and latent class regression, t via the R package poLCA (Linzer and Lewis,
2011), are not included, as they encounter computational diculties due to the explosion
in the number of parameters even for G = 3. As `soft' cluster assignment probabilities are
not available for k -medoids or Ward's hierarchical clustering, their wDBS values cannot be
compared. Thus, Figure 5 illustrates a comparison of the wASW values using the MAP
classications where necessary; in so doing, the soft clustering information is discarded.
The ClickClust package allows the initial state probabilities to be either estimated or
equal to 1/v for all categories; both scenarios were considered. Other function arguments
were set to their default values. Only the MEDseq models accommodate gating covariates,
while all models except the ClickClust models accommodate the sampling weights. In all
cases, the rst time point was dropped. Only the MEDseq model type with the highest
wASW for each G value is shown, for clarity. The wASW values for the ClickClust models
are not shown; they are approximately 0.11 for G â‰¥ 2, and negative thereafter. Across all
G values, one of the MEDseq model types always outperforms its competitors.

MEDseq: no covariates
MEDseq: all covariates
k âˆ’medoids
Ward's Hierarchical Clustering
2

4

6

8

10 12

14

16 18 20 22 24 26 28 30 32 34 36 38 40

Number of Components (G)

Figure 5: Values of the wASW criterion, using Hamming distances, for the best MEDseq model type for each
G value with no covariates and all covariates. Corresponding values for weighted k -medoids and weighted
Ward's hierarchical clustering are also shown.

16

0.6

While the wASW values for the ClickClust models being close to zero or even negative
b matrix of cluster memshows inferior clustering behaviour, this method also returns a Z
bership probabilities. Thus, these models can be compared to the MEDseq models in terms
of the wDBS criterion also. This is shown in Figure 6. Again, only the best model of each
type is shown for each G value. The MEDseq models again exhibit the best performance
across the entire range of G values. Notably, the optimal ClickClust model according to
BIC has only G = 2 components. An advantage of ClickClust is that it allows sequences
of unequal lengths, but this is not a concern for the MVAD data.

0.4
0.3
0.1

0.2

Weighted Mean DBS

0.5

MEDseq: no covariates
MEDseq: all covariates
ClickClust

2

4

6

8

10 12

14

16 18 20 22 24 26 28 30 32 34 36 38 40

Number of Components (G)

Figure 6: Values of the wDBS criterion for the best MEDseq model type at each G value with no covariates
and all covariates. Corresponding values for the best ClickClust model are also shown.

The R package seqHMM (Helske and Helske, 2019) provides tools for tting mixtures of
hidden Markov models, with gating covariates inuencing cluster membership probabilities.
However, the sampling weights are not accommodated. Such models allow cluster memberships to evolve over time, similar to mixed membership models (Airoldi et al., 2014). They
thus cannot be directly compared to MEDseq models. However, we note that the seqHMM
package provides a pre-tted model for the MVAD data with 2 clusters  with 3 and 4
hidden states, respectively  and no covariates. Replicating the same model with the rst
time point omitted and otherwise using the same function arguments yields a model with
wDBS=0.50 and wASW=0.23. Otherwise identical seqHMM models, including either all covariates or only those deemed optimal for the MEDseq model using stepwise selection, both
achieve wDBS=0.47 and wASW=0.23. Notably, these wDBS values are comparable (albeit
inferior) to those for MEDseq models with G = 2, while the wASW values are much worse.

6

Discussion of the MVAD Results

The clusters uncovered by the G = 10 UCN model deemed optimal according to the wDBS
criterion for the MVAD data are shown in Figure 7. Seriation has been applied using
the overall Hamming distance matrix (Hahsler et al., 2008) to group observations within
clusters for visual clarity. To better inform a discussion of these results, corresponding
central sequence estimates are shown in Figure 8 and the average time spent in each state
by cluster  weighted by the estimated cluster membership probabilities  is shown in Table
4, along with the cluster sizes.
17

Noise
9
8
7
6

Clusters

5

4

3

2
1
Aug.93

Apr.94

Dec.94

Aug.95

Apr.96

Dec.96

Aug.97

Apr.98

Dec.98

Time

Employment
Further Education

Higher Education
Joblessness

School
Training

Figure 7: Clusters uncovered using the wDBS criterion for the optimal 10-component UCN model with
stepwise selection of covariates.

9
8
7

Clusters

6
5
4
3
2
1
Aug.93

Apr.94

Dec.94

Aug.95

Apr.96

Dec.96

Aug.97

Apr.98

Dec.98

Time

Employment
Further Education

Higher Education
Joblessness

School
Training

Figure 8: Central sequences of the optimal 10-component UCN model with stepwise selection of covariates.
The noise component's central sequence is not shown, as it does not contribute to the likelihood.

18

Table 4: Average time (in months) spent in each state by cluster, weighted by the estimated cluster membership probabilities, for the optimal 10-component UCN model with stepwise selection of covariates. Estimated
cluster sizes nbg correspond to the MAP partition.
Cluster (g )
1
2
3
4
5
6
7
8
9
Noise

n
bg

EM

FE

HE

JL

SC

TR

79
46
138
155
65
30
39
57
87
16

47.79
9.67
33.66
61.83
28.25
6.42
37.68
4.46
4.44
14.15

1.79
4.38
30.96
2.99
2.84
33.27
2.81
27.19
0.50
17.66

0.00
0.00
1.16
0.00
0.00
7.40
2.59
37.79
38.00
1.97

2.29
43.96
3.31
3.55
5.11
4.23
2.68
0.77
1.35
14.39

0.50
2.76
0.73
0.48
0.89
16.36
23.73
0.79
26.41
2.37

18.63
10.23
1.18
2.15
33.91
3.32
1.52
0.00
0.30
20.46

This solution tends to group individuals who experienced trajectories that are similar or
that dier only for relatively short periods. In particular, the dominating combinations of
states experienced over time are clearly identied, and dierences in durations and/or age at
transition are quite limited in size. Within clusters, substantial reduction of misalignments
and/or dierences in the durations of states are evident. Ultimately the partition is characterised not only by the sequencing (i.e. the experienced combinations of states), but also by
the durations of the states and by the ages at transitions which appear mostly homogeneous
within clusters. This can be explained by the fact that cases in the identied groups tended
to dedicate the same period of time  1, 2, or 3 years  to further/higher education and/or
training. This is interesting because one might expect the chosen dissimilarity metric to
attach higher importance to the sequencing.
The 10-cluster solution for the MVAD data separates individuals who prolonged their
studies after the end of compulsory education (clusters 3, 6, 7, 8, and 9) from those who
entered the labour market (clusters 1, 4, and 5). Interestingly, individuals who experienced
prolonged periods of unemployment are mostly isolated in cluster 2; this is particularly
important because the Status Zero Survey originally aimed to identify such `at risk' subjects.
Notably, the optimal model identied is a UCN model, i.e. one whose precision parameters vary only across clusters, and not across time points. The estimated precision parameters, given in Table 5, show that the model captures dierent degrees of homogeneity in the
cluster-specic sequence distributions. The sequences in clusters 1, 8, and 9, for instance,
show greater heterogeneity than the more uniformly distributed sequences in clusters 2,
3, and 6. Thus, model selection favours a model based on the simple Hamming distance
(albeit weighted dierently in each cluster) rather than a more exible variant which allows
dierent time periods to contribute dierently to the overall distance via period-specic
weights. Note that the wDBS criterion used to identify the model is not based on parameter counts, meaning the UCN model is not chosen over a more exible alternative on the
basis of parsimony.
Table 5: Precision parameters of the optimal 10-component UCN model with stepwise selection of covariates.
By denition, Î»g = 0 characterises the noise component.
Cluster (g )

1

2

3

4

5

6

7

8

9

Noise

bg
Î»

3.81

2.22

2.77

3.11

2.84

2.45

3.08

3.49

3.63

0

Clusters 6, 7 and 9 include subjects who continued school for about two years, presumably to retake previously failed examinations or to pursue academic or vocational qualications. These individuals are split into three groups depending on whether they continued
their studies (further education  cluster 6, or higher education  cluster 9) or were employed directly (cluster 7). Clusters 3 and 8 group subjects who entered further education,
19

for about two years (or more, in some cases in the larger cluster 3). Most of the subjects in
cluster 3 entered employment directly after further education, whereas the vast majority of
those in cluster 8 continued in further education until the end of the observation period.
As for the clusters of individuals who moved quickly to the labour market after the end
of compulsory education, it is possible to distinguish between individuals who immediately
found a job and remained in employment for most of the observation period (the large
cluster 4) and individuals who entered government-supported training schemes (clusters 1
and 5). A further separation is between subjects who were employed after about 2 years of
training (cluster 1) and those who participated in training for a much longer period (cluster
5). Importantly, most of the individuals in these two clusters were able to nd a job even
if some respondents experienced some periods of unemployment.
It is interesting to observe that the cluster of careers dominated by persistent unemployment (cluster 2) is characterized by dierent experiences at the end of the compulsory
education period. Indeed, some subjects entered employment directly after the end of compulsory education but left or lost their job after some months, while some prolonged their
education before becoming unemployed. However, the majority entered a training period
that did not evolve into steady employment.
The coecients of the gating network with associated WLBS standard errors are given in
Table 6, from which a number of interesting eects can be identied. The interpretation
of the eects of the covariates is made clearer by virtue of the lower number included after
stepwise selection. For completeness, gating network coecients and associated WLBS
standard errors for the model with all covariates included are provided in Appendix C.
Table 6: Multinomial logistic regression coecients and associated WLBS standard errors (in parentheses)
for the gating network of the optimal 10-component UCN model with stepwise selection of covariates.
Cluster
2
3
4
5
6
7
8
9

Noise

(Intercept)
âˆ’0.46 (0.45)
0.04 (0.39)
0.48 (0.38)
âˆ’0.16 (0.43)
âˆ’2.38 (0.91)
âˆ’0.19 (0.49)
âˆ’3.21 (0.50)
âˆ’1.76 (0.49)
âˆ’1.96 (0.62)

FMPR
GCSE5eq
âˆ’0.54 (0.56) âˆ’0.22 (0.70)
0.29 (0.45)
1.30 (0.46)
âˆ’0.89 (0.44) âˆ’0.25 (0.53)
âˆ’0.27 (0.52)
0.17 (0.59)
0.62 (0.63)
2.03 (0.75)
âˆ’0.66 (0.57)
1.37 (0.59)
0.28 (0.47)
3.34 (0.55)
0.71 (0.43)
3.85 (0.50)
0.37 (0.86)
1.70 (0.93)

Livboth
0.08 (0.51)
âˆ’0.30 (0.42)
âˆ’0.21 (0.37)
âˆ’0.07 (0.43)
1.43 (0.72)
âˆ’0.03 (0.51)
1.12 (0.49)
0.35 (0.43)
âˆ’1.07 (0.72)

Relative to the reference cluster (cluster 1), characterised by those who successfully
transitioned to stable employment after a short period of training, the positive `FMPR'
coecients indicate that those whose father's current or most recent job is professional or
managerial are more likely to belong to clusters 3, 6, 8, and 9. These clusters are characterised by extended periods of higher education and/or further education. Conversely, clusters 2, 4, 5, and 7 have negative `FMPR' coecients. The eect is particularly pronounced
for cluster 4, which mostly comprises subjects who immediately entered employment.
Those who achieved 5 or more high GCSE grades are less likely to experience joblessness
(cluster 2) or to immediately enter employment (cluster 4). This suggests, as expected, that
more academically inclined students tend to further their education in order to improve their
job prospects. The largest positive coecients for this covariate suggest that such students
are more likely to pursue higher education after an initial 2-year period in either school
(cluster 9) or further education (cluster 8). Additionally, such students are more likely
to secure employment immediately after periods of further education (cluster 3) or school
(cluster 7), or enter further education after prolonging their time in school (cluster 6).
20

Unlike the other covariates, `Livboth' was not measured until June 1995. According to
Figure 1, this coincides with the point by which most subjects had turned 18 and left school.
Subjects who lived at home with both parents at this point are more likely to have stayed in
school beyond the compulsory period and then pursued further education (cluster 6), or to
have stayed in school or further education and then pursued higher education (clusters 8
and 9, respectively). Interestingly, such subjects are also more likely to belong to cluster 2,
characterised by joblessness. This is the only covariate for which this is the case, perhaps
suggesting that subjects who are materially supported by their parents can aord to endure
extended periods of unemployment, possibly to research job opportunities in line with their
expectations. Conversely, subjects who do not live at home with both parents are more
likely to enter the job market sooner, either immediately (cluster 4), after long periods of
training (cluster 5), or after short periods in school (cluster 7) or further education (cluster
3). However, the eects of the `Livboth' coecients appear to be slight.
The optimal G = 10 UCN model contains a noise component, which allows the remaining
non-noise clusters to be modelled more clearly. Figure 9 focuses on this noise component,
which soaks up subjects who don't neatly t into any of the dened clusters and transition
frequently between states. This includes transitions in and out of education and in and out
of employment. The only covariate with a negative coecient associated with the noise
component is `Livboth'. It is likely that subjects living at home are given a strong sense of
direction by the inuence of their parents and benet from familial stability in terms of a
lack of disruption to their parents' marriage due to divorce or death.
16
15
14
13
12

Observations

11
10
9
8
7
6
5
4
3
2
1
Aug.93

Apr.94 Nov.94

Jul.95 Feb.96

Oct.96

Jun.97 Jan.98

Sep.98 Apr.99

Time
Employment
Further Education

Higher Education
Joblessness

School
Training

Figure 9: Observations assigned to the noise component of the optimal 10-component UCN model with
stepwise selection of covariates.

7

Conclusion

In McVicar and Anyadike-Danes (2002), Ward's hierarchical clustering algorithm is applied
to an OM dissimilarity matrix to identify relevant patterns in the data. Notably, reference is
not made to the associated covariates until the uncovered clustering structure is investigated.
21

In particular, MLR is used to relate the assignments of the trajectories to clusters to a set of
baseline covariates. It is also worth noting that the sampling weights are incorporated only
in the MLR stage and not in the clustering itself. In other words, weights are incorporated
only in the equivalent of the gating network. This is arguably a three-stage approach,
comprising the computation of pairwise string distances using OM (or some other distance
metric), the hierarchical or partition-based clustering, and the MLR.
MEDseq models, on the other hand, represent a more coherent model-based clustering
approach. The sequences are modelled directly using a nite mixture of exponential-distance
models, with the Hamming distance and weighted generalisations thereof employed as the
distance metric. A range of precision parameter settings have been explored to allow different time points contribute dierently to the overall distance. Thus, varying degrees of
parsimony are accommodated. Sampling weights are accounted for by weighting each observation's contribution to the likelihood. Dependency on covariates is introduced by relating
the cluster membership probabilities to covariates under the mixture of experts framework.
Thus, MEDseq models treat the weights, the relation of covariates to clusters, and the clustering itself simultaneously. Model selection in the MEDseq setting identies a reasonable
solution for the MVAD data and shows that clustering the sequence trajectories in a holistic
manner allows new insights to be gleaned from these data.
Opportunities for future research are varied and plentiful. Co-clustering approaches
could be used to simultaneously provide clusters of the observed sequence trajectories and
the time periods. While this would require the use of the CEM or stochastic EM algorithms
(Govaert and Nadif, 2013), such an approach could be especially useful for the MEDseq
models (CU, UU, CUN, and UUN) which weight the Hamming distance by period-specic
precision parameters, as it could reduce the number of within-cluster precision parameters
required to 1 < T ? â‰¤ T . Indeed, parsimony has been achieved in a similar fashion by
Melnykov (2016a) in the context of nite mixtures with Markov components. In particular,
co-clustering approaches which respect the ordering of the sequences by restricting the
column-wise clusters to form contingent blocks may prove especially useful.
It may also be of interest for other applications to extend the MEDseq models to accommodate sequences of dierent lengths, for which the Hamming distance is not dened.
These dierent lengths could be attributable to missing data, either by virtue of sequences
not starting on the same date, shorter follow-up time for some subjects, or non-response
for some time points. While the Hamming distance is only dened for equal-length strings,
adapting the MEDseq models to such a setting would be greatly simplied if aligning the
sequences of dierent lengths is straightforward. Another limitation of MEDseq models is
that time-varying covariates are not accommodated. However, neither of these concerns are
relevant for the MVAD data.
MEDseq models implicitly assume substitution-cost matrices with zero along the diagonal and a single value common to all other entries. The relationship between the exponent of
an exponential-distance model based on the Hamming distance and the Hamming distance
itself (which has a single substitution cost, typically equal to 1) is apparent from the fact
that multiplying the substitution-cost matrix by any scalar yields the same model, because
its value is absorbed into the precision parameter. This is also the case for models employing weighted Hamming distance variants under which the precision parameters, and hence
the otherwise common substitution costs, vary across clusters and/or time points. However, all model types in the MEDseq family cannot account for situations in which some
states are more dierent than others  e.g. one where the cost associated with moving from
employment to joblessness is assumed to be greater than the cost associated with moving
from school to training  as they assume that substitution costs are the same between each
22

pair of states. Such concerns are most pronounced when there is an explicit ordering to the
states, e.g. education levels (Studer and Ritschard, 2016).
Hence, another potential extension is to consider MEDseq models with an alternative
distance measure, particularly OM. This would require the subjective specication, or estimation, of the v(v âˆ’ 1)/2 o-diagonal entries of symmetric substitution-cost matrices.
Potentially, as per the range of precision parameter settings in the MEDseq model family,
the substitution-cost matrices could also be allowed to vary across clusters and/or time
points. However, the normalising constant under an exponential-distance model using OM
depends both on the heterogeneous substitution costs and on Î¸ and is not available in closed
form, thereby greatly complicating model tting. Indeed, the dependence on Î¸ renders even
oine pre-computation of the normalising constant infeasible for even moderately large T
or v . Considering insertions and deletions also would present further challenges. Truncation
of the sum over all sequences or an importance sampling approach could be used to address
the intractability. In any case, some level of approximation would be required, while the
ECM algorithm for MEDseq models based on the Hamming distance is exact.
As well as removing the normalising constant's dependence on Î¸ , another positive consequence of the homogeneity of substitution costs with respect to pairs of states under the
Hamming distance is that the ECM algorithm used for parameter estimation scales well
with v , the size of the alphabet. Though restrictive, having only one parameter associated
with each substitution-cost matrix, regardless of its dimensions, helps address concerns
about overparameterisation, especially when the substitution costs implied by the precision
parameter(s) vary across clusters and/or time points (Studer and Ritschard, 2016).
Furthermore, it is likely that results on the MVAD data would not dier greatly with
OM (with state-dependent substitution costs) used in place of the Hamming distance, particularly for models where Î» varies across clusters and/or time points, save for a solution
with potentially fewer clusters being found. Ultimately, the weighted Hamming distance
variants preserve the timing of transitions, by virtue of prohibiting insertions and deletions,
but amount to improved substitution costs reecting replacements of states.
Overall, the MEDseq models appear promising from the perspective of reconciling the
distance-based and model-based cultures within the SA community. The results on the
MVAD data are encouraging; they seem to suggest that the dierent precision parameter
settings of dierent MEDseq models adequately address the misalignment problem inherent
in the use of the Hamming distance. It remains to be seen if this holds for more turbulent
sequence data, e.g. those related to employment activities tracked over longer periods.

Acknowledgements
This work was supported by the Science Foundation Ireland funded Insight Centre for Data
Analytics in University College Dublin under grant number SFI/12/RC/2289_P2.

References
Abbott, A. and J. Forrest (1986). Optimal matching methods for historical sequences.
Journal of Interdisciplinary History 16 (3), 471494. 1
Abbott, A. and A. Hrycak (1990). Measuring resemblance in sequence data: an optimal
matching analysis of musician's careers. American Journal of Sociology 96 (1), 145185.
1
23

Agresti, A. (2002). Categorical Data Analysis. New York: John Wiley & Sons. 2
Airoldi, E. M., D. M. Blei, E. A. Erosheva, and S. E. Fienberg (2014). Handbook of Mixed
Membership Models and Their Applications. Chapman and Hall/CRC Press. 17
Baneld, J. and A. E. Raftery (1993). Model-based Gaussian and non-Gaussian clustering.
Biometrics 49 (3), 803821. 2
Biernacki, C., G. Celeux, and G. Govaert (2000). Assessing a mixture model for clustering
with the integrated completed likelihood. IEEE Transactions on Pattern Analysis and
Machine Intelligence 22 (7), 719725. 14
Billari, F. C. (2001). The analysis of early life courses: complex description of the transition
to adulthood. Journal of Population Research 18 (2), 119142. 4
Bishop, C. M. (2006). Pattern Recognition and Machine Learning. New York: Springer. 8
BÃ¶hning, D., E. Dietz, R. Schaub, P. Schlattmann, and B. G. Lindsay (1994). The distribution of the likelihood ratio for mixtures of densities from the one-parameter exponential
family. Annals of the Institute of Statistical Mathematics 46 (2), 373388. 9
Bouveyron, C., G. Celeux, T. B. Murphy, and A. E. Raftery (2019). Model-Based Clustering and Classication for Data Science: With Applications in R. Cambridge Series in
Statistical and Probabilistic Mathematics. Cambridge University Press. 2
Celeux, G. and G. Govaert (1992). A classication EM algorithm for clustering and two
stochastic versions. Computational Statistics and Data Analysis 14 (3), 315332. 12
Celeux, G. and G. Soromenho (1996). An entropy criterion for assessing the number of
clusters in a mixture model. Journal of Classication 13, 195212. 14
Chambers, R. L. and C. J. Skinner (2003). Analysis of Survey Data. Chichester: John
Wiley & Sons. 6
Dayton, C. M. and G. Macready (1988). Concomitant-variable latent-class models. Journal
of the American Statistical Association 83 (401), 173178. 2
Dempster, A. P., N. M. Laird, and D. B. Rubin (1977). Maximum likelihood from incomplete
data via the EM algorithm. Journal of the Royal Statistical Society: Series B (Statistical
Methodology) 39 (1), 138. 8
Gabadinho, A., G. Ritschard, N. S. MÃ¼ller, and M. Studer (2011). Analyzing and visualizing
state sequences in R with TraMineR. Journal of Statistical Software 40 (4), 137. 4
Gormley, I. C. and S. FrÃ¼hwirth-Schnatter (2019). Mixtures of experts models. In
S. FrÃ¼hwirth-Schnatter, G. Celeux, and C. P. Robert (Eds.), Handbook of Mixture Analysis, Chapter 12, pp. 279316. London: Chapman and Hall/CRC Press. 2, 8
Govaert, G. and M. Nadif (2013). Co-Clustering: Models, Algorithms and Applications.
ISTE-Wiley. 22
Gower, J. C. (1971). A general coecient of similarity and some of its properties. Biometrics 27 (4), 857871. 6
Hahsler, M., K. Hornik, and C. Buchta (2008). Getting things in order: an introduction to
the R package seriation. Journal of Statistical Software 25 (3), 134. 17
24

Hamming, R. W. (1950). Error detecting and error correcting codes. The Bell System
Technical Journal 29 (2), 147160. 3
Helske, S. and J. Helske (2019). Mixture hidden Markov models for sequence data: the
seqHMM package in R. Journal of Statistical Software 88 (3), 132. 17
Helske, S., J. Helske, and M. Eerola (2016). Analysing complex life sequence data with hidden markov modeling. In G. Ritschard and M. Studer (Eds.), Proceedings of International
Conference on Sequence Analysis and Related Methods, pp. 209240. 3
Hoos, H. and T. StÃ¼tzle (2004). Stochastic Local Search: Foundations & Applications. San
Francisco, CA, USA: Morgan Kaufmann Publishers Inc. 10
Irurozki, E., B. Calvo, and J. A. Lozano (2019). Mallows and generalized Mallows model
for matchings. Bernoulli 25 (2), 11601188. 6
Jacobs, R. A., M. I. Jordan, S. J. Nowlan, and G. E. Hinton (1991). Adaptive mixtures of
local experts. Neural Computation 3 (1), 7987. 8
Kaufman, L. and P. J. Rousseeuw (1990). Partitioning around medoids (program PAM).
In Finding Groups in Data: An Introduction to Cluster Analysis, pp. 68125. New York:
John Wiley & Sons. 3, 10
Lazarsfeld, P. F. and N. W. Henry (1968). Latent Structure Analysis. Boston: Houghton
Miin. 2
Lesnard, L. (2010). Setting cost in optimal matching to uncover contemporaneous sociotemporal patterns. Sociological Methods & Research 38 (3), 389419. 6
Levenshtein, V. I. (1966). Binary codes capable of correcting deletions, insertions, and
reversals. Soviet Physics Doklady 10 (8), 707710. 1
Linzer, D. A. and J. B. Lewis (2011). poLCA: an R package for polytomous variable latent
class analysis. Journal of Statistical Software 42 (10), 129. 16
Mallows, C. L. (1957). Non-null ranking models. Biometrika 44 (1/2), 114130. 5
McVicar, D. (2000). Status 0 four years on: young people and social exclusion in Northern
Ireland. Labour Market Bulletin 14, 114119. 3, 4
McVicar, D. and M. Anyadike-Danes (2002). Predicting successful and unsuccessful transitions from school to work by using sequence methods. Journal of the Royal Statistical
Society: Series A (Statistics in Society) 165 (2), 317334. 3, 4, 8, 14, 21
Melnykov, V. (2016a). Model-based biclustering of clickstream data. Computational Statistics and Data Analysis 93 (C), 3145. 3, 22
Melnykov, V. (2016b). ClickClust: an R package for model-based clustering of categorical
sequences. Journal of Statistical Software 74 (9), 134. 16
Menardi, G. (2011). Density-based silhouette diagnostics for clustering methods. Statistics
and Computing 21 (3), 295308. 13
Meng, X. L. and D. R. Rubin (1993). Maximum likelihood estimation via the ECM algorithm: a general framework. Biometrika 80 (2), 267278. 9

25

Murphy, K. and T. B. Murphy (2019). Gaussian parsimonious clustering models with
covariates and a noise component. Advances in Data Analysis and Classication , 133.
URL https://doi.org/10.1007/s11634-019-00373-8. 2, 8, 13, 14
Murphy, K., T. B. Murphy, R. Piccarreta, and I. C. Gormley (2019). MEDseq: mixtures of
exponential-distance models with covariates. R package version 1.0.0. 3, 14
Murphy, T. B. and D. Martin (2003). Mixtures of distance-based models for ranking data.
Computational Statistics and Data Analysis 41 (34), 645655. 5
O'Hagan, A., T. B. Murphy, L. Scrucca, and I. C. Gormley (2019). Investigation of
parameter uncertainty in clustering using a Gaussian mixture model via jackknife,
bootstrap and weighted likelihood bootstrap. Computational Statistics , 135. URL
https://doi.org/10.1007/s00180-019-00897-9. 10
Pamminger, C. and S. FrÃ¼hwirth-Schnatter (2010). Model-based clustering of categorical
time series. Bayesian Analysis 5 (2), 345368. 3
Piccarreta, R. and M. Studer (2019). Holistic analysis of the life course: methodological
challenges and new perspectives. Advances in Life Course Research 41, 100251. 8

R

Core Team (2019). R: a language and environment for statistical computing. Vienna,
Austria: R Foundation for Statistical Computing. 3

Rousseeuw, P. J. (1987). Silhouettes: a graphical aid to the interpretation and validation
of cluster analysis. Computational and Applied Mathematics 20, 5365. 13
Schwarz, G. (1978). Estimating the dimension of a model. The Annals of Statistics 6 (2),
461464. 13
Smyth, P. (2000). Model selection for probabilistic clustering using cross-validated likelihood. Statistics and Computing 10 (1), 6372. 14
Studer, M. (2013). WeightedCluster library manual: a practical guide to creating typologies
of trajectories in the social sciences with R. Technical report, LIVES Working Papers 24.
12, 13, 16
Studer, M. and G. Ritschard (2016). What matters in dierences between life trajectories:
a comparative review of sequence dissimilarity measures. Journal of the Royal Statistical
Society: Series A (Statistics in Society) 179 (2), 481511. 2, 23
Wu, L. L. (2000). Some comments on sequence analysis and optimal matching methods in
sociology: review and prospect. Sociological Methods & Research 29 (1), 4164. 3

26

Appendices

Appendix A The MEDseq Model Family: Parameter Counts
The models in the MEDseq family dier only in their treatments of the precision parameters,
which dierentiate the Hamming distance and the weighted variants thereof. While the
BIC has been shown to be inadequate as a means of selecting MEDseq models, Table
A.1 nevertheless summarises the number of free parameters under each MEDseq model
type, in order to demonstrate the increasing level of complexity in moving from the most
parsimonious CCN model to the most heavily parameterised UU model. The number of
estimated parameters for each component's central sequence is treated as the sequence
length T , leading to the strictest possible penalty. Note that central sequence parameters
corresponding to time points with estimated or xed precision parameter values of 0 are
not counted. Note also that estimated precision parameter values of 0 are counted, but
precision parameters xed at 0 associated with the noise component are not counted. The
number of gating network parameters is not accounted for in Table A.1; when there are
gating covariates, there are (r + 1) Ã— G extra parameters, where r + 1 is the dimension
of the associated design matrix, including the intercept term. When mixing proportions
are constrained to be equal, there are no additional parameters for models without a noise
component and one additional parameter for models with a noise component; otherwise
there are G âˆ’ 1 additional parameters.
Table A.1: Number of estimated parameters under each MEDseq model type. Models with names ending
with the letter N, indicating the presence of a noise component for which the single precision parameter is
xed to 0, behave like the corresponding model without this component for all other components. Thus, Î»
and all subscript variants thereof refer to the non-noise components only.
Model

CC
CCN
UC
UCN
CU
CUN
UU
UUN

Precision

Î»g (Clusters)

Î»t (Time Points)

Î»g,t = Î»

Constrained

Constrained

Î»g,t = Î»g

Unconstrained

Constrained

Î»g,t = Î»t

Constrained

Unconstrained

Î»g,t = Î»g,t

Unconstrained

Unconstrained

Number of Parameters
Central Sequence(s)
Precision
GT 1(Î» 6= 0)
(G âˆ’ 1) T 1(Î» 6= 0)
P
T G
g=1 1(Î»g 6= 0)
PGâˆ’1
T g=1 1(Î»g 6= 0)
P
G T
t=1 1(Î»t 6= 0)
P
(G âˆ’ 1) T
1(Î»t 6= 0)
PG PT t=1
1(Î»
g,t 6= 0)
g=1
t=1
PGâˆ’1 PT
t=1 1(Î»g,t 6= 0)
g=1

1
1(G > 1)
G
Gâˆ’1
T
1(G > 1)T
GT
(G âˆ’ 1) T

Appendix B Further Details on Estimating MEDseq Models
Weighted complete data likelihood functions for all model types in the MEDseq family are
given in Table B.1. Table B.2 outlines the corresponding CM-steps for the precision parameter(s). The sampling weights are accounted for in all cases. The CM-step formulas can be
simplied somewhat for unweighted models. Recall that the rst letter of the model name
denotes whether the precision parameters are constrained/unconstrained across clusters,
the second denotes the same across time points (i.e. sequence positions), and model names
ending with the letter N include a noise component. All models are written as though gating
network covariates xi are included. Moreover, models with a noise component are written
in the GN rather than NGN form, i.e. it assumed that the covariates aect the mixing
proportions of the noise component rather than Ï„0 being constant (see Section 4.1). All
derivations closely follow the same steps as in Section 4.1.3 for the CC model.
27

Table B.1: Weighted complete data likelihood functions for all MEDseq model types, which dier according
to the constraints imposed on the precision parameters across clusters and/or time points. The expressions
for the various weighted Hamming distance metric variants employed are given in full.
Model

Weighted Complete Data Likelihood

CC

Qn

UC

Qn

CU

Qn

UU

Qn

CCN

Qn

UCN

Qn

CUN

Qn

UUN

Qn



i=1


g=1 Ï„g (xi )

QG

exp(âˆ’Î»

(

"
QG

Ï„g (xi )

QG


Ï„g (xi )

g=1

i=1



i=1

g=1

g=1

i=1



i=1

QGâˆ’1


Ï„g (xi )

"
QGâˆ’1

i=1

i=1

g=1



QGâˆ’1
g=1

i=1

g=1

zi,g wi

)

!zi,g #wi

PT
Î» 1(si,t 6=Î¸g,t ))

t=1 gt
âˆ’Î»g,t
+1
t=1 (vâˆ’1)e

exp(âˆ’
QT

exp(âˆ’Î»

(

PT

(

t=1 1 si,t 6=Î¸g,t
T
(vâˆ’1)eâˆ’Î» +1

))

!zi,g #wi

zi,g 

)

!zi,g

Ï„g (xi )

P
exp(âˆ’Î»g T
t=1 1(si,t 6=Î¸g,t ))

T
(vâˆ’1)eâˆ’Î»g +1

Ï„g (xi )

zi,g
P
Î»t 1(si,t 6=Î¸g,t ))
exp(âˆ’ T
QT t=1
âˆ’Î»
t
(vâˆ’1)e
+1
)
t=1 (

Ï„g (xi )

exp(âˆ’
QT



"
QGâˆ’1

))

zi,g wi
P
exp(âˆ’ T
Î»t 1(si,t 6=Î¸g,t ))
QT t=1
âˆ’Î»
t
(vâˆ’1)e
+1
)
t=1 (

Ï„g (xi )

g=1

(

t=1 1 si,t 6=Î¸g,t
T
(vâˆ’1)eâˆ’Î» +1

P
exp(âˆ’Î»g T
t=1 1(si,t 6=Î¸g,t ))

T
(vâˆ’1)eâˆ’Î»g +1

"
QG

PT

PT
Î» 1(si,t 6=Î¸g,t ))
t=1 gt

âˆ’Î»g,t
+1
t=1 (vâˆ’1)e

Ï„0(xi )
vT

zi,0 wi



Ï„0(xi )
vT



Ï„0(xi )
vT

!zi,g



zi,0

#w i

zi,0 wi

Ï„0(xi )
vT

zi,0

#wi

Table B.2: CM-steps for the precision parameter(s) for all MEDseq model types, which dier according to
the constraints imposed across clusters and/or time points.
Model

Precision Parameter CM-steps


Pn PG
(m+1)
wi
T
bi,g
i=1
g=1 z


Pn PG
(m+1)
b (m+1)
z
b
w
d
s
,
Î¸
i
i
H
g
g=1
i=1
i,g

!
âˆ’1

CC

b(m+1) = max 0, log(v âˆ’ 1) + log
Î»

UC

b(m+1)
Î»
= max 0, log(v âˆ’ 1) + log
g



CU

b(m+1) = max 0, log(v âˆ’ 1) + log
Î»
t



UU

b(m+1) = max 0, log(v âˆ’ 1) + log
Î»
g,t



CCN

b(m+1) = max 0, log(v âˆ’ 1) + log
Î»

UCN

b(m+1)
Î»
= max 0, log(v âˆ’ 1) + log
g



CUN

b(m+1) = max 0, log(v âˆ’ 1) + log
Î»
t



PGâˆ’1 (m+1)
bi,g
wi
i=1
g=1 z


Pn PGâˆ’1 (m+1)
b(m+1)
bi,g
wi 1 si,t 6=Î¸
g,t
g=1 z
i=1

UUN

b(m+1) = max 0, log(v âˆ’ 1) + log
Î»
g,t



(m+1)
bi,g
wi
i=1 z


Pn
(m+1)
b(m+1)
z
b
w
1
s
i
i,t 6=Î¸g,t
i=1 i,g

(m+1)
bi,g
wi
i=1 z


(m+1)
b (m+1)
z
b
w
d
s
,
i H i Î¸g
i=1 i,g

T

Pn

Pn

(m+1)
bi,g
wi
g=1 z


Pn PG
(m+1)
b(m+1)
bi,g
wi 1 si,t 6=Î¸
g,t
g=1 z
i=1

Pn

i=1

PG

Pn
(m+1)
bi,g
wi
i=1 z


(m+1)
b(m+1)
z
b
w
1
s
i
i,t 6=Î¸g,t
i=1 i,g

Pn



(m+1)
bi,g
wi
i=1 z


(m+1)
b (m+1)
z
b
w
d
s
,
i H i Î¸g
i=1 i,g

T

Pn

Pn

Pn

!
âˆ’1

!
âˆ’1

Pn PGâˆ’1 (m+1)
T
bi,g
wi
i=1
g=1 z


Pn PGâˆ’1 (m+1)
b (m+1)
bi,g
wi dH si ,Î¸
g
g=1 z
i=1

Pn

28

!
âˆ’1

!
âˆ’1

!
âˆ’1
!
âˆ’1

!
âˆ’1

Appendix C MVAD Data: Gating Network Coecients
Multinomial logistic regression coecients and associated WLBS standard errors for the
gating network of a G = 10 UCN model with stepwise selection of covariates are provided
in Table 6. For completeness, coecients and WLBS standard errors for an otherwise
equivalent model with all covariates included (except those used to dene the sampling
weights) are given in Table C.1. Such a model achieves a wDBS value of 0.4717 (see Table
3), compared to 0.4745 for the optimal model with only a subset of covariates detailed in
Section 5.1. Notably, G = 10 and the UCN model type are both also optimal according to
the wDBS criterion for the model with all covariates included.
Table C.1: Multinomial logistic regression coecients and associated WLBS standard errors (in parentheses)
for the gating network of the 10-component UCN model with all covariates included.
Cluster
2
3
4
5
6
7
8
9

Noise

(Intercept)
(0.68)
(0.49)
(0.50)
(0.57)
(1.09)
(0.63)
(0.63)
(0.63)
(0.67)

âˆ’1.29
0.10
0.66
âˆ’1.16
âˆ’2.52
0.10
âˆ’2.86
âˆ’1.82
âˆ’1.76

Gender
(0.54)
(0.39)
(0.39)
(0.49)
(0.61)
(0.54)
(0.46)
(0.42)
(1.02)

âˆ’0.57
âˆ’0.55
âˆ’0.19
1.24
âˆ’0.57
âˆ’0.76
âˆ’0.60
âˆ’0.40
0.40

Catholic
(0.69)
(0.40)
(0.39)
(0.42)
(0.70)
(0.53)
(0.47)
(0.43)
(0.97)

1.10
0.21
âˆ’0.23
0.39
0.65
âˆ’0.05
âˆ’0.04
0.58
âˆ’0.93

Funemp
GCSE5eq
FMPR
(0.59) âˆ’0.06 (0.68)
0.36 (0.65)
(0.54)
1.25 (0.49)
0.50 (0.47)
(0.51) âˆ’0.29 (0.51) âˆ’0.86 (0.42)
(0.59)
0.24 (0.61) âˆ’0.26 (0.56)
(1.10)
1.97 (0.77)
0.83 (0.70)
(0.72)
1.32 (0.59) âˆ’0.50 (0.63)
(0.71)
3.24 (0.55)
0.31 (0.54)
(0.70)
3.77 (0.53)
0.82 (0.48)
(0.85)
1.34 (0.99)
0.03 (0.98)

1.50
0.50
âˆ’0.09
âˆ’0.17
0.41
0.26
âˆ’0.24
âˆ’0.35
0.48

29

Livboth
(0.53)
(0.38)
(0.39)
(0.44)
(0.74)
(0.53)
(0.48)
(0.46)
(0.86)

âˆ’0.04
âˆ’0.27
âˆ’0.16
âˆ’0.14
1.46
0.03
1.17
0.41
âˆ’0.65

