1

Reviewing and Improving the Gaussian Mechanism
for Differential Privacy

arXiv:1911.12060v2 [cs.CR] 7 Dec 2019

Jun Zhao, Teng Wang, Tao Bai, Kwok-Yan Lam, Zhiying Xu, Shuyu Shi, Xuebin Ren, Xinyu Yang, Yang Liu, Han Yu

Abstractâ€”Differential privacy provides a rigorous framework
to quantify data privacy, and has received considerable
interest recently. A randomized mechanism satisfying
(Ç«, Î´)-differential privacy (DP) roughly means that, except
with a small probability Î´, altering a record in a dataset cannot
change the probability that an output is seen by more than a
multiplicative factor eÇ« . A well-known solution to (Ç«, Î´)-DP is
the Gaussian mechanism initiated by Dwork et al. [1] in 2006
with an improvement byq
Dwork and Roth [2] inq2014, where a
Gaussian noise amount 2 ln 2Î´ Ã— âˆ†
of [1] or 2 ln 1.25
Ã— âˆ†
Ç«
Î´
Ç«
of [2] is added independently to each dimension of the query
result, for a query with â„“2 -sensitivity âˆ†. Although both classical
Gaussian mechanisms [1], [2] explicitly assume 0 < Ç« â‰¤ 1
only, our review finds that many studies in the literature have
used the classical Gaussian mechanisms under values of Ç«
and Î´ where we show the added noise amounts of [1], [2] do
not achieve (Ç«, Î´)-DP. We obtain such result by analyzing the
optimal (i.e., least) Gaussian noise amount ÏƒDP-OPT for (Ç«, Î´)-DP
and identifying the set of Ç« and Î´ where the noise amounts of
classical Gaussian mechanisms are even less than ÏƒDP-OPT . The
inapplicability of mechanisms of [1], [2] to large Ç« can also be
seen from
our result that ÏƒDP-OPT for large Ç« can be written as

Î˜ âˆš1Ç« , but not Î˜ 1Ç« .
Since ÏƒDP-OPT has no closed-form expression and needs to
be approximated in an iterative manner, we propose Gaussian
mechanisms by deriving closed-form upper bounds for ÏƒDP-OPT .
Our mechanisms achieve (Ç«, Î´)-DP for any Ç«, while the classical
Gaussian mechanisms [1], [2] do not achieve (Ç«, Î´)-DP for large
Ç« given Î´. Moreover, the utilities of our proposed Gaussian mechanisms improve those of the classical Gaussian mechanisms [1],
[2] and are close to that of the optimal yet more computationally
expensive Gaussian mechanism.
Since most mechanisms proposed in the literature for (Ç«, Î´)-DP
are obtained by ensuring a condition called (Ç«, Î´)-probabilistic
differential privacy (pDP), we also present an extensive discussion
of (Ç«, Î´)-pDP including deriving Gaussian noise amounts to
achieve it.
To summarize, our paper fixes the literatureâ€™s long-time misuse
of Gaussian mechanism [1], [2] for (Ç«, Î´)-differential privacy and
provides a comprehensive study for the Gaussian mechanisms.
Index Termsâ€”Differential privacy, Gaussian mechanism, probabilistic differential privacy, data analysis.

I. I NTRODUCTION
Differential privacy. Differential privacy [3] has received
considerable interest [1], [4]â€“[11] since it provides a rigorJun Zhao, Teng Wang, Tao Bai, Kwok-Yan Lam, and Han Yu are with
Nanyang Technological University, Singapore (Emails: junzhao@ntu.edu.sg,
N1805892E@e.ntu.edu.sg, bait0002@e.ntu.edu.sg, kwokyan.lam@ntu.edu.sg,
han.yu@ntu.edu.sg).
Zhiying Xu and Shuyu Shi are with Nanjing University, China (Emails:
zyxu@smail.nju.edu.cn, ssy@nju.edu.cn).
Xuebin Ren and Xinyu Yang are with Xiâ€™an Jiaotong University, China
(Emails: xuebinren@mail.xjtu.edu.cn, yxyphd@mail.xjtu.edu.cn).
Yang Liu is with WeBank Co Ltd, China (Email: yangliu@webank.com).

ous framework to quantify data privacy. Roughly speaking,
a randomized mechanism achieving (Ç«, Î´)-differential privacy
(DP) means that, except with a (typically small) probability
Î´, altering a record in a dataset cannot change the probability
that an output is seen by more than a multiplicative factor
eÇ« . Formally, for D and Dâ€² iterating through all pairs of
neighboring datasets which differ by one record, and for Y
iterating through all subsets of the output range of a randomized mechanism Y , the mechanism Y achieves (Ç«, Î´)-DP if
P [Y (D) âˆˆ Y] â‰¤ eÇ« P [Y (Dâ€² ) âˆˆ Y] + Î´, where P [Â·] denotes the
probability, and the probability space is over the coin flips of
the randomized mechanism Y . If Î´ = 0, the notion of (Ç«, Î´)DP becomes Ç«-DP.
Classical Gaussian mechanisms [1], [2] to achieve
(Ç«, Î´)-differential privacy. Among various mechanisms to
achieve DP, the Gaussian mechanism for real-valued queries
initiated by [1] has received much attention, where a certain
amount of zero-mean Gaussian noise is added independently
to each dimension of the query result. Below, for a Gaussian
mechanism with parameter Ïƒ, we mean that Ïƒ is the standard
deviation of the Gaussian noise.
As shown in [1], [2], the noise amount in the Gaussian
mechanism scales with the â„“2 -sensitivity âˆ† of a query, which
is defined as the maximal â„“2 distance between the true query
results for any two neighboring datasets D and Dâ€² that differ
in one record; i.e., âˆ† = maxneighboring D, Dâ€² kQ(D) âˆ’ Q(Dâ€² )k2 .
We will elaborate the notion of neighboring datasets in Remark 1 on Page 4. For a query with â„“2 -sensitivity1 âˆ†, the
noise amount in the first Gaussian mechanism proposed by
Dwork et al. [1] in 2006 to achieve (Ç«, Î´)-DP, denoted by
Dwork-2006, is given by
q
(1)
ÏƒDwork-2006 := 2 ln Î´2 Ã— âˆ†Ç« .
Improving Dwork-2006 via a smaller amount of noise
addition, the Gaussian mechanism by Dwork and Roth [2]
in 2014, denoted by Dwork-2014, adds Gaussian noise with
standard deviation
q
âˆ†
ÏƒDwork-2014 := 2 ln 1.25
(2)
Î´ Ã— Ç« .

Both Page 6 in [1] for Dwork-2006 and Theorem A.1
on Page 261 in [2] for Dwork-2014 consider Ç« â‰¤ 1. We
will formally prove that Dwork-2006 and Dwork-2014
fail to achieve (Ç«, Î´)-DP for large Ç« given Î´. Moreover, we
will show in Section III that many studies [7], [8], [12]â€“
1 For p = 1, 2, . . ., the â„“ -sensitivity of a query Q is defined as the maximal
p
â„“p distance between the outputs for two neighboring datasets D and D â€² that
differ in one record: âˆ†Q,p = maxneighboring D, D â€² kQ(D) âˆ’ Q(D â€² )kp .

2

[21] applying Dwork-2006 and Dwork-2014 neglect the
condition Ç« â‰¤ 1, and use Dwork-2006 or Dwork-2014
under values of Ç« and Î´ where the added Gaussian noise
amount actually does not achieve (Ç«, Î´)-DP. This renders their
obtained results inaccurate.
One may wonder why we consider both mechanisms since
clearly it holds that
ÏƒDwork-2014 in Eq. (2) < ÏƒDwork-2006 in Eq. (1).

(3)

The reason is as follows. Although Dwork-2014 achieves
higher utility than that of Dwork-2006 for the set of Ç« and Î´
under which they both achieve (Ç«, Î´)-DP, Dwork-2006 has
wider applicability than Dwork-2014; i.e., the set of Ç« and
Î´ where Dwork-2014 achieves (Ç«, Î´)-DP is a strict subset
of the set of Ç« and Î´ where Dwork-2006 achieves (Ç«, Î´)-DP.
Given the above, we discuss both mechanisms.
Our contributions. We make the following contributions
in this paper.
1) Failures of classical Gaussian mechanisms for large Ç«.
We prove (in Theorem 1 on Page 4) that the classical Gaussian mechanisms Dwork-2006 of [1] and Dwork-2014
of [2] fail to achieve (Ç«, Î´)-DP for large Ç« given Î´. In
fact, we prove that for any Gaussian mechanism with noise
amount F (Î´) Ã— âˆ†Ç« for some function F (Î´), there exists
a positive function G(Î´) for any 0 < Î´ < 1 such that the
above Gaussian mechanism does not achieve (Ç«, Î´)-DP for
any Ç« > G(Î´). The above result applies to Dwork-2006
and
F (Î´) as
q
q Dwork-2014, where the former specifies
2
1.25
2 ln Î´ and the latter specifies F (Î´) as 2 ln Î´ .
2) The literatureâ€™s misuse of classical Gaussian mechanisms for large Ç«. After a literature review (in Table I
on Page 5), we find that many papers [7], [8], [12]â€“[21]
use the classical Gaussian mechanism Dwork-2006 or
Dwork-2014 under values of Ç« and Î´ where the added
noise amount actually does not achieve (Ç«, Î´)-DP. This
makes their obtained results inaccurate.

no closed-form expression and needs to be approximated
in an iterative manner. Hence, we propose new Gaussian
mechanisms (Mechanism 1 and Mechanism 2 in Theorems 4 and 5 on Page 6) by deriving closed-form upper
bounds for ÏƒDP-OPT . We summarize the advantages of our
Gaussian mechanisms as follows.
i) As discussed, our Gaussian mechanisms have
closed-form expressions and are computationally
efficient than [22]â€™s optimal Gaussian noise amount,
which has no closed-form expression and needs to
be approximated in an iterative manner. In addition,
both numerical and experimental studies show that the
utilities of our Gaussian mechanisms are close to that
of the optimal yet more computationally expensive
Gaussian mechanism by [22].
ii) Our Gaussian mechanisms all achieve (Ç«, Î´)-DP for
any Ç«, while the classical Gaussian mechanisms
Dwork-2006 of [1] and Dwork-2014 of [2] were
proposed for only 0 < Ç« â‰¤ 1 and we show that they do
not achieve (Ç«, Î´)-DP for large Ç« given Î´, as noted in
Contribution 1) above.
iii) We prove (in Inequality (10) on Page 7) that the noise
amounts of our Gaussian mechanisms are less than that
of Dwork-2014 (and hence also less than that of
Dwork-2006), for 0 < Ç« â‰¤ 1 where the proofs of
Dwork-2006 of [1] and Dwork-2014 of [2] require.
iv) For a subset of Ç« > 1 where Dwork-2014 happens
to work (Dwork-2014â€™s original proof requires Ç« â‰¤
1), experiments (in Figure 2 on Page 7) show that our
Mechanism 1 often adds noise amount less than that
of Dwork-2014.
5) (Ç«, Î´)-Differential privacy versus (Ç«, Î´)-probabilistic differential privacy. Since most mechanisms proposed in the
literature for (Ç«, Î´)-differential privacy (DP) are obtained
by ensuring a notion called (Ç«, Î´)-probabilistic differential
privacy (pDP), which requires the privacy loss random
variable to fall in the interval [âˆ’Ç«, Ç«] with probability at
least 1 âˆ’ Î´, we also investigate (Ç«, Î´)-pDP, and show its
difference/relationship with (Ç«, Î´)-DP (in Section VI on
Page 7). In particular, the minimal Gaussian noise amount
to achieve (Ç«, Î´)-pDP given Î´ scales with 1Ç« as Ç« â†’ 0 (from
Theorem 7 on Page 8), while the minimal Gaussian noise
amount to achieve (Ç«, Î´)-DP given Î´ converges to its upper
âˆ†
as Ç« â†’ 0 (from Theorem 3 on Page 5).
bound 2âˆš2Â·inverf(Î´)
Moreover, while clearly (Ç«, Î´)-pDP implies (Ç«, Î´)-DP, we
âˆ’Ç«âˆ—
)
also prove that (Ç«, Î´)-DP implies (Ç«âˆ— , Î´(1+e
1âˆ’eÇ«âˆ’Ç«âˆ— )-pDP for
any Ç«âˆ— > Ç«.

3) An Ç«-independent upper bound and asympotics of the
optimal Gaussian noise amount for (Ç«, Î´)-DP. We prove
(in Theorem 3 on Page 5) that the optimal (i.e., least)
Gaussian noise amount ÏƒDP-OPT for (Ç«, Î´)-DP is always
âˆ†
less than 2âˆš2Â·inverf(Î´)
, which does not depend on Ç«, where
inverf() denotes the inverse of the error function. This is
in contrast to the classical Gaussian mechanismsâ€™ noise
amounts ÏƒDwork-2006 in Eq. (1) and ÏƒDwork-2014 in Eq. (2)
which scale with 1Ç« and tend to âˆ as Ç« â†’ 0. In fact, we
prove that ÏƒDP-OPT given a fixed Î´ converges
 to its upper
âˆ†
2
âˆš
bound 2 2Â·inverf(Î´) as Ç« â†’ 0, and is Î˜ âˆš1Ç« as Ç« â†’ âˆ.
q
 6) Gaussian mechanisms for (Ç«, Î´)-probabilistic differenAlso, we show that ÏƒDP-OPT given a fixed Ç« is Î˜
ln 1Î´
tial privacy. For (Ç«, Î´)-pDP, we also derive the optimal
Gaussian
mechanism (in Theorem 6 on Page 8) which
as Î´ â†’ 0.
adds
the
least amount of Gaussian noise (denoted by
4) Our Gaussian mechanisms for (Ç«, Î´)-differential priÏƒ
).
However, since ÏƒpDP-OPT has no closed-form
pDP-OPT
vacy with closed-form expressions. Although the optimal
expression
and needs to be approximated in an iterative
Gaussian mechanism for (Ç«, Î´)-DP has been proposed in
manner,
we
propose Gaussian mechanisms for (Ç«, Î´)-pDP
a very recent work [22], its noise amount ÏƒDP-OPT has
(Mechanism 3 and Mechanism 4 in Theorems 8 and 9
2 A positive sequence x can be written as Î˜ (y) for a positive sequence y
on Page 9) by deriving more computationally efficient
if lim inf

x
y

and lim sup

x
y

are greater than 0 and smaller than âˆ.

3

upper bounds (in closed-form expressions) for ÏƒpDP-OPT .
Organization. The rest of the paper is organized as follows.
â€¢ Section II surveys related work.
â€¢ In Section III, we elaborate (Ç«, Î´)-differential privacy (DP)
and review the literatureâ€™s misuse of classical Gaussian
mechanisms.
â€¢ In Section IV, we discuss the optimal Gaussian mechanism
for (Ç«, Î´)-DP, where the noise amount has no closed-form
expression.
â€¢ Section V presents our Gaussian mechanisms for (Ç«, Î´)-DP
with closed-form expressions of noise amounts.
â€¢ Since most mechanisms proposed in the literature for
(Ç«, Î´)-DP are obtained by ensuring a notion called (Ç«, Î´)probabilistic differential privacy (pDP), Section VI is devoted to (Ç«, Î´)-pDP, where we discuss the difference/relationship between (Ç«, Î´)-pDP and (Ç«, Î´)-DP, and derive
the optimal Gaussian mechanism for (Ç«, Î´)-pDP, where the
noise amount has no closed-form expression. Then we propose Gaussian mechanisms for (Ç«, Î´)-pDP with closed-form
expressions of noise amounts.
â€¢ In view that concentrated differential privacy [9] and related
notions [10], [23], [24] have recently been proposed as
variants of differential privacy, we show in Section VII
that achieving (Ç«, Î´)-DP by ensuring one of these privacy
definitions gives Gaussian mechanisms worse than ours.
â€¢ Section VIII presents experimental results.
â€¢ We conclude the paper in Section IX.

Due to the space limitation, additional details including the
proofs are provided in the appendices of this supplementary
file.
Notation. Throughout the paper, P [Â·] denotes the probability, and F [Â·] stands for the probability density function. The
error function is denotedR by erf(), and its complement is
2
x
erfc(); i.e., erf(x) := âˆš2Ï€ 0 eâˆ’t dt and erfc(x) := 1 âˆ’ erf(x).
In addition, inverf() is the inverse of the error function, and
inverfc() is the inverse of the complementary error function.
II. R ELATED W ORK
Differential privacy. The notion of differential privacy
(DP) [3] has received much attention [25]â€“[30] since it provides a rigorous framework to quantify data privacy. The
Gaussian mechanism to achieve DP has been investigated
in [1], [2], while the Laplace mechanism is introduced in [3]
and the exponential mechanism is proposed in [31]. The Gaussian (resp., Laplace) mechanism adds independent Gaussian
(resp., Laplace) noise to each dimension of the query result,
while the exponential mechanism can address non-numeric
queries. Recently, the following mechanisms to achieve DP
have been proposed: the truncated Laplacian mechanism [32],
the staircase mechanism [33], [34], and the Podium mechanism [35]. Compared with these mechanisms, the Gaussian
mechanism is more friendly for composition analysis since
the privacy loss random variable (defined in Section VI on
Page 7) after composing independent Gaussian mechanisms
follows a Gaussian distribution, whereas the privacy loss
after composing independent truncated Laplacian mechanisms

(staircase mechanisms, or podium mechanisms) has a complicated probability distribution.
Use of Gaussian mechanism. The Gaussian mechanism has been used by Dwork et al. [27] to design algorithms for privacy-preserving principal component analysis.
Nikolov et al. [28] leverage the Gaussian mechanism for
differentially private release of a k-way marginal query. The
Gaussian mechanism is also used by Hsu et al. [29] for
enabling multiple parties to distributedly solve convex optimization problems in a privacy-preserving and distributed
manner. Gilbert and McMillan [36] apply the Gaussian
mechanism to differentially private recovery of heat source
location. Bun et al. [37] employ the Gaussian mechanism to
derive a lower bound on the length of a combinatorial object
called a fingerprinting code, proposed by Boneh and Shaw [38]
for watermarking copyrighted content. Abadi et al. [26] apply
(Ç«, Î´)-DP to stochastic gradient descent of deep learning, where
the Gaussian mechanism is used for adding noise to the
gradient. Recently, Liu [39] have presented a generalized
Gaussian mechanism based on the â„“p -sensitivity1 .
Probabilistic differential privacy. Most mechanisms proposed in the literature for (Ç«, Î´)-DP are obtained by ensuring a notion called (Ç«, Î´)-probabilistic differential privacy
(pDP) [40], which requires the privacy loss random variable
to fall in the interval [âˆ’Ç«, Ç«] with probability at least 1 âˆ’ Î´.
For the formal definition and results discussed below, see
Section VI for details, where we present i) relations between
(Ç«, Î´)-DP and (Ç«, Î´)-pDP, ii) an analytical but not closed-form
expression for the optimal Gaussian mechanism (denoted by
Mechanism pDP-OPT) to achieve (Ç«, Î´)-pDP, and iii) Gaussian mechanisms for (Ç«, Î´)-pDP, denoted by Mechanism 3
and Mechanism 4, respectively.
Other variants of differential privacy. Different variants of differential privacy have been proposed in the
literature recently, including mean-concentrated differential
privacy (mCDP) [9], zero-concentrated differential privacy
(zCDP) [10], ReÌnyi differential privacy [23] (RDP), and
truncated concentrated differential privacy (tCDP) [24]. These
notions are more complex than (Ç«, Î´)-DP, so we believe that
(Ç«, Î´)-DP will still be used in many applications. Therefore, any
issue concerning the classical Gaussian mechanism for (Ç«, Î´)DP is worthy of serious discussions in the research community.
Moreover, we show in Section VII on Page 10 that achieving
(Ç«, Î´)-DP by ensuring one of these privacy definitions (i.e.,
mCDP, zCDP, RDP, and tCDP) gives Gaussian mechanisms
worse than ours.
Composition. One of the appealing properties of differential
privacy is the composition property [2], meaning that the
composition of differentially private algorithms satisfies a
certain level of differential privacy. In Appendix P of this
supplementary file, we provide analyses for the composition
of Gaussian mechanisms. Our result is that for m queries
Q1 , Q2 , . . . , Qm with â„“2 -sensitivity âˆ†1 , âˆ†2 , . . . , âˆ†m , if the
query result of Qi is added with independent Gaussian noise
of amount (i.e., standard deviation) Ïƒi , then the differential
privacy (DP) level for the composition of the m noisy answers
is the same as that of a Gaussian mechanism with noise

4

âˆ’1/2
P
m âˆ†i 2
for a query with â„“2 -sensitivity points (Î´, Gâˆ— (Î´)) such that Dwork-2014 does not achieve
amount Ïƒâˆ— :=
i=1 Ïƒi 2
(Ç«, Î´)-differential privacy for Ç« > Gâˆ— (Î´); e.g., Gâˆ— (10âˆ’3 ) =
DP
1. Let ÏƒÇ«,Î´ be a Gaussian noise amount which achieves
7.47, Gâˆ— (10âˆ’4 ) = 8.00, Gâˆ— (10âˆ’5 ) = 8.43, and Gâˆ— (10âˆ’6 ) =
(Ç«, Î´)-DP for a query with â„“2 -sensitivity 1, where the expres8.79. For the Gaussian mechanism Dwork-2006 of [1], the
DP
sion of ÏƒÇ«,Î´
can follow from classical Dwork-2006 and
blue line in Figure 1(ii) on Page 5 illustrates all points
Dwork-2014 of [1], [2] (when Ç« â‰¤ 1), the optimal one (i.e.,
(Î´, G# (Î´)) such that Dwork-2006 does not achieve (Ç«, Î´)DP-OPT), or our proposed mechanisms (i.e., Mechanism 1
differential privacy for Ç« > G# (Î´); e.g., G# (10âˆ’3 ) = 8.51,
and Mechanism 2). Then the above composition satisfies
G# (10âˆ’4 ) = 8.99, G# (10âˆ’5 ) = 9.39, and G# (10âˆ’6 ) =
DP
(Ç«, Î´)-DP for Ç« and Î´ satisfying Ïƒâˆ— â‰¥ ÏƒÇ«,Î´
with Ïƒâˆ— defined
9.73.
above.
The literatureâ€™s misuse of the classical Gaussian mechIII. (Ç«, Î´)-D IFFERENTIAL P RIVACY AND U SAGE OF THE
anisms. After a literature review, we find that many paG AUSSIAN M ECHANISM
pers [7], [8], [12]â€“[21] use the classical Gaussian mechanism
The formal definition of (Ç«, Î´)-differential privacy [1] is as Dwork-2006 (resp., Dwork-2014) under values of Ç« and
Î´ where Dwork-2006 (resp., Dwork-2014) actually does
follows.
not achieve (Ç«, Î´)-differential privacy. Table I on Page 5 sumDefinition 1 ((Ç«, Î´)-Differential privacy [1]). A randomized marizes selected papers which misuse the classical Gaussian
algorithm Y satisfies (Ç«, Î´)-differential privacy, if for any two mechanism Dwork-2006 or Dwork-2014.
neighboring datasets D and Dâ€² that differ only in one record,
Usage of Ç« > 1. Although Ç« â‰¤ 1 is preferred in practical
and for any possible subset of outputs Y of Y , we have
applications, there are still cases where Ç« > 1 is used, so
P [Y (D) âˆˆ Y] â‰¤ eÇ« Â· P [Y (Dâ€² ) âˆˆ Y] + Î´.
(4) it is necessary to have Gaussian mechanisms which apply to
not only Ç« â‰¤ 1 but also Ç« > 1. We discuss usage of Ç« > 1 as
where P [Â·] denotes the probability of an event. If Î´ = 0, Y is follows. First, the references [7], [8], [12]â€“[21] in Table I have
said to satisfy Ç«-differential privacy.
used Ç« > 1. Second, the Differential Privacy Synthetic Data
Challenge
organized by the National Institute of Standards
Remark 1 (Notion of neighboring datasets). Two datasets
â€²
and
Technology
(NIST) [41] included experiments of Ç« as
D and D are called neighboring if they differ only in
10.
Third,
for
a
variant of differential privacy called local
one record. There are still variants about this. In the first
â€²
â€²
differential
privacy
[42] which is implemented in several
case, the size of D and D differ by one so that D is
industrial
applications,
Apple [43], [44] and Google [45] have
obtained by adding one record to D or deleting one record
â€²
adopted
Ç«
>
1.
from D. In the second case, D and D have the same size
(say n), and have different records at only one of the n
positions. Finally, the notion of neighboring datasets can also
IV. T HE O PTIMAL G AUSSIAN M ECHANISM FOR
be defined to include both cases above. Our results in this
(Ç«, Î´)-D IFFERENTIAL P RIVACY
paper do not rely on how neighboring datasets are specifically
A recent work [22] of Balle and Wang in ICML 2018 andefined. In a differential privacy application, after the notion alyzed the optimal Gaussian mechanism for (Ç«, Î´)-differential
of neighboring datasets is defined, what we need is just the â„“2 - privacy, where â€œoptimalâ€ means that the noise amount is the
sensitivity âˆ† of a query Q with respect to neighboring datasets: least among Gaussian mechanisms. This optimal Gaussian
âˆ† = maxneighboring datasets D, Dâ€² kQ(D) âˆ’ Q(Dâ€² )k2 .
mechanism is also analyzed by Sommer et al. [46], where
Theorem 1 below shows failures of the classical Gaussian
mechanisms [1], [2] for large Ç«.

the shape of the privacy loss is also discussed. Based on [22],
we present Theorem 2 below.

Theorem 1 (Failures of the classical Gaussian mechanisms
of Dwork and Roth [2] and of Dwork et al. [1] to achieve
(Ç«, Î´)-differential privacy for large Ç«). For a positive function
F (Î´), consider a Gaussian mechanism which adds Gaussian
noise with standard deviation F (Î´) Ã— âˆ†
Ç« to each dimension
of a query with â„“2 -sensitivity âˆ†. With an arbitrarily fixed
0 < Î´ < 1, as Ç« increases, the above Gaussian mechanism
does not achieve (Ç«, Î´)-differential privacy for large enough Ç«
(specifically, for any Ç« > G(Î´) with G(Î´) being some positive
function). This result applies to the classical Gaussian mechanism Dwork-2014 of Dwork and Roth [2] and mechanism
Dwork-2006
of Dwork et al. [1], where the former q
specifies
q
1.25
F (Î´) as 2 ln Î´ and the latter specifies F (Î´) as 2 ln 2Î´ .

Theorem 2 (Optimal Gaussian mechanism for
(Ç«, Î´)-differential privacy). The optimal Gaussian mechanism
for (Ç«, Î´)-differential privacy, denoted by Mechanism DP-OPT,
adds Gaussian noise with standard deviation ÏƒDP-OPT specified
below to each dimension of a query with â„“2 -sensitivity âˆ†.
(i) We derive ÏƒDP-OPT as follows based on Theorem 8 of Balle
and Wang [22]:

p
a2 + Ç« = 2Î´,
With a satisfying erfc (a) âˆ’ eÇ« erfc
we get ÏƒDP-OPT :=

(a+

âˆš
a2 +Ç« )Â·âˆ†
âˆš
,
Ç« 2

(5)

where erfc() is the complementary error function.
For Ç« â‰¥ 0.01 and 0 < Î´ â‰¤ 0.05, we prove the following
results:
We formally prove Theorem 1 in Appendix B.
(ii) ÏƒDP-OPT > âˆšâˆ†2Ç« .
Remark 2. For the Gaussian mechanism Dwork-2014
q
1
âˆšâˆ†
Â·âˆ†
of [2], the blue line in Figure 1(i) on Page 5 illustrates all (iii) ÏƒDP-OPT < 2 ln 2Î´
Ç« + 2Ç« .

5

1

1

0.8

0.8

0.6

0.6
10-3

0.4
0.2

10

-4

10

-5

10-3

0.4

10-4
10-5

0.2

10-6
7.5

8

10-6

8.5

8.5

0

9

9.5

0
0

5

10

15

20

(i) Mechanism Dwork-2014 of Dwork and Roth [2]

0

5

10

15

20

(ii) Mechanism Dwork-2006 of Dwork et al. [1]

Fig. 1: The shaded area in each subfigure represents the set of (Ç«, Î´) where Mechanism Dwork-2014 (resp., Dwork-2006)
does not achieve (Ç«, Î´)-differential privacy.
TABLE I:
Selected papers
Imtiaz and Sarwate [12]
Liu et al. [13]
Wang et al. [14]
Ermis and Cemgil [15]
Liu et al. [16]
Imtiaz and Sarwate [17]
JaÌˆlkoÌˆ et al. [7]
HeikkilaÌˆ et al. [8]
Imtiaz and Sarwate [18]
Pyrgelis et al. [19]
Wang et al. [21]
Jain and Thakurta [20]

Misuse of the Classical Gaussian Mechanisms in the Literature from 2014 to 2018.
Mechanism
Ç«
Î´
The resulting noise amounts The least noise amounts
Dwork-2014
10
0.01
0.3108
0.3501
Dwork-2014
6, 10
0.1
0.3746, 0.2248
0.3813, 0.2818
Dwork-2014 8.87, 9.59
10âˆ’5
0.5462, 0.5052
0.5172, 0.5513
âˆ’2
Dwork-2014
10
10 , 10âˆ’5
0.3108, 0.4845
0.3501, 0.4999
Dwork-2014
8
10âˆ’1
0.2809
0.3215
Dwork-2014
10
10âˆ’2
0.3108
0.3501
Dwork-2014
10
10âˆ’3
0.3776
0.4061
Dwork-2014 10, 31.62
10âˆ’4
0.4344, 0.1374
0.1976, 0.4553
Dwork-2006
10
10âˆ’2
0.3325
0.3501
Dwork-2006
10
10âˆ’1
0.2448
0.2818
Dwork-2006
10
10âˆ’1
0.2448
0.2818
âˆ’3
Dwork-2006
10
10
0.3898
0.4061

Remark 3. Results (ii) and (iii)
 of Theorem 2 mean that putationally efficient upper bounds for ÏƒDP-OPT in Section V.
In Appendix O of this supplementary file, we present
ÏƒDP-OPT is in the form of Î˜ âˆš1Ç« for large Ç« (note 1Ç« is
Algorithm
1 to compute ÏƒDP-OPT of Theorem 2.
1
smaller than âˆšÇ« for large Ç«). This further implies the result of
We now analyze the asympotics for the optimal Gaussian
Theorem 1 for 0 < Î´ â‰¤ 0.05 (our direct proof for Theorem 1
noise amount ÏƒDP-OPT of (Ç«, Î´)-differential privacy. As a side
in Appendix B works for any 0 < Î´ < 1).
âˆ†
result, we prove that ÏƒDP-OPT is always less than 2âˆš2Â·inverf(Î´)
âˆš

Ç«
2
Remark 4. With r(u) := erfc (u)âˆ’e erfc u + Ç« , the term and hence bounded even for Ç« â†’ 0. This is in contrast to the
a in Eq. (5) satisfies r(a) = 2Î´. Then r(u) strictly decreases classical Gaussian mechanismsâ€™ noise amounts ÏƒDwork-2006
as u increases given the derivative râ€² (u) = âˆš2Ï€ exp(âˆ’u2 ) Ã— and ÏƒDwork-2014 in Eq. (1) and (2) which scale with 1 and
Ç«
âˆš
âˆš
2
uâˆ’
âˆš u +Ç« < 0. Based on this and r(0) = 1 âˆ’ eÇ« erfc ( Ç«), hence tend to âˆ as Ç« â†’ 0.
2
u +Ç«
âˆš
for a in Eq. (5), we obtain a > 0 if 2Î´ < 1 âˆ’ eÇ« erfc ( Ç«), Theorem 3 (An upper bound and asympotics of the optimal
and a â‰¤ 0 otherwise. More discussions about Remark 4 are Gaussian noise amount for (Ç«, Î´)-differential privacy).
presented in Appendix D of this supplementary file.
â‘  For any Ç« > 0 and 0 < Î´ < 1, ÏƒDP-OPT is less than
âˆš âˆ†
, which is the optimal Gaussian noise amount
Remark 5. Mechanism DP-OPT is just the optimal Gaussian
2 2Â·inverf(Î´)
to
achieve
(0,
Î´)-differential privacy.
mechanism for (Ç«, Î´)-differential privacy in the sense that it
â‘¡
Given
a
fixed
0 < Î´ < 1, ÏƒDP-OPT converges to its upper
gives the minimal required amount of noise when the noise
âˆ†
âˆš
as Ç« â†’ 0.
bound
follows a Gaussian distribution. However, it may not be the
2 2Â·inverf(Î´)
 
optimal mechanism for (Ç«, Î´)-differential privacy, since there â‘¢ Given a fixed 0 < Î´ < 1, ÏƒDP-OPT is Î˜ âˆš1 as Ç« â†’ âˆ;
Ç«

.
may exist other perturbation methods [32], [35], [47] which
âˆ†
âˆš
= 1.
specifically, limÇ«â†’âˆ ÏƒDP-OPT
may outperform a Gaussian mechanism under certain utility
2Ç« q

measure [33].
â‘£ Given a fixed Ç« > 0, ÏƒDP-OPT is Î˜
ln 1Î´ as Î´ â†’ 0;
. q

We prove Theorem 2 in Appendix C of this supplementary
âˆ†
1
specifically, limÎ´â†’0 ÏƒDP-OPT
2
ln
= 1.
Ç«
Î´
file.
Intuition of Result â‘  of Theorem 3 based on Theorem 2.
Since ÏƒDP-OPT of Theorem 2 has no closed-form expression
and needs to be approximated in an iterative manner, we first With Î´ fixed, when Ç« tends to 0, the quantity a in Eq. (5)
provide its asympotics in Theorem 3 and present more com- of Theorem 2 is negative and is close to âˆ’ inverfc(1 âˆ’ Î´);

6

TABLE II: Different mechanisms to achieve (Ç«, Î´)-differential privacy (DP).
Comparison
Common properties
â€¢ the optimal Gaussian mechanism to achieve (Ç«, Î´)-DP,
â€¢ no closed-form expression,
DP-OPT
â€¢ computed using the bisection method
Noise amounts ÏƒDP-OPT , ÏƒMechanism-1 ,
of Theorem 2
with the number of iterations being
and ÏƒMechanism-2 are all smaller than
logarithmic in the given error (i.e., tolerance).
ÏƒDwork-2014 and ÏƒDwork-2006 ,
â€¢ closed-form expression involving
for 0 < Ç« â‰¤ 1 which the proofs of
the complementary error function
Dwork-2014 and Dwork-2006 require
Our Mechanism 1 erfc() and its inverse inverfc(),
(The proof is in Appendix A).
of Theorem 4
â€¢ computational complexity: dependent on
erfc() & inverfc() implementations and often very efficient,
â€¢ ÏƒMechanism-1 is slightly greater than ÏƒDP-OPT .
â€¢ closed-form expression involving
Our Mechanism 2 only elementary functions,
of Theorem 5
â€¢ computed in constant amount of time,
â€¢ ÏƒMechanism-2 is slightly greater than ÏƒMechanism-1 .
DP Mechanisms

We prove Lemma 1 in Appendix G of this supplementary
i.e., inverf(Î´), whereâˆšwe use erfc (âˆ’a) = 2 âˆ’ erfc (a). Then
the numerator (a + a2 + Ç«)âˆ† of Eq. (5) can be written as file. Theorem 2 and Lemma 1 imply
Ç«âˆ†
Ç«âˆ†
âˆš
and approaches (âˆ’a)Â·2
to scale with Ç« instead of
âˆ’a+ a2 +Ç« âˆš
ÏƒDP-OPT in Eq. (5) < ÏƒMechanism-1 in Eq. (7b) of Theorem 4,
scaling with Ç« as Ç« â†’ 0. As the numerator and denominator
(6)
of Eq. (5) are both Î˜(Ç«) as Ç« â†’ 0, ÏƒDP-OPT with fixed Î´ does
where Theorem 4 below presents Mechanism 1 to achieve
not grow unboundedly as Ç« â†’ 0.
We prove Theorem 3 in Appendix E of this supplementary (Ç«, Î´)-differential privacy.
file. Theorem 3 provides the first asymptotic results in the Theorem 4 (Gaussian Mechanism 1 for (Ç«, Î´)-differential
literature on the optimal Gaussian noise amount for (Ç«, Î´)- privacy). (Ç«, Î´)-Differential privacy can be achieved by
differential privacy. The proofs delicately bound ÏƒDP-OPT to Mechanism 1, which adds Gaussian noise with standard
avoid over-approximation.
deviation ÏƒMechanism-1 to each dimension of a query with â„“2 For clarification, we note that Results â‘¡ and â‘£ of The- sensitivity âˆ†, for Ïƒ
Mechanism-1 given by
orem 3 do not contradict each other since Result â‘¡ fixes
ï£±
ï£¶
ï£«
ï£±
ï£´
0 < Î´ < 1 and considers Ç« â†’ 0 so that Ç«/Î´ â†’ 0, while
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£·
ï£¬
ï£´
Result â‘£ fixes Ç« > 0 and considers Î´ â†’ 0 so that Î´/Ç« â†’ 0. ï£´
ï£´
ï£´
ï£·
ï£¬
ï£´
2Î´
ï£´
ï£´
ï£¶ï£·
ï£«s
inverfc
ï£´
ï£¬

ï£´
2
ï£²
More specifically, to bound ÏƒDP-OPT in Result â‘£, we consider
ï£´
ï£­
Ç« erfc (âˆšÇ«)
ï£´
ï£¸ï£¸
ï£­
+Ç«
erfc
inverfc
2Î´+e
ï£´
ï£²b :=
(7a)
Ç« > f (Î´) for some function f , which clearly holds given a
âˆš
1âˆ’eÇ«Â·
ï£´
2Î´+eÇ« erfc( Ç«)
ï£´
ï£´
âˆš
fixed
Ç«
>
0
and
Î´
â†’
0.
With
Ç«
>
f
(Î´),
the
expression
ï£´
ï£´
q
q
ï£´
ï£´
if 2 âˆ’ eÇ« erfc ( Ç«) > 2Î´,
ï£´
ï£´
ï£´
âˆ†
âˆ†
1
1
ï£´
ï£´
in
Result
â‘£
is
less
than
,
which
is
2
ln
2
ln
ï£´
ï£³
Ç«
Î´
f (Î´)
Î´
ï£´
0 otherwise;
ï£´
ï£´
âˆ†
ï£´
for suitable f (Î´), so Result â‘¡ does not
less than 2âˆš2Â·inverf(Î´)
âˆš
ï£´
2 +Ç« Â·âˆ†
ï£´
)
(b+ bâˆš
ï£³
.
(7b)
Ïƒ
:=
contradict Result â‘£.
Mechanism-1
Ç« 2
V. O UR P ROPOSED G AUSSIAN M ECHANISMS
(Ç«, Î´)-D IFFERENTIAL P RIVACY

FOR

Table II summarizes different mechanisms to achieve (Ç«, Î´)differential privacy (DP), including DP-OPT in Theorem 2
of the previous section as well as our Mechanism 1 and
Mechanism 2 to be presented below.
We now detail our Gaussian mechanisms for (Ç«, Î´)differential privacy, where the noise amounts have
closed-form3 expressions and are more computationally
efficient than the above Theorem 2â€™s DP-OPT which has no
closed-form expression. Our idea is to present computationally
efficient upper bounds of ÏƒDP-OPT . To this end, we first present
Lemma 1, which upper bounds a in Eq. (5) of Theorem 2.
Lemma 1. a in Eq. (5) is less than b in Eq. (7a).
3 Closed-form

expressions in this paper can include functions erf(), erfc(),
inverf(), and inverfc().

The expression of ÏƒMechanism-1 involves the complementary
error function erfc() and its inverse inverfc(). Hence, we further present Lemma 2 below, which will enable us to propose
Mechanism 2. Its noise amount is given by the closed-form
expression of ÏƒMechanism-2 and has only elementary functions.
Lemma 2 upper bounds b in Eq. (7a) of Theorem 4.
Lemma 2. b in Eq. (7a) is less than c in Eq. (9).

We prove Lemma 2 in Appendix H of this supplementary
file. Theorem 4 and Lemma 2 imply
ÏƒMechanism-1 in Eq. (7b) < ÏƒMechanism-2 in Eq. (9),

(8)

where the presented Mechanism 2 in Theorem 5 below is
further simpler than Mechanism 1 as noted above.
Theorem 5 (Gaussian Mechanism 2 for (Ç«, Î´)-differential
privacy). For 0 < Î´ < 0.5, (Ç«, Î´)-differential privacy can be
achieved by Mechanism 2, which adds Gaussian noise with

7
6

60

= 0.1

50

1.2

=1

5

=5

1

40
4
30

0.8
3

20
10
10 -7

SDP-OPT
DP-OPT
Dwork-2014
Dwork-2006
Mechanism 1
Mechanism 2
Mechanism 3
Mechanism 4

10 -6

10 -5

10 -4

10 -3

2
10 -7

10 -6

(i)

10 -5

10 -4

10 -3

0.6
10 -7

10 -6

(ii)

10 -5

10 -4

(iii)

0.45

0.35

0.6
0.4

= 15

= 10
0.5

10 -3

0.35

= 20

0.3
0.25

0.3

0.2

0.4
10 -7

10 -6

10 -5

10 -4

10 -3

(iv)

0.25
10 -7

10 -6

10 -5

(v)

10 -4

10 -3

0.15
10 -7

10 -6

10 -5

10 -4

10 -3

(vi)

Fig. 2: The noise amounts of different mechanisms with respect to Î´, for Ç« = 0.1, 1, 5, 10, 15 and 20. The meanings of the
legends are as follows.
â€¢ pDP-OPT (resp., DP-OPT) is the optimal Gaussian mechanism to achieve (Ç«, Î´)-pDP (resp., (Ç«, Î´)-DP), where pDP is short
for probabilistic differential privacy, a notion stronger than differential privacy (DP) and to be elaborated in Section VI.
â€¢ Dwork-2006 (resp., Dwork-2014) is the Gaussian mechanism proposed by Dwork et al. [1] in 2006 (resp., Dwork and
Roth [2] in 2014) to achieve (Ç«, Î´)-DP.
â€¢ Mechanism 1 and Mechanism 2, which are our proposals to achieve (Ç«, Î´)-DP and discussed in Section V, are simpler
and more computationally efficient than DP-OPT.
â€¢ Mechanism 3 and Mechanism 4, which are our proposals to achieve (Ç«, Î´)-pDP and will be discussed in Section VI-D,
are simpler and more computationally efficient than pDP-OPT.

standard deviation ÏƒMechanism-2 to each dimension of a query
with â„“2 -sensitivity âˆ†, for ÏƒMechanism-2 given by
âˆš
q
(c+ câˆš2 +Ç« )Â·âˆ†
2
; ÏƒMechanism-2 :=
. (9)
c := ln âˆš16Î´+1âˆ’1
Ç« 2

Superiority of our mechanisms. The following discussions
show the superiority of our proposed mechanisms.

i) From
Inequalities
(6)
and
(8),
we
have
ÏƒDP-OPT in Eq. (5)
<
ÏƒMechanism-1 in Eq. (7b)
<
ÏƒMechanism-2 in Eq. (9). Among these noise amounts,
ÏƒMechanism-1 and ÏƒMechanism-2 are straightforward to
compute, whereas ÏƒDP-OPT require higher computational
complexity (a simple approach is the bisection method
in [48, Page 3]. Also, our plots in Figure 2 show
that the noise amounts added by the optimal Gaussian
mechanism DP-OPT and our more computationally
efficient Mechanism 1 are close.
ii) For 0 < Ç« â‰¤ 1 where the proofs of Dwork-2006 of [1]
and Dwork-2014 of [2] require, we prove in Appendix A
that

differential privacy, ÏƒMechanism-1 < ÏƒDwork-2014 still holds
as given by Figure 2. Moreover, our Mechanism 1 and
Mechanism 2 apply to any Ç«. A similar discussion holds
for Dwork-2006.
Applications of our mechanisms. Our proposed mechanisms
has the following applications. First, the noise amounts of our
mechanisms can be set as initial values to quickly search
for the optimal value or its tighter upper bound (as the
optimal value has no closed-form expression). We use such
approach in Algorithm 1 of Appendix O of this supplementary
file. In addition, our upper bounds may provide an intuitive
understanding about how a sufficient Gaussian noise amount
changes
to Ç« and Î´: given

 according
 Î´, a noise amount of
Î˜ 1Ç« + Î˜ âˆš1Ç« suffices; i.e., Î˜ 1Ç« suffices for small Ç« and

Î˜ âˆš1Ç« suffices for large Ç«. Finally, our mechanisms can
be useful for Internet of Things (IoT) devices with little
power or computational capabilities, since our mechanisms
are more computationally efficient than the optimal Gaussian
mechanism.

VI. (Ç«, Î´)-P ROBABILISTIC D IFFERENTIAL P RIVACY:
C ONNECTION TO (Ç«, Î´)-D IFFERENTIAL P RIVACY AND
G AUSSIAN M ECHANISMS
In this section, for (Ç«, Î´)-probabilistic differential privacy,
iii) From Theorem 1, there exists a function G(Î´) such
that Dwork-2014 does not achieve (Ç«, Î´)-differential pri- we discuss its connection to (Ç«, Î´)-differential privacy and its
vacy for Ç« > G(Î´). Figure 1 shows G(10âˆ’3 ) = 7.47, Gaussian mechanisms.
G(10âˆ’4 ) = 8.00, G(10âˆ’5 ) = 8.43, and G(10âˆ’6 ) =
8.79. Result ii) above considers 0 < Ç« â‰¤ 1. For A. (Ç«, Î´)-Probabilistic differential privacy
To achieve (Ç«, Î´)-differential privacy (formally given in
1 < Ç« â‰¤ G(Î´) which the proof of Dwork-2014 does
not cover but Dwork-2014 happens to achieve (Ç«, Î´)- Definition 1 on Page 4), most mechanisms ensure a condition
ÏƒMechanism-1 < ÏƒMechanism-2 < ÏƒDwork-2014 < ÏƒDwork-2006 .
(10)

8

1

1

0.8

0.8

0.6
0.4
0.2

0.6

10-3

0.4

10-4
10-5

0.2

Lemma 3. (Ç«, Î´)-Probabilistic differential privacy implies
(Ç«, Î´)-differential privacy.
âˆ’Ç«âˆ—

)
Lemma 4. (Ç«, Î´)-Differential privacy implies (Ç«âˆ— , Î´Â·(1+e
1âˆ’eÇ«âˆ’Ç«âˆ— )probabilistic differential privacy for any Ç«âˆ— > Ç«.

10-3

10-4
10-5

While the straightforward Lemma 3 is shown in [2], the
proof of Lemma 4 is not trivial. Although [9] of Dwork
0
5
10
15
20
0
5
10
15
20
and Rothblum, and [10] of Bun and Steinke mention that
differential privacy is equivalent, up to a small loss in pa(i) Mechanism Dwork-2014
(ii) Mechanism Dwork-2006
rameters, to probabilistic differential privacy, [9], [10] do not
Fig. 3: The shaded area in each subfigure represents the set of
present Lemma 4. For completeness, we present the proofs of
(Ç«, Î´) where Mechanism Dwork-2014 (resp., Dwork-2006)
Lemmas 3 and 4 in Appendices I and J of this supplementary
does not achieve (Ç«, Î´)-probabilistic differential privacy.
file.
Similar to Theorem 1 on Page 4, we show in Figure 3 the
on the privacy loss random variable defined below. Such
failures of the classical Gaussian mechanisms of Dwork and
condition is termed (Ç«, Î´)-probabilistic differential privacy [40]
Roth [2] in 2014 and of Dwork et al. [1] in 2006 to achieve
and elaborated below. We will explain that (Ç«, Î´)-probabilistic
(Ç«, Î´)-probabilistic differential privacy for large Ç«.
differential privacy is sufficient but not necessary for (Ç«, Î´)We now present the optimal Gaussian mechanism for (Ç«, Î´)differential privacy.
probabilistic
differential privacy.
â€²
For neighboring datasets D and D , the privacy loss
LY,D,Dâ€² (y) represents the multiplicative difference between
the probabilities that the same output y is observed when the
randomized algorithm Y is applied to D and Dâ€² , respectively. C. An analytical but not closed-form expression for the optimal Gaussian mechanism of (Ç«, Î´)-probabilistic differential
Specifically, we define
privacy
F [Y (D) = y]
,
(11)
LY,D,Dâ€² (y) := ln
F [Y (Dâ€² ) = y]
The optimal Gaussian mechanism of (Ç«, Î´)-probabilistic
differential
privacy (pDP) is given in Theorem 6 below.
where F [Â·] denotes the probability density function.
0

10-6
5.2

5.4

5.6

10-6

6.4

6.6

6.8

0

For simplicity, we use probability density function F [Â·] in Theorem 6 (Optimal Gaussian mechanism for
Eq. (11) above by assuming that the randomized algorithm Y (Ç«, Î´)-probabilistic differential privacy). The optimal
has continuous output. If Y has discrete output, we replace Gaussian mechanism for (Ç«, Î´)-probabilistic differential
F [Â·] by probability notation P [Â·].
privacy, denoted by Mechanism pDP-OPT, adds Gaussian
When y follows the probability distribution of random vari- noise with standard deviation ÏƒpDP-OPT to each dimension of
able Y (D), LY,D,Dâ€² (y) follows the probability distribution of a query with â„“2 -sensitivity âˆ†, for ÏƒpDP-OPT given by
ï£±
LY,D,Dâ€² (Y (D)), which is the privacy loss random variable.

p
ï£´
2 + Ç« = 2Î´;(13a)
d
Solve
d
such
that
erfc
(d)
+
erfc
ï£´
As a sufficient condition to enforce (Ç«, Î´)-differential privacy,
ï£²
âˆš

(Ç«, Î´)-probabilistic differential privacy of [40] is defined such
d + d2 + Ç« Â· âˆ†
ï£´
ï£´
that the privacy loss random variable LY,D,Dâ€² (Y (D)) falls
âˆš
.
(13b)
ï£³ ÏƒpDP-OPT :=
Ç« 2
in the interval [âˆ’Ç«, Ç«] with probability at least 1 âˆ’ Î´; i.e.,
P [âˆ’Ç« â‰¤ LY,D,Dâ€² (Y (D)) â‰¤ Ç«] â‰¥ 1 âˆ’ Î´. This is equivalent to Remark 6. Mechanism pDP-OPT is just the optimal
the following definition.
Gaussian mechanism for (Ç«, Î´)-probabilistic differential privacy
in the sense that it gives the minimal required amount
Definition 2 ((Ç«, Î´)-Probabilistic differential privacy [40]).
of
noise
when the noise follows a Gaussian distribution.
A randomized algorithm Y satisfies (Ç«, Î´)-probabilistic differHowever,
it may not be the optimal mechanism for (Ç«, Î´)ential privacy, if for any two neighboring datasets D and
probabilistic
differential privacy, since there may exist other
â€²
D (elaborated in Remark 1 on Page 4), we have that for
perturbation
methods
(e.g., adding non-Gaussian noise) which
y following the probabilistic distribution of the output Y (D)
may
outperform
a
Gaussian
mechanism under certain utility
(notated as y âˆ¼ Y (D)),
measure
[47].


F [Y (D) = y]
Ç«
â‰¥ 1 âˆ’ Î´,
(12)
â‰¤
e
Pyâˆ¼Y (D) eâˆ’Ç« â‰¤
We prove Theorem 6 in Appendix K of this supplementary
F [Y (Dâ€² ) = y]
file. We present the asympotics of ÏƒpDP-OPT as Theorem 7
where F [Â·] denotes the probability density function.
below.
B. Relationships between differential privacy and probabilistic
differential privacy
Lemmas 3 and 4 below present the relationships between
differential privacy and probabilistic differential privacy.

Theorem 7 (The asympotics of the optimal Gaussian noise
amount for (Ç«, Î´)-probabilistic differential privacy).

â‘  Given a fixed 0 < Î´ < 1, ÏƒpDP-OPT is Î˜ 1Ç«
as Ç« â†’ 0. Specifically,
given a fixed 0 < Î´ < 1,
.
inverfc(Î´)Â·âˆ†
âˆš
limÇ«â†’0 ÏƒpDP-OPT
= 1.
Ç« 2

9

TABLE III: Different mechanisms to achieve (Ç«, Î´)-probabilistic differential privacy (pDP).
pDP Mechanisms

Comparison
â€¢ the optimal Gaussian mechanism to achieve (Ç«, Î´)-pDP,
â€¢ no closed-form expression,
Our pDP-OPT
â€¢ computed using the bisection method with the number of iterations
of Theorem 6
being logarithmic in the given error (i.e., tolerance).
â€¢ closed-form expression involving
the complementary error functionâ€™s inverse inverfc(),
Our Mechanism 3
â€¢ computational complexity: dependent on
of Theorem 8
inverfc() implementations and often very efficient,
â€¢ ÏƒMechanism-3 is slightly greater than ÏƒpDP-OPT .
â€¢ closed-form expression involving only elementary functions,
Our Mechanism 4
â€¢ computed in constant amount of time,
of Theorem 9
â€¢ ÏƒMechanism-4 is slightly greater than ÏƒMechanism-3 .
 
Result â‘  of Theorem 7.
â‘¡ Given a fixed 0 < Î´ < 1, ÏƒpDP-OPT is Î˜ âˆš1Ç«
as Ç« â†’ âˆ. Specifically,
given
a
fixed
0
<
Î´
<
1,
.

From Theorem 6, the optimal Gaussian mechanism
âˆšâˆ†
limÇ«â†’âˆ ÏƒpDP-OPT
= 1.
pDP-OPT
does not have a closed-form expression. In the next
2Ç«
q

subsection, we detail our Gaussian mechanisms for (Ç«, Î´)-pDP,
ln Î´1
â‘¢ Given a fixed Ç« > 0, ÏƒpDP-OPT is Î˜
as Î´ â†’ 0. .Specifically,
given a fixed Ç« > 0, where the noise amounts have closed-form expressions and are

 q
more computationally efficient than pDP-OPT.
1
âˆ†
2 ln Î´ = 1.
limÎ´â†’0 ÏƒpDP-OPT
Ç«

Theorem 7 is proved in Appendix L of this supplementary
file.

D. Our Gaussian mechanisms for (Ç«, Î´)-probabilistic differential privacy with closed-form expressions of noise amounts

Remark 7. From Result â‘  of Theorem 7, given a fixed
The idea of our Gaussian mechanisms is to present compu0 < Î´ < 1, ÏƒpDP-OPT = Î˜ 1Ç« â†’ âˆ as Ç« â†’ 0. In contrast,
tationally efficient upper bounds of ÏƒpDP-OPT . To this end, we
from Result â‘  of Theorem 3, given a fixed 0 < Î´ < 1,
âˆ†
ÏƒDP-OPT â†’ 2âˆš2Â·inverf(Î´)
as Ç« â†’ 0. This shows a fundamen- first present Lemma 5, which upper bounds d in Eq. (13a) of
Theorem 6.
tal difference between (Ç«, Î´)-differential privacy and (Ç«, Î´)Lemma 5. d in Eq. (13a) is greater than inverfc(2Î´) and less
probabilistic differential privacy.
than inverfc(Î´).
Remark 8. In Lemmas 3 and 4 above, we show the relationship between differential privacy and probabilistic differential
We prove Lemma 5 in Appendix M of this supplementary
privacy that the latter implies the former and the former file. Theorem 6 and Lemma 5 imply an upper bound of
implies the latter up to possible loss in privacy parameters. ÏƒpDP-OPT as ÏƒMechanism-3 in Theorem 8 below, where we
Given this, one may wonder if this relationship contradicts present Mechanism 3 to achieve (Ç«, Î´)-probabilistic differtheir difference discussed in Remark 7 above as Ç« â†’ 0. Below ential privacy.
we explain there is no contradiction, by showing that the
8
(Gaussian
Mechanism 3
for
Gaussian noise amount for probabilistic differential privacy Theorem
(Ç«,
Î´)-Probabilistic
differential
privacy).
(Ç«,
Î´)-Probabilistic
obtained by first achieving differential privacy is at the same
order as the optimal Gaussian noise amount for probabilistic differential privacy can be achieved by Mechanism 3, which
adds Gaussian noise with standard deviation ÏƒMechanism-3
differential privacy when Ç« â†’ 0.
âˆ’Ç«
to each dimension of a query with â„“2 -sensitivity âˆ†, for
)
From Lemma 4, (0, Î´Â·(1âˆ’e
1+eâˆ’Ç« )-differential privacy im- ÏƒMechanism-3 given by
plies (Ç«, Î´)-probabilistic differential privacy. From Result â‘ 
ï£±
âˆ’Ç«
)
f := inverfc(Î´);
(14a)
ï£´
of Theorem 3, (0, Î´Â·(1âˆ’e
ï£²


1+eâˆ’Ç« )-differential privacy can be
p
achieved by the Gaussian mechanism with noise amount
f + f2 + Ç« Â· âˆ†
ï£´
âˆ†

ï£³
âˆš
.
(14b)
Ïƒ
:=
.
Hence,
(Ç«,
Î´)-probabilistic
differential
âˆš
Mechanism-3
âˆ’Ç«
2 2Â·inverf Î´Â·(1âˆ’eâˆ’Ç« )
Ç« 2
1+e
privacy can also be achieved by the Gaussian mechanism with

The expression of ÏƒMechanism-3 involves the complementary
âˆ†
 , which given Î´ is Î˜ 1Ç« as
noise amount âˆš
âˆ’Ç«
error
functionâ€™s inverse inverfc(). Hence, we further present
2 2Â·inverf Î´Â·(1âˆ’eâˆ’Ç« )
1+e
(1âˆ’eâˆ’Ç« ) 
inverf(x)
Lemma
6 below, which will enable us to propose Mechanism
1
Ç«âˆšâ†’ 0 due to limÇ«â†’0 1+eâˆ’Ç« Ç« = 2 and limxâ†’0
=
x
4.
Its
noise
amount is given by the closed-form expression of
Ï€
2 from [49]. From Result â‘  of Theorem 7, the optimal Gaus- ÏƒMechanism-4 and has only elementary functions.
sian noise amount for (Ç«, Î´)-probabilistic differential privacy
Lemma 6 upper bounds f in Eq. (14a).
given Î´ is also Î˜ 1Ç« as Ç« â†’ 0. Hence, the combination of
Lemma 4 and Result â‘  of Theorem 3 does not contradict Lemma 6. f in Eq. (14a) is less than g in Eq. (15a).

10

We prove Lemma 6 in Appendix N of this supplementary
file.
Theorem 8 and Lemma 6 imply an upper bound of
ÏƒMechanism-3 as ÏƒMechanism-4 in Theorem 9 below, where
the presented Mechanism 4 is further simpler than
Mechanism 3 as noted above.
Theorem
9
(Gaussian
Mechanism 4
for
(Ç«, Î´)-Probabilistic differential privacy). (Ç«, Î´)-Probabilistic
differential privacy can be achieved by Mechanism 4, which
adds Gaussian noise with standard deviation ÏƒMechanism-4
to each dimension of a query with â„“2 -sensitivity âˆ†, for
ÏƒMechanism-4 given by
s
ï£±
ï£´
2
ï£´
ï£´ g := ln âˆš
;
(15a)
ï£´
ï£²
8Î´ + 1 âˆ’ 1


p
ï£´
ï£´
g + g2 + Ç« Â· âˆ†
ï£´
ï£´
ï£³ ÏƒMechanism-4 :=
âˆš
.
(15b)
Ç« 2

with standard deviation Ïƒ achieves Ï-zCDP by [10], where
âˆ†2
that âˆš
the GausÏ = 2Ïƒ
2 . Combining these results, we can derive
âˆš

âˆ†Â·

ln

1
Î´+

ln

1
Î´ +Ç«

âˆš
sian mechanism with standard deviation
2Ç«
achieves (Ç«, Î´)-DP. This expression is obtained
q by solving
2
âˆ†
Ïƒ which satisfy Ï = 2Ïƒ
Ï ln( 1Î´ ). Such
2 and Ç« = Ï + 2
noise amount is even worse (i.e., higher) than our weakest
âˆš Mechanism 4 in Theorem 9 on Page 10 in view of
8Î´ + 1 âˆ’ 1 > 2Î´ given 0 < Î´ < 1. Hence, achieving (Ç«, Î´)DP by first ensuring zCDP cannot give Gaussian mechanisms
better than ours.
Relationship between RDP and DP. Mironov [23] shows
that (Î±, ÏÎ±)-RDP implies (Ç«, Î´)-DP for Ç« = ÏÎ± + ln(1/Î´)
Î±âˆ’1 , and
the Gaussian mechanism with standard deviation Ïƒ achieves
âˆ†2
(Î±, ÏÎ±)-RDP for Ï = 2Ïƒ
2 . Combining these results, we can
also prove
that
the
Gaussian
mechanism with standard deviaâˆš

âˆš
âˆ†Â·

ln

1
Î´+

ln

1
Î´ +Ç«

âˆš
tion
achieves (Ç«, Î´)-DP. This expression
2Ç«
is obtained by finding the smallest Ïƒ such that there exists
ln(1/Î´)
âˆ†2
Table III summarizes different mechanisms to achieve (Ç«, Î´)- Î± > 1 such that Ï = 2Ïƒ2 and Ç« = ÏÎ± + Î±âˆ’1 (we just
express Ïƒ and take its minimum with respect to Î±). As noted
probabilistic differential privacy discussed above.
above, this noise amount is even worse (i.e., higher) than our
weakest Mechanism 4 in Theorem 9. Thus, achieving (Ç«, Î´)VII. C ONCENTRATED D IFFERENTIAL P RIVACY AND
DP by first ensuring RDP cannot give Gaussian mechanisms
R ELATED N OTIONS
better than ours. We emphasize that the comparison may be
Several variants of differential privacy (DP), including different if the RDP paper [23]â€™s Proposition 3 that (Î±, ÏÎ±)ln(1/Î´)
mean-concentrated differential privacy (mCDP) [9], zero- RDP implies (ÏÎ± + Î±âˆ’1 , Î´)-DP can be improved. Yet, we
concentrated differential privacy (zCDP) [10], ReÌnyi differen- have not been able to find such improvement after checking
tial privacy [23] (RDP), and truncated concentrated differential prior papers related to RDP.
Relationship between tCDP and DP. Bun et al. [24]
privacy (tCDP) [24] have been recently proposed as alternashow that
tives to (Ç«, Î´)-DP. Below we show that achieving (Ç«, Î´)-DP by ï£±
q (Ï, Ï‰)-tCDP implies (Ç«, Î´)-DP for Ç« =
first ensuring one of these privacy definitions (mCDP, zCDP, ï£²Ï + 2 Ï ln 1 if ln 1 â‰¤ (Ï‰ âˆ’ 1)2 Ï,
Î´
Î´
and the Gaussian
RDP, and tCDP) cannot give Gaussian mechanisms better than ï£³
ln( Î´1 )
1
2
ÏÏ‰
+
if
ln
â‰¥
(Ï‰
âˆ’
1)
Ï,
Ï‰âˆ’1
Î´
ours, based on existing results on the relationships between
mechanism with standard deviation Ïƒ achieves (Ï, Ï‰)-tCDP
mCDP, zCDP, RDP, tCDP and DP.
2
âˆ†
for Ï = 2Ïƒ
2 . We can see that these results are already
Lemma 7 (Relationship between (Ç«, Î´)-DP and covered by the above discussions for the relationship between
(Âµ, Ï„ )-mCDP). For Ç« > Âµ, (Âµ, Ï„ )-mCDP implies (Ç«, Î´)- zCDP and DP, and for the relationship between RDP and DP.
probabilistic
privacy
(pDP)
Therefore, achieving (Ç«, Î´)-DP by first ensuring tCDP cannot


 for
 differential
(Ç«+Âµ)2
(Ç«âˆ’Âµ)2
+ exp âˆ’ 2Ï„ 2 , which further implies give Gaussian mechanisms better than ours.
Î´ = exp âˆ’ 2Ï„ 2
(Ç«, Î´)-DP.
VIII. E XPERIMENTS
Despite not being presented in [9] which proposes mCDP,
This section presents experiments to evaluate different
the first part of Lemma 7 clearly follows from the definitions
Gaussian
mechanisms for mean estimation and histogram
of mCDP and pDP by using the tail bounds on the privacy loss
estimation
under differential privacy.
random variable of mCDP, while the second part of Lemma 7
is from Lemma 3.
For a query with â„“2 -sensitivity 1, Theorem 3.2 in [9] A. Mean Estimation
shows that the Gaussian mechanism with standard deviation Ïƒ
We evaluate the utility of all mechanisms for the task of
achieves ( 2Ïƒ1 2 , Ïƒ1 )-mCDP,which based
on
Lemma
7
implies
private
mean estimation using synthetic data. The input dataset



d
(Ç«+ 2Ïƒ1 2 )2
(Ç«âˆ’ 2Ïƒ12 )2
x
=
(x
given d,
1 , . . . , xn ) contains n vectors xi âˆˆ R for a P
+ exp âˆ’ 2( 1 )2
.
(Ç«, Î´)-pDP for Î´ = exp âˆ’ 2( 1 )2
Ïƒ
Ïƒ
and the query for mean computation is Q(x) = (1/n) ni=1 xi .
Expressing Ïƒ in terms of Ç« and Î´ gives Ïƒ as ÏƒpDP-OPT of We set n = 1000 and sample each dataset x in two steps [39].
Theorem 6. Hence, using the relationship between mCDP and The first step is to sample an initial data center x0 âˆˆ Rd ,
(p)DP does not give a new mechanism which we have not with each dimension of x0 independently following a standard
presented.
Gaussian distribution with zero mean and variance being
Relationship between zCDP and DP. From Proposition 1. The second step is to construct x = (x1 , . . . , xn ) with
1.3 and Proposition
1.6 in [10], Ï-zCDP implies (Ç«, Î´)-DP xi = x0 + Î¾i , where each Î¾i âˆˆ Rd is independently and
q
for Ç« = Ï + 2 Ï ln( Î´1 ). Moreover, the Gaussian mechanism identically distributed (i.i.d.) with independent coordinates

11

SDP-OPT

DP-OPT

Dwork-2014

Dwork-2006

Mechanism 1

Mechanism 2

Mechanism 3

Mechanism 4

3000
4

6

4

3

5

3

2

4

2

1

3

1

2
10-8 10-7 10-6 10-5 10-4

0

0
0.1

0.3

0.5

0.7

0.9 1

(a) Error w.r.t. Ç«

4000

10 20 30 40 60






80 100

(b) Error w.r.t. Î´
(c) Error w.r.t. dimension d
Fig. 4: Mean estimation.

2000

3000

1000

2000

0
0.1

0.3

0.5

0.7

0.9 1

1000
10-9

10-8

10-7

10-6

(a) Error w.r.t. Ç«
(b) Error w.r.t. Î´
Fig. 5: Histogram estimation.

sampled uniformly from the interval [âˆ’1/2, 1/2]. We consider while fixing Ç« = 0.1. Both subfigures show that the utilities of
bounded differential privacy, where two neighboring datasets our proposed Gaussian mechanisms are higher than those of
have the same size n, and have different records at only one the classical ones [1], [2] and close to that of the optimal yet
of the n positions. Since the points xi in each dataset all lie in more computationally expensive DP-OPT mechanism.
an âˆš
â„“âˆ -ball of radius 1, the â„“2 -sensitivity of mean estimation
IX. C ONCLUSION
is d/n, where d is a recordâ€™s dimension.
For the above query Q on the dataset x, we consider
Differential privacy (DP) has received considerable interest
different Gaussian mechanisms to achieve (Ç«, Î´)-differential recently since it provides a rigorous framework to quane be such a Gaussian mechanism. We report the tify data privacy. Well-known solutions to (Ç«, Î´)-DP are the
privacy. Let Q
e
â„“2 error Q(x)
âˆ’ Q(x) . The results for different Gaussian Gaussian mechanisms by Dwork et al. [1] in 2006 and by
2
mechanisms are presented in Figure 4. The plots consider Dwork and Roth [2] in 2014, where a certain amount of
Ç« â‰¤ 1 since this is required by the proofs of Dwork-2006 Gaussian noise is added independently to each dimension
of [1] and Dwork-2014 of [2]. Figure 4-(a) fixes Î´ = 10âˆ’4 of the query result. Although the two classical Gaussian
and varies Ç«; Figure 4-(b) fixes Ç« = 0.1 and varies Î´; and mechanisms [1], [2] explicitly state their usage for Ç« â‰¤ 1
Figure 4-(c) with Ç« = 0.1 and Î´ = 10âˆ’4 evaluates the only, many studies applying them neglect the constraint on
impact of a data recordâ€™s dimension d. All subfigures of Ç«, rendering the obtained results inaccurate. In this paper, for
Figure 4 show that our proposed Gaussian mechanisms achieve (Ç«, Î´)-DP, we present Gaussian mechanisms which work for
better utilities than the classical Gaussian mechanisms [1], every Ç«. Another improvement is that our mechanisms achieve
[2] Dwork-2014 and Dwork-2006; In fact, Dwork-2014 higher utilities than those of the classical ones [1], [2]. Since
and Dwork-2006 have the largest â„“2 -errors. Moreover, the most mechanisms proposed in the literature for (Ç«, Î´)-DP are
utilities of our proposed mechanisms are close to that of obtained by ensuring a condition called (Ç«, Î´)-probabilistic
the optimal yet more computationally expensive Gaussian differential privacy (pDP), we also present the difference/relationship between (Ç«, Î´)-DP and (Ç«, Î´)-pDP, and Gaussian
mechanism DP-OPT.
mechanisms for (Ç«, Î´)-pDP. Our research on reviewing and
improving
the Gaussian mechanisms will benefit differential
B. Histogram Estimation
privacy applications built based on the primitive.
We now run experiments on the Adult dataset from the UCI
machine learning repository4, to evaluate different Gaussian
R EFERENCES
mechanisms for histogram estimation with differential privacy.
[1] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor, â€œOur
The Adult dataset contains census information with 45222
data, ourselves: Privacy via distributed noise generation,â€ in Eurocrypt,
records and 15 attributes. The attributes include both categor2006, pp. 486â€“503.
[2] C. Dwork and A. Roth, â€œThe algorithmic foundations of differential
ical ones such as race, gender, and education level, as well as
privacy,â€ Foundations and Trends in Theoretical Computer Science (FnTnumerical ones such as capital gain, capital loss, and weight.
TCS), vol. 9, no. 3â€“4, pp. 211â€“407, 2014.
We consider the combination of all categorical attributes and
[3] C. Dwork, F. McSherry, K. Nissim, and A. Smith, â€œCalibrating noise
to sensitivity in private data analysis,â€ in Theory of Cryptography
let the histogram query be a vector of the counts. Here we
Conference (TCC), 2006, pp. 265â€“284.
tackle unbounded differential privacy, where a neighboring
[4] P. Kairouz, S. Oh, and P. Viswanath, â€œThe composition theorem for
dataset is obtained by deleting or adding one record, so the
differential privacy,â€ IEEE Transactions on Information Theory, vol. 63,
no. 6, pp. 4037â€“4049, June 2017.
sensitivity of the histogram query is 1. For different Gaussian
[5] S. Song, K. Chaudhuri, and A. D. Sarwate, â€œStochastic gradient descent
mechanisms satisfying (Ç«, Î´)-differential privacy, we compare
with differentially private updates,â€ in IEEE Global Conference on
their Mean Squared Error (MSE) and plot the results in
Signal and Information Processing (GlobalSIP), 2013, pp. 245â€“248.
[6] Y. Wang and A. Anandkumar, â€œOnline and differentially-private tensor
Figure 5.
decomposition,â€ in Conference on Neural Information Processing SysIn Figure 5-(a), we vary Ç« from 0.1 to 1.0 while fixing
tems (NIPS), 2016, pp. 3531â€“3539.
âˆ’6
âˆ’9
âˆ’5
Î´ = 10 . In Figure 5-(b), we vary Î´ from 10
to 10
[7] J. JaÌˆlkoÌˆ, O. Dikmen, and A. Honkela, â€œDifferentially private variational
4 http://archive.ics.uci.edu/ml

inference for non-conjugate models,â€ in Conference on Uncertainty in
Artificial Intelligence (UAI), 2017.

10-5

12

[8] M. HeikkilaÌˆ, E. Lagerspetz, S. Kaski, K. Shimizu, S. Tarkoma, and
A. Honkela, â€œDifferentially private Bayesian learning on distributed
data,â€ in NIPS, 2017, pp. 3229â€“3238.
[9] C. Dwork and G. Rothblum, â€œConcentrated differential privacy,â€ arXiv
preprint arXiv:1603.01887v1, 2016.
[10] M. Bun and T. Steinke, â€œConcentrated differential privacy: Simplifications, extensions, and lower bounds,â€ in Theory of Cryptography
Conference (TCC), 2016, pp. 635â€“658.
[11] S. Meiser and E. Mohammadi, â€œTight on budget? Tight bounds for rfold approximate differential privacy,â€ in ACM SIGSAC Conference on
Computer and Communications Security (CCS), 2018, pp. 247â€“264.
[12] H. Imtiaz and A. D. Sarwate, â€œDistributed differentially-private
algorithms for matrix and tensor factorization,â€ arXiv preprint
arXiv:1804.10299, 2018.
[13] H. Liu, Z. Wu, Y. Zhou, C. Peng, F. Tian, and L. Lu, â€œPrivacy-preserving
monotonicity of differential privacy mechanisms,â€ Applied Sciences,
vol. 8, no. 11, p. 2081, 2018.
[14] J. Wang, W. Bao, L. Sun, X. Zhu, B. Cao, and P. S. Yu, â€œPrivate model compression via knowledge distillation,â€ arXiv preprint
arXiv:1811.05072, 2018.
[15] B. Ermis and A. T. Cemgil, â€œDifferentially private variational dropout,â€
arXiv preprint arXiv:1712.02629, 2017.
[16] H. Liu, Z. Wu, C. Peng, F. Tian, and L. Lu, â€œAdaptive Gaussian
mechanism based on expected data utility under conditional filtering
noise.â€ KSII Transactions on Internet & Information Systems, vol. 12,
no. 7, pp. 3497â€“3515, 2018.
[17] H. Imtiaz and A. D. Sarwate, â€œDifferentially-private canonical correlation analysis,â€ in IEEE GlobalSIP, 2017, pp. 283â€“287.
[18] â€”â€”, â€œDifferentially private distributed principal component analysis,â€
in IEEE ICASSP, 2018, pp. 2206â€“2210.
[19] A. Pyrgelis, C. Troncoso, and E. De Cristofaro, â€œKnock knock, whoâ€™s
there? Membership inference on aggregate location data,â€ arXiv preprint
arXiv:1708.06145, 2017.
[20] P. Jain and A. G. Thakurta, â€œ(Near) dimension independent risk bounds
for differentially private learning,â€ in International Conference on Machine Learning, 2014, pp. 476â€“484.
[21] Y. Wang, S. Fienberg, and A. Smola, â€œPrivacy for free: Posterior
sampling and stochastic gradient Monte Carlo,â€ in ICML, 2015, pp.
2493â€“2502.
[22] B. Balle and Y.-X. Wang, â€œImproving the Gaussian mechanism for
differential privacy: Analytical calibration and optimal denoising,â€ in
ICML, 2018, pp. 403â€“412.
[23] I. Mironov, â€œReÌnyi differential privacy,â€ in IEEE Computer Security
Foundations Symposium (CSF), 2017, pp. 263â€“275.
[24] M. Bun, C. Dwork, G. N. Rothblum, and T. Steinke, â€œComposable and
versatile privacy via truncated CDP,â€ in ACM Symposium on Theory of
Computing (STOC), 2018, pp. 74â€“86.
[25] R. Shokri and V. Shmatikov, â€œPrivacy-preserving deep learning,â€ in ACM
CCS, 2015, pp. 1310â€“1321.
[26] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang, â€œDeep learning with differential privacy,â€ in ACM
CCS, 2016, pp. 308â€“318.
[27] C. Dwork, K. Talwar, A. Thakurta, and L. Zhang, â€œAnalyze Gauss:
Optimal bounds for privacy-preserving principal component analysis,â€
in ACM STOC, 2014, pp. 11â€“20.
[28] A. Nikolov, K. Talwar, and L. Zhang, â€œThe geometry of differential
privacy: The sparse and approximate cases,â€ in ACM STOC, 2013, pp.
351â€“360.
[29] J. Hsu, Z. Huang, A. Roth, and Z. S. Wu, â€œJointly private convex
programming,â€ in ACM-SIAM SODA, 2016, pp. 580â€“599.
[30] T. Elahi, G. Danezis, and I. Goldberg, â€œPrivEx: Private collection of
traffic statistics for anonymous communication networks,â€ in ACM CCS,
2014, pp. 1068â€“1079.
[31] F. McSherry and K. Talwar, â€œMechanism design via differential privacy,â€
in IEEE FOCS, 2007, pp. 94â€“103.
[32] Q. Geng, W. Ding, R. Guo, and S. Kumar, â€œTruncated Laplacian mechanism for approximate differential privacy,â€ arXiv preprint
arXiv:1810.00877, 2018.
[33] Q. Geng, â€œThe optimal mechanism in differential privacy,â€ Ph.D. dissertation, University of Illinois at Urbana-Champaign, 2014.
[34] Q. Geng, P. Kairouz, S. Oh, and P. Viswanath, â€œThe staircase mechanism
in differential privacy,â€ IEEE Journal of Selected Topics in Signal
Processing, vol. 9, no. 7, pp. 1176â€“1184, 2015.
[35] V. Pihur, â€œThe Podium mechanism: Improving on the Laplace and
Staircase mechanisms,â€ arXiv preprint arXiv:1905.00191, 2019.

[36] A. Gilbert and A. McMillan, â€œLocal differential privacy for physical
sensor data and sparse recovery,â€ arXiv preprint arXiv:1706.05916v1,
2017.
[37] M. Bun, J. Ullman, and S. Vadhan, â€œFingerprinting codes and the price
of approximate differential privacy,â€ in ACM Symposium on Theory of
Computing (STOC), 2014, pp. 1â€“10.
[38] D. Boneh and J. Shaw, â€œCollusion-secure fingerprinting for digital data,â€
IEEE Transactions on Information Theory, vol. 44, no. 5, pp. 1897â€“1905,
1998.
[39] F. Liu, â€œGeneralized Gaussian mechanism for differential privacy,â€ IEEE
Transactions on Knowledge and Data Engineering, vol. 31, no. 4, pp.
747â€“756, 2018.
[40] A. Machanavajjhala, D. Kifer, J. Abowd, J. Gehrke, and L. Vilhuber,
â€œPrivacy: Theory meets practice on the map,â€ in IEEE International
Conference on Data Engineering (ICDE), 2008, pp. 277â€“286.
[41] National
Institute
of
Standards
and
Technology
(NIST),
â€œDifferential
privacy
synthetic
data
challenge,â€
https://www.challenge.gov/challenge/differential-privacy-synthetic-data-challenge/,
accessed: 2019-11-25.
[42] J. Duchi, M. J. Wainwright, and M. I. Jordan, â€œLocal privacy and
minimax bounds: Sharp rates for probability estimation,â€ in Conference
on Neural Information Processing Systems (NIPS), 2013, pp. 1529â€“
1537.
[43] J. Tang, A. Korolova, X. Bai, X. Wang, and X. Wang, â€œPrivacy loss in
Appleâ€™s implementation of differential privacy on macOS 10.12,â€ arXiv
preprint arXiv:1709.02753, 2017.
[44] Apple,
â€œDifferential
privacy
overview,â€
https://www.apple.com/privacy/docs/Differential Privacy Overview.pdf,
accessed: 2019-11-25.
[45] UÌ. Erlingsson, V. Pihur, and A. Korolova, â€œRAPPOR: Randomized
aggregatable privacy-preserving ordinal response,â€ in Proc. ACM Conference on Computer and Communications Security (CCS), 2014, pp.
1054â€“1067.
[46] D. M. Sommer, S. Meiser, and E. Mohammadi, â€œPrivacy loss classes:
The central limit theorem in differential privacy,â€ PoPETS, vol. 2019,
no. 2, pp. 245â€“269, 2019.
[47] Q. Geng and P. Viswanath, â€œOptimal noise adding mechanisms for
approximate differential privacy,â€ IEEE Transactions on Information
Theory, vol. 62, no. 2, pp. 952â€“969, 2016.
[48] G.
S.
Rao,
Mathematical
Methods.
I.K.
International
Publishing
House
Pvt.
Limited,
2010,
https://books.google.com/books?id=SJKVs7cumsUC&pg=PA3.
[49] L. Carlitz, â€œThe inverse of the error function,â€ Pacific Journal of
Mathematics, vol. 13, no. 2, pp. 459â€“470, 1963.
[50] J. Zhao, T. Wang, T. Bai, K.-Y. Lam, X. Ren, X. Yang, S. Shi, Y. Liu,
and H. Yu, â€œReviewing and improving the Gaussian mechanism for
differential privacy,â€ 2019, this is the submitted supplementary file.
[Online]. Available: https://www.ntu.edu.sg/home/junzhao/DP.pdf
[51] G. K. Karagiannidis and A. S. Lioumpas, â€œAn improved approximation
for the Gaussian Q-function,â€ IEEE Communications Letters, vol. 11,
no. 8, 2007.
[52] M. Abramowitz and I. Stegun, â€œHandbook of mathematical functions
with formulas, graphs, and mathematical tables,â€ National Bureau of
Standards, Washington, DC, 1964.
[53] J. Craig, â€œA new, simple and exact result for calculating the probability
of error for two-dimensional signal constellations,â€ in IEEE MILCOM,
1991, pp. 571â€“575.

A PPENDIX
The appendices are organized as follows. Appendices A
and B are also provided in the submission, while other
appendices are given in this submitted supplementary file (the
same as [50]).
â€¢ Appendix A presents the proof of
ÏƒMechanism-1 < ÏƒMechanism-2 < ÏƒDwork-2014 < ÏƒDwork-2006 .
â€¢ Appendix B presents the proof of Theorem 1.
â€¢ Appendix C presents the proof of Theorem 2.
â€¢ Appendix D presents more discussions about Remark 4 of
Page 5.
â€¢ Appendix E presents the proof of Theorem 3.
â€¢ Appendix F presents the proof of Lemma 10.

13

â€¢ Appendix G proves Lemma 1, which along with Theorem 2
implies Theorem 4.
â€¢ Appendix H proves Lemma 2, which along with Theorem 4
implies Theorem 5.
â€¢ Appendix I presents the proof of Lemma 3.
â€¢ Appendix J presents the proof of Lemma 4.
â€¢ Appendix K presents the proof of Theorem 6.
â€¢ Appendix L presents the proof of Theorem 7.
â€¢ Appendix M proves Lemma 5, which along with Theorem 6
implies Theorem 8.
â€¢ Appendix N proves Lemma 6, which along with Theorem 8
implies Theorem 9.
â€¢ Appendix O presents Algorithm 1 to compute ÏƒDP-OPT of
Theorem 2.
â€¢ Appendix P provides analyses for the composition of
Gaussian mechanisms to achieve (Ç«, Î´)-DP or (Ç«, Î´)-pDP.
â€¢ Appendix Q shows Lemma 8, which is used in the proofs
of Lemmas 2 and 6.

A. Proving ÏƒMechanism-1 < ÏƒMechanism-2 < ÏƒDwork-2014 <
ÏƒDwork-2006
To prove ÏƒMechanism-1 < ÏƒMechanism-2 < ÏƒDwork-2014 <
ÏƒDwork-2006 , from Inequalities (3) and (8), we just need
to establish ÏƒMechanism-2 < ÏƒDwork-2014 . Recalling Eq. (2)
and (9), we will prove
r
1.25
2 ln
Î´
s
s

âˆš
2
2
>
ln âˆš
+ Ç« + ln âˆš
2,
16Î´ + 1 âˆ’ 1
16Î´ + 1 âˆ’ 1
for Ç« â‰¤ 1 and 0 < Î´ < 0.5.

(16)

square on both sides:
1.25
2
âˆ’ 0.5, for 0 < Î´ < 0.5.
< ln
ln âˆš
Î´
16Î´ + 1 âˆ’ 1

(19)

Due to 1.25 Ã— exp(âˆ’0.5) â‰ˆ 0.7582 > 0.75, Inequality (19) is
implied by
2
0.75
âˆš
for 0 < Î´ < 0.5.
<
Î´
16Î´ + 1 âˆ’ 1

(20)

2
âˆ’ 0.75
We define f (Î´) := âˆš16Î´+1âˆ’1
Î´ . Taking the derivative of
f (Î´) with respect to Î´, we obtain

3
16
âˆš
+
f â€² (Î´) = âˆ’ âˆš
( 16Î´ + 1 âˆ’ 1)2 16Î´ + 1 4Î´ 2
âˆš
5 16Î´ + 1 âˆ’ (8Î´ + 1)
âˆš
=
8Î´ 2 16Î´ + 1
25(16Î´ + 1) âˆ’ (8Î´ + 1)2
âˆš
âˆš
=
8[5 16Î´ + 1 + (8Î´ + 1)]Î´ 2 16Î´ + 1
64Î´(1 âˆ’ Î´) + 320Î´ + 24
âˆš
âˆš
=
8[5 16Î´ + 1 + (8Î´ + 1)]Î´ 2 16Î´ + 1
> 0, for 0 < Î´ < 0.5.

(21)

Hence, f (Î´) is strictly increasing for 0 < Î´ < 0.5, resulting
2
= âˆ’0.5 < 0, so
in f (Î´) < f (0.5) = âˆš16Î´+1âˆ’1
âˆ’ 0.75
Î´
that Inequality (20) is proved. Then following the explanation
above, we complete establishing ÏƒMechanism-2 < ÏƒDwork-2014 .


B. Proof of Theorem 1
From Theorem 2, ÏƒDP-OPT is the minimal required amount
of Gaussian noise to achieve (Ç«, Î´)-differential privacy. Hence,
to show that the Gaussian noise amount F (Î´) Ã— âˆ†/Ç« is not
sufficient for (Ç«, Î´)-differential privacy, we will prove that for
any 0 < Î´ < 1, there exists a positive function G(Î´) such that
for any Ç« > G(Î´), we have

Since the term after â€œ>â€ in Inequality (16) is increasing
with respect to Ç«, we can just let Ç« be 1 in Inequality (16).
Hence, we will obtain Inequality (16) once proving
F (Î´) Ã— âˆ†/Ç« < ÏƒDP-OPT .
(22)
r
âˆš
1.25
We can show that the function x+ x2 + Ç« strictly increases
2 ln
Î´
as x increases for x âˆˆ (âˆ’âˆ, âˆ) by noting its
s
âˆš derivative
s

âˆš
1 + âˆšxx2 +Ç« is positive. Also, limxâ†’âˆ’âˆ (x + x2 + Ç«) =
2
2
âˆš
>
ln âˆš
+ 1 + ln âˆš
2,
limxâ†’âˆ’âˆ âˆ’x+âˆšÇ« x2 +Ç« = 0 and limxâ†’âˆ (x + x2 + Ç«) = âˆ.
16Î´ + 1 âˆ’ 1
16Î´ + 1 âˆ’ 1
âˆš
2
for 0 < Î´ < 0.5.
(17) Hence, the values that x+ x + Ç« for x âˆˆ (âˆ’âˆ, âˆ) can take
constitutes the open interval (0, âˆ). Then due to F (Î´) > 0,
q
q
2
we
can define h such that
âˆš
and
b
denoting
ln
,
then
With a denoting ln 1.25
Î´
âˆš
âˆš 16Î´+1âˆ’1
âˆš
âˆš
âˆš
h + h2 + Ç«
Inequality (17) means 2 a > ( b2 + 1 + b )/ 2, which is
âˆš
.
(23)
F
(Î´)
=
0.25
equivalent
toâˆšb < âˆš
a âˆ’ 0.25
2
aâˆš since setting b as a âˆ’ a will let
âˆš
âˆš
( b2 + 1 + b )/ 2 be 2 a exactly (note that a âˆ’ 0.25
a > 0
(a+ aâˆš2 +Ç« )Â·âˆ†
of (5), clearly
clearly holds for 0 < Î´ < 0.5). Hence, the desired result From Eq. (23) and ÏƒDP-OPT =
âˆšÇ« 2
âˆš
h+ âˆšh2 +Ç«
a+ âˆša2 +Ç«
Inequality (17) is equivalent to
Inequality (22) is equivalent to
<
and
2
2
s
r
further equivalent to h < a.
2
1.25
0.25
As
shown
Appendix
D,
ln âˆš
< ln
âˆ’q
,
âˆš in

Î´
Ç«
16Î´ + 1 âˆ’ 1
2+Ç«
ln 1.25
u
strictly
decreases
as
r(u)
:=
erfc
(u)
âˆ’
e
erfc
Î´
u increases for u âˆˆ (âˆ’âˆ, âˆ). Then h < a is equivalent to
for 0 < Î´ < 0.5,
(18)
r(h) > r(a). We will prove limÇ«â†’âˆ r(h) = 2, which along
which clearly is implied by the following after taking the with r(a) = 2Î´ in Eq. (5) implies that for any 0 < Î´ < 1,

14

there exists a positive function G(Î´) such that for any
Ç« > G(Î´), we have r(h) > r(a) and thus h < a.
From the above discussion, the desired result Eq. (22)
follows once we show limÇ«â†’âˆ r(h) = 2. From Eq. (23), it
Ç« âˆš
âˆ’ F (Î´)Â·2
. Hence, for any Ç« â‰¥ 4Ã—[F (Î´)]2 ,
holds that h = Fâˆš(Î´)
2
2
Ç«
we have h â‰¤ âˆ’ 4âˆš2Â·F (Î´) , which implies
p

eÇ« erfc
h2 + Ç«
â‰¤ eÇ« erfc (|h|)


Ç«
Ç«
âˆš
â‰¤ e erfc
4 2 Â· F (Î´)

2 !
Ç«
âˆš
â‰¤ eÇ« Ã— exp âˆ’
4 2 Â· F (Î´)
â†’ 0, as Ç« â†’ âˆ,

2



(24)

where the last â€œâ‰¤â€ uses erfc (x) â‰¤ exp âˆ’x for
âˆš x > 0.The
above result Eq. (24) implies limÇ«â†’âˆ [eÇ« erfc h2 + Ç« ] =
0. Combining this and limÇ«â†’âˆ erfc (h) = 2, we derive
limÇ«â†’âˆ r(h) = 2. Then as already explained, the desired
result is proved.


C. Proof of Theorem 2
Proving Theorem 2â€™s Property (i):
The optimal Gaussian mechanism for (Ç«, Î´)-differential privacy, denoted by Mechanism DP-OPT, adds Gaussian noise
with standard deviation ÏƒDP-OPT to each dimension of a query
with â„“2 -sensitivity âˆ†, for ÏƒDP-OPT obtained by Theorem 8 of
Balle and Wang [22] to satisfy


Ç«ÏƒDP-OPT
âˆ†
âˆ’
Î¦
2ÏƒDP-OPT
âˆ†


Ç«ÏƒDP-OPT
âˆ†
Ç«
= Î´,
(25)
âˆ’
âˆ’e Î¦ âˆ’
2ÏƒDP-OPT
âˆ†
where Î¦ (Â·) denotes the cumulative distribution function of
the standard univariate Gaussian probability distribution with
mean 0 and variance 1.
We define

1 Ç«ÏƒDP-OPT
âˆ†
a := âˆš
âˆ’
.
(26)
âˆ†
2ÏƒDP-OPT
2
âˆš

(a+ aâˆš2 +Ç« )Â·âˆ†
, as given by Eq. (5).
Then ÏƒDP-OPT equals
Ç« 2
âˆš
âˆ†
Also, âˆš12 âˆ’ 2ÏƒDP-OPT
âˆ’ Ç«ÏƒDP-OPT
in
Eq.
(25) equals âˆ’ a2 + Ç«,
âˆ†
2

2

âˆ†
âˆ†
1 Ç«ÏƒDP-OPT
since 21 âˆ’ 2ÏƒDP-OPT
= Ç«.
âˆ’
âˆ’ Ç«ÏƒDP-OPT
âˆ’
âˆ†
2
âˆ†
2ÏƒDP-OPT
Thus, Eq. (25) becomes
 âˆš 
 p

Î¦ âˆ’a 2 âˆ’ eÇ« Î¦ âˆ’ 2(a2 + Ç«) = Î´.
(27)
Given

 âˆš  1 1
Î¦ âˆ’a 2 = + erf (âˆ’a)
2 2
1 1
= âˆ’ erf (a)
2 2
1
= erfc (a)
2

(28)

and

 p

Î¦ âˆ’ 2(a2 + Ç«)
 p

1 1
= + erf âˆ’ a2 + Ç«
2 2
p

1 1
= âˆ’ erf
a2 + Ç«
2 2
p

1
a2 + Ç« .
= erfc
(29)
2
Then
we
write
(25)
as
âˆš
 Eq.
1
Ç« 1
2 + Ç« = Î´, so a is given by
a
erfc
(a)
âˆ’
e
Â·
erfc
2
2
Eq. (5).
Proving Theorem 2â€™s Property (ii):
For Ç« â‰¥ 0.01 and 0 < Î´ â‰¤ 0.05, we know
âˆš from Appendix D
to be presented soon that 1 âˆ’ eÇ«âˆšerfc ( Ç«) > 2Î´ and a >
(a+ aâˆš2 +Ç« )Â·âˆ†
, we clearly have
0. Using this in ÏƒDP-OPT :=
Ç« 2
âˆ†
âˆš
ÏƒDP-OPT > 2Ç« .
Proving Theorem 2â€™s Property (iii):
From Theorem 2â€™s
âˆš Property
 (ii) proved above, a > 0. Given
erfc (a) âˆ’ eÇ« erfc a2 + Ç« q
= 2Î´, we use erfc (a) > 2Î´ to

derive a < inverfc(2Î´) <

1
ln 2Î´
, where the last step uses

15

0 < Î´ â‰¤ 0.05 and Proposition 1 below. Then we have
âˆš

a + a2 + Ç« Â· âˆ†
âˆš
ÏƒDP-OPT : =
Ç« 2

p
âˆš 
a + (a + Ç«)2 Â· âˆ†
âˆš
<
Ç« 2
âˆš
(2a + Ç« ) Â· âˆ†
âˆš
=
Ç« 2
r
âˆ†
1 âˆ†
Â·
+âˆš
< 2 ln
2Î´ Ç«
2Ç«
q
Proposition 1. inverfc(x) < ln x1 for 0 < x < 1.

âˆš
âˆš
last step holds from erfc ( Ç«) < exp(âˆ’Ç«)
, which we obtain
Ï€Ç«
âˆš
by replacing x with Ç« in Reference [51]â€™s Inequality (4):
2
)
âˆš
erfc (x) < exp(âˆ’x
.
x Ï€
âˆš
âˆš
Proving Result ii): From erfc ( Ç«) < exp(âˆ’Ç«)
given above,
Ï€Ç«
âˆš
1
Ç«
âˆš
we have s(Ç«) = e erfc ( Ç«) < Ï€Ç« â†’ 0 as Ç« â†’ âˆ. Also,
s(0) = 1. Since we know from Result i) that s(Ç«) strictly
decreases as Ç« increases for Ç« > 0, the values that s(Ç«) for
Ç« âˆˆ (0, âˆ) can take constitutes the open interval (0, 1).
(30)


Proof
of Proposition 1. The desired result inverfc(x) <
q
ln x1 follows from Lemma 8 (i.e., inverfc(x) <
q
2
ln âˆš8x+1âˆ’1
for 0 < x < 1) and the obvious inequality
âˆš
8x + 1 âˆ’ 1 > 2x for 0 < x < 1.

Lemma
8. For 0 < y < 1, it holds that inverfc(y) <
q
2
âˆš
ln 8y+1âˆ’1 .

E. Proof of Theorem 3
We first present Lemma 10, which is proved in Appendix F
below.
Lemma 10 (Bounds of the optimal Gaussian noise amount
for (Ç«, Î´)-differential privacy). Given a fixed 0 < Î´ < 1, we
have:
ï£±
âˆ†
âˆ†
ï£²For Ç« > 0: ÏƒDP-OPT < 2âˆš2Â·inverfc(1âˆ’Î´) = 2âˆš2Â·inverf(Î´) ; (31a)


âˆš
inverfc(2Î´)+ [inverfc(2Î´)]2 +Ç« Â·âˆ†
ï£³
âˆš
For Ç« > 0: ÏƒDP-OPT <
. (31b)
Ç« 2

If 0 < Î´  < 0.5, with Ç«âˆ— denoting the solution to
âˆš
eÇ«âˆ— erfc Ç«âˆ— = 1 âˆ’ 2Î´, we have:

We defer the proof of Lemma 8 to the end (i.e., Ap-ï£±
âˆ†
q
;(32a)
ï£²For 0<Ç«â‰¤Ç«âˆ— : ÏƒDP-OPT > âˆš
2âˆ’2Î´ 2
pendix Q).
2{inverfc( 2âˆ’2Î´
eÇ« +1 )+ [inverfc( eÇ« +1 )] +Ç«}
âˆ†
ï£³For Ç« > Ç« : Ïƒ
(32b)
âˆ—
DP-OPT > âˆš2Ç« .
D. More discussions about Remark 4 of Page 5
If 0.5 â‰¤ Î´ < 1 (which does not hold in practice and is
âˆš

With r(u) := erfc (u) âˆ’ eÇ« erfc u2 + Ç« , the term a presented here only for completeness), with Ç«# denoting the
in Eq. (5) satisfies r(a) = 2Î´. We know that r(u) strictly solution to eÇ«# erfc âˆšÇ«#  = 1 âˆ’ Î´, we have:
decreases as u increases for u âˆˆ (âˆ’âˆ,
âˆš âˆ) in view of the ï£±
âˆ†
2
q
;(33a)
âˆš u +Ç« < 0. Moreover, ï£´
derivative râ€² (u) = âˆš2Ï€ exp(âˆ’u2 ) Â· uâˆ’
ï£²For Ç« > 0: ÏƒDP-OPT> âˆš2{inverfc( 2âˆ’2Î´
2âˆ’2Î´ 2
u2 +Ç«
âˆš
eÇ« +1 )+ [inverfc( eÇ« +1 )] +Ç«}
Ç«
we nowâˆšshow r(0) = 1 âˆ’ e erfc ( Ç«) > 0. With s(Ç«) :=
 âˆš . (33b)
ï£´For Ç« > Ç«# : ÏƒDP-OPT > 
âˆš âˆ†
eÇ« erfc ( Ç«), we know from Lemma 9 below that s(Ç«) strictly ï£³
inverf(Î´)+ [inverf(Î´)]2 +Ç« Â· 2
decreases as Ç« increases for Ç« > 0. The above analysis induces
We prove Lemma 10 in Appendix F. Below we use
r(0) = 1 âˆ’ s(Ç«) > 1 âˆ’ s(0) = 0.
Lemma
10 to show Theorem 3.
Summarizing the
=
2Î´,
âˆš above results, r(a)
Eq.
(31a)
is Result â‘  of Theorem 3. Eq. (31a) (32a)
Ç«
r(0) = 1 âˆ’ e erfc( Ç«) > 0, we define Ç«âˆ— as the solution to
âˆš
and
(33a)
imply
Result â‘¡ of Theorem 3. If 0 < Î´ < 0.5,
Ç«âˆ—
1 âˆ’ e erfc Ç«âˆ— = 2Î´ (Ç«âˆ— exists for 0 < Î´ < 0.5 from
Eq.
(31b)
and
(32b)
imply Result â‘¢ of Theorem 3. If 0.5 â‰¤
Lemma 9 below), and have the following results for a in
Î´
<
1,
Eq.
(31b)
and
(33b) imply Result â‘¢ of Theorem 3.
Eq. (5), where â€œiffâ€ is short for â€œif and only ifâ€:
âˆš
To
prove
Result
â‘£ of
Theorem
3
(i.e.,
q
.
1) a > 0 iff 1âˆ’eÇ« erfc (âˆšÇ«) > 2Î´ (i.e., iff Ç« > Ç«âˆ— when Ç«âˆ— exists);
âˆ†
1
=
1),
below
we
use
the
lim
Ïƒ
2
ln
Î´â†’0 DP-OPT
Ç«
Î´
2) a = 0 iff 1âˆ’eÇ« erfc (âˆšÇ«) = 2Î´ (i.e., iff Ç« = Ç«âˆ— when Ç«âˆ— exists);
Ç«
3) a < 0 iff 1âˆ’e erfc ( Ç«) < 2Î´ (i.e., iff Ç« < Ç«âˆ— when Ç«âˆ— exists). sandwich method. Specifically, we find an upper bound and a
lowerq
bound for ÏƒDP-OPT , and show that dividing each bound
In most real-world applications with Ç«âˆšâ‰¥ 0.01 and Î´ â‰¤ 0.05,
âˆ†
Ç«
by
2 ln Î´1 converges to 1 as Î´ â†’ 0.
case 1) above holds since 1 âˆ’ e erfc ( Ç«) = 1 âˆ’ s(Ç«) â‰¥ 1 âˆ’
Ç«
For the upper bound part, given a fixed Ç« > 0, we use
s(0.01) > 0.1 â‰¥ 2Î´, where we use the above result that s(Ç«)
Theorem 2â€™s Property (iii) to derive
strictly decreases as Ç« increases.
!
r

1
âˆ†
Lemma 9. The following results hold.
2 ln
ÏƒDP-OPT
âˆš
Ç«
Î´
i) With s(Ç«) := eÇ« erfc ( Ç«), s(Ç«) strictly decreases as Ç«
!
!
r
r
increases for Ç« > 0.
âˆ†
âˆ†
1 âˆ†
1
Â·
+âˆš
2 ln
2 ln
<
ii) The values that s(Ç«) for Ç« âˆˆ (0, âˆ) can take constitutes
2Î´ Ç«
Ç«
Î´
2Ç«
the open interval (0, 1).
â†’ 1, as Î´ â†’ 0.
(34)
Proof of Lemma 9:
Proving Result i): We obtain the desired
The proof for the lower bound part is more complex and is
âˆš result in view of
the derivative sâ€² (Ç«) := âˆ’ âˆš1Ï€Ç« + eÇ« erfc ( Ç«) < 0, where the presented below.

16

âˆš

We define f (x) = ex erfc a2 + x . Then we have the
first-order derivative f â€² (x) and second-order derivative f â€²â€² (x)
as follows:
p

exp(âˆ’a2 )
f â€² (x) = ex erfc
a2 + x âˆ’ p
Ï€(a2 + x)

This further induces
exp(âˆ’A2 )
âˆš
4A Â· (A2 + 1)(A2 + 2) Ï€
2Î´
Â·
â‰¤
Ç« Â· exp(Ç«)
2A2 + 3
âˆš
2Î´
â‰¤
Â· 4A Â· (0.5A2 + 0.75) Ï€,
Ç« Â· exp(Ç«)

and

 exp(âˆ’a2 )
p
exp(âˆ’a2 )
+ âˆš
. where the last step uses
a2 + x âˆ’ p
Ï€(a2 + x) 2 Ï€(a2 + x)3/2
(A2 + 1)(A2 + 2) âˆ’ (2A2 + 3)(0.5A2 + 0.75)
We have the following two propositions. After stating their
= âˆ’0.25 < 0.
proofs, we continue proving Theorem 2.
Then

(40)

f â€²â€² (x) = ex erfc

Proposition 2. f â€² (x) < 0 for x â‰¥ 0.
Proposition 3. f â€²â€² (x) > 0 for x â‰¥ 0.
Proof of Proposition 2: From Proposition 3, we have
f â€² (x) â‰¤ f â€² (0) for x â‰¥ 0, which along with
2
)
âˆš
f â€² (0) = erfc (|a|) âˆ’ exp(âˆ’a
< 0 from Reference [52]â€™s In|a| Ï€
â€²
equality (4) implies f (x) < 0 for x â‰¥ 0.
Proof
of âˆš Proposition
3:
We
can
write
f â€²â€² (x) = ex u( a2 + x) for function u(y) defined by
2
)
âˆš
(1 âˆ’ 2y12 ). We have u(y) > 0
u(y) := erfc (y) âˆ’ exp(âˆ’y
y Ï€
from the asymptotic expansion (i.e., Inequality 7.12.1 in [52])
of the complementary error function erfc (Â·). Hence, the
desired result is proved.
Now we continue the proof of Theorem 2.
Propositions 2 and 3 induce f â€² (x) â‰¤ R f â€² (Ç«) < 0 for
Ç«
x Râ‰¥ 0. Then we have f (0) âˆ’ f (Ç«) = âˆ’ x=0 f â€² (x) dx â‰¥
Ç«
âˆ’ x=0 f â€² (Ç«) dx = âˆ’f â€² (Ç«)Ç«, which implies
p
 2Î´
exp(âˆ’a2 )
âˆ’f â€² (Ç«) = p
âˆ’ eÇ« erfc
a2 + Ç« â‰¤ . (35)
Ç«
Ï€(a2 + Ç«)

For notation convenience, we define
p
A := a2 + Ç«.

(36)

Then

2Î´
exp(âˆ’A2 )
âˆš
âˆ’ erfc (A) â‰¤
.
A Ï€
Ç« Â· exp(Ç«)

(37)

From the inverse factorial series of the complementary error
function erfc (Â·) [52], it holds that
erfc (A)


1
exp(âˆ’A2 )
1
âˆš
1âˆ’
â‰¤
+
A Ï€
2(A2 + 1) 4(A2 + 1)(A2 + 2)


2
2A2 + 3
exp(âˆ’A )
âˆš
1âˆ’
,
(38)
=
A Ï€
4(A2 + 1)(A2 + 2)
which we use in the above Inequality (37) to obtain
exp(âˆ’A2 )
2A2 + 3
2Î´
âˆš
Â·
â‰¤
.
A Ï€
4(A2 + 1)(A2 + 2)
Ç« Â· exp(Ç«)

(39)

exp(âˆ’A2 )
âˆš
2Î´
â‰¤
Â· 4A Â· (0.5A2 + 0.75) Ï€
Ç« Â· exp(Ç«)
r
r
iâˆš
1h 
1 2
2Î´
ln
â‰¤
+ 0.75 Ï€.
Â· 4 ln 0.5
Ç« Â· exp(Ç«)
Î´
Î´

(41)

(42)

We consider 0 < Î´ â‰¤ 0.005. We can assume Î´ â‰¤ eâˆ’1.5 . For
such Î´ â‰¤ eâˆ’1.5 , it holds that
r 1 2
r 1 2
ln
ln
0.5
+ 0.75 â‰¤
,
(43)
Î´
Î´
which we use in Inequality (42) to derive
r 1 3 âˆš Ï€
2
ln
exp(âˆ’A ) â‰¤ 8Î´
.
(44)
Î´ Ç« Â· exp(Ç«)
3 âˆš
q
ln 1Î´
Ï€/Ç« â‰¤ 1, which clearly
Then for Î´ â‰¤ eâˆ’1.5 and 8Î´
holds given a fixed Ç« > 0 and Î´ â†’ 0, we have
v
u
Ç« Â· exp(Ç«)
Aâ‰¥u
3 âˆš
tln q
8Î´
ln 1Î´
Ï€
s
1
Ç«
1
3
= Ç« + ln + ln âˆš âˆ’ ln ln .
(45)
Î´
2
Î´
8 Ï€
For q
Ç« â‰¥ 1 and
0 < Î´ â‰¤ 0.005, we can verify that â€¢ Î´ â‰¤ eâˆ’1.5 ,
3 âˆš
ln 1Î´
Ï€/Ç« â‰¤ 1, and ln 8âˆšÇ« Ï€ âˆ’ 32 ln ln Î´1 â‰¥ ln 8âˆš1 Ï€ âˆ’
â€¢ 8Î´
3
1
2 ln ln 0.005 > 0.0057. Hence,
s
r
1
0.0057
Ç«
3
1
A â‰¥ ln + ln âˆš âˆ’ ln ln > ln
, (46)
Î´
8 Ï€
2
Î´
Î´
which implies
ÏƒDP-OPT

âˆš


a2 + Ç« Â· âˆ†
âˆš
=
Ç« 2
âˆš

2
A âˆ’Ç« + A Â·âˆ†
âˆš
=
Ç« 2
!
r
r
1
1
âˆ†
ln + ln 0.0057 âˆ’ Ç« + ln + ln 0.0057 .
> âˆš
Î´
Î´
Ç« 2
(47)
q
2 ln 1Î´
Clearly, dividing the above lower bound of (47) by âˆ†
Ç«
a+

17

converges to 1 as Î´ â†’ 0. Combining this with (34), we
complete proving Result â‘£ of Theorem 3.

F. Proof of Lemma 10

Proof of Lemma 10â€™s Eq. (33a) for 0.5 â‰¤ Î´ < 1 and Ç« > 0:
The proof is similar to that for Eq. (32a) above. First, with
0.5 â‰¤ Î´ < 1 and Ç« > 0, from Appendix D, a in Eq. (5) is
negative. Then similar to the proof of Eq. (50), we have


2 âˆ’ 2Î´
< a < 0.
(52)
âˆ’ inverfc
eÇ« + 1

Proof of Lemma 10â€™s Eq. (31a) for Ç« > 0:
We write ÏƒDP-OPT of Theorem 2 as a function ÏƒDP-OPT (Ç«, Î´).
Given a fixed 0 < Î´ < 0.5, clearly ÏƒDP-OPT (Ç«, Î´) strictly Then we also obtain Eq. (33a) in a way similar to the proof
decreases as Ç« increases, which implies for Ç« > 0 that of Eq. (51).
ÏƒDP-OPT (Ç«, Î´) is less than limÇ«â†’0 ÏƒDP-OPT (Ç«, Î´) (if such limit Proof of Lemma 10â€™s Eq. (33b) for 0.5 â‰¤ Î´ < 1 and Ç« > Ç« :
#
âˆš
exists). When Ç« â†’ 0, a in Eq. (5) is negative and satisfies
Since eÇ« erfc ( Ç«) strictly decreases as Ç« increases
erfc (a) âˆ’ erfc (âˆ’a) â†’ 2Î´ so that a â†’ âˆ’ inverfc(1 âˆ’ Î´) due to
from Lemma 9 on
Page 15, for Ç«# denoting the solution
âˆš 
erfc (âˆ’a) = 2 âˆ’ erfc (a). This further implies for Ç« â†’ 0 that
Ç«#
Ç«
to
e
erfc
=
1 âˆ’ Î´,
we have for Ç« > Ç«# that
#
âˆš

âˆš
âˆš 
eÇ« erfc ( Ç«) < eÇ«# erfc Ç«# = 1 âˆ’ Î´, which gives a lower
a + a2 + Ç« Â· âˆ†
âˆš
ÏƒDP-OPT (Ç«, Î´) =
bound on a of Eq. (5):
Ç« 2
âˆ†
âˆš
 âˆš
=
âˆš 
âˆ’a + a2 + Ç« Â· 2
a > inverfc 2Î´ + eÇ« erfc Ç«
âˆ†
> inverfc(1 + Î´)
â†’ âˆš
.
(48)
2 2 Â· inverfc(1 âˆ’ Î´)
= âˆ’ inverf(Î´).
(53)
Hence, for Ç« > 0, we have
Then
ÏƒDP-OPT (Ç«, Î´) < lim ÏƒDP-OPT (Ç«, Î´)
ÏƒDP-OPT (Ç«, Î´)
Ç«â†’0
âˆš

âˆ†
a + a2 + Ç« Â· âˆ†
= âˆš
âˆš
=
2 2 Â· inverfc(1 âˆ’ Î´)
Ç« 2
âˆ†
âˆ†
.
(49)
= âˆš
âˆš
=
 âˆš
2 2 Â· inverf(Î´)
âˆ’a + a2 + Ç« Â· 2
Proof of Lemma 10â€™s Eq. (31b) for Ç« > 0: Eq. (31b) follows
âˆ†
 âˆš .
(54)
> 
p
from Eq. (5) and Lemma 11 presented at the end of this
inverf(Î´) + [inverf(Î´)]2 + Ç« Â· 2
subsection.
Proof of Lemma 10â€™s Eq. (32a) for 0 < Î´ < 0.5 and 0 <

Ç« â‰¤ Ç«âˆ— :
We consider 0 < Î´ < 0.5 and 0 < Ç« â‰¤ Ç«âˆ— here. In this case, Lemma 11. a in Eq. (5) is less than inverfc(2Î´).
from Appendix
result follows since Eq. (5) induces
âˆš D, a in Eq. (5) is negative or zero. Then we Proof of Lemma 11: The
erfc (|a|) = erfc (âˆ’a), which along erfc (a) = 2Î´ +eÇ« erfc âˆša2 + Ç« > 2Î´ and erfc (Â·) is a strictly
have erfc a2 + Ç« < âˆš
with erfc (a) âˆ’ eÇ« erfc a2 + Ç« = 2Î´ and erfc (a) = 2 âˆ’ decreasing function.
erfc (âˆ’a) implies 2 âˆ’ erfc (âˆ’a) âˆ’ eÇ« erfc (âˆ’a) < 2Î´. Then we
have erfc (âˆ’a) > 2âˆ’2Î´
eÇ« +1 , which along with the aforementioned
result a â‰¤ 0 implies
G. Establishing Lemma 1, which along with Theorem 2 im

plies Theorem 4
2 âˆ’ 2Î´
âˆ’ inverfc
< a â‰¤ 0.
(50)
âˆš
eÇ« + 1
When eÇ« erfc ( Ç«) + 2Î´ â‰¥ 2, we have b = 0 from Eq. (7a)
on Page 6 and a â‰¤ 0 from Appendix D on Page 15, so the
Thus,
desired âˆš
result a â‰¤ b follows. Below we focus on the case of
ÏƒDP-OPT (Ç«, Î´)
Ç«
Ç«) + 2Î´ < 2.
e
erfc
(
âˆš

a + a2 + Ç« Â· âˆ†
We use Theorem 2 to prove Theorem 4. In particular, we
âˆš
=
will show that a specified in Eq. (5) is less than b defined
Ç« 2
in Eq. (7a).
âˆ†
âˆš
=
 âˆš
Recall that Eq. (5) presents
âˆ’a + a2 + Ç« Â· 2

p
âˆ†
a2 + Ç« = 2Î´.
(55)
erfc (a) âˆ’ eÇ« erfc
q
>âˆš
. (51)
2âˆ’2Î´ 2
2 Â· {inverfc( 2âˆ’2Î´
[inverfc(
)
+
)]
+
Ç«}
Ç«
Ç«
e +1
e +1
We will find an upper bound for a and this upper bound will be
Proof of Lemma 10â€™s Eq. (32b) for 0 < Î´ < 0.5 and Ç« > Ç«âˆ— : b. To this
âˆš end, we will show erfc (a) is at least some fraction of
by i) proving a lower bound
We consider 0 < Î´ < 0.5 and Ç« > Ç«âˆ— here. In this case, from erfc a2 + Ç« . This will be done
âˆš
erfc( u2 +Ç«)
Appendix
D,
a
in
Eq.
(5)
is
positive.
Then
Ïƒ
(Ç«,
Î´)
=
DP-OPT
for a, and ii) showing that
strictly increases as u
âˆš
âˆš
erfc(u)
(a+ aâˆš2 +Ç« )Â·âˆ†
Ç«Â·âˆ†
âˆšâˆ† .
âˆš
increases
for
u
âˆˆ
(âˆ’âˆ,
âˆ).
>
=
Ç« 2
Ç« 2
2Ç«

18

We first give a lower âˆš
bound for
 a. From Eq. (55),
âˆš we have
erfc (a) = 2Î´ + eÇ« erfc a2âˆš+ Ç« < 2Î´ + eÇ« erfc ( Ç«), which
implies that if 2Î´ + eÇ« erfc ( Ç«) < 2,
âˆš 
(56)
a > inverfc 2Î´ + eÇ« erfc Ç« ,

where we note that the image domain of erfc (Â·) is (0, 2) since
the image domain of erf (Â·) is (âˆ’1, 1) and erfc (Â·) = 1âˆ’erf (Â·).

H. Establishing Lemma 2, which along with Theorem 4 implies Theorem 5
From Eq. (61), it holds that erfc (b) > 2Î´, which implies
b < inverfc(2Î´). For 0 < Î´ < 0.5, we replace y in
Lemma
q 8 on Page 15 with 2Î´ to obtain inverfc(2Î´) < c for
2
. Then we have b < c. Thus, Theorem 4
c := ln âˆš16Î´+1âˆ’1
implies Theorem 5.


âˆš

erfc( u2 +Ç«)
We now prove h(u) :=
strictly increases as u
erfc(u)
increases for u âˆˆ (âˆ’âˆ, âˆ). Taking the derivative of h(u) I. Proof of Lemma 3
with respect to u, we obtain
The sktech of the following proof is given in [2]. We present
âˆš
âˆš


â€²
2 + Ç« Ã— erfc (u) âˆ’ erfc
2 + Ç« Ã— erfcâ€² (u)the full details for completeness.
u
u
erfc
hâ€² (u) =
Recall that a mechanism Y achieves (Ç«, Î´)-differential prierfc2 (u)
vacy
if
2
Îº(u)
,
(57)
= âˆš Ã— exp(âˆ’u2 ) Ã—
Ï€
P [Y (x) âˆˆ Y] â‰¤ eÇ« P [Y (xâ€² ) âˆˆ Y] + Î´,
erfc2 (u)

for any output set Y, neighboring datasets x and xâ€² , (62)

for Îº(u) defined by


p
u
the coin flips of the
Îº(u) := âˆ’ exp (âˆ’Ç«) Ã— âˆš
u2 + Ç« . where the probability space is over
Ã— erfc (u) + erfc
u2 + Ç«
randomized mechanism Y , D and Dâ€² iterate through all pairs
(58) of neighboring datasets, and Y iterates through all subsets of
the output range.
To achieve (Ç«, Î´)-differential privacy, we first show that it
We will prove Îº(u) > 0. To this end, we first investigate the
suffices to ensure
monotonicity of Îº(u) for u âˆˆ (âˆ’âˆ, âˆ). Taking the derivative


F [Y (x) = y]
Ç«
of Îº(u) with respect to u, we get
P
â‰¤ e â‰¥ 1 âˆ’ Î´,
F [Y (xâ€² ) = y]

2
u
Ã— âˆš exp âˆ’u2
Îºâ€² (u) = exp (âˆ’Ç«) Ã— âˆš
for any output y, neighboring datasets x and xâ€² ,
(63)
Ï€
u2 + Ç«
âˆš
2
where the probability space is over the coin flips of the
u2 + Ç« âˆ’ âˆšuu2 +Ç«
Ã—
erfc
(u)
âˆ’ exp (âˆ’Ç«) Ã—
randomized mechanism Y , D and Dâ€² iterate through all pairs
u2 + Ç«
of neighboring datasets, and y iterates through the output range

2
u
âˆ’ âˆš exp âˆ’u2 âˆ’ Ç« Ã— âˆš
O. Specifically, we will prove that Eq. (63) implies Eq. (62).
Ï€
u2 + Ç«
We define set S by
Ç«


= âˆ’ exp (âˆ’Ç«) Ã— 2
Ã— erfc (u)
3/2
F [Y (x) = y]
(u + Ç«)
Ç«
(64)
â‰¤e .
S := y
F [Y (xâ€² ) = y]
< 0.
(59)
Hence, Îº(u) strictly decreases as u increases for u âˆˆ
Îº(u)
:= 1 âˆ’
(âˆ’âˆ, âˆ). Combining this and limuâ†’âˆ erfc(u)

Îº(u)
>0
exp (âˆ’Ç«) > 0, we conclude for u âˆˆ (âˆ’âˆ, âˆ) that erfc(u)
and hence Îº(u) > 0. Thus, hâ€² (u) in Eq. (57) is positive, so that
h(u) is increasing for u âˆˆ (âˆ’âˆ, âˆ). This along with Eq. (56)
implies
âˆš  
h(a) â‰¥ h inverfc 2Î´ + eÇ« erfc Ç«
.
(60)

From Eq. (55) and (60), and h(a) :=
erfc (a) =

âˆš
erfc( a2 +Ç«)
,
erfc(a)

we derive

2Î´
1 âˆ’ eÇ« Â· h(a)

2Î´
âˆš 
1 âˆ’ Â· h inverfc 2Î´ + eÇ« erfc ( Ç«)
= erfc (b) ,
(61)

â‰¥

eÇ«

where the last step uses the expression of b in Eq. (7a). Hence,
it holds that a â‰¤ b. Then we obtain the desired result of
Theorem 2 implying Theorem 4.


Then if Eq. (63) holds, we have
P [Y (x) âˆˆ S] â‰¥ 1 âˆ’ Î´.

(65)

With O being the output range, O \ S is the complement set
of S. Then Eq. (65) implies
P [Y (x) âˆˆ O \ S] = 1 âˆ’ P [Y (x) âˆˆ S] â‰¤ Î´.

(66)

To show that Eq. (63) implies Eq. (62), we have
P [Y (x) âˆˆ Y]

= P [Y (x) âˆˆ Y âˆ© S] + P [Y (x) âˆˆ Y \ S]
Z
=
F [Y (x) = y] dy + P [Y (x) âˆˆ Y \ S]
yâˆˆYâˆ©S
Z
(*)
â‰¤
eÇ« F [Y (xâ€² ) = y] dy + P [Y (x) âˆˆ O \ S]
yâˆˆYâˆ©S

(#)

â‰¤ eÇ« P [Y (xâ€² ) âˆˆ Y âˆ© S] + Î´
â‰¤ eÇ« F [Y (xâ€² ) âˆˆ Y] + Î´,

(67)

where the above step (*) uses Eq. (64) and Y \ S âŠ† O \ S,
and step (#) uses Eq. (66).


19

J. Proof of Lemma 4
For neighboring datasets D and Dâ€² , the privacy loss
K. Proof of Theorem 6
LY,D,Dâ€² (y) represents the multiplicative difference between
For the proposed Gaussian mechanism, we now prove
the probabilities that the same output y is observed when the


randomized algorithm Y is applied to D and Dâ€² , respectively.
F [Y (D) = y]
Ç«
âˆ’Ç«
â‰¥ 1 âˆ’ Î´,
â‰¤
e
P
e
â‰¤
yâˆ¼Y (D)
Specifically, we define
F [Y (Dâ€² ) = y]
LY,D,Dâ€² (y) := ln

F [Y (D) = y]
,
F [Y (Dâ€² ) = y]

(68)

where F [Â·] denotes the probability density function.
For simplicity, we use probability density function F [Â·] in
Eq. (11) above by assuming that the randomized algorithm Y
has continuous output. If Y has discrete output, we replace
F [Â·] by probability notation P [Â·].
When y follows the probability distribution of random
variable Y (D), LY,D,Dâ€² (y) follows the probability distribution
of random variable LY,D,Dâ€² (Y (D)).
We have Lemmas 12 and 13 below, which will be proved
soon.
Lemma 12. Given datasets D, Dâ€² , and an (Ç«, Î´)-differentially
private randomized algorithm Y , for any real number t, it
holds that
Î´
P [LY,D,Dâ€² (Y (D)) â‰¥ t] â‰¤
.
(69)
1 âˆ’ eÇ«âˆ’t
Lemma 13. The relationships between privacy loss random
variables LY,D,Dâ€² (Y (D)) and LY,Dâ€² ,D (Y (Dâ€² )) are as follows.
Given datasets D, Dâ€² , and a randomized algorithm Y , for any
real number t, it holds that
âˆ’t

â€²

P [LY,D,Dâ€² (Y (D)) â‰¤ âˆ’t] â‰¤ e P [LY,Dâ€² ,D (Y (D )) â‰¥ t] .
(70)
Proof of Lemma 4: The result follows from Lemmas 12
and 13.

Proof of Lemma 12: Since LY,D,Dâ€² (Y (Â·)) can be seen as postprocessing on Y (Â·) and hence also satisfies (Ç«, Î´)-differential
privacy, we have
P [LY,D,Dâ€² (Y (D)) â‰¥ t]
â‰¤ Î´ + eÇ« P [LY,D,Dâ€² (Y (Dâ€² )) â‰¥ t]
Z
Ç«
=Î´+e
F [Y (Dâ€² ) = y] P [LY,D,Dâ€² (y) â‰¥ t] dy
Y


Z
F [Y (D) = y]
= Î´ + eÇ«
F [Y (Dâ€² ) = y] P
dy
â‰¥ et F [Y (Dâ€² ) = y]
Y


Z
F [Y (D) = y]
â‰¤ Î´ + eÇ«
eâˆ’t F [Y (D) = y] P
dy
â‰¥ et F [Y (Dâ€² ) = y]
Y
= Î´ + eÇ«âˆ’t P [LY,D,Dâ€² (Y (D)) â‰¥ t]

(71)


Proof of Lemma 13: We have
P [LY,D,Dâ€² (Y (D)) â‰¤ âˆ’t]


Z
F [Y (D) = y]
=
F [Y (D) = y] P
dy
â‰¤ eâˆ’t F [Y (Dâ€² ) = y]


ZY
F [Y (Dâ€² ) = y]
eâˆ’t F [Y (Dâ€² ) = y] P
â‰¤
dy
â‰¥ et F [Y (D) = y]
Y
= eâˆ’t P [LY,Dâ€² ,D (Y (Dâ€² )) â‰¥ t] .



for any output y, neighboring datasets D and Dâ€² .

(72)

The desired result Eq. (72) can also be written as


F [Y (D) = y]
â‰¤
Ç«
â‰¥ 1 âˆ’ Î´,
Pyâˆ¼Y (D) ln
F [Y (Dâ€² ) = y]
for any output y, neighboring datasets D and Dâ€² .

(73)

With (Ç«, Î´)-differential privacy being translated to Eq. (73), we
will show that the minimal noise amount can be derived, while
the classic mechanism by Dwork and Roth [2] presents only
a loose bound.
Let the output of the query Q on the dataset D be an mdimensional vector. We define notation r1 , . . . , rm such that
y âˆ’ Q(D) = [r1 , . . . , rm ].

(74)

Since Y (D) is the result of adding a zero-mean Gaussian
noise with standard deviation Ïƒ to Q(D), we have

m 
Y
rj 2
1
âˆš
eâˆ’ 2Ïƒ2 .
(75)
F [Y (D) = y] =
2Ï€Ïƒ 2
j=1
We introduce notation s1 , . . . , sm such that

Q(D) âˆ’ Q(Dâ€² ) = [s1 , . . . , sm ].

(76)

From Eq. (74) and (76), it holds that
y âˆ’ Q(Dâ€² ) = [r1 + s1 , . . . , rm + sm ].

(77)

Since Y (Dâ€² ) is the result of adding a zero-mean Gaussian
noise with standard deviation Ïƒ to Q(Dâ€² ), we have

m 
Y
(rj +sj )2
1
âˆš
F [Y (Dâ€² ) = y] =
eâˆ’ 2Ïƒ2
.
(78)
2Ï€Ïƒ 2
j=1
The combination of Eq. (75) and (78) induces


rj 2
Qm
âˆ’ 2Ïƒ
2
âˆš 1
e
j=1
2Ï€Ïƒ2
F [Y (D) = y]


= ln
ln
â€²
(r +s )2
Qm
F [Y (D ) = y]
âˆ’ j2Ïƒ2j
âˆš 1
e
j=1
2Ï€Ïƒ2


m
X
(rj + sj )2
rj 2
=
âˆ’ 2
2Ïƒ 2
2Ïƒ
j=1
Pm
Pm
2
j=1 sj
j=1 (sj rj )
+
.
(79)
=
Ïƒ2
2Ïƒ 2
We define
v
uX
um
S := t
sj 2 ,
(80)
j=1

and

G :=

Pm

j=1 (sj rj )

S

.

(81)

20

From Eq. (76), S is the â„“2 distance between Q(D) and Q(Dâ€² );
i.e.,
S := kQ(D) âˆ’ Q(Dâ€² )k2 .

(82)

Note that rj for each j âˆˆ {1, 2, . . . , m} defined in Eq. (74) is a
zero-mean Gaussian random variable with standard deviation
Ïƒ. In addition, r1 , . . . , rm are independent. Hence,
Pm
j=1 (sj rj )
is a zero-mean Gaussian
G defined as
S
Pm
2 2
j=1 (sj Ïƒ )
random variable with variance
= Ïƒ 2 , (83)
S2
where the last step uses Eq. (80). For notational simplicity, we
write G âˆ¼ Gaussian(0, Ïƒ 2 ).
From Eq. (80) and (81), it follows that
ln
Hence, we have

F [Y (D) = y]
S2
GS
= 2 + 2.
â€²
F [Y (D ) = y]
Ïƒ
2Ïƒ


F [Y (D) = y]
â‰¤Ç«
Pyâˆ¼Y (D) ln
F [Y (Dâ€² ) = y]


GS
S2
= PGâˆ¼Gaussian(0,Ïƒ2 )
+ 2 â‰¤Ç« .
Ïƒ2
2Ïƒ

Defining d as
result.

Ç«Ïƒ2
âˆ’âˆ†
âˆ†âˆš
2

Ïƒ 2

and solving Ïƒ, we obtain the desired


L. Proof of Theorem 7
â‘  Given a fixed 0 < Î´ < 1, we.
have
 limÇ«â†’0 d= inverfc(Î´),
inverfc(Î´)Â·âˆ†
âˆš
which results in limÇ«â†’0 ÏƒpDP-OPT
= 1.
Ç« 2
â‘¡ Given a fixed 0 < Î´ <
. 1,
 we have limÇ«â†’âˆ d = 0, which
âˆšâˆ†
= 1.
leads to limÇ«â†’âˆ ÏƒpDP-OPT
2Ç«
â‘¢ Given a fixed q
Ç« > 0, we use Lemma 5
to
derive
limÎ´â†’0 d ln 1Î´
=
1
and
thus
. q

âˆ†
1
limÎ´â†’0 ÏƒpDP-OPT

2 ln Î´ = 1.
Ç«

(84)

M. Establishing Lemma 5, which along with Theorem 6 implies Theorem 8
From
âˆš the definition of d in Eq. (13a): erfc (d) +
erfc d2 + Ç« = 2Î´, we clearly have Î´ < erfc (d) < 2Î´,
which implies inverfc(2Î´) < d < inverfc(Î´).


(85)

N. Proving Lemma 6, which along with Theorem 8 implies
Theorem 9



If S > 0, given the result Eq. (81) that G is a zero-mean
Gaussian random variable with standard deviation Ïƒ, we obtain


S2
GS
â‰¤
Ç«
+
PGâˆ¼Gaussian(0,Ïƒ2 )
Ïƒ2
2Ïƒ 2


2
S
Ç«Ïƒ 2
S
Ç«Ïƒ
âˆ’ â‰¤Gâ‰¤
âˆ’
=P âˆ’
S
2
S
2
!#
"
"
!#
2
Ç«Ïƒ2
S
âˆ’ Ç«ÏƒS âˆ’ S2
1
1
S âˆ’ 2
âˆš
âˆš
âˆ’
1 + erf
1 + erf
=
2
2
Ïƒ 2
Ïƒ 2
!
!
S
S
Ç«Ïƒ2
Ç«Ïƒ2
âˆ’
+
1
1
S
S
âˆš 2 + erf
âˆš 2
= erf
2
2
Ïƒ 2
Ïƒ 2
= fÇ«, Ïƒ (S),

We can prove that fÇ«, Ïƒ (S) is a decreasing function of S.
Hence, the optimal Gaussian mechanism to achieve (Ç«, Î´)probabilistic differential privacy satisfies fÇ«, Ïƒ (âˆ†) = 1 âˆ’ Î´.

(86)

q
2
>
To show Lemma 6, it suffices to prove ln âˆš8Î´+1âˆ’1
inverfc(Î´) for 0 < Î´ < 1. This clearly follows from Lemma 8
proved in Appendix Q by replacing y with Î´.
O. Algorithm 1 to compute ÏƒDP-OPT of Theorem 2
As discussed at the end of Section V, the noise amounts of
our mechanisms can be set as initial values to quickly search
for the optimal value ÏƒDP-OPT . In particular, Algorithm 1 to
compute ÏƒDP-OPT will use Lemma 14 below.

Lemma 14. We have the following bounds for a in Eq. (5) of
Theorem 2:
for fÇ«, Ïƒ (S) defined by
ï£±
0 < a < b of Eq. (7a)
"
!
!#
ï£´
ï£´
âˆš
Ç«Ïƒ2
Ç«Ïƒ2
S
S
ï£´
ï£´
âˆ’
+
1
< c of Eq. (9),
if 1âˆ’eÇ« erfc ( Ç«)>2Î´; (90a)
S
S
âˆš 2 + erf
âˆš 2
fÇ«, Ïƒ (S) :=
erf
, (87) ï£²
âˆš
2
Ïƒ 2
Ïƒ 2
a=0,
if 1âˆ’eÇ« erfc ( Ç«)=2Î´;(90b)
ï£´
ï£´


ï£´
âˆš
ï£³âˆ’ inverfc 2âˆ’2Î´
where Eq. (86) uses the cumulative distribution function of a ï£´
if 1âˆ’eÇ« erfc ( Ç«)<2Î´. (90c)
eÇ« +1 <a<0,
zero-mean Gaussian random variable G as well as the fact that
Proof of Lemma 14: First, (90a) follows from Lemmas 1
erf(Â·) is an odd function; i.e., erf(âˆ’x) = âˆ’ erf(x).
and 2. Second, (90b) holds from Eq. (5) and Remark 4. Next,
If S = 0, it is clear that
we prove Eq. (90c) as follows.


GS
S2
From Lemma 9 on Page 15, we have
PGâˆ¼Gaussian(0,Ïƒ2 )
â‰¤ Ç« = 1.
(88)
+
ï£± If 0.5 â‰¤ Î´ < 1,
Ïƒ2
2Ïƒ 2
ï£´
ï£´
ï£´
The â„“2 -sensitivity âˆ† of the query Q is the maximal ï£´
ï£´
ï£´ then any Ç« >âˆš0 satisfies
ï£´
â„“2 distance between the (true) query outputs for any two ï£´
ï£² 1 âˆ’ eÇ« erfc Ç« < 2Î´.
neighboring datasets D and Dâ€² that differ in one record:
If 0 < Î´ < 0.5, then 0 < Ç« < Ç«âˆ— satisfies
ï£´
âˆ† = maxneighboring D, Dâ€² kQ(D) âˆ’ Q(Dâ€² )k2 . From Eq. (82), ï£´
ï£´
ï£´
âˆš 
ï£´
we have 0 â‰¤ S â‰¤ âˆ†. Then summarizing Eq. (86) and (88), to ï£´
1 âˆ’ eÇ« erfc Ç« < 2Î´,
ï£´
ï£´
ï£³
âˆš
guarantee Eq. (73), it suffices to ensure
where Ç«âˆ— denotes the solution to eÇ«âˆ— erfc ( Ç«âˆ— ) = 1 âˆ’ 2Î´.
fÇ«, Ïƒ (S) â‰¥ 1 âˆ’ Î´, for 0 < S â‰¤ âˆ†.
(89) Then we use Eq. (50) and (52) to obtain (90c).


21

Algorithm 1 Computing ÏƒDP-OPT of Theorem 2 based on
Lemma 14.
âˆš
1: diff â† 1 âˆ’ eÇ« erfc ( Ç«) âˆ’ 2Î´;
2: if diff = 0 then
3:
a â† 0;
4: else if diff > 0 then
5:
N â† 1;
6:
lower â† 0;
7:
upper â† any one of the following:
b of Eq. (7a) in our Theorem 4 for Mechanism 1,
c of Eq. (9) in our Theorem 5 for Mechanism 2;
8:
while N â‰¤ the allowed maximum number of iterations
do
9:
if upper âˆ’ lower < tolerance then
10:
a â† upper;
11:
break
12:
end if
13:
mid â† (lower + upper)/2;

p
mid2 + Ç« = 2Î´ then
14:
if erfc (mid) âˆ’ eÇ« erfc
15:
a â† mid;
16:
break
p

17:
else if erfc (mid) âˆ’ eÇ« erfc
mid2 + Ç« > 2Î´ then
18:
lower â† mid;
19:
else
20:
upper â† mid;
21:
end if
22:
N â† N + 1;
23:
end while
24: else
25:
N â† 1;


26:
lower â† âˆ’ inverfc 2âˆ’2Î´
eÇ« +1 ;
27:
upper â† 0;
28:
while N â‰¤ the allowed maximum number of iterations
do
29:
if upper âˆ’ lower < tolerance then
30:
a â† upper;
31:
break
32:
end if
33:
mid â† (lower + upper)/2;
p

34:
if erfc (mid) âˆ’ eÇ« erfc
mid2 + Ç« = 2Î´ then
35:
a â† mid;
36:
break
p

37:
else if erfc (mid) âˆ’ eÇ« erfc
mid2 + Ç« > 2Î´ then
38:
lower â† mid;
39:
else
40:
upper â† mid;
41:
end if
42:
N â† N + 1;
43:
end while
44: end if
âˆš
(a+ aâˆš2 +Ç« )Â·âˆ†
;
45: ÏƒDP-OPT â†
Ç« 2
46: return ÏƒDP-OPT

Note that in practice, due to Ç« â‰¥ 0.01 and Î´ â‰¤ 0.05, we
have (90a) as explained in Appendix D. We present (90b) and
(90c) for completeness.
To ensure Ïƒ returned by Algorithm 1 satisfies
0 â‰¤ Ïƒ âˆ’ ÏƒDP-OPT â‰¤ Î¶ for some Î¶ â‰¥ 0, we clearly have
the following results on the computational complexity of
Algorithm 1:
âˆš
â€¢ If 1 âˆ’ eÇ« erfc ( Ç«) > 2Î´, then Algorithm 1 takes at most
b
log2 Î¶ iterations (resp., log2 Î¶c ) if Line 7 uses b of Eq. (7a)
(resp., c of Eq. (9)), with each iteration
 having
 O(1)
complexity. The total complexity is O log2 Î¶b (resp.,


O log2 Î¶c ).
âˆš
â€¢ If 1 âˆ’ eÇ« erfc ( Ç«) < 2Î´, then Algorithm 1 takes
2âˆ’2Î´
inverfc( exp(Ç«)+1
)
at most log2
iterations, with each iteraÎ¶
tion
having
O(1)
complexity.
The total complexity is


2âˆ’2Î´
inverfc( exp(Ç«)+1
)
.
O log2
Î¶
P. Analyses of (Ç«, Î´)-Differential Privacy and (Ç«, Î´)Probabilistic Differential Privacy for the Composition
of Gaussian Mechanisms
This section provides analyses of (Ç«, Î´)-differential privacy
and (Ç«, Î´)-probabilistic differential privacy for the composition
of Gaussian mechanisms.
Lemma 15. For m queries Q1 , Q2 , . . . , Qm with â„“2 -sensitivity
âˆ†1 , âˆ†2 , . . . , âˆ†m , if the query result of Qi is added with
independent Gaussian noise of standard deviation Ïƒi , we have
the following results.
i) The differential privacy (DP) level for the composition of
the m noisy answers is the same as that of a Gaussian
mechanism with noise amount
!âˆ’1/2
m
X
âˆ†i 2
Ïƒâˆ— :=
(92)
Ïƒi 2
i=1

for a query with â„“2 -sensitivity 1.
ii) The probabilistic differential privacy (pDP) level for the
composition of the m noisy answers is the same as that of
a Gaussian mechanism with noise amount Ïƒâˆ— in Eq. (92)
for a query with â„“2 -sensitivity 1.
Remark 9.
DP
â€¢ Result i) of Lemma 15 implies the following. Let ÏƒÇ«,Î´
be a Gaussian noise amount which achieves (Ç«, Î´)-DP
for a query with â„“2 -sensitivity 1, where the expression of
DP
ÏƒÇ«,Î´
can follow from classical ones Dwork-2006 and
Dwork-2014 of [1], [2] (when Ç« â‰¤ 1), the optimal
one DP-OPT of Theorem 2, or our proposed mechanisms
Mechanism 1 of Theorem 4 and Mechanism 2 of
Theorem 5. Then the above composition satisfies (Ç«, Î´)-DP
DP
for Ç« and Î´ satisfying Ïƒâˆ— â‰¥ ÏƒÇ«,Î´
with Ïƒâˆ— defined above.
pDP
â€¢ Result ii) of Lemma 15 implies the following. Let ÏƒÇ«,Î´
be
a Gaussian noise amount which achieves (Ç«, Î´)-pDP for a
pDP
query with â„“2 -sensitivity 1, where the expression of ÏƒÇ«,Î´
can follow the optimal one, or our proposed mechanisms.

22

Then the above composition satisfies (Ç«, Î´)-pDP for Ç« and
pDP
Î´ satisfying Ïƒâˆ— â‰¥ ÏƒÇ«,Î´
with Ïƒâˆ— defined above.
Proof of Lemma 15:
We consider m queries Q1 , Q2 , . . . , Qm with â„“2 -sensitivity
âˆ†1 , âˆ†2 , . . . , âˆ†m . The query result of Qi on dataset D is added
with independent Gaussian noise of standard deviation Ïƒi , in
e i (D).
order to generate a noisy version Q
We first state a result for a general query Q. Let the query
result of Q on dataset D be added with Gaussian noise of
standard deviation Ïƒ, in order to generate a noisy version
e
Q(D).
From Eq. (82) (83) and (84), we obtain:

e
with y following the probability distribution of Q(D)
(i.e., a Gaussian distribution with mean Q(D)
and standard deviation Ïƒ),
e
F[Q(D)=y
]
the term ln F Q(D
obeys a Gaussian distribution
[ e â€² )=y]
â€²
â€²
)k2 ]2
)k2 ]2
and variance [kQ(D)âˆ’Q(D
.
with mean [kQ(D)âˆ’Q(D
2Ïƒ2
Ïƒ2
(93)

e be the composition of mechanisms Q
e1 , Q
e2 , . . . , Q
em .
Let Q
e i (D), and let
Let yi follow the probability distribution of Q
y be the composition of y1 , y2 , . . . , ym , which means that
e
y follow the probability distribution of Q(D).
Following
Eq. (11), the privacy loss function of Q on neighbouring
datasets D and Dâ€² can be defined as
h
i
e
F Q(D)
=y
h
i
LQ,D,D
â€² (y) = ln
e
e â€²) = y
F Q(D
ii
h
h
e i (D) = yi
Q
F âˆ©m
i=1
ii .
h
= ln h
(94)
m
e i (Dâ€² ) = yi
F âˆ©i=1 Q
e 1, Q
e2 , . . . , Q
e m are independent, we further have
Since Q
i
h
e i (D) = yi
m
F Q
X
i.
ln h
(95)
LQ,D,D
â€² (y) =
e
e i (Dâ€² ) = yi
F Q
i=1

From

(93),

ln

ei (D)=yi ]
F [Q
e i (Dâ€² )=yi ]
F [Q

distribution with mean
[kQi (D)âˆ’Qi (Dâ€² )k2 ]2
.
Ïƒi 2

follows

[kQi (D)âˆ’Qi (Dâ€² )k2 ]2
2Ïƒi 2

a

Gaussian

and variance

Then from (95), LQ,D,D
â€² (y) follows a
e
Pm [kQi (D)âˆ’Qi (Dâ€² )k2 ]2
Gaussian distribution with mean
i=1
2Ïƒi 2
â€²
2
Pm
i (D )k2 ]
.
and variance i=1 [kQi (D)âˆ’Q
Ïƒi 2
e both (Ç«, Î´)-differential
To account for the privacy level of Q,
privacy and (Ç«, Î´)-probabilistic differential privacy can be
given by conditions on LQ,D,D
â€² (y) for any pair of neighboring
e
â€²
e
datasets D and D . In particular, from Theorem 5 of [22], Q
achieves (Ç«, Î´)-differential privacy if and only if
ï£«
ï£¶
Pyâˆ¼Q(D)
[LQ,D,D
â€² (y) > Ç«]
e
e
ï£­
ï£¸ â‰¤ Î´,
(96)
âˆ’eÇ« Pyâˆ¼Q(D)
[LQ,D,D
â€² (y) < âˆ’Ç«]
e
e
for any pair of neighboring datasets D and Dâ€² .

e achieves (Ç«, Î´)-probabilistic differential
From Definition 2, Q

privacy if and only if
Pyâˆ¼Q(D)
[ LQ,D,D
â€² (y) > Ç«] â‰¤ Î´,
e
e

(97)
â€²

for any pair of neighboring datasets D and D .

Our analysis above shows that LQ,D,D
â€² (y) follows a Gause
â€²

)
sian distribution with mean A(D, Dâ€² ) and variance A(D,D
2
â€²
2
P
m
[kQ
(D)âˆ’Q
(D
)k
]
i
i
2
for A(D, Dâ€² ) := i=1
. Since kQi (D) âˆ’
2Ïƒi 2
Qi (Dâ€² )k2 is at most the â„“2 -sensitivity âˆ†i of query Qi ,
P
âˆ†i 2
the term A(D, Dâ€² ) is no greater than m
i=1 Ïƒi 2 . Lemma 7
of [22] proves that the left hand side of Eq. (96) strictly
e achieves (Ç«, Î´)increases when A(D, Dâ€² ) increases. Hence, Q
âˆ—
differential privacy if for L obeying a Gaussian distribution
Pm
2
âˆ—
i
with mean Aâˆ— and variance A2 for Aâˆ— := i=1 âˆ†
Ïƒi 2 , we have

P[Lâˆ— > Ç«] âˆ’ eÇ« P[Lâˆ— < âˆ’Ç«] â‰¤ Î´.

(98)

From (93) above and [22]â€™s Theorem 5, Inequality (98) is
also the condition to ensure that answering a query with â„“2 sensitivity 1 and Gaussian noise amount âˆš1Aâˆ— satisfies (Ç«, Î´)differential privacy.
e achieves (Ç«, Î´)-probabilistic differential privacy
Similarly, Q
if for Lâˆ— obeying a Gaussian distribution with mean Aâˆ— and
Pm
2
âˆ—
i
variance A2 for Aâˆ— := i=1 âˆ†
Ïƒi 2 , we have
P[|Lâˆ— | > Ç«] â‰¤ Î´.

(99)

From (93) above, Inequality (99) is also the condition to ensure
that answering a query with â„“2 -sensitivity 1 and Gaussian noise
amount âˆš1Aâˆ— satisfies (Ç«, Î´)-probabilistic differential privacy.
âˆ’1/2
P
m âˆ†i 2
With the above results and âˆš1Aâˆ— =
,
2
i=1 Ïƒi
Lemma 15 is proved.

Q. Proof of Lemma 8
Lemma 8 (Restated).
For 0 < y < 1, it holds that
q
2
inverfc(y) < ln âˆš8y+1âˆ’1
.
Proof: We define a function g(Â·) as
1
1
exp(âˆ’2x2 ) + exp(âˆ’x2 ).
2
2
Then we derive for 0 < y < 1 that
s
2
âˆ’1
.
g (y) = ln âˆš
8y + 1 âˆ’ 1
g(x) =

(100)

(101)

We relate Lemma 8 with the result
erfc(x) < g(x), for x > 0.

(102)

The rest of the proof includes two parts: i) using (102) to show
Lemma 8, and ii) proving (102).
Using (102) to show Lemma 8:
We replace x by g âˆ’1 (y) in Eq. (102), and thus obtain
g(g âˆ’1 (y)) > erfc(g âˆ’1 (y)).

(103)

The term g(g âˆ’1 (y)) in Eq. (103) equals y and can also be
written as erfc(inverfc(y)); i.e., we can express Eq. (103) as
follows:
erfc(inverfc(y)) > erfc(g âˆ’1 (y)).

(104)

23

As erfc() is a decreasing function, Eq. (104) implies
inverfc(y) < g âˆ’1 (y).

(105)

From
Eq. (101), we know that g âˆ’1 (y) in Eq. (105) equals
q
2
. Hence, Eq. (105) above means Lemma 8.
ln âˆš8y+1
âˆ’1
Proving (102):
The
error function erfc(x) equals
R âˆ complementary
âˆ’t2
âˆš2
e
dt.
We
will
prove another form of the
Ï€ x
complementary error function for x â‰¥ 0. Specifically,
we will show


Z Ï€2
x2
2
exp âˆ’
dÎ¸, for x â‰¥ 0. (106)
erfc(x) =
Ï€ 0
sin2 Î¸
The right hand side of Eq. (106) is an alternative form of the
complementary error function, and is known as Craigâ€™s formula [53] in the literature. Yet, to show Eq. (106), Craig [53]
uses empirical arguments and not many studies present a
rigorous proof. Below we formally establish Eq. (106) for
completeness.R
2
âˆ
Given âˆš2Ï€ 0 eâˆ’s ds = erfc(0) = 1, we now write erfc(x)
R
2
âˆ
(i.e., âˆš2Ï€ x eâˆ’t dt) as follows:
Z âˆ
2
2
âˆš
eâˆ’t dt
Ï€ x
Z âˆ
Z âˆ
2
2
2
2
eâˆ’s ds Â· âˆš
eâˆ’t dt
=âˆš
Ï€ 0
Ï€ x
Z
Z âˆ
2
4 âˆ âˆ’s2
e
ds
eâˆ’t dt.
(107)
=
Ï€ 0
x

We express the integral of Eq. (107) in polar coordinates.
Specifically, under s = r cos Î¸ and t = r sin Î¸, the intervals
s âˆˆ [0, âˆ) and t âˆˆ [x, âˆ) correspond to r âˆˆ [x/ sin Î¸, âˆ)
and Î¸ âˆˆ [0, Ï€2 ]. Also, it holds that dsdt = rdr dÎ¸. Then the
right hand side (RHS) of Eq. (107) is given by
Z âˆ
Z Ï€2
2
4
RHS of Eq. (107) =
dÎ¸
reâˆ’r dr
Ï€ 0
x/ sin Î¸
 y=âˆ

Z Ï€2
2
4
1
=
dÎ¸ âˆ’ eâˆ’y
Ï€ 0
2
y=x/ sin Î¸


Z Ï€2
2
x2
=
exp âˆ’
dÎ¸.
(108)
Ï€ 0
sin2 Î¸
Summarizing Eq. (107) and Eq. (108), we have proved
Eq. (106). To further bound erfc(x) based on Eq. (106), we
obtain for x > 0 that


Z Ï€2
x2
2
exp âˆ’
dÎ¸
Ï€ 0
sin2 Î¸


Z Ï€
Z Ï€2
2 4
2
x2
<
dÎ¸
+
exp âˆ’
exp(âˆ’x2 )dÎ¸
Ï€ 0
Ï€ Ï€4
sin2 Ï€4
2 Ï€
2 Ï€
= Â· Â· exp(âˆ’2x2 ) + Â· Â· exp(âˆ’x2 )
Ï€ 4
Ï€ 4
= g(x),
which along with Eq. (106) gives (102).
Since we have shown (102) and the result that (102) implies
Lemma 8, we complete proving Lemma 8.


