Submitted to the Annals of Probability

LIMITING ENTROPY OF DETERMINANTAL PROCESSES
B Y A NDRÃS M Ã‰SZAROS1 ,

arXiv:1905.11459v2 [math.PR] 25 May 2020

1 Central

European University, Budapest Meszaros_Andras@phd.ceu.edu

We extend Lyonsâ€™s tree entropy theorem to general determinantal measures. As a byproduct we show that the sofic entropy of an invariant determinantal measure does not depend on the chosen sofic approximation.

1. Introduction. Let P = (pij ) be an orthogonal projection matrix, where rows and
columns are both indexed with a finite set V . Then there is a unique probability measure
Î·P on the subsets of V such that for every F âŠ‚ V we have
Î·P ({B|F âŠ‚ B âŠ‚ V }) = det(pij )i,jâˆˆF .

The measure Î·P is called the determinantal measure corresponding to P [13]. Let B P be a
random subset of V with distribution Î·P . In this paper we investigate the asymptotic behavior
of the Shannon-entropy of B P defined as
X
H(B P ) =
âˆ’P(B P = A) log P(B P = A).
AâŠ‚V

Let P1 , P2 , . . . be a sequence of orthogonal projection matrices. Assume that rows and
columns of Pn are both indexed with the finite set Vn . Let Gn be a graph on the vertex set Vn .
Throughout the paper we assume that the degrees of graphs are at most D for some fixed finite
D . Our main theorem is the following.

T HEOREM . Assume that the sequence of pairs (Gn , Pn ) is Benjamini-Schramm convergent and tight. Then
H(B Pn )
nâ†’âˆž
|Vn |
lim

exists.

Note that this theorem will be restated in a slightly more general and precise form as
Theorem 2.5 in the next section. We will also give a formula for the limit.
We define Benjamini-Schramm convergence of (Gn , Pn ) along the lines of [6] and [2] via
the following local sampling procedure. Fix any positive integer r , this will be our radius of
sight. For a vertex o âˆˆ Vn let Br (Gn , o) be the r -neighborhood of o in the graph Gn , and let
Mn,r,o be the submatrix of Pn determined by rows and columns with indeces in Br (Gn , o).
Then the outcome of the local sampling at o is the pair (Br (Gn , o), Mn,r,o ). Of course, we
are only interested in the outcome up to rooted isomorphism. Now if we pick o as a uniform
random element of Vn , we get a probability measure Âµn,r on the set of isomorphism classes
of pairs (H, M ), where H is a rooted r -neighborhood and M is a matrix where rows and
columns are indexed with the vertices of H . We say that the sequence (Gn , Pn ) converges if
for any fixed r the measures Âµn,r converge weakly as n tends to infinity. See the next section
for more details including the description of the limit object.
MSC 2010 subject classifications: Primary 60C05, 37A35; secondary 60K99, 60B99
Keywords and phrases: determinantal processes, spanning trees, tree entropy, sofic entropy, weak convergence

1
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

2

To define the notion of tightness, we introduce a measure Î½n on N âˆª {âˆž} for each pair
(Gn , Pn ) as follows. Given k âˆˆ N âˆª {âˆž} we set
Î½n ({k}) = |Vn |âˆ’1

X

u,vâˆˆVn
dn (u,v)=k

|Pn (u, v)|2 ,

where dn is the graph metric on Vn = V (Gn ). Then the sequence (Gn , Pn ) is tight if the
family of measures Î½n is tight, that is, for each Îµ > 0 we have a finite R such that
Î½n ({R + 1, R + 2, . . . } âˆª {âˆž}) < Îµ

for all n. Tightness makes sure that the local sampling procedure from the previous paragraph
detects most of the significant matrix entries for large enough r .
Note that a related convergence notion of operators was introduced by Lyons and
Thom [15]. We expect that their notion is slightly stronger, but were unable to clarify this.
The idea of the proof of the main theorem is the following. Consider a uniform random
ordering of Vn . Then using the chain rule for conditional entropy we can write H(B Pn ) as the
sum of |Vn | conditional entropies. We show that in the limit we can control these conditional
entropies. This method in the context of local convergence first appeared in [7].
Now we describe a special case of our theorem. Consider a finite connected graph G, and
consider the uniform measure on the set of spanning trees of G. This measure turns out to be
a determinantal measure, the corresponding projection matrix Pâ‹† (G) is called the transfercurrent matrix [9]. Since this is a uniform measure, the Shannon-entropy is simply log Ï„ (G),
where Ï„ (G) is the number of spanning trees in G. A theorem of Lyons [14] states that if Gn
is a Benjamini-Schramm convergent sequence of finite connected graphs then
log Ï„ (Gn )
nâ†’âˆž |V (Gn )|
lim

exists. This theorem now follows from our results, because it is easy to see that the sequence
(L(Gn ), Pâ‹† (Gn )) is convergent and tight in our sense, where L(Gn ) is the line graph of Gn .
See Section 7. Note that we need to take the line graph of Gn , because the uniform spanning
tree measure is defined on the edges of Gn rather than the vertices of Gn . We also obtain a
formula for limit which is different from Lyonsâ€™s original formula. However, in practice it
seems easier to evaluate Lyonsâ€™s original formula.
Another application comes from ergodic theory. Let Î“ be a finitely generated countable
group, and let T be an invariant positive contraction on â„“2 (Î“). Here a linear operator is called
a positive contraction if it is positive semidefinite and has operator norm at most 1. Invariance
means that for any Î³, g1 , g2 âˆˆ Î“ we have
hT g1 , g2 i = hT (Î³ âˆ’1 g1 ), Î³ âˆ’1 g2 i.

Note that here we identify elements of Î“ with their characteristic vectors. Then the determinantal measure ÂµT corresponding to T gives us an invariant measure on {0, 1}Î“ . Note that
there is a natural graph structure on Î“. Namely, we can fix a finite generating set S , and
consider the corresponding Cayley-graph Cay(Î“, S). When Î“ belongs to the class of sofic
groups, one can define the so-called sofic entropy of this invariant measure [1]. This is done
by first considering an approximation of Cay(Î“, S) by a sequence of finite graphs Gn , and
then investigating how we can model ÂµT on these finite graphs. In general it is not known
whether sofic entropy depends on the chosen approximating sequence Gn or not, apart from
certain trivial examples. However, in our special case, our results allow us to give a formula

imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

3

for the sofic entropy, which only depends on the measure ÂµT , but not on the finite approximations. This shows that in this case the sofic entropy does not depend on the chosen sofic
approximation.
Observe that in our main theorem the graphs Gn do not play any role in the definition
of the random subsets B Pn or the Shannon entropy H(B Pn ), they are only there to help us
define our convergence notion. This suggests that there might be a notion of convergence of
orthogonal projection matrices without any additional graph structure such that the normalized Shannon entropy of B Pn is continuous.
Structure of the paper. In Section 2 we explain the basic definitions and state our results.
In Section 3 we investigate what happens if we condition a Benjamini-Schramm convergence
sequence of determinantal measures in a Benjamini-Schramm convergent way. In Sections 4,
5 and 6 we prove the theorems stated in Section 2. In Section 7 we explain the connections
of our results and Lyonsâ€™s tree entropy theorem. The proof of a technical lemma about the
measurability of the polar decomposition is given in the Appendix.
2. Definitions and statements of the results.
2.1. The space of rooted graphs and sofic groups. Fix a degree bound D . A rooted graph
is a pair (G, o) where G is a (possibly infinite) connected graph with degrees at most D ,
o âˆˆ V (G) is a distinguished vertex of G called the root. Given two rooted graphs (G1 , o1 ) and
(G2 , o2 ) their distance is defined to be the infimum over all Îµ > 0 such that for r = âŒŠÎµâˆ’1 âŒ‹ there
is a root preserving graph isomorphism from Br (G1 , o1 ) to Br (G2 , o2 ). Let G be the set of
isomorphism classes of rooted graphs. With the above defined distance G is a compact metric
space. Therefore, the set of probability measures P(G) endowed with the weak* topology is
also compact. A sequence of random rooted graphs (Gn , on ) Benjamini-Schramm converges
to the random rooted graph (G, o), if their distributions converge in P(G). Given any finite
graph G, we can turn it into a random rooted graph U (G) = (Go , o) by considering a uniform
random vertex o of G and its connected component Go . A sequence of finite graphs Gn
Benjamini-Schramm converges to the random rooted graph (G, o) if the sequence U (Gn )
Benjamini-Schramm converges to (G, o).
Let S be a finite set, an S -labeled Schreier graph is a graph where each edge is oriented
and labeled with an element from S , moreover for every vertex v of the graph and every
s âˆˆ S there is exactly one edge labeled with s entering v and there is exactly one edge labeled
with s leaving v . For example, if Î“ is a group with generating set S , then its Cayley-graph
Cay(Î“, S) is an S -labeled Schreier-graph. The notion of Benjamini-Schramm convergence
can be extended to the class of S -labeled Schreier-graphs with the modification that graph
isomorphisms are required to respect the orientation and labeling of the edges. Let Î“ be a
finitely generated group. Fix a finite generating set S , and consider the Cayley-graph GÎ“ =
Cay(Î“, S). Let eÎ“ be the identity of Î“. We say that Î“ is sofic if there is a sequence of finite
S -labeled Schreier-graphs Gn , such that Gn Benjamini-Schramm converges to (GÎ“ , eÎ“ ).
2.2. The space of rooted graph-operators. Fix a degree bound D , and let K be a nonempty finite set.
A rooted graph-operator (RGO) is a triple (G, o, T ), where (G, o) is a rooted graph and T
is a bounded operator on â„“2 (V (G) Ã— K). In this paper we will use real Hilbert spaces, but the
results can be generalized to the complex case as well. Note that to prove our main theorem
it suffices to only consider the case |K| = 1. The usefulness of allowing |K| > 1 will be only
clear in Section 5, where we extend our results to positive contractions.
Given two RGOs (G1 , o1 , T1 ) and (G2 , o2 , T2 ) their distance d((G1 , o1 , T1 ), (G2 , o2 , T2 ))
is defined as the infimum over all Îµ > 0 such that for r = âŒŠÎµâˆ’1 âŒ‹ there is a root preserving
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

4

graph isomorphism Ïˆ from Br (G1 , o1 ) to Br (G2 , o2 ) with the property that
(1)

|hT1 (v, k), (v â€² , kâ€² )i âˆ’ hT2 (Ïˆ(v), k), (Ïˆ(v â€² ), k â€² )i| < Îµ

for every v, v â€² âˆˆ V (Br (G1 , o1 )) and k, kâ€² âˆˆ K . Here we identified elements of V (Gi ) Ã— K
with their characteristic vectors in â„“2 (V (Gi ) Ã— K).
Two RGOs (G1 , o1 , T1 ) and (G2 , o2 , T2 ) are called isomorphic if their distance is 0, or
equivalently if there is a root preserving graph isomorphism Ïˆ from (G1 , o1 ) to (G2 , o2 )
such that
hT1 (v, k), (v â€² , kâ€² )i = hT2 (Ïˆ(v), k), (Ïˆ(v â€² ), kâ€² )i

for every v, v â€² âˆˆ V (G1 ) and k, kâ€² âˆˆ K . Let RGO be the set of isomorphism classes of RGOs.
For any 0 < B < âˆž, we define
RGO(B) = {(G, o, T ) âˆˆ RGO|

kT k â‰¤ B}.

One can prove that RGO(B) is a compact metric space with the above defined distance d.
Let P(RGO(B)) be the set of probability measures on RGO(B) endowed with the weak*
topology, this is again a compact space. Often it will be more convenient to consider an
element P(RGO) as a random RGO.
A RGO (G, o, T ) is called a rooted graph-positive-contraction (RGPC) if T is a selfadjoint positive operator with norm at most 1. Then the set RGPC of isomorphism classes
of RGPCs is a compact metric space. Therefore, P(RGPC) with the weak* topology is
compact.
We need a slight generalization of the notion of RGO. An h-decorated RGO is a tuple (G, o, T, A(1) , A(2) , . . . , A(h) ), where G, o and T are like above, A(1) , A(2) , . . . , A(h)
(1)
(2)
(h)
are subsets of V (G) Ã— K . Given two h-decorated RGOs (G1 , o1 , T1 , A1 , A1 , . . . , A1 )
(1)
(2)
(h)
and (G2 , o2 , T2 , A2 , A2 , . . . , A2 ) their distance is defined as the infimum over all Îµ > 0
such that for r = âŒŠÎµâˆ’1 âŒ‹ there is a root preserving graph isomorphism Ïˆ from Br (G1 , o1 ) to
Br (G2 , o2 ) satisfying the property given in (1), and for i = 1, 2, . . . , h we have
(i)

(i)

ÏˆÌ„(A1 âˆ© (Br (G1 , o1 ) Ã— K)) = A2 âˆ© (Br (G2 , o2 ) Ã— K),

where ÏˆÌ„(v, k) = (Ïˆ(v), k).
(1)
(h)
(1)
(h)
Two h-decorated RGOs (G1 , o1 , T1 , A1 , . . . , A1 ) and (G2 , o2 , T2 , A2 , . . . , A2 ) are
called isomorphic if their distance is 0. Let RGO h be the set of isomorphism classes of
h-decorated RGOs. We also define RGOh (B) and RGPC h the same way as their nondecorated versions were defined. With the above defined distance they are compact metric
spaces. Similarly as before, P(RGO h (B)) and P(RGPC h ), endowed with the weak* topology, are compact spaces. Whenever the value of h is clear from the context, we omit it and
simply use the term "decorated RGO".
A finite graph-positive-contraction is a pair (G, T ), where G is finite graph with degrees
at most D , and T is a positive contraction on â„“2 (V (G) Ã— K). It can be turned into a random
RGPC
U (G, T ) = (Go , o, To )

by choosing o as a uniform random vertex of G.
Note that all the definitions above depend on the choice of the finite set K . In most of the
paper we can keep K as fixed. Whenever we need to emphasize the specific choice of K , we
will refer to K as the support set of RGOs. Unless stated otherwise the support set is always
assumed to be K . Let L âŠ‚ K and let (G, o, T ) be a RGO with support set K . Let PL be the
orthogonal projection from â„“2 (V (G) Ã— K) to â„“2 (V (G) Ã— L) âŠ‚ â„“2 (V (G) Ã— K). We define the
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

5

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

operator restL (T ) on â„“2 (V (G) Ã— L) as restL (T ) = PL T â†¾â„“2 (V (G)Ã—L) . So (G, o, restL (T )) is
an RGO with support set L.
Sometimes we need to consider more than one operator on a rooted graph. A double RGO
will mean a tuple (G, o, T1 , T2 ) where (G, o) is a rooted graph and T1 , T2 are bounded operators on â„“2 (V (G) Ã— K). We omit the details how the set of isomorphism classes of double
RGOs can be turned into a metric space. It is also clear what we mean by a decorated double
RGO, or a triple RGO, or a double RGPC.
2.3. Determinantal processes. Let E be a countable set, and T be a positive contraction
of â„“2 (E). Then there is a random subset B T of E with the property that for each finite subset
F of E we have
P[F âŠ‚ B T ] = det(hT x, yi)x,yâˆˆF ,

where we identify an element x âˆˆ E with its characteristic vector in â„“2 (E). The distribution
of B T is uniquely determined by these constraints, and it is called the determinantal measure
corresponding to T [13].
Using the definition of the random subset B T , we can define a map
Ï„ : RGPC â†’ P(RGPC 1 ) by Ï„ (G, o, T ) = (G, o, T, B T ). This induces a map
Ï„âˆ— : P(RGPC) â†’ P(P(RGPC 1 )). Taking expectation we get the map
EÏ„âˆ— : P(RGPC) â†’ P(RGPC 1 ). So given a random RGPC (G, o, T ) the meaning of
(G, o, T, B T ) is ambiguous. Unless stated otherwise (G, o, T, B T ) will mean a random decorated RGPC, i.e., its distribution is an element of P(RGPC 1 ).
P ROPOSITION 2.1.

The maps Ï„, Ï„âˆ— and EÏ„âˆ— are continuous.

2.4. Trace and spectral measure. Given a random RGO (G, o, T ) we define
X
Tr(G, o, T ) = E
hT (o, k), (o, k)i.
kâˆˆK

We extend the definition to the decorated case in the obvious way.
Given a random RGPC (G, o, T ) its spectral measure is the unique measure Âµ = Âµ(G,o,T )
on [0, 1] with the property that, for any integer n â‰¥ 0 we have
Z 1
xn dÂµ.
Tr(G, o, T n ) =
0

Note that Âµ([0, 1]) = |K|. Also if T is a projection with probability 1, then we have
Âµ = Tr(G, o, T )Î´1 + (|K| âˆ’ Tr(G, o, T ))Î´0 .

If (G, T ) is a finite graph-positive-contraction, then the spectral measure of U (G, T ) can be
obtained as
1
|V (G)|

|V (G)Ã—K|

X

Î´Î»i ,

i=1

where Î»1 , Î»2 , . . . , Î»|V (G)Ã—K| are the eigenvalues of T with multiplicity.

imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

6

2.5. An equivalent characterization of tightness. We already defined the notion of tightness in the Introduction. Here we repeat the definition in a slightly more general setting. For a
finite graph-positive-contraction (G, T ) we define the measure Î½(G,T ) on N âˆª {âˆž} by setting
X
|hT (v1 , k1 ), (v2 , k2 )i|2 ,
Î½(G,T ) ({t}) = |V (G)|âˆ’1
(v1 ,k1 ),(v2 ,k2 )âˆˆV (G)Ã—K
dG (v1 ,v2 )=t

for all t âˆˆ N âˆª {âˆž}. A sequence (Gn , Tn ) of finite graph-positive-contractions is tight if the
family of measures Î½(Gn ,Tn ) is tight, that is, for each Îµ > 0 we have a finite R such that
Î½(Gn ,Tn ) ({R + 1, R + 2, . . . } âˆª {âˆž}) < Îµ

for all n. The next lemma gives an equivalent characterization of tightness.
L EMMA 2.2. Let (Gn , Pn ) be a Benjamini-Schramm convergent sequence of finite
graph-positive-contractions with limit (G, o, T ). Assume that P1 , P2 , . . . are orthogonal projections. Then the following are equivalent
i) The sequence (Gn , Pn ) is tight.
ii) The limit T is an orthogonal
Î½(Gn ,Pn ) ({âˆž}) = 0 for every n.

projection

with

probability

1

and

P ROOF. i)â‡’ ii): Recall the following well-known result.
P ROPOSITION 2.3. Let E be a countable set, and let T be a positive contraction on
â„“2 (E). Then for all e âˆˆ E we have hT 2 e, ei â‰¤ hT e, ei. Moreover, if for all e âˆˆ E we have
hT 2 e, ei = hT e, ei, then T is an orthogonal projection.
Let (Hn , on , Tn ) = U (Gn , Pn ). Then
Î½(Gn ,Pn ) (N âˆª {âˆž}) = |V (Gn )|âˆ’1 Tr(Pnâˆ— Pn ) = |V (Gn )|âˆ’1 Tr(Pn ) = Tr(Hn , on , Tn ).

Combining this with the definition of tightness we get that for any Îµ > 0 we have an R such
that
X
X
(2)
E
|hTn (on , k), (v, kâ€² )i|2 > Tr(Hn , on , Tn ) âˆ’ Îµ
kâˆˆK (v,k â€² )âˆˆBR (Hn ,on )Ã—K

for every n.
Using the convergence of (Hn , on , Tn ) we get that

lim Tr(Hn , on , Tn ) = Tr(G, o, T ),

nâ†’âˆž

and
lim E

nâ†’âˆž

X

X

kâˆˆK (v,k â€² )âˆˆBR (Hn ,on )Ã—K

|hTn (on , k), (v, kâ€² )i|2
=E

X

X

kâˆˆK (v,k â€² )âˆˆBR (G,o)Ã—K

|hT (o, k), (v, kâ€² )i|2 .

Combining these with inequality (2) we get that
X
X
Tr(G, o, T 2 ) = E
|hT (o, k), (v, kâ€² )i|2
kâˆˆK (v,k â€² )âˆˆV (G)Ã—K

â‰¥E

X

X

kâˆˆK (v,k â€² )âˆˆBR (G,o)Ã—K

imsart-aop ver.

|hT (o, k), (v, kâ€² )i|2 â‰¥ Tr(G, o, T ) âˆ’ Îµ.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

7

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

Tending to 0 with Îµ we get that
Tr(G, o, T 2 ) â‰¥ Tr(G, o, T ).

Combining this with the first statement of Proposition 2.3 we get that with probability 1 we
have hT 2 (o, k), (o, k)i = hT (o, k), (o, k)i for every k âˆˆ K . But then it follows from the unimodularity of (G, o, T ) that with probability 1 we have hT 2 (v, k), (v, k)i = hT (v, k), (v, k)i
for any (v, k) âˆˆ V (G) Ã— K . See [2, Lemma 2.3 (Everything Shows at the Root)] and Section 3. Then Proposition 2.3 gives us that T is a projection with probability 1. From the
definition of tightness it is clear that Î½n ({âˆž}) = 0 for every n.
ii)â‡’ i): Pick any Îµ > 0. From the monotone convergence theorem and the fact that T is a
projection with probability 1 we have
Tr(G, o, T ) = Tr(G, o, T 2 ) = E

X

X

kâˆˆK (v,k â€² )âˆˆV (G)Ã—K

= lim E
Râ†’âˆž

X

X

kâˆˆK (v,k â€² )âˆˆBR (G,o)Ã—K

|hT (o, k), (v, kâ€² )i|2

|hT (o, k), (v, kâ€² )i|2

Thus, if we choose a large enough R0 , then we have
X
X
Îµ
|hT (o, k), (v, kâ€² )i|2 < .
Tr(G, o, T ) âˆ’ E
2
â€²
kâˆˆK (v,k )âˆˆBR0 (G,o)Ã—K

Then from the convergence of (Hn , on , Tn ) we get that there is an N such that if n > N we
have
Î½(Gn ,Pn ) ({R0 + 1, R0 + 2, . . . } âˆª {âˆž}) =
X
Tr(Hn , on , Tn ) âˆ’ E

X

kâˆˆK (v,k â€² )âˆˆBR0 (Hn ,on )Ã—K

|hTn (on , k), (v, kâ€² )i|2 < Îµ.

Using the condition that Î½(Gn ,Pn ) ({âˆž}) = 0 for all n and the definition of Î½(Gn ,Pn ) we get
that the support of the measure Î½(Gn ,Pn ) is contained in {0, 1, . . . , |V (Gn )|}. Thus, the choice
R = max(R0 , |V (G1 )|, |V (G2 )|, . . . , |V (GN )|) is good for Îµ.
2.6. Sofic entropy. Let C be a finite set and let Î“ be a finitely generated group. Let f be
a random coloring of Î“ with C , that is a random element of C Î“ . (The measurable structure of
C Î“ comes from the product topology on C Î“ .) Given a coloring f âˆˆ C Î“ and Î³ âˆˆ Î“ we define
the coloring fÎ³ by fÎ³ (g) = f (Î³ âˆ’1 g) for all g âˆˆ Î“. This notation extends to random colorings
in the obvious way. A random coloring f is invariant if for every Î³ âˆˆ Î“ the distribution of fÎ³
is the same as the distribution of f .
Now assume that Î“ is a finitely generated sofic group, and f is an invariant random coloring of Î“. Let S be a finite generating set, and let G1 , G2 , . . . be a sequence of S -labeled
Schreier-graphs Benjamini-Schramm converging to the Cayley-graph GÎ“ = Cay(Î“, S). Now
we define the so called sofic entropy of f . There are many slightly different versions
of this notion [8, 3], we will follow AbÃ©rt and Weiss [1]. Let G be a finite S -labeled
Schreier graph and g be a random coloring of V (G). Given Îµ > 0 and a positive integer r , we say that g is an (Îµ, r) approximation of f on the graph G, if there are at least
(1 âˆ’ Îµ)|V (G)| vertices v âˆˆ V (G), such that Br (G, v) is isomorphic to Br (GÎ“ , eÎ“ ), moreover dT V (f â†¾ Br (GÎ“ , eÎ“ ), g â†¾ Br (G, v)) < Îµ, where dT V is the total variational distance, and
it is meant that we identify Br (GÎ“ , eÎ“ ) and Br (G, v). Let us define


H(g)
g is an (Îµ, r) approximation of f on G .
H(G, Îµ, r) = sup
|V (G)|
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

8

Here H(g) is the Shannon-entropy of g . Let H(Îµ, r) be the supremum of H(G, Îµ, r), over all
finite S -labeled Schreier graphs G. We define two versions of sofic entropy. The first one
h(f ) = inf lim sup H(Gn , Îµ, r).
Îµ,r

nâ†’âˆž

Note that this might depend on the chosen sofic approximation. Another option is to define
sofic entropy as
hâ€² (f ) = inf H(Îµ, r).
Îµ,r

Observe that hâ€² (f ) â‰¥ h(f ). It is open whether hâ€² (f ) = h(f ) for any sofic approximation
apart from trivial counterexamples. We can also express these quantities as
h(f ) = inf lim sup H(Gn , Îµ, âŒŠÎµâˆ’1 âŒ‹) and hâ€² (f ) = inf H(Îµ, âŒŠÎµâˆ’1 âŒ‹).
Îµ

Îµ

nâ†’âˆž

hâ€² (f )

The quantities h(f ) and
are isomorphism invariants in the abstract ergodic theoretic
sense.
Remark. Sofic entropy can be defined in a more general setting. Namely, let Q be a locally
finite vertex transitive graph. Let o be any vertex of it. Assume that (Q, o) is a BenjaminiSchramm limit of finite graphs. Let f be a random coloring of V (Q) with C such that the
distribution of f is invariant under all automorphisms of Q. We would like to define the sofic
entropy of f the same way as above. The only problematic point is that in the definition of
(Îµ, r)-approximation we need to identify Br (G, v) with Br (Q, o). But Br (Q, o) might have
non-trivial automorphisms, in which case there are more than one possible identifications and
it is not clear which we should choose. If all the automorphisms Br (Q, o) can be extended
to an automorphism of Q, then we can choose any identification, because they all give the
same total variation distance. But if Br (Q, o) has other automorphisms then things get more
complicated. However, one can overcome these difficulties and get a sensible notion of sofic
entropy [1]. Here we do not give the details, we just mention that Theorem 2.6 stated in the
next subsection can be extended to this more general setting.
2.7. Our main theorems. Let E be a countable set, and T be a positive contraction on
â„“2 (E). Let c be a [0, 1] labeling of E . For e âˆˆ E let I(e) be the indicator of the event that
e âˆˆ B T . For e âˆˆ E we define
hÌ„(e, c, T ) = H(I(e)|{I(f )|c(f ) < c(e)}).

Here, H is the conditional entropy, that is, with the notation
g(x) = âˆ’x log x âˆ’ (1 âˆ’ x) log(1 âˆ’ x),

we have

H(I(e)|{I(f )|c(f ) < c(e)}) = Eg(E[I(e)|{I(f )|c(f ) < c(e)}]).

Moreover, we define
hÌ„(e, T ) = EhÌ„(e, c, T ),

where c is an i.i.d. uniform [0, 1] labeling of E .
For a random RGPC (G, o, T ) we define
X
hÌ„(G, o, T ) = E
hÌ„((o, k), T ).
kâˆˆK

If L âŠ‚ K and (G, T ) is a finite graph-positive-contraction we define hL (G, T ) to be the
Shannon entropy of B T âˆ© (V (G) Ã— L).
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

9

T HEOREM 2.4. Let (Gn , Pn ) be a sequence of finite graph-positive-contractions,
such that limnâ†’âˆž U (Gn , Pn ) = (G, o, P ) for some random RGPC (G, o, P ). Assume that
P1 , P2 , . . . are orthogonal projections, and P is an orthogonal projection with probability 1.
Let L âŠ‚ K . Then
hL (Gn , Pn )
= hÌ„(G, o, restL (P )).
nâ†’âˆž |V (Gn )|
lim

Using Lemma 2.2 we immediately get the following theorem.
T HEOREM 2.5. Let (Gn , Pn ) be a tight sequence of finite graph-positive-contractions,
such that limnâ†’âˆž U (Gn , Pn ) = (G, o, P ) for some random RGPC (G, o, P ). Assume that
P1 , P2 , . . . are orthogonal projections. Let L âŠ‚ K . Then
lim

nâ†’âˆž

hL (Gn , Pn )
= hÌ„(G, o, restL (P )).
|V (Gn )|

Let Î“ be a finitely generated sofic group. A positive contraction T on â„“2 (Î“ Ã— K) is called
invariant, if for any Î³, g1 , g2 âˆˆ Î“ and k1 , k2 âˆˆ K we have
hT (g1 , g1 ), (g2 , k2 )i = hT (Î³ âˆ’1 g1 , k1 ), (Î³ âˆ’1 g2 , k2 )i.

For an invariant positive contraction if we regard the random subset B T as a random
coloring with {0, 1}K , we see that B T is an invariant coloring. Thus we can speak about its
sofic entropy.
As before let S be a finite generating set of Î“, let eÎ“ be the identity of Î“, and GÎ“ =
Cay(Î“, S) be the Cayley-graph of Î“.
T HEOREM 2.6. Let Î“ be a finitely generated sofic group. If T is an invariant positive
contraction on â„“2 (Î“ Ã— K) then we have
h(B T ) = hâ€² (B T ) = hÌ„(GÎ“ , eÎ“ , T )

for any sofic approximation of Î“.
Note that we can easily generalize the definition of hÌ„ to any invariant random coloring f .
It is known that even in this more general setting hÌ„ is an upper bound on the sofic entropy.
However, hÌ„ is not an isomorphism invariant in the ergodic theoretic sense. See [18].
The random ordering idea above was used by Borgs, Chayes, Kahn and LovÃ¡sz [7] to give
the growth of the partition function and entropy of certain Gibbs measures at high temperature
on Benjamini-Schramm convergent graph sequences. See also [4].
2.8. An example: Why tightness is necessary?. We consider two connected graphs H1
and H2 . Let H1 be the complete graph on 4 vertices, and let H2 be the graph that is
obtained from a star with 3 edges by doubling each edge. Both have 4 vertices and 6
edges. Let Ti be a uniform random spanning tree of Hi , and let Pi be the corresponding
6 Ã— 6 transfer-current matrix. It is straightforward to check that for any e âˆˆ E(Hi ) we have
P(e âˆˆ Ti ) = 12 . Thus, in both P1 and P2 all the diagonal entries are equal to 12 . Now let
Gi be the empty graph on the vertex set E(Hi ). Then the pairs (G1 , P1 ) and (G2 , P2 ) are
indistinguishable by local sampling, that is, U (G1 , P1 ) and U (G2 , P2 ) have the same distribution. On the other hand H1 has 16 spanning trees, and H2 has only 8 spanning trees. So
|V (G1 )|âˆ’1 H(B P1 ) 6= |V (G2 )|âˆ’1 H(B P2 ). This shows that the condition of tightness can not
be omitted in Theorem 2.5. One could think that this only works, because the graphs G1 and
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

10

G2 are not connected. But Theorem 2.5 still fails without the assumption of tightness, even
if we assume that all the graphs are connected. We sketch the main idea. Let i âˆˆ {1, 2}. For
each n we consider a block diagonal matrix Bi,n , where we have n diagonal blocks each of
which equal to Pi . Then we take a connected graph Gi,n on Vi,n (the set of columns of Bi,n )
in such a way that if two columns are in the same block, then they must be at least at distance
d(n) in the graph Gi,n for some d(n) tending to infinity. Moreover, we can choose Gi,n such
that the sequences (G1,n ) and (G2,n ) have the same Benjamini-Schramm limit (G, o). Then
both of the sequences (G1,n , B1,n ) and (G2,n , B2,n ) have the same limit, namely, (G, o, 21 I).
But their asymptotic entropy is different.

3. Unimodularity and conditional determinantal processes.
3.1. Unimodularity. We define bi-rooted graph-operators as tuples (G, o, oâ€² , T ), where
G is a connected graph with degree bound D , o, oâ€² âˆˆ V (G) and T is a bounded operator on
â„“2 (V (G) Ã— K). Let biRGO be the set of isomorphism classes of bi-rooted graph-operators.
We omit the details how to endow this space with a measurable structure. A random RGO
(G, o, T ) is called unimodular, if for any non-negative measurable function f : biRGO â†’ R
we have
X
X
f (G, v, o, T ).
f (G, o, v, T ) = E
E
vâˆˆV (G)

vâˆˆV (G)

The next lemma gives some examples of unimodular random RGOs. The proof goes like
the one given in [6].
L EMMA 3.1. If (G, T ) is a finite graph-positive-contraction, then U (G, T ) is unimodular. The limit of unimodular random RGOs is unimodular.
Of course the notion of unimodularity can be extended to double/triple (decorated) RGOs.
We will use the following consequence of unimodularity.
L EMMA 3.2. Let (G, o, T, S) be a unimodular random double RGO. Assume that there
is a finite B such that kT k, kSk < B with probability 1. Then
Tr(G, o, T S) = Tr(G, o, ST ).

P ROOF. The proof is the same as in [2, Section 5].
It has the following consequences.
L EMMA 3.3. In the following statements we always assume that P and Pi are all orthogonal projections with probability 1.
1. Let (G, o, P1 , P2 , U ) be a unimodular random triple RGO, such that with probability 1 we
have U â†¾ ker P1 â‰¡ 0 and U â†¾ Im P1 is an isomorphism between Im P1 and Im P2 . Then
Tr(G, o, P1 ) = Tr(G, o, P2 ).

2. Let (G, o, P1 , P2 , T ) be a unimodular random triple RGO, such that with probability 1 we
have Im T P1 = Im P2 and T is injective on Im P1 . Then
Tr(G, o, P1 ) = Tr(G, o, P2 ).

imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

11

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

3. (rank-nullity theorem) Let (G, o, P, P1 , P2 , T ) be a unimodular random quadruple RGO,
such that with probability 1 we have that P1 is the orthogonal projection to ker(T â†¾ Im P )
and P2 is the orthogonal projection to Im(T â†¾ Im P ). Then
Tr(G, o, P ) = Tr(G, o, P1 ) + Tr(G, o, P2 ).

P ROOF. To prove part 1 observe that P1 U âˆ— U = P1 and U P1 U âˆ— = P2 . Note that all operators have norm at most 1, so from Lemma 3.2
Tr(G, o, P1 ) = Tr(G, o, (P1 U âˆ— )U ) = Tr(G, o, U (P1 U âˆ— )) = Tr(G, o, P2 ).

To prove part 2 let T P1 = U H be the unique polar decomposition of T P1 , then
(G, o, P1 , P2 , U P1 ) satisfies the conditions in part 1, so the statement follows. The rather
technical details why the polar decomposition is measurable are given in the Appendix. Note
that once we established the measurability of U , unimodularity follows from the uniqueness
of the decomposition.
To prove part 3 let H = Im P âˆ© (ker T â†¾ Im P )âŠ¥ . Let PH be the orthogonal projection
to H , then we have P = P1 + PH . Therefore, Tr(G, o, P ) = Tr(G, o, P1 ) + Tr(G, o, PH ).
It is also clear that Im T P = Im(T â†¾ H) and T is injective on H . Thus part 2 gives us
Tr(G, o, PH ) = Tr(G, o, P2 ). Putting everything together we obtain that
Tr(G, o, P ) = Tr(G, o, P1 ) + Tr(G, o, PH ) = Tr(G, o, P1 ) + Tr(G, o, P2 ).

3.2. Conditional determinantal processes. Let P be an orthogonal projection to a closed
subspace H of â„“2 (E). Given C âŠ‚ E , let [C] be the closed subspace generated by e âˆˆ C , and
let [C]âŠ¥ be the orthogonal complement of it. Note that [C]âŠ¥ = [E\C]. We define P/C as the
orthogonal projection to the closed subspace (H âˆ© [C]âŠ¥ ) + [C], and PÃ—C as the orthogonal
projection to the closed subspace H âˆ© [C]âŠ¥ . We also define Pâˆ’C = I âˆ’ (I âˆ’ P )/C .
P ROPOSITION 3.4. We have P/C = PÃ—C + P[C] , where P[C] is the orthogonal projection
to [C]. In other words P/C e = e for e âˆˆ C and P/C e = PÃ—C e for e âˆˆ E\C . Moreover, if Cn
is an increasing sequence of subsets of E and C = âˆªCn , then P/Cn converges to P/C in the
strong operator topology. Furthermore, the sequence hPÃ—Cn e, ei is monotone decreasing.
P ROOF. The first statement is trivial. To prove the second statement, observe that PÃ—Cn
is a sequence of orthogonal projections to a monotone decreasing sequence of closed subspaces with intersection Im PÃ—C , so PÃ—Cn converge to PÃ—C in the strong operator topology.
It is also clear that P[Cn ] converge to P[C] , so from P/Cn = PÃ—Cn + P[Cn ] the statement follows. To prove the third statement observe that hPÃ—Cn e, ei = kPÃ—Cn ek22 . So the statement
follows again from the fact that PÃ—Cn is a sequence of orthogonal projections to a monotone
decreasing sequence of closed subspaces.
For C, D âŠ‚ E we define P/Câˆ’D = (P/C )âˆ’D , and we define Pâˆ’D/C = (Pâˆ’D )/C . We only
include the next lemma here to make it easier to compare formulas in [13] with our formulas.
L EMMA 3.5. Let P be an orthogonal projection to a closed subspace H . Then for any
D âŠ‚ E we have
Im Pâˆ’D = H + [D] âˆ© [D]âŠ¥ .

imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

12

Moreover, if C and D are disjoint subsets of E , then

and

Im P/Câˆ’D = (H âˆ© [C]âŠ¥ ) + [C âˆª D] âˆ© [D]âŠ¥
Im Pâˆ’D/C = (H + [D] âˆ© [C âˆª D]âŠ¥ ) + [C].

If C and D are finite, then the above formulas are true even if we omit the closures.
P ROOF. We only prove the first statement. The other statements can be easily deduced
from it. Unpacking the definitions we need to prove that
((H âŠ¥ âˆ© [D]âŠ¥ ) + [D])âŠ¥ = H + [D] âˆ© [D]âŠ¥ .

As a first step observe that H + [D] âˆ© [D]âŠ¥ = Im(P[D]âŠ¥ â†¾ H). Indeed, if x âˆˆ (Im P[D]âŠ¥ â†¾ H),
then x = lim xn , where for all n we have xn âˆˆ [D]âŠ¥ and there is an yn âˆˆ [D] such that
xn + yn âˆˆ H . But then xn = (xn + yn ) âˆ’ yn âˆˆ H + [D], which implies that x âˆˆ H + [D].
Clearly x âˆˆ [D]âŠ¥ , so x âˆˆ H + [D] âˆ© [D]âŠ¥ .
To prove the other containment let x âˆˆ H + [D] âˆ© [D]âŠ¥ , then x = lim xn where
xn = yn + zn with yn âˆˆ H and zn âˆˆ [D]. Since P[D]âŠ¥ is continuous, we have
x = P[D]âŠ¥ x = lim P[D]âŠ¥ (yn + zn ) = lim P[D]âŠ¥ yn âˆˆ Im(P[D]âŠ¥ â†¾ H).

Now it is easy to see that we need to prove that

(H âŠ¥ âˆ© [D]âŠ¥ ) + [D] = (Im P[D]âŠ¥ â†¾ H)âŠ¥ .

First let x âˆˆ (Im P[D]âŠ¥ â†¾ H)âŠ¥ . Then for any h âˆˆ H we have
0 = hx, P[D]âŠ¥ hi = hP[D]âŠ¥ x, hi,

which implies that P[D]âŠ¥ x âˆˆ H âŠ¥ âˆ© [D]âŠ¥ . Thus, x = P[D]âŠ¥ x + P[D] x âˆˆ (H âŠ¥ âˆ© [D]âŠ¥ ) + [D].
To show the other containment let us consider x = y + z such that y âˆˆ H âŠ¥ âˆ© [D]âŠ¥ and
z âˆˆ [D]. Then for any h âˆˆ H we have
hx, P[D]âŠ¥ hi = hP[D]âŠ¥ x, hi = hy, hi = 0,

because y âˆˆ H âŠ¥ .
For the last statement, see the discussion in the paper [13] after the proof of Corollary 6.4.
We have the following lemma. See [13, Equation (6.5)].
L EMMA 3.6. Let C and D be disjoint finite subsets of E such that
P[B P âˆ© (C âˆª D) = C] > 0. Then P/Câˆ’D = Pâˆ’D/C and conditioned on the event
B P âˆ© (C âˆª D) = C , the distribution of B P is the same as that of B P/Câˆ’D .
The lemma above shows why the pairs (C, D) of finite disjoint sets with the property that
P[B P âˆ© (C âˆª D) = C] > 0 are interesting for us. The next proposition gives an equivalent
characterization of these pairs.
P ROPOSITION 3.7. Let C and D be disjoint finite subsets of E . Then we have
P[B P âˆ© (C âˆª D) = C] > 0 if and only if Im P[C] P = [C] and Im P[D] (I âˆ’ P ) = [D].
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

13

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

This motivates the following definitions. A (not necessary finite) subset C of E is called
independent (with respect to P ) if Im P[C] P = [C]. A subset D of E is called dually independent (with respect to P ) if Im P[D] (I âˆ’ P ) = [D]. A pair (C, D) of subsets of E is called
permitted (with respect to P ) if C and D are disjoint, C is independent and D is dually
independent.
We will need the following theorem of Lyons [13, Theorem 7.2].
T HEOREM 3.8.

The pair (B P , E\B P ) is permitted with probability 1.

We will also need the following statements.
P ROPOSITION 3.9.
ted.

If (C, D) is permitted, C â€² âŠ‚ C and D â€² âŠ‚ D , then (C â€² , D â€² ) is permit-

P ROPOSITION 3.10. Assume (C, D) is a permitted pair. Then D is dually independent
with respect to P/C , or equivalently, D is independent with respect to I âˆ’ P/C .
P ROOF. By the definition of a permitted pair Im P[D] (I âˆ’ P ) = [D], so it is enough to
show that Im P[D] (I âˆ’ P ) âŠ‚ Im P[D] (I âˆ’ P/C ). Take any r âˆˆ Im P[D] (I âˆ’ P ), then there is
x such that r = P[D] (I âˆ’ P )x. Let y = P[C]âŠ¥ (I âˆ’ P )x. We claim that y âˆˆ Im(I âˆ’ P/C ), or
in other words, y is orthogonal to any element w âˆˆ Im P/C . We can write w as w = w0 + w1 ,
where w0 âˆˆ Im P âˆ© [C]âŠ¥ and w1 âˆˆ [C]. We have
hy, w0 i = hP[C]âŠ¥ (I âˆ’ P )x, w0 i = h(I âˆ’ P )x, P[C]âŠ¥ w0 i = h(I âˆ’ P )x, w0 i = 0,

since w0 âˆˆ Im P . Moreover hy, w1 i = 0, because y âˆˆ [C]âŠ¥ and w1 âˆˆ [C]. Thus, hy, wi = 0,
so y is indeed in the image of I âˆ’ P/C , then P[D] y is in the image of P[D] (I âˆ’ P/C ). Using
that C and D are disjoint P[D] y = P[D] P[C]âŠ¥ (I âˆ’ P )x = P[D] (I âˆ’ P )x = r .
Assume for a moment that E is finite, then |B P | = dim Im P with probability 1. If (C, D)
is a permitted pair, then the distribution of B P/Câˆ’D is the same as that of B P conditioned on
the event that B P âˆ© (C âˆª D) = C . So |B P/Câˆ’D | = dim Im P with probability 1. In particular,
E|B P | = E|B P/Câˆ’D |. The next lemma extends this statement to the more general unimodular
setting.
L EMMA 3.11. Let (G, o, P, C, D) be a unimodular random decorated RGPC where P
is an orthogonal projection and the pair (C, D) is permitted with probability 1. Then
Tr(G, o, P ) = Tr(G, o, P/Câˆ’D ) = Tr(G, o, Pâˆ’D/C ).

This can be obtained from combining Proposition 3.10 and the following lemma.
L EMMA 3.12. Let (G, o, P, C) be a unimodular random decorated RGPC where P is
an orthogonal projection and C is independent with probability 1. Then
Tr(G, o, P ) = Tr(G, o, P/C ).

We also have the corresponding dual statement, that is, let (G, o, P, D) be a unimodular
random decorated RGPC where P is an orthogonal projection and D is dually independent
with probability 1. Then
Tr(G, o, P ) = Tr(G, o, Pâˆ’D ).
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

14

P ROOF. We only need to prove the first statement, because the second one can be obtained
by applying the first statement to I âˆ’ P .
Observe that ker(P[C] â†¾ Im P ) = Im PÃ—C from the definition of PÃ—C , moreover,
Im(P[C] â†¾ Im P ) = [C], because C is independent. Applying the rank nullity theorem
(Lemma 3.3.3) and then using the fact P/C = PÃ—C + P[C] from Proposition 3.4 we get
that
Tr(G, o, P ) = Tr(G, o, PÃ—C ) + Tr(G, o, P[C] ) = Tr(G, o, PÃ—C + P[C] ) = Tr(G, o, P/C ).

The next lemma gives an extension of Lemma 3.6.
L EMMA 3.13.

Let F âŠ‚ E , and assume that
hP/B P âˆ©F âˆ’F \B P e, ei = hPâˆ’F \B p /B P âˆ©F e, ei

for all e âˆˆ E with probability 1. Then for any finite A âŠ‚ E we have

P(A âŠ‚ B P |B P â†¾ F ) = P(A âŠ‚ B P/BP âˆ©F âˆ’F \BP ).
P ROOF. Let F1 , F2 , . . . be an increasing sequence of finite sets such that their union is F .
The crucial step in the proof is the following lemma.
L EMMA 3.14. Let (C, D) be a permitted pair, such that C âˆªD = F . Then hP/Câˆ’D e, ei â‰¤
hPâˆ’D/C e, ei for all e âˆˆ E . Now assume that hP/Câˆ’D e, ei = hPâˆ’D/C e, ei for all e âˆˆ E . Let
us define Pn = P/Câˆ©Fn âˆ’Dâˆ©Fn . Then B P/Câˆ’D is the weak limit of B Pn .
P ROOF. Let A be a finite set such that, A âˆ© F = âˆ…, moreover let A be an upwardly closed
subset of 2A , i.e. if X âŠ‚ Y âŠ‚ A and X âˆˆ A, then Y âˆˆ A. Using that determinantal measures
have negative associations ([13, Theorem 6.5]) we get the following inequality for m > n
P[B Pn âˆ© A âˆˆ A] = P[B P/Câˆ©Fn âˆ’Dâˆ©Fn âˆ© A âˆˆ A] â‰¥ P[B P/Câˆ©Fm âˆ’Dâˆ©Fn âˆ© A âˆˆ A].

Tending to infinity with m, we get that

P[B Pn âˆ© A âˆˆ A] â‰¥ P[B P/Câˆ’Dâˆ©Fn âˆ© A âˆˆ A].

(3)

To justify this last statement, let U be the set of orthogonal projections R such that D âˆ© Fn
is dually independent with respect to R. Combining Proposition 3.9 and Proposition 3.10,
we obtain that P/Câˆ©Fm and P/C are all contained in U . For R âˆˆ U , the probability
P[B Râˆ’Dâˆ©Fn âˆ© A âˆˆ A] is a continuous function of (hRe, f i)e,f âˆˆAâˆª(Dâˆ©Fn ) . As we proved in
Proposition 3.4, P/Câˆ©Fm tends to P/C in the strong operator topology. Thus,
lim P[B P/Câˆ©Fm âˆ’Dâˆ©Fn âˆ© A âˆˆ A] = P[B P/Câˆ’Dâˆ©Fn âˆ© A âˆˆ A].

mâ†’âˆž

This gives us Inequality (3).
Tending to infinity with n we get that
lim inf P[B Pn âˆ© A âˆˆ A] â‰¥ lim P[B P/Câˆ’Dâˆ©Fn âˆ© A âˆˆ A] = P[B P/Câˆ’D âˆ© A âˆˆ A].
nâ†’âˆž

nâ†’âˆž

A similar argument gives that
lim sup P[B Pn âˆ© A âˆˆ A] â‰¤ P[B Pâˆ’D/C âˆ© A âˆˆ A]
nâ†’âˆž

imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

15

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

Therefore,
(4)

P[B Pâˆ’D/C âˆ© A âˆˆ A] â‰¥ lim sup P[B Pn âˆ© A âˆˆ A]
nâ†’âˆž

â‰¥ lim inf P[B Pn âˆ© A âˆˆ A] â‰¥ P[B P/Câˆ’D âˆ© A âˆˆ A].
nâ†’âˆž

These inequalities are in fact true without the assumption A âˆ© F = âˆ…. Indeed, let A âŠ‚ E finite
and A be an upwardly closed subset of 2A . We define Aâ€² = A\F and
Aâ€² = {X âŠ‚ Aâ€² |X âˆª (A âˆ© C) âˆˆ A}.
â€²

Note that Aâ€² is upwardly closed subset of 2A .
Then P[B P/Câˆ’D âˆ© A âˆˆ A] = P[B P/Câˆ’D âˆ© Aâ€² âˆˆ Aâ€² ]. Moreover, for any large enough n, we
have P[B Pn âˆ© A âˆˆ A] = P[B Pn âˆ© Aâ€² âˆˆ Aâ€² ]. Clearly Aâ€² âˆ© F = âˆ…, so we reduced the problem
to the already established case.
Choosing A = {e} and A = {{e}} in (4), we get that hP/Câˆ’D e, ei â‰¤ hPâˆ’D/C e, ei for
all e âˆˆ E . Inequality (4) tells us that B Pâˆ’D/C stochastically dominates B P/Câˆ’D . But if
hP/Câˆ’D e, ei = hPâˆ’D/C e, ei for all e âˆˆ E , then the distribution of B P/Câˆ’D and B Pâˆ’D/C must
be the same. Then inequality (4) gives the statement.
Let A be any finite set. We define the martingale Xn by
Xn = P[A âŠ‚ B P |B P â†¾ Fn ] = P[A âŠ‚ B P/BP âˆ©Fn âˆ’Fn \BP ].

Combining the previous lemma with our assumptions on B P we get that with probability 1
we have lim Xn = P[A âŠ‚ B P/BP âˆ©F âˆ’F \BP ]. On the other hand we have
lim Xn = P[A âŠ‚ B P |B P â†¾ F ].

The statement follows.

L EMMA 3.15. Let (G, o, P, F ) be a unimodular random decorated RGPC where P is
an orthogonal projection with probability 1. Then with probability 1, we have that for any
finite set A âŠ‚ V (G) Ã— K
P(A âŠ‚ B P |B P â†¾ F ) = P(A âŠ‚ B P/BP âˆ©F âˆ’F \BP ).

P ROOF. From Lemma 3.14, we have that for all e âˆˆ V (G) Ã— K we have
hP/B P âˆ©F âˆ’F \B P e, ei â‰¤ hPâˆ’F \B P /B P âˆ©F e, ei.

From Lemma 3.11, we have Tr(G, o, P/B P âˆ©F âˆ’F \B P ) = Tr(G, o, Pâˆ’F \B P /B P âˆ©F ), which
imply that with probability 1 we have hP/B P âˆ©F âˆ’F \B P e, ei = hPâˆ’F \B P /B P âˆ©F e, ei for any
e âˆˆ {o} Ã— K , but then it is true for any e from unimodularity. (See [2, Lemma 2.3 (Everything Shows at the Root)].) Therefore, Lemma 3.13 can be applied to get the statement.
The lemma above establishes Conjecture 9.1 of [13] in the special unimodular case. Note
that this conjecture is false in general as it was pointed out to the author by Russel Lyons.
Indeed, it follows from the results of Heicklen and Lyons [11] that for the WUSF on certain trees, conditioning on all edges but one does not (a.s.) give a measure corresponding
to an orthogonal projection, because the probability of the remaining edge to be present is
in (0, 1) a.s.
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

16

3.3. Limit of conditional determinantal processes.
T HEOREM 3.16. Let (Gn , on , Pn , Cn , Dn ) be a convergent sequence of unimodular
random decorated RGPCs with limit (G, o, P, C, D). Assume that Pn and P are orthogonal projections and (Cn , Dn ) and (C, D) are all permitted with probability 1. Then
(Gn , on , (Pn )/Cn âˆ’Dn ) converges to (G, o, P/Câˆ’D ).
This will follow from applying the next lemma twice, first for the sequence Pn , then for
I âˆ’ (Pn )/C with Dn in place of Cn . At the second time we need to use Proposition 3.10 to
show that the conditions of the lemma are satisfied.
L EMMA 3.17. Let (Gn , on , Pn , Cn , Dn ) be a convergent sequence of unimodular random decorated RGPCs with limit (G, o, P, C, D). Assume that Pn and P are orthogonal
projections and Cn , C are all independent with probability 1. Then (Gn , on , (Pn )/Cn , Dn )
converges (G, o, P/C , D).
P ROOF. The presence of Dn does not not add any extra difficulty to the problem, so for
simplicity of notation we will prove the following statement instead:
Let (Gn , on , Pn , Cn ) be a convergent sequence of unimodular random decorated RGPCs
with limit (G, o, P, C). Assume that Pn and P are orthogonal projections, Cn and C are all
independent with probability 1. Then (Gn , on , (Pn )/Cn ) converges to (G, o, P/C ).
We start by the following lemma.
L EMMA 3.18. Let (Gn , on , Pn , Cn ) be a convergent sequence of decorated RGPCs with
limit (G, o, P, C). Assume that Pn and P are orthogonal projections, Cn and C are all independent, and there is an r such that Cn âŠ‚ V (Br (Gn , on )) Ã— K and C âŠ‚ V (Br (G, o)) Ã— K .
Then (Gn , on , (Pn )Ã—Cn ) converges to (G, o, PÃ—C ).
P ROOF. Let us choose an orthogonal projection Î  from a small neighborhood U of P .
If this neighborhood is small enough, then C is independent with respect to Î . For c âˆˆ C ,
hÎ e,ci
âŠ¥
we have Î Ã—{c} e = Î e âˆ’ hÎ e,ci
hÎ c,ci Î c. Indeed, clearly Î e âˆ’ hÎ c,ci Î c âˆˆ Im Î  âˆ© [{c}] , moreover
with the notation Î± =

hÎ e,ci
hÎ c,ci

for any w âˆˆ Im Î  âˆ© [{c}]âŠ¥ we have

hw, e âˆ’ (Î e âˆ’ Î±Î c)i = hw, (I âˆ’ Î )ei + hw, Î±Î ci = hÎ w, Î±ci = hw, Î±ci = 0.

By induction we get that

Î Ã—C e = Î e âˆ’

X

Î±c,e Î c.

câˆˆC

Here Î±c,e is a continuous function of (hÎ x, yi)x,yâˆˆCâˆª{e} in the neighborhood U . The statement can be deduced using this.
From compactness every subsequence of (Gn , on , Pn , (Pn )/Cn , Cn ) has a convergent subsequence, so it is enough to prove the following lemma.
L EMMA 3.19. Let (Gn , on , Pn , Cn ) be a convergent sequence of unimodular random
decorated RGPCs with limit (G, o, P, C). Assume that Pn and P are orthogonal projections,
Cn and C are all independent with probability 1. If (Gn , on , Pn , (Pn )/Cn , Cn ) converges to
(G, o, P, Q, C), then (G, o, Q) has the same distribution as (G, o, P/C ).

imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

17

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

P ROOF. Using Skorokhodâ€™s representation theorem we can find a coupling of
(Gn , on , Pn , (Pn )/Cn , Cn ) and (G, o, P, Q, C) such that limnâ†’âˆž (Gn , on , Pn , (Pn )/Cn , Cn ) =
(G, o, P, Q, C) with probability 1. By definition there is a random sequence r1 , r2 , . . .
such that limnâ†’âˆž rn = âˆž with probability 1, and there is a root preserving graph isomorphism Ïˆn from Brn (G, o) to Brn (Gn , on ) such that ÏˆÌ„n (C âˆ© (Brn (G, o) Ã— K)) =
Cn âˆ© (Brn (Gn , on ) Ã— K), where ÏˆÌ„n (v, k) = (Ïˆn (v), k) and with probability 1 for each
e, f âˆˆ V (G) Ã— K we have
lim hPn ÏˆÌ„n e, ÏˆÌ„n f i = hP e, f i,

nâ†’âˆž

and
lim h(Pn )/Cn ÏˆÌ„n e, ÏˆÌ„n f i = hQe, f i.

nâ†’âˆž

Of course, ÏˆÌ„n e only makes sense if n is large enough.
Let us define Cn (r) = Cn âˆ© (Br (Gn , on ) Ã— K) and C(r) = C âˆ© (Br (G, o) Ã— K).
Lemma 3.18 gives us that for any r we have
(5)

lim h(Pn )Ã—Cn (r) ÏˆÌ„n (e), ÏˆÌ„n (f )i = hPÃ—C(r) e, f i.

nâ†’âˆž

Note that Im PÃ—C(r) is a decreasing sequence of subspaces with intersection Im PÃ—C . So
PÃ—C(r) converges to PÃ—C in the strong operator topology.
In particular, for any e, f âˆˆ V (G) Ã— K , we have

(6)

lim hPÃ—C(r) e, f i = hPÃ—C e, f i,

râ†’âˆž

and
(7)

lim h(Pn )Ã—Cn (r) ÏˆÌ„n (e), ÏˆÌ„n (f )i = h(Pn )Ã—Cn ÏˆÌ„n (e), ÏˆÌ„n (f )i.

râ†’âˆž

We need the following elementary fact.
L EMMA 3.20. Let a(r, n) be non-negative real numbers, such that for any fixed n, the
sequence a(r, n) is monotone decreasing in r . Let An = limrâ†’âˆž a(r, n), assume that for any
fixed r the limit Br = limnâ†’âˆž a(r, n) exists. Then limnâ†’âˆž An â‰¤ limrâ†’âˆž Br if these limits
exist.
Note that if e = f then the limits in (6) and (7) are decreasing limits as we observed in
Proposition 3.4. So the previous lemma combined with equation (5) gives us that for any
e âˆˆ V (G) Ã— K we have
lim h(Pn )Ã—Cn ÏˆÌ„n e, ÏˆÌ„n ei â‰¤ hPÃ—C e, ei.

nâ†’âˆž

Combining this with Proposition 3.4, we get that
(8)

hQe, ei = lim h(Pn )/Cn ÏˆÌ„n e, ÏˆÌ„n ei â‰¤ hP/C e, ei.
nâ†’âˆž

On the other hand, from Lemma 3.12, we know that
E

X

kâˆˆK

hQ(o, k), (o, k)i = Tr(G, o, Q) = lim Tr(Gn , on , (Pn )/Cn )
nâ†’âˆž

= lim Tr(Gn , on , Pn ) = Tr(G, o, P ) = Tr(G, o, P/C )
nâ†’âˆž
X
=E
hP/C (o, k), (o, k)i.
kâˆˆK

imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

18

From this and inequality (8) we get that hQ(o, k), (o, k)i = hP/C (o, k), (o, k)i for all
k âˆˆ K with probability 1, so from unimodularity ([2, Lemma 2.3 (Everything shows at the
root)]) it follows that
(9)

hQe, ei = lim h(Pn )/Cn ÏˆÌ„n e, ÏˆÌ„n ei = hP/C e, ei
nâ†’âˆž

for all e âˆˆ V (G) Ã— K with probability 1.
Now we prove that with probability 1 for every e, f âˆˆ V (G) Ã— K we have hQe, f i =
hP/C e, f i. This is clear if e âˆˆ C , because in that case P/C e = Qe = e. So assume that e 6âˆˆ C ,
then
|hP/C e, f i âˆ’ hQe, f i| = |hPÃ—C e, f i âˆ’ hQe, f i|
â‰¤ |hPÃ—C e, f i âˆ’ hPÃ—C(r) e, f i|
+ |hPÃ—C(r) e, f i âˆ’ h(Pn )Ã—Cn (r) ÏˆÌ„n e, ÏˆÌ„n f i|
+ |h(Pn )Ã—Cn (r) ÏˆÌ„n e, ÏˆÌ„n f i âˆ’ h(Pn )Ã—Cn ÏˆÌ„n e, ÏˆÌ„n f i|
+ |h(Pn )Ã—Cn ÏˆÌ„n e, ÏˆÌ„n f i âˆ’ hQe, f i|.

Pick any Îµ > 0. If we choose a large enough r , then |hPÃ—C e, f i âˆ’ hPÃ—C(r) e, f i| < Îµ
and |hPÃ—C(r) e, ei âˆ’ hPÃ—C e, ei| < Îµ from equation (6). Fix such an r . Then if n is
large enough |hPÃ—C(r) e, f i âˆ’ h(Pn )Ã—Cn (r) ÏˆÌ„n e, ÏˆÌ„n f i| < Îµ from equation (5), and also
|h(Pn )Ã—Cn ÏˆÌ„n e, ÏˆÌ„n f i âˆ’ hQe, f i| < Îµ, because of Proposition 3.4 and the fact that e 6âˆˆ C .
Finally, observing that (Pn )Ã—Cn (r) âˆ’ (Pn )Ã—Cn is an orthogonal projection, we have
|h(Pn )Ã—Cn (r) ÏˆÌ„n e,ÏˆÌ„n f i âˆ’ h(Pn )Ã—Cn ÏˆÌ„n e, ÏˆÌ„n f i|
â‰¤ k(Pn )Ã—Cn (r) ÏˆÌ„n e âˆ’ (Pn )Ã—Cn ÏˆÌ„n ek2
q
= h(Pn )Ã—Cn (r) ÏˆÌ„n e âˆ’ (Pn )Ã—Cn ÏˆÌ„n e, ÏˆÌ„n ei

â‰¤ |h(Pn )Ã—Cn (r) ÏˆÌ„n e, ÏˆÌ„n ei âˆ’ hPÃ—C(r) e, ei|
+ |hPÃ—C(r) e, ei âˆ’ hPÃ—C e, ei|

1
2
+ |hPÃ—C e, ei âˆ’ h(Pn )Ã—Cn ÏˆÌ„n e, ÏˆÌ„n ei|

Now, for a large enough n we have |h(Pn )Ã—Cn (r) ÏˆÌ„n e, ÏˆÌ„n ei âˆ’ hPÃ—C(r) e, ei| < Îµ from equation (5) and |hPÃ—C e, ei âˆ’ h(Pn )Ã—Cn ÏˆÌ„n e, ÏˆÌ„n ei| = |hP/C e, ei âˆ’ h(Pn )/Cn ÏˆÌ„n e, ÏˆÌ„n ei| < Îµ from
line (9). Finally, |hPÃ—C(r) e, ei âˆ’ hPÃ—C e, ei| < Îµ follows from the choice of r . Putting everyâˆš
thing together, |hP/C e, f i âˆ’ hQe, f i| < 3Îµ + 3Îµ, so Lemma 3.19 follows.
This completes the proof of Lemma 3.17 and Theorem 3.16.
4. The proof of Theorem 2.4. First we observe that we may assume that |V (Gn )| â†’ âˆž.
If not, then we can take a large m = m(n) and replace Gn with m disjoint copies of Gn , and
Pn with the m fold direct sum of copies of Pn .
Let (G, P ) be a finite graph-positive-contraction, where P is an orthogonal projection. Let m = |V (G) Ã— L|. Fix an ordering e1 , e2 , . . . , em of the element of V (G) Ã— L.
Let Ei = {e1 , e2 , . . . , ei }. For e âˆˆ V (G) Ã— L let I(e) be the indicator of the event that e âˆˆ B P .
Let g(x) = âˆ’x log x âˆ’ (1 âˆ’ x) log(1 âˆ’ x). Using the chain rule for the conditional entropy
and Lemma 3.6 we obtain that
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

19

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

hL (G, P ) = H(I(e1 ), I(e2 ), . . . , I(em ))
=

mâˆ’1
X

H(I(ei+1 )|I(e1 ), I(e2 ), . . . , I(ei ))

i=0

=

mâˆ’1
X

X

i=0 CâŠ‚Ei

=

mâˆ’1
X
i=0

=

mâˆ’1
X
i=0

P[B P âˆ© Ei = C]g(P[ei+1 âˆˆ B P |B P âˆ© Ei = C])

Eg(P[ei+1 âˆˆ B P/(Ei âˆ©BP )âˆ’(Ei \BP ) ])
Eg(hP/(Ei âˆ©B P )âˆ’(Ei \B P ) ei+1 , ei+1 i).

Here expectation is over the random choice of B P .
Instead of a fixed ordering of V (G) Ã— L we can choose a uniform random ordering. Taking
expectation we get that
hL (G, P ) =

mâˆ’1
X
i=0

Eg(hP/(Ei âˆ©B P )âˆ’(Ei \B P ) ei+1 , ei+1 i),

where expectation is over the random choice of Ei = {e1 , e2 , . . . , ei } and B P . Note that
g(0) = g(1) = 0, so
g(hP/(Ei âˆ©B P )âˆ’(Ei \B P ) e, ei) = 0

whenever e âˆˆ Ei . Also note that ei+1 is a uniform random element of (V (G) Ã— L)\Ei . From
these it follows that if e is a uniform random element of V (G) Ã— L independent of Ei , then
(10)
Thus,

m
Eg(hP/(Ei âˆ©B P )âˆ’(Ei \B P ) e, ei) = Eg(hP/(Ei âˆ©B P )âˆ’(Ei \B P ) ei+1 , ei+1 i) â‰¤ log 2.
mâˆ’i

hL (G, P ) =

mâˆ’1
X
i=0

Let (G, o, P ) = U (G, P ). Then
hL (G, P ) =

mâˆ’1
X
i=0

So

m
Eg(hP/(Ei âˆ©B P )âˆ’(Ei \B P ) e, ei).
mâˆ’i

m 1 X
E
g(hP/(Ei âˆ©B P )âˆ’(Ei \B P ) (o, â„“), (o, â„“)i).
m âˆ’ i |L|
â„“âˆˆL

mâˆ’1
X
hL (G, P ) X 1
=
E
g(hP/(Ei âˆ©B P )âˆ’(Ei \B P ) (o, â„“), (o, â„“)i).
|V (G)|
mâˆ’i
i=0

â„“âˆˆL

For t âˆˆ [0, 1) we define

Ht (G, P ) = E

X

g(hP/(Ei âˆ©B P )âˆ’(Ei \B P ) (o, â„“), (o, â„“)i),

â„“âˆˆL

imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

20

where i = âŒŠtmâŒ‹, and Ei is a uniform random i element subset of V (G) Ã— L independent of
B P and o. For i = 0, 1, . . . , m âˆ’ 1, we have
Z (i+1)/m
X
1
m
E
Ht (G, P )dt.
g(hP/(Ei âˆ©B P )âˆ’(Ei \B P ) (o, â„“), (o, â„“)i) =
mâˆ’i
m âˆ’ âŒŠtmâŒ‹
i/m
â„“âˆˆL

Therefore

hL (G, P )
=
|V (G)|

(11)

Z

1

0

m
Ht (G, P )dt.
m âˆ’ âŒŠtmâŒ‹

Let mn = |V (Gn ) Ã— L|. Recall that we observed at the beginning of the proof that we may
assume that |V (Gn )| â†’ âˆž. So we assume this.
L EMMA 4.1. Let (Gn , Pn ) be the sequence given in the statement of the theorem. For
any t âˆˆ [0, 1) we have
X
lim Ht (Gn , Pn ) = E
g(hP/(Et âˆ©B P )âˆ’(Et \B P ) (o, â„“), (o, â„“)i),
nâ†’âˆž

â„“âˆˆL

where Et is a Bernoulli(t) percolation of the set V (G) Ã— L independent of B P . Consequently,
X
1
mn
Ht (Gn , Pn ) =
E
g(hP/(Et âˆ©B P )âˆ’(Et \B P ) (o, â„“), (o, â„“)i).
lim
nâ†’âˆž mn âˆ’ âŒŠtmn âŒ‹
1âˆ’t
â„“âˆˆL

P ROOF. From Proposition 2.1 we have (Gn , on , Pn , B Pn ) â†’ (G, o, P, B P ). It is straightforward to show that (Gn , on , Pn , EâŒŠtmn âŒ‹ ) â†’ (G, o, P, Et ), here mn = |V (G) Ã— L| and
EâŒŠtmn âŒ‹ is a uniform âŒŠtmn âŒ‹ element subset of V (G) Ã— L independent of B Pn . Then
it follows that (Gn , on , Pn , EâŒŠtmn âŒ‹ , B Pn ) â†’ (G, o, P, Et , B P ). But then with the notations Cn = EâŒŠtmn âŒ‹ âˆ© B Pn , C = Et âˆ© B P , Dn = EâŒŠtmn âŒ‹ \B Pn and D = Et \B P we
have (Gn , on , Pn , Cn , Dn ) â†’ (G, o, P, C, D). It follows from Theorem 3.8 and Proposition 3.9, that (Cn , Dn ) and (C, D) are all permitted with probability 1. It is also
clear that (Gn , on , Pn , Cn , Dn ) are unimodular. Thus applying Theorem 3.16 we get
that (Gn , on , (Pn )/Cn âˆ’Dn ) converge
to (G, o, P/Câˆ’D ). We define the continuous map
P
f : RGPC â†’ R as f (G, o, P ) = â„“âˆˆL g(hP (o, â„“), (o, â„“)i). Then from the definition of weak*
convergence we get that
lim Ef (Gn , on , (Pn )/Cn âˆ’Dn ) = Ef (G, o, P/Câˆ’D )

nâ†’âˆž

and this is exactly what we needed to prove.
mn
From (10) we have mn âˆ’âŒŠm
Ht (G, P ) â‰¤ log 2 for any n and t. So combining equation
nâŒ‹
(11) and Lemma 4.1 with the dominated convergence theorem we get that
Z 1
hL (Gn , Pn )
mn
(12) lim
= lim
Ht (Gn , Pn )dt
nâ†’âˆž |V (Gn )|
nâ†’âˆž 0 mn âˆ’ âŒŠtmn âŒ‹
Z 1
mn
Ht (Gn , Pn )dt
=
lim
0 nâ†’âˆž mn âˆ’ âŒŠtmn âŒ‹
Z 1
X
1
E
g(hP/(Et âˆ©B P )âˆ’(Et \B P ) (o, â„“), (o, â„“)i)dt
=
0 1âˆ’t
â„“âˆˆL

imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

21

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

=

Z

1
0



1 X
P[(o, â„“) 6âˆˆ Et ]E g(hP/(Et âˆ©B P )âˆ’(Et \B P ) (o, â„“), (o, â„“)i) (o, â„“) 6âˆˆ Et dt
1âˆ’t
â„“âˆˆL

=

1X

Z

0 â„“âˆˆL



E g(hP/(Et âˆ©B P )âˆ’(Et \B P ) (o, â„“), (o, â„“)i) (o, â„“) 6âˆˆ Et dt.

Here we used the law of total expectation and the fact that
g(hB P/(Et âˆ©BP )âˆ’(Et \BP ) (o, â„“), (o, â„“)i) = 0 whenever (o, â„“) âˆˆ Et . Let c be an i.i.d. uniform [0, 1]
labeling of V (G) Ã— L. Observe that conditioned on the event (o, â„“) 6âˆˆ Et the distribution of Et
is the same as the distribution of {e âˆˆ V (G) Ã— L|c(e) < c(o, â„“)} conditioned on c(o, â„“) = t.
Let I(e) be the indicator of the event e âˆˆ B restL P . From Lemma 3.15 we get for â„“ âˆˆ L
Z 1


E g(hP/(Et âˆ©B P )âˆ’(Et \B P ) (o, â„“), (o, â„“)i) (o, â„“) 6âˆˆ Et dt
0

=

Z

=

Z

1

0
1
0



E g(E(I(o, â„“)|{I(f )|f âˆˆ Et })) (o, â„“) 6âˆˆ Et dt


E g(E(I(o, â„“)|{I(f )|c(f ) < c(o, â„“)})) c(o, â„“) = t dt

= E [g(E(I(o, â„“)|{I(f )|c(f ) < c(o, â„“)}))] = EhÌ„((o, â„“), restL P ).

Combining this with equation (12) we get Theorem 2.4.
5. Extension of Theorem 2.4 to positive contractions. To state the extension of Theorem 2.4 we need another tightness notion. Let K0 âŠƒ K be finite. A random RGPC
(G0 , o0 , T0 ) with support set K0 is called an K0 -extension of the random RGPC (G, o, T )
with support set K , if (G0 , o0 , restK (T0 )) has the same distribution as (G, o, T ). We say that
the extension is tight if T0 is an orthogonal projection with probability 1. A finite graphpositive-contraction (G0 , T0 ) with support set K0 is called an K0 -extension of the finite
graph-positive-contraction (G, T ) with support set K , if G = G0 and restK T0 = T . We say
that the extension is tight, if T0 is an orthogonal projection.
Given a sequence of finite graph-positive-contractions (Gn , Tn ) with support K and a
random RGPC (G, o, T ) with support set K , we say that lim U (Gn , Tn ) = (G, o, T ) p-tightly,
if there is a finite K0 âŠƒ K and there are tight K0 -extensions (Gn , Pn ) of (Gn , Tn ) and a tight
K0 -extension (G, o, P ) of (G, o, T ) such that lim U (Gn , Pn ) = (G, o, P ).
With these definitions we have the following extension of Theorem 2.4.
T HEOREM 5.1. Let (Gn , Tn ) be a sequence of finite graph-positive-contractions such
that lim U (Gn , Tn ) = (G, o, T ) p-tightly for some random RGPC (G, o, T ). Then
lim

nâ†’âˆž

hL (Gn , Tn )
= hÌ„L (G, o, T ).
|V (Gn )|

P ROOF. By the definition of tight convergence, there is a finite K0 âŠƒ K and there are
tight K0 -extensions (Gn , Pn ) of (Gn , Tn ) and a tight K0 -extension (G, o, P ) of (G, o, T )
such that lim U (Gn , Pn ) = (G, o, P ). Note that the distribution of B Tn is the same as
B Pn âˆ© (V (G) Ã— K). So hL (Gn , Tn ) = hL (Gn , Pn ). Similarly, hÌ„L (G, o, T ) = hÌ„L (G, o, P ).
So from Theorem 2.4
hL (Gn , Pn )
hL (Gn , Tn )
= lim
= hÌ„L (G, o, P ) = hÌ„L (G, o, T ).
lim
nâ†’âˆž |V (Gn )|
nâ†’âˆž |V (Gn )|
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

22

We do not know whether the condition of p-tightness can be replaced with tightness in the
theorem above.
Later we will need the following proposition.
P ROPOSITION 5.2. Let K âŠ‚ K0 , such that |K0 | = 2|K|. Any finite graph-positivecontraction (G, T ) has a tight K0 -extension (G, P ).
P ROOF. This is well known, see for
p example [13, Chapter 9]. We include the proof for
the readerâ€™s convenience. Let q(x) = x(1 âˆ’ x) on the interval [0, 1] and 0 otherwise. Using
functional calculus we can define q(T ), for every positive contraction. Then the block matrix


T q(T )
P=
q(T ) I âˆ’ T

gives the desired operator.

The K0 -extension given in the previous lemma will be called the standard K0 -extension
of (G, T ). The standard K0 -extension of a random RGPC is defined in the analogous way.
6. Sofic entropy: The proof of Theorem 2.6. Note that for any graph G the set of
random {0, 1}K colorings of V (G) can be identified with the set of random subsets of
V (G) Ã— K . In this proof we use the random subset terminology.
As we mentioned in Subsection 2.7, the inequality hâ€² (B T ) â‰¤ hÌ„(GÎ“ , eÎ“ , T ) is well known,
but we give the proof for completeness.
Let G be a graph, and F be a random subset of V (G) Ã— K . Let c be a [0, 1] labeling
of V (G) Ã— K . For e âˆˆ V (G) Ã— K let I(e) be the indicator of the event that e âˆˆ F . For
(v, k) âˆˆ V (G) Ã— K we define
hÌ„((v, k), c, F ) = H(I(v, k)|{I(v â€² , k â€² )|c(v â€² , kâ€² ) < c(v, k)}).

We also define
hÌ„((v, k), F ) = EhÌ„((v, k), c, F ),

where c is an i.i.d. uniform [0, 1] labeling of V (G) Ã— K .
Moreover, if r is an integer, then we define
hÌ„r ((v, k), c, F ) = H(I(v, k)|{I(v â€² , k â€² )|c(v â€² , kâ€² ) < c(v, k) and (v â€² , k â€² ) âˆˆ Br (G, v) Ã— K})

and

hÌ„r ((v, k), F ) = EhÌ„r ((v, k), c, F ),

where c is an i.i.d. uniform [0, 1] labeling of V (G) Ã— K .
Comparing these definitions with the definitions given in Subsection 2.7, we see that if
F = B T for some positive contraction T , then hÌ„((v, k), F ) = hÌ„((v, k), T ). Thus, it is justified
the use the same symbol in both cases.
If c is a [0, 1]-labeling such that the labels are pairwise distinct and G is finite, the chain
rule of conditional entropy gives us
X
hÌ„((v, k), c, F ).
H(F ) =
(v,k)âˆˆV (G)Ã—K

Taking expectation over c we get that
H(F ) =

X

hÌ„((v, k), F ).

(v,k)âˆˆV (G)Ã—K

imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

23

Or, alternatively,
X
H(F )
=E
hÌ„((o, k), F )
|V (G)|
kâˆˆK

where o is a uniform random vertex of V (G).
Combining this with the well known monotonicity properties of conditional entropies, for
any integer r , we have
X
X
H(F )
=E
hÌ„((o, k), F ) â‰¤ E
hÌ„r ((o, k), F ).
|V (G)|
kâˆˆK

kâˆˆK

Note that hÌ„r ((o, k), F ) only depends on the distribution of F âˆ© (Br (G, o) Ã— K). Therefore,
if F is an (Îµ, r) approximation, then we have
X
X
H(F )
â‰¤E
hÌ„r ((o, k), F ) â‰¤
hÌ„r ((eÎ“ , k), B T ) + Î·r (Îµ),
|V (G)|
kâˆˆK

kâˆˆK

where Î·r (Îµ) does not depend on G, and Î·r (Îµ) â†’ 0 as Îµ â†’ 0. In particular,
X
H(Îµ, r) â‰¤
hÌ„r ((eÎ“ , k), B T ) + Î·r (Îµ)
kâˆˆK

tending to 0 with Îµ we obtain that

inf H(Îµ, r) â‰¤
Îµ

But we have
lim

râ†’âˆž

X

X

hÌ„r ((eÎ“ , k), B T ).

kâˆˆK

hÌ„r ((eÎ“ , k), B T ) =

kâˆˆK

X

hÌ„((eÎ“ , k), B T ).

kâˆˆK

Thus tending to infinity with r we get
X
hâ€² (B T ) â‰¤
hÌ„((eÎ“ , k), B T ) = hÌ„(GÎ“ , eÎ“ , T ).
kâˆˆK

Now let G1 , G2 , . . . be a sequence of finite S -labeled Schreier graphs Benjamini-Schramm
converging to (GÎ“ , eÎ“ ). Let K âŠ‚ K0 , such that |K0 | = 2|K|. Let P be the standard K0 extension of T . Then it is clear that P is an invariant operator on â„“2 (V (GÎ“ ) Ã— K0 ).
L EMMA 6.1. There is a sequence of positive contractions Rn on â„“2 (V (Gn ) Ã— K0 ) such
that limnâ†’âˆž U (Gn , Rn ) = (GÎ“ , eÎ“ , P ). Moreover, the spectral measures Âµn = ÂµU (Gn ,Rn )
weakly converge to Âµ = Âµ(GÎ“ ,eÎ“ ,P ) = |K|(Î´0 + Î´1 ).

P ROOF. One can easily define a metric dâ€² on P(RGPC) such that for any
sequence of positive contractions Rn on â„“2 (V (Gn ) Ã— K0 ), we have that
limnâ†’âˆž dâ€² (U (Gn , Rn ), (GÎ“ , eÎ“ , P )) = 0 if and only if limnâ†’âˆž U (Gn , Rn ) = (GÎ“ , eÎ“ , P )
and Âµn weakly converge to Âµ.
Thus if the required sequence does not exist, then there is an Îµ > 0 and an infinite sequence n1 < n2 < . . . such that dâ€² (U (Gni , Rni ), (GÎ“ , eÎ“ , P )) â‰¥ Îµ for any i and any positive
contractions Rni on â„“2 (V (Gni ) Ã— K0 ).
We will now use the results of Lyons and Thom [15]. In their paper they are using ultralimits. However, by passing to a subsequence we may replace ultralimits by actual limits.
Thus [15, Proposition 4.4, Lemma 4.7 and Remark 4.3] provide us a subsequence (mi ) of
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

24

(ni ) and positive contractions Rmi on â„“2 (V (Gmi ) Ã— K0 ), such that limiâ†’âˆž U (Gmi , Rmi ) =
(GÎ“ , eÎ“ , P ) and Âµmi weakly converge to Âµ. Indeed, [15, Proposition 4.4] gives us the convergence limiâ†’âˆž U (Gmi , Rmi ) = (GÎ“ , eÎ“ , P ) and [15, Proposition 4.7] is used to make sure
Rmi is indeed a positive contraction. Finally, the convergence of spectral measures follows
from [15, Remark 4.3].
Then limiâ†’âˆž dâ€² (U (Gmi , Rmi ), (GÎ“ , eÎ“ , P )) = 0, which contradicts to the choice of the
subsequence (ni ).
Finally, observe that
Tr(GÎ“ , eÎ“ , P ) = Tr(GÎ“ , eÎ“ , T ) + Tr(GÎ“ , eÎ“ , I âˆ’ T ) = |K|,

so the spectral measure Âµ is indeed equal to |K|(Î´0 + Î´1 ).

Note that Rn is not necessary an orthogonal projection. Now we modify Rn slightly to get
an orthogonal projection. Let us define
(
x
for 0 â‰¤ x < 21 ,
w(x) =
x âˆ’ 1 for 21 â‰¤ x â‰¤ 1
|V (G )Ã—K |

0
Note that w is not continuous, but w2 is continuous. Let (vi )i=1 n
be an orthonormal
basis of â„“2 (V (Gn )Ã— K0 ) consisting of eigenvectors of Rn , such that Rn vi = Î»i vi . Let w(Rn )
be the unique operator, such that w(Rn )vi = w(Î»i )vi for i = 1, 2, . . . , |V (Gn ) Ã— K0 |.
Then Pn = Rn âˆ’ w(Rn ) will be the orthogonal projection to the span of {vi |Î»i â‰¥ 21 }.
Moreover,

(13)

lim E

nâ†’âˆž

X

kâˆˆK0

kw(Rn )(o, k)k22 = lim E
nâ†’âˆž

= lim

Z

X

kâˆˆK0

nâ†’âˆž 0

1

hw(Rn )2 (o, k), (o, k)i

w2 dÂµn =

Z

1

w2 dÂµ

0

2

2

= |K|(w (0) + w (1)) = 0

Here the expectation is over a uniform random vertex o of V (Gn ). This easily implies that
U (Gn , Rn ) and U (Gn , Pn ) have the same limit, that is, lim U (Gn , Pn ) = (GÎ“ , eÎ“ , P ). (Note
that in the language of [15] the vanishing limit in (13) means that (Rn ) and (Pn ) represent
the same operator.) Now using Theorem 2.4 we get that
H(B restK (Pn ) )
= lim hK (Gn , Pn )
nâ†’âˆž
nâ†’âˆž
|V (Gn )|
lim

= hÌ„(GÎ“ , eÎ“ , restK (P )) = hÌ„(GÎ“ , eÎ“ , T ).

Now for any Îµ and r for large enough n we have that B restK (Pn ) is an (Îµ, r)-approximation
of B T , because limnâ†’âˆž U (Gn , rest(Pn )) = (GÎ“ , eÎ“ , T ). So hÌ„(GÎ“ , eÎ“ , T ) â‰¤ h(B T ) follows.
Putting everything together we get that hÌ„(GÎ“ , eÎ“ , T ) â‰¤ h(B T ) â‰¤ hâ€² (B T ) â‰¤ hÌ„(GÎ“ , eÎ“ , T ).
So Theorem 2.6 follows.
7. Tree entropy. Let G = (V, E) be a locally finite connected graph. Choose an orienta~ . The vertex-edge incidence matrix A = (ave )
tion of each edge to obtain the oriented graph G
~ is a V Ã— E matrix such that
of G
ï£±
ï£´
if e enters v ,
ï£²1
ave = âˆ’1 if e leaves v ,
ï£´
ï£³
0
otherwise.
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

25

~ be the closed subspace of â„“2 (E) generated by the rows of A, and let Pâ‹†
Let â‹† = â‹†(G)
be the orthogonal projection from â„“2 (E) to â‹†. If G is finite, then the determinantal measure
corresponding to Pâ‹† is the uniform measure on the spanning trees of G [9]. Let Ï„ (G) be the
number of spanning trees of G, then H(B Pâ‹† ) = log Ï„ (G). If G is infinite, the corresponding
determinantal measure is the so-called wired uniform spanning forest(WUSF) [17, 10, 5, 12].
Note that in both cases, the resulting measure does not depend on the chosen orientation of
G.
Given a rooted graph (G, o) and a non-negative integer k , let pk (G, o) be the probability
that a simple random walk starting at o is back at o after k steps.
The following theorem was proved by Lyons [14].

T HEOREM 7.1. Let Gn be a sequence of finite connected graphs, such that |V (Gn )| â†’
âˆž and their Benjamini-Schramm limit is a random rooted graph (G, o). Then
!
âˆž
X
1
log Ï„ (Gn )
= E log deg(o) âˆ’
pk (G, o) .
lim
nâ†’âˆž |V (Gn )|
k
k=1

Using our results we can give another expression for the limiting quantity. Let G be a
connected locally finite infinite graph, let F be the WUSF of G. For e âˆˆ E(G) let I(e) be the
indicator of the event that e âˆˆ F. Given a [0, 1] labeling c of E(G) and an edge e âˆˆ E(G) we
define
hÌ„(G, e, c) = H(I(e)|{I(f )|c(f ) < c(e)}),

and
hÌ„(G, e) = EhÌ„(G, e, c),

where the expectation is over the i.i.d. uniform random [0, 1] labeling of G. Now we state our
version of the tree entropy theorem.
T HEOREM 7.2. Let Gn be a sequence of finite connected graphs, such that |V (Gn )| â†’
âˆž and their Benjamini-Schramm limit is a random rooted graph (G, o). Then
log Ï„ (Gn ) 1 X
lim
hÌ„(G, e),
= E
nâ†’âˆž |V (Gn )|
2 eâˆ¼o

where the summation is over the edges e incident to the root o.

~ o) be the random rooted oriented graph obtained from (G, o) by orientP ROOF. Let (G,
~
ing each edge independently and uniformly to one of the two possible directions. Let L(G)
~
~
~
be the line graph of G, that is the vertex set of L(G) is V (G) and two vertices of L(G)
~ are adjacent. Let (G
~ â€² , oâ€² ) be obtained from
are connected if the corresponding edges in G
~
(G, o) by biasing by the degree of the root. Let e be a uniform random edge incident to oâ€² .
~ â€² ), e, P ~ â€² ) will be a random RGPC, which we denote by (L, e, P ). (Here the
Then (L(G
â‹†(G )
~ n of Gn such
support set K of (L, e, P ) is a one element set.) Now there is an orientation G
~ n is (G,
~ o). This can be proved by choosing random
that the Benjamini-Schramm limit of G
orientations, and using concentration results. We omit the details. Let (Ln , Pn ) be the finite~ n ), P ~ ). We have the following lemma.
graph-contraction (L(G
â‹†(Gn )

L EMMA 7.3.

We have limnâ†’âˆž U (Ln , Pn ) = (L, e, P ).

imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

26

P ROOF. This can be proved by slightly modifying the argument of the proof of
[2, Proposition 7.1].
The proof can be finished using Theorem 2.4.
Both Lyonsâ€™s and our theorem can be extended to edge weighted graphs, but in this case
they are about two different quantities. However, these two quantities are closely related as
we explain now. Let G be a connected finite graph, and assume that each
Q edge e has a positive
weight w(e). The weight of a spanning tree T is defined as w(T ) = eâˆˆT w(T ). Let
X
Z(G, w) =
w(T )
T is a spanning tree

be the sum of the weights of the spanning trees of G. Let F be a random spanning tree of
G, such that for any spanning tree T we have P(F = T ) = Z(G, w)âˆ’1 w(T ). This is again
a determinantal process, the only difference compared to the uniform case is that for each
edge
pe we need to multiply the corresponding column of the vertex-edge incidence matrix
by w(e). In fact, this is the way we define the weighted version of the WUSF for infinite
graphs. The Shannon entropy H(F) of F is related to Z(G, w) by the identity

(14)

H(F) = log Z(G, w) âˆ’ E log w(F).

Let (Gn , wn ) be a Benjamini-Schramm convergent sequence of weighted connected
graphs, such that |V (Gn )| â†’ âˆž and their Benjamini-Schramm limit is a random rooted
weighted graph (G, o, w). Assume that the weights are uniformly bounded away from zero
and infinity, that is, there are 0 < C1 < C2 < âˆž such that all the weight are from the interval
[C1 , C2 ]. Then the generalization of Lyonsâ€™s theorem states that
!
âˆž
X
log Z(Gn , wn )
1
lim
= E log Ï€(o) âˆ’
pk,w (G, o) ,
nâ†’âˆž
|V (Gn )|
k
k=1

where Ï€(v) is total weight of the edges incident to v , and pk,w (G, o) is defined using the random walk with transition probabilities p(x, y) = Ï€(x)âˆ’1 w(xy) instead of the simple random
walk. On the other hand our theorem states that
H(Fn )
1 X
lim
hÌ„(G, e, w),
= E
nâ†’âˆž |V (Gn )|
2 eâˆ¼o

where hÌ„(G, e, w) is defined as above, but using the weighted version of the WUSF.
These two statements above together with equation (14) of course imply that
limnâ†’âˆž |V (Gn )|âˆ’1 E log w(Fn ) exists. However, there is a more direct proof. It is based
on the observation that
X
1
E log w(Fn )
P(e âˆˆ Fn ) log w(e)
=
|V (Gn )|
|V (Gn )|
eâˆˆE(Gn )

1 X
P(e âˆˆ Fn ) log w(e),
= E
2 eâˆ¼o

where the last expectation is over a uniform random o âˆˆ V (Gn ). Since we know that the
limit of Fn is F, where F is the WUSF of the random rooted weighted graph (G, o, w) (see
[2, Proposition 7.1]) we get that
E log w(Fn ) 1 X
= E
P(e âˆˆ F) log w(e).
lim
nâ†’âˆž |V (Gn )|
2 eâˆ¼o
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

27

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

Using equation (14), this provides us another formula for the
limnâ†’âˆž |V (Gn )|âˆ’1 log Z(Gn , wn ). Namely,

log Z(Gn , wn ) 1 X
lim
P(e âˆˆ F) log w(e) + hÌ„(G, e, w) .
= E
nâ†’âˆž
|V (Gn )|
2 eâˆ¼o

limit

Q UESTION 7.4. We have seen that if (G, o) is an infinite random rooted graph which is
the limit of finite connected graphs, then
!
âˆž
X
1
1 X
E log deg(o) âˆ’
hÌ„(G, e).
pk (G, o) = E
k
2 eâˆ¼o
k=1

Is this true for any infinite unimodular random rooted graph?

APPENDIX: MEASURABILITY OF THE POLAR DECOMPOSITION
The key idea is that we can realize every operator on a single fixed Hilbert-space. This
can be done by using the canonical representatives defined by Aldous and Lyons in a slightly
different setting. See Section 2 of [2]. Now we give the details. Let us call a RGO (G, o, T )
half-canonical if the following hold. If G is finite then V (G) = [0, |V (G)| âˆ’ 1] âŠ‚ N, if G
is infinite then V (G) = N, the root o is equal to 0, moreover Br (G, o) = [0, |Br (G, o)| âˆ’ 1]
for all r . If G is infinite then T is an operator on the Hilbert space H = â„“2 (N Ã— K). If
G is finite we will still consider T as an operator on H by setting T (v, k) to be 0 for all
(v, k) âˆˆ (N\V (G)) Ã— K . Let HC be the set of half-canonical RGOs. We endow HC with a
metric as follows. Given two elements (G1 , 0, T1 ) and (G2 , 0, T2 ) of HC , their distance is
defined as the infimum of Îµ > 0 such that for r = âŒŠÎµâˆ’1 âŒ‹ we have that G1 and G2 are the same
restricted to the vertices [0, r], moreover
|hT1 (v, k), (v â€² , k â€² )i âˆ’ hT2 (v, k), (v â€² , kâ€² )i| < Îµ

for every v, v â€² âˆˆ [0, r] and k, kâ€² âˆˆ K . Then the obvious map g : HC â†’ RGO is continuous.
The next lemma shows that we can go the other direction too.
L EMMA A.5. There is a measurable map from f : RGO â†’ HC such that for any
(G, o, T ) âˆˆ RGO we have that (G, o, T ) and f (G, o, T ) are isomorphic as RGOs. In other
words g â—¦ f = id.
P ROOF. The construction given in Section 2 of [2] can be adopted to this situation.
Let B(H) be the set of bounded linear operators on H . We endow B(H) with a measurable structure by considering the coarsest Ïƒ -algebra such that all the B(H) â†’ R maps
T 7â†’ hT e, f i are measurable for e, f âˆˆ N Ã— K . We also endow H with the measurable structure coming from the norm k Â· k2 .
L EMMA A.6. Let T be a B(H)-valued measurable map, x be an H -valued measurable
map defined on the same measurable space. Then T x is an H -valued measurable map.
P ROOF. Let e1 , e2 , . . . be an enumeration of N Ã— K . Then T x is the pointwise limit of
ï£¶
ï£«
n
n
X
X
ï£­ hx, ej ihT ej , ei iï£¸ ei .
yn =
i=1

j=1

Since yn is measurable, T x is measurable too.
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

28

This also has the following consequence.
L EMMA A.7. Let S and T be B(H)-valued measurable maps. Then ST is a B(H)valued measurable map.
P ROOF. Let e, f âˆˆ N Ã— K . Then ST e = S(T e), here T e is an H -valued measurable map,
so S(T e) is an H -valued measurable map. So hST e, f i is measurable.
Given a B(H)-valued measurable map T , let T + be its generalized inverse. Note that T +
is not necessary bounded. We need the following theorem.
T HEOREM A.8 ([16]).

For any x âˆˆ H the map T + x is an H -valued measurable map.

From this we obtain the following lemma.
L EMMA A.9. Let T be a B(H)
-valued measurable map, and let T = U P be its unique
âˆš
polar decomposition, i.e. P = Aâˆ— A and U = T P + . Then U is a B(H)-valued measurable
map.
P ROOF. From Lemma A.7 (Aâˆ— A)n is a measurable map for all n. Approximating the
square root function by polynomials we get that P is a B(H)-valued measurable map. The
statement follows by combining Theorem A.8 and the argument of the proof of Lemma A.7.
Then it is not difficult to prove the following.
L EMMA A.10. For an RGO (G, o, T ) let T = U P be the polar decomposition of T , then
the map (G, o, T ) 7â†’ (G, o, U ) is measurable.
Acknowledgements. The author is grateful to MiklÃ³s AbÃ©rt for the useful discussions
throughout the writing of this paper, to Russel Lyons and the anonymous referee for their
valuable comments. The author was partially supported by the ERC Consolidator Grant
648017.
REFERENCES
[1] A BÃ‰RT, M. and W EISS , B. In preparation.
[2] A LDOUS , D. and LYONS , R. (2007). Processes on unimodular random networks. Electronic Journal of
Probability 12 1454â€“1508.
[3] AUSTIN , T. (2016). Additivity properties of sofic entropy and measures on model spaces. In Forum of
Mathematics, Sigma 4. Cambridge University Press.
[4] AUSTIN , T. and P ODDER , M. (2018). Gibbs measures over locally tree-like graphs and percolative entropy
over infinite regular trees. Journal of Statistical Physics 170 932â€“951.
[5] B ENJAMINI , I., LYONS , R., P ERES , Y. and S CHRAMM , O. (2001). Special invited paper: uniform spanning
forests. Annals of probability 1â€“65.
[6] B ENJAMINI , I. and S CHRAMM , O. (2000). Recurrence of distributional limits of finite planar graphs. Electron. J. Probab. 6 1â€“13.
[7] B ORGS , C., C HAYES , J., K AHN , J. and L OVÃSZ , L. (2013). Left and right convergence of graphs with
bounded degree. Random Structures & Algorithms 42 1â€“28.
[8] B OWEN , L. (2010). Measure conjugacy invariants for actions of countable sofic groups. Journal of the
American Mathematical Society 23 217â€“245.
[9] B URTON , R. and P EMANTLE , R. (1993). Local characteristics, entropy and limit theorems for spanning
trees and domino tilings via transfer-impedances. The Annals of Probability 1329â€“1371.
imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

LIMITING ENTROPY OF DETERMINANTAL PROCESSES

29

[10] H Ã„GGSTRÃ–M , O. (1998). Uniform and minimal essential spanning forests on trees. Random Structures &
Algorithms 12 27â€“50.
[11] H EICKLEN , D. and LYONS , R. (2003). Change intolerance in spanning forests. Journal of Theoretical
Probability 16 47â€“58.
[12] LYONS , R. (1998). A birdâ€™s-eye view of uniform spanning trees and forests. Microsurveys in discrete probability 41 135â€“162.
[13] LYONS , R. (2003). Determinantal probability measures. Publications MathÃ©matiques de lâ€™IHÃ‰S 98 167â€“
212.
[14] LYONS , R. (2005). Asymptotic enumeration of spanning trees. Combinatorics, Probability and Computing
14 491â€“522.
[15] LYONS , R. and T HOM , A. (2016). Invariant coupling of determinantal measures on sofic groups. Ergodic
Theory and Dynamical Systems 36 574â€“607.
[16] NASHED , M. Z. and S ALEHI , H. (1973). Measurability of generalized inverses of random linear operators.
SIAM Journal on Applied Mathematics 25 681â€“692.
[17] P EMANTLE , R. (1991). Choosing a spanning tree for the integer lattice uniformly. The Annals of Probability
1559â€“1574.
[18] S EWARD , B. (2016). Weak containment and Rokhlin entropy. arXiv preprint arXiv:1602.06680.

imsart-aop ver.

2020/04/06 file:

aop1435.tex date:

May 26, 2020

