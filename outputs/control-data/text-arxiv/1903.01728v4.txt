Mining Dual Emotion for Fake News Detection

arXiv:1903.01728v4 [cs.CL] 14 Feb 2021

Xueyao Zhangâ€ 

Juan Caoâˆ—â€ 

Institute of Computing Technology,
Chinese Academy of Sciences
University of Chinese Academy of
Sciences
zhangxueyao19s@ict.ac.cn

Institute of Computing Technology,
Chinese Academy of Sciences
University of Chinese Academy of
Sciences
caojuan@ict.ac.cn

Qiang Shengâ€ 

Lei Zhongâ€ 

Institute of Computing Technology,
Chinese Academy of Sciences
University of Chinese Academy of
Sciences
shengqiang18z@ict.ac.cn

Institute of Computing Technology,
Chinese Academy of Sciences
University of Chinese Academy of
Sciences
zhonglei18s@ict.ac.cn

Xirong Liâˆ—

Key Lab of Data Engineering and
Knowledge Engineering, Renmin
University of China
Beijing, China
xirong@ruc.edu.cn

Kai Shu

Illinois Institute of Technology
Chicago, Illinois, USA
kshu@iit.edu

ABSTRACT

1

Emotion plays an important role in detecting fake news online.
When leveraging emotional signals, the existing methods focus on
exploiting the emotions of news contents that conveyed by the publishers (i.e., publisher emotion). However, fake news often evokes
high-arousal or activating emotions of people, so the emotions of
news comments aroused in the crowd (i.e., social emotion) should
not be ignored. Furthermore, it remains to be explored whether
there exists a relationship between publisher emotion and social
emotion (i.e., dual emotion), and how the dual emotion appears in
fake news. In this paper, we verify that dual emotion is distinctive
between fake and real news and propose Dual Emotion Features to
represent dual emotion and the relationship between them for fake
news detection. Further, we exhibit that our proposed features can
be easily plugged into existing fake news detectors as an enhancement. Extensive experiments on three real-world datasets (one in
English and the others in Chinese) show that our proposed feature
set: 1) outperforms the state-of-the-art task-related emotional features; 2) can be well compatible with existing fake news detectors
and effectively improve the performance of detecting fake news.1 2

In recent years, fake news on social media has threatened not only
cyberspace security, but also the real-world order in politics [14],
economy [12], society [2], etc. The most recent example is the
concomitant infodemic during the COVID-19 pandemic across the
world [41]. Thousands of news pieces with misleading content have
been spreading through social media [44] and led to socio-economic
disorder [6] and weakened the effect of pandemic prevention [4].
To tackle this issue, researchers have been devoted to developing
automatic methods to detect fake news (i.e., designing a classifier
to judge a given news piece as real or fake) by leveraging signals
from text [5, 32, 34], images [20, 35], or social contexts [17, 24, 26â€“
28, 39, 40]. 3
In existing text-based works [1, 5, 15], the role of sentimental
or emotional signals has been considered for fake news detection.
Ajao et al. [1] point out that there exists a relationship between
news veracity and the sentiments of the posted text, and append a
sentimental feature (the ratio of the number of negative and positive
words) to help text-only fake news detectors. Instead of appending a
sole feature, Giachanou et al. [15] extract richer emotional features
from the news contents based on emotional lexicons for fake news
detection. To the best of our knowledge, most existing works leverage the emotional signals of fake news content conveyed by the
publishers but rarely focus on the emotions of fake news comments
aroused in the crowd. However, for spreading in the crowd virally,
fake news often evokes high-arousal or activating emotions of the
crowd [37]. Therefore, in addition to emotions of news contents,
it is necessary to explore whether emotions of news comments
and the relationship between the two emotions are helpful for fake
news detection.
To describe the two emotions clearly, we define them respectively
as 1) publisher emotion: the emotions conveyed by publishers of
the news pieces; and 2) social emotion: the emotions aroused in
the crowd facing to the news pieces. And we adopt dual emotion
as a general term of these two emotions. For a news piece, dual

ACM Reference Format:
Xueyao Zhang, Juan Cao, Xirong Li, Qiang Sheng, Lei Zhong, and Kai Shu.
2021. Mining Dual Emotion for Fake News Detection. In Proceedings of the
Web Conference 2021 (WWW â€™21), April 19â€“23, 2021, Ljubljana, Slovenia. ACM,
New York, NY, USA, 12 pages. https://doi.org/10.1145/3442381.3450004
âˆ— Corresponding

authors
Key Laboratory of Intelligent Information Processing of Chinese Academy of
Sciences. Also at State Key Laboratory of Communication Content Cognition, Peopleâ€™s
Daily Online.
1 Please kindly note that the examples in this paper contain offensive and swear words.
2 The code and datasets are released at https://github.com/RMSnow/WWW2021.
â€  At

This paper is published under the Creative Commons Attribution 4.0 International
(CC-BY 4.0) license. Authors reserve their rights to disseminate the work on their
personal and corporate Web sites with the appropriate attribution.
WWW â€™21, April 19â€“23, 2021, Ljubljana, Slovenia
Â© 2021 IW3C2 (International World Wide Web Conference Committee), published
under Creative Commons CC-BY 4.0 License.
ACM ISBN 978-1-4503-8312-7/21/04.
https://doi.org/10.1145/3442381.3450004

3 In

INTRODUCTION

this paper, we use news pieces to refer to social media news posts. A news piece
generally contains content and its attached comments.

WWW â€™21, April 19â€“23, 2021, Ljubljana, Slovenia

Xueyao Zhang, Juan Cao, Xirong Li, Qiang Sheng, Lei Zhong, and Kai Shu

Publisher emotion: Angry

CONTENT

A massacre happened with a violent house demolition, killing a
family of seven! But the disgusting local government is still
blocking the news. Waiting for a thorough investigation!
Social emotion: Angry

COMMENTS
Another f**king house demolition!

...
The killers will not confess their crimes easily!

relationship in dual emotion can be indicative of the news veracity
and should be considered when modeling.
To model the dual emotion and emotion resonances and dissonances for fake news detection, we propose Dual Emotion Features to represent publisher emotion, social emotion and the similarity
and difference of the dual emotion jointly. Besides, it is convenient to
implement and plug the features into existing fake news detectors
as an enhancement.
In this paper, our contributions are summarized as follows:
â€¢ We propose and verify that the dual emotion (i.e., publisher
emotion and social emotion) signal is distinctive between fake
and real news.
â€¢ We firstly propose the feature set, Dual Emotion Features, to
comprehensively represent dual emotion and the relationship between the two kinds of emotions, and exhibit how
to plug it into the fake news detectors as a complement and
enhancement.
â€¢ We conduct experiments on the real-world datasets, including a newly-constructed Chinese dataset. The results demonstrate that: 1) Dual Emotion Features outperforms the existing
emotional features for fake news detection. 2) It can be compatible with existing fake news detectors and effectively
improve the performance of the detectors.

...
The disgusting government!

(a) Emotion resonance in a fake news piece: the publisher emotion
and social emotion are both angry.
Publisher emotion: Happy

CONTENT

Exciting! On the 70th Anniversary of the Victory of the
Anti-Japanese War, Prime Minister of Japan resigns officially. It is
worth celebrating for every Chinese!
Social emotion: Angry

COMMENTS
Donâ€™t readily believe in rumors!

...
So stupid of you. Donâ€™t spread it any more!

...
Too naive... Think twice before talking.

(b) Emotion dissonance in a fake news piece: the publisher emotion
is happy while the social emotion is angry.

Figure 1: Two fake news pieces on Chinese microblog platform Weibo, with different Dual Emotion. The texts are
translated from Chinese to English manually.

emotion has two appearances: emotion resonances (i.e., the publisher emotion is same or similar to the social emotion) and emotion
dissonances (i.e., the publisher emotion is different from the social
emotion). We analyze the data and find that the two appearances
have a statistically significant distinction between fake and real
news (see details in Section 4.2). For example, as to the emotion
resonance, there are more fake news pieces whose dual emotion are
both angry than real news, while as to the emotion dissonances,
more fake news pieces whose publisher emotion is happy while
social emotion is angry. Figure 1 shows two representative examples selected from fake news pieces on Weibo 4 . In Figure 1a, the
fake news publisher conveys its rage with expressions like â€œmassacreâ€, â€œkillingâ€, â€œdisgustingâ€. As a result, the great indignation of
the crowd is evoked, shown by â€œf**kingâ€, â€œkillersâ€, and â€œdisgustingâ€. In Figure 1b, the fake news publisher expresses happiness
with â€œExciting!â€ and â€œcelebratingâ€. While the crowd considers it
as a ridiculous news piece, and use â€œreadily believeâ€, â€œSo stupidâ€
and â€œToo naiveâ€ to express their disgust and contempt to the publisher. The data observation statistical findings highlight that the
4 https://www.weibo.com

2

RELATED WORK

Fake news detection is also known as false news detection, rumor detection, misinformation detection, etc. [33] and is closely
connected to the field of information credibility evaluation. In the
earliest study on information credibility evaluation, Castillo et al.
[5] manually extract content features, publisher features, topic features, and propagation features from news pieces. And the work
finds that sentiment-based features like the fraction of sentimental
words and exclamation marks are effective for evaluating information credibility. In recent years, researchers begin to utilize deep
learning models such as GRU-based and CNN-based models for
fake news detection [26, 47]. Beyond news content, social contexts
such as texts of comments and reposts [17, 26â€“28, 38], viewpoints
and stances of the crowd [19, 22], and user credibility[24, 40] are
emphasized as well.
There are also existing works focusing on discovering the distinctive emotional signals between fake and real news. Ajao et al. [1]
verify that there exists a relationship between news veracity (real
or fake) and the usage of sentimental words, and design an emotion
feature (the ratio of the count of negative and positive words) to
help detect fake news. Besides, Giachanou et al. [15] extract emotion features based on emotional lexicons from news contents for
fake news detection. However, these works only leverage the emotional signals of fake news contents but ignore the emotions of fake
news comments and the relationship between the two emotions.
Recently, Wu and Rao [45] propose an adaptive fusion network for
fake news detection, modeling emotion embeddings from the contents and the comments. However, this work focuses on adaptively
fusing various features by advanced deep learning models, and do
not explore the specific distinction of dual emotion signals between
fake and real news. So far, the work that pays attention to mining
dual emotion signals from publishers and crowds remains vacant.

Mining Dual Emotion for Fake News Detection

WWW â€™21, April 19â€“23, 2021, Ljubljana, Slovenia

CONTENT

Dual Emotion
Features

a) Publisher Emotion

A massacre happened with a violent house
demolition, killing a family of seven! But the
disgusting local government is still blocking the
news. Waiting for a thorough investigation!

COMMENTS
Mean
pooling

Another f**king house demolition!

...

...

b) Social Emotion

The killers will not confess their crimes easily!

Concat

Concat

...

...

Max
pooling

The disgusting government!

Subtraction

Subtraction

c) Emotion Gap
...
...

A
massacre
...

...
...

BiGRU

Mean
pooling

......

...
Fake

investigation

...
Concat

MLP

Softmax

d) Fake News Detector

Real

Figure 2: An overall framework of using Dual Emotion Features for fake news detection. Dual Emotion Features consist of three
components: a) Publisher Emotion extracted from the content; b) Social Emotion extracted from the comments; c) Emotion
Gap representing the similarity and difference between publisher emotion and social emotion. Dual Emotion Features are
concatenated with the features from d) Fake News Detector (here, BiGRU as an example) for the final prediction of veracity.

3

MODELING DUAL EMOTION FOR FAKE
NEWS DETECTION

To model dual emotion signals for fake news detection, we propose
Dual Emotion Features, which can leverage publisher emotion, social emotion, and the similarity and difference of the dual emotion.
Figure 2 exhibits the process of obtaining Dual Emotion Features and
integrating them into an existing fake news detector as an enhancement to classify a given piece of news. In this section, we detail the
feature extraction of publisher emotion and social emotion, and the
modeling of emotion gap. Then, we describe the process to plug
Dual Emotion Featuresinto the existing fake news detectors.

3.1

Publisher Emotion

To comprehensively represent the Publisher Emotion, we use a variety of features extracted from news contents, including the emotion
category, emotional lexicon, emotional intensity, sentiment score,
and other auxiliary features. In the five kinds of features, emotion
category, emotional intensity and sentiment score provide the overall information and the other two provide word- and symbol-level
information.
Given the input sequence of the textual content with length ğ¿,
T = [ğ‘¡ 1, ğ‘¡ 2, . . . , ğ‘¡ğ‘– , . . . , ğ‘¡ğ¿ ], where ğ‘¡ğ‘– is the ğ‘– ğ‘¡â„ word in the text, the
goal is to extract emotion features ğ‘’ğ‘šğ‘œ T from the text T .
3.1.1 Emotion Category. We use public emotion classifiers (which
will be introduced in Section 4.2) to get emotion category features.
Usually, the output of an emotion classifier is the probabilities that
the given text contains certain emotions.
Given the emotion classifier ğ‘“ and the text T , we assume the
dimension of the output is ğ‘‘ ğ‘“ and thus the prediction of the text is

ğ‘“ (T ). So we can obtain the emotion category features ğ‘’ğ‘šğ‘œ ğ‘ğ‘ğ‘¡ğ‘’
=
T
ğ‘“ (T ), where ğ‘’ğ‘šğ‘œ ğ‘ğ‘ğ‘¡ğ‘’
âˆˆ Rğ‘‘ ğ‘“ .
T
3.1.2 Emotional Lexicon. Usually, a piece of text conveys specific
emotions by using several specific words (which are generally included in emotional lexicons). Thus, we next extract the features
based on the emotional lexicon. The approach is dependent on the
existing emotion dictionaries annotated by experts. In the emotion
dictionary, we assume that there are ğ‘‘ğ‘’ kinds of emotions, denoted
as ğ¸ = {ğ‘’ 1, ğ‘’ 2, . . . , ğ‘’ğ‘‘ğ‘’ }. For the emotion ğ‘’ âˆˆ ğ¸, the dictionary provides a list of emotional words Eğ‘’ = {ğ‘¤ğ‘’,1, ğ‘¤ğ‘’,2, . . . , ğ‘¤ğ‘’,ğ¿ğ‘’ }, where
ğ¿ğ‘’ is the length of the emotion lexicon of ğ‘’ in the dictionary.
Given the text T , we gradually aggregate the scores of each
word and the whole text across all the emotions for rich representation. For one of the emotions ğ‘’, we firstly calculate the word-level
score ğ‘  (ğ‘¡ğ‘– , ğ‘’), where ğ‘¡ğ‘– is ğ‘– ğ‘¡â„ word in the text T . If the word ğ‘¡ğ‘– is in
the dictionary Eğ‘’ , we consider not only its occurrence frequency,
but also its contextual words (specifically, degree words and negation words). For example, in the sentence â€œI am not very joyful
todayâ€ (the length of the sentence is 6), â€œjoyfulâ€ belongs to the
emotion happy and its occurrence frequency is 1/6. Assume that
we only consider the left context and the window size is 2 (i.e., the
context words are â€œnotâ€ and â€œveryâ€). When we set the negation
value of â€œnotâ€ as -1 and the degree value of â€œveryâ€ as 2, the final
ğ‘  ( ğ‘—ğ‘œğ‘¦ğ‘“ ğ‘¢ğ‘™, ğ‘’â„ğ‘ğ‘ğ‘ğ‘¦ ) = âˆ’1 âˆ— 2 âˆ— (1/6) = âˆ’1/3. In practice, we use the
existing emotion dictionary to match and calculate the values of
negation and degree words. As described above, ğ‘  (ğ‘¡ğ‘– , ğ‘’) is defined
in Equation 1:

ğ‘  (ğ‘¡ğ‘– , ğ‘’) =

1Eğ‘’ (ğ‘¡ğ‘– ) âˆ— ğ‘›ğ‘’ğ‘”(ğ‘¡ğ‘– , ğ‘¤) âˆ— ğ‘‘ğ‘’ğ‘”(ğ‘¡ğ‘– , ğ‘¤)
ğ¿

(1)

WWW â€™21, April 19â€“23, 2021, Ljubljana, Slovenia


1Eğ‘’ (ğ‘¡ğ‘– ) =

Xueyao Zhang, Juan Cao, Xirong Li, Qiang Sheng, Lei Zhong, and Kai Shu

1,

ğ‘– ğ‘“ ğ‘¡ğ‘– âˆˆ Eğ‘’

0,

ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’

(2)

where ğ‘¤ is the window size of the left context. And ğ‘›ğ‘’ğ‘”(ğ‘¡ ğ‘— )
(Equation 3) and ğ‘‘ğ‘’ğ‘”(ğ‘¡ ğ‘— ) (Equation 4) are respectively the negation
value and degree value of ğ‘¡ ğ‘— , which can be looked up according to
the emotion dictionary.
ğ‘›ğ‘’ğ‘”(ğ‘¡ğ‘– , ğ‘¤) =

ğ‘–âˆ’1
Ã–

ğ‘›ğ‘’ğ‘”(ğ‘¡ ğ‘— )

(3)

ğ‘‘ğ‘’ğ‘”(ğ‘¡ ğ‘— )

(4)

ğ‘—=ğ‘–âˆ’ğ‘¤

ğ‘‘ğ‘’ğ‘”(ğ‘¡ğ‘– , ğ‘¤) =

ğ‘–âˆ’1
Ã–

3.1.5 Other Auxiliary Features. Considering that the above features do not explicitly exploit the information beyond emotion
dictionaries, we introduce a set of auxiliary features to capture the
emotional signals behind the non-word elements, including emoticons, punctuations, and uppercase letters (only for English). Also,
we add the frequency of sentimental words and personal pronouns
to enhance the awareness of the usersâ€™ word usages. Take emoticons as an example. The emoticons are universal for emotional
expression across the world, such as â€œ: )â€ for â„ğ‘ğ‘ğ‘ğ‘¦, â€œ: (â€ for ğ‘ ğ‘ğ‘‘. Besides, punctuations like â€œ!â€ and â€œ?â€ can also convey peopleâ€™s moods
and emotions. Table 1 summarizes the auxiliary features used in
the Dual Emotion Features. Assume that there are ğ‘‘ğ‘ features, and
we can extract the other auxiliary features ğ‘’ğ‘šğ‘œ ğ‘ğ‘¢ğ‘¥
âˆˆ Rğ‘‘ğ‘ .
T

ğ‘—=ğ‘–âˆ’ğ‘¤

We then calculate text-level score on the specific emotion ğ‘’,
denoted as ğ‘  (T , ğ‘’), by summing the scores of each word in the text,
as Equation 5 shows:
ğ‘  (T , ğ‘’) =

ğ¿
âˆ‘ï¸

ğ‘  (ğ‘¡ğ‘– , ğ‘’),

Type

Emoticons

(5)

âˆ€ğ‘’ âˆˆ ğ¸

ğ‘–=1

Finally, the emotional lexicon features ğ‘’ğ‘šğ‘œ ğ‘™ğ‘’ğ‘¥
are obtained by
T
concatenating all the scores of the ğ‘‘ğ‘’ emotions (Equation 6), where
âŠ• is the concatenation operator, and ğ‘’ğ‘šğ‘œ ğ‘™ğ‘’ğ‘¥
âˆˆ Rğ‘‘ğ‘’ .
T
ğ‘’ğ‘šğ‘œ ğ‘™ğ‘’ğ‘¥
T = ğ‘  (T , ğ‘’ 1 ) âŠ• ğ‘  (T , ğ‘’ 2 ) âŠ• Â· Â· Â· âŠ• ğ‘  (T , ğ‘’ğ‘‘ğ‘’ )

(6)

3.1.3 Emotional Intensity. As for emotional lexicons, we also consider the emotional intensity of the lexicons. For example, when
expressing the emotion â„ğ‘ğ‘ğ‘ğ‘¦, the word â€œecstaticâ€ owns a higher
intensity than â€œjoyfulâ€. The extracting process is similar to that of
the emotional lexicon features, except for that we here include the
intensity scores. Given the emotions ğ¸, the emotional word list Eğ‘’
for every emotion ğ‘’, and the text T , we first calculate the intensityaware text-level scores ğ‘  â€² (T , ğ‘’) by summing the intensity-weighted
word-level scores, as shown in Equation 7:
ğ‘  â€² (T , ğ‘’) =

ğ¿
âˆ‘ï¸

ğ‘  â€² (ğ‘¡ğ‘– , ğ‘’) =

ğ‘–=1

ğ¿
âˆ‘ï¸

ğ‘–ğ‘›ğ‘¡ (ğ‘¡ğ‘– ) âˆ— ğ‘  (ğ‘¡ğ‘– , ğ‘’),

âˆ€ğ‘’ âˆˆ ğ¸

(7)

â€²
â€²
â€²
ğ‘’ğ‘šğ‘œ ğ‘–ğ‘›ğ‘¡
T = ğ‘  (T , ğ‘’ 1 ) âŠ• ğ‘  (T , ğ‘’ 2 ) âŠ• Â· Â· Â· âŠ• ğ‘  (T , ğ‘’ğ‘‘ğ‘’ )

âˆˆ

Sentimental Words

Personal Pronoun
Others
(For English corpus)

The frequency of uppercase letters

Table 1: Auxiliary Feature List

To get the Publisher Emotion of the text T from the content, we
concatenate all five kinds of features described above and obtain
ğ‘’ğ‘šğ‘œ T , as shown in Equation 9:

ğ‘–=1

where ğ‘–ğ‘›ğ‘¡ (ğ‘¡ğ‘– ) denotes the intensity score of the word ğ‘¡ğ‘– . If ğ‘¡ğ‘– is in
the dictionary, ğ‘–ğ‘›ğ‘¡ (ğ‘¡ğ‘– ) can be calculated according to the emotion
dictionary, otherwise ğ‘–ğ‘›ğ‘¡ (ğ‘¡ğ‘– ) = 0.
The emotional intensity features ğ‘’ğ‘šğ‘œ ğ‘–ğ‘›ğ‘¡
can be obtained by conT
catenating all the intensity scores of ğ‘‘ğ‘’ kinds of emotions, as shown
in Equation 8:

where ğ‘’ğ‘šğ‘œ ğ‘–ğ‘›ğ‘¡
T

Punctuations

Features
The frequency of happy emoticons
The frequency of angry emoticons
The frequency of surprised emoticons
The frequency of sad emoticons
The frequency of neutral emoticons
The frequency of exclamation mark
The frequency of question mark
The frequency of ellipsis mark
The frequency of positive sentimental words
The frequency of negative sentimental words
The frequency of degree words
The frequency of negation words
The frequency of pronoun first
The frequency of pronoun second
The frequency of pronoun third

(8)

Rğ‘‘ğ‘’ .

3.1.4 Sentiment Score. In addition to the emotion-level features described above, we also consider the coarse-grained sentiment score
of the text. Usually, the sentiment score is a positive or negative
value, which represents the degree of the positive or negative polarity of the whole text. And it can be calculated by using sentiment
dictionaries or public toolkits. Assuming that the dimension of the
sentiment score is ğ‘‘ğ‘  (usually, ğ‘‘ğ‘  = 1), we can get the sentiment
score feature ğ‘’ğ‘šğ‘œ ğ‘ ğ‘’ğ‘›ğ‘¡ğ‘–
âˆˆ Rğ‘‘ğ‘  .
T

ğ‘–ğ‘›ğ‘¡
ğ‘ ğ‘’ğ‘›ğ‘¡ğ‘–
ğ‘’ğ‘šğ‘œ T = ğ‘’ğ‘šğ‘œ ğ‘ğ‘ğ‘¡ğ‘’
âŠ• ğ‘’ğ‘šğ‘œ ğ‘™ğ‘’ğ‘¥
âŠ• ğ‘’ğ‘šğ‘œ ğ‘ğ‘¢ğ‘¥
T
T âŠ• ğ‘’ğ‘šğ‘œ T âŠ• ğ‘’ğ‘šğ‘œ T
T

(9)

where ğ‘’ğ‘šğ‘œ T âˆˆ Rğ‘‘ (i.e., ğ‘‘ = ğ‘‘ ğ‘“ + 2ğ‘‘ğ‘’ + ğ‘‘ğ‘  + ğ‘‘ğ‘ ).

3.2

Social Emotion

We first extract Social Emotion from the comments of a news piece
and then aggregate them as the whole representation. The comments of a news piece are denoted as M = [M1, M2, . . . , Mğ‘– , . . . ,
Mğ¿M ], where Mğ‘– is the ğ‘– ğ‘¡â„ comment of the news piece, and ğ¿ M is
the length of comment list. As for Mğ‘– , we can calculate its emotion
vector ğ‘’ğ‘šğ‘œ Mğ‘– by Equation 9, where ğ‘’ğ‘šğ‘œ Mğ‘– âˆˆ Rğ‘‘ . Then we stack
the transposed emotion vector (row vector) of every comment to
obtain the whole emotion vector of comments ğ‘’ğ‘šğ‘œ
Â›
M , as shown in
Equation 10:
T
T
T
ğ‘’ğ‘šğ‘œ
Â›
M = ğ‘’ğ‘šğ‘œ M âŠ• ğ‘’ğ‘šğ‘œ M âŠ• Â· Â· Â· âŠ• ğ‘’ğ‘šğ‘œ M
1

ğ¿M Ã—ğ‘‘ .
where ğ‘’ğ‘šğ‘œ
Â›
M âˆˆR

2

ğ¿M

(10)

Mining Dual Emotion for Fake News Detection

WWW â€™21, April 19â€“23, 2021, Ljubljana, Slovenia

After getting ğ‘’ğ‘šğ‘œ
Â›
M , we consider two aggregators to generate
the Social Emotion of the whole comment list: 1) Mean pooling for
representing the average emotional signals (Equation 11); and 2)
max pooling for capturing the extreme emotional signals (Equation 12).
ğ‘’ğ‘šğ‘œğ‘šğ‘’ğ‘ğ‘›
= ğ‘šğ‘’ğ‘ğ‘›(ğ‘’ğ‘šğ‘œ
Â›
M)
M

(11)

ğ‘’ğ‘šğ‘œğ‘šğ‘ğ‘¥
Â›
M)
M = ğ‘šğ‘ğ‘¥ (ğ‘’ğ‘šğ‘œ

(12)

where ğ‘’ğ‘šğ‘œğ‘šğ‘’ğ‘ğ‘›
, ğ‘’ğ‘šğ‘œğ‘šğ‘ğ‘¥
âˆˆ Rğ‘‘ .
M
M
Finally, we concatenate them as the Social Emotion:
ğ‘’ğ‘šğ‘œ M = ğ‘’ğ‘šğ‘œğ‘šğ‘’ğ‘ğ‘›
âŠ• ğ‘’ğ‘šğ‘œğ‘šğ‘ğ‘¥
M
M
where ğ‘’ğ‘šğ‘œ M âˆˆ

3.3

(13)

R2ğ‘‘ .

Emotion Gap

To model the resonances and dissonances of dual emotion, we
propose Emotion Gap (denoted as ğ‘’ğ‘šğ‘œ ğ‘”ğ‘ğ‘ ). It is designed as the subtraction between Publisher Emotion and Social Emotion. As shown
in Equation 14, ğ‘’ğ‘šğ‘œ ğ‘”ğ‘ğ‘ is concatenated by the difference of ğ‘’ğ‘šğ‘œ T
and ğ‘’ğ‘šğ‘œğ‘šğ‘’ğ‘ğ‘›
and the difference of ğ‘’ğ‘šğ‘œ T and ğ‘’ğ‘šğ‘œğ‘šğ‘ğ‘¥
:
M
M
ğ‘šğ‘ğ‘¥
ğ‘’ğ‘šğ‘œ ğ‘”ğ‘ğ‘ = (ğ‘’ğ‘šğ‘œ T âˆ’ ğ‘’ğ‘šğ‘œğ‘šğ‘’ğ‘ğ‘›
M ) âŠ• (ğ‘’ğ‘šğ‘œ T âˆ’ ğ‘’ğ‘šğ‘œ M )

(14)

where ğ‘’ğ‘šğ‘œ ğ‘”ğ‘ğ‘ âˆˆ R2ğ‘‘ . By this means, it can measure the differences (i.e., dissonances) between the dual emotion. For emotions
resonances, the values in the Emotion Gap vector are tiny (nearly
zero).

3.4

Dual Emotion Features

Finally, Dual Emotion Features are concatenated by the Publisher
Emotion, the Social Emotion and the Emotion Gap. In Equation 15
we obtain the Dual Emotion Features, where ğ‘’ğ‘šğ‘œ ğ‘‘ğ‘¢ğ‘ğ‘™ âˆˆ R5ğ‘‘ .
ğ‘’ğ‘šğ‘œ ğ‘‘ğ‘¢ğ‘ğ‘™ = ğ‘’ğ‘šğ‘œ T âŠ• ğ‘’ğ‘šğ‘œ M âŠ• ğ‘’ğ‘šğ‘œ ğ‘”ğ‘ğ‘

(15)

After getting Dual Emotion Features, we can concatenate it with
representations that extracted by the fake news detectors, which
is exemplified by Figure 2. Assuming that the fake news detector
is BiGRU and the output feature vector is denoted as ğµğ‘–ğºğ‘…ğ‘ˆ T , the
concatenated vector [ğµğ‘–ğºğ‘…ğ‘ˆ T , ğ‘’ğ‘šğ‘œ ğ‘‘ğ‘¢ğ‘ğ‘™ ] is fed into a multi-layer
perceptron (MLP) layer and a softmax layer for the final prediction
^ as shown in Equation 16:
of news veracity ğ‘¦,

ğ‘¦^ = Softmax MLP([ğµğ‘–ğºğ‘…ğ‘ˆ T , ğ‘’ğ‘šğ‘œ ğ‘‘ğ‘¢ğ‘ğ‘™ ])
(16)

4

EXPERIMENTS AND EVALUATION

In this section, we conduct experiments to compare our proposed
Dual Emotion Features and other baseline features and explore
their roles in improving the performance of fake news detection.
Specifically, we mainly answer the following evaluation questions:
â€¢ EQ1: Are Dual Emotion Features more effective than baseline
features when used alone for fake news detection? How
effective are the different types of features in Dual Emotion
Features?
â€¢ EQ2: Can Dual Emotion Features help improve the performance of text-based fake news detectors?

â€¢ EQ3: How robust do the fake news detection models with
Dual Emotion Features in real-world scenarios?
â€¢ EQ4: How effective are the components of Dual Emotion
Features, including the publisher emotion, social emotion,
and emotion gap?

4.1

Dataset

Although the emotions are believed universal, albeit affected by culture [11], how emotions are expressed and perceived varies across
different socio-cultural backgrounds [36]. Thus, we conduct experiments on three real-world datasets in two languages (meanwhile,
two countries with different cultures), one in English (RumourEval19) and two in Chinese (Weibo-16 and Weibo-20). The statistics of
these datasets are shown in Table 2.
4.1.1 RumourEval-19. The dataset RumourEval-19 is constructed
for determining the veracity of the rumors on Twitter and Reddit.
It is released in an academic evaluation5 [16]. Each news piece is
labeled as fake, real, or unverified. We keep the same dataset splits
and evaluation criteria as what the organizers provide.
4.1.2 Weibo-16. The dataset Weibo-16 is firstly proposed in [26]
and has been a benchmark dataset of fake news detection in Chinese
[17, 38, 47]. Each news piece is labeled as fake or real. It needs to
be clarified that in the original dataset, the subset of fake news
has many duplications. Concerned about the influence to learning
and evaluation by duplications, we perform deduplication on the
subset of fake news based on a clustering algorithm based on text
similarity. As a result, the amount of clusters is only 59% of the
original amount of fake pieces. We suppose that the duplication
may increase the risk of data leakage when splitting training and
testing sets and make models tend to learn some event-specific
features[42] (as they may repeat multiple times in the training
process), which limits the generalizability of models. Therefore,
we filtered out the highly similar fake news pieces and produce a
deduplication version of Weibo-16 (Table 2). We also clustered real
news pieces but found no duplications in Weibo-16. As an empirical
supplement of our analysis, we conduct comparison experiments
between the original and the deduplication version of Weibo-16,
and verified the necessity of deduplication (see details in Appendix
A). In our experiments in the main text, the deduplicated Weibo-16
is divided into train / val. / test sets in the ratio of 3:1:1.
4.1.3 Weibo-20. As a benchmark Chinese dataset for fake news
detection, Weibo-16 contains fake news pieces ranging from Dec
2010 to April 2014, and is not extended until now. Besides, the scale
of Weibo-16 is smaller after deduplication (Section 4.1.2). Therefore,
we constructed the dataset Weibo-20 on the basis of Weibo-16.
We keep the two-class setting (i.e., fake or real for each news
pieces). For fake news, we retain the 1,355 fake news pieces of
Weibo-16 and further collect news pieces judged as misinformation
officially by Weibo Community Management Center6 (the same
source of fake news of Weibo-16 [26]) ranging from April 2014 to
Nov 2018. And we filter out the highly similar fake news pieces and
guarantee there are no duplications. For real news, we retain the
2,351 real news pieces of Weibo-16 and gather 850 unique real news
5 SemEval-2019

Task 7: http://alt.qcri.org/semeval2019/index.php?id=tasks

6 https://service.account.weibo.com/

WWW â€™21, April 19â€“23, 2021, Ljubljana, Slovenia

Xueyao Zhang, Juan Cao, Xirong Li, Qiang Sheng, Lei Zhong, and Kai Shu

Veracity

Training

Validating

Testing

Total

Fake
Real
Unverified
Total
Fake
Real
Unverified
Total
Fake
Real
Unverified
Total
Fake
Real
Unverified
Total

RumourEval-19
#pcs
#com
79
1,135
144
1,905
104
1,838
327
4,878
19
824
10
404
9
212
38
1,440
40
689
31
805
10
181
81
1,675
138
2,648
185
3,114
123
2,231
446
7,993

Weibo-16
#pcs
# com
801
649,673
1,410
482,226
2,211 1,131,899
268
222,149
470
146,948
738
369,097
286
193,740
471
179,942
757
373,682
1,355 1,065,562
2,351
809,116
3,706 1,874,678

Weibo-20
#pcs
#com
1,896
749,141
1,920
516,795
3,816 1,265,936
632
137,941
640
185,087
1,272
323,028
633
245,216
641
149,260
1,274
394,476
3,161 1,132,298
3,201
851,142
6,362 1,983,440

Table 2: Statistics of the three datasets. #pcs: number of news pieces; #com: number of comments.

pieces in the same period as the fake news. The newly-collected real
news pieces are real news verified by NewsVerify7 which focuses
on discovering and verifying suspicious news pieces on Weibo.
Totally, Weibo-20 contains 3,161 fake news pieces and 3,201 real
news pieces. As for dataset splits, we split train / val. / test sets in
the ratio of 3:1:1.

4.2

Preliminary Analysis of Dual Emotion
Signals

To check whether it is statistically dependent or not between dual
emotion signals and the veracity of news pieces, we construct two
categorical variables to do a chi-squared statistical significance test.
The one is News Veracity, whose value is Fake or Real. The other is
Dual Emotion Category, whose value is combined publisher emotion
category and social emotion category, such as publisher emotion
is none and social emotion is angry. To calculate the value of Dual
Emotion Category, we use the open-source emotion classification
model released by NVIDIA8 [21] for RumourEval-19, and use Emotion Detection Service on Baidu AI platform9 for the two Chinese
datasets. In the chi-squared statistical significance test, we firstly assume that the dual emotion signals are independent of the veracity
of news pieces (i.e., the null hypothesis). Then we check whether
the chi-squared statistic is over the critical value or not. Specifically,
on the dataset RumourEval-19, the chi-squared statistic is 50.570,
over the critical value of 48.602 for the probability of 95%, which
means we can reject the null hypothesis. Similarly, on the dataset
Weibo-16, the chi-squared statistic is 209.14, which is much more
than the critical value of 50.892 for the probability of 99%. And on
the dataset Weibo 20, the chi-squared statistic is 239.963, which is
much more than the critical value of 46.963 for the probability of
99%. In conclusion, we can reject the null hypothesis on all three
datasets, which indicates that dual emotion signals are statistically
dependent on news veracity.
7 https://www.newsverify.com/

8 https://github.com/NVIDIA/sentiment-discovery
9 https://ai.baidu.com/tech/nlp/emotion_detection

We visualize the variable Dual Emotion Category further. On RumourEval 19, we select three emotion categories to visualize, joyful,
sad and none (over 98% of news pieces covered). And on Chinese
datasets, we select four emotion categories, angry, disgusting, happy
and none (over 97% of news pieces covered). We utilize the heatmap
to exhibit the distribution of Dual Emotion Category in Figure 3. In
the heatmap, each cell represents the percentage of news pieces
whose Dual Emotion Category is the specific value. And we normalize the percentages for each row (i.e., each publisher emotion).
For example, in the top sub-figure of Figure 3a, the upper-left cell
indicates that among fake news pieces whose publisher emotion is
joyful, the percentage of pieces whose social emotion is also joyful
is 85.5%.
In Figure 3, we can see there are distinct emotion resonances and
emotion dissonances in fake news from real news. For example, in
Figure 3a, the percentage of dual emotion categories that are both
joyful in fake news is 8.2% higher than that of real news. And the
percentage of emotion dissonance with sad publisher emotion and
joyful social emotion in fake news is 1.9% higher than real news.
Evidence is stronger on the two Chinese datasets. Specifically, as
for emotion resonances, there are more news pieces whose dual
emotion categories are both angry and are both disgusting in fake
news than real news. As for emotion dissonances, there are more
news pieces emotion dissonances with are happy/none publisher
emotion but angry/disgusting social emotion in fake news.
It needs to be recognized that the specific emotion resonances
or dissonances may vary from English to Chinese datasets, since
the expression styles of people using different languages may be
also different. However, our analysis shows that on each dataset
itself, no matter what its dominant language is, the fake news owns
distinct emotion resonances and dissonances from real news, which
can be helpful for distinguishing the fake and real news.

4.3

Experimental Setup

4.3.1 Emotion Resources. For emotion classifiers, as described in
Section 4.2, we adopt the pretrained models of NVIDIA for English

Mining Dual Emotion for Fake News Detection

(a) On RumourEval-19

WWW â€™21, April 19â€“23, 2021, Ljubljana, Slovenia

(b) On Weibo-16

(c) On Weibo-20

Figure 3: The distribution of Dual Emotion Category on the three datasets. In fake news, there are distinct emotion resonances
and emotion dissonances from real news.
and Baidu AI for Chinese. To ensure the robustness of the two models, per language we randomly sampled 100 instances and had their
emotion categories manually and independently labeled by three
annotators, resulting the accuracy of 87% for NVIDIA model and
83% for Baidu model. Therefore, the two classifiers are considered
reliable for extracting emotions for fake news detection. As for
other emotion resources, for English corpus, we adopt NRC Emotion lexicon[30] and NRC Emotion Intensity lexicon[29] to extract
emotion lexicon and emotion intensity features, respectively. And
we use the Vader package of NLTK[3] to calculate sentiment scores.
For Chinese corpus, we adopt the Affective Lexicon Ontology[46]
to extract emotion lexicon and emotion intensity features. And we
utilize the dictionary HowNet[10] to calculate sentiment scores.
As for auxiliary features in Table 1, for emoticons, we utilize the
List of emoticons of Wikipedia[43] and divide emoticons into five
emotions: happy, angry, surprised, sad and neutral. For sentimental
words and degree words, we use the bilingual sentiment dictionary
in HowNet[10]. For negation words, we compile the words list from
Wikipedia, Oxford Dictionary, and Cambridge Dictionary.10
4.3.2 Fake News Detectors and Baselines. In the experiments, we
select two baseline emotion features to evaluate the effectiveness
of our Dual Emotion Features. These features are implemented with
the same emotion dictionaries as Dual Emotion Features:
â€¢ Emoratio: Ajao et al. [1] propose an emotion feature that
can be extracted from the content text of news pieces, named
10 The

negation word lists are released together with our code and datasets.

emoratio. It is calculated by the ratio of count of negative
emotional words and count of positive emotional words.
â€¢ EmoCred: Giachanou et al. [15] utilize the emotional lexicon and intensity features of the content texts. These features
are calculated based on the lexiconsâ€™ occurrence frequency.
For testing the ability of the emotional features to help the textbased fake news detectors (especially those that do not explicitly
model the emotional signals), we select BiGRU (as Figure 2 shows),
BERT, and other state-of-the-art fake news detectors as follows:
â€¢ BiGRU: Text-based models like GRU[8] and LSTM[18] are
proven effective for fake news detection in [7, 26]. Here we
use BiGRU to examine whether Dual Emotion Features can
improve it or not. In practice, as for word embeddings, we
use GloVe [31] for English and Chinese Word Vectors for
Chinese [25]. The max sequence length of ğµğ‘–ğºğ‘…ğ‘ˆ T is 100,
and the dimensionality of hidden state of ğµğ‘–ğºğ‘…ğ‘ˆ T is 32.
â€¢ BERT [9]: As a strong text classification model, BERT has
been adopted to represent semantic signals when detecting
fake news in [45]. In the experiments, we truncate the sequences to the maximum length of 512, and finetune the
pretrained models11 for our task.
â€¢ NileTMRG [13]: For RumourEval-19 dataset, we use the
model implemented by the competition organizers12 [16],
NileTMRG. The model is effective and outperforms other
11 The

pretrained models are downloaded from https://huggingface.co/models. We use
bert-base-uncased for English and bert-base-chinese for Chinese.
12 https://github.com/kochkinaelena/RumourEval2019

WWW â€™21, April 19â€“23, 2021, Ljubljana, Slovenia

contestantsâ€™ models of the leaderboard except for the champion. The model is a linear SVM and uses text features, social
features, and use comment stance features. In practice, we
keep all the hyperparameters of the original model.
â€¢ HSA-BLSTM [17]: For the two Chinese datasets, we implement the HSA-BLSTM, which is widely used as a baseline
on Weibo-16 dataset. The authors propose a hierarchical attention neural network and utilize not only the contents of
news pieces but also the comments. In experiments, we keep
all the hyperparameters as those in the original model.
4.3.3 Model Parameters. The dimensionalities of sub features in
Dual Emotion Features, i.e., ğ‘‘ ğ‘“ , ğ‘‘ğ‘’ , ğ‘‘ğ‘  and ğ‘‘ğ‘ , are determined by
the language-specific emotion resources. The value of ğ‘‘ ğ‘“ , as the
output of pretrained emotion classifiers, is 16 for English and 8 for
Chinese. The value of ğ‘‘ğ‘’ is the size of emotion kinds of the English
or Chinese emotion dictionaries, which is 8 or 21, respectively.
For ğ‘‘ğ‘  , sentiment scores of English texts, produced by the Vader
package of NLTK, correspond to four dimensions (positive, negative,
neutral and compound), while sentiment scores of Chinese texts are
calculated by HowNet, which have one dimension only. The value
of ğ‘‘ğ‘ is the number of the heuristic features in Table 1, which is 16
for English and 15 for Chinese. The full dimension ğ‘‘ is computed as
Equation 9, which is 52 for English and 66 for Chinese. The window
size is 2, which was determined by grid search that maximizes the
performance on the validation set. As for the amount of comments,
we set ğ¿ M = 100, which means that only the earliest 100 comments
(or less) of every news piece are considered. In Equation 16, the
output dimensionality of MLP is 32.
4.3.4 Evaluation Metrics. On RumourEval-19, we adopt the official
evaluation metrics, macro F1 score and RMSE (root mean squared
error) [16]. Considering the imbalance of the dataset, we also consider the F1 scores of fake, real, and unverified news. On the two
Weibo datasets, we use accuracy and macro F1 score as the evaluation metrics, the same as [17]. We also the F1 scores of fake and
real news. The other experiments use the macro F1 score.

4.4

Results

4.4.1 Effectiveness of Dual Emotion Features. To answer EQ1 under
the circumstance that the confounding factor of fake news detectors
is excluded, we utilize emotion features alone to detect fake news.
We adopt a simple five-layer MLP and feed only emotion features
into it. Table 3 displays the results on the three datasets.
Source

Emotion Features
R-19 W-16 W-20
Emoratio
0.185 0.553 0.524
Content
EmoCred
0.253 0.564 0.542
Publisher Emotion
0.290 0.571 0.573
Comments Social Emotion
0.296 0.692 0.754
Content, Emotion Gap
0.332 0.716 0.746
Comments Dual Emotion Features 0.337 0.728 0.759
Table 3: Macro F1 scores when only using emotion features
on the MLP model. R-19: RumourEval-19, W-16: Weibo-16,
W-20: Weibo-20.

Xueyao Zhang, Juan Cao, Xirong Li, Qiang Sheng, Lei Zhong, and Kai Shu

Removed type
R-19 W-16 W-20
Emotion Category
0.193 0.679 0.686
Emotion Lexicon
0.239 0.715 0.745
Emotional Intensity
0.216 0.725 0.750
Sentiment Score
0.245 0.723 0.743
Other Auxiliary Features 0.307 0.653 0.722
Table 4: Macro F1 scores of Dual Emotion Features when removing one specific type of emotion features on the MLP
model. R-19: RumourEval-19, W-16: Weibo-16, W-20: Weibo20.

In Table 3, among the three emotion features that source from
Content, Publisher Emotion is more effective than EmoCred and
Emoratio, especially on RumourEval. It reveals the effectiveness
of Dual Emotion Features in modeling emotional signals. Whatâ€™s
more, we can see the more improvements of Social Emotion and
Emotion Gap, which are first proposed to help detect fake news
in this paper. Specifically, on RumourEval-19, using Emotion Gap
owns 4.2% increase than Publisher Emotion. And on the two Chinese
datasets, using Social Emotion or Emotion Gap can both improve the
macro F1 score of more than 10%. Moreover, using Dual Emotion
Features can further obtain enhancements on the three datasets.
Especially on RumourEval-19, only using Dual Emotion Features for
fake news detection owns a high macro F1 score of 0.337. And only
using Emotion Gap is also effective, which is 0.332 for the macro F1
score. It is worth mentioning that such two emotion features even
outperform the state-of-the-art model NileTMRG (0.309 for macro
F1 score, shown in Table 5). That indicates the necessity of dual
emotion signals and the importance of mining dual emotion and the
relationship between them for fake news detection. Additionally,
it needs to be clarified that comparing the three datasets to each
other, the performances in RumourEval-19 are rather worse than
the two Chinese datasets. The reasons are discussed in [16, 23], that
the amount of news pieces is small and there is a relatively low
inter-annotator agreement for the dataset.
In Section 3.1, we adopt five types of emotion features when
modeling emotional signals (Emotion Category, Emotion Lexicon,
Emotional Intensity, Sentiment Score, and Other Auxiliary Features).
To verify the effect of every type of emotion features, we remove
one specific type of features from Dual Emotion Features every time,
to observe the performance changes. As Table 4 shows, the macro
F1 scores of Dual Emotion Features all decrease regardless of the
removed type of emotion features. Thus, it reveals the necessity of
using five types of emotion features jointly.
4.4.2 Performance Evaluation within Fake News Detectors. To answer EQ2, we exhibit the results of adding Dual Emotion Features into the existing fake news detectors on the three datasets.
Table 5 exhibits the results on RumourEval-19 dataset. Overall, after using Dual Emotion Features, the three fake news detectors are both improved a lot. Specifically, on the text-based detectors, BiGRU and BERT, the use of Dual Emotion Features both
improves the performance more than EmoCred and Emoratio. Especially, putting Dual Emotion Features into BERT owns 0.346 for
macro F1 score, far more than the other two emotion features. On

Mining Dual Emotion for Fake News Detection

Models

WWW â€™21, April 19â€“23, 2021, Ljubljana, Slovenia

F1 score
Fake News Real News Unverified News
0.269
0.804
0.500
0.222
0.083
0.275
0.823
0.463
0.160
0.200
0.311
0.797
0.456
0.295
0.182
0.340
0.752
0.580
0.337
0.104
0.272
0.808
0.533
0.105
0.176
0.271
0.857
0.406
0.240
0.167
0.308
0.833
0.367
0.367
0.189
0.346
0.778
0.557
0.244
0.238
0.309
0.770
0.557
0.245
0.125
0.331
0.754
0.571
0.280
0.143
0.307
0.786
0.296
0.500
0.125
0.342
0.754
0.565
0.565
0.100
Table 5: Results on RumourEval-19.

Macro F1 score

BiGRU
+ Emoratio
+ EmoCred
+ Dual Emotion Features
BERT
+ Emoratio
+ EmoCred
+ Dual Emotion Features
NileTMRG
+ Emoratio
+ EmoCred
+ Dual Emotion Features

RMSE

Weibo-16
Models
BiGRU
+ Emoratio
+ EmoCred
+ Dual Emotion Features
BERT
+ Emoratio
+ EmoCred
+ Dual Emotion Features
HSA-BLSTM
+ Emoratio
+ EmoCred
+ Dual Emotion Features

Weibo-20

F1 score
Macro F1 score Accuracy
Macro F1 score
Fake Real
0.807
0.822
0.754 0.860
0.839
0.794
0.810
0.738 0.851
0.850
0.766
0.778
0.711 0.820
0.829
0.826
0.838
0.781 0.871
0.855
0.824
0.845
0.762 0.886
0.900
0.837
0.857
0.780 0.894
0.901
0.849
0.867
0.797 0.901
0.902
0.867
0.873
0.837 0.896
0.915
0.849
0.855
0.819 0.879
0.913
0.863
0.872
0.829 0.898
0.920
0.854
0.861
0.822 0.886
0.903
0.908
0.913
0.885 0.930
0.932
Table 6: Results on Weibo-16 and Weibo-20.

the state-of-the-art model NileTMRG, using Emoratio and Dual
Emotion Features both improves the macro F1 score further. And
the improvement of Dual Emotion Features is 3.3%, which is 1.1%
higher than Emoratio.
The experimental results on the two Weibo datasets are displayed
in Table 6. Overall, we can see that our proposed Dual Emotion Features outperforms Emoratio and EmoCred on any models in both
datasets. Specifically, on BiGRU and BERT, the improvements in
macro F1 score of Dual Emotion Features are at least 1.5% higher
on the two datasets. However, when using Emoratio or EmoCred
on BiGRU, sometimes the metrics even decrease. It reveals that
Emoratio and EmoCred are more likely to be overfitted, since both
of them focus on the contents alone but ignore the comments. And
learning dual emotion jointly can avoid this situation to some extent. On the state-of-the-art model HSA-BLSTM, after using Dual
Emotion Features as an enhancement, all the metrics are improved
further in both datasets. Especially in Weibo-16, the accuracy and
macro F1 score both own about 6% improvement, far more than
Emoratio and EmoCred.

Accuracy
0.839
0.850
0.829
0.855
0.900
0.901
0.902
0.915
0.913
0.920
0.903
0.932

F1 score
Fake Real
0.839 0.839
0.854 0.846
0.836 0.821
0.857 0.852
0.900 0.900
0.900 0.902
0.901 0.903
0.913 0.918
0.912 0.914
0.920 0.920
0.902 0.905
0.932 0.933

4.4.3 Evaluation Under Real-World Scenario Simulation. In the
fields of fake news detection, when splitting datasets, most works
just shuffle the datasets and split them into train / val. / test sets
[17, 26, 38, 47], including the datasets splits in Table 2. The kind
of data split can somehow prove the effectiveness of proposed
methods, but also has a shortcoming: In the real-world scenarios,
when a check-worthy news piece emerges, we only own the data
previously-emerging to train the detector, which cannot be guaranteed when adopting the above data split. To answer EQ3, we
simulate a real-world scenario by additionally performing a temporal data split, which means that instances in the train / val. / test
sets are arranged in chronological order, to evaluate the ability of
models to detect future news pieces.
In this section, we adopt the dataset Weibo-20 and select the
most recent 20% news pieces of them as the testing set. Among the
remaining 80% news pieces, we next select the most recent 25% of
them for validation and let the others be the training set. The results
on temporally split Weibo-20 are displayed in Table 7. Compared
with Table 2, we can see that in Table 7 all the performances decrease
a lot. It indicates that the temporal data-split strategy creates a more

WWW â€™21, April 19â€“23, 2021, Ljubljana, Slovenia

Models

Macro F1 Acc.

BiGRU
0.680
0.681
+ Emoratio
0.628
0.632
+ EmoCred
0.659
0.666
+ Dual Emotion Features 0.701
0.702
BERT
0.722
0.728
+ Emoratio
0.719
0.724
+ EmoCred
0.725
0.728
+ Dual Emotion Features 0.734
0.734
HSA-BLSTM
0.776
0.778
+ Emoratio
0.771
0.774
+ EmoCred
0.777
0.781
0.808
+ Dual Emotion Features 0.805
Table 7: Results on Weibo-20 (temporal data
short for Accuracy.

Xueyao Zhang, Juan Cao, Xirong Li, Qiang Sheng, Lei Zhong, and Kai Shu

F1 score
Fake Real
0.694 0.666
0.665 0.592
0.709 0.609
0.714 0.689
0.762 0.682
0.757 0.681
0.752 0.699
0.773 0.692
0.796 0.686
0.796 0.663
0.806 0.646
0.827 0.694
split). Acc. is

challenging scenario, because the topics and writing styles of newly
arrived instances are likely to change over time. Such a scenario
can somehow expose the drawback of existing techniques and
it requires a model of higher generalizability to cope with novel
instances.
Under this hard setting, the models with our proposed Dual
Emotion Features still outperform those with Emoratio and EmoCred. Sometimes the introduction of Emoratio or EmoCred even
leads to a performance decrease. In contrast, using Dual Emotion
Features still enhances both models and increases all the metrics,
which reveals the effectiveness and generalization ability of Dual
Emotion Features to some extent.
4.4.4 Ablation Study. To answer EQ4, we further conduct ablation
experiments on RumourEval-19, Weibo-16, Weibo-20 and Weibo20 (temporally) (splitting datasets temporally, described in Section 4.4.3). The results are displayed in Table 8.
In Table 8, we can see that among the four datasets, adding
Dual Emotion Features into the fake news detectors all obtain the
highest macro F1 scores. Besides, compared with the original fake
news detectors (Table 5 and Table 6), using any component of Dual
Emotion Features all enhances the performances of them. During the
three components of Dual Emotion Features, it exhibits that adopting
Social Emotion or Emotion Gap improves the macro F1 scores more
than Publisher Emotion on any models on all the datasets. So it
concludes that Social Emotion and Emotion Gap matter more when
detecting fake news.

4.5

Case Study

We provide a qualitative analysis of Dual Emotion Features in some
cases. Take the detector BiGRU on RumourEval-19 as an example,
we select three fake news pieces that missed by the original BiGRU
but detected after using Dual Emotion Features as an enhancement
(Figure 4). In the figure, there are rich dual emotion signals in
every case, such as emotion resonances of angry in the left case,
of joyful in the middle case, and emotion dissonances with none
publisher emotion and sad social emotion in the right case. However,
it exhibits using Emoratio or EmoCred do not help BiGRU detect

Models
R-19 W-16 W-20 W-20(t)
Publisher Emotion 0.310 0.809 0.842
0.681
Social Emotion
0.322 0.818 0.847
0.693
BiGRU+
Emotion Gap
0.336 0.811 0.849
0.693
Dual Emotion
0.340 0.826 0.855
0.701
Features
Publisher Emotion 0.312 0.850 0.889
0.705
Social Emotion
0.339 0.856 0.911
0.730
BERT+
Emotion Gap
0.338 0.858 0.906
0.731
Dual Emotion
0.346 0.867 0.915
0.734
Features
Publisher Emotion 0.311
Nile
Social Emotion
0.325
0.337
TMRG+ Emotion Gap
Dual Emotion
0.342
Features
Publisher Emotion
0.876 0.915
0.779
HSASocial Emotion
0.892 0.922
0.792
0.901 0.926
0.800
BLSTM+ Emotion Gap
Dual Emotion
0.908 0.932
0.805
Features
Table 8: Ablation study of the three components of Dual
Emotion Features. The evaluation metric is macro F1 scores.
R-19: RumourEval-19, W-16: Weibo-16, W-20: Weibo-20, and
W-20(t): temporally split Weibo-20.

rightly for the three cases. It reveals that mining dual emotion
additionally sometimes is a remedy for the incompetence of only
using semantics for detecting fake news.

5

CONCLUSION AND FUTURE WORK

In this paper, we bring a new concept of dual emotion, i.e., the
publisher emotion and social emotion, into fake news research. We
uncover the relationship between dual emotion signals (especially,
the emotion gap) and the news veracity. Based on the data observation and analysis, we further propose a feature set, Dual Emotion
Features, to expose the distinctive emotional signals for detecting
fake news. Further, we exhibit that our proposed features can be
easily plugged into existing fake news detectors as an enhancement.
The extensive experiments conducted on three real-world datasets
(including a newly-constructed Chinese dataset) have demonstrated
that our proposed feature set outperforms the existing emotional
features in fake news detection and essentially improves the performance of existing text-based methods. In future work, we plan to
leverage multi-modal information (e.g., emotion in visual contents)
to capture the emotions more precisely and use more sophisticated
models for dual emotion representation.

ACKNOWLEDGMENTS
We thank Chuan Guo, Peng Qi, Yuting Yang for their insightful comments. This work is funded by National Natural Science Foundation
of China (No. 61672523), and the Fundamental Research Funds for
the Central Universities and the Research Funds of Renmin University of China (No. 18XNLG19). Kai Shu is supported by the John S.

Mining Dual Emotion for Fake News Detection

Content

Publisher emotion: Angry

WWW â€™21, April 19â€“23, 2021, Ljubljana, Slovenia

Content

Publisher emotion: Joyful

Content

Publisher emotion: None

Black Lives Matter THUGS Blocking Emergency
Crews From Reaching Hurricane Victims.

Believe it or not, this is a shark on the freeway in
#Houston, #Texas #HurricaneHarvyâ€¦

Category 6? If Hurricane Irma Becomes The
Strongest Hurricane In History, It Could Wipe
Entire Cities Off The Map.

Comments

Comments

Comments

Social emotion: Angry

Run over their asses.

Social emotion: Joyful

Fresh water? Nice try.

...

...

Oh my!

Get out of there people. Florida, South Carolina.

...

...
And why don't we have military support there to
enforce the law?

BiGRU
BiGRU + Emoratio
BiGRU + EmoCred
BiGRU + Dual Emotion Features

Watch what the power of prayer does

...

When thugs block emergency vehicles, vehicles should
run over the thugs

Fake
0.33
0.35
0.27
0.65

Real
0.61
0.57
0.64
0.21

Unverified
0.06
0.08
0.09
0.14

Social emotion: Sad

...

It's trying to ask you for directions...must be a female
shark!! ğŸ˜†

BiGRU
BiGRU + Emoratio
BiGRU + EmoCred
BiGRU + Dual Emotion Features

Fake
0.31
0.36
0.40
0.65

Real
0.50
0.56
0.54
0.22

Unverified
0.19
0.08
0.06
0.13

Pray to god the only chance you have...

BiGRU
BiGRU + Emoratio
BiGRU + EmoCred
BiGRU + Dual Emotion Features

Fake
0.47
0.40
0.28
0.63

Real
0.52
0.59
0.58
0.17

Unverified
0.01
0.01
0.14
0.20

Figure 4: Three fake news pieces on RumourEval-19, which are missed by original BiGRU but detected after using Dual Emotion
Features. The prediction results of the four models are shown at the bottom, where the numbers represent confidence scores
(a float value from 0 to 1). The scores that identify prediction labels are shown in bold.
and James L. Knight Foundation through a grant to the Institute for
Data, Democracy & Politics at The George Washington University.

REFERENCES
[1] Oluwaseun Ajao, Deepayan Bhowmik, and Shahrzad Zargari. 2019. Sentiment
Aware Fake News Detection on Online Social Networks. In IEEE ICASSP 2019.
2507â€“2511.
[2] BBC. 2020. Bangladesh lynchings: Eight killed by mobs over false child abduction
rumours. Retrieved October 19, 2020 from https://www.bbc.com/news/worldasia-49102074
[3] Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural language processing
with Python: analyzing text with the natural language toolkit. " Oâ€™Reilly Media,
Inc.".
[4] Leonardo Bursztyn, Aakaash Rao, Christopher P Roth, and David H YanagizawaDrott. 2020. Misinformation During a Pandemic. Working Paper 27417. National
Bureau of Economic Research. https://doi.org/10.3386/w27417
[5] Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. 2011. Information credibility on twitter. In WWW 2011. 675â€“684.
[6] Qingqing Chen. 2020. Coronavirus rumors trigger irrational behaviors among
Chinese netizens. Retrieved October 19, 2020 from https://www.globaltimes.cn/
content/1178157.shtml (in Chinese).
[7] Tong Chen, Xue Li, Hongzhi Yin, and Jun Zhang. 2018. Call Attention to Rumors:
Deep Attention Based Recurrent Neural Networks for Early Rumor Detection. In
PAKDD 2018. 40â€“52.
[8] Kyunghyun Cho, Bart van MerriÃ«nboer, Dzmitry Bahdanau, and Yoshua Bengio. 2014. On the Properties of Neural Machine Translation: Encoderâ€“Decoder
Approaches. In SSST@EMNLP 2014. 103â€“111.
[9] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:
Pre-training of Deep Bidirectional Transformers for Language Understanding. In
NAACL-HLT, Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association
for Computational Linguistics, 4171â€“4186. https://doi.org/10.18653/v1/n19-1423
[10] Zhendong Dong and Qiang Dong. 2003. HowNet: a hybrid language and knowledge resource. In International Conference on Natural Language Processing and
Knowledge Engineering, 2003. IEEE, 820â€“824.
[11] Paul Eckman. 1972. Universal and Cultural Differences in Facial Expression of
Emotion. In Nebraska Symposium on Motivation, Vol. 19. 207â€“284.
[12] Dina ElBoghdady. 2013. Market quavers after fake AP tweet says Obama was
hurt in White House explosions. The Washington Post (2013).
[13] Omar Enayet and Samhaa R. El-Beltagy. 2017. NileTMRG at SemEval-2017
Task 8: Determining Rumour and Veracity Support for Rumours on Twitter. In
SemEval@ACL 2017. 470â€“474.
[14] Marc Fisher, John Woodrow Cox, and Peter Hermann. 2016. Pizzagate: From
rumor, to hashtag, to gunfire in DC. Washington Post 6 (2016).
[15] Anastasia Giachanou, Paolo Rosso, and Fabio Crestani. 2019. Leveraging Emotional Signals for Credibility Detection. In ACM SIGIR 2019. 877â€“880.

[16] Genevieve Gorrell, Ahmet Aker, Kalina Bontcheva, Leon Derczynski, Elena
Kochkina, Maria Liakata, and Arkaitz Zubiaga. 2019. SemEval-2019 Task
7: RumourEval, Determining Rumour Veracity and Support for Rumours. In
SemEval@NAACL-HLT 2019. 845â€“854.
[17] Han Guo, Juan Cao, Yazi Zhang, Junbo Guo, and Jintao Li. 2018. Rumor Detection
with Hierarchical Social Attention Network. In CIKM 2018. 943â€“951.
[18] Sepp Hochreiter and JÃ¼rgen Schmidhuber. 1997. Long short-term memory. Neural
computation 9, 8 (1997), 1735â€“1780.
[19] Zhiwei Jin, Juan Cao, Yongdong Zhang, and Jiebo Luo. 2016. News Verification by
Exploiting Conflicting Social Viewpoints in Microblogs. In AAAI 2016. 2972â€“2978.
[20] Zhiwei Jin, Juan Cao, Yongdong Zhang, Jianshe Zhou, and Qi Tian. 2016. Novel
visual and statistical image features for microblogs news verification. IEEE Trans.
Multim. 19, 3 (2016), 598â€“608.
[21] Neel Kant, Raul Puri, Nikolai Yakovenko, and Bryan Catanzaro. 2018. Practical
Text Classification With Large Pre-Trained Language Models. arXiv:1812.01207
(2018).
[22] Elena Kochkina, Maria Liakata, and Arkaitz Zubiaga. 2018. All-in-one: Multi-task
Learning for Rumour Verification. In COLING 2018. 3402â€“3413.
[23] Quanzhi Li, Qiong Zhang, and Luo Si. 2019. eventAI at SemEval-2019 Task 7:
Rumor Detection on Social Media by Exploiting Content, User Credibility and
Propagation Information. In SemEval@NAACL-HLT 2019. 855â€“859.
[24] Quanzhi Li, Qiong Zhang, and Luo Si. 2019. Rumor detection by exploiting
user credibility information, attention and multi-task learning. In ACL 2019.
1173â€“1179.
[25] Shen Li, Zhe Zhao, Renfen Hu, Wensi Li, Tao Liu, and Xiaoyong Du. 2018. Analogical Reasoning on Chinese Morphological and Semantic Relations. In ACL(2)
2018. ACL, 138â€“143.
[26] Jing Ma, Wei Gao, Prasenjit Mitra, Sejeong Kwon, Bernard J Jansen, Kam-Fai
Wong, and Meeyoung Cha. 2016. Detecting rumors from microblogs with recurrent neural networks. In IJCAI 2016. 3818â€“3824.
[27] Jing Ma, Wei Gao, and Kam-Fai Wong. 2017. Detect Rumors in Microblog Posts
Using Propagation Structure via Kernel Learning. In ACL 2017. 708â€“717.
[28] Jing Ma, Wei Gao, and Kam-Fai Wong. 2018. Rumor Detection on Twitter with
Tree-structured Recursive Neural Networks. In ACL 2018. 1980â€“1989.
[29] Saif Mohammad. 2018. Word Affect Intensities. In LREC 2018.
[30] Saif Mohammad and Peter D. Turney. 2013. Crowdsourcing a Word-Emotion
Association Lexicon. Comput. Intell. 29, 3 (2013), 436â€“465.
[31] Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. Glove:
Global Vectors for Word Representation. In EMNLP 2014. 1532â€“1543.
[32] VerÃ³nica PÃ©rez-Rosas, Bennett Kleinberg, Alexandra Lefevre, and Rada Mihalcea.
2018. Automatic Detection of Fake News. In COLING 2018. 3391â€“3401.
[33] Francesco Pierri and Stefano Ceri. 2019. False News On Social Media: A DataDriven Survey. SIGMOD Rec. 48, 2 (2019), 18â€“27.
[34] Vahed Qazvinian, Emily Rosengren, Dragomir Radev, and Qiaozhu Mei. 2011.
Rumor has it: Identifying misinformation in microblogs. In EMNLP 2011. 1589â€“
1599.

WWW â€™21, April 19â€“23, 2021, Ljubljana, Slovenia

Xueyao Zhang, Juan Cao, Xirong Li, Qiang Sheng, Lei Zhong, and Kai Shu

[35] Peng Qi, Juan Cao, Tianyun Yang, Junbo Guo, and Jintao Li. 2019. Exploiting
multi-domain visual information for fake news detection. In ICDM 2019. IEEE,
518â€“527.
[36] Peter J Richerson and Robert Boyd. 2008. Not by genes alone: How culture transformed human evolution. University of Chicago press.
[37] Ralph L Rosnow. 1991. Inside rumor: A personal journey. American psychologist
46, 5 (1991), 484.
[38] Natali Ruchansky, Sungyong Seo, and Yan Liu. 2017. CSI: A Hybrid Deep Model
for Fake News Detection. In CIKM 2017. 797â€“806.
[39] Kai Shu, Suhang Wang, and Huan Liu. 2018. Understanding user profiles on
social media for fake news detection. In MIPR 2018. IEEE, 430â€“435.
[40] Kai Shu, Suhang Wang, and Huan Liu. 2019. Beyond News Contents: The Role
of Social Context for Fake News Detection. In WSDM 2019. 312â€“320.
[41] The Lancet Infectious Diseases. 2020. The COVID-19 infodemic. The Lancet
Infectious Diseases 20, 8 (2020), 875. https://doi.org/10.1016/S1473-3099(20)30565X
[42] Yaqing Wang, Fenglong Ma, Zhiwei Jin, Ye Yuan, Guangxu Xun, Kishlay Jha, Lu
Su, and Jing Gao. 2018. EANN: Event Adversarial Neural Networks for MultiModal Fake News Detection. In KDD 2018. 849â€“857.
[43] Wikipedia. 2020. List of emoticons. Retrieved October 19, 2020 from https:
//en.wikipedia.org/wiki/List_of_emoticons
[44] Wikipedia. 2020. Misinformation related to the COVID-19 pandemic. Retrieved
October 19, 2020 from https://en.wikipedia.org/wiki/Misinformation_related_to_
the_COVID-19_pandemic
[45] Lianwei Wu and Yuan Rao. 2020. Adaptive Interaction Fusion Networks for Fake
News Detection. In ECAI 2020. 2220â€“2227.
[46] Linhong Xu, Hongfei Lin, Yu Pan, Hui Ren, and Jianmei Chen. 2008. Constructing
the Affective Lexicon Ontology. Journal of the China Society for Scientific 27, 2
(2008), 180â€“185. (in Chinese).
[47] Feng Yu, Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2017. A Convolutional
Approach for Misinformation Identification. In IJCAI 2017. 3901â€“3907.

APPENDIX A. THE REASONS WHY THE
DATASET WEIBO-16 NEEDS TO BE
DEDUPLICATED
In Section 4.1.2, we mention that the original version of Weibo-16
contains many duplications of fake news pieces. Table 9 shows
the data statistics. Comparing to Table 2, the number of fake news
pieces decrease from 2,312 to 1,355 after deduplication. And there
are no duplications in real news pieces.

Training

Validation

Testing

Total

Veracity
Fake
Real
Unverified
Total
Fake
Real
Unverified
Total
Fake
Real
Unverified
Total
Fake
Real
Unverified
Total

#pcs
1,386
1,410
2,796
463
470
933
463
471
934
2,312
2,351
4,663

#com
789,841
482,226
1,272,067
255,833
146,948
402,781
224,795
179,942
404,737
1,270,469
809,116
2,079,585

Table 9: Statistics of the original version of Weibo-16. #pcs:
number of news pieces; #com: number of comments.
To further research the impact of duplications data on the ability
of models, we conduct comparison experiments on the original and
deduplicated versions of Weibo-16 respectively. And the results are
exhibited in Table 10. Here we choose BiGRU and HSA-BLSTM
as fake news detectors. Considering the class imbalance of the

deduplicated version of the dataset, we train the models based on
class weights on the deduplicated training set.
Dataset Version
Macro F1 Acc.
Train & Val
Test
original
original
0.793
0.793
BiGRU
original
0.806
0.807
deduplicated
deduplicated
0.807
0.822
original
original
0.854
0.854
HSA-BLSTM
original
0.873
0.873
deduplicated
deduplicated
0.849
0.855
Table 10: Results of the comparison experiments on the original and deduplication versions of Weibo-16. Acc. is short for
Accuracy.
Models

In Table 10, we can see that if we train and validate the detectors
on the deduplicated version of the dataset, the performances of
the two detectors will increase on the original testing set (shown
in bold in the table). Therefore, it verifies that training on the
deduplicated datasets will enhance the generalization ability of
the models to some extent. Moreover, if we fix the training and
validation set deduplicated and just change the testing set from the
original version to the deduplicated version, on BiGRU the macro
F1 score and accuracy increase, while on HSA-BLSTM the metrics
both decrease. We suppose the reasons are that on the original
testing set, the detectors will predict the duplicated news pieces
as highly similar results. So some clusters of duplicated pieces
may be all predicted correctly, while others may be all predicted
mistakenly, resulting in the unstable performance of the detectors.
In a conclusion, deduplicating the dataset can help mitigate this
issue.

APPENDIX B. THE METHOD TO CALCULATE
THE DUAL EMOTION CATEGORY
It is mentioned in Section 4.2 that we use the pretrained emotion
classifiers to calculate the value of Dual Emotion Category. The
method to calculate the Dual Emotion Category are as follows:
For publisher emotion, we feed the text of the news content into
the emotion classifier and take the emotion with the maximum
probability as the publisher emotion category. For social emotion,
we feed the news comments once a time. After getting the output
vector of each comment, each dimension of which represents the
probability of the given comment having a certain kind of emotion,
we average the probability vector of all the comments in each dimension. Finally, we take the emotion with the maximum probability
as the social emotion category (i.e., soft voting).
For example, assume that the the output of an emotion classifier
is a probability vector on angry, disgusting, happy and none and the
given news piece has two comments. The content probabilities are
[0.3, 0.1, 0, 0.6]. So we can use the corresponding emotion of 0.6,
none, as the publisher emotion category. The probability vector is
[0.8, 0.1, 0, 0.1] for the first comment, and [0.6, 0.3, 0.1, 0] for the
second comment. So we firstly average all the comment probability
values and get [0.7, 0.2, 0.05, 0.05]. Then we use the corresponding
emotion of 0.7, angry, as the news social emotion category. Thus,
the categorical variable Dual Emotion Category is none for publisher
emotion and angry for social emotion.

