Tracking Control by the Newton-Raphson Method with Output
Prediction and Controller Speedup

arXiv:1910.00693v1 [math.OC] 1 Oct 2019

Y. Wardi, C. Seatzu, J. CorteÌs, M. Egerstedt, S. Shivam, and I. Buckley âˆ—.

â€ 

October 3, 2019

Abstract
This paper presents a control technique for output tracking of reference signals in
continuous-time dynamical systems. The technique is comprised of the following three
elements: (i) output prediction which has to track the reference signal, (ii) a controller
based on an integrator with variable gain, and (iii) a speedup of the control action for
enhancing the trackerâ€™s accuracy and, in some cases, guaranteeing stability of the closedloop system. The technique is suitable for linear and nonlinear systems, implementable by
simple algorithms, can track reference points as well as time-dependent reference signals,
and may have large, even global domains of attraction. The derived theoretical results
include convergence of the tracking controller and error analysis, and are supported by
illustrative simulation and laboratory experiments.

1

Introduction

The subject of this paper is a reference-tracking control technique for dynamical systems
modelled by ordinary differential equations. The technique is founded on real-time implementations of a fluid-flow variant of the Newton-Raphson method for solving algebraic equations.
The relevance of the Newton-Raphson method is due to the observation, argued for in the sequel, that tracking can be viewed as a dynamic process of attempting to solve a time-dependent
suite of nonlinear algebraic equations.
Existing nonlinear regulation techniques such as the Byrnes-Isidori regulator [1], Khalilâ€™s
high-gain observers for output regulation [2], and Model Predictive Control (MPC) [3] are
more general and perhaps more powerful than the technique presented here. However, their
effectiveness is partly due to significant computational sophistication like nonlinear inversions,
âˆ—

Wardi, Egerstedt, Shivam and Buckley are with the School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, 30332, USA. email: {ywardi, magnus}@ece.gatech.edu, {sshivam6,
ihbuckl}@gatech.edu.
Seatzu is with the Department of Electrical and Electronic Engineering, University of Cagliari, Italy. e-mail:
seatzu@diee.unica.it.
CorteÌs is with the Department of Mechanical and Aerospace Engineering, University of California, San Diego.
e-mail: cortes@ucsd.edu
â€ 
Seatzuâ€™s work is supported by the Region of Sardinia Project RASSR05871 MOSIMA, FSC 2014-2020,
Annuity 2017, Subject Area 3, Action Line 3.1.
CorteÌsâ€™ work is supported by NSF Award CNS-1446891.
Egerstedtâ€™s work is supported by grant DCIST CRA W911NF-17-2-0181 from the US Army Research Lab.

1

r(t)

+- .

e(t)

u(t)

ï¿½ Controller

ï¿½

Plant

y(t)

ï¿½

Figure 1: Basic control system
the appropriate nonlinear normal form, and real-time algorithms for optimal control. The
control technique described in this paper, essentially comprising a variable-gain integrator,
is simple and requires low computing efforts. Nevertheless it will be shown to have inherent
stability properties and work well on various test problems. Furthermore, it is not a local
method, but its domain of attraction is often large and sometimes global. Nor is it based on a
linearization, and it can be nonlinear. As a matter of fact, the controller is not defined by an
explicit algebraic function of the systemsâ€™ state variable, but rather by a differential equation.
As the purpose of this paper is to introduce a new idea, we do not make direct comparisons
of the proposed technique with existing nonlinear-control methods. Instead, we describe it
in a general setting, analyze its salient features, provide results of simulation and laboratory
experiments, and discuss directions for future developments.
The system-diagram that we consider is depicted in Figure 1, where the reference signal
rptq, control input uptq, and system output yptq are all in Rm , with a given m P t1, 2, . . . , u.
The condition that the reference, control, and output have the same dimension is essential for
the discussion here, and although ad-hoc ways to circumvent the effects of its absence have
begun to emerge [4], we defer their general exposition to a future publication.
The plant subsystem in Figure 1 is a dynamical system based on an ordinary differential
equation, whose input, state, and output variables are uptq P Rm , xptq P Rn for some n P
t1, 2, . . .u, and yptq P Rm , respectively. The tracking/regulation technique, implemented by
the controller subsystem, is based on the following three elements: output prediction, NewtonRaphson flow, and controller speedup. The predictor computes, at time t, an estimate of the
future output at time t ` T for a given T Ä… 0, denoted by yÌ‚pt ` T q, and the controller is
underscored by a process aiming at solving the time-dependent equation rpt ` T q Â´ yÌ‚pt `
T q â€œ 0.1 The predictor yÌ‚pt ` T q is a function of xptq and the input variable uptq, and
9
via a differential equation in terms of pxptq, uptqq
therefore the tracking controller defines uptq
as well. Under the ideal conditions of perfect output prediction, this feedback law results in
perfect asymptotic tracking under general assumptions. In the presence of prediction errors,
the asymptotic tracking error will be shown to be equal to the asymptotic prediction error.
Furthermore, it will be proved that an increase in the controllerâ€™s gain can, in some cases,
stabilize the closed-loop system and reduce tracking errors that are due to certain disturbances
and computational errors in the loop. All of this will be defined and described in detail in
later sections.
To explain the term â€œfluid-flow variantâ€ of an iterative algorithm in Rm , and place the
forthcoming results in the context of the established literature, consider an iterative algorithm
of the form
uk`1 â€œ uk ` gpuk q,
(1)
1

Details of this will be provided in the sequel.

2

k â€œ 0, 1, . . ., where uk P Rm , and g : Rm Ã‘ Rm is a function assumed to be locally Lipschitz continuous. Placing the algorithm in a temporal framework, suppose that an iteration
according to (1) is computed once every âˆ†t seconds for a given âˆ†t Ä… 0, and scale the step
size in the Right-Hand Side (RHS) of (1) by âˆ†t. Defining upkâˆ†tq :â€œ uk and taking the limit
âˆ†t Ã‘ 0 we obtain the following equation,
9
uptq
â€œ gpuptqq.

(2)

The process defined by Eq. (2) is said to be the fluid-flow version of the algorithm defined by
Eq. (1).
Fluid-flow processes can be useful in investigating asymptotic properties of their associated
discrete algorithms with small step sizes, such as convergence, optimality and stability of limit
points, etc. They have been applied mainly to the design of gradient-descent algorithms for
problems in optimization and linear algebra, including sorting, eigenvalue decomposition, and
linear programming; see [5â€“7] for early works. Ref. [6] recognized their potential applications
in massively-parallel computing platforms such as neural nets, slated to solve very-large scale
problems. Recent applications to learning and distributed optimization can be found in [8, 9],
respectively, and references therein.
Second-order optimization methods, especially variants of the Newton-Raphson algorithm,
have been considered as well due to their superlinear convergence rates. Refs. [10,11] consider
first- and second-order algorithms for convex (or concave) constrained programs with timevarying cost functions. [10] is concerned with applications to traffic engineering in telecommunications, and [11] considers distributed optimization over multi-agent networks with consensus constraints. Both references derive general theoretical results in abstract settings of
the Newton-Raphson flow beyond their motivating problem-classes, including convergence under weak smoothness assumptions and convergence in a general network setting, respectively.
Ref. [12] derives a continuous-flow, primal-dual technique for convex optimization without
assuming differentiability of the cost function. Combining results from the theory of convex,
nondifferentiable optimization with fluid-flow techniques, it defines the flow by differential
inclusions, and derives convergence results, including global asymptotic stability of the minimum and superlinear/quadratic (depending on assumptions) convergence rates under the
weakest-to-date smoothness assumptions on the cost function.
This paper also considers a fluid-flow variant of the Newton-Raphson method, but applies
if to finding roots of algebraic equations rather than to convex optimization. However, in
contrast with the aforementioned references, the resulting control variable uptq cannot be
defined or described by an equation like (2). To get around this difficulty we use an output
predictor, yÌ‚pt ` T q, and define the tracking controller as a fluid-flow version of the NewtonRaphson method aiming at solving the time-dependent equations rpt ` T q Â´ yÌ‚pt ` T q â€œ 0.
Thus, in a way, the predictor is utilized as an observer as well.
Prediction is commonly used in control, especially for system identification and model
construction. In this paper we evidently use it in a different way, in the definition of the
tight-loop control. It resembles the use of prediction in model predictive control [3], but our
proposed controller is not based on MPC since it does not solve optimal control problems
in the loop. A more detailed comparison with MPC will be made at the end of Section 2
following an expanded explanation of our technique.
Regarding the third element of the proposed technique, the idea that high controller-gains
can enhance stability-robustness and reduce tracking-convergence time is implicit in [13] and
3

explicit in [14]. This paper explores it, in conjunction with the Newton-Raphson flow and
output prediction, in the aforementioned general setting of linear and nonlinear control.
The rest of the paper is structured as follows. Section 2 presents the problem and recounts
the past developments of our tracking-control technique. Section 3 carries out analyses of
tracking-convergence and how it is impacted by disturbances and other errors in the loop.
Section 4 derives a verifiable sufficient condition for stability of linear systems at high controller
speeds (rates). Section 5 presents simulation results and Section 6 describes a laboratory
experiment. Section 7 concludes the paper and discusses directions for future research.
Preliminary results concerning the material in this paper can be found in four conference
papers, [4, 15â€“17]. This paper extends them in the following ways: 1.) It presents a new
version of the controller which can yield perfect asymptotic tracking, in contrast with the
published works where only approximate tracking is obtained. 2). The analysis includes
tracking convergence for general classes of systems and problems (see Section 3). In contrast,
the only analyses in the published works pertain to simple examples (see Section 2). 3). It
provides a comprehensive stability analysis for linear systems. 4). The examples are more
complex than in the conference versions.

2

Problem Formulation and Earlier Results

This section provides a background material on the specific problem considered in the paper,
and recounts the early approaches to it pursued by the authors.
The output tracking of a system can be viewed as a real-time implementation of an algorithm for solving a certain kind of algebraic equations. To see this point consider the system
depicted in Figure 1, and suppose for a moment that the plant-subsystem is a memoryless
nonlinearity of the form
yptq â€œ gpuptqq,
(3)
where the function g : Rm Ã‘ Rm is continuously differentiable. The tracking problem can be
viewed as an effort to solve the time-dependent system of equations
rptq Â´ gpuq â€œ 0
in the variable u P Rm , and the controller has to be designed to ensure that
`
Ë˜
lim rptq Â´ gpuptqq â€œ 0.
tÃ‘8

(4)

(5)

To solve this problem we define the controller subsystem in Figure 1 so as to implement the
fluid-flow version of the Newton-Raphson method. It has the following form,
9
uptq
â€œ

Â´ Bg

where we assume that the Jacobian

Bu

puptqq

Bg
Bu puptqq

Â¯Â´1 `

Ë˜
rptq Â´ gpuptqq ,

(6)

is nonsingular for all t Ä› 0.

We make the observation that this controller has the form uptq
9
â€œ Aptqeptq, with eptq :â€œ
rptq Â´ yptq (see Figure 1) and Aptq is the inverse Jacobian in Eq. (6), an m Ë† m matrix. This
controller essentially is an integrator with a variable gain, Aptq. Now it is well known that a
standalone integral controller can guarantee tracking of a constant reference, but may result
4

in oscillations and even instability of the closed-loop system (e.g., [18]). In the present case,
however, tracking and stability seem to be ensured by the particular choice of the gain Aptq
in Eq. (6). To see this point, consider the Lyapunov function
1
V puptqq :â€œ }rptq Â´ gpuptqq}2 .
2

(7)

In the case where the reference signal is a constant, i.e., rptq â€ r for some r P Rm , it can be
seen that V9 ptq â€œ Â´}r Â´ gpuptqq}2 , hence by (7) V9 ptq â€œ Â´2V ptq, which guarantees asymptotic
tracking in the sense of Eq. (5). Variants of this simple yet powerful argument underscore
convergence-proofs of fluid-flow convex-optimization algorithms in various settings, and the
global asymptotic stability of their limit points. For instance, see [12] for nondifferentiable
problems.
If rptq is a function of time, Eq. (5) is no longer necessarily true. However, if rptq is
bounded, continuous, and piecewise differentiable, the controller defined by (6) guarantees
that
â€º
â€º
(8)
limsuptÃ‘8 â€ºrptq Â´ yptqâ€º Ä Î·,
9
where Î· :â€œ limsupt}rptq}
: t P Ru (see [16]).
To tighten the upper bound in (8), we speed up the action of the controller. One way to
do it is to multiply the Right-Hand Side (RHS) of Eq. (6) by a constant Î± Ä… 1, which results
in the following equation,
9
uptq
â€œÎ±

Â´ Bg
Bu

puptqq

Â¯Â´1 `

Ë˜
rptq Â´ gpuptqq .

(9)

This gives the following bound,
â€º
â€º Î·
limsuptÃ‘8 â€ºrptq Â´ yptqâ€º Ä ,
Î±
provided that the Jacobian

Bg
Bu puptqq

(10)

is nonsingular for every t Ä› 0 (see [16]).

This paper considers the plant subsystem to be a dynamical system defined by an ordinary
differential equation. Accordingly, let xptq P Rn denote its state variable modelled by the
equation
9
xptq
â€œ f pxptq, uptqq,
(11)
where uptq P Rm is the control input, f : Rn Ë† Rm Ã‘ Rn is a suitable function, t Ä› 0, and a
given xp0q :â€œ x0 P Rn is the initial state. The output function is
yptq â€œ hpxptqq,

(12)

where yptq P Rm , for a function h : Rn Ã‘ Rm . We make the following assumptions on the
functions f and h:
Assumption 2.1. 1). The function f : Rn Ë† Rm Ã‘ Rn is continuously differentiable, and
for every compact set Î“ Ä‚ Rm there exists K Ä… 0 such that, for every x P Rn and for every
u P Î“,
`
Ë˜
}f px, uq} Ä K }x} ` 1 .
(13)
2). The function h : Rn Ã‘ Rm is continuously differentiable.

5

Assumption 2.1 guarantees the existence of a unique continuous, piecewise-differentiable
solution for Eq. (11) on the time-horizon tt : t Ä› 0u, as long as the input uptq is piecewise
continuous and bounded.
Extensions of the controller defined in (9) from the case of memoryless plants to that of
dynamic plants raises a few challenges. To start with, the input-to-output relation cannot
be expressed in a functional algebraic form like in Eq. (3), because xptq, hence yptq is not
a function of uptq but of tupÏ„ q : Ï„ Äƒ tu. Therefore the controller cannot be defined by an
equation like (9). We resolve this issue with the use of an output predictor. Given T Ä… 0, it
predicts, at time t, the future output ypt ` T q, and we denote the predicted value by yÌ‚pt ` T q.
Suppose that yÌ‚pt ` T q depends on, and is computable from xptq and uptq, then it has the
following functional form,
yÌ‚pt ` T q :â€œ gpxptq, uptqq,
(14)
where the dependence of g on T is implicit since T is assumed fixed.
Assumption 2.2. The function gpÂ¨, Â¨q is continuously differentiable in px, uq.
We define a specific predictor below. Now the Newton-Raphson flow can extend the one
in Eq. (9) by considering the equation rpt ` T q Â´ yÌ‚pt ` T qq â€œ 0 at time t. The resulting
controller equation has the following form,
9
uptq
â€œÎ±

Â´ Bg
Bu

Â¯Â´1 `
Ë˜
rpt ` T q Â´ gpxptq, uptqq ,
pxptq, uptqq

(15)

where it is assumed that rpt ` T q is known in advance at time t. Putting together the state
equation (11) with the control equation (15), we obtain the joint equation
Ëœ
Â¸
Ë™
Ë†
f pxptq, uptqq
xptq
9
Â´
Â¯
Â´1 `
Ë˜ ,
â€œ
(16)
Bg
9
uptq
Î± Bu
pxptq, uptqq
rpt ` T q Â´ gpxptq, uptqq
which can be viewed as the state equation of an n`m-dimensional dynamical system with the
augmented state pxptqJ , uptqJ qJ and the input rpt ` T q. We are concerned with its BoundedInput-Bounded-State
(BIBS) stability, namely a guarantee that, if the process rpt`T q : t Ä›
(
0 is bounded then txptq : t Ä› 0u and tuptq : t Ä› 0u are bounded as well. Henceforth we
will use the term â€œstabilityâ€ to refer to BIBS stability. In contrast with the case where the
plant is memoryless, stability cannot be taken for granted in the present case where the plant
is a dynamical system.
This controller was presented in [15] with the particular
predictor defined as follows: At
(
time t, given xptq and uptq, let Î¾pÏ„ q : Ï„ P rt, t ` T s be defined by the differential equation
9 q â€œ f pÎ¾pÏ„ q, uptqq,
Î¾pÏ„

Î¾ptq â€œ xptq

(17)

with the boundary condition Î¾ptq â€œ xptq; then define
yÌ‚pt ` T q :â€œ gpxptq, uptqq â€œ hpÎ¾pt ` T qq.

(18)

Observe that Eq. (17) is essentially the state equation (11) except that it is defined only
on the interval Ï„ P rt, t ` T s with the constant input upÏ„ q â€ uptq and the initial condition
Î¾ptq â€œ xptq.
6

The resulting predictor yÌ‚pt ` T q, defined by Eqs. (17)-(18), can admit efficient approximations by numerical means such as the Forward Euler method. Stability of the closed-loop
system defined by Eq. (16) with this particular predictor was examined (in [15]) for a number
of second-order linear-system examples. It was shown that, for a fixed Î±, the system is stable
for a large T but unstable for a small T . At the same time, small T may be desirable since
it results in a smaller prediction error than larger T . To circumvent this conundrum, it was
proved that for all of the examples analyzed in [15], if the closed-loop system is unstable for
given T Ä… 0 and Î± Ä… 0 then it can be stabilized by increasing Î± while keeping the same T .
Moreover, simulation results suggest that the following extension of Eq. (10),
limsuptÃ‘8 }rptq Â´ yÌ‚ptq} Äƒ

Î·
,
Î±

(19)

is satisfied under general conditions. Thus, a controllerâ€™s speedup by choosing a large Î± in Eq.
(15) serves the dual purpose of stabilizing the closed-loop system if need be, and reducing the
asymptotic tracking error. We point out that stabilizability by increasing Î± is not guaranteed.
The derivation of sufficient conditions for it in general is quite challenging since the function
gpx, uq lacks a closed form, but some results will be derived in Section 4.
Finally, a word must be said about the relationship between the proposed technique and
Model-Predictive Control. MPC uses optimal control over rolling horizons to compute a future
target trajectory as well as the control input to track it. Our technique is not concerned with
how to compute the reference trajectory, but only with its tracking. Therefore, if the reference
trajectory is given a priori, then our technique does not have to solve optimal control problems
and it can be simpler than MPC. On the other hand, if the reference trajectory has to be
computed in real time, then our technique can use various computational methods including
interpolation as in Section 5, below; optimal control as in MPC or over longer horizons; or
learning methods based on neural nets as in [4]. Comparisons of its effectiveness and efficiency
vis-a-vis MPC is the subject of a current study.

3

Enhanced Controller, Tracking and Error Analysis

This section first presents a modified control algorithm which ensures exact asymptotic tracking of rpt ` T q by yÌ‚pt ` T q without resorting to a controller speedup. It then performs an error
analysis of the controller which sheds light on the robustness of its tracking performance. In
particular, it identifies the errors whose effects on tracking can be reduced by speeding up the
controller vs. those whose effects cannot be thus reduced.
In the forthcoming discussion we will use the shorthand notation txptqu for the state
trajectory txptq : t Ä› 0u, and similarly for the input process (trajectory) tuptqu, output
process typtqu, and other signals and functions of time. Also, we will say that the trajectory
of the closed-loop system is nonsingular if for every point pxptqJ , uptqJ qJ is computes, the
Bg
partial Jacobian Bu
pxptq, uptqq is nonsingular.

3.1

Modified Controller

Consider the system depicted in Figure 1, where the plant is a dynamical system as defined
by Eqs. (11)-(12). Suppose that Assumption 2.1 and Assumption 2.2 are satisfied, and rpÂ¨q
is continuous and piecewise differentiable. Fix a lookahead time T Ä… 0. We consider the case
7

where there is no controller speedup, namely Î± â€œ 1, and modify the controller equation (15)
as follows,

9
uptq
â€œ

Â´ Bg
Bu

pxptq, uptqq

Â¯Â´1 Â´
Â¯
Bg
9 ` T q Â´ pxptq, uptqqf pxptq, uptqq . (20)
rpt ` T q Â´ yÌ‚pt ` T q ` rpt
Bx

Observe that the difference between this controller and the one defined by (15) is in the
Bg
9 ` T q Â´ Bx
addition of the last two terms in the RHS of (20), rpt
pxptq, uptqqf pxptq, uptqq.
Define the Lyapunov function
1
V pxptq, uptqq :â€œ }rpt ` T q Â´ yÌ‚pt ` T q}2 .
2

(21)

Proposition 3.1. If the trajectory of the closed-loop system under the state equation (11) and
the controller equation (20) is nonsingular, then V pxptq, uptqq satisfies the following equation,
V9 pxptq, uptqq â€œ Â´2V pxptq, uptqq.

(22)

`
Ë˜
lim rptq Â´ yÌ‚ptq â€œ 0.

(23)

Consequently, we have that
tÃ‘8

Proof. Taking the derivative with respect to t in (21), and considering the fact that
yÌ‚pt ` T q â€œ gpxptq, uptqq,
D
@
d
9 ` T q Â´ gpxptq, uptqq .
V9 pxptq, uptqq â€œ rpt ` T q Â´ yÌ‚pt ` T q, rpt
dt

(24)

Next, by Eqs. (11) and (20),
Â´ Bg
Â¯Â´1
d
Bg
Bg
gpxptq, uptqq â€œ
pxptq, uptqqf pxptq, uptqq `
pxptq, uptqq
pxptq, uptqq
dt
Bx
Bu
Bu
Â´
Â¯
Bg
9 ` Tq Â´
rpt ` T q Â´ gpxptq, uptqq ` rpt
pxptq, uptqqf pxptq, uptqq .
Bx

(25)

Lastly, simplifying and applying Eq. (25) to (24), Eq. (22) is obtained. Consequently, and
by (21), Eq. (23) follows.
l
Remark 3.2. Observe that the proof does not require any assumptions about stability of the
closed-loop system. In fact, if trptqu is bounded then (by (23)) tyÌ‚ptqu is bounded as well, but
it is still possible that t||yptq||u is unbounded. This situation can arise, for example, if the
closed-loop system is unstable.

3.2

Error Analysis

This subsection considers three types of potential errors in the loop, corresponding to the
various terms in the RHS of Eq. (20), and evaluates their effects on the tracking performance.

8

3.2.1

Prediction error.

Consider a prediction error defined as E1 ptq :â€œ yÌ‚pt ` T q Â´ ypt ` T q, and define the asymptotic
prediction error by
Î·1 :â€œ limsuptÃ‘8 }E1 ptq}.
(26)
By Eq. (23),
limsuptÃ‘8 }rptq Â´ yptq} â€œ Î·1 .

(27)

Defining the asymptotic tracking error by the Left-hand Side (LHS) of (27), we see that the
asymptotic prediction error is translated to the asymptotic tracking error.
3.2.2

Error in rpt
9 ` Tq Â´

Bg
Bx pxptq, uptqqf pxptq, uptqq.

Bg
9 ` T q Â´ Bx
Let E2 ptq denote an additive error in the term rpt
pxptq, uptqqf pxptq, uptqq in the RHS
of Eq. (20). Due to this error the controllerâ€™s definition is modified from (20) to the following
equation,

Â¯Â´1 Â´
rpt ` T q Â´ yÌ‚pt ` T q
Bu
Â¯
Bg
`rpt
9 ` Tq Â´
pxptq, uptqqf pxptq, uptqq ` E2 ptq .
Bx
uptq
9
â€œ

Â´ Bg

pxptq, uptqq

(28)

Define
Î·2 :â€œ limsuptÃ‘8 }E2 ptq}.

(29)

Proposition 3.3. Consider the closed-loop system defined by Eqs. (11), (12), and (28),
and suppose that Assumption 2.1 and Assumption 2.2 are satisfied. If the trajectory of the
closed-loop system is nonsingular, then
limsuptÃ‘8 }rptq Â´ yÌ‚ptq} Ä Î·2 .

(30)

The proof follows as a corollary of Proposition 3.4 below, hence it is not proved here.
This result, together with the definition of Î·1 (Eq. (26)), imply that
limsuptÃ‘8 }rptq Â´ yptq} Ä Î·1 ` Î·2 .

(31)

We next show that it is possible to reduce the upper bound on the asymptotic tracking error in
Eq. (31) by speeding up the controller. Fix Î± Ä… 1, and extend the definition of the controller
from Eq. (28) to the following equation,
Â¯Â´1 Â´` `
Ë˜
Î± rpt ` T q Â´ yÌ‚pt ` T q
Bu
Â¯
Bg
9 ` Tq Â´
`rpt
pxptq, uptqqf pxptq, uptqq ` E2 ptq .
Bx

9
uptq
â€œ

Â´ Bg

pxptq, uptqq

(32)

Observe
that the gain
`
Ë˜ Î± does not multiply the entire RHS of Eq. (32) but only the term
rpt ` T q Â´ yÌ‚pt ` T q therein. The result, formalized by the next proposition and the ensuing
corollary, shows that it is possible to attenuate the effect of Î·2 but not Î·1 .

9

Proposition 3.4. Consider the closed-loop system defined by Eqs. (11), (12), and (32),
and suppose that Assumption 2.1 and Assumption 2.2 are satisfied. If the trajectory of the
closed-loop system is nonsingular, then
Î·2
(33)
limsuptÃ‘8 }rptq Â´ yÌ‚ptq} Ä .
Î±
Proof. Define the Lyapunov function V pxptq, uptqq by Eq. (21). Taking derivatives with
respect to t, and recalling that yÌ‚pt ` T q â€œ gpxptq, uptqq, we have that
@
D
d
9 ` T q Â´ gpxptq, uptqq .
V9 pxptq, uptqq â€œ rpt ` T q Â´ yÌ‚pt ` T q, rpt
(34)
dt
By Eqs. (11) and (32), after some algebra we obtain that
d
Bg
gpxptq, uptqq â€œ
pxptq, uptqqf pxptq, uptqq
dt
Bx
`
Ë˜
Bg
pxptq, uptqqf pxptq, uptqq ` E2 ptq.
`Î± rpt ` T q Â´ yÌ‚pt ` T q ` rpt
9 ` Tq Â´
Bx
Using Eq. (35) in Eq. (34) we obtain,
@
`
Ë˜
D
V9 pxptq, uptqq â€œ rpt ` T q Â´ yÌ‚pt ` T q, Â´Î± rpt ` T q Â´ yÌ‚pt ` T q Â´ E2 ptq .

(35)

(36)

Consequently, for every  Ä… 0 and t Ä› 0, if Î±}rpt ` T q Â´ yÌ‚pt ` T q} Ä… }E2 ptq} `  then, by the
Cauchy-Schwarz inequality, V9 pxptq, uptqq Äƒ Â´||rpt ` T q Â´ yÌ‚pt ` T q||. This, together with the
definition of Î·2 (Eq. 29)), implies Eq. (33) thereby completing the proof.
l
Corollary 3.5. Under the conditions of Proposition 3.4,
limsuptÃ‘8 }rptq Â´ yptq} Ä Î·1 `

Î·2
.
Î±

Proof. It follows immediately from Proposition 3.4 and the definition of Î·1 .

(37)
l

The enhanced controller, defined by Eq. (32), seems to have better convergence than the
earlier controller defined by Eq. (15). However, the latter controller still has a place since it is
simpler, and also can be more practical in situations where rpt ` T q is computed in real time
9 ` T q cannot be computed at that time. An intermediate control algorithm
(at time t) but rpt
between (15) and (32), defined by Eq. (38), is also possible.
Â´ Bg
Â¯Â´1 Â´ `
Â¯
Ë˜ Bg
9
uptq
â€œ
pxptq, uptqq
Î± rpt ` T q Â´ yÌ‚pt ` T q Â´
pxptq, uptqqf pxptq, uptqq .
(38)
Bu
Bx
For the purpose of analysis, the controllers based on Eqs. (15) and (38) can be viewed as
Bg
9 ` T q ` Bx
special cases of the controller defined by (32) by setting E2 ptq :â€œ Â´rpt
pxptq, uptqq,
9 ` T q, respectively.
and E2 ptq â€œ Â´rpt
Â´
3.2.3

Error in

Bg
Bu pxptq, uptqq

Â¯Â´1

.

Convergence of the standard Newton-Raphson method for solving nonlinear equations is
known to be robust to errors in the computation of the inverse-Jacobian (see, e.g., [19]).
A similar robustness holds for convergence of the controller defined by Eq. (32) with respect
Â¯Â´1
Â´
Bg
to errors in the term Bu
pxptq, uptqq
, and Eq. (33) still holds if such errors are small
enough. Therefore we henceforth implicitly assume that the inverse-Jacobian in Eq. (32) is
exact.
10

4

Stability Analysis

The experience with simulation examples in [15] suggests that an increasing of the controller
rate Î± can stabilize the closed-loop system. This motivates us to explore verifiable conditions
under which this happens. It may be a difficult problem for general nonlinear systems, because
the controller uptq is defined implicitly by a differential equation, whose RHS is not explicit
but contains a term, gpxptq, uptqq, which also is defined by a differential equation. Therefore,
while the problem is posed in a general setting, we carry out an analysis only for linear systems
and defer the general case for a future study.
Consider a closed-loop system defined by Eqs. (11)-(12), with the controller defined by
either (15), (32) with E2 ptq â€ 0, or (38), with a fixed Î± Ä… 0. It can be viewed as a dynamical
system with state variable pxptqJ , uptqJ qJ P Rn`m and input rptq P Rm . We call the state
pxptqJ , uptqJ qJ P Rn`m the augmented state, and denote it by zptq. The input trptqu is
assumed to be a continuous and piecewise continuously-differentiable function of t, and we
denote the L8 norms of trptqu and trptqu
9
by }r}8 and }r}
9 8 , respectively. Assume a given
compact set Î“ Ä‚ Rn`m such that the initial (augmented) state z0 :â€œ zp0q is constrained to Î“.
The stability notion we have in mind is the following variant of the concept of BIBS stability,
uniform in Î±:
Definition 4.1. The system is Î±-stable if there exist Î±Ì„ Ä› 0 and three class-K functions, Î²psq,
Î³1 psq and Î³2 psq such that, for every initial state z0 P Î“, input trptqu, and Î± Ä› Î±Ì„,
9 8 q.
}zptq} Ä Î²p}zp0q}q ` Î³1 p}r}8 q ` Î³2 p}r}

(39)

Note the fact that the three class-K functions are independent of Î± P rÎ±Ì„, 8q.
The following result ascertains that Î±-stability implies asymptotic tracking of rptq by yÌ‚ptq.
Proposition 4.2. Consider the closed-loop system defined by Eqs. (11)-(12) with the controller defined by either (15), (32) with E2 ptq â€ 0, or (38). Suppose that Assumption 2.1 and
Assumption 2.2 are satisfied. If the system is Î±-stable then, for every input trptqu such that
9 8 Äƒ 8, for every zp0q P Î“, and for every nonsingular trajectory tzptqu,
}r}8 Äƒ 8 and }r}
lim limsuptÃ‘8 }rptq Â´ yÌ‚ptq} â€œ 0.

Î±Ã‘8

(40)

Proof. Consider first the case where the controller is defined by Eq. (32) with E2 ptq â€ 0.
Then for every Î± Ä… 0, Î·2 â€œ 0, and hence, by Proposition 3.4, limtÃ‘8 ||rptq Â´ yÌ‚ptq|| â€œ 0, this
implies (40). Next, consider the case where the controller is defined by Eq. (15). It is a
Bg
special case of Eq. (32) with E2 ptq â€œ Â´rpt
9 ` T q ` Bx
pxptq, uptqqf pxptq, uptqq. Therefore, if the
system is Î±-stable then there exists Î·Ì„2 Ä… 0 and Î±Ì„ Ä… 0 such that, for every Î± Ä› Î±Ì„, Î·2 Ä Î·Ì„2 .
Now Eq. (40) follows from Eq. (33). Finally, the case where the controller is defined by Eq.
9 ` T q.
l
(38) is simpler since it corresponds to (32) with E2 ptq â€œ Â´rpt
Consider now the special case where the system is linear and time invariant. Accordingly,
it is defined by the equations
xptq
9
â€œ Axptq ` Buptq,

yptq â€œ Cxptq,

(41)

where A P RnË†n , B P RnË†m , and C P RmË†n are given matrices. Suppose that the controller
is defined by either Eq. (15), (32) with E2 ptq â€ 0, or (38); in either case Assumption 2.1 and
11

Assumption 2.2 are satisfied. The respective analyses of these three cases are almost identical,
hence we perform a detailed analysis only for the case of (15) and point out in context the
required modifications for the two other cases. Furthermore, to simplify the exposition, we
assume that A is nonsingular.
Fix T Ä… 0. By Eqs. (17)-(18), we have that
gpxptq, uptqq â€œ CeAT xptq ` CAÂ´1 peAT Â´ IqBuptq,

(42)

where I denotes the identity matrix. Therefore,
Bg
pxptq, uptqq â€œ CeAT ,
Bx

(43)

Bg
pxptq, uptqq â€œ CAÂ´1 peAT Â´ IqB.
Bu

(44)

and

We assume that the matrix

Bg
Bu pxptq, uptqq

â€œ CAÂ´1 peAT Â´ IqB is nonsingular.

With the controller defined by (15), the closed-loop system has the form of Eq. (16). By
Eqs. (15) and (42)-(44) the controller has the following form,
Â´
Â¯Â´1
Â´
Â¯Â´1
9
CeAT xptq Â´ Î±uptq. (45)
rpt ` T q Â´ Î± CAÂ´1 peAT Â´ IqB
uptq
â€œ Î± CAÂ´1 peAT Â´ IqB
Therefore Eq. (16) assumes the form
Ë™
Ë†
Ë™
Ë†
xptq
9
xptq
â€œ Î¦Î±
` Î¨Î± rpt ` T q,
9
uptq
uptq

(46)

where Î¦Î± is an pn ` mq Ë† pn ` mq matrix having the following block structure,
Ëœ
Â¸
A
B
Â´
Â¯Â´1
,
Î¦Î± â€œ
Â´Î± CAÂ´1 peAT Â´ IqBq
CeAT Â´Î±I
and Î¨Î± is an pn ` mq Ë† n matrix of the form
Â¸
Ëœ
0
Â´
Â¯Â´1 ,
Î¨Î± â€œ
Î± CAÂ´1 peAT Â´ IqB

(47)

(48)

where the block of zeros is n Ë† n.
Observe that Î± multiplies the last m rows of Î¦Î±
can write Î¦Î± in the following way,
Â¨
Ï†1,1
Ï†1,2
Â¨
Ëš Ï†2,1
Ï†
Â¨
2,2
Ëš
Ëš
Â¨
Â¨
Â¨
Ëš
Ëš
Â¨
Â¨
Â¨
Ëš
Ëš
Â¨
Â¨
Â¨
Î¦Î± â€œ Ëš
Ëš Ï†n,1
Ï†n,2
Â¨
Ëš
Ëš Î±Ï†n`1,1 Î±Ï†n`1,2 Â¨
Ëš
Ëš
Â¨
Â¨
Â¨
Ëš
Ë
Â¨
Â¨
Â¨
Î±Ï†n`m,1 Î±Ï†n`m,2 Â¨
12

but none of its first n rows, and hence we
Â¨
Â¨
Â¨
Â¨
Â¨
Â¨
Â¨
Â¨
Â¨
Â¨

Â¨
Ï†1,n`m
Â¨
Ï†2,n`m
Â¨
Â¨
Â¨
Â¨
Â¨
Â¨
Â¨
Ï†n,n`m
Â¨ Î±Ï†n`1,n`m
Â¨
Â¨
Â¨
Â¨
Â¨ Î±Ï†n`m,n`m

Ë›
â€¹
â€¹
â€¹
â€¹
â€¹
â€¹
â€¹
â€¹
â€¹
â€¹
â€¹
â€¹
â€¹
â€¹
â€š

(49)

for some scalars Ï†j,i , j â€œ 1, . . . , n ` m; i â€œ 1, . . . , n ` m. The determinant of sI Â´ Î¦Î± is a
two-dimensional polynomial in Î± and s, which we denote by PÎ± psq. The standard formula
for computing determinants reveals the following result, whose proof can be found in the
appendix.
Lemma 4.3. For every i â€œ 1, . . . , m there exists a polynomial Pi psq in s, of degree no more
than n ` i, such that,
m
Ã¿
Î±i PmÂ´i psq.
(50)
PÎ± psq â€œ
iâ€œ0

Remark 4.4. For the cases where the controller is defined by either (32) with E2 ptq â€ 0
or (38), the only resulting difference to Î¦Î± is that the entries of its last m rows are firstorder polynomials in Î± with possibly-nonzero free coefficients (currently they are first-order
polynomials whose free coefficients are 0). That would not affect the validity of Lemma 4.3 or
the rest of the analysis in this section.
Since by assumption degpPi q Ä n ` i, we can write Pi psq as
Pi psq â€œ

n`i
Ã¿

ai,j sj

(51)

jâ€œ0

for some coefficients ai,j , j â€œ 0, . . . , n`i. We assume, without loss of generality, that ai,n`i â€° 0
to ensure that degpPi q â€œ n ` i. Then
PÎ± psq â€œ

m
Ã¿

Î±i

n`mÂ´i
Ã¿

iâ€œ0

amÂ´i,j sj .

(52)

jâ€œ0

The highest-order term (in s) of PÎ± psq is am,n`m sn`m , and we assume that am,n`m â€œ 1.
We next derive a sufficient condition for the Î±-stability of the system. The condition consists of two polynomials having all of their roots in the Left-Half Plane (LHP). One polynomial
has degree n, the other has degree m, and both are independent of Î± hence the sufficient condition is verifiable.
The first polynomial is P0 psq, which by (50) is the polynomial-coefficient of Î±m , the leading
term in PÎ± psq in terms of the power of Î±. Note (Eq. (51)) that degpP0 q â€œ n.
The second polynomial, denoted by Qpsq, is defined as follows. For every i â€œ 0, . . . , m,
consider the polynomial Pi psq, defined in Eq. (51), whose degree is n ` i. Define a polynomial
PÌƒi psq as the monomial consisting of the highest-order term of Pi psq, namely,
PÌƒi psq â€œ ai,n`i sn`i .

(53)

Next, in analogy to (50), define the family of polynomials parameterized by Î± Ä… 0, tPÌƒÎ± psqu,
by
m
Ã¿
PÌƒÎ± psq â€œ
Î±i PÌƒmÂ´i psq.
(54)
iâ€œ0

By (53),
PÌƒÎ± psq â€œ

m
Ã¿

Î±i amÂ´i,n`mÂ´i sn`mÂ´i .

iâ€œ0

13

(55)

Observe that for every Î± Ä… 0, PÌƒÎ± psq is evenly divisible by sn . Dividing it by sn , we define
QÌƒÎ± psq :â€œ

m
Ã¿

Î±i amÂ´i,n`mÂ´i smÂ´i ,

(56)

iâ€œ0

and we note that
PÌƒÎ± psq â€œ sn QÌƒÎ± psq.

(57)

We make the observation that PÌƒÎ± psq has the degree (in s) of n ` m hence it has n ` m roots;
by (57), n of those roots are at s â€œ 0, and the remaining m roots are the roots of QÌƒÎ± psq.
Finally, we define the mth-degree polynomial Qpsq by setting Î± â€œ 1 in QÌƒÎ± psq (Eq. (56));
namely,
m
Ã¿
amÂ´i,n`mÂ´i smÂ´i .
(58)
Qpsq :â€œ QÌƒ1 psq â€œ
iâ€œ0

Observe that Qpsq is independent of Î±, and its degree is m.
The following result establishes the Î±-stability of the system.
Theorem 4.5. If the polynomials P0 psq and Qpsq have all of their roots in the open Left-Half
Plane (LHP), then the system is Î±-stable.
The proof is based on the following two arguments: For large-enough Î±, (i) the matrix
Î¦Î± is Hurwitz, and (ii) the effect of the gain Î± in Î¨Î± (Eq. (48)) on ||zptq|| is bounded even
though Î± can be arbitrarily large.
To prove the first argument we employ a root-locus technique in a nonstandard setting,
where the functional dependence of PÎ± psq on Î± and s is via a two-dimensional polynomial.
The proof proceeds as follows: First we show that bounded branches of the root locus must
converge to the zeros of P0 psq, and this follows standard root-locus arguments. Then we prove
that unbounded branches have the same asymptotic angles as the angles of the roots of Qpsq,
hence unbounded branches will be in the LHP for large-enough Î± if all of the roots of Qpsq
are in the LHP.
The proof of Theorem 4.5 will be preceded by a sequence of technical lemmas, where those
proofs that are straightforward are relegated to the appendix. Throughout the forthcoming
discussion we denote a generic branch of the root locus of PÎ± psq by tspÎ±quÎ±Ä›0 , or by tspÎ±qu
for a simpler notation.
Lemma 4.6. If tspÎ±qu is bounded over Î± P r0, 8q, then the limit limÎ±Ã‘8 spÎ±q exists and it
is a root of P0 psq.
For a proof, please see the appendix.
Consider next the case where tspÎ±qu is unbounded. Let A Ä‚ r0, 8q be an unbounded set
such that
lim |spÎ±q| â€œ 8.
Î±Ã‘8; Î±PA

Lemma 4.7. There exist constants c Ä… 0 and C Ä… c such that, as Î± Ã‘ 8; Î± P A,
c Ä liminf

|spÎ±q|
,
Î±

and

14

limsup

|spÎ±q|
Ä C.
Î±

(59)

Proof. Consider first the right inequality of Eq. (59). Let us argue by contradiction. If
that inequality does not hold, there exists an unbounded set A1 Ä‚ A such that, as Î± Ã‘ 8,
Î± P A1 ,
|spÎ±q|
Ã‘ 8.
(60)
Î±
By Eq. (50), @Î± P A1 ,
m
Ã¿
Î±i PmÂ´i pspÎ±qq â€œ 0.
iâ€œ0

Dividing this equation by

spÎ±qm`n ,

we get that

m Â´
m Â´
Ã¿
Ã¿
Î± Â¯i PmÂ´i pspÎ±qq
Î± Â¯i PmÂ´i pspÎ±qq Pm pspÎ±qq
Ë†
â€œ
Ë†
`
â€œ 0.
spÎ±q
spÎ±qn`mÂ´i
spÎ±q
spÎ±qn`mÂ´i
spÎ±qm`n
iâ€œ0
iâ€œ1

(61)

But degpPmÂ´i q â€œ n ` m Â´ i, hence, and by (51), as Î± Ã‘ 8; Î± P A1 ,
PmÂ´i pspÎ±qq
Ã‘ amÂ´i,n`mÂ´i
spÎ±qn`mÂ´i
which is a finite-magnitude number. Therefore, and by (60),
m Â´
Ã¿
Î± Â¯i PmÂ´i pspÎ±qq
Ë†
Ã‘0
spÎ±q
spÎ±qn`mÂ´i
iâ€œ1

as Î± Ã‘ 0; Î± P A1 . Furthermore, degpPm q â€œ n ` m, hence, and since (by assumption) the
leading coefficient of Pm is 1,
Pm pspÎ±qq
Ã‘ 1.
spÎ±qm`n
This contradicts (61) thereby ascertaining the right inequality of (59).
The left inequality of (59) is provable by similar arguments, hence it is relegated to the
appendix.
l
Given a polynomial PÎ± psq (as defined by (50)) and Î± Ä› 0, we next examine the derivatives
of spÎ±q with respect to the coefficients of PmÂ´i psq, for i â€œ 0, . . . , m, as defined by (51). For this
purpose we consider all but the leading coefficients, namely amÂ´i,j , j â€œ 0, . . . , n ` m Â´ i Â´ 1.
We denote these derivatives by BaBspÎ±q
. For apparent reasons of notation, we will use ` and Î½
mÂ´i,j
instead of i and j in the following discussion
Lemma 4.8. There exist r Ä› 0 and L Ä… 0 such that, if |spÎ±q| Ä› r, then for every ` â€œ 0, . . . , m,
and for every Î½ â€œ 0, . . . , n ` m Â´ ` Â´ 1,
Ë‡ BspÎ±q Ë‡
Ë‡
Ë‡
(62)
Ë‡
Ë‡ Ä L.
BamÂ´`,Î½
The proof is carried out in the appendix by realizing that PÎ± pspÎ±qq â€œ 0, and taking
derivatives of this equation with respect to amÂ´`,Î½ . We remark that the assertion of Lemma 4.8
may not hold true for the case where Î½ â€œ n ` m Â´ `, namely for the leading coefficient of
PmÂ´` psq.
Recall the definition of PÌƒÎ± psq which was made in Eq. (55). Similarly to the notation spÎ±q
for a generic root of PÎ± pÂ¨q, we denote by tsÌƒpÎ±qu a generic branch of the root locus of PÌƒÎ± pÂ¨q.
15

Lemma 4.9. There exist constants r Ä… 0 and K Ä… 0 such that, if |spÎ±q| Ä› r for some Î± Ä… 0,
then there exists sÌƒpÎ±q such that
|sÌƒpÎ±q Â´ spÎ±q| Äƒ K.
(63)
Proof. The polynomials PmÂ´` psq and PÌƒmÂ´` psq, ` â€œ 0, . . . , m, have the same respective
leading coefficients, amÂ´`,n`mÂ´` . As for the other coefficients, those of PmÂ´` psq are amÂ´`,Î½ ,
Î½ â€œ 0, . . . , n ` m Â´ ` Â´ 1, and those of PÌƒmÂ´` psq are 0. The statement now follows from
Lemma 4.8 and the mean-value theorem.
l
Fix Î± Ä… 0. It has been mentioned that, by Eq. (57), n of the roots of PÌƒÎ± psq are at 0, and
its remaining m roots are the roots of QÌƒÎ± psq as defined by (56). We next characterize the
roots of QÌƒÎ± psq.
Lemma 4.10. Let s be a root of the polynomial QpÂ¨q. Then for every Î± Ä… 0, Î±s is a root of
the polynomial QÌƒÎ± pÂ¨q.
Proof. By Eqs. (56) and (58), we see that for every complex variable s, and for every
Î± Ä… 0,
QÌƒÎ± pÎ±sq â€œ Î±m Qpsq.
(64)
Therefore, if s is a root of QpÂ¨q, Î±s is a root of QÌƒÎ± pÂ¨q.

l

Given a complex variable s, let =s denote the angle (argument) of s with respect to the
positive side of the horizontal axis. Thus, if s â€œ |s|ejÏ† according to its polar coordinates, then
=s â€œ Ï†.
Lemma 4.11. Let si , i â€œ 1, . . . , m denote the roots of the polynomial Qpsq. Suppose that
none of these roots is 0. For every unbounded branch of the root locus of PÎ± psq, denoted by
tspÎ±qu, there exists i P t1, . . . , mu such that,
lim =spÎ±q â€œ =si .

Î±Ã‘8

(65)

Proof. By Lemma 4.10, m of the root-locusâ€™ branches of QÌƒÎ± psq are straight lines tÎ±si u8
Î±â€œ0 ,
i â€œ 1, . . . , m. By Eq. (57), these are the unbounded root loci of PÌƒÎ± psq. Therefore, and by
Lemma 4.9, if tspÎ±qu is unbounded, there exist r Ä… 0, K Ä… 0 and i P t1, . . . , mu such that, if
|spÎ±q| Ä… r, then |spÎ±q Â´ Î±si | Äƒ K. This implies Eq. (65) and completes the proof.
l
Proof of Theorem 4.5. Suppose that all of the roots of the polynomials P0 psq and Qpsq
are in the LHP. Then Lemma 4.6 and Lemma 4.11 imply that there exists Î± Ä› 0 such that
@Î± Ä› Î±Ì„, the closed-loop system matrix Î¦Î± is Hurwitz. According the Definition 4.1, we have
to show that the class-K functions Î² and Î³1 satisfy Eq. (39) for all large-enough Î± (Î³2 pÂ¨q is
9
irrelevant because trptqu
is not an explicit part of the input). This is not apparent in light of
the fact that the matrix Î¨Î± has a multiplicative Î±-term (see Eq. (48)). Nonetheless this is
true because of the block of zeros in Î¨Î± . We next show this point.
As a matter of notation, we say that a matrix is OpÎ±k q for an integer k (possibly nonpositive) if the highest power of Î± among all of its elements is Î±k . Recall Eq. (49), and note, that
the first n rows of Î¦Î± do not contain Î±, and the last m rows contain Î± as a multiplicative
factor. Therefore, by Cramerâ€™s rule, the first n columns of psI Â´ Î¦Î± qÂ´1 are OpÎ±0 q, and its last
m columns are OpÎ±Â´1 q. Denote by Î¦1,Î± psq and Î¦2,Î± psq the matrices comprised of the first n
columns and last m columns of psI Â´ Î¦Î± qÂ´1 , respectively. Then Î¦1,Î± psq is OpÎ±0 q, and Î¦2,Î± psq
16

is OpÎ±Â´1 q. As for Î¨Î± , denote the matrix comprised of its last m rows by Î¨2,Î± . Then (by
(48)), Î¨2,Î± is OpÎ±1 q. Now the r-to-z (input-to-state) transfer function is
Ë™
Ë†
`
Ë˜
0
Â´1
â€œ Î¦2,Î± psqÎ¨2,Î± .
(66)
psI Â´ Î¦Î± q Î¨Î± â€œ Î¦1,Î± psq Î¦2,Î± psq
Î¨2,Î±
Since Î¦2,Î± psq is OpÎ±Â´1 q and Î¨2,Î± is OpÎ±1 q, psI Â´ Î¦Î± qÂ´1 Î¨2,Î± is OpÎ±0 q. Therefore, and since
Î¦Î± is Hurwitz, there exist Ïƒ Ä… 0 and Î±Ì„ Ä› 0 such that, for every Î± Ä› Î±Ì„, the real parts all the
poles of the r-to-z transfer function are smaller than Â´Ïƒ. This implies the Î±-stability of the
closed-loop system.
l
We remark that if either matrix P0 psq or Qpsq has a root in the RHP then the closed-loop
system is not Î±-stable.
Example. The following example is of an Î±-stable system where the plant subsystem is
neither stable not of a minimum phase. Let
Ë†
Ë™
Ë† Ë™
`
Ë˜
2
1
0
Aâ€œ
,
Bâ€œ
,
C â€œ Â´10 1 ,
Â´1 Â´1
1
and T â€œ 0.25s. The plant transfer function is
Gpsq â€œ

s Â´ 12
,
s2 Â´ s Â´ 1

`
Ë˜
`
whichË˜ is unstable and not of a minimum phase. Next, PÎ± psq â€œ s3 Â´ s2 Â´ s ` Î± s2 ` 16.19s `
97.18 . Therefore P0 â€œ s2 `16.19s`97.18 and P1 psq â€œ s3 Â´s2 Â´s, implying that Qpsq â€œ s`1.
Both Qpsq and P0 psq have all of their roots in the LHP, hence the system is Î±-stable.

5

Simulation Experiments

This section presents simulation results for two problems, namely an inverted pendulum and
a platoon of autonomous vehicles. For the inverted pendulum we use the controller defined by
Eq. (32). As for the platoon system, we assume that the vehiclesâ€™ controllers have no a-priori
9
for their respective reference trajectories, therefore we use the controllers
knowledge of trptqu
defined by Eqs. (15) and (38). We then present the better results of the two, which are with
(15).

5.1

Inverted pendulum

The considered pendulum is mounted on a cart which can move in the two directions of a
given line, parameterized by z P R. Let Î¸ denote the angle of the pendulum from its pivot on
the cart to the left of the upward-vertical direction. Thus, if the pendulum is pointed upwards
then Î¸ â€œ 0, and if it points sideways along the z axis in the positive direction then Î¸ â€œ Â´Ï€{2
rads. Let M and m denote the masses of the cart and pendulum, respectively, and let ` be
the distance from the cart to the pendulumâ€™s center of mass. Furthermore, let F be the force
applied to the cart in the positive direction of the z axis, and let Î¸ be the systemâ€™s output to
be controlled.
9 J . However,
9 Î¸, Î¸q
This system generally is four-dimensional with the state variable x :â€œ pz, z,
a simpler, second-order representation of the pendulumâ€™s motion can be obtained by making
17

the following two assumptions: 1). The pendulum consists of a weightless rod and a point
mass at its end. 2). There is no friction in the movement of either cart or pendulum. In this
case, the dynamic equation of the pendulumâ€™s motion becomes
pM ` ` m` sin2 Î¸qÎ¸: ` m`Î¸92 psin Î¸qpcos Î¸q ` pM ` mqg sin Î¸ â€œ F cos Î¸;

(67)

see [20]. This equation provides a state-space representation of the system where the state
9 J , the input is u â€œ F , and the output is y â€œ Î¸. We chose the following
variable is x â€œ pÎ¸, Î¸q
parameters for the simulation: M â€œ 1kg, m â€œ 0.2kg, ` â€œ 2m, and g â€œ 9.81m{s2 . The
simulation starts at the initial state xp0q â€œ p Ï€6 , 0qJ , and it solves the state equation in a
specified horizon t P r0, tf s by the forward Euler method with the step-size dt â€œ 0.01s. The
control algorithm uses the prediction horizon T â€œ 0.2s, and it computes the predicted state
trajectory (Eq. (17)) by the forward-Euler method with the step-size âˆ†t â€œ 0.01T . The initial
condition for the controller equation (32) is up0q â€œ 0.
The target trajectory for the tracking-control experiment is rptq â€œ Â´ Ï€6 ` Ï€3 sin t, which
oscillates between the angles of 30o and Â´90o . At Â´90o the pendulum points at the horizontal
direction along the positive z-axis, and this can be problematic because it is physically impossible to balance the pendulum at this angle. However, in the present experiment rptq just
touches the horizontal direction and then immediately retreats therefrom. The time-horizon
for the simulation is tf â€œ 25s.
For the controllerâ€™s equation (32) we first took Î± â€œ 1, and noted convergence of Î¸ptq to
rptq in about 2 seconds. To speed up the convergence we increased the controllerâ€™s gain to
Î± â€œ 35, and the results are depicted in Figures 2-4. Figure 2 shows the graphs of Î¸ptq in
blue, and the reference rptq in red. The two graphs appear to coalesce for the first time at
about t â€œ 1s, and remain close to each other except for slight differences when rptq â€ Â´ Ï€2
rads (about -1.57 in the graph). This is not surprising because at such points the pendulum is
horizontal. The maximum error, |rptq Â´ Î¸ptq|, for t Ä› 1 was measured from the graphs at 0.022
radians, or 1.2605 degrees. To further highlight the discrepancies between Î¸ptq and rptq we
9 :â€œ x2 ptq. The results are depicted in Figure 3, and they clearly
plot the angular velocity, Î¸ptq
9
at points where Î¸ â€ Â´ Ï€2 rads. Furthermore,
show a distortion from the sinusoidal form of rptq
we plot the graph of the control signal uptq in Figure 4, and we notice large peaks at the
point where rptq â€œ Â´ Ï€2 . All of this is expected in light of the earlier remarks concerning the
challenges of controlling the pendulum at (or close to) the horizontal angle.
To verify that the discrepancies between rptq and Î¸ptq, and the large peaks in uptq indeed
are due to the fact that rptq reaches Â´Ï€{2 periodically, we attenuated the sinusoid part of rptq
by the factor of 0.8, and thus rptq â€œ Â´ Ï€6 ` 0.8 Ï€3 sin t, corresponding to oscillations between
9
the angles of 18o and Â´78o . We only show the resulting graph of Î¸ptq
since it most clearly
indicates the distortions in Î¸ptq. This graph is depicted in Figure 5, where its distortion at
about the lower-peak angle of Â´78o is barely visible. The discrepancies between Î¸ptq and rptq
is hardly noticeable from their respective graphs which are not shown here. Also, the peak
control at these values (not shown here) is reduced to nearly 60, which is about 10% of its
value obtained from the full-sinusoidal swing that is depicted in Figure 4.

5.2

Platoon of autonomous vehicles

The simulation experiment described in this subsection concerns the planar motion of a platoon, controlled to follow a given path in the pz1 , z2 q plane. The platoon consists of four agents
18

Angle [rads]

1

0

-1

-2
0

5

10

15

20

25

Time [s]

Figure 2: Inverted pendulum: Î¸ and r vs. t

Angular velocity [rad/s]

2
1
0
-1
-2
-3
0

5

10

15

20

25

20

25

Time [s]

Figure 3: Inverted pendulum: Î¸9 vs. t

Input, u

600
400
200
0
0

5

10

15

Time [s]

Figure 4: Inverted pendulum: u vs. t

19

Angular velocity [rad/s]

1
0
-1
-2
-3
0

5

10

15

20

25

Time [s]

Figure 5: Inverted pendulum, reduced oscillations: Î¸9 vs. t
(vehicles), denoted by Ai , i â€œ 1, 2, 3, 4, in the order of their movement. A1 is the leading vehicle, and Ai follows AiÂ´1 , i â€œ 2, 3, 4. A1 is provided with an exogenous reference trajectory
(path) to track, tr1 ptqu, and for i â€œ 2, 3, 4, Ai attempts to follow AiÂ´1 at a prescribed distance
(arclength) of d m on the path. Whereas the target reference for each agent remains on the
path tr1 ptqu, the agent itself can get off the path while pursuing its target reference. In this
way the agentsâ€™ motions are two-dimensional and not confined to one-dimensional curves. We
assume that each agent controls its own motion: u1 ptq depends on r1 ptq, while for i â€œ 2, 3, 4,
ui ptq is computed by the position and velocity of AiÂ´1 , which are assumed to be measured by
Ai or transmitted to it by AiÂ´1 .
The motion-dynamics of the vehicles follow the bicycle model, a sixth-order nonlinear
system that has been extensively used in the design and analysis of motion control for autonomous vehicles; see, e.g., [21] and references therein. The state space consists of the
9 J , where z1 and z2 are the planer position-coordinates of the
six-tuple x â€œ pz1 , z2 , v` , vn , Ïˆ, Ïˆq
center of gravity of the vehicle, v` and vn are the longitudinal and lateral velocities, Ïˆ is the
heading of the vehicle and Ïˆ9 is its angular velocity. The input, u â€œ pa` , Î´f qJ , consists of the
longitudinal acceleration and steering angle of the front wheel, respectively, and the output
is the position of the center of gravity of the vehicle, namely y â€œ pz1 , z2 qJ .
The dynamic equations of the vehicles are given by the following equations (see [22]),
z91 â€œ v` cos Ïˆ Â´ vn sin Ïˆ

(68)

z92 â€œ v` sin Ïˆ ` vn cos Ïˆ
9 n ` a`
v9 ` â€œ Ïˆv

(69)

9 ` ` 2 pFc,f cos Î´f ` Fc,r q {m
v9 n â€œ Â´Ïˆv
Ïˆ: â€œ 2 plf Fc,f cos Î´f Â´ lr Fc,r q {Iz ,

(71)

(70)

(72)

where m is the mass of the vehicle, lf and lr are the front and rear axlesâ€™ distances from the
vehicleâ€™s center of mass, Iz is the yaw moment of inertia, and Fc,f and Fc,r are the lateral
forces on the front and rear wheels. These forces are approximated by the following equations,
Â´
Â´
Â¯Â¯
9 `
Fc,f â€œ CÎ±,f Î´f Â´ tanÂ´1 pvn ` lf Ïˆq{v
(73)
Â´
Â¯
9 ` ,
Fc,r â€œ Â´CÎ±,r tanÂ´1 pvn Â´ lr Ïˆq{v
(74)
20

where CÎ±,f and CÎ±,r are the cornering stiffness of the front and rear tires, respectively.
In the simulation we used the following model-parameters as in [23], Volvo V70 model,
except for Iz (not provided there) which has been estimated by averaging data from cars of
similar weights and dimensions. Thus, m â€œ 1, 700kg, lr â€œ 1.5m, lf â€œ 1.5m, Iz â€œ 2, 500kg Â¨ m2 ,
and CÎ±f â€œ CÎ±r â€œ 29, 963.5N/rad. As for the considered problem, controller and simulation
parameters, the desired inter-agent distance is d â€œ 10m, the simulation horizon is tf â€œ 38s,
and the discretization step size for the simulation is dt â€œ 0.01 secs. The controller prediction
horizon is set to T â€œ 0.5s, and the discretization time step for the predictor is âˆ†T â€œ 0.001T.
The controllersâ€™ speedup factor is Î± â€œ 100 for all the vehicles. The target trajectory tr1 ptqu is
indicated by the curve in Figure 6, and its acceleration along the path is indicated by the blue
graph in Figure 7. Its initial speed is r91 p0q â€œ 0, and its largest speed, obtained at t P r10, 15s
and again at t P r25, 30s, is 20m/s. At the point of largest curvature, when z2 attains its
maximum (see Figure 6), its speed is 8.66m/s. The four vehicles start at rest at the point
r1 p0q, and the initial condition of their controller is up0q â€œ p2, 0qJ .
Figures 6-9 present simulation results with the controller defined by Eq. (15). Figure
6 depicts the target and agent-trajectories from left to right in the pz1 , z2 q plane. Both
coordinates z1 and z2 are of the same scale thereby indicating quite large curvature of the
target trajectory at the point of maximum z2 . Figure 8 shows the graphs of the lateral
(normal) errors of the vehiclesâ€™ centers of gravity from the target trajectory tr1 ptqu, and we
note that the relatively large error-spurts correspond to the larger curvatures indicated in
Figure 6. Furthermore, as expected, the errors of later vehicles in the platoon tend to be
larger than those of earlier ones. The maximum lateral error, obtained for A4 , is about 38
cm.
Graphs of an approximate measure of the inter-agent distances vs. time are shown in
Figure 9. We have to use an approximate (not exact) distance for the following reason: The
objective of the control law is to drive the vehicles to the path tr1 ptqu where they maintain
an inter-agent distance of 10m. The term â€œdistanceâ€ between two consecutive vehicles means
the arclength between them, which is well defined as long as both vehicles are on the path,
but not well defined when one or both of them are off the path. Therefore we display, in
Figure 9, the approximate measure of distance between two vehicles defined as the sum of the
Euclidean distance of each vehicle to the nearest-point to it on the path, and the arclength
between these two nearest points.2 The justification for this measure of distance is that the
control algorithm drives the vehicles towards the path, where this measure coincides with the
arclength. In fact, Figure 8 shows that the vehicles converge to the path tr1 u except for at
points of large curvature, and Figure 9 displays a convergence of the corresponding measure
of distance towards 10m except at such points.
Finally, the longitudinal accelerations of the vehicles are depicted in Figure 7. Although
they may make for an uncomfortable ride, they closely track the acceleration of the target
path tr1 ptqu, with a notable deviation corresponding to its region of largest curvature.

6

Experimental Results

This section describes results of laboratory experiments in which a platoon of four mobile
robots (agents) attempts to maintain a given inter-agent distance. The present system is
2

The nearest point is assumed to be unique.

21

Figure 6: Platoon: target trajectory in the z-plane

Figure 7: Platoon: Reference-path and vehicle accelerations

22

Figure 8: Platoon: lateral errors vs. time

Figure 9: Platoon: approximate inter-agent distances

Figure 10: Experiment: Stills of the robotsâ€™ positions around the curve

23

different from the one considered in Subsection 5.2 in several ways including the following
three: (i) The experimental setting is a laboratory vs. simulation, (ii) the vehiclesâ€™ dynamic
equations follow a unicycle model vs. a bicycle model, and (iii) Ai , i â€œ 2, 3, 4, only have to
maintain the given inter-agent distance from AiÂ´1 but not follow its trajectory.
The platoon consists of four agents denoted by Ai , i â€œ 1, . . . , 4, according to their order.
The lead agent, A1 , is assigned its planar target trajectory, tr1 ptqu, by an exogenous source,
and for every i â€œ 2, 3, 4, Ai aims at keeping a given Euclidean distance from AiÂ´1 .
The experiments were conducted in the Robotarium, a remotely-accessible testing facility
for motion control of robotic systems located at the Georgia Tech campus [24]. The vehicles
in the Robotarium are differential-drive robots, approximately 15cm in diameter, which were
designed and assembled in-house. Their motion is modelled by unicycle dynamics having the
following form,
Â¨
Ë› Â¨
Ë›
Ë™
z91 ptq
cos Ïˆptq 0 Ë†
Ëz92 ptqâ€š â€œ Ë sin Ïˆptq 0â€š vptq ,
(75)
Ï‰ptq
9
0
1
Ïˆptq
where z :â€œ pz1 , z2 qJ P R2 is the center of gravity of a robot and Ïˆ is its heading. Eq. (75)
is a state-space representation of a vehicle with the state variable x :â€œ pz1 , z2 , ÏˆqJ and a
control input u :â€œ pv, Ï‰qJ , where v and Ï‰ are its longitudinal velocity and angular velocity,
respectively. The output of the system is yptq :â€œ zptq â€œ pz1 ptq, z2 ptqqJ .
Fix a prediction horizon T Ä… 0. A direct integration of Eq. (17), together with (18), result
in the following closed-form for the output predictor yÌ‚pt ` T q :â€œ gpxptq, uptqq,
`
Ë˜
`
Ë˜ Ë™
Ë†
Ë™
Ë†
vptq
z1 ptq
sin Ïˆptq
`
Ï‰ptqT
Â´
sin
Ïˆptq
`
Ë˜
`
Ë˜ ;
gpxptq, uptqq â€œ
`
(76)
z2 ptq
Ï‰ptq Â´ cos Ïˆptq ` Ï‰T ` cos Ïˆptq
if Ï‰ptq â€œ 0, Lâ€™Hopitalâ€™s rule yields
Ë†
gpxptq, uptqq â€œ

z1 ptq
z2 ptq

Ë™

Ë†
` vptqT

cospÏˆptqq
sinpÏˆptqq

Ë™
.

(77)

The controller uses this functional closed form and does not resort to numerical integration
of (17).
The future target-point ri pt ` T q is defined for the agent Ai according to the following
heuristic. For i â€œ 1, tr1 ptqu is assumed to be known in advance and hence r1 pt ` T q can be
used in the computations of A1 at time t. For i â€œ 2, 3, 4, the definitions and computations of
ri pt ` T q are recursive, as follows. At time t, let `i denote the directional line from yÌ‚iÂ´1 pt ` T q
towards yi ptq, namely the line connecting the predicted position of AiÂ´1 towards the current
position of Ai . Then we define ri pt`T q as the point on `i of distance d m from yÌ‚iÂ´1 pt`T q. This
procedure is justified by the observation that if A1 moves in a straight line, then subsequent
agents will converge to that line behind each other at the target distance d.
We conducted experiments with the controller defined by Eq. (38), Î± â€œ 45 and T â€œ
0.25s. The exogenous target curve, tr1 ptqu, is an ellipse defined by the equation r1 ptq â€œ
`
Ë˜J
1.1 sinp0.06tq, 0.7 cosp0.06tq , and the target inter-robot distance is d â€œ 0.25m. The results
are depicted in Figures 10-12. Figure 10 shows stills captured during the experiment. In
the leftmost image the robots are initialized, and in subsequent images of their positions are
shown; the first robot moves along the closed curve defined by tr1 ptqu while the remaining
24

0.6
0.5
0.4
0.3
0.2
0

20

40

60

80

100

120

140

Figure 11: Experiment: inter-robot distances vs. time
0.8
0.6
0.4
0.2
0
0

20

40

60

80

100

120

140

Figure 12: Experiment: tracking error vs. time
robots converge to the target inter-robot distances. Figure 11 depicts the inter-robot distances
vs. t; note convergence towards the target distance of 0.25m. Finally, Figure 12 depicts the
graph of the tracking error }yi ptqÂ´ri ptq} versus time, and we discern rapid convergence towards
0 for all four robots. An additional view of the control-algorithmâ€™s performance can be seen
in the video clip contained in [25].

7

Conclusions

This paper presents a tracking-control technique based on a fluid-flow version of the NewtonRaphson method, output prediction and controller speedup. The controller is simple to compute and may have large, even global stability domains of attraction. A stability analysis is
carried out for linear systems, while examples of nonlinear systems are tested by simulation
and lab experiments.
Current investigations concern theoretical and practical problems. On the theoretical side,
the most pressing challenge is to derive sufficient conditions for the Î± stability of closedloop systems in a general setting of nonlinear dynamical systems. Practical considerations
include the testing of the control technique on applications in mobile robotics and autonomous
25

vehicles. Of a particular interest is to derive alternative output-prediction techniques to the
one presented in this paper, and what comes to mind are methods that are based on learning
and neural nets.

8

Appendix

This section provides proofs of various assertions made throughout the paper.
Proof of Lemma 4.3. The characteristic polynomial of Î¦Î± , denoted by PÎ± psq, is a twodimensional polynomial in pÎ±, sq. Denote its respective degrees in Î± and s by degÎ± pP q and
degs pP q, and define its total degree, denoted by degpP q, as the degree (in q) of the polynomial
Pq pqq.
By Eq. (49), we observe that every element (entry) in the matrix sI Â´Î¦Î± has a total degree
of zero or 1; for example, the pn ` mq Ë† pn ` mq element is s Â´ Î±Ï†n`m,n`m which contains
both Î± and s but not the product of the two. Since the determinant of a matrix consists of
the linear combination of products of elements one from each row, we have that
degpP q â€œ n ` m.

(78)

Furthermore, degÎ± pP q â€œ m, since only the last m rows of Î¦Î± contain the term Î±. Therefore,
Eq. (50) is in force for some polynomials PmÂ´i psq, i â€œ 0, . . . , m, and by 78), the degree (in s)
of PmÂ´i must not exceed n ` pm Â´ iq. This completes the proof.
Proof of Lemma 4.6. We have that PÎ± pspÎ±qq â€œ 0 @ Î± P r0, 8q. Therefore, and by Eq.
(50),
m
Ã¿
Î±i PmÂ´i pspÎ±qq â€œ 0.
(79)
iâ€œ0

Dividing the latter equation by

Î±m ,

mÂ´1
Ã¿

we obtain that

Î±iÂ´m PmÂ´i pspÎ±qq ` P0 pspÎ±qq â€œ 0.

(80)

iâ€œ0

Since tspÎ±qu is bounded, the sum-term in the RHS of Eq. (80) goes to 0 as Î± Ã‘ 8. Therefore,
taking Î± Ã‘ 8 in (80), we have that
lim P0 pspÎ±qq â€œ 0.

Î±Ã‘8

Since tspÎ±qu is bounded, it has at least one limit (accumulation) point; and by the latter
equation, such a limit point must be a root of P0 psq. Since P0 psq has a finite number (n) of
roots, the limit lim spÎ±q (as Î± Ã‘ 8) exists and it is a root of P0 psq.
l
Proof of the left inequality of Eq. (59). We argue by contradiction. If the left inequality
in (59) is not satisfied, there exists an unbounded set A2 Ä‚ A such that, as Î± Ã‘ 8; Î± P A2 ,
|spÎ±q|
Ã‘ 0.
Î±
By (50), for every Î± P A2 ,

m
Ã¿

Î±i PmÂ´i pspÎ±qq â€œ 0.

iâ€œ0

26

(81)

Divide this equation by Î±m spÎ±qn to obtain, @ Î± P A2 ,
mÂ´1
Ã¿
iâ€œ0

PmÂ´i pspÎ±qq P0 pspÎ±qq
`
â€œ
Î±mÂ´i spÎ±qn
spÎ±qn

mÂ´1
Ã¿
iâ€œ0

spÎ±qmÂ´i PmÂ´i pspÎ±qq P0 pspÎ±qq
Â¨
`
â€œ 0.
Î±mÂ´i
spÎ±qm`nÂ´i
spÎ±qn

(82)

By Eq. (81), and since degpPmÂ´i q â€œ n ` m Â´ i for all i â€œ 0, . . . , m Â´ 1; as Î± Ã‘ 8, Î± P A2 ,
mÂ´1
Ã¿
iâ€œ0

spÎ±qmÂ´i PmÂ´i pspÎ±qq
Â¨
Ã‘ 0.
Î±mÂ´i
spÎ±qm`nÂ´i

Furthermore, since degpP0 q â€œ n,
P0 pspÎ±qq
â€° 0.
Î±PA2 ;Î±Ã‘8 spÎ±qn
lim

This contradicts Eq. (82) and hence completes the proof.

l

Proof of Lemma 4.8. By Eq. (52), for every Î± Ä› 0,
PÎ± pspÎ±qq â€œ

m
Ã¿
iâ€œ0

Î±i

n`mÂ´i
Ã¿

amÂ´i,j spÎ±qj â€œ 0.

(83)

jâ€œ0

Fix ` P t0, . . . , mu and Î½ P t0, . . . , n ` m Â´ ` Â´ 1u. Taking derivatives in (83) with respect to
amÂ´`,Î½ we obtain,
m n`mÂ´i
Ã¿
Ã¿
iâ€œ0

hence

Î±i amÂ´i,j Â¨ jspÎ±qjÂ´1

jâ€œ0

BspÎ±q
` Î±` spÎ±qÎ½ â€œ 0,
BamÂ´`,Î½

BspÎ±q
Î±` spÎ±qÎ½
â€œ Â´ Å™m Å™n`mÂ´i
.
BamÂ´`,Î½
Î±i amÂ´i,j Â¨ jspÎ±qjÂ´1
iâ€œ0
jâ€œ0

(84)

(85)

Now both numerator and denominator in Eq. (85) are comprised of two-dimensional polynomials in Î± and s â€œ spÎ±q. Their total degrees are n ` m Â´ 1 for the denominator, and ` ` Î½ for
the numerator. But Î½ Ä n ` m Â´ ` Â´ 1 by assumption, hence ` ` Î½ Ä n ` m Â´ 1, implying that
the total degree of the numerator is less or equal to that of the denominator. This, together
with Lemma 4.7, imply that Eq. (62) and hence the lemmaâ€™a assertion.
l

References
[1] A. Isidori and C. Byrnes, â€œOutput regulation of nonlinear systems,â€ IEEE Transactions
on Automatic Control, vol. 35, pp. 131â€“140, 1990.
[2] H. Khalil, â€œOn the design of robust servomechanisms for minimum phase nonlinear systems,â€ Proc. 37th IEEE Conference on Decision and Control, Tampa, FL, pp. 3075â€“3080,
1998.
[3] J. Rawlings, D. Mayne, and M. Diehl, Model Predictive Control: Theory, Computation,
and Design, 2nd Edition. Nob Hill, LLC, 2017.
27

[4] S. Shivam, A. Kanellopoulos, K. Vamvoudakis, and Y. Wardi, â€œA predictive deep learning
approach to output regulation: The case of collaborative pursuit evasion,â€ in 58th IEEE
Conference on Decision and Control, Nice, France, December 11-13, to appear, 2019.
[5] K. Arrow, L. Hurwicz, and H. Uzawa, Studies in Linear and Nonlinear Programming.
Stanford, California: Stanford University Press, 1958.
[6] R. Brockett, â€œDynamical systems that sort lists, diagonalize matrices, and solve linear
programming problems,â€ Linear Algebra and Its Applications, vol. 146, pp. 79â€“91, 1991.
[7] U. Helmke and J. Moore, Optimization and Dynamical Systems.
0387198571, 1994.

Springer, isbn

[8] J. Lee, M. Simchiwitz, M. Jordan, and B. Recht, â€œGradient descent only converges to
minimizers,â€ J. Machine Learning Research, vol. 49, pp. 1â€“21, 2016.
[9] N. Dhingra, S. Khong, and M. JovanovicÌ, â€œThe proximal augmented lagrangian method
for nonsmooth composite optimization,â€ IEEE Transactions on Automatic Control, to
appear, 2019.
[10] W. Su, â€œTraffic engineering and time-varying convex optimization,â€ Ph.D. dissertation,
The Pennsylvania State University, 2009.
[11] S. Rahili and W. Ren, â€œDistributed continuous-time convex optimization with timevarying cost functions,â€ IEEE Transactions Automatic Control, vol. 62, no. 4, pp. 1590â€“
1605, 2017.
[12] N. K. Dhingra, S. Z. Khong, and M. R. JovanovicÌ, â€œA second order primal-dual method
for nonsmooth convex composite optimization,â€ IEEE Transactions Automatic Control,
2017, submitted. https://arxiv.org/abs/1709.01610.
[13] E. Sontag, â€œSmooth stabilization implies coprime factorization,â€ IEEE Trans. Automatic
Control, vol. 34, no. 4, pp. 435â€“443, 1989.
[14] S. Kolathaya, J. Reher, A. Hereid, and A. Ames, â€œInput to state stabilizing control Lyapunov functions for robust bipedal robotic locomotion,â€ in American Control Conference,
Milwakee, Wisconsin, June 27-29, 2018.
[15] Y. Wardi, C. Seatzu, M. Egerstedt, and I. Buckley, â€œPerformance regulation and tracking
via lookahead simulation: Preliminary results and validation,â€ in 56th IEEE Conf. on
Decision and Control, Melbourne, Australia, December 12-15, 2017.
[16] Y. Wardi, C. Seatzu, and M. Egerstedt, â€œTracking control via variable-gain integrator
and lookahead simulation: Application to leader-follower multiagent networks,â€ in 6th
IFAC Conf. on Analysis and Design of Hybrid Systems (ADHSâ€™18), Oxford, UK, July
11-13, 2018.
[17] S. Shivam, I. Buckley, Y. Wardi, C. Seatzu, and M. Egerstedt, â€œTracking control by the
Newton-Raphson flow: Applications to autonomous vehicles,â€ in 2019 European Control
Conference (ECC 2019), Napoli, Italy, June 25-28, 2019.
[18] G. Franklin, J. Powell, and A. Emami-Naeini, Feedback Control of Dynamical Systems.
Pearson, Eighth Edition, 2019.
28

[19] P. Lancaster, â€œError analysis for the Newton-Raphson method,â€ Numerische Mathematik,
vol. 9, pp. 55â€“68, 1966.
[20] Wikipedia. (2010) https://en.wikipedia.org/wiki/Inverted pendulum.
[21] M. Plessen, D. Bernardini, H. Esen, and A. Bemporad, â€œSpatial-based predictive control and geometric corridor planning for adaptive cruise control coupled with obstacle
avoidance,â€ IEEE Transactions Control Systems Technology, vol. 26, no. 4, pp. 38â€“50,
2018.
[22] J. Kong, M. Pfeiffer, G. Schildbach, and F. Borrelli, â€œKinematic and dynamic vehicle
models for autonomous driving control design,â€ in Proc. IEEE Intelligent Vehicles Symposium (IV), 2015.
[23] Mathworks.com.
(2019)
https://www.mathworks.com/help/ident/examples/
modeling-a-vehicle-dynamics-system.html.
[24] D. Pickem, P. Glotfelter, L. Wang, M. Mote, A. Ames, E. Feron, and M. Egerstedt.,
â€œThe Robotarium: A remotely accessible swarm robotics research testbed.â€ in IEEE Int.
Conf. Robot. Autom., May 2017.
[25] I. Buckley. (2019) https://youtu.be/4CSIagrxcu8.

29

