1

Persuasion-based Robust Sensor Design Against
Attackers with Unknown Control Objectives

arXiv:1901.10618v2 [eess.SY] 11 Sep 2020

Muhammed O. Sayin and Tamer BasÌ§ar, Life Fellow, IEEE

Abstractâ€”In this paper, we introduce a robust sensor design
framework to provide â€œpersuasion-basedâ€ defense in stochastic
control systems against an unknown type attacker with a control
objective exclusive to its type. For effective control, such an
attackerâ€™s actions depend on its belief on the underlying state
of the system. We design a robust â€œlinear-plus-noiseâ€ signaling
strategy to encode sensor outputs in order to shape the attackerâ€™s
belief in a strategic way and correspondingly to persuade the
attacker to take actions that lead to minimum damage with
respect to the systemâ€™s objective. The specific model we adopt is
a Gauss-Markov process driven by a controller with a (partially)
â€œunknownâ€ malicious/benign control objective. We seek to defend
against the worst possible distribution over control objectives
in a robust way under the solution concept of Stackelberg
equilibrium, where the sensor is the leader. We show that a
necessary and sufficient condition on the covariance matrix of
the posterior belief is a certain linear matrix inequality and
we provide a closed-form solution for the associated signaling
strategy. This enables us to formulate an equivalent tractable
problem, indeed a semi-definite program, to compute the robust
sensor design strategies â€œgloballyâ€ even though the original
optimization problem is non-convex and highly nonlinear. We
also extend this result to scenarios where the sensor makes
noisy or partial measurements. Finally, we analyze the ensuing
performance numerically for various scenarios.
Index Termsâ€”Stackelberg games, Stochastic control, Security,
Sensor placement, Semi-definite programming.

I. I NTRODUCTION
YBER connectedness of control systems has brought in
new security challenges where attackers can manipulate
control systems at unprecedented levels with various malicious
tasks on their agenda [1]â€“[3]. We can view such intelligent
attackers as decision makers that take actions driven by and
compatible with their own objective and information available
to them. This implies that the kind of information available to
an attacker has an indirect impact on what actions the attacker
would take. Correspondingly, it is intuitively expected that if
we can manipulate the information available to attackers, then
we can persuade them to attack the system in a way in line
with the systemâ€™s objective to the extent possible, so that the
attack would cause minimum damage to the system.
There are certain distinct challenges for persuasion-based
defense measures. For example, attackers make their decisions
based on the belief they have formed using the information

C

This research was supported by the U.S. Office of Naval Research (ONR)
MURI grant N00014-16-1-2710.
Muhammed O. Sayin is with Laboratory for Information and Decision
Systems at MIT, Cambridge, MA 02139. E-mail: sayin@mit.edu
Tamer BasÌ§ar is with the Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Urbana, IL 61801 USA.
E-mail: basar1@illinois.edu

available to them. A challenge is how to shape that belief
in a desired way by controlling the information available to
the attacker. The first requirement (and challenge) here is to
be able to identify how an attacker would form its belief.
However, when an attacker forms its belief strategically, there
might be multiple Nash equilibria in a general-sum setting1 , as
shown in the strategic information transmission framework [4].
In that case how an attacker forms its belief is not well defined
since the attacker might be forming its belief differently at
different equilibria and whether (and which) equilibrium will
be realized would not be known, and constitutes an uncertainty. Furthermore, even when there exists a well-defined
characterization of how an attacker would form its belief,
another challenge is what decision the attacker would make
based on that belief, since that decision would depend on the
attackerâ€™s malicious objective. This implies that persuasionbased defense is attack-specific. Therefore another challenge
is how to persuade an attacker whose objective is not known
to act in a certain way.
Before addressing these challenges, let us briefly review
the literature from a broader perspective where a decision
maker seeks to induce another one to take certain actions. A
closely related framework is Bayesian persuasion, introduced
by Kamenica and Gentzkow in their seminal paper [5]. They
addressed how a sender could persuade a receiver to take
certain actions under the solution concept of Stackelberg
equilibrium [6] where the sender (the receiver) is the leader
(the follower). In other words, the receiver is aware of the
senderâ€™s signaling strategy while taking its actions. Such a
leader-follower scheme creates an environment where the
receiverâ€™s actions are not strategic, and therefore there is a
well-defined characterization for how the belief is formed.
In Bayesian persuasion framework, a necessary and sufficient condition is that mean of posterior belief must be equal
to the prior belief. This enables us to formulate an equivalent
problem over distributions over posterior beliefs under a
linear equality constraint. The authors provided a geometrical
interpretation to compute the solution, which necessitates
computation of a convex envelope of a function. Although this
interpretation provides essential insight for designing signaling
strategies and has led to various applications (see the recent
survey on Bayesian persuasion [7] and the references therein),
it is viable only for scenarios where the state space is very
1 In a zero-sum setting, there exists a unique â€œbabbling equilibriumâ€ where
the attacker forms a belief independent of the information provided by a
defender (since the defender would not share anything useful) whereas the
defender just makes irrelevant information available to the attacker (since a
more informed attacker would not cause less damage to the system).

2

small.
We emphasize that [5] studies the Bayesian persuasion
problem in a very general framework, where the underlying
distribution is arbitrary as long as its support set is compact,
cost functions are arbitrary, and the signaling strategy is any
stochastic kernel (between the state space and the signal
space). Therefore if we consider specific distributions and
cost functions, we should be able to obtain more tractable
solutions. For example in [8], the author addressed Bayesian
persuasion problem for multi-variate Gaussian information and
quadratic cost functions, and provided a closed-form solution
for the optimal signaling strategy, which turns out to be a
linear function. We note that the studies [5], [8] focused
on static systems. To be able to adopt this framework to
control systems, an important step would be to extend the
framework to dynamic systems. In [9], we have extended the
results in [8] to dynamic environments where the underlying
information is a discrete-time Gauss Markov process. We
showed that there exists a linear signaling strategy optimal
within the general class of measurable policies and provided
a semi-definite program (SDP) to compute optimal signaling
strategies numerically.
Before delving into persuasion-based defense measures in
control systems, let us also review the literature on security of
control systems. To this end, we selectively focus on studies
where an attacker can monitor and intervene the links from
sensor to controller and from controller to actuator so that there
would be an information flow to the attacker who monitors
these links. In [10], the authors showed that an attacker can
lead to unbounded estimation error by injecting false data into
the link from sensor to controller when there exists a certain
threshold-based detector monitoring the link. In [11], [12], the
authors characterized the reachable set to which an evasive
attacker can drive the system by injecting data into both links
jointly. In [13], [14], the authors analyzed attacks where an
attacker seeks to drive the state of the system according to
his/her adversarial goal evasively by injecting data into both
links jointly. In [15], the authors have analyzed optimal attack
strategies to maximize quadratic cost of a system with linear
Gaussian dynamics by injecting false data into the link from
controller to actuator without being detected.
As seen in the literature reviewed above, an attacker can
monitor and intervene the links in a control system, e.g., as
illustrated in Fig. 1 for a linear quadratic Gaussian (LQG)
control system. This implies that an attacker can bypass the
controller of a system by monitoring and intervening both links
jointly. Then the attacker would receive the sensor outputs
and could generate its own control inputs to conduct its
malicious control objective similar to the controller of the
system. From this viewpoint, within the Bayesian persuasion
framework, we can encode the sensor outputs to persuade
the attacker to generate control inputs that would minimize
the systemâ€™s very own control objective as much as possible.
We partially addressed this challenge in [9], [16], [17]. In
[9], we formulated an optimal linear signaling rule in an
LQG setting when attackerâ€™s control objective is known to
the sensor. This limits applicability of the solution since the
sensor must know when there is an attack and what the control

Measurement
yk

Sensor

Signal
Encoder

s k = Î·k (yy1:k )

Might be corrupted
by Attacker

y 1:kâˆ’1

Dynamic System

wk
x k+1 = Axxk + Buuk +w

Unknown-type
Attacker

Controller

?

Control Input

uk = Î³k (ss1:k )
Actuator

Physical Plant

When there is an attack, Controller
does not actuate the system anymore

Fig. 1: A discrete-time LQG control system where an
(unknown-type) attacker can monitor and intervene the links
from sensor to controller, and from controller to actuator
jointly in order to drive the system according to its malicious
control objective. The attacker might also corrupt the data
received by the controller of the system to evade a detector
monitoring that data. Details of how an attacker can evade
detection by corrupting that data has earlier been studied
in the literature, e.g., [10]â€“[14], and is out of the scope of
this paper since here we focus on adopting persuasion-based
defense against attackers with unknown control objectives.
Furthermore, the results of this paper hold for any strategy
that the attacker can use to evade such detectors as long as
those strategies do not impact how the attacker constructs its
control inputs.

objective of the attacker is beforehand. In the follow-up papers
[16], [17], we showed that this limitation could be relaxed
in a straightforward way if the sensor knows the distribution
over the control objectives of attackers that may attack the
system and at what probability there might be an attack.
Correspondingly, a risk-neutral sensor could minimize the
expected damage with respect to that distribution. However,
this still limits its applicability since the sensor must know
the underlying distribution over the attack space.
Although it is not a persuasion-based defense, it is worth
noting that in [18], the authors proposed linear encoding
schemes2 for sensor outputs in an LQG control problem in
order to enhance detectability of false data injection attacks
under an essential assumption that the encoding matrix is
oblivious to attackers. In that respect, the encoding scheme
could be viewed as corrupting the information available to
attackers (without impacting the information flowing to the
controller of the system) in order to limit the attackerâ€™s
capability to evade detection rather than persuading the attacker to attack in a certain way. And this security measure
becomes undermined completely once the encoding scheme is
compromised.
Coming to the specifics of this paper, we also consider
a discrete-time LQG control problem, similar to the studies
reviewed above [13]â€“[18], but with important differences. We
2 We use the terminologies encoding scheme and signaling rule/strategy
interchangeably.

3

particularly seek to design linear-plus-noise signaling rules
for persuasion-based robust sensor design against an unknown
type attacker with a control objective exclusive to its type.
It is robust in the sense that sensor outputs are designed
against the worst possible distribution over all possible control
objectives of the attacker. We consider the scenario where
the set of types is finite and known to the system. Under
the solution concept of Stackelberg equilibrium, we consider
the setting where the sensor is the leader and the attacker is
the follower. This yields that the underlying encoding scheme
is not necessarily oblivious to the attacker. Furthermore, we
address the scenarios where the sensor can have partial or
noisy measurements different from the models in [9], [16],
[17]. Note that the worst case distribution over the type set
turns out to be not necessarily a degenerate distribution, i.e.,
defending only against the (strongest) type of attack that leads
to largest cost for the system is not necessarily optimal with
respect to the systemâ€™s objective.
Due to the underlying leader-follower setting, the response
of the follower (the attacker) is non-strategic and the problem
faced by the leader (the sensor) turns out to be an optimization
problem rather than a fixed-point problem. By using the classical method of completion of squares [19], we can show that the
objective function in that optimization problem is linear in the
covariance matrix of the posterior estimate of the underlying
(control-free) state. However that covariance matrix depends
on the encoding scheme in a nonlinear way, which leads to
a non-convex and highly nonlinear optimization problem, to
be solved globally in order to compute robust sensor design
strategies. In [9], our previous inspection revealed a necessary
condition on this covariance matrix, which is just a linear
matrix inequality. Here we show that this necessary condition
is also a sufficient condition when the sensor selects linear plus
noise signaling strategies. Furthermore for any matrix satisfying the necessary condition, we provide a closed-form solution
for the associated linear plus noise signaling rule. Therefore
instead of trying to solve a non-convex and highly nonlinear
optimization problem, we are able to bring the problem to
one of solving a linear optimization problem under linear
matrix inequality constraints, which can be done numerically
using existing SDP solvers effectively, e.g., [20], [21]. This
solution concept can be seen to have similar flavor with our
previous paper [9], reviewed above. However, here we develop
and present a completely new and more comprehensive set of
technical tools since the results of [9] cannot be adopted for the
general setting of this paper. The reader can refer to Appendix
A for a detailed discussion on this matter.
We now highlight the main contributions of this paper as
follows:
â€¢ We show that a necessary and sufficient condition on the
covariance matrix of the posterior estimate of controlfree state is a certain linear matrix inequality. This result
is important by itself since it yields a tractable solution
concept to design sensor outputs in general settings not
limited to the special setting studied in this paper.
â€¢ Based on this necessary and sufficient condition, we
provide an SDP equivalent to the original optimization
problem faced by the sensor, which is non-convex and

highly nonlinear, while the SDP could be solved globally
using existing powerful computational tools effectively
[20], [21]. Furthermore, this result can be extended to
scenarios where there are partial or noisy measurements.
â€¢ We note that robust signaling rule can dictate sensors to
introduce irrelevant information into sensor outputs quite
contrary to other settings, e.g., when there is no uncertainty
(or there is imperfect information) on attackerâ€™s type. This
observation enables us to draw the following conclusions:
â€“ The equivalence result does not necessarily hold if the
sensor can only use linear signaling rules.
â€“ Based on Blackwellâ€™s Irrelevant Information Theorem
[22, Theorem D.1.1], linear signaling strategies are not
the best one within the general class of measurable
strategies in this robust setting.
The paper is organized as follows: In Section II, we formulate the robust sensor design game. In Section III, we
analyze the equilibrium of the robust sensor design game under
perfect measurements. In Section IV, we extend the results
to the cases where there are partial or noisy measurements.
In Section V, we examine numerically the performance of
the proposed scheme for various scenarios. We conclude
the paper in Section VI with several remarks and possible
research directions. An appendix provides further discussion
on related literature, proofs of all technical results in the
order they appear throughout the paper, and some closed-form
expressions for the readerâ€™s reference.
Notation: We denote a collection of parameters via a
subscript, e.g., {xk }, by dropping the subscript, e.g., x, for
notational brevity. For a vector x and a matrix A, x0 and A0
denote their transposes, and kxk denotes the Euclidean (L2 )
norm of the vector x. For a matrix A, Tr{A} and rank{A}
denote its trace and rank, respectively. We denote the identity
and zero matrices with the associated dimensions by I and O,
respectively. We denote the set of m-by-m symmetric, positive
semi-definite, and positive definite matrices by Sm , Sm
+ , and
â€ 
Sm
++ , respectively. For a matrix A, A denotes its MoorePenrose inverse. For positive semi-definite matrices A and B,
A  B means that A âˆ’ B is also a positive semi-definite matrix.
We denote the Kronecker product of matrices A and B by
A âŠ— B.
We denote an ordered set {xk , . . . , x1 } and its augmented
0
vector version, xk0 Â· Â· Â· x10 , by x1:k , by some abuse of
notation. N (0, .) denotes the multivariate Gaussian distribution with zero mean and designated covariance matrix. We
denote random variables by bold lower case letters, e.g., x .
We denote expectation and (co)variance of a random variable
x by E{xx} and cov{xx}, respectively. For random variables x
and y , E{xx|yy} denotes the expectation of x with respect to the
random variable y . We denote the set of all possible probability
distributions over a set â„¦ by âˆ†(â„¦).

II. P ROBLEM F ORMULATION
Consider a control system, as illustrated in Fig. 1, whose
underlying state dynamics and sensor measurements are de-

4

scribed, respectively, by:

B. Attack Model

wk ,
x k+1 = Axxk + Buuk +w
y k = Cxxk +vvk ,
where3

RmÃ—m , B

RmÃ—r ,

(1)
(2)
RnÃ—m ,

for k = 1, . . . , Îº,
Aâˆˆ
âˆˆ
and C âˆˆ
and the initial state x 1 âˆ¼ N (0, Î£1 ). The additive state and
wk } and {vvk }, respectively, are
measurement noise sequences {w
white Gaussian vector processes, i.e., w k âˆ¼ N (0, Î£w ) and v k âˆ¼
N (0, Î£v ); and are independent of the initial state x 1 and of
each other.
As seen in Fig. 1, measurements y 1:k âˆˆ Rnk are encoded into
a signal s k âˆˆ Rm through a signaling strategy Î·k (Â·), which
is a stochastic kernel, and s k = Î·k (yy1:k ) almost everywhere
over Rm . We specifically consider â€œlinear plus noiseâ€ signaling
rules such that the signal s k is given by
Ï‘ k,
s k = Î·k (yy1:k ) = Lk0 y 1:k +Ï‘

(3)

almost everywhere over Rm , where Lk âˆˆ RnkÃ—m can be any
nk-by-m deterministic matrix, and Ï‘ k âˆ¼ N (0, Î˜k ) is a zero
mean multivariate Gaussian noise independent of every other
parameter, and its covariance matrix Î˜k âˆˆ Sm
+ can be any mby-m positive semi-definite matrix. We denote the set of such
signaling rules by Ï’k , i.e., Î·k âˆˆ Ï’k . Furthermore, the closedloop control input u k âˆˆ Rr is given by
u k = Î³k (ss1:k ),

(4)

almost everywhere over Rr , where Î³k (Â·) can be any Borel
measurable function from Rmk to Rr . We denote the set of
such control policies by Î“k , i.e., Î³k âˆˆ Î“k . For notational brevity,
let us denote signaling (control) strategies and the associated
sets across the horizon by Î· and Ï’ (Î³ and Î“), respectively.
A. Defense Model
We consider an LQG control problem, where the controller
of the system selects a measurable control strategy Î³ âˆˆ Î“ in
order to minimize
Îº

âˆ‘ Ekxxk+1 k2Q + Ekuuk k2R ,

(5)

k=1
r
where4 Q âˆˆ Sm
+ and R âˆˆ S++ . As illustrated in Fig. 1, we
consider the encoder of the system as a decision maker,
denoted by PS . PS selects the signaling strategy Î· âˆˆ Ï’ in
order to minimize the same objective with the controller, (5).
Note that if there were no attacks, identity function, where
the measurements are shared with the controller fully, would
be an optimal encoding scheme due to the data processing
inequality [23, Theorem 2.8.1]. However, we consider here
the scenarios where there can be an attack with an unknown
control objective. Correspondingly there might be encoding
schemes that do not share the measurements fully and can
lead to better performance with respect to (5).
3 Even

though we consider time-invariant matrices A, B, and C, for notational
simplicity, the provided results could be extended to time-variant cases rather
routinely. Furthermore, we consider all the random parameters to have zero
mean; however, the derivations can be extended to non-zero mean case in a
straight-forward way.
4 For notational simplicity, we consider time-invariant Q and R. However,
the results provided could be extended to the general time-variant case rather
routinely.

We consider an attacker who is aware of the underlying state
dynamics, i.e., gain matrices A, B, and C; covariance matrices
Î£1 , Î£w , and Î£v ; and the encoding scheme, i.e., Î·. The attacker
is of an unknown type, which determines its control objective.
Let us denote the set of all possible types by â„¦. We suppose
that â„¦ is finite and known by the system. We seek to provide a
compact and unified analysis. Therefore we consider that the
control objective of type Ï‰ âˆˆ â„¦ is given by
Îº

âˆ‘ EkxxÏ‰k+1 k2QÏ‰ + EkuuÏ‰k k2RÏ‰ ,

(6)

k=1
Ï‰
r
where QÏ‰ âˆˆ Sm
+ and R âˆˆ S++ are exclusive to the type Ï‰.
Note that when there is an attack, the attacker selects a control
strategy Î³ Ï‰ âˆˆ Î“ in order to construct its control input u Ï‰
k
and correspondingly its control objective includes the term
2
EkuuÏ‰
k kRÏ‰ . We also denote the state driven by type-Ï‰ attacker
Ï‰
by x k , to make it explicit.

Remark 1 (Versatility of Control Objectives). We model the
control objectives of the system and the attacker by (5) and
(6), respectively, within a unified framework. However, arbitrariness of weight matrices in the control objectives (5) and
(6) brings in flexibility to model various attack scenarios (that
are not in the exact form of (6)) through the transformation
of the underlying state space as exemplified in Section V. 
C. Game Model
We analyze the interaction between the attacker and PS
under the solution concept of Stackelberg equilibrium where
PS is the leader. Note that from the viewpoint of PS , either
the controller of the system is receiving the sensor output and
driving the state or there is an unknown type attack, and it is
getting the sensor output and it is generating the control input.
Since whether there is an attack or not is also an uncertainty,
let us view the attacker and the controller of the system as
a single player in a unified way, denoted by PC , with an
unknown type from the extended type set â„¦o := â„¦ âˆª {Ï‰o },
where type-Ï‰o corresponds to the controller of the system, i.e.,
QÏ‰o = Q and RÏ‰o = R. Therefore, we consider a Stackelberg
game between the leader PS and the follower PC (of an
unknown type).
We note that depending on its type, PC selects different
control policies, which lead to different control inputs, and
Ï‰
states. Therefore for type-Ï‰ PC , we use Î³kÏ‰ , x Ï‰
k and u k . The
objective of type-Ï‰ PC is given by
Îº

UCÏ‰ (Î·, Î³ Ï‰ ) :=

âˆ‘ EkxxÏ‰k+1 k2QÏ‰ + EkuuÏ‰k k2RÏ‰ .

(7)

k=1

On the other hand, the objective of PS is given by
(
Îº

US (Î·, {Î³ Ï‰ }Ï‰âˆˆâ„¦o ) := max

pâˆˆâˆ†(â„¦o )
Îº

+pÏ‰o

âˆ‘
k=1

âˆ‘

pÏ‰

Ï‰âˆˆâ„¦

2
EkxxÏ‰
âˆ‘
k0 +1 kQÏ‰o
0

k =1

)
2
o
EkxxÏ‰
k+1 kQÏ‰o


o 2
+ EkuuÏ‰
k kRÏ‰o

, (8)

5

where âˆ†(â„¦o ) denotes all possible distributions over the extended type set â„¦o . Note that the maximization in (8) computes
the cost of PS for the worst case distribution over â„¦o .
Before describing the game formally, let us take a closer
look at PS â€™s objective (8). We can view (8) consisting of two
parts, one of which is
Îº

pÏ‰o

âˆ‘


2
o
o 2
uÏ‰
EkxxÏ‰
k+1 kQÏ‰o + Eku
k kRÏ‰o ,

(9)

k=1

where pÏ‰o corresponds to the probability that the controller of
the system drives the state under the worst case distribution
and the summation is identical to (5) since QÏ‰o = Q and RÏ‰o =
R. The other part is
Îº

âˆ‘

pÏ‰

Ï‰âˆˆâ„¦

âˆ‘
0

2
EkxxÏ‰
k0 +1 kQÏ‰o ,

(10)

k =1

which implies that PS seeks to minimize
when type-Ï‰ attacker drives the state. Note that it includes
only the first term in (5) since we consider that PS would not
necessarily want the attacker to have small size control inputs.
2
âˆ‘Îºk=1 EkxxÏ‰
k+1 kQÏ‰o

Definition (Robust Sensor Design Game). The robust sensor
design game
w1:Îº ,vv1:Îº )
G := (Ï’, Î“,xx1 ,w
(11)
is a Stackelberg game between the leader PS and the follower
PC . Objectives of PC and PS are given by (7) and (8),
respectively. Then a tuple of strategies (Î·, {Î³ Ï‰ }Ï‰âˆˆâ„¦o ) attains
the Stackelberg equilibrium provided that

Î· âˆˆ argmin US Î· 0 , {Î³ Ï‰ (Î· 0 )}Ï‰âˆˆâ„¦o
(12a)
Î· 0 âˆˆÏ’


Î³ Ï‰ (Î·) âˆˆ argmin UCÏ‰ Î·, Î³(Î·) .

(12b)

Î³âˆˆÎ“

where, by an abuse of notation, we denote type-Ï‰ PC â€™s strategy Î³ Ï‰ by Î³ Ï‰ (Î·) to show its dependence on PS â€™s signaling
rules due to the leader-follower scheme, explicitly.
Note that there might be multiple best responses by PC
for a signaling strategy. Correspondingly (12a) would not be
well defined if these best responses lead to different costs for
PS . However, as we will show later in detail, reaction set of
type-Ï‰ PC turns out to be an equivalence class such that all
Î³ Ï‰ in the reaction set lead to the same control input almost
surely, and correspondingly lead to the same cost for PS .
III. ROBUST S ENSOR D ESIGN F RAMEWORK
In this section, we consider the special case where PS has
access to perfect measurements, i.e., y k = x k for k = 1, . . . , Îº;
the general noisy/partial measurements case will be addressed
later in Section IV. To compute the equilibrium of the game G ,
we first focus on best response strategy of PC for a given signaling strategy. This enables us to formulate the optimization
problem faced by PS to compute robust signaling strategies.
Even though this is a finite-dimensional optimization problem,
further inspection reveals that it is highly nonlinear and nonconvex. Therefore a generic approach would not be able
to address it globally. To mitigate this issue, we formulate
a tractable problem equivalent to the original optimization

problem. We can solve this tractable problem globally using
existing computational tools effectively. Given that solution,
we also show how we can compute the associated signaling
strategies. We now provide the details of these steps.
An important challenge in the design of encoding schemes
in control systems compared to communication systems is that
the underlying state depends on control inputs. To mitigate this
issue, we introduce control-free state {xxok } evolving according
to
wk ,
x ok+1 = Axxok +w
(13)
and x o1 = x 1 . As shown in [24], the routine technique of
completion of squares yields that
Îº

âˆ‘ Ekxxk+1 k2QÏ‰ + Ekuuk k2RÏ‰ =
k=1

Îº

âˆ‘ Ekuuok + KkÏ‰ x ok k2âˆ†Ï‰k + Î´0Ï‰ ,

(14)

k=1

Ï‰
where the matrices KkÏ‰ , âˆ†Ï‰
k , and scalar Î´o are given by
âˆ’1 0 Ï‰
KkÏ‰ = (âˆ†Ï‰
k ) B QÌƒk+1 A
0 Ï‰
Ï‰
âˆ†Ï‰
k = B QÌƒk+1 B + R
Îº

Î´0Ï‰ = Tr{QÏ‰ Î£1 } + âˆ‘ Tr{QÌƒÏ‰
k+1 Î£w }
k=1

{QÌƒÏ‰
k}

and
satisfies the following discrete-time dynamic Riccati
equation
Ï‰
0
Ï‰
Ï‰
Ï‰ âˆ’1 0 Ï‰
QÌƒÏ‰
k = Q + A (QÌƒk+1 âˆ’ QÌƒk+1 B(âˆ†k ) B QÌƒk+1 )A
Ï‰
o
and QÌƒÏ‰
Îº+1 = Q . Furthermore u k depends on the control inputs
through the following transformation:

u ok = u k + KkÏ‰ Buukâˆ’1 + . . . + KkÏ‰ Akâˆ’2 Buu1 .
Note that âˆ†Ï‰
k is positive definite for all k.
Contrary to team problems (where all decision makers have
the same objective), as studied in [24], in non cooperative
settings, (14) does not imply that a control input leading to
u ok = âˆ’KkÏ‰ E{xxok |ss1:k } is optimal since control inputs can have
an impact on the signals that will be generated in future
stages. However, as we will show below, PC cannot impact
the signals generated in future stages when PS uses linear plus
noise signaling strategies only. To show this, we let the gain
matrix Lk âˆˆ RnkÃ—m in signaling
strategy Î·k , as described in (3),
 0
0
0
Â· Â· Â· Lk,1
be partitioned as Lk = Lk,k
, where Lk, j âˆˆ RnÃ—m .
Then, signal s k can be written as
0
0
0
0
Ï‘k
Ï‘ k = Lk,k
x 1 +Ï‘
x ok + . . . + Lk,1
x o1 +Ï‘
Lk,k
x k + . . . + Lk,1
n
o
0
kâˆ’2
0
0
+ Lk,k Buukâˆ’1 + . . . + (Lk,k A + . . . + Lk,2 )Buu1 ,

where the term in-between {Â·} is Ïƒ -ss1:kâˆ’1 measurable. Similar
to5 [9, Lemma 12], this yields that
E{xxok |ss1:k } = E{xxok |sso1:k },

(15)

Ï‘ k . Correspondingly, since âˆ†Ï‰
where we define s ok := Lk0 x o1:k +Ï‘
k
is positive definite for all k, right-hand sides of (14) and (15)
yield that optimal reaction of type-Ï‰ PC is indeed the one
that leads to
(16)
u ok = âˆ’KkÏ‰ E{xxok |ss1:k },
5 We note that [9, Lemma 12] shows a result similar to (16) when the sender
selects only linear and memoryless signaling strategies.

6

almost everywhere over Rr , since E{xxok |ss1:k } does not depend
on u 1:k . This shows that all strategies in the best reaction set
of type-Ï‰ PC lead to (16) and therefore lead to the same cost
for PS .
Based on (16), the following lemma shows that we can
write the optimization objective in (8) as a linear function of
the covariance matrix of the posterior estimate of control-free
state, i.e.,6
Hk := cov{E{xxok |ss1:k }},
for k = 1, . . . , Îº.
Lemma 1. The problem faced by PS , i.e., (12a), can be
written as
!

certain number of matrices, it is a highly nonlinear and nonconvex optimization problem due to the matrix inversion in
(18). Therefore it is difficult to obtain a global solution through
a generic attempt, e.g., genetic algorithm [25] or particle
swarm optimization [26]. On the other hand, the following
proposition shows that there is a computationally tractable
relationship between the covariance matrix and linear plus
noise signaling strategies.
Proposition 1 (A Necessary and Sufficient Condition). For
any signaling rule Î· âˆˆ Ï’, covariance matrix of posterior
estimate of the control-free state, {Hk = cov{E{xxok |ss1:k }}},
satisfies
Î£o1  H1  O,

Îº

min max

âˆ‘

Î·âˆˆÏ’ pâˆˆâˆ†(â„¦o ) Ï‰âˆˆâ„¦o

pÏ‰

Ï‰

Î¾ +âˆ‘

Tr {Hk ÎžÏ‰
k}

,

(17)

k=1

where ÎžÏ‰
k is a certain symmetric matrix, described in (50), that
does not depend on the optimization arguments, and Î¾ Ï‰ âˆˆ R,
described in (44) and (49), is a certain fixed scalar.
We emphasize that complexity of the objective functions (5)
Ï‰
and (8) is buried in fixed parameters {{ÎžÏ‰
k }, Î¾ }. Based on
this observation, we make the following remarks:
Remark 2 (Versatility of the results with respect to PC â€™s
objective). The problem faced by PS is a linear function of the
covariance matrices {Hk } since optimal reaction of PC turns
out to be linear in the posterior estimate of the control-free
state, i.e., E{xxok |ss1:k }, as seen in (16). Therefore the results
henceforth hold for any other scenarios where PC has any
other objective in which optimal reaction of PC still turns
out to be a linear function of the posterior estimate. Note that
Ï‰
we need to compute the associated {{ÎžÏ‰
k }, Î¾ } accordingly.

Remark 3 (Versatility of the results with respect to PS â€™s
objective). We motivate and consider the case where PS has
objective (8). However, the results henceforth would also hold
for scenarios where PS â€™s objective is any other (convex or
non-convex) quadratic function of the state and control input.
Ï‰
Note that we also need to compute the associated {{ÎžÏ‰
k }, Î¾ }
accordingly.

Compared to original form of the optimization problem
(12a), the optimization problem (17) has a concrete structure
showing that the optimization function depends on the signaling strategy through the covariance matrix only, and it is a
linear function of the covariance matrix. Therefore it is instructive to study the relationship between the covariance matrix
and the signaling strategy. Since the underlying distributions
are all jointly Gaussian, we can express the covariance matrix
in closed form:
Hk = E{xxoks 01:k }E{ss1:ks 01:k }â€  E{xxoks 01:k }0

Î£ok

(19b)

Î£o1  S1  O,

(20a)

Î£ok  Sk  ASkâˆ’1 A0 , for k > 1,

(20b)

there exists a (memoryless) linear-plus-noise signaling strategy8 Î· âˆˆ Ï’ such that Sk = Hk .
In the following, we provide a description of signaling
strategies9 that lead to covariance matrices matching with a
given collection of positive semi-definite matrices S1:Îº satisfying (35). To this end, we let


Î›Ì„k O 0
0
o
Î£k âˆ’ ASkâˆ’1 A = UÌ„k
UÌ„
O O k
t

k
be the eigen-decomposition such that Î›Ì„k âˆˆ S++
, where tk =
o
0
rank{Î£k âˆ’ ASkâˆ’1 A }. Furthermore, we let
 1/2 
h
i
Î›Ì„
1/2
0
0
Tk := Î›Ì„k
O UÌ„k (Sk âˆ’ ASkâˆ’1 A )UÌ„k k
O

have the eigen-decomposition Tk = Uk Î›kUk0 with eigenvalues,
e.g., Î»k,1 , . . . , Î»k,tk . We note that Î»k,t turns out to be in [0, 1].
Then, the associated signaling strategy is given by
0
Ï‘ k,
s k = Lk,k
x k +Ï‘

(21)

2 , . . . , Î¸ 2 , 0, . . . , 0},
where Ï‘ k âˆ¼ N (0, Î˜k ) with Î˜k = diag{Î¸k,1
k,tk
and the gain matrix Lk,k is given by
 âˆ’1/2

o O
Î›Ì„
U
Î›
k
k
k
Lk,k = UÌ„k
,
O
O
o , . . . , Î» o } is a diagonal matrix such that
where Î›ok := diag{Î»1,1
1,tk
t
o , Î¸ 2 } k satisfies
{Î»k,i
k,i i=1

(18)

o )2
(Î»k,i
o )2 + Î¸ 2
(Î»k,i
k,i

= Î»k,i , âˆ€ i = 1. . . . ,tk .

the definition of Î£ok , we have Î£ok = AÎ£ok A0 + Î£w .
a signaling strategy is described in (21) later.
9 A derivation of the associated signaling strategies can be found in the
constructive proof of Proposition 1, which is provided in Appendix C.
7 By

we say â€œcovariance matrixâ€ instead of â€œcovariance matrix of
posterior estimate of control-free stateâ€, and we say â€œposteriorâ€ instead of
â€œposterior estimate of control-free stateâ€.

 Hk  AHkâˆ’1 A , for k > 1,

where7 Î£ok := E{xxok (xxok )0 }.
Furthermore for any collection of positive semi-definite
matrices S1:Îº satisfying

and the signal s k is given by (3). This yields that even though
computing robust signaling strategies would mean finding a
6 Henceforth

(19a)
0

8 Such

7

The following corollary to Proposition 1 provides a problem
equivalent to (17).
Corollary 1 (Equivalence Result). The problem faced by PS ,
i.e., (8), is equivalent to
!
Îº

minm

max

âˆ‘ o pÏ‰

{Sk âˆˆS+ } pâˆˆâˆ†(â„¦o ) Ï‰âˆˆâ„¦

Î¾ Ï‰ + âˆ‘ Tr{Sk ÎžÏ‰
k} ,

(22)

k=1

subject to the following linear matrix inequalities:
Î£o1  S1  O
Î£ok

(23a)
0

 Sk  ASkâˆ’1 A , for k > 1.

(23b)

And given a solution S1:Îº , an associated signaling strategy can
be computed according to (21).
Henceforth, we will be working with (22) instead of (17)
while analyzing the equilibrium of the game G . Furthermore,
for brevity of presentation, let us introduce
ï£®
ï£¹
ï£® Ï‰
ï£¹
SÎº
ÎžÎº
ï£¯
ï£º Ï‰
ï£¯
ï£º
..
..
S := ï£°
ï£» , Îž := ï£°
ï£»,
.
.
ÎžÏ‰
1

S1

âˆ‘ o pÏ‰ (Î¾ Ï‰ + Tr {SÎžÏ‰ }) .

SâˆˆÎ¨ pâˆˆâˆ†(â„¦o ) Ï‰âˆˆâ„¦

(24)

The following proposition addresses the existence of an
equilibrium for the game G .
Proposition 2 (Existence Result). There exists at least one
tuple of strategies (Î·, {Î³ Ï‰ (Î·)}Ï‰âˆˆâ„¦o ) attaining the equilibrium
of the Stackelberg game G , i.e., satisfying (12).
It is instructive to examine whether optimal signaling strategies end up using irrelevant information or not. The inner
optimization problem in (24)
max

âˆ‘

pâˆˆâˆ†(â„¦o ) Ï‰âˆˆâ„¦o

pÏ‰ (Î¾ Ï‰ + Tr{SÎžÏ‰ })

Ï‰0

since the optimization objective in (24) is a linear function of
p âˆˆ âˆ†(â„¦o ). Based on the observation (26) and the assumption
that the type set â„¦o is finite, the following theorem provides
an algorithm to compute robust sensor outputs.
Theorem 1 (Computing the Equilibrium). The value of the
Stackelberg equilibrium (24) is given by Âµ = minÏ‰âˆˆâ„¦o {ÂµÏ‰ },
where



ÂµÏ‰ := min Î¾ Ï‰ + Tr ÎžÏ‰ S
(27)
SâˆˆÎ¨

0
0
s.t. Tr S(ÎžÏ‰ âˆ’ ÎžÏ‰ ) â‰¥ Î¾ Ï‰ âˆ’ Î¾ Ï‰ âˆ€Ï‰ 0 âˆˆ â„¦o .
Furthermore, let ÂµÏ‰ âˆ— = Âµ and



Sâˆ— âˆˆ argmin Î¾ Ï‰ + Tr ÎžÏ‰ S

(28)

SâˆˆÎ¨

and Î¨ âŠ‚ SmÎº
+ be the set corresponding to the constraints (23) in
this new high-dimensional space, i.e., RmÎºÃ—mÎº . With this new
notation, the problem faced by PS , i.e., (22), can be written
as
min max

according to (24), given S âˆˆ Î¨, maximizing pâˆ— âˆˆ âˆ†(â„¦o ) is
given by

pâˆ— âˆˆ p âˆˆ âˆ†(â„¦o ) | pÏ‰ = 0 provided that

 0
0
(26)
(Î¾ Ï‰ + Tr{SÎžÏ‰ }) < max Î¾ Ï‰ + Tr{SÎžÏ‰ }

(25)

is a convex function of S âˆˆ Î¨ since the maximum of any
family of linear/affine functions is a convex function [27].
Therefore, there might be examples where any extreme point
of the constraint set Î¨ is not a solution for (24). Correspondingly, optimal signaling strategy can turn out to be including
irrelevant information. This is interesting in view of Blackwellâ€™s Irrelevant Information Theorem [22, Theorem D.1.1].
Particularly, the theorem says that given a cost measure, for
any Borel measurable function that uses irrelevant information,
there exists another Borel measurable function that does not
use any irrelevant information and can lead to a cost less
than or equal to the one attained with the former function.
Therefore we can conclude that in this robust setting, linear
signaling strategies are not the best one within the general
class of measurable strategies.
Next, we seek to compute the equilibrium of G . To this end,
we examine the equilibrium conditions further. In particular,


0
0
s.t. Tr S(ÎžÏ‰ âˆ’ ÎžÏ‰ ) â‰¥ Î¾ Ï‰ âˆ’ Î¾ Ï‰ âˆ€Ï‰ 0 âˆˆ â„¦o .
Then, given Sâˆ— âˆˆ Î¨, an associated linear-plus-noise signaling
strategy Î· âˆˆ Ï’ can be computed according to (21).
For the readerâ€™s reference, in the following, we list the steps
to compute robust sensor design strategies:
â€¢ We first compute the matrices ÎžÏ‰
k , described in (50),
and scalars Î¾ Ï‰ , described in (44) and (49), for each
type of control objectives, Ï‰ âˆˆ â„¦o . This step includes
computation of gain matrices of optimal control input,
e.g., (16), in an LQG control problem.
Ï‰
â€¢ Given computed {{ÎžÏ‰
k , Î¾ }}, we solve SDP, described
in (27), for each type by using an SDP solver, e.g., [20],
[21], numerically.
â€¢ When we compute Sâˆ— according to (28), we can compute the associated signaling strategies according to
(30). Note that this step includes computation of eigendecomposition of some matrices.
We re-emphasized that we provide an algorithm to compute
robust signaling strategies globally even though the problem
is highly nonlinear and non-convex. There is, however, still
room to develop computationally more efficient approaches.
And the solution concept proposed in the paper can be used as
a benchmark to evaluate performance of such computationally
efficient algorithms.
IV. N OISY OR PARTIAL M EASUREMENTS
In this section, we seek to obtain robust signaling strategies
under noisy or partial (i.e., imperfect) measurements of the
type (2). To this end, we turn the problem to the same structure
with the case under perfect measurements based on a recent
result from [28] and then invoke the results from the previous
section.
There are several challenges in robust sensor design under
imperfect measurements. For example, Proposition 1 does

8

not hold anymore. To obtain a result similar to Proposition
1, a first attempt would be to focus on the covariance matrix of the posterior estimate of control-free measurements,
i.e., cov{E{yyok |ss1:k }}, where y ok := Cxxok + v k , instead of Hk =
cov{E{xxok |ss1:k }}. Quite contrary to the control-free state {xxok },
however, control-free measurements {yyok } do not necessarily
constitute a Markov process since in general E{yyok |yyo1:kâˆ’1 } 6=
E{yyok |yyokâˆ’1 }. Therefore, we focus on the augmented vector of
measurements y o1:k âˆˆ Rnk .
Since the measurements are jointly Gaussian, we have
E{yyok |yyo1:kâˆ’1 } = E{yyok (yyo1:kâˆ’1 )0 }E{yyo1:kâˆ’1 (yyo1:kâˆ’1 )0 }â€ y o1:kâˆ’1 .
This implies that the augmented measurements {yy1:k }kâ‰¥0
evolve according to
y o1:k = Aky o1:kâˆ’1 +eek ,

(29)

where we define


E{yyok (yyo1:kâˆ’1 )0 }E{yyo1:kâˆ’1 (yyo1:kâˆ’1 )0 }â€ 
Ak :=
,
I
 o

y âˆ’ E{yyok |yyo1:kâˆ’1 }
ek := k
0

Lemma 2. Let us denote signaling strategies when s k âˆˆ Rnk
by Î·Ìƒk and the associated strategy space by Ï’Ìƒk . Then for any
{Î·Ìƒk âˆˆ Ï’Ìƒk }, there exists a {Î·k âˆˆ Ï’k } such that they both lead to
the same control strategy and correspondingly the same cost
for PS . And such a signaling strategy {Î·k âˆˆ Ï’k } is given by
Î·k (yy1:k ) = E{xxok |Î·Ìƒ1 (yy1 ), . . . , Î·Ìƒk (yy1:k )}, âˆ€k â‰¥ 1.

Note that neither Ak âˆˆ RnkÃ—n(kâˆ’1) nor e k âˆˆ Rnk depend on
signaling or control strategies. Furthermore, similar to (15),
it can be shown that
E{yyo1:k |ss1:k } = E{yyo1:k |sso1:k },

where we define10 WkÏ‰ := D0k ÎžÏ‰ Dk , which can be viewed
as the counterpart of ÎžÏ‰
k under imperfect measurements. We
remark the resemblance between (17) and (32), where we have
Yk instead of Hk and WkÏ‰ instead of ÎžÏ‰
k.
Recall that yk âˆˆ Rn , which yields that y1:k âˆˆ Rnk . Under
the assumption that sk âˆˆ Rnk instead of sk âˆˆ Rm (so that
PS can disclose the auxiliary y1:k perfectly), we would have
transformed the problem under imperfect measurements into
a problem under perfect measurements, and correspondingly
we could have invoked the results from the previous section
directly. The following lemma shows that results for the case
where s k âˆˆ Rnk would also hold for the case where s k âˆˆ Rm
even when nk > m.

(30)

(33)

Based on Lemma 2, the following corollary to Proposition
1 provides a tractable necessary and sufficient condition on
{Yk }.
Corollary 2 (A Necessary and Sufficient Condition Under
Imperfect Measurements). For any signaling rule Î· âˆˆ Ï’,
covariance matrix of posterior estimate of the control-free
measurements, {Yk = cov{E{yyo1:k |ss1:k }}}, satisfies
Î£y1  Y1  O,

Ï‘ k.
where we now have s ok = Lk0 y o1:k +Ï‘
Since s o1:k is Ïƒ -yy1:k measurable, x ok and s o1:k are independent
of each other conditioned on y o1:k . This implies that x ok , y o1:k ,
and s o1:k can be viewed as forming a Markov chain in the order
x ok â†’ y o1:k â†’ s o1:k . In that respect, [28, Lemma 1] shows that
when {xxok ,yyo1:k ,ss1:k } are jointly Gaussian and form a Markov
chain in the order x ok â†’ y o1:k â†’ s o1:k , there exists a linear relation
between E{xxok |sso1:k } and E{yyo1:k |sso1:k } irrespective of s o1:k , and
the relation is given by

where
:= E{yyo1:k (yyo1:k )0 }.
Furthermore for any collection of positive semi-definite
matrices S1:Îº satisfying

E{xxok |sso1:k } = Dk E{yyo1:k |sso1:k },

there exists a linear-plus-noise signaling strategy Î· âˆˆ Ï’ such
that Sk = Yk .

(31)

where Dk âˆˆ RmÃ—nk is defined by

Î£yk

Under imperfect measurements, counterpart of the covariance matrix Hk = cov{E{xxok |ss1:k }} is the covariance matrix
of the posterior estimate of control-free augmented measurements, denoted by

Î£y1  S1  O,
Î£yk

for k > 1,

max

âˆ‘ o pÏ‰

pâˆˆâˆ†(â„¦o ) Ï‰âˆˆâ„¦
{Sk âˆˆSkn
+}

Î£yk

Correspondingly, (17), i.e., the problem faced by PS , can be
written as
!
Îº

k=1

(35b)

Îº

min

Î¾ Ï‰ + âˆ‘ Tr {SkWkÏ‰ } ,

(36)

k=1

Î£y1  S1  O,

Hk = DkYk D0k .

Î·âˆˆÏ’ pâˆˆâˆ†(â„¦o ) Ï‰âˆˆâ„¦

(35a)

 Sk  Akâˆ’1 Skâˆ’1 A0kâˆ’1 ,

Corollary 3. The problem faced by PS , i.e., (32), is equivalent
to
!

Based on (30) and (31), we have

Î¾ Ï‰ + âˆ‘ Tr {YkWkÏ‰ } ,

(34b)

subject to the following linear matrix inequalities:

Yk := cov{E{yyo1:k |ss1:k }}.

âˆ‘ o pÏ‰

for k > 1,

Î£yk

The following corollary provides a problem equivalent to
(32).

Dk := E{xxok (yyo1:k )0 }E{yyo1:k (yyo1:k )0 }â€  .

min max

(34a)

 Yk  Akâˆ’1Ykâˆ’1 A0kâˆ’1 ,

(32)

 Sk  Akâˆ’1 Skâˆ’1 A0kâˆ’1 ,

(37a)
for k > 1.

(37b)

Furthermore, given as solution {S1:Îº } for (36), we can
compute an optimal signaling strategy for (32), as follows:
â€¢ Compute signaling strategies Î·Ìƒ âˆˆ Ï’Ìƒ as if signal s k can be
nk dimensional, i.e., s k âˆˆ Rnk , according to (21), where
10 We

use the cyclic property of the trace operator.

9

â€¢

we have Î£yk instead of Î£ok , Ak instead of A, and y 1:k instead
of x k .11
For computed Î·Ìƒ âˆˆ Ï’Ìƒ, compute associated signaling strategies Î· âˆˆ Ï’ according to (33).

We remark that under imperfect measurements optimal
signaling strategies are not necessarily memoryless anymore.
Through a similar notational convention as in the previous
section, we can write (36) as
min maxo

âˆ‘

SâˆˆÎ¨Ì„ pâˆˆâ„¦ Ï‰âˆˆâ„¦o

pÏ‰ (Î¾ Ï‰ + Tr {SW Ï‰ }) ,

(38)

where we let Î¨Ì„ âŠ‚ SmÎº(Îº+1)/2 be the set corresponding to the
constraints (37). Then, based on Corollary 3, the following
corollary to Theorem 1 provides a computationally tractable
way to compute robust sensor outputs under imperfect measurements.
Corollary 4 (Computing the Equilibrium Under Imperfect
Measurements). The value of the Stackelberg equilibrium (38)
is given by Âµ = minÏ‰âˆˆâ„¦o {ÂµÏ‰ }, where



ÂµÏ‰ := min Î¾ Ï‰ + Tr W Ï‰ S
(39)
SâˆˆÎ¨Ì„

0
0
s.t. Tr (W Ï‰ âˆ’W Ï‰ )S â‰¥ Î¾ Ï‰ âˆ’ Î¾ Ï‰ âˆ€Ï‰ 0 âˆˆ â„¦o .
Furthermore, let ÂµÏ‰ âˆ— = Âµ and



Sâˆ— âˆˆ argmin Î¾ Ï‰ + Tr W Ï‰ S

(40)

SâˆˆÎ¨Ì„


0
0
s.t. Tr (W Ï‰ âˆ’W Ï‰ )S â‰¥ Î¾ Ï‰ âˆ’ Î¾ Ï‰ âˆ€Ï‰ 0 âˆˆ â„¦o .
Then, given Sâˆ— âˆˆ Î¨Ì„, an associated linear-plus-noise signaling
strategy Î· âˆˆ Ï’ can be computed according to Corollary 3.
V. I LLUSTRATIVE E XAMPLES
In this section, we examine the performance of the proposed
defense measure over various attack scenarios. As an illustrative example, we set length of the time horizon at Îº = 10,
dimension of state m = 2, and dimension of control input r = 2.
We consider the scenario where the systemâ€™s control objective
is to track an exogenous process {zzk } evolving according to

Correspondingly (41) can be written as
Îº

âˆ‘ EkxÌƒxÌƒk+1 k2Q + Ekuuk k2 ,
k=1

where




I2 
I
Q :=
âˆ’I2 2


âˆ’I2 .

As examples of attack scenarios, we consider a type set
â„¦
 = {Ï‰a , Ï‰
0b , Ï‰c }. Let us partition the underlying state x k =
0
x k,1 x k,2 and the exogenous process z k = z k,1 z k,2 ,
where x k,1 and z k,1 (or x k,2 and z k,2 ) correspond to the
first (or the second) entries of the state and the exogenous
process, respectively. We assume that type-Ï‰a attacker seeks
to make {xxk,1 } track {âˆ’zzk,1 } instead of {zzk,1 } whereas it is not
interested in {xxk,2 }. Then its control objective can be written
as
Îº

UCÏ‰a (Î·, Î³ Ï‰a ) =

a
a 2
âˆ’ (âˆ’zzk+1,1 )k2 + EkuuÏ‰
âˆ‘ EkxxÏ‰k+1,1
k k .

k=1

Similarly type-Ï‰b attacker seeks to make {xxk,2 } track {âˆ’zzk,2 }
instead of {zzk,2 } whereas it is not interested in {xxk,1 }. Then
its control objective can be written as
Îº

Ï‰

UC b (Î·, Î³ Ï‰b ) =

b
âˆ’ (âˆ’zzk+1,2 )k2 + Ekuuk b k2 .
âˆ‘ Ekxxk+1,2

Ï‰

Ï‰

k=1

On the other hand, type-Ï‰c attacker is interested in both
entries and seeks to make the entire state {xxk } track {âˆ’zzk }.
Accordingly, its control objective can be written as
UCÏ‰c (Î·, Î³ Ï‰c ) =

wzk âˆ¼ N (0, I2 )} is a white Gaussian
where z 1 âˆ¼ N (0, I2 ), and {w
noise process, and they are independent of each other and
every other parameter. Correspondingly, the systemâ€™s control
objective can be written as
Îº

o 2
o
âˆ’zzk+1 k2 + EkuuÏ‰
âˆ‘ EkxxÏ‰k+1
k k .

and augmented measurements are then given by

   
C O xk
v
yÌƒ k =
+ kz .
O Cz z k
vk

Îº

wzk ,
z k+1 = Azz k +w

UCÏ‰o (Î·, Î³ Ï‰o ) =

where {vvzk } is a white Gaussian measurement noise independent of every other parameter.
Note that the control objective is not in the form of (5);
however, we can transform it into
of (5) by intro the form
0
ducing the augmented state xÌƒk := x0k z0k evolving according
to

 
   
 
x k+1
I O xk
I
w
=
+
u k + zk
z k+1
O I zk
O
wk

(41)

k=1



1 1
while Î£1 = I2 and Î£w = I2 .
0 1
The sensor has access to the measurements:

We set A = Az = I2 and B =

y k = Cxxk +vvk
y zk = Czz k +vvzk ,
11 We provide closed-form expressions for the auxiliary parameters Î£y , A ,
k k
and Dk in Appendix G for the readerâ€™s reference.

c
c 2
âˆ’ (âˆ’zzk+1 )k2 + EkuuÏ‰
âˆ‘ EkxxÏ‰k+1
k k .

k=1

We note that numerical simulations show that mixtures of
types Ï‰a , Ï‰b and Ï‰c can lead to larger costs for the system
than any single type, including type-Ï‰c . In the following,
we examine the cost of PS under perfect and imperfect
measurements separately.
Under perfect measurements, the sensor has access to
yÌƒ k = xÌƒ k . Note that perfect measurements provide the utmost
freedom for PS to shape the belief of the attacker. For any
cost that PS can attain under imperfect measurements, PS
can select a signaling strategy under perfect measurements to
attain the same cost. Therefore, PS attains the lowest possible
cost under perfect measurements in the robust sensor design
framework.
In Table I, we tabulate the cost to PS for the scenarios
where i) there is no attack, i.e., type of PC is Ï‰o ; ii) there

10

TABLE I: Under perfect measurements, i.e., yÌƒ k = xÌƒ k , comparison of the costs to PS , i.e., US as described in (8), over
various scenarios. Entries at each row corresponds to the cost
to PS for different types of PC when it constructs the sensor
outputs according to the extended type set â„¦o . And the last
column provides the maximum cost of PS across all types of
PC .

TABLE II: Under imperfect measurements, comparison of the
costs to PS , i.e., US as described in (8), over various scenarios.
Entries at each row corresponds to the cost to PS for different
types of PC when it constructs the sensor outputs according
to the extended type set â„¦o . And the last column provides the
maximum cost of PS across all types of PC .
â„¦o

Ï‰o

Ï‰a

Ï‰b

Ï‰c

Max

Max

{Ï‰o }

112.39

326.21

324.82

403.09

403.09

352.65

354.02

{Ï‰a }

171.64

209.99

259.51

242.26

259.56

246.30

351.85

{Ï‰b }

167.80

269.60

195.90

254.20

269.60

267.35

320.81

{Ï‰c }

187.26

211.62

201.94

199.51

211.62

224.77

137.71

224.77

{Ï‰o , Ï‰a }

171.40

209.99

260.40

242.97

260.40

191.12

351.11

245.95

351.11

{Ï‰o , Ï‰b }

167.53

270.40

195.90

255.04

270.40

115.29

321.56

185.63

267.93

321.56

{Ï‰o , Ï‰c }

187.26

211.62

201.94

199.51

211.62

{Ï‰o , Ï‰c }

106.26

202.40

224.77

137.71

224.77

{Ï‰o , Ï‰a , Ï‰b , Ï‰c }

185.48

210.00

210.00

202.77

210.00

{Ï‰o , Ï‰a , Ï‰b , Ï‰c }

81.17

199.46

199.46

166.68

199.46

â„¦o

Ï‰o

Ï‰a

Ï‰b

{Ï‰o }

43.03

323.70

354.02

{Ï‰a }

122.31

191.12

351.85

{Ï‰b }

119.09

320.81

185.63

{Ï‰c }

106.26

202.40

{Ï‰o , Ï‰a }

119.65

{Ï‰o , Ï‰b }

Ï‰c

is an attack by type-Ï‰a attacker, i.e., type of PC is Ï‰a ; iii)
there is an attack by type-Ï‰b attacker, i.e., type of PC is Ï‰b ;
and iv) there is an attack by type-Ï‰c attacker, i.e., type of PC
is Ï‰c . Cost to PS varies depending on the type of PC and
how prepared PS is while constructing the sensor outputs. In
other words, PS constructs the sensor outputs according to an
extended type set.
For example, PS would have constructed signaling strategies according to â„¦o = {Ï‰o } if it views that there would not
be any attack. Correspondingly, if there is no attack, then the
cost would be 43.03. However, if there is an attack by, e.g.,
type-Ï‰b attacker, then the cost would be 354.02, which is
significantly higher compared to 43.03. Next, consider that PS
has constructed the sensor outputs according to â„¦o = {Ï‰b }.
Then, the system would be prepared against an attack by
type-Ï‰b attacker, and the cost would be 185.63 when typeÏ‰b attacker attacks. This is significantly lower than the cost
354.02 obtained when PS constructs sensor outputs without
any concern about possible attacks. However, now the cost
to PS is 119.09 if there is no attack and the type of PC is
Ï‰o . This is also higher than the cost 43.3 obtained when PS
constructs sensor outputs without any concern about possible
attacks. It is an uncertainty whether there will be an attack
or not. Correspondingly, if PS constructs the sensor outputs
according to â„¦o = {Ï‰o , Ï‰b }, then the cost would be 115.29
when there is no attack. It is lower than the cost 119.09
obtained before. On the other hand, the cost would still be
around 185.63 when type-Ï‰b attacker attacks the system.
Even though PS is prepared to an attack by type-Ï‰b attacker
by constructing the sensor outputs according to â„¦o = {Ï‰o , Ï‰b },
there can be an attack by another type attacker, e.g., type-Ï‰a .
Then the cost would be 321.56, which is significantly higher
than the cost 185.63 that would be obtained when type-Ï‰b
attacker attacks. The system can decrease this cost by also
considering the possibility of attacks by type-Ï‰a attacker while
constructing the sensor outputs. For example, if PS constructs
the sensor outputs by taking into account types Ï‰a , Ï‰b , and
Ï‰c attacks, then the cost would be at most 199.46 if any of

those types of attacks occurs and the cost would be 81.17 if
there is no attack. These examples show the importance of
constructing sensor outputs in a robust way.
As an example for imperfect measurements, we take y k =
x k,1 + x k,2 + v k , where v k âˆ¼ N (0, 1), and y zk = z k + v zk , where
{vvzk âˆ¼ N (0, I2 )}. In Table II, we tabulate the costs to PS
over various scenarios, similar to Table I. Table II shows that
imperfect measurements lead to larger cost for the system
when there is no attack, as to be expected. However, at
certain scenarios, imperfect measurements can lead to better
performance for the system. For example, when PS constructs
sensor outputs by considering that there would not be any
attack, i.e., according to â„¦o = {Ï‰o }, and there is an attack by
type-Ï‰b attacker, the cost would be 324.82, which is lower
than the cost 354.02 obtained under perfect measurements.
For this scenario, imperfect measurements end up obfuscating
type-Ï‰b attacker and lead to lower cost. In that respect, robust
sensor outputs can be viewed as optimal imperfect measurements that lead to minimum cost for the system. Furthermore,
the cost to PS increases under imperfect measurements over
the scenarios where it is prepared. In Table II, we highlight
those scenarios by shading their cells. A comparison of shaded
cells of Tables I and II verifies the observation emphasized
above, i.e., imperfect measurements limit PS â€™s ability to
persuade PC .
VI. C ONCLUDING REMARKS
In this paper, we have proposed and addressed persuasionbased robust sensor design as a security measure in control
systems against attackers with unknown control objectives.
By designing sensor outputs cautiously in advance, we have
sought to shape attackersâ€™ believes about the underlying state
of the system in order to induce them to act/attack to the
system in line with the systemâ€™s normal operation. We have
modeled the problem formally under the solution concept
of Stackelberg equilibrium where the defender/sensor is the
leader. Non-strategic reaction of the follower/attacker implies
that the defender faces an optimization problem while seeking
to design robust sensor strategies. We have shown that the

11

optimization problem is non-convex and highly nonlinear. To
mitigate this issue, we have formulated a tractable problem
equivalent to that problem and shown how to compute the associated signaling strategies. We have also extended the results
to scenarios where there are imperfect measurements of the
underlying state. Finally, we have examined the performance
of the proposed framework across various attack scenarios.
Future directions of research on this topic include development of computationally efficient algorithms to compute
optimal signaling rules and developing persuasion-based sensor design strategies for scenarios where attackers have partial
information about the underlying state dynamics instead of full
knowledge of it or have side information about the state instead
of relying on sensor outputs only. Another interesting research
direction would be its application on sensor placement or
sensor selection.
Furthermore, even though we have motivated the framework
by relating it to security, the framework could also address
strategic information disclosure over multi-agent control networks where agents have different control objectives. Particularly, independent of how we motivate and set up the signaling
problem (e.g., a security application or a multi-agent noncooperative control network), the solution concept developed
can be adopted in various settings in a straightforward way
provided that
â€¢ Information of interest and all random variables/vectors
are jointly Gaussian
â€¢ There is a single sender and possibly multiple receivers
â€¢ Optimal reaction of each receiver is linear in its posterior
belief
â€¢ The senderâ€™s objective depends on receiversâ€™ reactions
only through an arbitrary quadratic function of their
posterior beliefs
In this paper, we have used this result to address uncertainties
regarding attackersâ€™ (or receiversâ€™) objectives in the security
of control systems over a finite horizon. However, the result
could be adopted in several other scenarios as well, such as:
â€¢ over infinite horizon (as we did in [29])
â€¢ when there are additional tractable constraints on the
covariance of the posterior belief (as we did in [28] for
a power constraint over the signals when there is an
additive Gaussian noise channel between the sender and
the receiver)
Furthermore, the ability to turn signaling problems (which
lead to highly nonlinear and non-convex optimization problems) into linear optimization problems (over the space of
positive-semi definite matrices with linear matrix inequality
constraints) facilitates analysis of problems over more complex
settings, e.g., where
â€¢ There can be multiple controllers seeking to drive the
same system
â€¢ There can be multiple senders that compete with each
other to induce a controller to take certain actions
A PPENDIX A
N OVELTY R ELATIVE TO R EFERENCE [9]
In Reference [9], we formulated an SDP equivalent to the
original optimization problem in scenarios where there is no

uncertainty on the attackerâ€™s objective. Although it may seem
to have a similar flavor, in [9] we used different technical tools
and these tools cannot be adopted for the settings of this paper.
Particularly, in [9] we exploited the fact that a solution of a
linear optimization problem over a compact convex set lies at
extreme points12 of the constraint set. Even though we were
able to characterize the extreme points of the constraint set
for the specific optimization problem in [9], characterization
of extreme points is challenging in general, e.g., see [30].
Furthermore, in the settings of this paper, the associated
optimization problem includes an inner maximization induced
by the sensorâ€™s robustness concern. Therefore the techniques
developed in [9] cannot be used in this setting since the objective function is no longer linear in the optimization arguments
due to the inner maximization. It is indeed a convex function
since maximum of any family of linear/affine functions is a
convex function [27]. Correspondingly, the solution does not
necessarily lie at an extreme point of the constraint set. To be
able to solve this optimization problem globally, in this paper
we have shown that those linear matrix inequalities provide not
only necessary but also sufficient conditions. This leads to a
more comprehensive solution concept since it can be adopted
in other sensor design settings in a straightforward way in
order to obtain an equivalent tractable optimization problem,
e.g., for the settings over imperfect measurements as we did
here, infinite horizon as shown in [29] (based on the results
of this paper), and several others.
A PPENDIX B
P ROOF OF L EMMA 1
Based on (16) and (12a), we obtain (17) through some
algebra as detailed below. We focus on i) part of the cost
induced by the controller of the system, e.g., (9), and ii) part
of the cost induced by the attacker, e.g., (10), separately.
Part-i) For notational brevity, let us first introduce the
following matrices
ï£®
ï£¹
I KÎºÏ‰ B KÎºÏ‰ AB Â· Â· Â· KÎºÏ‰ AÎºâˆ’2 B
Ï‰ B Â· Â· Â· K Ï‰ AÎºâˆ’3 Bï£º
ï£¯
I
KÎºâˆ’1
Îºâˆ’1
ï£¯
ï£º
Ï‰ AÎºâˆ’4 Bï£º
ï£¯
Ï‰
I
Â· Â· Â· KÎºâˆ’2
Î¦ := ï£¯
ï£º
ï£¯
ï£º
..
..
ï£°
ï£»
.
.
I
ï£® Ï‰
ï£¹
ï£® Ï‰
ï£¹
KÎº
âˆ†Îº
ï£º Ï‰
ï£¯
ï£º
ï£¯
..
..
K Ï‰ := ï£°
ï£» , âˆ† := ï£°
ï£».
.
.
K1Ï‰

âˆ†Ï‰
1

Then, the right hand side of (14) can be written in a compact
form as
kÎ¦Ï‰ u + K Ï‰ x o k2âˆ†Ï‰ + Î´0Ï‰

0
in terms of the augmented vectors u = u0Îº Â· Â· Â· u01 and


0
x o = (xxoÎº )0 Â· Â· Â· (xxo1 )0 . Correspondingly, for type-Ï‰ PC ,
we obtain
u Ï‰ = âˆ’(Î¦Ï‰ )âˆ’1 K Ï‰ xÌ‚ o ,
(42)
12 We say that a point in a convex set is an extreme point if it cannot be
expressed as a convex combination of any other two points in the set.

12


0
where xÌ‚ o := E{xxoÎº |ss1:Îº }0 Â· Â· Â· E{xxo1 |ss1 }0 is the augmented
vector of posteriors. Related to (9), this yields
Îº

Ï‰o o
o
o 2
x âˆ’ xÌ‚ o )k2âˆ†Ï‰o + Î´oÏ‰o
k2QÏ‰o + EkuuÏ‰
âˆ‘ EkxxÏ‰k+1
k kRÏ‰o = EkK (x
k=1

= Tr{HV Ï‰o } + Î¾ Ï‰o ,

A PPENDIX C
P ROOF OF P ROPOSITION 1
The necessity condition has been shown in [9, Lemma 3].
In order to show the sufficiency of the condition, suppose
that a collection of positive semi-definite matrices S1:Îº satisfying (35) is given. Then S1 âˆˆ Sm satisfies
Î£o1  S1  O.

where we define Î£o := E{xxo (xxo )0 },
V Ï‰o := âˆ’(K Ï‰o )0 âˆ†Ï‰o K Ï‰o ,

(43)

Î¾ Ï‰o := Î´oÏ‰o âˆ’ Tr{Î£o ÎžÏ‰o },

(44)

and H := E{xÌ‚xÌ‚o (xÌ‚xÌ‚o )0 }, which follows since E{xxo (xÌ‚xÌ‚o )0 } =
E{xÌ‚xÌ‚o (xÌ‚xÌ‚o )0 } due to the law of iterated expectations.
Part-ii) The state x k can be written in terms of control-free
state x ok and control inputs u 1:k as follows:
kâˆ’2

wkâˆ’1 + âˆ‘ Ai Buukâˆ’iâˆ’1 .
x k = Axxokâˆ’1 +w

(45)

i=0

Let us define
ï£®
B
ï£¯
ï£¯
Z := ï£¯
ï£°

AB
B

Â·Â·Â·
Â·Â·Â·
..
.

ï£¹
AÎºâˆ’1 B
AÎºâˆ’2 Bï£º
ï£º
.. ï£º .
. ï£»
B

Then (42) and (45) yield that for Ï‰ âˆˆ â„¦, we have
Îº

âˆ‘ EkxxÏ‰k+1 k2QÏ‰o = EkAÌ„xxo +ww âˆ’ T Ï‰ xÌ‚ o k2QÌ„Ï‰o

(46)

k=1

= Tr{HV Ï‰ } + Î¾ Ï‰ ,
(47)
 0

0
where w := w Îº Â· Â· Â· w 01 , AÌ„ := IÎº âŠ— A, T Ï‰ := Z(Î¦Ï‰ )âˆ’1 K Ï‰ ,
Ï‰
Ï‰
QÌ„ o = IÎº âŠ— Q o , and for all Ï‰ âˆˆ â„¦ we define
V Ï‰ := (T Ï‰ )0 QÌ„Ï‰o T Ï‰ âˆ’ (T Ï‰ )0 QÌ„Ï‰o AÌ„ âˆ’ AÌ„0 QÌ„Ï‰o T Ï‰ ,
Ï‰

o 0

Ï‰o

Ï‰o

Î¾ := Tr{Î£ AÌ„ QÌ„ AÌ„} + ÎºTr{Î£w Q }.

(48)
(49)

wk } is a white noise and T Ï‰
Note that (47) follows since {w
turns out to be an upper triangular (block) matrix.
Combining Parts i) and ii) together, we obtain that PS faces
the following problem:

âˆ‘

pÏ‰ (Tr{HV Ï‰ } + Î¾ Ï‰ ),

Ï‰âˆˆâ„¦o

where V Ï‰ and Î¾ Ï‰ for Ï‰ âˆˆ â„¦o are as described in (43), (44),
(48), and (49). Based on the definition of H, it can be shown
that
ï£®
ï£¹
HÎº
AHÎºâˆ’1
Â· Â· Â· AÎºâˆ’1 H1
ï£¯ HÎºâˆ’1 A0
HÎºâˆ’1
AÎºâˆ’2 H1 ï£º
ï£º
ï£¯
H =ï£¯
..
.. ï£º .
..
ï£°
.
.
. ï£»
Îºâˆ’1
0
Îºâˆ’2
0
H1 (A ) H1 (A ) Â· Â· Â·
H1
m
Therefore, the corresponding ÎžÏ‰
k âˆˆ S in (17) is defined by
Îº
Ï‰
ÎžÏ‰
k := Vk,k +

âˆ‘

Ï‰ lâˆ’k
Ï‰
Vk,l
A + (Alâˆ’k )0Vl,k
,

(50)

l=k+1
Ï‰ âˆˆ RmÃ—m is an m Ã— m block of V Ï‰ , with indexing
where Vk,l
from the right-bottom to the left-top.

(51)

o
o
Note
 that Î£1  O can be singular. Therefore let Î£1 =
Î›Ì„1 O 0
UÌ„1
UÌ„ be the eigen-decomposition such that Î›Ì„1 âˆˆ
O O 1
t1
S++ and t1 := rank{Î£o1 }. When we multiply the terms in (51)
from right by the unitary matrix UÌ„1 and from left by the
transpose of the unitary matrix, i.e., UÌ„10 , we obtain


Î›Ì„1 O
 UÌ„10 S1UÌ„1  O,
O O

which implies that

Î›Ì„1
O

 

O
M1,1 M1,2
âˆ’
 O,
(52)
O
M2,1 M2,2


M1,1 M1,2
where we let UÌ„10 S1UÌ„1 =
be the corresponding
M2,1 M2,2
t
partitioning, e.g., M1,1 âˆˆ S 1 .
Since UÌ„10 S1UÌ„1  O, we have M2,2  O [31, Observation
7.1.2]. However, the bottom-right block of the positive semidefinite matrix (the whole term) on the left-hand-side of the
inequality (52), i.e., âˆ’M2,2 , must also be a positive semidefinite matrix, which implies O  M2,2 . Therefore we can
conclude that M2,2 = O.
0 = O.
Next we invoke [32, Lemma 3] yielding M1,2 = M2,1
Therefore (52) can be written as

 

Î›Ì„1 O
M
O
âˆ’ 1,1
 O.
(53)
O O
O
O
âˆ’1/2

âˆ’1/2

We define T1 := Î›Ì„1 M1,1 Î›Ì„1 , let T1 = U1 Î›1U10 be its eigendecomposition, and let Î»1,1 , . . . , Î»1,t1 be its eigenvalues. Then
(53) yields that It1  T1  Ot1 and correspondingly It1  Î›1 
O, which implies that Î»1,i âˆˆ [0, 1] for all i = 1, . . . ,t1 .
1/2
1/2
Since M1,1 = Î›Ì„1 T1 Î›Ì„1 , M1,2 = M2,1 = O, and M2,2 = O,
S1 can be written as
 1/2

1/2
O UÌ„ 0 .
(54)
S1 = UÌ„1 Î›Ì„1 T1 Î›Ì„1
O
O 1
1
Since Î›Ì„1 âˆˆ St++
is not a singular matrix, (54) yields that there
exists a bijective relation between S1 âˆˆ Sm and T1 âˆˆ St1 , i.e.,
given S1 , we can compute T1 and vice versa. Therefore, we
can just focus on T1 instead of S1 . To this end, consider a
Ï‘ 1 , where Ï‘ 1 âˆ¼ N(0, Î˜1 ). Then,
signaling strategy s 1 = L10 x 1 +Ï‘
the covariance matrix H1 is given by

H1 = Î£o1 L1 (L10 Î£o1 L1 + Î˜1 )â€  L10 Î£o1 .

(55)

Note that we can set L1 âˆˆ RmÃ—m and Î˜1 âˆˆ Sm
+ arbitrarily. Given
theeigenvalues of T1 ; it can be verified that if we set L1 =
âˆ’1/2
o
UÌ„1 Î›Ì„1 U1 Î›1 O and Î˜1  O such that
O
O
o
o
Î›o1 = diag{Î»1,1
, . . . , Î»1,t
},
1
2
2
Î˜1 = diag{Î¸1,1
, . . . , Î¸1,t
, 0, . . . , 0}
1

13

o , Î¸ 2 } satisfy
and the entries {Î»1,i
1,i
o )2
(Î»1,i
o )2 + Î¸ 2
(Î»1,i
1,i

= Î»1,i , for i = 1, . . . ,t1 ,

(56)

then we obtain H1 = S1 exactly. Particularly, for such L1,1
and Î˜1 , eigen-decomposition of Î£o1 yields that L10 Î£1 L1 can be
written as




 âˆ’1/2



âˆ’1/2
Î›Ì„1 O 0
Î›o1U10
Î›Ì„1
O 0
Î›Ì„1 
U
Î›o1 O

1

UÌ„ UÌ„1
UÌ„ UÌ„1
O O 1
O
O 1
O
O
 o 2

(Î›Ì„1 ) O
=
O
O
since unitary matrices satisfy UÌ„1UÌ„10 = UÌ„10 UÌ„1 = I. On the other
hand, Î£o1 L1 can be written as

 âˆ’1/2


 1/2

o
o
Î›Ì„ O 0
UÌ„1 1
UÌ„1UÌ„1 Î›Ì„1 U1 Î›1 O = UÌ„1 Î›Ì„1 U1 Î›1 O .
O O
O
O
O
O
Therefore Î£o1 L1 (L10 Î£o1 L1 + Î˜1 )â€  L10 Î£o1 can be written as
 1/2
 o 2
â€  

1/2
o
(Î›Ì„1 ) + Î˜1 O
Î›o1U10 Î›1
O UÌ„ 0
UÌ„1 Î›Ì„1 U1 Î›1 O
O
O
O
O
O
O 1
 1/2

0 1/2 O
= UÌ„1 Î›Ì„1 U1 Î›1U1 Î›1
UÌ„ 0 , (57)
O
O 1
which follows from (56). Recall that T1 = U1 Î›1U10 . Therefore
(57) is equivalent to (54), which verifies the claim. Note also
o , Î¸ 2 } satisfying (56) since Î» âˆˆ
that there always exist {Î»1,i
1,i
1,i
[0, 1] for all i = 1, . . . ,t1 .
We have shown that given S1 âˆˆ Sm satisfying (51), we can
select a signaling strategy such that H1 = S1 exactly. Next, by
following similar lines, we compute the associated signaling
strategies for k > 1 under the assumption that we have obtained
them up to k âˆ’ 1.
Suppose that H j = S j for j < k. Then, Sk âˆˆ Sm satisfies
Î£ok  Sk  ASkâˆ’1 A0 ,
which is equivalent to
Î£ok âˆ’ AHkâˆ’1 A0  Sk âˆ’ AHkâˆ’1 A0  O.

(58)

0
Correspondingly, Î£ok âˆ’ AHkâˆ’1
 A  O can be singular. Let
Î›Ì„
O
Î£ok âˆ’ AHkâˆ’1 A0 = UÌ„k k
UÌ„ 0 be the eigen-decomposition
O O k
tk
such that Î›Ì„k âˆˆ S++
and tk := rank{Î£ok âˆ’ AHkâˆ’1 A0 }. When we
multiply the terms in (58) from right by the unitary matrix UÌ„k
and from left by the transpose of the unitary matrix, i.e., UÌ„k0 ,
we obtain


Î›Ì„k O
 UÌ„k0 (Sk âˆ’ AHkâˆ’1 A0 )UÌ„k  O.
(59)
O O

Following the same reasons for the case k = 1, [32, Lemma 3]
yields that there exists a symmetric matrix Tk âˆˆ Stk such that
 1/2

1/2
Î›Ì„
T
Î›Ì„
O
0
k
k
Sk = AHkâˆ’1 A + UÌ„k k
UÌ„ 0
(60)
O
O k
and there exists a bijective relation between Tk and Sk âˆ’
AHkâˆ’1 A0 . Similarly, (59) and (60) yield that Itk  Tk  Otk ,
which implies that Tk âˆˆ Stk has eigenvalues in the closed

interval [0, 1]. Let Tk = Uk Î›kUk0 be the eigen decomposition
and Î»k,1 , . . . , Î»k,tk âˆˆ [0, 1] be the associated eigenvalues.
Furthermore, consider a signaling strategy s k = Lk0 x k + Ï‘ k ,
where Ï‘ k âˆ¼ N(0, Î˜k ). Then, the covariance matrix Hk is given
by
Hk = AHkâˆ’1 A0 + (Î£ok âˆ’ AHkâˆ’1 A0 )Lk
Ã—(Lk0 (Î£ok âˆ’ AHkâˆ’1 A0 )Lk + Î˜k )â€  Lk0 (Î£ok âˆ’ AHkâˆ’1 A0 ),
which follows since
cov{E{xxok |ss1:k }} = cov{E{xxok |ss1:kâˆ’1 }}
+ cov{E{xxok |ssk âˆ’ E{ssk |ss1:kâˆ’1 }}},
due to the independence of the jointly Gaussian s 1:kâˆ’1 and
s k âˆ’ E{ssk |ss1:kâˆ’1 }. We can again set Lk âˆˆ RmÃ—m and Î˜k âˆˆ Sm
+
arbitrarily. Given 
the eigenvalues of
Tk , it can be verified that

âˆ’1/2
o
if we set Lk = UÌ„k Î›Ì„k Uk Î›k O and Î˜k  O such that
O
O
o
o
, . . . , Î»k,t
},
Î›ok = diag{Î»k,1
k
2
2
Î˜k = diag{Î¸k,1
, . . . , Î¸k,t
, 0, . . . , 0}
k
o , Î¸ 2 } satisfy
and the entries {Î»k,i
k,i
o )2
(Î»k,i
o )2 + Î¸ 2
(Î»k,i
k,i

= Î»k,i , for i = 1, . . . ,tk ,

then we would obtain Hk = Sk exactly. Therefore, by induction,
we conclude that for any S1:Îº satisfying (35), there exists a
certain signaling strategy Î· âˆˆ Ï’ such that Hk = Sk for all k =
1, . . . , Îº.
A PPENDIX D
P ROOF OF P ROPOSITION 2
Since the objective function in (24) is continuous in the
optimization arguments, and the constraint sets are decoupled
and compact, the extreme value theorem and maximum theorem (showing the continuity of parametric maximization under
certain conditions [33]) yields the existence of a solution to
(24).
A PPENDIX E
P ROOF OF T HEOREM 1
Based on the existence result in Proposition 2, suppose that
Sâˆ— solves (24) and pâˆ— is the maximizer of (25) for Sâˆ— . Since
pâˆ— âˆˆ âˆ†(â„¦o ), there must be at least one type with positive
weight. For example, suppose positive weight for the type
Ï‰ âˆˆ â„¦o , i.e., pÏ‰ > 0. This implies that
0

0

Î¾ Ï‰ + Tr{Sâˆ— ÎžÏ‰ } â‰¥ Î¾ Ï‰ + Tr{Sâˆ— ÎžÏ‰ } âˆ€Ï‰ 0 âˆˆ â„¦o
 0

0
since Î¾ Ï‰ +Tr{Sâˆ— ÎžÏ‰ } = maxÏ‰ 0 âˆˆâ„¦o Î¾ Ï‰ + Tr{Sâˆ— ÎžÏ‰ } by (26).
Furthermore, this also implies that
 0

0
Î¾ Ï‰ + Tr{Sâˆ— ÎžÏ‰ } = âˆ‘ pâˆ—Ï‰ 0 Î¾ Ï‰ + Tr{Sâˆ— ÎžÏ‰ }
Ï‰ 0 âˆˆâ„¦o

14

0

0

since Î¾ Ï‰ + Tr{Sâˆ— ÎžÏ‰ } = Î¾ Ï‰ + Tr{Sâˆ— ÎžÏ‰ } if pâˆ—Ï‰ 0 > 0. These
necessary conditions yield that (24) is equivalent to
min [Î¾ Ï‰ + Tr{SÎžÏ‰ }]
SâˆˆÎ¨

0

0

s.t. Tr{S(ÎžÏ‰ âˆ’ ÎžÏ‰ )} â‰¥ Î¾ Ï‰ âˆ’ Î¾ Ï‰ âˆ€Ï‰ 0 âˆˆ â„¦o
which is an SDP isolated from the distribution over the
extended type set. Therefore, by searching over the extended
type set â„¦o , we can compute the minimum of (24), which is
the minimum over â„¦o . Once the minimum value is computed,
Sâˆ— can be computed according to the corresponding type, i.e.,
(28).
A PPENDIX F
P ROOF OF L EMMA 2
For a signaling strategy as described in (33), we would have
E{xxok |Î·1 (yy1 ), . . . , Î·k (yy1:k )}
= E{xxok |E{xxo1 |Î·Ìƒ1 (yy1 )}, . . . , E{xxok |Î·Ìƒ1 (yy1 ), . . . , Î·Ìƒk (yy1:k )}}
= E{xxok |Î·Ìƒ1 (yy1 ), . . . , Î·Ìƒk (yy1:k )},
where the last line follows since E{xxol |Î·Ìƒ1 (yy1 ), . . . , Î·Ìƒl (yy1:l )}, for
l â‰¤ k, is just a measurable function of {Î·Ìƒ1 (yy1 ), . . . , Î·Ìƒl (yy1:l )}}
while E{xxok |Î·Ìƒ1 (yy1 ), . . . , Î·Ìƒk (yy1:k )} is already conditioned on
{Î·Ìƒ1 (yy1 ), . . . , Î·Ìƒk (yy1:k )}. This yields that they both would lead
to the same posterior. Recall that the best reaction of PC is
linear function of E{xxok |ss1:k } as described in (16). Therefore
they both would lead to the same control inputs almost surely
and therefore the same cost for PS .
A PPENDIX G
C LOSED -F ORM E XPRESSIONS FOR AUXILIARY
PARAMETERS U NDER I MPERFECT M EASUREMENTS
Note that Î£yk âˆˆ Snk , Ak âˆˆ RnkÃ—n(kâˆ’1) , and Dk âˆˆ RmÃ—nk can
be written as




O
Î£yk = O Ik âŠ—C Î£o
+ Ik âŠ— Î£v ,
Ik âŠ—C0


ï£¹
ï£®
 o

O
y
â€ 
O
C
O
Î£
(Î£
)
nÃ—(kâˆ’1)n
kâˆ’1 ï£» ,
Ikâˆ’1 âŠ—C0
Ak = ï£° nÃ—(Îºâˆ’k)n
I(kâˆ’1)n



 o
O
Dk = OmÃ—(Îºâˆ’k)m Im OmÃ—(kâˆ’1)m Î£
(Î£yk )â€  .
Ik âŠ—C0
R EFERENCES
[1] J. Giraldo, E. Sarkar, A. A. Cardenas, M. Maniatakos, and M. Kantarcioglu, â€œSecurity and privacy in cyber-physical systems: A survey of
surveys,â€ IEEE Design & Test, vol. 34, pp. 7â€“17, 2017.
[2] A. Humayed, J. Lin, F. Li, and B. Luo, â€œCyber-physical systems security
â€“ A survey,â€ IEEE Internet of Things Journal, vol. 4, no. 6, 2017.
[3] N. Nelson, â€œThe impact of Dragonfly malware on industrial control
systems,â€ The SANS Institute, 2016.
[4] V. Crawford and J. Sobel, â€œStrategic information transmission,â€ Econometrica, vol. 50, no. 6, pp. 1431â€“1451, 1982.
[5] E. Kamenica and M. Gentzkow, â€œBayesian persuasion,â€ American Economic Review, vol. 101, pp. 25 090â€“2615, 2011.
[6] T. BasÌ§ar and G. J. Olsder, Dynamic Noncooperative Game Theory.
Society for Industrial Mathematics (SIAM) Series in Classics in Applied
Mathematics, 1999.
[7] E. Kamenica, â€œBayesian persuasion and information design,â€ Annual
Review of Economics, vol. 11, 2019.

[8] W. Tamura, â€œA theory of multidimensional information disclosure,â€
Working paper, available at SSRN 1987877, 2014.
[9] M. O. Sayin, E. Akyol, and T. BasÌ§ar, â€œHierarchical multistage Gaussian
signaling games in noncooperative communication and control systems,â€
Automatica, vol. 107, pp. 9â€“20, 2019.
[10] Y. Liu, P. Ning, and M. K. Reiter, â€œFalse data injection attacks against
state estimation in electric power grids,â€ ACM Trans. Information and
System Security, vol. 14, no. 1, 2009.
[11] Y. Mo and B. Sinopoli, â€œIntegrity attacks on cyber-physical systems,â€
in Proc. 1st ACM Int. Conf. High Confidence Networked Systems, 2012,
pp. 47â€“54.
[12] â€”â€”, â€œOn the performance degradation of cyber-physical systems under
stealthy integrity attacks,â€ IEEE Trans. Autom. Control, vol. 61, no. 9,
pp. 2618â€“2624, 2016.
[13] Y. Chen, S. Kar, and J. M. F. Moura, â€œCyber physical attacks with
control objectives and detection constraints,â€ in Proc. 55th IEEE Conf.
on Decision and Control (CDC), 2016, pp. 1125â€“1130.
[14] â€”â€”, â€œCyber physical attacks constrained by control objectives,â€ in
Proc. Americal Control Conference (ACC), 2016, pp. 1185â€“1190.
[15] R. Zhang and P. Venkitasubramaniam, â€œStealthy control signal attacks
in linear quadratic Gaussian control systems: Detectability reward tradeoff,â€ IEEE Trans. Inf. Forensics and Security, vol. 12, no. 7, pp. 1555â€“
1570, 2017.
[16] M. O. Sayin and T. BasÌ§ar, â€œSecure sensor design for cyber-physical
systems against advanced persistent threats,â€ in Proceedings of International Conference on Decision and Game Theory for Security on Lecture
Notes in Computer Science, S. Rass, B. An, C. Kiekintveld, F. Fang, and
S. Schauder, Eds., vol. 10575. Vienna, Austria: Springer, Oct. 2017,
pp. 91â€“111.
[17] â€”â€”, â€œSecure sensor design against undetected infiltration: Minimum
impact-minimum damage,â€ arXiv:1801.01630, 2018.
[18] F. Miao, Q. Zhu, M. Pajic, and G. J. Pappas, â€œCoding schemes for
securing cyber-physical systems against stealthy data injection attacks,â€
IEEE Trans. Autom. Control, vol. 4, no. 1, pp. 106â€“117, 2017.
[19] P. R. Kumar and P. Varaiya, Stochastic Systems. Prentice-Hall, 1986.
[20] M. Grant and S. Boyd, â€œCVX: Matlab software for disciplined convex
programming, version 2.1,â€ http://cvxr.com/cvx, mar 2014.
[21] â€”â€”, â€œGraph implementations for nonsmooth convex programs,â€ in
Recent Advances in Learning and Control. Springer-Verlag Limited,
2008, pp. 95â€“110.
[22] S. YuÌˆksel and T. BasÌ§ar, Stochastic Networked Control Systems.
BirkhaÌˆuser/Springer, 2013, vol. 10.
[23] T. M. Cover and J. A. Thomas, Elements of Information Theory. WileyInterscience, 2006.
[24] R. Bansal and T. BasÌ§ar, â€œSimultaneous design of measurement and
control strategies for stochastic systems with feedback,â€ Automatica,
vol. 25, no. 5, pp. 679â€“694, 1989.
[25] J. Sadeghi, S. Sadeghi, and S. T. A. Niaki, â€œOptimizing a hybrid vendormanaged inventory and transportation problem with fuzzy demand: An
improved particle swarm optimization algorithm,â€ Information Sciences,
vol. 272, pp. 126â€“144, 2014.
[26] J. Kennedy and R. Eberhart, â€œParticle swarm optimization,â€ in Proc.
IEEE Int. Conf. Neural Networks, 1995, pp. 1942â€“1948.
[27] S. Boyd and L. Vandenberghe, Convex Optimization.
Cambridge
University Press, 2004.
[28] M. O. Sayin and T. BasÌ§ar, â€œDeceptive multi-dimensional information
disclosure over a Gaussian channel,â€ in Proceedings of the American
Control Conference (ACC), 2018, pp. 6545â€“6552.
[29] â€”â€”, â€œOn the optimality of linear signaling to deceive Kalman filters
over finite/infinite horizons,â€ in Proceedings of International Conference
on Decision and Game Theory for Security on Lecture Notes in Computer Science, T. Alpcan, Y. Vorobeychik, J. S. Baras, and G. Dan, Eds.,
vol. 11836. Stockholm, Sweden: Springer, 2019, pp. 459â€“478.
[30] M. Jerison, â€œA property of extreme points of compact convex sets,â€ Proc.
Amer. Math. Soc., vol. 5, pp. 782â€“783, 1954.
[31] R. A. Horn and C. R. Johnson, Matrix Analysis. Cambridge University
Press, 1985.
[32] M. O. Sayin and T. BasÌ§ar, â€œDynamic information disclosure for deception,â€ in Proceedings of the 57th IEEE Conference on Decision and
Control (CDC), 2018, pp. 1110â€“1117.
[33] E. Ok, Real Analysis with Economics Applications. Princeton University
Press, 2007.

15

Muhammed O. Sayin received the B.S. and M.S. degrees in electrical and
electronics engineering from Bilkent University, Ankara, Turkey, in 2013 and
2015, respectively. He received the Ph.D. degree in electrical and computer
engineering from the University of Illinois at Urbana-Champaign (UIUC) in
2019. He is currently a Postdoctoral Associate at Laboratory for Information
and Decision Systems (LIDS) at MIT. His current research interests include
dynamic games and decision theory, information design problems, and multiagent systems.

Tamer BasÌ§ar (Sâ€™71-Mâ€™73-SMâ€™79-Fâ€™83-LFâ€™13) is with the University of
Illinois at Urbana-Champaign, where he holds the academic positions of
Swanlund Endowed Chair; Center for Advanced Study Professor of Electrical
and Computer Engineering; Research Professor at the Coordinated Science
Laboratory; and Research Professor at the Information Trust Institute. He is
also the Director of the Center for Advanced Study.
He received B.S.E.E. from Robert College, Istanbul, and M.S., M.Phil, and
Ph.D. from Yale University. He is a member of the US National Academy
of Engineering, member of the European Academy of Sciences, and Fellow
of IEEE, IFAC (International Federation of Automatic Control) and SIAM
(Society for Industrial and Applied Mathematics), and has served as president
of IEEE CSS (Control Systems Society), ISDG (International Society of
Dynamic Games), and AACC (American Automatic Control Council). He has
received several awards and recognitions over the years, including the highest
awards of IEEE CSS, IFAC, AACC, and ISDG, the IEEE Control Systems
Award, and a number of international honorary doctorates and professorships.
He has over 900 publications in systems, control, communications, and
dynamic games, including books on non-cooperative dynamic game theory,
robust control, network security, wireless and communication networks, and
stochastic networked control. He was the Editor-in-Chief of Automatica
between 2004 and 2014, and is currently editor of several book series. His
current research interests include stochastic teams, games, and networks;
distributed algorithms; security; and cyber-physical systems.

