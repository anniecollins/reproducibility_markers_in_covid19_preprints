A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

arXiv:1901.06602v7 [math.NT] 20 Mar 2021

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI
Dedicated to Wolfgang M. Schmidt on the occasion of his 85th birthday
A BSTRACT. We extend the parametric geometry of numbers (initiated by Schmidt and
Summerer, and deepened by Roy) to Diophantine approximation for systems of m linear
forms in n variables, and establish a new connection to the metric theory via a variational
principle that computes fractal dimensions of a variety of sets of number-theoretic interest. The proof relies on two novel ingredients: a variant of Schmidtâ€™s game capable of
computing the Hausdorff and packing dimensions of any set, and the notion of templates,
which generalize Royâ€™s rigid systems. In particular, we compute the Hausdorff and packing
dimensions of the set of singular systems of linear forms and show they are equal, resolving a conjecture of Kadyrov, Kleinbock, Lindenstrauss and Margulis, as well as a question
of Bugeaud, Cheung and Chevallier. As a corollary of Daniâ€™s correspondence principle,
the divergent trajectories of a one-parameter diagonal action on the space of unimodular
lattices with exactly two Lyapunov exponents with opposite signs has equal Hausdorff and
packing dimensions. Other applications include quantitative strengthenings of theorems
due to Cheung and Moshchevitin, which originally resolved conjectures due to Starkov and
Schmidt respectively; as well as dimension formulas with respect to the uniform exponent
of irrationality for simultaneous and dual approximation in two dimensions, completing
partial results due to Baker, Bugeaud, Cheung, Chevallier, Dodson, Laurent and Rynne.

C ONTENTS

1.
2.
3.

4.

Part 1. Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Readersâ€™ Guide . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Conventions and Glossary of Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Statements of Main results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.1. Dani correspondence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2. Dimensions of very singular matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3. 1 Ã— 2 and 2 Ã— 1 matrices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.4. Singularity on average . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.5. Starkovâ€™s conjecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.6. Schmidtâ€™s conjecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
The variational principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1

3
3
4
7
8
11
14
16
16
17
18

2

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

4.1. Successive minima functions and templates . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2. New proofs of old results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5. Directions to further research . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1. Exact Hausdorff and packing dimensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.2. Quantitative Schmidtâ€™s conjecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.3. Regularity of dimension functionals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.4. Intersecting standard and uniform exponent level sets . . . . . . . . . . . . . . . . .
5.5. Precise dimension formulas for uniform exponent level sets . . . . . . . . . . . .
5.6. Metric theory for Îµ-Dirichlet improvable matrices . . . . . . . . . . . . . . . . . . . . . .
5.7. Weighted singular matrices and general diagonal flows . . . . . . . . . . . . . . . .
5.8. Inhomogeneous Diophantine approximation . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.9. Parametric geometry of numbers in arbitrary characteristic. . . . . . . . . . . . .
6. Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

18
26
27
27
27
28
28
28
29
29
29
30
30

Part 2. Proof of main theorems using the variational principle . . . . . . . . . .
Leitfaden to Part 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of (7.1) + Theorem 3.5, upper bound for packing dimension . . . . . . . . . . .
Proof of (7.2) + Theorem 3.5, first formula, lower bound for Hausdorff
dimension . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.5, upper bound for Hausdorff dimension . . . . . . . . . . . . . . . .
Proof of Theorem 3.5, second formula, lower bound for Hausdorff dimension
Proof of Theorem 3.8, lower bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.8, upper bound when n â‰¥ 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.9. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.6, lower bound for Hausdorff dimension . . . . . . . . . . . . . . . .
Proof of Theorem 3.7, lower bound for Hausdorff dimension . . . . . . . . . . . . . . . .
Proof of Theorem 3.6, upper bound for Hausdorff dimension . . . . . . . . . . . . . . . .
Proof of Theorem 3.7, upper bound for Hausdorff dimension . . . . . . . . . . . . . . . .
Proof of Theorem 3.7, upper bound for packing dimension . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 3.14 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 4.2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 4.10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Proof of Theorem 4.11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

31
31
32

7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.

35
39
42
43
47
50
53
53
54
55
56
56
64
65
65
67
68
68

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

Part 3. Dimension games . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27. Preliminaries on measures and dimensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
28. A characterization of Hausdorff and packing dimensions using games . . . . . . .
29. Playing games with Diophantine targets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3

70
70
71
77

Part 4. Proof of the variational principle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
30. Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
31. Proof of Theorem 4.6, lower bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
31.1. Reduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
31.2. Mini-strategy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
31.3. Error correction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .104
31.4. Uniform error bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .110
32. Proof of Theorem 4.6, upper bound. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .116
Part 5. Appendix and references . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
Appendix A. Translating between Schmidtâ€“Summererâ€™s notation and ours . . . . . . .122
References. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .123

Part 1. Introduction
1. R EADERS â€™ G UIDE
The following brief guide will aid non-linear navigation across the paper. To prevent misunderstanding, the reader should first acquaint themselves with Conventions
1 through 7, which may be found at the start of Section Â§2. The conventions are followed by a glossary of notation (in the order of their appearance), which may be skipped
on a first reading. After the conventions one must read Section Â§3 (Main Results) and
Section Â§4 (The Variational Principle), which contain statements of all the main theorems as well as fundamental definitions that are germane to the sequel. Section Â§5
contains a sample of future research directions. The several theorems of Section Â§3 are
all consequences of a single variational principle in the parametric geometry of numbers,
which provides a unifying perspective to both old and new results in the metric theory of
Diophantine approximation. Theorem 4.6 in Section Â§4 is the version of this variational
principle we prove in the sequel.
At this stage, there are a few potential routes ahead. Readers keen to get directly to
the various applications in Section Â§3 could take the variational principle (Theorem 4.6)

4

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

for granted and move directly to Part 2 (Proofs of main theorems using the variational principle). This allows one to better familiarize themselves with how to apply the
variational principle before entering the myriad details that its intricate proof entails.
An alternate route would be to skip the proofs of the applications in Part 2, and instead
move straight to the heart of the paper, viz. our proof of the variational principle (Theorem 4.6). This proof involves reading Part 3 (Dimension games) and Part 4 (Proof of
the variational principle) in order. We note that the proof of the upper bound in Section
Â§32 is significantly shorter than that of the lower bound in Section Â§31.
Readers particularly interested in our variant of Schmidtâ€™s game (that computes the
Hausdorff and packing dimensions of any Borel set in a doubling metric space) may
read Section Â§27 (Preliminaries on measures and dimensions) and Section Â§28 (A
characterization of Hausdorff and packing dimensions using games) (both in Part 3)
independently of all other sections in the paper.
2. C ONVENTIONS

AND

G LOSSARY

OF

N OTATION

We begin with our most important conventions, which should not be skipped and may
be especially useful for a non-linear reader.
def

Convention 1. We denote the nonnegative integers as N = {0, 1, 2, . . .}.
def

Convention 2. Where applicable, the nonzero integers m, n, and d = m + n are treated
as constant.
Convention 3. All measures and sets are assumed to be Borel, and measures are assumed
to be locally finite. Sometimes we restate these hypotheses for emphasis.
Convention 4. Given a vector space V and some index set I we use the notation
hxi âˆˆ V : i âˆˆ Ii
to mean the set generated by {xi âˆˆ V : i âˆˆ I}, or the smallest subspace containing
{xi âˆˆ V : i âˆˆ I}.
Convention 5. We use uppercase letters X, Y, . . . for matrices and bold letters x, y, . . .
for vectors.
Convention 6. In what follows, A . B means that there exists a constant C (the implied
constant) such that A â‰¤ CB. A â‰ B means A . B . A. Similarly, A .+ B means that
A â‰¤ B + C for some constant C. When we write A .Î² B or A .+,Î² B this signifies
that the implied constant depends on Î². We use A â‰+ B to mean A .+ B and B .+ A.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

5

For instance, this allows us to write A â‰+ B = C â‰+ D without having to write O(1)
everywhere, which would obscure some of the information and also be more cluttered.
Convention 7. Recall that Î˜(x) denotes any number such that x/C â‰¤ Î˜(x) â‰¤ Cx for
some uniform constant C. Similarly, â„¦(x) and O(x) denote numbers such that x/C â‰¤
â„¦(x) and |O(x)| â‰¤ Cx for some uniform positive constant C, respectively.

Glossary of Notation. For the readerâ€™s convenience we summarize a partial list of notations and terminology in the order that they appear in the sequel.
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢

M . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The space of m Ã— n matrices with real entries
Sing(m, n) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The set of singular m Ã— n matrices

def
1
Î´m,n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Î´m,n = mn 1 âˆ’ m+n
BA(m, n) . . . . . . . . . . . . . . . . . . . . . . . . . The set of badly approximable m Ã— n matrices
VWA(m, n) . . . . . . . . . . . . . . . . . . . . The set of very well approximable m Ã— n matrices
dimH (S) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The Hausdorff dimension of a set S
dimP (S) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The packing dimension of a set S
Ik . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The k-dimensional identity matrix
def
d . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .d = m + n
Î»j (Î›) (1 â‰¤ j â‰¤ d) . . . . . . . . . . . . . . . . . . . . . . . . . . The jth minimum of a lattice Î› âŠ† Rd
ï£®
ï£¹

t/m
ï£¯ e Im
ï£¯
â€¢ gt . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . For t âˆˆ R, gt = ï£°
def

eâˆ’t/n In
ï£®

ï£º
ï£º âˆˆ SLd (R)
ï£»

ï£¹

I A ï£º
def ï£¯ m
ï£º âˆˆ SLd (R)
â€¢ uA . . . . . . . . . . . . . . . . . . . . . . . . . . For an m Ã— n matrix A, uA = ï£¯
ï£°
ï£»
In

â€¢ Ï‰
b (A) . . . . . . . . . . . . . . . . The uniform exponent of irrationality of an m Ã— n matrix A
â€¢ VSing(m, n) . . . . . . The set of very singular m Ã— n matrices, i.e. {A : Ï‰
b (A) > n/m}
def
âˆ’1
â€¢ Ï„b(A) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Ï„b(A) = lim inf tâ†’âˆ t log Î»1 (gt uA Zd )
â€¢ Ï„ ................................................................... Ï„ =
def

n
1 Ï‰âˆ’ m
n Ï‰+1

â€¢ Singm,n (Ï‰) . . . . . . . . . . . . . . . . . . . . . . Singm,n (Ï‰) = {A : Ï‰
b (A) = Ï‰} = {A : Ï„b(A) = Ï„ }
â€¢ trivially singular . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Section Â§ 3.2.1
def
â€¢ Singâˆ—m,n (Ï‰) . . . . . . . . . . . Singâˆ—m,n (Ï‰) = {A âˆˆ Singm,n (Ï‰) : A is not trivially singular}


def
â€¢ P(A) . . . . . . . . . . . . . . . P(A) = limÎµâ†’0 lim inf T â†’âˆ T1 Î» t âˆˆ [0, T ] : Î»1 (gt uA Zd ) â‰¤ Îµ
â€¢ singular on average . . . . . . . . . . . . . . . . . . . . . . . . A is singular on average if P(A) = 1

6

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

â€¢ k-singular . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .See Definition 3.13
â€¢ {x} . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . {x} denotes the fractional part of x âˆˆ R
 km  kn
def
â€¢ fm,n (k) . . . . . . . . . . . . . . . . . . . . . . . . . . . . fm,n (k) = mn âˆ’ k(m+nâˆ’k)mn
âˆ’ m+n
(m+n)2
m+n
def

â€¢ h, hA , hi (t) . . . . . . . . . . . h = hA = (h1 , . . . , hd ) : [0, âˆ) â†’ Rd , hi (t) = log Î»i (gt uA Zd )
def
â€¢ Vj,t . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Vj,t = spanR{r âˆˆ Zd : kgt uA rk â‰¤ Î»j (gt uA Zd )}
def
â€¢ Fj,I (t) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .n. . . . . . . . . . . Fj,I (t) = log kgt uA (Vj,t âˆ© Zd )k
o
def

Z(j) . . . . . . . . . . . . . . . . . . . . . . . . . . Z(j) = Lm+ âˆ’ Lnâˆ’ : LÂ± âˆˆ [0, dÂ± ]Z, L+ + Lâˆ’ = j
template . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 4.1
balanced template . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 4.1
partial template . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 4.1
Tm,n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .The space of m Ã— n templates
def P
Fj . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Fj = 0<iâ‰¤j fi for a map f : [0, âˆ) â†’ Rd
convexity condition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Fj is convex when fj < fj+1
quantized slope condition . . . Slopes of the pieces of Fj are in Z(j) when fj < fj+1
def
def
f0 , fd+1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . f0 = âˆ’ âˆ and fd+1 = + âˆ
def
D(f) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D(f) = {A : hA â‰+ f}
def S
D(F ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . D(F ) = f âˆˆF D(f)
LÂ± = LÂ± (f, I, q) . . . . . . . . . . . . . Chosen so that L+ + Lâˆ’ = q and Fqâ€² = Lm+ âˆ’ Lnâˆ’ on I
MÂ± = MÂ± (f, I, p, q) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . MÂ± (p, q) = LÂ± (q) âˆ’ LÂ± (p)
Î´(f), Î´(f) . . . . . . . . . . . . . . Lower and upper average contraction rates of a template f
def
f (t)
Ï„b(f) . . . . . . . . . . . . . The uniform dynamical exponent of f: Ï„b(f) = lim inf tâ†’âˆ âˆ’1
t 1
âˆ—
âˆ—
def
g
g
b (A) â‰¥ Ï‰, A not trivially singular}
â€¢ Singm,n (Ï‰) . . . . . . . . . . . . . . . . Singm,n (Ï‰) = {A : Ï‰
s
â€¢ H (A) . . . . . . . . . . . . . . . . . . . . The s-dimensional Hausdorff measure of a set A âŠ† Rd
â€¢ P s (A) . . . . . . . . . . . . . . . . . . . . . . . The s-dimensional packing measure of a set A âŠ† Rd
â€¢ dimH (A) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The Hausdorff dimension of a set A âŠ† Rd
â€¢ dimP (A) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The packing dimension of a set A âŠ† Rd
â€¢ B(x, Ï) . . . . . . . . . . . . . . . . . . . . . . The closed ball centered at x âˆˆ Rd with radius Ï > 0
â€¢ N (A, Îµ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The Îµ-neighborhood of a set A âŠ† Rd
def
â€¢ dimx (Âµ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . dimx (Âµ) = lim inf Ïâ†’0 log Âµ(B(x, Ï))/ log Ï
def
â€¢ dimx (Âµ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . dimx (Âµ) = lim supÏâ†’0 log Âµ(B(x, Ï)) log Ï
P
def
â€¢ Î´(A) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .Î´(A) = lim inf kâ†’âˆ k1 ki=0 âˆ’ log #(Ai )/ log(Î²)
P
def
â€¢ Î´(A) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Î´(A) = lim supkâ†’âˆ k1 ki=0 âˆ’ log #(Ai )/ log(Î²)
â€¢ h(Î›) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (log Î»1 (Î›), . . . , log Î»d (Î›))
â€¢ Î›-rational . . . . . . . . . . . . . . A subspace V âŠ† Rd is Î›-rational if V âˆ© Î› is a lattice in V
â€¢ Vq (Î›) . . . . . . . . . . . . . . . . . . . . . . . . . Set of all q-dimensional Î›-rational subspaces of Rd
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢
â€¢

7

kV k . . . . . . . . . . . . . . . . Covolume of V âˆ© Î› in V , where Î› is understood from context
def
L . . . . . . . . . . . . . . . . . . L = {0} Ã— Rn is the subspace of Rd contracted by the (gt ) flow
C(V, Îµ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Conical Îµ-neighborhood of a subspace V âŠ† Rd
Î·-integral . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . see Def. 31.1
splits, mergers, transfers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 31.2
simple . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 31.2
convex hull function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 31.6
b-perturbation of f at t0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Lemma 31.14
G = G(d, n) . . . . . . . . . . The Grassmannian variety of n-dimensional subspaces of Rd
standard template . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 9.1
s[(tk , âˆ’Îµk ), (tk+1, âˆ’Îµk+1 )] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . See Def. 9.1
3. S TATEMENTS

OF

M AIN

RESULTS

The notion of singularity (in the sense of Diophantine approximation) was introduced
by Khintchine, first in 1937 in the setting of simultaneous approximation [41], and later
in 1948 in the more general setting of matrix approximation [42]. Since then this notion
has been studied within Diophantine approximation and allied fields, see Moshchevitinâ€™s
excellent yet far from comprehensive 2010 survey [51].
Let M denote the set of all m Ã— n matrices with real entries. A matrix A âˆˆ M is called
singular if for all Îµ > 0, there exists QÎµ such that for all Q â‰¥ QÎµ , there exist integer vectors
p âˆˆ Zm and q âˆˆ Zn such that
kAq + pk â‰¤ ÎµQâˆ’n/m

and

0 < kqk â‰¤ Q.

Here and from now on k Â· k is used to denote two fixed norms1, one on Rm and the other
on Rn . We denote the set of singular m Ã— n matrices by Sing(m, n). For 1 Ã— 1 matrices
(i.e. numbers), being singular is equivalent to being rational, and in general any matrix
A which satisfies an equation of the form Aq = p, with p, q integral and q nonzero,
is singular. However, Khintchine proved that there exist singular 2 Ã— 1 matrices whose
entries are linearly independent over Q [40, Satz II]2, and his argument generalizes to
the setting of m Ã— n matrices for all (m, n) 6= (1, 1). The name singular derives from the
fact that Sing(m, n) is a Lebesgue nullset for all m, n, see e.g. [41, p.431] or [13, Chapter
1

Note that many definitions, such as the one above, and all our main theorems, are insensitive to the choice
of these norms. In some cases, e.g. in the course of a proof, we specify a particular norm for computational
convenience.
2
Although Khintchineâ€™s seminal 1926 paper [40] includes a proof of the existence of 2Ã—1 and 1Ã—2 matrices
possessing a certain property which clearly implies that they are singular, it does not include a definition
of singularity nor discuss any property equivalent to singularity.

8

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

5, Â§7]. Note that singularity is a strengthening of the property of Dirichlet improvability
introduced by Davenport and Schmidt [22].
In contrast to the measure zero result mentioned above, the computation of the Hausdorff dimension of Sing(m, n) has been a challenge that so far only met with partial
progress. The first breakthrough was made in 2011 by Cheung [16], who proved that
the Hausdorff dimension of Sing(2, 1) is 4/3; this was extended in 2016 by Cheung and
Chevallier [17], who proved that the Hausdorff dimension of Sing(m, 1) is m2 /(m + 1) for
all m â‰¥ 2; while most recently Kadyrov, Kleinbock, Lindenstrauss, and Margulis (KKLM)

def
1
,
[38] proved that the Hausdorff dimension of Sing(m, n) is at most Î´m,n = mn 1 âˆ’ m+n
and went on to conjecture that their upper bound is sharp for all (m, n) 6= (1, 1) (see also
[11, Problem 1]).
Cheung and Chevallierâ€™s result for singular vectors was an equality and they needed to
develop separate tools to deal with upper and lower bounds. They developed the notion
of best approximation vectors and a multidimensional extension of Legendreâ€™s theorem
on convergents of real continued fraction expansions, as well as the notion of self-similar
coverings that construct Cantor sets with â€œinhomogeneousâ€ tree structures. On the other
hand, though KKLM were only able to prove an upper bound rather than an equality,
their methods, which were orthogonal to those of Cheung and Chevallier, leveraged the
technology of integral inequalities developed by Eskin, Margulis and Mozes [26] and
extend Cheung and Chevallierâ€™s upper bound to the matrix framework.
Completely independent of the aforementioned results and techniques, we prove (as
announced in [21]) that KKLMâ€™s conjecture is correct, and further that the packing dimension of Sing(m, n) is the same as its Hausdorff dimension, thus answering a question
of Bugeaud, Cheung, and Chevallier [11, Problem 7]. To summarize:

Theorem 3.1. For all (m, n) 6= (1, 1), we have
def

dimH (Sing(m, n)) = dimP (Sing(m, n)) = Î´m,n = mn 1 âˆ’

1
m+n


,

where dimH (S) and dimP (S) denote the Hausdorff and packing dimensions of a set S, respectively.

3.1. Dani correspondence. The set of singular matrices is linked to homogeneous dynamics via the Dani correspondence principle [19, 44]. For each t âˆˆ R and for each matrix

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

A âˆˆ M, let

ï£®

t/m

e
def ï£¯
gt = ï£¯
ï£°

ï£¹

Im
eâˆ’t/n In

ï£º
ï£º,
ï£»

ï£®

9

ï£¹

I
A ï£º
def ï£¯ m
ï£º,
uA = ï£¯
ï£°
ï£»
In
def

where Ik denotes the k-dimensional identity matrix. Finally, let d = m + n, and for each
j = 1, . . . , d, let Î»j (Î›) denote the jth minimum of a lattice Î› âŠ† Rd , i.e. the infimum of
Î» such that the set {r âˆˆ Î› : krk â‰¤ Î»} contains j linearly independent vectors. Then the
Dani correspondence principle is a dictionary between the Diophantine properties of a
matrix A on the one hand, and the dynamical properties of the orbit (gt uA Zd )tâ‰¥0 on the
other.
Recall that an mÃ—n matrix A is called badly approximable if there exists c > 0 such that
n
for all integer vectors p âˆˆ Zm and q âˆˆ Zn \ {0} we have kAq+ pk â‰¥ ckqkâˆ’ m ; and is called
very well approximable if there exist Îµ > 0 and infinitely many integer vectors p âˆˆ Zm and
n
q âˆˆ Zn \ {0} such that kAq + pk â‰¤ kqkâˆ’( m +Îµ) . Such classes have been intensively studied
within the field of metric Diophantine approximation [5, 10, 24].
Diophantine properties of A Dynamical properties of (gt uA x0 )tâ‰¥0
A is badly approximable

(gt uA x0 )tâ‰¥0 is bounded

A is singular

(gt uA x0 )tâ‰¥0 is divergent

A is very well approximable

lim suptâ†’âˆ 1t d(x0 , gt uA x0 ) > 0

We denote the sets of badly approximable, singular, and very well approximable matrices by BA(m, n), Sing(m, n), and VWA(m, n), respectively. Using the Dani correspondence principle, the fact that they are all Lebesgue null sets can now be seen to follow
from the ergodicity of the (gt)-action (see [3, Corollary 2.2 in Chapter III]). Indeed, in
each case it suffices to show that any trajectory that equidistributes is not in the respective set. An equidistributed trajectory is not bounded because the orbit must be dense,
proving that BA(m, n) is Lebesgue null. An equidistributed trajectory is not divergent
because that would imply escape of mass, proving that Sing(m, n) is Lebesgue null. Finally, an equidistributed trajectory does not escape to infinity at a linear rate because this
would imply that it spends a proportionally long time near infinity infinitely often, which
would imply escape of mass (along a subsequence); thereby proving that VWA(m, n) is
Lebesgue null.

10

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

It follows from the Dani correspondence principle that Theorem 3.1 implies that the
set of divergent trajectories of the one-parameter diagonal (gt )-action (on the space of
unimodular lattices that has exactly two Lyapunov exponents with opposite signs) has
equal Hausdorff and packing dimensions. In the sequel, we focus on Diophantine statements and leave it to the interested reader to translate our results in the language of
homogeneous dynamics.
Let us precisely state the result mentioned in the middle row of the table above as it is
particularly germane to our theme.
Theorem 3.2 ([19, Theorem 2.14]). A matrix A âˆˆ M is singular if and only if the trajectory (gt uA Zd )tâ‰¥0 is divergent in the space of unimodular lattices in Rd , or equivalently (via
Mahlerâ€™s compactness criterion [25, Theorem 11.33]) if
lim Î»1 (gt uA Zd ) = 0.

tâ†’âˆ

It is natural to ask about the set of matrices such that the above limit occurs at a
prescribed rate, such as the set of matrices such that âˆ’ log Î»1 (gt uA Zd ) grows linearly with
respect to t. This question is closely linked with the concept of uniform exponents of
irrationality. The uniform exponent of irrationality of an m Ã— n matrix A, denoted Ï‰
b (A),
is the supremum of Ï‰ such that for all Q sufficiently large, there exist integer vectors
p âˆˆ Zm and q âˆˆ Zn such that
kAq + pk â‰¤ Qâˆ’Ï‰ and 0 < kqk â‰¤ Q.
By Dirichletâ€™s theorem ([23] or [59, Theorem 1E in Â§II]), every m Ã— n matrix A satisfies
n
Ï‰
b (A) â‰¥ m
. Moreover, it is immediate from the definitions that any matrix A satisfying
n
b (A) >
Ï‰
b (A) > m is singular. We call a matrix very singular if it satisfies the inequality Ï‰
n
, in analogy with the set of very well approximable matrices, which satisfy a similar
m
inequality for the regular (non-uniform) exponent of irrationality. We denote the set of
very singular mÃ—n matrices by VSing(m, n). The relationship between uniform exponents
of irrationality and very singular matrices on the one hand, and homogeneous dynamics
on the other, is given as follows:
Theorem 3.3. A matrix A is very singular if and only if Ï„b(A) > 0, where

âˆ’1
log Î»1 (gt uA Zd ).
tâ†’âˆ
t
Moreover, the quantities Ï„ = Ï„b(A) and Ï‰ = Ï‰
b (A) are related by the formula
def

Ï„b(A) = lim inf

(3.1)

n
1Ï‰âˆ’ m
Â·
Ï„=
n Ï‰+1

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

11

This theorem is a straightforward example of the Dani correspondence principle and is
probably well-known, but we have not been able to find a reference.
Proof. The first assertion follows from (3.1), so it suffices to prove (3.1). Let Ï‰ = Ï‰
b (A),
and let Ï„ be given by (3.1); then we need to prove that Ï„b(A) = Ï„ . We prove the â‰¥
direction; the â‰¤ direction is similar. Fix Îµ > 0 and t â‰¥ 0, and let Q = e(1/nâˆ’Ï„ )t . By
the definition of Ï‰, if t (and thus Q) is sufficiently large then there exist p, q such that
kAq + pk â‰¤ Qâˆ’Ï‰+Îµ and 0 < kqk â‰¤ Q. Now let
r = gt uA (p, q) = (et/m (Aq + p), eâˆ’t/n q).
Then
Î»1 (gt uA Zd ) â‰¤ krk â‰ max(et/m kAq + pk, eâˆ’t/n kqk)
â‰¤ max(et/m Qâˆ’Ï‰+Îµ , eâˆ’t/n Q)

= max(et/m e(1/nâˆ’Ï„ )(âˆ’Ï‰+Îµ) , eâˆ’Ï„ t )

= exp âˆ’t min Ï„, n1 âˆ’ Ï„ (Ï‰ âˆ’ Îµ) âˆ’

Since t was arbitrary, it follows that

1
m




âˆ’1
log Î»1 (gt uA Zd ) â‰¥ min Ï„, n1 âˆ’ Ï„ (Ï‰ âˆ’ Îµ) âˆ’
tâ†’âˆ
t
Taking the limit as Îµ â†’ 0 we get


Ï„b(A) â‰¥ min Ï„, n1 âˆ’ Ï„ Ï‰ âˆ’ m1 = min(Ï„, Ï„ ) = Ï„.
Ï„b(A) = lim inf

.

1
m



.



3.2. Dimensions of very singular matrices. Perhaps unsurprisingly, the set of very singular matrices has the same dimension properties as the set of singular matrices.
Theorem 3.4. For all (m, n) 6= (1, 1), we have
dimH (VSing(m, n)) = dimP (VSing(m, n)) = Î´m,n .

One can also ask for more precise results regarding the function Ï‰
b . Specifically, for
3
n
each Ï‰ > m we can consider the levelset
(3.2)

def

def

Singm,n (Ï‰) = {A : Ï‰
b (A) = Ï‰} = {A : Ï„b(A) = Ï„ } = Singm,n (Ï„ ),

where Ï„ is given by (3.1). Elements of the set above are called Ï‰-singular or Ï„ -singular.
It would be desirable to obtain precise formulas for the Hausdorff and packing dimensions of Singm,n (Ï‰) in terms of Ï‰, m, and n, see e.g. [11, Problem 2]. However, this
appears to be extremely challenging at the present juncture. We have made significant
3

For results considering the superlevelset, see Theorem 4.9.

12

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

progress towards this question: solving it completely in the cases (m, n) = (1, 2) and
(m, n) = (2, 1), and for packing dimension in the case where n â‰¥ 2. See Theorems 3.8
and 3.10 for details.
In general, we have obtained asymptotic formulas of two types: estimates valid when
Ï‰ is small and estimates valid when Ï‰ is large. Note that while the minimum value of Ï‰
b
n
is always m (corresponding to Ï„b = 0), the maximum value depends on whether or not n
is at least 2. If n â‰¥ 2, then the maximum value of Ï‰
b is âˆ (corresponding to Ï„b = n1 ), while
if n = 1, then the maximum value of Ï‰
b (excluding rational points) is 1 (corresponding to
mâˆ’1 4
Ï„b = 2m ). Consequently, we have two different asymptotic estimates of the dimensions
of Singm,n (Ï‰) when Ï‰ is large corresponding to these two cases. In all of the formulas
below, Ï„ is related to Ï‰ by the formula (3.1).
Theorem 3.5. Suppose that (m, n) 6= (1, 1). Then for all Ï‰ >
have
q
Ï‰âˆ’
âˆš 
= Î´m,n âˆ’ Î˜ Ï„

dimH (Singm,n (Ï‰)) = Î´m,n âˆ’ Î˜

n
m



n
m

sufficiently close to

n
,
m

we


dimP (Singm,n (Ï‰)) = Î´m,n âˆ’ Î˜ Ï‰ âˆ’

n
m




dimP (Singm,n (Ï‰)) = Î´m,n âˆ’ Î˜ Ï‰ âˆ’

n
m



= Î´m,n âˆ’ Î˜ (Ï„ )

unless (m, n) = (2, 2), in which case


dimH (Singm,n (Ï‰)) = Î´m,n âˆ’ Î˜ Ï‰ âˆ’

n
m

= Î´m,n âˆ’ Î˜ (Ï„ )



= Î´m,n âˆ’ Î˜ (Ï„ ) .

In the sequel, we refer to the dimension formulas in the case (m, n) âˆˆ
/ {(1, 1), (2, 2)} as â€œthe
first case of Theorem 3.5â€, and to the dimension formulas in the case (m, n) = (2, 2) as â€œthe
second case of Theorem 3.5â€.
Theorem 3.6. Suppose that n â‰¥ 2. Then for all Ï‰ < âˆ sufficiently large, we have
dimH (Singm,n (Ï‰)) = mn âˆ’ 2m + Î˜
= mn âˆ’ 2m + Î˜

1
Ï‰
1
n



âˆ’Ï„



dimP (Singm,n (Ï‰)) = mn âˆ’ m.

Theorem 3.7. Suppose that n = 1 and m â‰¥ 2. Then for all Ï‰ < 1 sufficiently close to 1, we
have
4

The reason for this is that if n = 1, then for trivial reasons the value of Ï‰
b at a point x âˆˆ Rm is at most the
minimum value of Ï‰
b over the coordinates x1 , . . . , xm , and if x is irrational, then for some i = 1, . . . , m, xi
is irrational and therefore (since we are in one dimension) satisfies Ï‰
b (xi ) = 1.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

dimH (Singm,n (Ï‰)) = Î˜ (1 âˆ’ Ï‰)


= Î˜ mâˆ’1
âˆ’
Ï„
2m

13

dimP (Singm,n (Ï‰)) = 1.

Beyond the results above, we have a precise formula for the packing dimension when
n â‰¥ 2, which remains a lower bound when n = 1.
Theorem 3.8. Define the function
mn
mn 1 + mÏ„
def
Î´ m,n (Ï„ ) = max mn âˆ’ m, Î´m,n âˆ’
(d + m)Ï„, mn âˆ’
mn
Ï„
m+n
m + n 1 âˆ’ mâˆ’1

!

Â·

Then we have
dimP (Singm,n (Ï„ )) â‰¥ Î´ m,n (Ï„ ),

(3.3)

with the understanding that the last piece of Î´ m,n (Ï„ ) is ignored if m = 1. If n â‰¥ 2, then
equality holds in (3.3).
Remark. The cases of the maximum correspond to Ï„ âˆˆ [Ï„2 , n1 ], Ï„ âˆˆ [Ï„1 , Ï„2 ], and Ï„ âˆˆ [0, Ï„1 ],
m
m2 âˆ’d
and Ï„2 = n(m+d)
. Note that Ï„1 > 0 if and only if m2 > d.
respectively, where Ï„1 = mn(d+m)
When Ï„1 â‰¤ 0, then the second case of the maximum holds for all Ï„ âˆˆ [0, Ï„2 ].
When n = 1, the inequality (3.3) is strict for some values of Ï„ , as shown by the following theorem:
Theorem 3.9. We have
dimP (Singm,1 (Ï„ )) â‰¥ 1

for all 0 < Ï„ â‰¤

dimP (Singm,1 (Ï„ )) â‰¥ m âˆ’ 1

for all 0 < Ï„ â‰¤

mâˆ’1
,
2m

and

1
.
m2

Remark. To see that Theorem 3.9 implies that the inequality (3.3) in Theorem 3.8 is
strict for some values of Ï„ , note that Î´ m,1 ( mâˆ’1
) = 12 < 1. For m â‰¥ 3, we have
2m
 
1
1
=mâˆ’1âˆ’ 2
< m âˆ’ 1.
Î´ m,1
2
m
m âˆ’mâˆ’1
When m = 2, we instead have

 

1
1
mâˆ’1
=
=
< 1 = m âˆ’ 1.
Î´ m,1
Î´
m,1
m2
2m
2
3.2.1. Trivially singular matrices. Call a matrix A trivially singular if there exists j =
1, . . . , d âˆ’ 1 such that
log Î»j+1(gt uA Zd ) âˆ’ log Î»j (gt uA Zd ) â†’ âˆ as t â†’ âˆ.

14

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Then all of the formulas above in Theorems 3.5-3.9 remain true if Singm,n (Ï‰) is replaced
by the set
def
Singâˆ—m,n (Ï‰) = {A âˆˆ Singm,n (Ï‰) : A is not trivially singular}.
Similarly, the formulas in Theorems 3.1 and 3.4 above and in Theorems 3.10-3.14 below
remain true if we restrict to the respective sets of matrices that are not trivially singular. The reason for this is since while proving lower bounds none of the templates (see
Definition 4.1) we construct are trivially singular.
Moreover, for n â‰¥ 2 we have
dimH (Singâˆ—m,n (âˆ)) = mn âˆ’ 2m

dimP (Singâˆ—m,n (âˆ)) = mn âˆ’ m

and for n = 1, m â‰¥ 2 we have
dimH (Singâˆ—m,n (1)) = 0

dimP (Singâˆ—m,n (1)) = 1.

Note that the class of trivially singular matrices is smaller than the class of matrices
with degenerate trajectories in the sense of [19, Definition 2.8], but larger than the class
considered in [11, p.2] consisting of matrices A such that the group AZn + Zm does not
have full rank. A d Ã— 1 or 1 Ã— d matrix is trivially singular if and only if it is contained in
a rational hyperplane of Rd .

3.3. 1 Ã— 2 and 2 Ã— 1 matrices. Beyond our asympototic formulas stated in the previous section, we obtain precise formulas for the Hausdorff and packing dimensions of
Singm,n (Ï‰) for the cases (m, n) = (1, 2) and (m, n) = (2, 1). Our dimension formulas complete a cornucopia of bounds due to Baker, Bugeaudâ€“Laurent, Laurent, Dodson, Yavid,
Rynne, and Bugeaudâ€“Cheungâ€“Chevallier (1977â€“2016). We refer to [11] for a detailed
history of the prior results.
Theorem 3.10. For all Ï‰ âˆˆ (2, âˆ) (corresponding to Ï„ âˆˆ (0, 1/2)) we have
ï£±
ï£² 4 âˆ’ 4 âˆšÏ„ âˆ’ 6Ï„ 3 + 4Ï„ 4 âˆ’ 2Ï„ + 8 Ï„ 2 if Ï„ â‰¤ Ï„ def
0 =
3
dimH (Sing1,2 (Ï‰)) = 3 3
ï£³ 1âˆ’2Ï„
if Ï„ â‰¥ Ï„0
1+Ï„
ï£±
1
ï£² 4âˆ’8Ï„ if Ï„ â‰¤ Ï„ def
1 = 8
3
dimP (Sing1,2 (Ï‰)) =
ï£³1
if Ï„ â‰¥ Ï„1

(cf. Figure 1).

âˆš
3 2âˆ’2
14

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

15

(0, 34 )
( 81 , 1)

1

f1 (Ï„ ) = dimP (Sing1,2 (Ï‰))
âˆš

(3

0.5

2âˆ’2
,2
14

âˆ’

âˆš

2)

f2 (Ï„ ) = dimH (Sing1,2 (Ï‰))

0

0

0.1

0.2

0.3

0.4

0.5

F IGURE 1. Graphs of the dimension functions
def

def

f1 (Ï„ ) = dimP (Sing1,2 (Ï‰)) and f2 (Ï„ ) = dimH (Sing1,2 (Ï‰)).
The packing dimension function f1 is linear on the intervals [0, 1/8] and
[1/8, 1/2], while the Hausdorff dimension function
f2 is real-analytic on the
âˆš
intervals [0, Ï„0 ] and [Ï„0 , 1/2], where Ï„0 = (3 2 âˆ’ 2)/14 âˆ¼ 0.1602.
Remark. There had been a lot of partial progress towards the Hausdorff dimension part
of Theorem 3.10. In particular, the â‰¥ direction follows from [11, Corollary 2 and Theorem 3]. For Ï„ â‰¥ Ï„0 the upper bound follows from [11, Corollary 2] and for Ï„ < Ï„0 , a
non-optimal upper bound is given in [11, Theorem 1].

Remark. By JarnÄ±Ìkâ€™s identity [37] (see also [31, Theorem A]), for all Ï‰ âˆˆ [2, âˆ) we have
Sing1,2 (Ï‰) = Sing2,1 (Ï‰ â€² )
where Ï‰ â€² = 1 âˆ’

1
Ï‰

, and
Sing1,2 (âˆ) = Sing2,1 (1) âˆª Sing2,1 (âˆ).

Thus by applying an appropriate substitution to the above formulas and using the fact
that Sing2,1 (âˆ) is countable (it is the set of rational points), it is possible to get explicit
formulas for dimH (Sing2,1 (Ï‰ â€² )) and dimP (Sing2,1 (Ï‰ â€²)), either in terms of Ï‰ â€² or in terms of
Ï‰ â€² âˆ’ 21
Ï„
=
Â·
Ï„ = â€²
Ï‰ +1
1 + 2Ï„
â€²

16

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

However, the resulting formulas are not very elegant so we omit them.
âˆš
Remark. The transition point Ï„0 = (3 2 âˆ’ 2)/14 in the above formula for Hausdorff
dimension corresponds to
âˆš
âˆš
âˆš
âˆš
Ï‰0 = 2 + 2 , Ï‰0â€² = 2/2 , Ï„0â€² = (4 âˆ’ 3 2)/2 , and dimH (Sing1,2 (Ï‰0 )) = 2 âˆ’ 2.
The transition point Ï„1 = 1/8 for packing dimension corresponds to
Ï‰1 = 3 , Ï‰1â€² = 2/3 , Ï„1â€² = 1/10 , and dimP (Sing1,2 (Ï‰1 )) = 1.
Remark. Theorem 3.10 implies that dimH (Sing1,2 (Ï‰)) < dimP (Sing1,2 (Ï‰)) for all Ï‰ âˆˆ
(2, âˆ). This answers the first part of [11, Problem 7] in the affirmative.
3.4. Singularity on average. A different way of quantifying the notion of singularity is
the notion of singularity on average introduced in [38]. Given a matrix A, we define the
proportion of time spent near infinity to be the number

1 
def
P(A) = lim lim inf Î» t âˆˆ [0, T ] : Î»1 (gt uA Zd ) â‰¤ Îµ âˆˆ [0, 1],
Îµâ†’0 T â†’âˆ T
where Î» denotes Lebesgue measure. The matrix A is said to be singular on average if
P(A) = 1. Clearly, every singular matrix is singular on average.
Theorem 3.11. For all p âˆˆ [0, 1], we have
dimH ({A : P(A) = p}) = dimP ({A : P(A) = p}) = pÎ´m,n + (1 âˆ’ p)mn.
In particular, the dimension of the set of matrices singular on average is Î´m,n .
Note that the Hausdorff dimension part of this theorem proves the conjecture stated in
[38, Remark 2.1], where the upper bound was proven. However, we give an independent
proof of the upper bound. Also note that when p = 1, the lower bound for Hausdorff
dimension follows from Theorem 3.1.
3.5. Starkovâ€™s conjecture. In [63, p.213], Starkov asked whether there exists a singular
vector (i.e. m Ã— 1 singular matrix) which is not very well approximable. Here, we recall
n
, there exist infinitely
that a matrix A is called very well approximable if for some Ï‰ > m
many pairs (p, q) âˆˆ Zm Ã— Zn such that
(3.4)

kAq + pk â‰¤ kqkâˆ’Ï‰ ,

or equivalently in terms of the Dani correspondence principle, a matrix A is very well
approximable if lim suptâ†’âˆ âˆ’ 1t log Î»1 (gt uA Zd ) > 0. This question was answered affirmatively by Cheung [16, Theorem 1.4] in the case m = 2. In fact, Cheung showed that if

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

17

Ïˆ is any function such that q 1/2 Ïˆ(q) â†’ 0 as q â†’ âˆ, then there exists a 2 Ã— 1 singular
vector which is not Ïˆ-approximable. Here, a matrix A is called Ïˆ-approximable if there
exist infinitely many pairs (p, q) âˆˆ Zm Ã— Zn such that q 6= 0 and
kAq + pk â‰¤ Ïˆ(kqk).
The following theorem improves on Cheungâ€™s result both by generalizing it to the case of
arbitrary m, n (i.e. to the matrix approximation framework), and also by computing the
dimension of the set of matrices with the given property:
Theorem 3.12. If Ïˆ is any function such that q n/m Ïˆ(q) â†’ 0 as q â†’ âˆ, then the set of mÃ—n
singular matrices that are not Ïˆ-approximable has Hausdorff dimension Î´m,n . Equivalently,
if Ï† is any function such that Ï†(t) â†’ âˆ as t â†’ âˆ, then the set of m Ã— n singular matrices A
such that âˆ’ log Î»1 (gt uA Zd ) â‰¤ Ï†(t) for all t sufficiently large has Hausdorff dimension Î´m,n .
The same is true for the packing dimension.
Note that this theorem is optimal in the sense that if Ïˆ(q) â‰¥ cq âˆ’n/m for some constant
c, then it is easy to check that every singular m Ã— n matrix is Ïˆ-approximable.
3.6. Schmidtâ€™s conjecture. In [60, p.273], Schmidt conjectured that for all 2 â‰¤ k â‰¤ m,
there exists an m Ã— 1 matrix A such that
(3.5)

Î»kâˆ’1 (gt uA Zd ) â†’ 0 and Î»k+1(gt uA Zd ) â†’ âˆ as t â†’ âˆ.

This conjecture was proven by Moshchevitin [52], who constructed an m Ã— 1 matrix A
satisfying (3.5) and not contained in any rational hyperplane5 (see also [39, 56]). To
extend this discussion to the matrix framework, we make the following definition.
Definition 3.13. An m Ã— n matrix A is k-singular for 2 â‰¤ k â‰¤ m + n âˆ’ 1 if
(3.6)

Î»kâˆ’1 (gt uA Zd ) â†’ 0 and Î»k+1(gt uA Zd ) â†’ âˆ as t â†’ âˆ.

(Note that any matrix satisfying (3.6) is singular by Theorem 3.2.)
We improve Moshchevitinâ€™s result by computing a lower bound on the Hausdorff dimension of the set of matrices witnessing Schmidtâ€™s conjecture in the matrix framework:
5

As observed by Moshchevitin [52, Corollary 2], proving Schmidtâ€™s conjecture by constructing an m Ã— 1
matrix A satisfying (3.5) which is contained in a rational hyperplane is actually trivial: let A = (x, 0)
where x âˆˆ Rkâˆ’1 or x âˆˆ Rkâˆ’2 is a badly approximable vector. We assume that if Schmidt had noticed this
example, he would have included in his conjecture the requirement that A should not be contained in a
rational hyperplane.

18

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Theorem 3.14. For all (m, n) 6= (1, 1) and for all 2 â‰¤ k â‰¤ m + n âˆ’ 1, the Hausdorff
dimension of the set of matrices A that satisfy (3.6) is at least
max(fm,n (k), fm,n (k âˆ’ 1))
where
(3.7)

k(m + n âˆ’ k)mn
fm,n (k) = mn âˆ’
âˆ’
(m + n)2
def



km
m+n



kn
m+n



Â·

Here {x} denotes the fractional part of a real number x. The same formula is valid for the
set of matrices A that satisfy (3.6) and are not trivially singular.
Remark. The function fm,n satisfies fm,n (m + nâˆ’k) = fm,n (k) and fm,n (1) = fm,n (m + nâˆ’
1) = Î´m,n . Moreover, for all 1 â‰¤ k â‰¤ m + n âˆ’ 1 we have fm,n (k) â‰¤ Î´m,n . It follows that
when k = 2 or m + n âˆ’ 1, the Hausdorff and packing dimensions of the set of matrices A
that satisfy (3.6) are both equal to Î´m,n .
Remark. When m = 1 or n = 1, the fractional parts appearing in (3.7) can be computed
explicitly, leading to the formula
fm,n (k) = mn âˆ’

k(m + n âˆ’ k)
Â·
m+n

However, this formula is not valid when m, n â‰¥ 2.
We conjecture that the lower bound in Theorem 3.14 is optimal for both the Hausdorff
and packing dimensions (see Conjecture 5.1 below).
4. T HE

VARIATIONAL PRINCIPLE

4.1. Successive minima functions and templates. All the theorems in the previous
section (with the exception of Theorems 3.2 and 3.3) are consequences of a single variational principle in the parametric geometry of numbers. This variational principle is a
quantitative analogue of theorems due to Schmidt and Summerer [61, Â§2] and Roy [53,
Theorem 1.3]. However, we will state their results in language somewhat different from
the language used in their papers, due to the fact that the fundamental object we consider is the one-parameter family of unimodular lattices (gt uA Zd )tâ‰¥0 used by the Dani
correspondence principle, rather than a one-parameter family of (non-unimodular) convex bodies as is done in [61, 53]. We leave it to the reader to verify that the theorems
we attribute below to [61] and [53] are indeed faithful translations of their results to our
setting.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

19

The fundamental question of our version of the parametric geometry of numbers will be
as follows: given a matrix A, what does the function h = hA = (h1 , . . . , hd ) : [0, âˆ) â†’ Rd
defined by the formula
def

hi (t) = log Î»i (gt uA Zd )

(4.1)

look like? The function hA will be called the successive minima function of the matrix A.
The Dani correspondence principle shows that many interesting Diophantine questions
about the matrix A are equivalent to questions about its successive minima function.
Thus the dictionary in Â§3.1 may be translated as follows.
Diophantine properties of A Asymptotic properties of hA,1
A is badly approximable

lim sup âˆ’hA,1 (t) < âˆ
tâ†’âˆ

A is singular
A is very well approximable

lim inf âˆ’hA,1 (t) = âˆ
tâ†’âˆ

lim sup
tâ†’âˆ

âˆ’hA,1 (t)
>0
t

The main restriction on the successive minima function comes from an application of
Minkowskiâ€™s second theorem on successive minima (see Theorem 30.1 below) to certain
subgroups of the lattice gt uA Zd . Specifically, fix j = 1, . . . , d âˆ’ 1 and let I be an interval
such that hj (t) < hj+1 (t) for all t âˆˆ I. For each t âˆˆ I, let6
def

Vj,t = hr âˆˆ Zd : kgt uA rk â‰¤ Î»j (gt uA Zd )i âŠ† Rd .
Then the map t 7â†’ Vj,t is continuous, and therefore constant, on I. By Minkowskiâ€™s second
theorem (Theorem 30.1), we have
X
def
hi (t) â‰+ Fj,I (t) = log kgt uA (Vj,t âˆ© Zd )k,
iâ‰¤j

where kÎ“k denotes the covolume of a discrete group Î“ âŠ† Rd (relative to its linear span).
Now an argument based on the exterior product formula for covolume and the definition
of gt (see Lemma 31.8) shows that Fj,I â‰+ Gj,I for some convex, piecewise linear function
Gj,I whose slopes are in the set
o
n
def
(4.2)
Z(j) = Lm+ âˆ’ Lnâˆ’ : LÂ± âˆˆ [0, dÂ± ]Z, L+ + Lâˆ’ = j ,
6

Here, Vj,t is the smallest subspace containing {r âˆˆ Zd : kgt uA rk â‰¤ Î»j (gt uA Zd )}. See Convention 4.

20

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

where for convenience we write
def

d+ = m,

def

def

[a, b]Z = [a, b] âˆ© Z.

dâˆ’ = n,

This suggests that h can be approximated by a piecewise linear function f such that
P
whenever fj < fj+1 on an interval I, the function Fj := iâ‰¤j fi is convex and piecewise
linear on I with slopes in Z(j). Moreover, it is obvious that h1 â‰¤ Â· Â· Â· â‰¤ hd , and the
formula for gt implies that for all i, we have âˆ’ n1 â‰¤ hâ€²i â‰¤ m1 wherever hi is differentiable.
We therefore make the following definition:
Definition 4.1. An m Ã— n template is a piecewise linear7 map f : [0, âˆ) â†’ Rd with the
following properties:
(I) f1 â‰¤ Â· Â· Â· â‰¤ fd .
(II) âˆ’ n1 â‰¤ fiâ€² â‰¤ m1 for all i.
(III) For all j = 0, . . . , d and for every interval I such that fj < fj+1 on I, the function
X
def
Fj =
fi
0<iâ‰¤j

is convex and piecewise linear on I with slopes in Z(j). Here we use the convention that f0 = âˆ’âˆ and fd+1 = +âˆ. We will call the assertion that Fj is convex
the convexity condition, and the assertion that its slopes are in Z(j) the quantized
slope condition.
When m = 1, templates are a slight generalization of reparameterized versions of the
rigid systems of [53]. We denote the space of m Ã— n templates by Tm,n .
A template f will be called balanced if Fd = f1 + . . . + fd = 0. Note that every template
is equal to a constant plus a balanced template, since by condition (III), Fd is piecewise
linear with slopes in Z(d) = {0}, and thus constant. So for most purposes the distinction
between balanced and unbalanced templates is irrelevant, but in some places it will make
a difference. A partial template is a piecewise linear map f satisfying (I)-(III) whose
domain is a closed, possibly infinite, subinterval of [0, âˆ). An example of a (partial)
template is shown in Figure 2.
The fundamental relation between templates and successive minima functions is given
as follows:
Theorem 4.2.

7

(i) For every m Ã— n matrix A, there exists an m Ã— n template f such that hA â‰+ f.
(ii) For every m Ã— n template f, there exists an m Ã— n matrix A such that hA â‰+ f.
In this paper, piecewise linear functions are assumed to be continuous.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

21

F IGURE 2. The joint graph of a 1 Ã— 2 partial template f = (f1 , f2 , f3 ), where
the joint graph of a template is the union of the graphs of its component
functions.

In the case m = 1, Theorem 4.2 follows from [53, Theorem 1.3] (cf. [54, Corollary
4.7] for part (ii)).
Theorem 4.2(ii) asserts that for every template f, the set
def

D(f) = {A : hA â‰+ f}
is nonempty. It is natural to ask how big this set is in terms of Hausdorff and packing
dimension. Moreover, given a collection of templates F , we can ask the same question
about the set
[
def
D(F ) =
D(f).
f âˆˆF

It turns out to be easier to answer the second question than the first, assuming that the
collection of templates F is closed under finite perturbations. Here, F is said to be closed
under finite perturbations if whenever g â‰+ f âˆˆ F , we have g âˆˆ F .
Theorem 4.3 (Variational principle, version 1). Let F be a (Borel) collection of templates
closed under finite perturbations. Then

(4.3)

dimH (D(F )) = sup Î´(f),
f âˆˆF

dimP (D(F )) = sup Î´(f),
f âˆˆF

where the functions Î´, Î´ : Tm,n â†’ [0, mn] are as in Definition 4.5 below.

22

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Corollary 4.4. With F as above, we have
(4.4)

dimH (D(F )) = sup dimH (D(f)),

dimP (D(F )) = sup dimP (D(f)).

f âˆˆF

f âˆˆF

However, note that Theorem 4.3 does not imply that dimH (D(f)) = Î´(f) for an individual template f, since the family {f} is not closed under finite perturbations. And indeed,
since the function Î´ is sensitive to finite perturbations, the formula dimH (D(f)) = Î´(f)
cannot hold for all f âˆˆ Tm,n .
Definition 4.5. We define the lower and upper average contraction rate of a template f
as follows. Let I be an open interval on which f is linear. For each q = 1, . . . , d such that
fq < fq+1 on I, let LÂ± = LÂ± (f, I, q) âˆˆ [0, dÂ± ]Z be chosen to satisfy L+ + Lâˆ’ = q and
(4.5)

Fqâ€²

=

q
X

fiâ€² =

i=1

L+ Lâˆ’
âˆ’
on I,
m
n

as guaranteed by (III) of Definition 4.1. An interval of equality for f on I is an interval
(p, q]Z, where 0 â‰¤ p < q â‰¤ d satisfy
(4.6)

fp < fp+1 = Â· Â· Â· = fq < fq+1 on I.

As before, we use the convention that f0 = âˆ’âˆ and fd+1 = +âˆ. Note that the collection
of intervals of equality forms a partition of [1, d]Z. If (p, q]Z is an interval of equality for f
on I, then we let MÂ± (p, q) = MÂ± (f, I, p, q), where
(4.7)

MÂ± (f, I, p, q) = LÂ± (f, I, q) âˆ’ LÂ± (f, I, p),

or equivalently, MÂ± (p, q) are the unique integers such that
M+ + Mâˆ’ = q âˆ’ p and

q
X

fiâ€² =

i=p+1

M+ Mâˆ’
âˆ’
on I.
m
n

Note that we have MÂ± â‰¥ 0 by (II) of Definition 4.1.8 Next, let
[

(4.8)
p, p + M+ (p, q) Z
S+ = S+ (f, I) =
(p,q]Z

(4.9)

8

Indeed, we have

Sâˆ’ = Sâˆ’ (f, I) =

[

p + M+ (p, q), q

(p,q]Z

q
X
qâˆ’p
qâˆ’p
m+n
fiâ€² â‰¥ âˆ’
M+ âˆ’
=
mn
n
n
i=p+1

on I, and thus M+ â‰¥ 0, and similarly Mâˆ’ â‰¥ 0.



Z

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

23

where the unions are taken over all intervals of equality for f on I. Note that S+ and Sâˆ’
are disjoint and satisfy S+ âˆª Sâˆ’ = [1, d]Z, and that #(S+ ) = m and #(Sâˆ’ ) = n. Next, let
(4.10)

Î´(f, I) = #{(i+ , iâˆ’ ) âˆˆ S+ Ã— Sâˆ’ : i+ < iâˆ’ } âˆˆ [0, mn]Z,

and note that
(4.11)

mn âˆ’ Î´(f, I) = #{(i+ , iâˆ’ ) âˆˆ S+ Ã— Sâˆ’ : i+ > iâˆ’ }.

The lower and upper average contraction rates of f are the numbers
(4.12)

def

def

Î´(f) = lim inf âˆ†(f, T ),

Î´(f) = lim sup âˆ†(f, T ),

T â†’âˆ

T â†’âˆ

where

Ë†
1 T
âˆ†(f, T ) =
Î´(f, t) dt.
T 0
Here we abuse notation by writing Î´(f, t) = Î´(f, I) for all t âˆˆ I. We will also have occasion
later to use the notations
Ë† T2
1
Î´(f, t) dt
âˆ†(f, [T1 , T2 ]) =
T2 âˆ’ T1 T1
def

and
(4.13)

Î´(T+ , Tâˆ’ ) = #{(i+ , iâˆ’ ) âˆˆ T+ Ã— Tâˆ’ : i+ < iâˆ’ } âˆˆ [0, mn]Z.

Note that according to (4.13), Î´(f, I) = Î´(S+ , Sâˆ’ ).
Definition 4.5 can be understood intuitively in terms of a simple version of one-dimensional
physics with sticky collisions and conservation of momentum; cf. Figure 3. Suppose that
we observe particles P1 , . . . , Pd travelling along trajectories f1 , . . . , fd during a time interval I along which f is linear, and we want to infer the velocities of these particles before
they collided, based on the following background information: before the collision m of
the particles were travelling upwards at a speed of m1 , and n of the particles were travelling downwards at a speed of n1 . When particles collide (that is, when the velocities of the
particles of lower index are more upwards than the velocities of the particles of higher
index at the same location), they join forces to move as a unit, and their new velocity
is determined by conservation of momentum. However, we can still think of the group
as being composed of a certain number of â€œupwardsâ€ particles and a certain number of
â€œdownwardsâ€ particles.
The equations (4.8) and (4.9) can be understood as suggesting a particular solution to
this problem of inference: assume that within each group, all of the upwards-travelling
particles started out below all of the downwards-travelling particles. This is not the only

24

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

â†“ â†“
â†‘
l
â†“

â†‘

â†“
â†“

1

1

0

1

2

2

F IGURE 3. The joint graph in Figure 2, with an illustration of the sets
SÂ± (f, I) and the contraction rates Î´(f, I) for each interval of linearity I.
The â€œone-dimensional physicsâ€ interpretation of templates can be seen in
this picture as follows: first one particle is going up while two are going
down; then the top two collide into each other and their new velocity is determined by conservation of momentum; then they split apart again. Given
this interpretation of the motion occurring in I as being the result of â€œcollisionsâ€ between m particles going up and n particles going down, Î´(f, I)
counts the number of particle pairs that are â€œmoving towardsâ€ each other
(including particles â€œcollidingâ€ with each other).
possible solution but it is the nicest one for certain purposes. Specifically, we can imagine
a force of â€œgravityâ€ attempting to bring all of the particles together, which acts between
any two particles by imposing a fixed energy cost if the two particles are travelling away
from each other.9 The total energy cost is then the codimension mn âˆ’ Î´(f, I) defined by
(4.11). The equations (4.8) and (4.9) can then be thought of as giving the solution that
minimizes this cost.
The idea of codimension as an energy cost is also useful for computing the suprema
(4.3) in certain circumstances, since it suggests principles like the conservation of energy.
However, one needs to be careful since the stickiness of collisions means that some naive
formulations of conservation of energy are violated.
In most cases of interest, the collection F in Theorem 4.3 is defined by some Diophantine condition. In this case, generally rather than D(F ) the set we are really interested
9

This is of course unlike real gravity, which imposes an energy cost that varies with respect to distance.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

25

in is the set of all matrices whose corresponding successive minima functions satisfy the
same Diophantine condition. Although these two sets are a priori different, Theorem
4.2(i) implies that they are the same and thus Theorem 4.3 is equivalent modulo Theorem 4.2(i) to the following:
Theorem 4.6 (Variational principle, version 2). Let S be a (Borel) collection of functions
from [0, âˆ) to Rd which is closed under finite perturbations, and let
def

D(S) = {A : hA âˆˆ S}.

(4.14)
Then
(4.15)

dimH (D(S)) =

sup

Î´(f),

f âˆˆSâˆ©Tm,n

dimP (D(S)) =

sup

Î´(f)

f âˆˆSâˆ©Tm,n

with the understanding that dimH () = dimP () = sup() = âˆ’âˆ (or 0 if desired).
In fact, Theorem 4.6 will be the version of the variational principle that we prove.
Proof of equivalence. Theorem 4.6 implies Theorem 4.3 since we can take S = {g : g â‰+
f âˆˆ F }. Conversely, Theorem 4.3 implies Theorem 4.6 modulo Theorem 4.2(i) since we
can take F = S âˆ© Tm,n .

Theorem 4.6 can be thought of as a quantitative strengthening of Theorem 4.2, as
shown by the following equivalent formulation:
Theorem 4.7 (Variational principle, version 3).
(i) Let S be a (Borel) set of m Ã— n matrices of Hausdorff (resp. packing) dimension > Î´.
Then there exist a matrix A âˆˆ S and a template f â‰+ hA whose lower (resp. upper)
average contraction rate is > Î´.
(ii) Let f be a template whose lower (resp. upper) average contraction rate is > Î´. Then
there exists a (Borel) set S of m Ã— n matrices of Hausdorff (resp. packing) dimension
> Î´, such that hA â‰+ f for all A âˆˆ S.
Proof of equivalence. Part (i) is equivalent to the â‰¤ direction of (4.15), and part (ii) to the
â‰¥ direction. For the first equivalence, for the forwards direction take S = {A : hA âˆˆ S},
and for the backwards direction take S = {g : g â‰+ hA , A âˆˆ S}. For the second
equivalence, for the backwards direction take S = D(f) and S = {g : g â‰+ f}.

It is worth stating the special case of Theorem 4.6 that occurs when the collection S
is defined by the Diophantine conditions defining Singm,n (Ï‰) and Singâˆ—m,n (Ï‰) for some
n
Ï‰â‰¥ m
. Thus, we define the uniform dynamical exponent of a map f : [0, âˆ) â†’ Rd to be

26

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

the number

âˆ’1
f1 (t).
tâ†’âˆ
t
Moreover, f is said to be trivially singular if fj+1 (t) âˆ’ fj (t) â†’ âˆ as t â†’ âˆ for some
j = 1, . . . , d âˆ’ 1. Letting S = {f : Ï„b(f) = Ï„ } or S = {f : Ï„b(f) = Ï„, f not trivially singular}
in Theorem 4.6 yields the following result:
def

Ï„b(f) = lim inf

Theorem 4.8 (Special case of variational principle). For all Ï‰ â‰¥

n
,
m

we have

dimH (Singm,n (Ï‰)) = sup{Î´(f) : f âˆˆ Tm,n , Ï„b(f) = Ï„ }
dimP (Singm,n (Ï‰)) = sup{Î´(f) : f âˆˆ Tm,n , Ï„b(f) = Ï„ }

dimH (Singâˆ—m,n (Ï‰)) = sup{Î´(f) : f âˆˆ Tm,n , Ï„b(f) = Ï„, f not trivially singular}
dimP (Singâˆ—m,n (Ï‰)) = sup{Î´(f) : f âˆˆ Tm,n , Ï„b(f) = Ï„, f not trivially singular}

where Ï„ is as in (3.1).
Theorem 4.6 can also be used to compute the dimensions of the set
[
g âˆ— (Ï‰) def
Singâˆ—m,n (Ï‰ â€² ).
=
{A
:
Ï‰
b
(A)
â‰¥
Ï‰,
A
not
trivially
singular}
=
Sing
m,n
Ï‰ â€² â‰¥Ï‰

Theorem 4.9 (Special case of variational principle). For all Ï‰ â‰¥

n
,
m

we have

g âˆ— (Ï‰)) = sup dimH (Singâˆ— (Ï‰ â€²))
dimH (Sing
m,n
m,n
Ï‰ â€² â‰¥Ï‰

g âˆ— (Ï‰)) = sup dimP (Singâˆ— (Ï‰ â€² )).
dimP (Sing
m,n
m,n
Ï‰ â€² â‰¥Ï‰

(Theorem 4.9 is also true with the stars removed, but in that case it is not as interesting
because dimH (Singm,n (âˆ)) is â€œtoo largeâ€, whereas dimH (Singâˆ—m,n (âˆ)) is the â€œcorrectâ€ size
according to Â§3.2.1.)
It is natural to expect that the map Ï‰ 7â†’ dimH (Singâˆ—m,n (Ï‰)) is monotonically decreasing,
in which case Theorem 4.9 would imply that
âˆ—

âˆ—
g
dimH (Sing
m,n (Ï‰)) = dimH (Singm,n (Ï‰)).

4.2. New proofs of old results. In addition to our new results, our techniques now provide a uniform framework to prove classical results in metric Diophantine approximation.
The following result was proven in the one-dimensional setting by JarnÄ±Ìk (1928) and in
the matrix setting by Schmidt (1969).
Theorem 4.10 (JarnÄ±Ìkâ€“Schmidt, [35, 58]). The Hausdorff dimension of the set of badly
approximable matrices is mn.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

Recall that for each Ï‰ >

n
,
m

27

we say that a matrix A is Ï‰-approximable if

lim sup sup
|q|â†’âˆ pâˆˆZm

âˆ’ log kAq âˆ’ pk
â‰¥ Ï‰.
log kqk

It follows from the Dani correspondence principle that A is Ï‰-approximable if and only if
lim sup
tâ†’âˆ

âˆ’hA,1 (t)
â‰¥Ï„
t

where Ï„ is as in (3.1).
The following theorem was proven in the one-dimensional case independently by
JarnÄ±Ìk (1929) and Besicovitch (1934), and in the matrix case by Bovey and Dodson
(1986).
Theorem 4.11 (JarnÄ±Ìkâ€“Besicovitchâ€“Boveyâ€“Dodson, [36, 6, 8]). The Hausdorff dimension
of the set of Ï‰-approximable matrices is mn(1 âˆ’ Ï„ ). In particular, the Hausdorff dimension
of the very well approximable matrices is mn.
We provide proofs of these theorems in Sections 25 and 26 respectively.
5. D IRECTIONS

TO FURTHER RESEARCH

We conclude our introduction with a small sample of problems and research directions,
which we hope will illustrate the wide scope awaiting future exploration.
5.1. Exact Hausdorff and packing dimensions. Determine whether an appropriate
gauge function exists with respect to which the Hausdorff measure of the singular matrices have positive and finite measure. The same question for packing measures is also
open. It would be natural to expect that the Î´m,n -dimensional Hausdorff measure of
Sing(m, n) is zero, and that the Î´m,n -dimensional packing measure of Sing(m, n) is infinite. In general, determining exact dimensions for any of the sets we have studied in this
paper would be an interesting challenge.
5.2. Quantitative Schmidtâ€™s conjecture. We conjecture that the inequality in Theorem
3.14 is actually an equality:
Conjecture 5.1. For 2 â‰¤ k â‰¤ m + n âˆ’ 1, the Hausdorff and packing dimensions of the set
of k-singular m Ã— n matrices (see Definition 3.13) are both equal to
max(fm,n (k), fm,n (k âˆ’ 1)), where
kmn
fm,n (k) = mn âˆ’
m+n
def


1âˆ’

k
m+n



âˆ’



km
m+n



kn
m+n



Â·

28

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Here, {x} denotes the fractional part of a real number x.
Remark 5.2. When k = 2 or m + n âˆ’ 1, the Hausdorff and packing dimensions of the set
of k-singular matrices are both equal to Î´m,n .
5.3. Regularity of dimension functionals.
Problem 5.3. Determine when/whether the functions
Ï‰ 7â†’ dimH (Singm,n (Ï‰)),

Ï‰ 7â†’ dimP (Singm,n (Ï‰))

are decreasing and continuous.
Although it is natural to suspect that these functions are in fact decreasing and continuous for all (m, n) 6= (1, 1), Theorem 3.9 seems to suggest otherwise: it suggests that
the function Ï„ 7â†’ dimP (Singm,1 (Ï„ )) may have a discontinuity at Ï„ = 1/m2 for all m â‰¥ 3.
Indeed, the proof of Theorem 3.9 gives us no reason to suspect that the inequality is strict
in Theorem 3.8 for Ï„ slightly greater than 1/m2 . If in fact equality holds for such Ï„ , then
there is a discontinuity! If this were the case, it would show that the conjecture we made
in the announcement of this paper [21, Conjecture 2.10] was too optimistic.
5.4. Intersecting standard and uniform exponent level sets. Let Ï‰(A) and Ï‰
b (A) denote the standard and uniform exponents of irrationality of a matrix A, respectively:
def

Ï‰
b (A) = lim inf
Qâ†’âˆ

def

Ï‰(A) = lim sup
Qâ†’âˆ

sup

sup

0<kqkâ‰¤Q

p

sup

sup

0<kqkâ‰¤Q

p

âˆ’ log kAq + pk
log Q

âˆ’ log kAq + pk
log Q

The Hausdorff dimensions of the levelsets of Ï‰ are well-known, and we have provided
many results on the Hausdorff dimensions of the levelsets of Ï‰
b . However, it is natural to
ask about the dimension of the intersection of two such sets:
Question 5.4. What is the behavior of the function

(Ï‰, Ï‰
b ) 7â†’ dimH ({A : Ï‰(A) = Ï‰, Ï‰
b (A) = Ï‰
b })?

5.5. Precise dimension formulas for uniform exponent level sets. As mentioned previously, it is very challenging to obtain precise formulas for the Hausdorff and packing
dimensions of Singm,n (Ï‰) = {A : Ï‰
b (A) = Ï‰} in terms of Ï‰, m, and n. Though we
have completely solved (see Theorems 3.8 and 3.10 for details) this problem in the cases
(m, n) = (1, 2) and (m, n) = (2, 1), and for packing dimension in the case where n â‰¥ 2, it
is plausible that finding a closed form expression in all scenarios is hopeless. To express

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

29

the limit of our current understanding, note that we do not have conjectural formulas for
Hausdorff dimension even for the cases when (m, n) âˆˆ {(1, 3), (3, 1), (2, 2)} at present.
5.6. Metric theory for Îµ-Dirichlet improvable matrices. Given 0 < Îµ < 1, an m Ã— n
matrix A is called Îµ-Dirichlet improvable (see [22]) if for all sufficiently large Q, there
exists (p, q) âˆˆ Zm+n such that
kAq âˆ’ pk â‰¤ ÎµQâˆ’n/m and 0 < kqk < Q.
An mÃ—n matrix A is Dirichlet improvable if it is Îµ-Dirichlet improvable for some 0 < Îµ < 1.
Singular matrices are Îµ-Dirichlet improvable for all 0 < Îµ < 1.
Question 5.5. How do the Hausdorff and packing dimensions of the set of Îµ-Dirichlet
improvable m Ã— n matrices vary as functions of Îµ? It would already be interesting just to
give estimates on these dimensions, if not precisely determine them.
5.7. Weighted singular matrices and general diagonal flows. In the parametric geometry of numbers and the Dani correspondence principle we are generally concerned
with the (gt ) flow as defined in Â§3.1. What happens if the (gt ) flow is replaced by some
other diagonal flow (ht ), for example
ht = diag(ea1 t , . . . , eam t , eâˆ’b1 t , . . . , eâˆ’bn t ) âˆˆ SLm+n (R)
where a1 , . . . , am , b1 , . . . , bn are positive real numbers? For example, is it possible to compute the Hausdorff and packing dimensions of the set of m Ã— n matrices A such that
the trajectory (ht uA Zm+n )tâ‰¥0 is divergent as a function of a1 , . . . , am , b1 , . . . , bn ? When
m = 2 and n = 1, this question in case of the Hausdorff dimension has been addressed by
Liao, Shi, Solan, and Tamam [47]. Without obtaining dimension formulas, Guan and Shi
proved that the Hausdorff dimension of the set of divergent-on-average trajectories for a
one-parameter subgroup action on a finite-volume homogeneous space is not full, [32].
5.8. Inhomogeneous Diophantine approximation. Our results fall within the domain
of homogeneous Diophantine approximation. It would be of interest to investigate analogues of our results in the frameworks of inhomogeneous approximation, see [12, 13,
46]. In this setting, given an m Ã— n matrix A and x âˆˆ Rm , the pair (A, x) is called singular
if for all Îµ > 0, there exists QÎµ such that for all Q â‰¥ QÎµ , there exist integer vectors p âˆˆ Zm
and q âˆˆ Zn such that
kAq + p + xk â‰¤ ÎµQâˆ’n/m

and

0 < kqk â‰¤ Q.

30

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

It is also natural to study the inhomogeneous approximation frameworks where we fix
one coordinate of the pair (A, x) and let the other vary. Extending our variational principle (Theorem 4.6) and its corollaries to such inhomogeneous frameworks would be a
natural next step. When m = n = 1, this question in case of the Hausdorff dimension has
been recently investigated by Kim and Liao [43].

5.9. Parametric geometry of numbers in arbitrary characteristic. It would be of interest to develop the technology introduced in this work to study questions of Diophantine
approximation in the function field setting, see Roy and Waldschmidt [55].

6. A CKNOWLEDGEMENTS
This research began on 28th November 2016 when the authors met at the American
Institute of Mathematics in San Jose, California, via their SQuaRE program. We thank
the institute and their staff for their hospitality and excellent working conditions. In
particular, we thank Estelle Basor for her singular encouragement and support. The
first-named author was supported in part by a 2017-2018 Faculty Research Grant from
the University of Wisconsin-La Crosse. The second-named author was supported in part
by the Simons Foundation grant #245708. The third-named author was supported in
part by the EPSRC Programme Grant EP/J018260/1, and is currently supported by a
Royal Society University Research Fellowship. The fourth-named author was supported
in part by the NSF grant DMS-1361677. We thank Pieter Allaart, ValeÌrie BertheÌ, Nicolas
Chevallier, Elon Lindenstrauss, Seonhee Lim, Antoine Marnat, Damien Roy, Johannes
Schleischitz and Hao Xing for helpful comments and clarifying questions. In particular,
we thank Damien Roy for his meticulous reading and criticism, as well as for pointing out
several translations between the notation in his papers and those of Schmidtâ€“Summerer
and ours. This eventually led to the inclusion of Appendix A. We also thank Lingmin
Liao for their punctilious reading and several discussions that greatly helped improve
the exposition. Finally, we thank an anonymous referee for their extremely scrupulous
report, which helped us improve several points throughout the paper, and pushed us to
clarify many facts that were previously â€œtacitly assumed and never spelled outâ€. The
quest of refereeing a long and at times necessarily arduous paper is largely a thankless
endeavor for which we are greatly appreciative.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

31

Part 2. Proof of main theorems using the variational principle
7. L EITFADEN

TO

PART 2

In this part we prove all the theorems of Section 3 (with the exception of Theorems
3.2 and 3.3) as well as Theorem 4.2 from Section 4, making full use of the variational
principle that has been proven in Part 4.
For reference, the following theorems are proven in the following subsections:
â€¢ Theorems 3.1 and 3.4 are proved in Â§8 and Â§9.
To prove Theorems 3.1 and 3.4 it suffices10 to show that
(7.1)

dimP (Sing(m, n)) â‰¤ Î´m,n ,

(7.2)

dimH (VSing(m, n)) â‰¥ Î´m,n .
We prove these inequalities first (in Â§8 and Â§9 respectively), since their proofs
provide the best basic illustration of our techniques.
â€¢ Theorem 3.8 is proven in Â§13 and Â§12.
The packing dimension upper bound (valid for n â‰¥ 2) is proven in Â§13. The
packing dimension lower bound is proven in Â§12.
â€¢ Theorem 3.9 is proven in Â§14.

â€¢ Theorem 3.5 is proven in Â§8, Â§9, Â§10, Â§11, and Â§12.
In Â§8, after proving (7.1), we obtain the upper bound for packing dimension in
Theorem 3.5. The packing dimension lower bound in Theorem 3.8 (proven in
Â§12) implies the packing dimension lower bound in Theorem 3.5. This completes
the proof for the packing dimension asymptotic formula. Regarding the Hausdorff
dimension, there are two asymptotic formulas that have to be proved. For the first
case of Theorem 3.5: the lower bound for Hausdorff dimension is obtained in
Â§9, after proving (7.2); and the upper bound for Hausdorff dimension is proven
in Â§10. For the second case of Theorem 3.5: the lower bound for Hausdorff
dimension is proven in Â§11; and the upper bound for Hausdorff dimension follows
from that for packing dimension (proven in Â§8).
â€¢ Theorem 3.6 is proven in Â§13 Â§12, Â§15, and Â§17.
Theorem 3.8 (proven in Â§13 and Â§12) implies the packing dimension formula in
Theorem 3.6. The upper and lower bounds for the Hausdorff dimension formula
in Theorem 3.6 are proven in Â§15 and Â§17, respectively.
10

This follows from the monotonicity of the Hausdorff and packing dimensions, and the fact that the latter
is bounded below by the former (see Section 27).

32

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

â€¢ Theorem 3.7 is proven in Â§14,Â§16, Â§18, and Â§19 .
The packing dimension upper bound in Theorem 3.7 is proven in Â§19. The packing dimension lower bound is implied by Theorem 3.9 (proven in Â§14). The
lower and upper bounds for the Hausdorff dimension formula in Theorem 3.7
are proven in Â§16 and Â§18, respectively.
â€¢ Theorem 3.10 is proven in Â§20.
â€¢ Theorem 3.11 is proven in Â§21.
â€¢ Theorem 3.12 is proven in Â§22.
â€¢ Theorem 3.14 is proven in Â§23.
â€¢ Theorem 4.2 is proven in Â§24.
8. P ROOF

OF

(7.1) + T HEOREM 3.5,

UPPER BOUND FOR PACKING DIMENSION

In some sense, the variational principle means that it is harder to prove upper bounds
on dimension than lower bounds: for a lower bound one only needs to exhibit a template
or sequence of templates with the appropriate dimension properties, while for an upper
bound one needs to prove something about all possible templates. This is in contrast to
the usual situation in which it is easier to prove upper bounds. Our technique for proving
upper bounds is based on continuing the analogy with physics (cf. Figure 3 and the three
paragraphs following Definition 4.5) by defining a function that measures the â€œpotential
energyâ€ of any configuration of particles: the potential energy is larger the farther apart
the particles are. We then prove an inequality relating the change in potential energy and
the contraction rate. Integrating this inequality gives a relation between the potential
energy at a given point in time, which is always positive, and the average contraction
rate up to that time. This then yields a bound on the average contraction rate up to any
point in time.
Let f : [0, âˆ) â†’ Rd be a balanced11 template (cf. Definition 4.5). We define the
â€œpotential energy of f at time tâ€ to be the number

 2
mn2
mn
|f1 (t)|,
|fd (t)| .
(8.1)
Ï†(t) = Ï†f (t) = max
m+n
m+n
Note that Ï†(t) â‰¥ 0 for all t â‰¥ 0. The motivation for the definition of Ï† is the following
lemma:

11

Since any template can be written as a translation of a balanced template, we can without loss of generality consider only balanced templates in what follows.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

33

Lemma 8.1. Let I be an interval of linearity12 for f such that Ï†â€² (t) is well-defined for all
t âˆˆ I, and such that f(t) 6= 0 for all t âˆˆ I. Then
Ï†â€² (t) â‰¤ Î´m,n âˆ’ Î´(f, I)

(8.2)

for t âˆˆ I. Equality holds in precisely the following cases:
1. S+ (f, I) = {1, . . . , m};
2. S+ (f, I) = {1, . . . , m âˆ’ 1, m + 1}, and f1 = . . . = fm and fm+1 = . . . = fm+n on I
(and in particular since f is balanced we have m|f1 | = n|fd | on I);
3a. S+ (f, I) = {2, . . . , m + 1}, and m|f1 | â‰¥ n|fd | on I;
3b. S+ (f, I) = {1, . . . , m âˆ’ 1, m + n}, and n|fd | â‰¥ m|f1 | on I.
If equality does not hold, then the difference between the two sides of (8.2) is at least
1/ max(m, n).
Note that when m = 1, cases 2 and 3a are equivalent, and when n = 1, cases 2 and 3b
are equivalent.
Proof. Note that the cases 3a and 3b are symmetric with respect to the operation of
replacing the m Ã— n template f by the n Ã— m template âˆ’f, while the other two cases
are individually symmetric with respect to this operation. Thus, we may without loss of
generality suppose that
(8.3)

Ï†=

m2 n
|f1 |
m+n

i.e.

m|f1 | â‰¥ n|fd |

on I. Let j â‰¥ 1 be the largest number such that
fj = f1 on I.
Note that since f is balanced and f(t) 6= 0 for all t âˆˆ I, (8.3) implies that j â‰¤ m.
Since I is an interval of linearity for f, it follows that fj < fj+1 on I. Accordingly, let
LÂ± = LÂ± (f, I, j) and SÂ± = SÂ± (f, I). Then by (8.3) and (4.5) we have


m2 n âˆ’Fjâ€² (t)
Lâˆ’ L+
m2 n
â€²
Ï† (t) =
=
âˆ’
m+n j
(m + n)j n
m
and on the other hand, by (4.11) we have
(8.4)
12



mn âˆ’ Î´(f, I) â‰¥ # Sâˆ’ âˆ© (0, j] Â· # S+ âˆ© (j, d] = Lâˆ’ (m âˆ’ L+ )

I.e. an interval on which f is linear. If I is an interval of linearity for f , we will denote the constant value
of f â€² on I by f â€² (I).

34

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

and thus
Î´m,n âˆ’ Î´(f, I) â‰¥ Lâˆ’ (m âˆ’ L+ ) âˆ’

mn
Â·
m+n

So to demonstrate (8.2) it suffices to show that


m2 n
Lâˆ’ L+
mn
â‰¤ Lâˆ’ (m âˆ’ L+ ) âˆ’
âˆ’
Â·
(m + n)j n
m
m+n
Indeed, since L+ + Lâˆ’ = j, we have


 


m2 n
m2 n
j
Lâˆ’ m
Lâˆ’ L+
1
1
mn
=
Lâˆ’
âˆ’
=
âˆ’
+
âˆ’
(m + n)j n
m
(m + n)j
m n
m
j
m+n
so we need to show that
(8.5)

Lâˆ’ m
â‰¤ Lâˆ’ (m âˆ’ L+ ).
j

If Lâˆ’ = 0, then this inequality is trivial (and equality holds). So suppose that Lâˆ’ > 0.
Since j = Lâˆ’ + L+ â‰¤ m, we have L+ < j â‰¤ m, so (j âˆ’ 1)(m âˆ’ L+ âˆ’ 1) â‰¥ 0, and thus
(8.6)

m â‰¤ j + (m âˆ’ L+ ) âˆ’ 1 â‰¤ j(m âˆ’ L+ ),

and rearranging yields (8.5). This completes the proof of (8.2).
Now suppose that equality holds in (8.2). The equality in (8.4) implies that
S+ = {1, . . . , L+ } âˆª {j + 1, . . . , j + m âˆ’ L+ }.
On the other hand, the equality in (8.5) implies that either Lâˆ’ = 0, or equality holds in
(8.6). In the latter case we have Lâˆ’ = j âˆ’ L+ = 1, and either j = 1 or m âˆ’ L+ = 1, from
the left and right hand sides of (8.6), respectively. So there are three cases:
1. If Lâˆ’ = 0, then S+ = {1, . . . , m}.
2. If Lâˆ’ = 1 and m âˆ’ L+ = 1, then S+ = {1, . . . , m âˆ’ 1, m + 1}. In this case j = m, i.e.
f1 = . . . = fm on I. Combining with (8.3) and using the fact that f is balanced
shows that fm+1 = . . . = fm+n on I.
3a. If Lâˆ’ = 1 and j = 1, then S+ = {2, . . . , m + 1}.
Note that the case 3b does not appear in this list due to the fact that we made the
assumption (8.3) without loss of generality, using the fact that 3a and 3b are symmetric.
The converse direction can be proved similarly.
Finally, suppose that equality does not hold in (8.2). Note that the difference between
the two sides of (8.2) is the sum of the difference between the two sides of (8.4) and
those of (8.5), i.e. mn âˆ’ Î´(f, I) âˆ’ Lâˆ’ m/j. Since this is a positive rational number with
denominator j, it must be â‰¥ 1/j â‰¥ 1/ max(m, n).


A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

35

Now suppose that the template f is singular, i.e. satisfies f1 (t) â†’ âˆ’âˆ as t â†’ âˆ. Then
f(t) 6= 0 for all sufficiently large t. So by Lemma 8.1, (8.2) holds for almost all sufficiently
large t, and thus for all sufficiently large T we have
Ë† T
0 .+ Ï†(T ) âˆ’ Ï†(0) .+
[Î´m,n âˆ’ Î´(f, t)] dt = T [Î´m,n âˆ’ âˆ†(f, T )].
0

It follows that



Ï†(T )
Ï†(T )
= Î´m,n âˆ’ lim inf
â‰¤ Î´m,n ,
Î´(f) = lim sup âˆ†(f, T ) â‰¤ lim sup Î´m,n + O(1/T ) âˆ’
T â†’âˆ
T
T
T â†’âˆ
T â†’âˆ

and applying Theorem 4.6 to the set
S = {f : [0, âˆ) â†’ Rd | f1 (t) â†’ âˆ’âˆ as t â†’ âˆ}
yields (7.1). Note that if f is Ï„ -singular, i.e. |f1 (t)| â‰¥ Ï„ t for all sufficiently large t, then
Ï†(T ) â‰¥

m2 n
Ï„T
m+n

for all sufficiently large T , and thus
Î´(f) â‰¤ Î´m,n âˆ’

m2 n
Ï„.
m+n

Applying Theorem 4.8 yields the upper bound of the packing dimension assertion of
Theorem 3.5.
9. P ROOF

OF

(7.2) + T HEOREM 3.5,

FIRST FORMULA , LOWER BOUND FOR

H AUSDORFF

DIMENSION

Lemma 8.1 provides motivation for how to construct a template yielding the lower
bound (7.2). Namely, the template f should be constructed in a way such that most of
the time, one of the four cases for the possible value of S+ (f, I) listed in Lemma 8.1
holds. For example, there may be two consecutive intervals of linearity I1 and I2 such
that S+ (f, I1 ) = {2, . . . , m + 1} and S+ (f, I2 ) = {1, . . . , m}; cf. Figure 4.
In contrast to the picture in Figure 4, if we want the template f to be singular then
we need f(t) 6= 0 for all t, so we will need to â€œcut offâ€ a small part of the picture. By
â€œgluingâ€ infinitely many of these pictures together we will get a singular template of large
Hausdorff dimension; cf. Figure 5.
To make the idea conveyed in Figure 5 rigorous, we introduce the notion of the
standard template defined by two points (tk , âˆ’Îµk ) and (tk+1 , âˆ’Îµk+1 ). The idea is that
f : [tk , tk+1] â†’ Rd should satisfy f1 (ti ) = f2 (ti ) = âˆ’Îµi for i = k, k + 1, and f1 should be as
small as possible given this restriction. Finally, the template should be chosen so that fd

36

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

t0

t1

t2

Î´(f, Ii )

mn âˆ’ m

mn

|Ii |/|I|

n
m+n

m
m+n

F IGURE 4. The joint graph of a partial template f such that S+ (f, I1 ) =
{2, . . . , m + 1} and S+ (f, I2 ) = {1, . . . , m}, where I1 = (t0 , t1 ) and I2 =
n
(t1 , t2 ). In this picture we have f(t0 ) = f(t2 ) = 0, and thus |I1 | = m+n
|I| and
m
|I2 | = m+n |I|, where I = (t0 , t2 ). Consequently,
Ë†
n
m
1
Î´(f, t) dt =
(mn âˆ’ m) +
(mn) = Î´m,n
|I| I
m+n
m+n
i.e. the average contraction rate of f over I is Î´m,n . Note that this partial
template is exactly the standard template defined by the points (t0 , 0) and
(t2 , 0) (cf. Definition 9.1).

F IGURE 5. The joint graph of a template f designed to be a singular template of large Hausdorff dimension. The gray regions represent intervals
where the precise value of the template is irrelevant; what matters is that
the template stays away from 0 on these regions.
is as small as possible, given the previous restrictions. Formally we make the following
definition:
Definition 9.1. Fix 0 â‰¤ tk < tk+1 and Îµk , Îµk+1 â‰¥ 0 and let âˆ†t = âˆ†tk = tk+1 âˆ’ tk and
âˆ†Îµ = âˆ†Îµk = Îµk+1 âˆ’ Îµk . Assume that the following formulas hold:
(9.1)

âˆ’

1
âˆ†t
m

â‰¤ âˆ†Îµ â‰¤ n1 âˆ†t,

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

(9.2)
(9.3)

âˆ†t if m = 1 and âˆ†Îµ â‰¤
âˆ†Îµ â‰¥ âˆ’ nâˆ’1
2n
either (n âˆ’ 1)

1
âˆ†t
n

mâˆ’1
âˆ†t
2m


âˆ’ âˆ†Îµ â‰¥ dÎµk or (m âˆ’ 1)

37

if n = 1,

1
âˆ†t
m


+ âˆ†Îµ â‰¥ dÎµk+1 .

Then the standard template defined by the two points (tk , âˆ’Îµk ) and (tk+1 , âˆ’Îµk+1) is the
partial template f : [tk , tk+1 ] â†’ Rd defined as follows:

â€¢ Let g1 , g2 : [tk , tk+1 ] â†’ R be piecewise linear functions such that gi (tj ) = âˆ’Îµj ,
and gi has two intervals of linearity: one on which giâ€² = m1 and another on which
giâ€² = âˆ’ n1 . For i = 1 the latter interval comes first while for i = 2 the former
interval comes first; cf. Figure 6. The existence of such functions g1 and g2 is
guaranteed by (9.1). Finally, let g3 = . . . = gd be chosen so that g1 + . . . + gd = 0.
â€¢ For each t âˆˆ [tk , tk+1 ] let f(t) = g(t) if g2 (t) â‰¤ g3 (t); otherwise let f1 (t) = g1 (t) and
let f2 (t) = . . . = fd (t) be chosen so that f1 + . . . + fd = 0.

We will sometimes denote the standard template defined by (tk , âˆ’Îµk ) and (tk+1 , âˆ’Îµk+1 )
by s[(tk , âˆ’Îµk ), (tk+1 , âˆ’Îµk+1 )].

(t1 , âˆ’Îµ1 )

(t2 , âˆ’Îµ2 )

F IGURE 6. The joint graphs of f and g on the interval [t1 , t2 ], where f is the
standard template s[(t1 , âˆ’Îµ1 ), (t2 , âˆ’Îµ2 )] as in Definition 9.1. The map g is
shown dotted while f is shown solid.
Lemma 9.2. A standard template is indeed a balanced partial template.
Proof. We show where the formulas (9.2) and (9.3) are needed, leaving the rest of the
proof as an exercise to the reader. The condition (9.3) is equivalent to the assertion that
g2 (t) â‰¥ g3 (t) where t is the location of the maximum of g2 . This implies that f2 (t) =
f3 (t), guaranteeing that the convexity condition (cf. Definition 4.1) is satisfied at t. The
condition (9.2) is equivalent to the assertion that there is no interval on which f1â€² = f2â€² =
Â±1. If such an interval exists, then f cannot be a template because if it were, we would
have {1, 2} âŠ† SÂ± but #(SÂ± ) = dÂ± = 1, a contradiction. Conversely, if there is no such

38

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

interval then the sets SÂ± can be computed in a consistent way on any interval of linearity
for f.

Example 9.3. The inequalities (9.1)-(9.3) always hold when Îµk = Îµk+1 = 0. In this case,
the standard template f defined by the points (tk , 0) and (tk+1 , 0) has only two intervals
of linearity, and the average value of Î´(f, Â·) on [tk , tk+1 ] is equal to Î´m,n ; see Figure 4.
Definition 9.4. Let (tk )âˆ
0 be an increasing sequence of nonnegative real numbers, and
let Îµk â‰¥ 0 for each k. The standard template defined by the sequence of points (tk , âˆ’Îµk ) is
the partial template produced by gluing together the standard templates defined by the
pairs of points (tk , âˆ’Îµk ) and (tk+1 , âˆ’Îµk+1 ) for each k. The standard template defined by
two parameters Ï„ â‰¥ 0 and Î» > 1, denoted f[Ï„, Î»], is the one defined by the sequence of
points (tk , Îµk )kâˆˆZ, where tk = Î»k and Îµk = Ï„ tk for all k. Note that in this case, (9.1)-(9.3)
become
Ï„ â‰¤ n1 ,

(9.4)
Ï„â‰¤

(9.5)
(9.6)

either (n âˆ’ 1)

1
n


âˆ’Ï„ â‰¥

mâˆ’1
2m

if n = 1,

1
dÏ„
Î»âˆ’1

or (m âˆ’ 1)

1
m


+Ï„ â‰¥

Î»
dÏ„.
Î»âˆ’1

We refer to f[Ï„, Î»] as being exponentially Î»-equivariant, viz. that f(Î»t) = Î»f(t) for all t â‰¥ 0.
âˆš
âˆš
Now fix Ï„ > 0 small and let Î» = 1 + Ï„ (or more generally Î» = 1 + Î˜( Ï„ )), and
note that (9.4)-(9.6) hold. Let f = f[Ï„, Î»] and tk , Îµk be as above. Now since the map
(Îµ1 , Îµ2 ) 7â†’ âˆ†(s[(0, âˆ’Îµ1 ), (1, âˆ’Îµ2 )], 1) is Lipschitz continuous, it follows that
âˆ†(f, [tk , tk+1 ]) = âˆ†(s[(tk , âˆ’Îµk ), (tk+1, âˆ’Îµk+1 )], [tk , tk+1])
 h
 
i 
Îµk+1
Îµk
= âˆ† s 0, âˆ’ âˆ†t
,
1,
âˆ’
,1
âˆ†tk
k


= âˆ†(s[(0, 0), (1, 0)], 1) âˆ’ O max(Îµâˆ†tk ,Îµk k+1 )

âˆš
Ï„
= Î´m,n âˆ’ O Î»âˆ’1
= Î´m,n âˆ’ O( Ï„ )

and thus for sufficiently large k

âˆš
âˆ†(f, tk ) = Î´m,n âˆ’ O( Ï„ ).
Given T large, let k be chosen so that tk â‰¤ T < tk+1 . Then


âˆš
k
= O(Î» âˆ’ 1) = O( Ï„ )
âˆ†(f, T ) âˆ’ âˆ†(f, tk ) = O T âˆ’t
tk

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

and thus

39

âˆš
âˆ†(f, T ) = Î´m,n âˆ’ O( Ï„ ).

Taking the limit as T â†’ âˆ shows that

âˆš
dimH (Singm,n (Ï„ )) â‰¥ Î´(f) = Î´m,n âˆ’ O( Ï„ ),

and taking the limit as Ï„ â†’ 0 completes the proof of (7.2), as well as of the lower bound
for Hausdorff dimension in the first case of Theorem 3.5.
âˆš
Remark 9.5. The O( Ï„ ) term in the above proof comes from combining two sources of
âˆš
Ï„
). We chose Î» = 1 + Î˜( Ï„ ) so as to
error: one of size O(Î» âˆ’ 1) and another of size O( Î»âˆ’1
minimize the sum of these two error terms.
Remark 9.6. Via a more careful argument one could exactly compute Î´(f[Ï„, Î»]) in terms
of Ï„ and Î» for the template f described above. Using calculus one could then optimize
over the variable Î» to get a lower bound which is the best possible using this technique.
10. P ROOF

OF

T HEOREM 3.5,

UPPER BOUND FOR

H AUSDORFF

DIMENSION

Let f be a Ï„ -singular template such that Î´(f) > Î´m,n âˆ’ z, where z > 0 is small. We aim
to show that Ï„ = O(z 2 ) if (m, n) 6= (2, 2). Indeed, let Ï† be as in (8.1), and let
def

E = {t â‰¥ 0 : Ï†â€² (t) < Î´m,n âˆ’ Î´(f, t)}.

(10.1)
By Lemma 8.1, we have



Ï†â€² (t) â‰¤ Î´m,n âˆ’ Î´(f, t) âˆ’ max(m, n)âˆ’1 t âˆˆ E

for all t sufficiently large. Here [t âˆˆ E] denotes 1 if t âˆˆ E and 0 otherwise. Integrating
over [0, T ] gives


Ï†(T ) âˆ’ Ï†(0) â‰¤ T Î´m,n âˆ’ âˆ†(f, T ) âˆ’ max(m, n)âˆ’1 Î» E âˆ© [0, T ] ,

where Î» denotes Lebesgue measure. On the other hand, since Î´(f) > Î´m,n âˆ’ z, we have
âˆ†(f, T ) â‰¥ Î´m,n âˆ’ z for all sufficiently large T , and thus rearranging the previous equation
and using the fact that Ï†(T ) â‰¥ 0 gives

(10.2)
Î» E âˆ© [0, T ] = O(zT )
and

(10.3)

Ï†(T ) = O(zT )

assuming T is sufficiently large. The trick now is that we also know Ï†(T ) = â„¦(Ï„ T ) since
f is Ï„ -singular (which means that |f1 (t)| â‰¥ Ï„ t for all sufficiently large t). So the question

40

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

is what kind of templates satisfy both an upper bound and a lower bound for Ï†, but for
which the exceptional set E is not large. The answer is given by the following lemma, in
which the problem has been rescaled so that the upper bound for Ï† is just 1:
def

Lemma 10.1. Suppose that (m, n) 6= (2, 2), and fix x > 0. Let f : I = [tâˆ’ , t+ ] â†’ Rd be
a partial template such that x â‰¤ Ï†(t) â‰¤ 1 for all t âˆˆ I. Then if |I| is sufficiently large
depending on m, n, then
Î»(E) & x,
where the exceptional set E is as in (10.1).
def

Proof. Let y = Î»(E); we need to show that either Ï†(t) . y for some t âˆˆ I, or else |I| =
O(1).
Throughout this proof, we will call an interval J a Type 1 interval if case 1 of Lemma
8.1 holds along it; we define Type 2/3a/3b intervals similarly. The basic idea is to reduce
to the case of a Type 2 interval to the left of a Type 3 interval to the left of a Type 1
interval, modulo a small perturbation. Since f cannot be static on any interval of fixed
Type, the bound on Ï† implies a bound on the length of each interval and thus on the
length of the whole interval I. The proof now splits into two cases.
Case 1: Suppose first that there is some Type 1 interval which is to the left of a Type
2/3a/3b interval. Without loss of generality, we may assume that there are no Type
(1/2/3a/3b) intervals between them. It follows that if the two intervals are I1 = (t1 , t2 )
and I2 = (t3 , t4 ), respectively, then we have 0 â‰¤ t3 âˆ’ t2 â‰¤ y.
If I2 is Type 2, then f1 (t3 ) = . . . = fm (t3 ) and fm+1 (t3 ) = . . . = fm+n (t3 ). On the other
hand, by the convexity condition we have fm (s) = fm+1 (s) for some s âˆˆ [t2 , t3 ]. It follows
that |fm+1 (t3 ) âˆ’ fm (t3 )| . y and thus Ï†(t3 ) â‰ |f(t3 )| . y.
If I2 is Type 3a, then m|f1 (t3 )| â‰¥ n|fd (t3 )|. On the other hand, by the convexity condition, for each j = 1, . . . , m there exists sj âˆˆ [t2 , t3 ] such that fj (sj ) = fj+1 (sj ). It follows
that |fj+1(t3 ) âˆ’ fj (t3 )| . y, so
(m + 1)|f1(t3 )| = âˆ’

m+1
X
i=1

fi (t3 ) + O(y) =

m+n
X

fi (t3 ) + O(y)

i=m+2

â‰¤ n|fd (t3 )| + O(y) â‰¤ m|f1 (t3 )| + O(y)
and thus Ï†(t3 ) â‰ |f(t3 )| . y. A similar argument applies if I2 is Type 3b.
Case 2: On the other hand suppose that no Type 1 interval is to the left of any Type
2/3a/3b interval. Now let
def
Ïˆ(t) = m|f1 (t)| âˆ’ n|fd (t)|

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

41

and let J be a Type 2/3a/3b interval. If J is Type 2, then Ïˆ = 0 on J and thus Ïˆ â€² = 0.
1
,
Suppose that J is Type 3a. Then on J we have m|f1 | â‰¥ n|fd |, f1â€² = âˆ’ n1 , and fdâ€² â‰¤ n(m+nâˆ’1)
from which it follows that
1
def m
Ïˆ â€² â‰¥ cm,n =
âˆ’
Â·
n
m+nâˆ’1

Note that cm,n > 0 unless m = 1, in which case cm,n = 0. Similar logic shows that if J is
Type 3b, then Ïˆ â€² â‰¥ cn,m on J.
Now let Ai denote the union of the Type i intervals in I. Note that A1 âˆª A2 âˆª A3 âˆª E = I
def
def
except for finitely many points. We can assume that t0 = sup(A2 ) â‰¤ t1 = inf(A1 ) and
sup(A3 ) â‰¤ t1 , as otherwise we are in Case 1 and we are done by the preceding argument.
Since t0 is the endpoint of a Type 2 interval, we have Ïˆ(t0 ) = 0. On the other hand, we
have
Ë† t0


Ïˆ â€² (t) dt â‰¥ cm,n Î» [tâˆ’ , t0 ] âˆ© A3a + cn,m Î» [tâˆ’ , t0 ] âˆ© A3b âˆ’ O(y)
Ïˆ(t0 ) â‰¥
tâˆ’



so we have Î» [tâˆ’ , t0 ] âˆ© A3a = O(y) if m â‰¥ 2 and Î» [tâˆ’ , t0 ] âˆ© A3b = O(y) if n â‰¥ 2,
respectively. On the other hand, if m = 1 then A3a = A2 and if n = 1 then A3b = A2 .
Consequently

Î» [tâˆ’ , t0 ] âˆ© A3 \ A2 = O(y)
and thus since Ï†â€² = Î´m,n âˆ’ (mn âˆ’ 1) on A2 , we have
Ë† t0
Ï†â€² (t) dt
0 â‰+ Ï†(t0 ) âˆ’ Ï†(tâˆ’ ) =
tâˆ’



= [Î´m,n âˆ’ (mn âˆ’ 1)]Î» [tâˆ’ , t0 ] âˆ© A2 âˆ’ O Î» [tâˆ’ , t0 ] âˆ© E âˆª A3 \ A2


mn
= 1âˆ’
(t0 âˆ’ tâˆ’ ) âˆ’ O(y)
m+n

Since (m, n) 6= (2, 2) by assumption, we have (m âˆ’ 1)(n âˆ’ 1) 6= 1 and thus
mn
6= 0
1âˆ’
m+n
2

m
and thus t0 âˆ’ tâˆ’ = O(1). Similarly, since Ï†â€² = Î´m,n âˆ’ (mn âˆ’ m) = m+n
on A3a and
n2
â€²
Ï† = Î´m,n âˆ’ (mn âˆ’ n) = m+n on A3b , and since (t0 , t1 ) âŠ† A3 âˆª E, we have

0 &+

min(m, n)2
(t1 âˆ’ t0 ) âˆ’ O(y).
m+n

mn
Since Ï†â€² = Î´m,n âˆ’ mn = âˆ’ m+n
on A1 , and since (t1 , t+ ) âŠ† A1 âˆª E, we have

0 â‰+ âˆ’

mn
(t+ âˆ’ t1 ) + O(y).
m+n

42

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Thus t1 âˆ’ t0 = O(1) and t+ âˆ’ t1 = O(1), so combining gives |I| = t+ âˆ’ tâˆ’ = O(1).



Let C > 0 be the constant such that Lemma 10.1 is true whenever |I| â‰¥ C. Notice that
any partial template whose domain has length â‰¥ C can be split up into partial templates
whose domains have length = C which cover the majority of the original domain. It
follows that in the context of Lemma 10.1, in general we have
Î»(E) & x|I| as long as |I| â‰¥ C,
where I is the domain of a partial template f satisfying x â‰¤ Ï† â‰¤ 1. Applying a scaling
argument yields:
Lemma 10.2. Suppose that (m, n) 6= (2, 2), and fix 0 < x0 â‰¤ x1 and I âŠ† R such that
|I| â‰¥ Cx1 . Let f : I â†’ Rd be a partial template such that x0 â‰¤ Ï†(t) â‰¤ x1 for all t âˆˆ I. Then
Î»(E) &

x0 |I|
Â·
x1

Now fix T large, let I = [T /2, T ], and let x0 = inf I Ï†, x1 = supI Ï†. Since f is Ï„ -singular
we have x0 & Ï„ T > 0, while by (10.3) we have x1 = O(zT ). In particular, if z is
sufficiently small then T â‰¥ Cx1 . Consequently, by Lemma 10.2 and (10.2),

Ï„ T 2 = O(x0 T ) = O x1 Î»(E âˆ© I) = O(zT )2 ,
which implies Ï„ = O(z 2 ).
âˆš
It follows that if f is a Ï„ -singular template, then Î´(f) â‰¤ Î´m,n âˆ’ Î˜( Ï„ ), since otherwise
we can take z = 2(Î´m,n âˆ’ Î´(f)) and apply the above argument. Taking the supremum over
f and applying Theorem 4.8 shows that

âˆš
dimH Singm,n (Ï„ ) â‰¤ Î´m,n âˆ’ Î˜( Ï„ ) if (m, n) 6= (2, 2).

When (m, n) = (2, 2), the upper bound for Hausdorff dimension follows from the upper
bound for packing dimension which we proved in Â§8.
11. P ROOF

OF

T HEOREM 3.5,

SECOND FORMULA , LOWER BOUND FOR

H AUSDORFF

DIMENSION

In this proof, we will employ a variant of the notion of a standard template defined by
two parameters, as in Definition 9.4, by introducing a third parameter.
Let m = n = 2, and fix 0 < Ï„ < n1 = 21 . Fix Î» > 1 and let tk = Î»k and Îµk = Ï„ tk . However,
rather than letting f = f[Ï„, Î»] (as in Definition 9.4), we will introduce a new parameter
Î³ âˆˆ [1 + 6Ï„ + 2Î»Ï„, Î»]. We define f as follows:

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

43

â€¢ On [1, Î³], we have f = s[(1, âˆ’Ï„ ), (Î³, âˆ’Î»Ï„ )]. Note that (9.3) is satisfied due to the
lower bound on Î³.
â€¢ Extend f to [Î³, Î»] via the requirement that f is constant on [Î³, Î»]: f1 = f2 = âˆ’Î»Ï„
and f3 = f4 = Î»Ï„ on [Î³, Î»].
â€¢ Extend f to [0, âˆ) via exponential equivariance13, i.e. so that f(Î»t) = Î»f(t) for all
t â‰¥ 0.

For simplicity of calculation, we set Î³ = 1 âˆ’ 2Ï„ + 10Î»Ï„ (this is possible as long as 1 âˆ’ 2Ï„ +
10Î»Ï„ â‰¤ Î»), since this means that f has only three intervals of linearity on [1, Î³] (otherwise
f has four intervals of linearity on [1, Î³]):
ï£±
1 1
ï£´
ï£´
ï£²(âˆ’ 2 , 2 , 0, 0) 1 < t < 1 + 4Ï„
f â€² (t) = (âˆ’ 21 , 16 , 61 , 61 ) 1 + 4Ï„ < t < 1 âˆ’ 2Ï„ + 6Î»Ï„
ï£´
ï£´
ï£³ 1 1
( 2 , âˆ’ 2 , 0, 0) 1 âˆ’ 2Ï„ + 6Î»Ï„ < t < 1 âˆ’ 2Ï„ + 10Î»Ï„ = Î³
(cf. Figure 7). It follows that

ï£±
ï£²2
Î´(f, t) =
ï£³3

1 < t < 1 âˆ’ 2Ï„ + 6Î»Ï„
1 âˆ’ 2Ï„ + 6Î»Ï„ < t < Î»

and thus if we let r = 1 âˆ’ 2Ï„ + 6Î»Ï„ , then the minima of the exponentially Î»-periodic14
function âˆ†(f, Â·) occur at Î»k r for k âˆˆ Z. It follows that
Î´(f) = âˆ†(f, r) = âˆ†(f, [Î»âˆ’1 r, r])
3(1 âˆ’ Î»âˆ’1 r) + 2(r âˆ’ 1)
râˆ’1
=
=
3
âˆ’
r âˆ’ Î»âˆ’1 r
r âˆ’ Î»âˆ’1 r
6Î»Ï„ âˆ’ 2Ï„
=3âˆ’
âˆ’1
(1 âˆ’ Î» )(1 âˆ’ 2Ï„ + 6Î»Ï„ )
= 3 âˆ’ Î˜(Ï„ ),

where the implied constant of Î˜ can depend on Î». This completes the proof. Note that
as in Â§9, one can optimize over the parameter Î» to get the best possible bound using
templates of this form, but we omit the required calculations.
12. P ROOF

OF

T HEOREM 3.8,

LOWER BOUND

We consider a two-parameter standard template f[Ï„, Î»] (as in Definition 9.4). Fix 0 <
Ï„ < 1/n, such that Ï„ < mâˆ’1
if n = 1. Now if Î» is sufficiently large, then (9.4)-(9.6) are
2m
13

Note that we form infinitely many periods when extending f backwards from 1 to 0, and so f now has
infinitely many intervals of linearity in [0, 1]. However, this does not cause any problems in what follows.
14
Meaning that âˆ†(f , Î»T ) = âˆ†(f , T ) for all T > 0.

44

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

F IGURE 7. A period of an exponentially equivariant 2 Ã— 2 template, with
Î³ = 1 âˆ’ 2Ï„ + 10Î»Ï„ . Here a template is called exponentially equivariant if it
is equal to a scaled copy of itself; the â€œperiodâ€ is an interval which is long
enough to recover the template from this self-similarity property.

satisfied (the left half of (9.6) if n â‰¥ 2, and the right half if n = 1), and thus there is a
standard template f = fÎ» = f[Ï„, Î»] defined by the sequence of points (tk , âˆ’Îµk )âˆ
0 , where
k
tk = Î» and Îµk = Ï„ tk .

def

Claim 12.1. Let g = s[(0, 0), (1, âˆ’Ï„ )] (as in Definition 9.1). As Î» â†’ âˆ, the upper average
contraction rate of fÎ» tends to
(12.1)
sup âˆ†(g, T ) = Î´ m,n (Ï„ )
0<T â‰¤1

mn
mn 1 + mÏ„
= max mn âˆ’ m, Î´m,n âˆ’
(d + m)Ï„, mn âˆ’
mn
m+n
m + n 1 âˆ’ mâˆ’1
Ï„

def

!

.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

45

1
1
, . . . , n(dâˆ’1)
) on
Proof. Indeed, first let Î³ > 0 be small enough so that gâ€² = (âˆ’ n1 , n(dâˆ’1)
(0, 2Î³); the definition of g guarantees that such Î³ exists. Since fÎ» is exponentially Î»equivariant and since [Î³, Î»Î³] is a period of fÎ» we have

Î´(fÎ» ) = sup âˆ†(fÎ» , T ).
T âˆˆ[Î³,Î»Î³]

Next, we extend g to [0, âˆ) by stipulating that g1â€² = âˆ’ n1 on [1, âˆ) and then defining
g2 , . . . , gd on [1, âˆ) in the same way as for standard templates (as in Definition 9.1).
Now since fÎ»â€² â†’ gâ€² almost everywhere as Î» â†’ âˆ, it follows that âˆ†(fÎ» , Â·) â†’ âˆ†(g, Â·)
uniformly on [Î³, Î»Î³], i.e. for every Îµ > 0 there exists Î»0 such that for all Î» â‰¥ Î»0 we have
|âˆ†(fÎ» , Â·) âˆ’ âˆ†(g, Â·)| < Îµ on [Î³, Î»Î³]. Thus, we have that
lim Î´(fÎ» ) = sup âˆ†(g, T ).

Î»â†’âˆ

T âˆˆ[Î³,âˆ)

But since Î´(g, t) = mn âˆ’ m for all t âˆˆ [0, Î³] âˆª [1, âˆ), it follows that âˆ†(g, T ) â‰¤ max(mn âˆ’
m, âˆ†(g, 1)) = max(âˆ†(g, Î³), âˆ†(g, 1)) for all T âˆˆ [0, Î³] âˆª [1, âˆ), and thus
sup âˆ†(g, T ) = sup âˆ†(g, T ).
T âˆˆ[Î³,âˆ)

0<T â‰¤1

To complete the proof, we need to show that (12.1) holds, i.e. that sup0<T â‰¤1 âˆ†(g, T ) =
Î´ m,n (Ï„ ). Indeed, from the definition of g, it follows that there exist intervals Ii = (ti , ti+1 ),
i = 0, 1, 2, with t0 = 0, t3 = 1, as follows:

I0

(g1â€² , g2â€² )

S+ (g, Â·)

mn âˆ’ Î´(g, Â·)

1
)
(âˆ’ n1 , n(dâˆ’1)

{2, . . . , m + 1}

m

{3, . . . , m + 2}

2m

I1 (case 1) (âˆ’ n1 , âˆ’ n1 )

1
I1 (case 2) ( m1 , âˆ’ m(dâˆ’1)
) {1, . . . , m}

I2
TABLE

0

( m1 , âˆ’ n1 )
{1, 3, . . . , m + 1} m âˆ’ 1
1. Two cases for the intervals of linearity of g. See Figure 8.

mâˆ’1
mâˆ’1
, while case 2 holds when Ï„ â‰¤ n(d+mâˆ’1)
. (When
Here case 1 holds when Ï„ â‰¥ n(d+mâˆ’1)
equality holds, I1 is empty and so the cases are compatible.) Now let 0 < T â‰¤ 1 be
maximal such that âˆ†(g, Â·) attains its maximum at T . Then Î´(g, t) â‰¥ âˆ†(g, T ) for t slightly
less than T , while Î´(g, t) < âˆ†(g, T ) for t slightly greater than T . Thus T = ti for some
i = 1, 2, 3. But if case 1 holds, then âˆ†(g, t2 ) < mn âˆ’ m = âˆ†(g, t1 ), so if T = t2 then case

46

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

F IGURE 8. The joint graph of g in Case 1 and Case 2, respectively. Note
that the slope of the last top segment may be either negative or positive
according to whether m < n or m > n, respectively (in the picture we have
m = n which corresponds to a horizontal slope).
2 holds. Now it can be checked by direct calculation15 that
âˆ†(g, t1 ) = mn âˆ’ m,

mn 1 + mÏ„
if case 2 holds,
mn
Ï„
m + n 1 âˆ’ mâˆ’1
mn
(d + m)Ï„,
âˆ†(g, t3 ) = Î´m,n âˆ’
m+n
âˆ†(g, t2 ) = mn âˆ’

which implies (12.1), since if Ï„ â‰¥
mn âˆ’

mâˆ’1
n(d+mâˆ’1)

then

1 + mÏ„
mn
â‰¤ mn âˆ’ m,
Â·
mn
Ï„
m + n 1 âˆ’ mâˆ’1

and thus when case 1 holds, the last term on the right-hand side of (12.1) does not
contribute to the maximum16. This concludes the proof of the claim.

Applying the variational principle (Theorem 4.6) to fÎ» gives us that
dimP (Singm,n (Ï„ )) â‰¥ lim Î´(fÎ» ) = sup âˆ†(g, T ) = Î´ m,n (Ï„ ).
Î»â†’âˆ

15

0<T â‰¤1

The calculation of âˆ†(g, t3 ) is somewhat tedious and it is easier to use the equality case of Lemma 13.1
mn
below instead of performing a direct computation, since Ïˆg (1) = m+n
(d + m)Ï„ . Some other formulas
n
mn
useful for the calculations: when case 2 of Table 1 holds we have t1 = m+n
(1 + mÏ„ ) and t2 = 1 âˆ’ mâˆ’1
Ï„.
16
Note that when m = 1, case 1 holds for all Ï„ â‰¥ 0 and thus again the last term on the right-hand side of
(12.1) can be ignored.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

47

This completes the proof of the lower bound in Theorem 3.8.

13. P ROOF

OF

T HEOREM 3.8,

UPPER BOUND WHEN

nâ‰¥2

To prove the upper bound when n â‰¥ 2 in Theorem 3.8, i.e. equality holds in (3.3), we
need a different definition of â€œpotential energyâ€ (cf. Section 8). Let f : [0, âˆ) â†’ Rd be a
balanced m Ã— n template. For each t â‰¥ 0 let


mn2
mn
def
Ïˆ(t) = Ïˆf (t) = max
(m + 1)f1 (t) + (d âˆ’ 1)f2 (t) ,
|fd (t)| .
m+n
m+n
Note that since f is balanced,
(m + 1)f1 (t) + (d âˆ’ 1)f2 (t) â‰¤ (m + 1)f1 (t) + f2 (t) + . . . + fd (t) = mf1 (t) â‰¤ 0
and thus Ïˆ(t) â‰¥ Ï†(t) â‰¥ 0 for all t â‰¥ 0. The analogous result to Lemma 8.1 is stated as
follows:
Lemma 13.1. Suppose that n â‰¥ 2. Let I be an interval of linearity for f such that Ïˆ â€² (t) is
well-defined for all t âˆˆ I, and such that f(t) 6= 0 for all t âˆˆ I. Then
(13.1)

Ïˆ â€² (t) â‰¤ Î´m,n âˆ’ Î´(f, t)

for t âˆˆ I. Equality holds in the following (non-exhaustive) cases:
1. when f1 < f2 = fd on I,
2. when f1 < f2 < f3 = fd , and f2â€² = âˆ’1/n on I.
Note that there is no symmetry here, unlike in the proof of Lemma 8.1, since Ïˆ is not
symmetric with respect to f 7â†’ âˆ’f.
Proof. The proof is similar to that of Lemma 8.1. We can suppose that
(13.2)

(m + 1)f1 (t) + (d âˆ’ 1)f2 (t) â‰¥ n|fd (t)|

for t âˆˆ I, since otherwise Ïˆ = Ï† on I and Lemma 8.1 implies the conclusion. Let j â‰¥ 2
be the largest number such that
f2 = fj on I.
Since I is an interval of linearity for f, we have fj < fj+1 on I. Let LÂ± = LÂ± (f, I, j) and
SÂ± = SÂ± (f, I). The proof now splits into two cases, first if f1 < f2 on I, and second if
f1 = f2 on I.

48

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Case 1: Suppose first that f1 < f2 on I. Let AÂ± = LÂ± (f, I, 1) and BÂ± = LÂ± âˆ’ AÂ± . By
(4.5), on I we have
j
m+n
âˆ’
Lâˆ’
m
mn
m+n
1
âˆ’
Aâˆ’
f1â€² =
m
mn


mn
dâˆ’1 â€²
â€²
â€²
â€²
Ïˆ =âˆ’
(m + 1)f1 +
(F âˆ’ f1 )
m+n
j âˆ’1 j
(m + d)n
dâˆ’1
=âˆ’
+ (m + 1)Aâˆ’ +
Bâˆ’
d
jâˆ’1

Fjâ€² =

and on the other hand, by (4.11) we have




mn âˆ’ Î´(f, t) â‰¥ # Sâˆ’ âˆ© {1} Â· # S+ âˆ© (1, d] + # Sâˆ’ âˆ© (1, j] Â· # S+ âˆ© (j, d]
(13.3)
= mAâˆ’ + Bâˆ’ (m âˆ’ L+ )
and thus
Î´m,n âˆ’ Î´(f, t) â‰¥ mAâˆ’ + Bâˆ’ (m âˆ’ L+ ) âˆ’

mn
Â·
d

So to demonstrate (13.1), it suffices to show that
âˆ’n + (m + 1)Aâˆ’ +

dâˆ’1
Bâˆ’ â‰¤ mAâˆ’ + Bâˆ’ (m âˆ’ L+ ).
jâˆ’1

Rearranging gives the equivalent formulation

dâˆ’1
Bâˆ’ â‰¤ (n âˆ’ Aâˆ’ ) + Bâˆ’ (m âˆ’ L+ ).
jâˆ’1

If Bâˆ’ = 0 this is obviously true (and since n â‰¥ 2 by assumption, the inequality is strict
in this case), and therefore if we backtrack we get that (13.1) is true as well in this case.
Otherwise, assume that Bâˆ’ > 0. Then we can rearrange again to get
dâˆ’1
n âˆ’ Aâˆ’
â‰¤
+ m âˆ’ L+ ,
B+ + Bâˆ’
Bâˆ’
and subtracting 1 from both sides gives
(13.4)

(n âˆ’ Lâˆ’ ) + (m âˆ’ L+ )
n âˆ’ Lâˆ’
â‰¤
+ m âˆ’ L+ .
B+ + Bâˆ’
Bâˆ’

1
â‰¤ min( B1âˆ’ , 1), and so backtracking shows that (13.1) is
This formula is true since B+ +B
âˆ’
true as well. If f2 = fd on I, then j = d and thus L+ = m, Lâˆ’ = n and so equality holds
(in (13.4) and equivalently) in (13.1). Similarly, if f1 < f2 < f3 = fd and f2â€² = âˆ’1/n on
I, then j = 2 and B+ = 0, so Bâˆ’ = B+ + Bâˆ’ = j âˆ’ 1 = 1 and thus equality holds. This
completes the proof of Case 1.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

49

Case 2: Next suppose that f1 = f2 on I. Then on I we have
Ïˆâ€² = âˆ’

(m + d)n m + d
mn m + d â€²
Fj = âˆ’
+
Lâˆ’
m+n j
d
j

and on the other hand, as in (8.4) we have
Î´m,n âˆ’ Î´(f, I) â‰¥ Lâˆ’ (m âˆ’ L+ ) âˆ’

(13.5)

mn
d

so to demonstrate (13.1), it suffices to show that
âˆ’n +

m+d
Lâˆ’ â‰¤ Lâˆ’ (m âˆ’ L+ ).
j

If Lâˆ’ = 0 this is obvious (and the inequality is strict), so assume that Lâˆ’ > 0. Then
rearranging gives the equivalent formulation
2m + n
n
â‰¤
+ m âˆ’ L+ .
L+ + Lâˆ’
Lâˆ’
Write M+ = m âˆ’ L+ and Mâˆ’ = n âˆ’ Lâˆ’ . Then subtracting 1 from both sides gives
Mâˆ’
L+ + 2M+ + Mâˆ’
â‰¤
+ M+
L+ + Lâˆ’
Lâˆ’

and multiplying by L+ + Lâˆ’ and rearranging gives
L+ â‰¤

(13.6)

Mâˆ’ L+
+ M+ (L+ + Lâˆ’ âˆ’ 2).
Lâˆ’

We now demonstrate (13.6). First, note that since L+ + Lâˆ’ = j â‰¥ 2, both terms on the
right-hand side are nonnegative. So if either term is individually at least L+ , then (13.6)
holds. In particular, if Lâˆ’ â‰¤ Mâˆ’ , then the first term is â‰¥ L+ , and if Lâˆ’ â‰¥ 2 and M+ â‰¥ 1,
then the second term is â‰¥ L+ . Also, if L+ = 0 then (13.6) obviously holds. So assume
that L+ > 0, that Lâˆ’ > Mâˆ’ , and that either Lâˆ’ â‰¤ 1 or M+ = 0.
If Lâˆ’ â‰¤ 1, then since Lâˆ’ > Mâˆ’ , we have Mâˆ’ = 0. But since n = Lâˆ’ + Mâˆ’ , this
contradicts our assumption that n â‰¥ 2.
If M+ = 0, then
j = L+ + Lâˆ’ > L+ +
and thus

n
dâˆ’j

>2>

m+d
.
j

Lâˆ’ + Mâˆ’
2L+ + 2M+ + Lâˆ’ + Mâˆ’
2m + n
=
=
2
2
2

Since f is balanced, this implies

nfd + (m + 1)f1 + (d âˆ’ 1)f2 = nfd + (m + d)fj
â‰¥

m+d
n
(fj+1 + . . . + fd ) +
(f1 + . . . + fj ) > 0,
dâˆ’j
j

50

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

contradicting (13.2). Thus neither Lâˆ’ â‰¤ 1 nor M+ = 0 can hold, and so (13.6) holds,
and backtracking yields (13.1). This completes our proof of Case 2, and thus completes
the proof of Lemma 13.1.

We are now ready to prove the upper bound in Theorem 3.8. Let f âˆˆ Singm,n (Ï„ ), i.e.
|f1 (t)| â‰¥ Ï„ t for all sufficiently large t, be a balanced template, and let T be a time such
that Î´(T ) > mn âˆ’ m. Note that this implies that 1 âˆˆ S+ (f, T ). Let T â€² be the largest
time such that f1â€² = 1/m on (T, T â€² ). If T â€² > T , then the convexity condition implies that
f1 (T â€²) = f2 (T â€² ). On the other hand, if T = T â€² , then f1â€² (T ) < 1/m, and since 1 âˆˆ S+ (f, T ),
this implies that f1 (T ) = f2 (T ). So either way f1 (T â€² ) = f2 (T â€² ).
Let g : [0, T â€² ] â†’ Rd be the standard template defined by the points (0, 0) and (T â€² , f1 (T â€² ))
(cf. Definition 9.1). Then f1 (T ) = g1 (T ) while f2 (T ) â‰¤ g2 (T ). Since f is balanced, using
the definition of g this implies that fd (T ) â‰¥ gd (T ). Consequently Ïˆf (T ) â‰¥ Ïˆg (T ) and
hence


âˆ’f1 (T â€² )
âˆ†(f, T ) â‰¤ Î´m,n âˆ’ Ïˆf (T ) â‰¤ Î´m,n âˆ’ Ïˆg (T ) = âˆ†(g, T ) = Î´ m,n
.
Tâ€²
The first equality holds because for g defined as above, on each interval of linearity one
of the conditions 1,2 is satisfied (cf. Table 1), and the second equality is a restatement of
(12.1).
Thus for all T such that Î´(T ) > mn âˆ’ m, we have



âˆ’f1 (T â€² )
,
Î´ m,n
âˆ†(f, T ) â‰¤ max mn âˆ’ m, max
T â€² â‰¥T
Tâ€²
and it follows that the same is true for all T . Taking the limsup gives

Î´(f) â‰¤ max mn âˆ’ m, Î´ m,n (Ï„ ) ,

where f âˆˆ Singm,n (Ï„ ). Taking the supremum over all f and applying Theorem 4.8 completes the proof.

14. P ROOF

OF

T HEOREM 3.9

The proof is similar to that in Section 11. Assume n = 1. There are two cases to
and when Ï„ < m12 .
consider, when 0 < Ï„ < mâˆ’1
2m
. Fix Î» > 1 and let tk = Î»k and Îµk = Ï„ tk . However, rather
Case 1. Fix 0 < Ï„ < mâˆ’1
2m
than letting f = f[Ï„, Î»], we will introduce a new parameter Î³ > 0 (which we think of as
being independent of Î»), small enough so that s[(Î³, âˆ’Îµ), (1, âˆ’Ï„ )] is well-defined for all

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

(Î³, âˆ’Îµ)

51

(1, âˆ’Ï„ )

F IGURE 9. The joint graph of f = s[(Î³, âˆ’Îµ), (1, âˆ’Ï„ )] with m = 2 and n = 1.
0â‰¤Îµâ‰¤

mâˆ’1
Î³
2m

mâˆ’1
(it suffices to take Î³ â‰¤ m4m
2 âˆ’1 ( 2m âˆ’ Ï„ )). Let


Ï„ + (Î» âˆ’ 1) mâˆ’1
2m
Îµ=
Î³.
Î»

We define f as follows:
â€¢ On [Î³, 1], we have f = s[(Î³, âˆ’Îµ), (1, âˆ’Ï„ )] (cf. Figure 9 for an example with m = 2).
â€¢ Extend f to [1, Î³Î»] via the requirements that f1â€² = f2â€² = âˆ’ mâˆ’1
and f3 = . . . = fd on
2m
[1, Î³Î»].
â€¢ Extend f to [0, âˆ) via exponential equivariance. This is possible by the definition
of Îµ.
Now since Î´(f, Â·) = 1 on [1, Î³Î»], we have
âˆ†(f, Î³Î») â‰¥

Î³Î»âˆ’1
Â·
Î³Î»

52

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Taking the supremum over f and applying Theorem 4.8 yields
dimP (Singm,n (Ï„ )) â‰¥

Î³Î»âˆ’1
Â·
Î³Î»

Taking Î» â†’ âˆ completes the proof.
< m1 . For each Î» > 1 let
Case 2. Now suppose that Ï„ < m12 , and let Ï„ â€² = (mâˆ’1)Ï„
1âˆ’mÏ„
fÎ» = f[Ï„ â€² , Î»] be the standard 1 Ã— m template defined by Ï„ â€² and Î» (as in Definition 9.4).
Claim 12.1 shows that
lim Î´(fÎ» ) = Î´1,m (Ï„ â€² ) â‰¥ mn âˆ’ n = m âˆ’ 1.

Î»â†’âˆ

Now the m Ã— 1 template âˆ’fÎ» has the same upper average contractivity as fÎ» . Thus to
complete the proof, it suffices to show that
Ï„ (âˆ’fÎ» ) = Ï„
for all sufficiently large Î». Indeed,
Ï„ (âˆ’fÎ» ) = lim inf 1t fd (t) =
tâ†’âˆ

1
f (t ),
t0 d 0

2
2
where t0 > 1 is the smallest time such that f2 (t0 ) = f3 (t0 ). Since f(1) = (âˆ’Ï„, âˆ’Ï„, mâˆ’1
Ï„, . . . , mâˆ’1
Ï„)
1
1
1
â€²
and f = (âˆ’ m , 1, âˆ’ m , . . . , âˆ’ m ) on (1, t0 ) (cf. Figure 10), we have that

fd (t0 ) = âˆ’Ï„ â€² + (t0 âˆ’ 1) =

2
Ï„â€²
mâˆ’1

âˆ’

1
(t
m 0

âˆ’ 1).

Thus
t0 = 1 +
fd (t0 ) =
Ï„ (âˆ’f(Î»)) =

m
Ï„â€²
mâˆ’1

1
Ï„â€²
mâˆ’1
1
Ï„â€²
fd (t0 )
= mâˆ’1m â€² = Ï„.
t0
1 + mâˆ’1 Ï„

This completes the proof in the case Ï„ < m12 .
and Ï„ = m12 as exercises for the reader.
Finally, we leave the equality cases Ï„ = mâˆ’1
2m
Specifically, one glues together partial templates corresponding to a sequence of values
Ï„k â†’ Ï„ to get a template which is Ï„ -singular but has the desired packing dimension
property.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

53

(t0 , fd (t0 ))
(Î», âˆ’Ï„ â€² Î»)
(1, âˆ’Ï„ â€² )

F IGURE 10. The joint graph of fÎ» = f[Ï„ â€² , Î»] on the interval [1, Î»], as in
Definition 9.4.
15. P ROOF

OF

T HEOREM 3.6,

LOWER BOUND FOR

H AUSDORFF

DIMENSION

Assume n â‰¥ 2, and fix 0 < Ï„ < n1 . As in Section Â§12 we consider a two-parameter
standard template f[Ï„, Î»] (as in Definition 9.4). Now if Î» is sufficiently large, then (9.4)(9.6) are satisfied, and thus there is a standard template f = fÎ» = f[Ï„, Î»] defined by the
k
sequence of points (tk , âˆ’Îµk )âˆ
0 , where tk = Î» and Îµk = Ï„ tk .
Modifying the proof of Claim 12.1 yields
lim Î´(fÎ» ) = inf âˆ†(g, T ),
0<T â‰¤1

Î»â†’âˆ
def

where g = s[(0, 0), (1, âˆ’Ï„ )] (as in Definition 9.1). Applying the variational principle (Theorem 4.6) to fÎ» gives us that
dimH (Singm,n (Ï„ )) â‰¥ inf âˆ†(g, T ).
0<T â‰¤1

Now Î´(g, t) â‰¥ mn âˆ’ 2m for all t, and Î´(g, t) â‰¥ mn âˆ’ m for all t â‰¤ n(dâˆ’1)
[ n1 âˆ’ Ï„ ]. It follows
d
that


mn(d âˆ’ 1) 1
âˆ’Ï„
âˆ†(g, T ) â‰¥ mn âˆ’ 2m +
d
n
for all 0 < T â‰¤ 1.
16. P ROOF

OF

T HEOREM 3.7,

Assume n = 1, and fix 0 < Ï„ <
(16.1)

LOWER BOUND FOR

mâˆ’1
,
2m

H AUSDORFF

DIMENSION

and let Î» be minimal such that (9.6) holds, i.e.
âˆ’1
def
âˆ’
Ï„
.
Î» = 1 + dÏ„2 mâˆ’1
2m

As usual we let tk = Î»k , Îµk = Ï„ tk , and f = f[Ï„, Î»].

54

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Fix t â‰¥ 0. If Î´(f, t) = 0, then Sâˆ’ (f, t) = {1} and thus f1â€² (t) = âˆ’1, while if Î´(f, t) â‰¥ 1
then we have the trivial bound f1â€² (t) â‰¤ m1 . Combining these two results into one formula
yields
Î´(f, t) for all t.
f1â€² (t) â‰¤ âˆ’1 + m+1
m
Thus
< âˆ’Ï„ = f1 (1) â‰¤ âˆ’1 +
âˆ’ mâˆ’1
2m

m+1
âˆ†(f, 1),
m

and rearranging gives
âˆ†(f, 1) > 21 .
1
1
It follows that âˆ†(f, T ) â‰¥ 2T
â‰¥ 2Î»
for all T âˆˆ [1, Î»]. The exponential equivariance of f
1
then implies that âˆ†(f, T ) â‰¥ 2Î» for all T > 0. So

1
= 12 âˆ’ Î˜ mâˆ’1
âˆ’Ï„
Î´(f) â‰¥ 2Î»
2m
(16.1)

and applying Theorem 4.8 completes the proof.

17. P ROOF

OF

T HEOREM 3.6,

UPPER BOUND FOR

H AUSDORFF

DIMENSION

Let f be a Ï„ -singular template which is not trivially singular, i.e. |f1 (t)| â‰¥ Ï„ t for all
sufficiently large t, and fj+1(t) âˆ’ fj (t) 9 âˆ as t â†’ âˆ for all j = 1, . . . , d âˆ’ 1. Then
there exists a constant C such that f2 (T ) â‰¤ f1 (T ) + C infinitely often. Fix T such that
f2 (T ) â‰¤ f1 (T ) + C. Since f is Ï„ -singular, we have f2 (T ) â‰¤ f1 (T ) + C â‰¤ âˆ’Ï„ T + C.
Since 1, 2 âˆˆ Sâˆ’ (f, t)
For all t such that f1â€² (t) = f2â€² (t) = âˆ’ n1 , we have
mn âˆ’ Î´(f, t) â‰¥ 2m
and for all t such that fiâ€² (t) > âˆ’ n1 for some i = 1, 2, we have


1
1
n
m+n
1
â€²
=âˆ’ +
âˆ’
fi (t) â‰¥
n+1 m n
n mn(n + 1)
and thus

m+n
2
+
n mn(n + 1)
and at the same time mn âˆ’ Î´(f, t) â‰¥ 0. Combining these two cases we have


2m2 n(n + 1) 2
â€²
â€²
mn âˆ’ Î´(f, t) â‰¥ 2m âˆ’
+ f1 (t) + f2 (t)
m+n
n
f1â€² (t) + f2â€² (t) â‰¥ âˆ’

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

55

and averaging over the interval [0, T ] gives



2m2 n(n + 1) 2 f1 (T ) f2 (T )
mn âˆ’ âˆ†(f, T ) â‰¥ 2m âˆ’
+
+
m+n
n
T
T


2
4m n(n + 1) 1
C
â‰¥ 2m âˆ’
.
âˆ’Ï„ +
m+n
n
2T

Taking the liminf as T â†’ âˆ and applying Theorem 4.8 completes the proof.
18. P ROOF

OF

T HEOREM 3.7,

UPPER BOUND FOR

H AUSDORFF

DIMENSION

Let f be a Ï„ -singular m Ã— 1 template, i.e. |f1 (t)| â‰¥ Ï„ t for all sufficiently large t. The
proof spilts in two cases.
Case 1. First suppose that both f1 = f2 and f2 = f3 infinitely often.
Fix T1 > 0 such that f2 (T1 ) = f3 (T1 ), and let T â‰¥ T1 be minimal such that f1 (T ) =
âˆ’ Ï„ > 0. For each t, let j(t) denote the unique element of Sâˆ’ (f, t).
f2 (T ). Let x = mâˆ’1
2m
Then
ï£±
ï£²= 1 âˆ’ 1
j(t) = 1, 2
m
â€²
â€²
f1 (t) + f2 (t)
ï£³â‰¥ 1 âˆ’ 1 + Î± j(t) > 2
m

where Î± > 0 is a constant. On the other hand,

1
1
âˆ’ 1 + 2x.
f1 (T ) + f2 (T ) â‰¤ âˆ’2Ï„ =
T
m
It follows that
Î»({t â‰¤ T : j(t) > 2}) = O(xT )

where Î» is Lebesgue measure. Consequently fi (t) = mt + O(xT ) for all i > 2 and t âˆˆ [0, T ].
On the other hand, since f2â€² â‰¥ âˆ’1 it follows that for t âˆˆ [0, T ] we have


m+1
mâˆ’1
âˆ’x T +T âˆ’t=
T âˆ’ t + O(xT ),
f2 (t) â‰¤ f2 (T ) + T âˆ’ t â‰¤ âˆ’
2m
2m
and thus we have f2 < f3 for all t âˆˆ I := (T /2 + cxT, T ), where c > 0 is a constant. In
particular we have T1 â‰¤ T /2 + cxT . By the minimality of T , it follows that f1 < f2 on
I. Using the convexity condition it is possible to prove that j(t) = 2 for all t âˆˆ I. Thus
f1â€² = m1 on I and thus
f1 (T /2) = f1 (T ) âˆ’

1
(T /2)
m

+ O(xT ) â‰¤ âˆ’Ï„ T âˆ’

1
(T /2)
m

+ O(xT ) = âˆ’(T /2) + O(xT ).

Consequently,
(18.1)

Î»({t â‰¤ T /2 : j(t) > 1}) = O(xT )

and thus âˆ†(f, T /2) = O(xT ).

56

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Case 2a. Now if f1 < f2 for all sufficiently large times, then it follows from the
convexity condition that j(t) = 1 for all sufficiently large times, and thus Î´(f) = 0.
Case 2b. If f2 < f3 for all sufficiently large times, then it follows from the convexity
condition that j(t) â‰¤ 2 for all sufficiently large times, and thus
2f1 (t) â‰¤ f1 (t) + f2 (t) = âˆ’

mâˆ’1
t+C
m

for some constant C. This demonstrates that Ï„ â‰¥ mâˆ’1
. Since equality holds infinitely
2m
mâˆ’1
mâˆ’1
often, we have Ï„ = 2m . Thus for Ï„ < 2m , we have f2 = f3 infinitely often.
19. P ROOF

OF

T HEOREM 3.7,

UPPER BOUND FOR PACKING DIMENSION

Let T1 > 0 be a local maximum of âˆ†(f, Â·), and by contradiction suppose that âˆ†(f, T1 ) >
1. Then Î´(f, I) > 1, where I is the interval of linearity for f whose right endpoint is T1 .
Equivalently, j > 2 on I, where j is as in Â§18. Let T be as in Â§18. Since f1 < f2 on
(T1 , T ), by the convexity condition we have j > 1 on (T1 , T ) and thus by (18.1) we have
T1 = T /2 + O(xT ). But then by the argument of Â§18, we have
âˆ†(f, T1 ) = âˆ†(f, T /2) + O(x) = O(x)
and thus if x is sufficiently small, then âˆ†(f, T1 ) < 1, a contradiction.
20. P ROOF

OF

T HEOREM 3.10

Note that the packing dimension formula in Theorem 3.10 follows immediately from
Theorem 3.8. Thus, we prove only the Hausdorff dimension formula. However, note that
the first part of the proof could apply to the computation of packing dimension as well.
Fix Ï„ > 0, and let f be a 1 Ã— 2 template which satisfies Ï„ (f) = Ï„ but is not trivially
singular. We claim that
(20.1)

Î´(f) â‰¤ Î´(Ï„ ),

where Î´(Ï„ ) is the right-hand side of the first formula of Theorem 3.10. This will prove
the upper bound of that formula. Indeed, since f is not trivially singular, the sets Fâˆ’ =
{t â‰¥ 0 : f1 (t) = f2 (t)} and F+ = {t â‰¥ 0 : f2 (t) = f3 (t)} are both unbounded. Since f is
piecewise linear, we can write Fâˆ’ âˆª F+ as the union of a sequence of intervals [s1 , t1 ] <
[s2 , t2 ] < . . .
Claim 20.1. We can assume without loss of generality that
F+ = [s1 , t1 ] âˆª [s3 , t3 ] âˆª . . . and Fâˆ’ = [s2 , t2 ] âˆª [s4 , t4 ] âˆª . . .

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

57

Proof. First, since Fâˆ’ and F+ are disjoint, for each k we have either [sk , tk ] âŠ† Fâˆ’ or
[sk , tk ] âŠ† F+ . Now let g : [0, âˆ) â†’ R3 be defined by the formulas
ï£±

1
1
ï£´
âˆ’
f
if t âˆˆ (tk , sk+1), [sk , tk ], [sk+1 , tk+1] âŠ† Fâˆ’
3 (t), âˆ’ 2 f3 (t), f3 (t), . . . , f3 (t)
ï£´
2
ï£²

g(t) =
if t âˆˆ (tk , sk+1), [sk , tk ], [sk+1 , tk+1] âŠ† F+
f1 (t), âˆ’ 21 f1 (t), . . . , âˆ’ 21 f1 (t)
ï£´
ï£´
ï£³
f(t)
otherwise.

Then Î´(g, t) â‰¥ Î´(f, t) for all t â‰¥ 0, so Î´(g) â‰¥ Î´(f) and Î´(g) â‰¥ Î´(f). Moreover, since the
minima of the functions
âˆ’g1 (t)
âˆ’f1 (t)
and t 7â†’
t 7â†’
t
t
on an interval of the form [tk , sk+1] are always attained at one of the endpoints of the
interval, we have Ï„ (g) = Ï„ (f). So it suffices to prove (20.1) with f replaced by g. Now
the corresponding sets Fâˆ’ and F+ defined in terms of g are clearly of the desired form,
with the exception that the roles of Fâˆ’ and F+ may be switched; this exception can be
dealt with by truncating the template from the left so as to cut out the interval [s1 , t1 ]. 

We observe that f1 and f2 â€œsplitâ€ at times t2k and â€œmergeâ€ at times s2k , while f2 and f3
â€œsplitâ€ at times t2k+1 and â€œmergeâ€ at times s2k+1 . Consequently
â€² +
f1â€² (t+
2k ) < f2 (t2k ),

â€² +
f2â€² (t+
2k+1 ) < f3 (t2k+1 ),

â€² âˆ’
f1â€² (sâˆ’
2k ) > f2 (s2k ),

â€² âˆ’
f2â€² (sâˆ’
2k+1 ) > f3 (s2k+1 ).

It follows that if j(t) denotes the unique element of S+ (f, t), then
âˆ’
j(s+
2k ) = j(t2k ) = 1,

âˆ’
j(t+
2k ) = j(s2k+1 ) = 2,

âˆ’
j(s+
2k+1 ) = j(t2k+1 ) = 2,

Thus by the convexity condition,
s2k+2 such that
ï£±
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£²
â€²
f (t) =
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£´
ï£³

âˆ’
j(t+
2k+1 ) = 3 > j(s2k+2 ) = 1.

there exists sequences of numbers t2k+1 < ak â‰¤ rk <
âˆ’ 21 , 1, âˆ’ 21

âˆ’ 12 , 41 , 41

âˆ’ 12 , âˆ’ 12 , 1






1

âˆ’ 12 , 1, âˆ’ 2

1, âˆ’ 12 , âˆ’ 12

1 1
1
,
,
âˆ’
4 4
2

(cf. Figure 11). Evidently, we have

t2k < t < s2k+1
s2k+1 < t < t2k+1
t2k+1 < t < ak
ak < t < rk
rk < t < s2k+2
s2k+2 < t < t2k+2

58

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

t2k s2k+1 t2k+1

s2k+2

ak rk

t2k+2

F IGURE 11. A piece of an arbitrary 1 Ã— 2 template.
ï£±
ï£´
1
ï£´
ï£´
ï£´
ï£´
ï£²0
Î´(f, t) = 3 âˆ’ j(f, t) =
ï£´
ï£´
1
ï£´
ï£´
ï£´
ï£³
2

t2k < t < t2k+1
t2k+1 < t < ak
ak < t < rk
rk < t < t2k+2 .

Now let Ak , Bk , Ck , Dk âˆˆ R be chosen so that

f1 (t) = Ak âˆ’ 21 t for all t âˆˆ [t2k , rk ],
f1 (t) = Bk + t for all t âˆˆ [rk , s2k+2],
f3 (t) = Ck + t for all t âˆˆ [t2k+1 , ak ],

f3 (t) = Dk âˆ’ 12 t for all t âˆˆ [ak , s2k+3].
Then the set of parameters



Ak , Bk , Ck , Dk



kâˆˆN

is a necessary and sufficient set of parameters for f in the following sense: the map
sending f to this set of parameters is injective, and its image is the set of all sequences of

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

59

parameters that satisfy the following inequalities:
(20.2)
(20.3)

sk â‰¤ tk < sk+1,
t2k+1 < ak â‰¤ rk < s2k+2

where sk , tk , ak , rk are defined by the equations
(20.4)
(20.5)
(20.6)
(20.7)
(20.8)
(20.9)

0 = (Ak âˆ’ 12 rk ) âˆ’ (Bk + rk )

0 = (Ck + ak ) âˆ’ (Dk âˆ’ 12 ak )


0 = 2 Ak âˆ’ 12 t2k + Dkâˆ’1 âˆ’ 12 t2k


0 = 2 Bk + s2k+2 + Dk âˆ’ 21 s2k+2


0 = Ak âˆ’ 12 t2k+1 + 2 Ck + t2k+1


0 = Ak âˆ’ 12 s2k+1 + 2 Dkâˆ’1 âˆ’ 12 s2k+1

The idea now is to take a function f defined by a sequence of parameters satisfying
(20.2)-(20.3), and to replace it by a function e
f defined by a sequence of parameters


ek , B
ek , C
ek , D
ek
A
.
kâˆˆN

If we can show that âˆ†(e
f, T ) â‰¥ âˆ†(f, T ) for all T , while Ï„b(e
f) = Ï„b(f), then it suffices to
e
prove (20.1) for f . A change that satisfies this inequality will be called an allowable
change. Note that if a change only affects the value of Î´(f, Â·) on two intervals I1 , I2 such
that max(I1 ) < min(I2 ), increasing it on I1 and decreasing it on I2 , with greater total area
for the effect on I1 , then the change is allowable. We now show that we can make some
allowable changes to simplify the structure of the template f.
Claim 20.2. We can without loss of generality assume that ak = rk for all k.

Proof. We claim that decreasing Ck by Îµ while leaving all other parameters fixed is an
allowable change. Indeed, this change will have the effect of increasing t2k+1 by 34 Îµ while
increasing ak by 23 Îµ. This means that Î´(f, Â·) is increased by 1 on an interval of length 34 Îµ
around t2k+1 , but decreased by 1 on an interval of length 23 Îµ around ak . Thus, the change
is allowable, and applying the maximum value of Îµ = 32 (rk âˆ’ ak ) completes the proof. 
From now on we will not treat Ck as an independent parameter, but rather assume that
it is given by (20.5) together with the formula ak = rk . Note that in this case, (20.4),
(20.5), and (20.8) combine to form the equation


(20.10)
0 = Ak âˆ’ 21 t2k+1 + 2 Dk âˆ’ Ak + Bk + t2k+1 .

60

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Claim 20.3. The following set of parameter changes is allowable:
ek = Ak + Îµ
A

ekâˆ’1 = Bkâˆ’1 + Îµ
B

e kâˆ’1 = Dkâˆ’1 âˆ’ Îµ
D

Proof. These changes lead to the following changes to tk , rk :
â€¢
â€¢
â€¢
â€¢
â€¢

no change to t2kâˆ’1
decrease rkâˆ’1 by 23 Îµ (thus increasing Î´(f, Â·) by 2 on an interval of this length)
increase t2k by 32 Îµ (thus increasing Î´(f, Â·) by 1 on an interval of this length)
increase t2k+1 by 23 Îµ (thus increasing Î´(f, Â·) by 1 on an interval of this length)
increase rk by 32 Îµ (thus decreasing Î´(f, Â·) by 2 on an interval of this length)

The changes to sk can be ignored as they do not affect Î´(f, Â·), except to note that âˆ†sk =
sek âˆ’ sk is always negative and so e
tk âˆ’ sek â‰¥ tk âˆ’ sk â‰¥ 0. The only decreasing effect, due to
the change on rk , is dominated by the increasing effect due to the change on rkâˆ’1 . Thus
the changes are allowable.

Now for each k, choose the maximum value of Îµ such that the changes lead to parameters satisfying (20.2)-(20.3) as well as the inequality
f1 (t) â‰¤ âˆ’Ï„ t for all t,
where Ï„ < Ï„b(f) is arbitrary. Note that by piecewise linearity, this inequality is equivalent
to saying that for all k we have
f1 (t2k ) â‰¤ âˆ’Ï„ t2k .

(20.11)

Then after the changes, (20.11) will be satisfied with equality for every k. Equivalently,
Ak âˆ’ 12 t2k = âˆ’Ï„ t2k .

(20.12)
Let uk = t2k , and note that

f(uk ) = (âˆ’Ï„ uk , âˆ’Ï„ uk , 2Ï„ uk ) .
This equality implies that for each k, we can define a template g(k) by letting g(k) = f on
[uk , uk+1] and then extending by exponential equivariance:
g(k) (Î»t) = Î»g(k) (t) where Î» = uk+1/uk .
Note that clearly, Ï„ (g(k) ) = Ï„ for all k. From now on we will specialize to the Hausdorff
dimension case of Theorem 3.10.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

61

Claim 20.4. We have
Î´(f) â‰¤ sup Î´(g(k) ).

(20.13)

k

Proof. Fix Îµ > 0. Then there exist infinitely many k such that âˆ†(f, uk+1 ) â‰¥ âˆ†(f, uk ) âˆ’ Îµ.
For such a k, we have
âˆ†(g(k) , uk ) = âˆ†(f, [uk , uk+1]) â‰¥ âˆ†(f, uk ) âˆ’ O(Îµ)
since uk+1 /uk is bounded away from 1. Thus
inf

T âˆˆ[uk ,uk+1 ]

âˆ†(f, T ) â‰¤

inf

T âˆˆ[uk ,uk+1 ]

âˆ†(g(k) , T ) + O(Îµ) = Î´(g(k) ) + O(Îµ).

Taking the liminf over k and then letting Îµ â†’ 0 gives (20.13).



Thus, we can without loss of generality assume that f is exponentially equivariant, i.e.
that
(20.14)

Ak = Î»k A,

Bk = Î»k B,

Dk = Î» k D

for some A, B, D > 0 and Î» > 1. Now by rescaling, we can without loss of generality
assume that u0 = 1. Plugging k = 0 into the formulas (20.4)-(20.9), (20.10), and
(20.12), and solving for the appropriate variables yields
A=

1
2

âˆ’Ï„

D = Î»( 23 âˆ’ 2A) = Î»( 21 + 2Ï„ )
t0 = 1
s1 = 32 (A + 2Î»âˆ’1 D) = 2 âˆ’ 2A = 1 + 2Ï„
t1 = 23 (A âˆ’ 2D âˆ’ 2B)

r0 = 32 (A âˆ’ B)

s2 = âˆ’ 32 (2B + D)
t2 = Î».
On the interval [u0 , u1 ] = [1, Î»], the behavior of Î´(f, Â·) is as follows:
ï£±
ï£´
ï£´
ï£²1 1 < t < t1
(20.15)
Î´(f, t) = 0 t1 < t < r0
ï£´
ï£´
ï£³
2 r0 < t < Î».

e = B âˆ’ Îµ. This change increases t1 by 4 Îµ and increases r0 by
Now consider the change B
3
2
4
Îµ, this increasing Î´(f, Â·) by 1 on an interval of length 3 Îµ around t1 and decreasing Î´(f, Â·)
3

62

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

t2k s2k+1

rk

t2k+1

t2k+2

F IGURE 12. A period of an exponentially periodic 1 Ã—2 template, simplified
using the arguments of this section.

by 2 on an interval of length 23 Îµ around r0 . Thus the change is allowable, and by taking
the maximum possible value of Îµ = 43 (t2 âˆ’ s2 ), we can without loss of generality assume
that s2 = t2 , or equivalently that
B = âˆ’ 43 Î» âˆ’ 12 D = Î»(A âˆ’ 23 ) = âˆ’Î»(1 + Ï„ )
(cf. Figure 12). Note that this implies
t1 = 32 A + 34 Î»A.
Now it is a problem of one-variable calculus: Î» is the only free parameter, and we must
optimize Î´(f). Note that Î» is subject to the restriction
Î»â‰¥

3/2 âˆ’ 2A
1/2 + 2Ï„
=
A
1/2 âˆ’ Ï„

which comes from the inequality s1 â‰¤ t1 . Now from (20.15), we have
Î´(f) = âˆ†(f, r0 ) = âˆ†(f, [Î»âˆ’1 r0 , r0 ]) =

1(t1 âˆ’ 1) + 2(1 âˆ’ Î»âˆ’1 r0 )
Â·
r0 âˆ’ Î»âˆ’1 r0

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

63

On the other hand,
t1 = 32 A + 43 Î»A,

r0 = 32 A âˆ’ 32 Î»A + Î».

Let x = Ï„ and y = 31 (Î» âˆ’ 1). Then
t1 = ( 13 âˆ’ 23 x)(3 + 6y) = (1 âˆ’ 2x)(1 + 2y),

r0 = 1 + 3y âˆ’ ( 31 âˆ’ 32 x)(3y) = 1 + (2 + 2x)y,

Î»(t1 âˆ’ 1) + 2(Î» âˆ’ r0 )
r0 (Î» âˆ’ 1)
(1 + 3y)(âˆ’2x + (2 âˆ’ 4x)y) + (2 âˆ’ 4x)y
=
(1 + (2 + 2x)y)(3y)
2
def 2 âˆ’x + (2 âˆ’ 7x)y + (3 âˆ’ 6x)y
= fx (y) = Â·
Â·
3
y + (2 + 2x)y 2

Î´(f) =

x
, âˆ), assuming
We now need to find the maximum of the function fx on the interval [ 1/2âˆ’x
that 0 < x < 1/2. The function fx has two critical points, given by the formulas17

0 = x + (4x + 4x2 )y + (âˆ’1 + 4x + 14x2 )y 2
âˆš
x
Îµ x âˆ’ 6x3 + 4x4 + 2x + 2x2
= âˆš
y=
2
3
1 âˆ’ 4x âˆ’ 14x
Îµ x âˆ’ 6x + 4x4 âˆ’ 2x âˆ’ 2x2
8
4 4 âˆš
fx (y) = âˆ’ Îµ x âˆ’ 6x3 + 4x4 âˆ’ 2x + x2
3 3
3
where Îµ = Â±1. Note that since the critical point corresponding to Îµ = âˆ’1 is negative, it
is not in the domain and so can be ignored. The critical point corresponding to Îµ = +1
âˆš
2âˆ’2
is positive if and only if 1 âˆ’ 4x âˆ’ 14x2 > 0, which in turn is true if and only if x < 3 14
.
In this case, it is easy to check that this critical point is in the domain of fx , and that the

17

Note that we found it easier to do these calculations first for the general case
f (y) =

âˆ’A + By + Cy 2
,
Dy + Ey 2

then plug in the values A = x, B = 2 âˆ’ 7x, C = 3 âˆ’ 6x, D = 1, and E = 2 + 2x, and finally multiply by 23 .
In the general case the formulas are
0 = AD + 2AEy âˆ’ (BE âˆ’ CD)y 2
âˆš
Îµ Q + AE
AD
y=
= âˆš
where Q = (AE)2 + (AD)(BE âˆ’ CD)
BE âˆ’ CD
Îµ Q âˆ’ AE
p

1
f (y) = 2 2AE + BD âˆ’ 2Îµ A2 E 2 + ABDE âˆ’ ACD2 .
D

64

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

critical point is a maximum. Thus in this case
4 4âˆš
8
sup fx (y) = fx (ycrit) = âˆ’
x âˆ’ 6x3 + 4x4 âˆ’ 2x + x2 .
3 3
3
y
âˆš

2âˆ’2
, then this critical point is negative or undefined, and thus
On the other hand, if x â‰¥ 3 14
fx has no critical points on its domain. It can be verified that fx is increasing in this case,
so its supremum is equal to its limiting value:

sup fx (y) = lim fx (y) =
y

yâ†’âˆ

2 3 âˆ’ 6x
1 âˆ’ 2x
Â·
=
Â·
3 2 + 2x
1+x

Since Î´(f) â‰¤ supy fx (y), this completes the proof of the upper bound. To prove the lower
x
bound, note that if y âˆˆ [ 1/2âˆ’x
, âˆ), then there is a unique exponentially periodic template
f satisfying the formulas appearing in the above proof, and this template satisfies Î´(f) =
fx (y). Thus dimH (Sing1,2 (Ï‰)) â‰¥ fx (y), and taking the supremum over y proves the lower
bound. Note that the exponentially periodic template f is the same as the standard
template defined by the sequence of points (tk , âˆ’Îµk ) = (Î»k , âˆ’Ï„ Î»k ), where Ï„ = x and
Î» = 1 + 3y.
21. P ROOF

OF

T HEOREM 3.11

Let f be a template, and let Ï† be as in Â§8. We claim that
mn
g(t),
Ï†â€² (t) â‰¤ Î´m,n âˆ’ Î´(f, t) +
m+n
where g(t) = 1 if f(t) = 0 and g(t) = 0 otherwise. Indeed, when f(t) 6= 0, this follows
from Lemma 8.1, and when f(t) = 0 it follows from direct calculation using the fact that
Ï†â€² (t) = 0 and Î´(f, t) = mn. Now fix T > 0. Integrating over [0, T ] gives



Ë† T
mn
mn
0 .+ Ï†(T )âˆ’Ï†(0) â‰¤
Î´m,n âˆ’ Î´(f, t) +
g(t) dt = T Î´m,n âˆ’ âˆ†(f, T ) +
G(T ) ,
m+n
m+n
0
where G(T ) is the average of g on [0, T ]. It follows that


mn
mn
Î´(f) â‰¤ lim sup Î´m,n +
G(T ) = Î´m,n +
lim sup G(T ) = P(f)Î´m,n +(1âˆ’P(f))mn,
m+n
m + n T â†’âˆ
T â†’âˆ
where
def

P(f) = lim inf (1 âˆ’ G(T ))
T â†’âˆ

is the proportion of time spent near infinity. Applying Theorem 4.6 gives
dimH ({A : P(A) = p}) â‰¤ dimP ({A : P(A) = p}) â‰¤ pÎ´m,n + (1 âˆ’ p)mn.
For the reverse direction, fix p and Îµ > 0 small. Define f on [1, 1 + Îµ] as follows:

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

65

â€¢ Let f = g[(0, 0), (1 + pÎµ, 0)] on [1, 1 + pÎµ]
â€¢ Let f(t) â‰¡ 0 on [1 + pÎµ, 1 + Îµ]
and extend by exponential equivariance. It is easy to see that P(f) = p and
dimP (D(f)) â‰¥ dimH (D(f)) â‰¥ pÎ´m,n + (1 âˆ’ p)mn âˆ’ O(Îµ).
This completes the proof.
22. P ROOF

OF

T HEOREM 3.12

Let Ï† be a function such that Ï†(t) â†’ âˆ as t â†’ âˆ, and without loss of generality
suppose that Ï† is increasing. Let (tk , âˆ’Îµk ) be a sequence of points such that:
(i)
(ii)
(iii)
(iv)

âˆ†tk â‰¤ 12 Ï†(tk ) for all k;
Îµk â‰¤ 12 Ï†(tk ) for all k;
Îµk â†’ âˆ as k â†’ âˆ;
Îµk /âˆ†tk â†’ 0 and Îµk+1/âˆ†tk â†’ 0 as k â†’ âˆ.

Then let f be the standard template defined by the sequence of points (tk , âˆ’Îµk ). Conditions (i) and (ii) imply that f1 (t) â‰¥ âˆ’Ï†(tk ) â‰¥ âˆ’Ï†(t) for all k âˆˆ N and t âˆˆ [tk , tk+1 ].
Condition (iii) implies that f is singular. Finally, condition (iv) implies that Î´(f) = Î´m,n ,
since
 
 
 
Îµk+1
Îµk
, 0, âˆ’
,1
âˆ†(f, [tk , tk+1 ]) = âˆ† s 0, âˆ’
âˆ†tk
âˆ†tk
â†’ âˆ†(s[(0, 0), (1, 0)], 1) = Î´m,n as k â†’ âˆ.

23. P ROOF

OF

T HEOREM 3.14

Fix 2 â‰¤ k â‰¤ d âˆ’ 1 and j âˆˆ {k âˆ’ 1, k}, and let f be a template with the following
properties:
(23.1)

fkâˆ’1 (t) â†’ âˆ’âˆ as t â†’ âˆ,

(23.2)

fk+1 (t) â†’ +âˆ as t â†’ âˆ,

(23.3)
(23.4)

1
f(t) â†’ 0 as t â†’ âˆ,
t

1
Î» [0, T ] âˆ© (Sj+ âˆª Sjâˆ’ ) â†’ 1 as T â†’ âˆ,
T

where Sj+ (resp. Sjâˆ’ ) is the set of all times t â‰¥ 0 such that the following hold:
â€¢ f1 (t) = . . . = fj (t) < fj+1 (t) = . . . = fd (t),
âŒ‰, âŒŠ jn
âŒ‹) (resp. (L+ , Lâˆ’ ) = (âŒŠ jm
âŒ‹, âŒˆ jn
âŒ‰)), where LÂ± = LÂ± (f, t, j).
â€¢ (L+ , Lâˆ’ ) = (âŒˆ jm
d
d
d
d

66

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Such a template can be constructed by alternating long SjÂ± intervals with short intervals
along which fk crosses 0 and returns, in a manner consistent with the rule on changes of
slopes (cf. Figure 13). The key point is that if t âˆˆ Sj+ then f1â€² (t) â‰¥ 0, but if t âˆˆ Sjâˆ’ then
is an integer). Note that the template f is not
f1â€² (t) â‰¤ 0 (with equality if and only if jm
d
trivially singular.

F IGURE 13. A piece of a template f with the desired properties, as described in Â§23 (Proof of Theorem 3.14). The triangular portion of the figure
can be made arbitrarily small in proportion to the rest.

To compute the lower contractivity of f, we observe that for t âˆˆ Sj+ , we have
"
#
jm
jn
âŒ‰
âŒ‹
âŒˆ
âŒŠ
1
def
d
f1â€² (Sj+ ) = f1â€² (t) =
âˆ’ d
j
m
n
"
#
jm
jn
jm
jn
+
{âˆ’
}
âˆ’
{
}
1 d
d
d
âˆ’ d
=
j
m
n
 
1 m + n jn
=
j mn
d
 


jn
jm
+ def
mn âˆ’ Î´(f, Sj ) = mn âˆ’ Î´(f, t) = Lâˆ’ (m âˆ’ L+ ) =
mâˆ’
d
d

  


jm
jn
jm
jn
mâˆ’
âˆ’
âˆ’ âˆ’
=
d
d
d
d
   2
jn
j(d âˆ’ j)mn (d âˆ’ j)m + jn jn
+
.
âˆ’
=
2
d
d
d
d

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

Similarly, for t âˆˆ Sjâˆ’ we have
def
f1â€² (Sjâˆ’ ) =

mn âˆ’

def
Î´(f, Sjâˆ’ ) =

f1â€² (t)

1m+n
=âˆ’
j mn



jm
d



j(d âˆ’ j)mn (d âˆ’ j)m + jn
mn âˆ’ Î´(f, t) =
+
d2
d

On the other hand, for t âˆˆ
/ Sj+ âˆª Sjâˆ’ we have âˆ’ n1 â‰¤ f1â€² (t) â‰¤
is an integer, then by (23.4) we have

1
m



jm
d



+

67



jm
d

2

.

and 0 â‰¤ Î´(f, t) â‰¤ mn. If

jm
d

Î´(f, Sj+ ) = Î´(f, Sjâˆ’ ) = fm,n (j)
and we are done. Otherwise, by (23.3) and (23.4) we have

1
Î» [0, T ] âˆ© SjÂ± â†’ Î±Â± as T â†’ âˆ,
T
where Î±+ + Î±âˆ’ = 1 and
Î±+ f1â€² (Sj+ ) + Î±âˆ’ f1â€² (Sjâˆ’ ) = 0.
It follows that
+

Î± =



jm
d



âˆ’

,

Î± =



jn
d



,

and thus
Î´(f) = Î±+ Î´(f, Sj+ ) + Î±âˆ’ Î´(f, Sjâˆ’ ) = fm,n (j).
This completes the proof.
24. P ROOF

OF

T HEOREM 4.2

Part (i) follows directly from Lemma 31.8, since we can take Î› = uA Zd where A
is the matrix in question. To prove part (ii), consider the template f that we need to
approxiomate by a successive minima function hA . If Î´(f) > 0, then by Theorem 4.6, the
packing dimension of D(f) is positive and thus D(f) is nonempty. If we take A âˆˆ D(f),
then hA â‰+ f. On the other hand, suppose that Î´(f) = 0, and consider the set
Z = {t â‰¥ 0 : âˆ†(f, t) > 0}
Then the density of Z is zero, i.e. limT â†’âˆ T1 |Z âˆ© [0, T ]| = 0, where | Â· | denotes 1dimensional Lebesgue measure. On the other hand, for all t âˆˆ
/ Z we must have f â€² (t) =
(âˆ’ n1 , . . . , âˆ’ n1 , m1 , . . . , m1 ). It follows that fn (t) < fn+1 (t) for all sufficiently large t. Then
the convexity and quantized slope conditions (see Definition 4.1) imply that Fn must
be piecewise linear with only finitely many intervals of linearity. Now it follows, using

68

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

the fact that Z has zero density, that Fnâ€² (t) = âˆ’1 for all sufficiently large t, which in
turn implies that f(t) â‰+ (âˆ’ n1 , . . . , âˆ’ n1 , m1 , . . . , m1 )t. Now there exist matrices A such that
hA (t) â‰+ (âˆ’ n1 , . . . , âˆ’ n1 , m1 , . . . , m1 )t (for example, matrices with rational entries) and so
this completes the proof.
25. P ROOF

OF

T HEOREM 4.10

A matrix A is badly approximable if and ony if its successive minima function hA is
bounded. Thus, by Theorem 4.6, the Hausdorff dimension of the set of badly approximable matrices is equal to the supremum of Î´ over bounded templates. Since Î´(0) = mn
and Î´(f) â‰¤ mn for all templates f, this supremum is equal to mn.
26. P ROOF

OF

T HEOREM 4.11

Analogously to the uniform dynamical exponent, we define the regular (non-uniform)
dynamical exponent of a map f : [0, âˆ) â†’ Rd to be the number
def

Ï„ (f) = lim sup
tâ†’âˆ

âˆ’1
f1 (t).
t

Now let f be a template with Ï„ (f) = Ï„ âˆˆ [0, n1 ] and consider the potential function
Ï†(t) = Ï†f (t) = mn|f1 (t)|.
Lemma 26.1. Let I be an interval of linearity for f. Then
Ï†â€² (I) â‰¤ mn âˆ’ Î´(I),
with equality in the following cases:
â€¢ f = 0 on I
â€¢ f1â€² = âˆ’ n1 and f2 = fd on I.
Proof. Let j be the largest value such that f1 = fj on I, and let LÂ± = LÂ± (f, I, j). Then


1 Lâˆ’ L+
â€²
âˆ’
Ï† (I) = mn
j n
m
while
mn âˆ’ Î´(I) â‰¥ Lâˆ’ (m âˆ’ L+ ).
So we need to show that
1
[mLâˆ’ âˆ’ nL+ ] â‰¤ Lâˆ’ (m âˆ’ L+ ).
j

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

69

Indeed, since Lâˆ’ â‰¤ n and j â‰¥ 1, we have

1
1
1
[mLâˆ’ âˆ’ nL+ ] â‰¤ [mLâˆ’ âˆ’ Lâˆ’ L+ ] = Lâˆ’ (m âˆ’ L+ ) â‰¤ Lâˆ’ (m âˆ’ L+ ).
j
j
j

Equality holds when L+ = m and Lâˆ’ = n, and when L+ = 0 and Lâˆ’ = 1.

âŠ³

Integrating gives
Ï†(T ) = mn|f1 (T )| â‰¤ T (mn âˆ’ âˆ†(T )).
Dividing by T and then taking the limsup gives
mnÏ„ â‰¤ mn âˆ’ Î´(f).
Rearranging gives
Î´(f) â‰¤ mn(1 âˆ’ Ï„ ).
Thus, by Theorem 4.6, we have
dimH ({Ï‰-approximable matrices}) = sup Î´(f) â‰¤ mn(1 âˆ’ Ï„ ).
f :Ï„ (f )=Ï„

Let us now show the reverse inequality. For each Î» > (1 + Ï„ /m)/(1 âˆ’ Ï„ /n), let fÎ» be
as in Figure 14, i.e. fÎ» is exponentially Î»-periodic and fÎ»,1 is maximal with respect to the
restriction fÎ»,1 (1) = âˆ’Ï„ . Then Ï„ (fÎ» ) = Ï„ , while Î´(fÎ» ) = mn(1 âˆ’Ï„ )/(1 âˆ’Î»âˆ’1 ). So as Î» â†’ âˆ,
we have Î´(fÎ» ) â†’ mn(1 âˆ’ Ï„ ) and the proof is complete.

F IGURE 14. The joint graph of fÎ» as described above.

70

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Part 3. Dimension games
27. P RELIMINARIES

ON MEASURES AND DIMENSIONS

We first recall the basics of Hausdorff and packing measures and dimensions, [7, 28].
Hausdorff measure and dimension were introduced in 1918 by Hausdorff [33], while
packing measure and dimension were introduced by Tricot in 1982 [65]. Sullivan independently re-invented packing measures and dimensions when studying the limit sets of
geometrically finite Kleinian groups in 1984 [64].
The s-dimensional Hausdorff measure of a set A âŠ† RD is
(âˆ
)
âˆ
(U
)
is
a
countable
cover
of
A
X
i
1
def
H s (A) = sup inf
(diam(Ui ))s :
Â·
Îµ>0
with diam(Ui ) â‰¤ Îµ âˆ€i
i=1
Dual to the Hausdorff measure, which is defined via economical coverings by small balls,
it is natural to define a measure in terms of dense packings by small disjoint balls. This
leads to the notion of the s-dimensional packing measure of a set A âŠ† RD , which is defined
as
(âˆ
)
âˆ
X
[
def
fs (Ai ) : A âŠ†
P s (A) = inf
P
Ai ,
i=1

where

def

fs (A) = inf sup
P
Îµ>0

(

âˆ
X

(diam(Bj ))s :

j=1

i=1

)
(Bj )âˆ
1 is a countable disjoint collection of balls
with centers in A and with diam(Bj ) â‰¤ Îµ âˆ€j

Â·

Given the measures defined above, we define the Hausdorff dimension and packing dimension of a set A âŠ† RD as follows:
def

dimH (A) = inf{s : H s (A) = 0} = sup{s : H s (A) = âˆ}
def

dimP (A) = inf{s : P s (A) = 0} = sup{s : P s (A) = âˆ}.
We recall two basic facts (see [28, Â§ 3.2 and Â§ 3.5]) about these dimensions. First, they
are both monotonic, i.e. if E âŠ† F âŠ† RD , then dimH (E) â‰¤ dimH (F ) and dimP (E) â‰¤
dimP (F ). Second, the packing dimension is bounded below by the Hausdorff dimension,
i.e. for F âŠ† RD , we have dimH (F ) â‰¤ dimP (F ).
In the sequel we will apply the following consequence of the Rogersâ€“Taylorâ€“Tricot
density theorem for Hausdorff and packing measures [62, Theorem 2.1], which provides
a method of computing the Hausdorff and packing dimensions of a Borel set in terms of
local geometric-measure-theoretic information. For each point x âˆˆ RD define the lower

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

71

and upper pointwise dimensions of a measure Âµ at x by
def

dimx (Âµ) = lim inf
Ïâ†’0

log Âµ(B(x, Ï))
log Âµ(B(x, Ï))
def
and dimx (Âµ) = lim sup
Â·
log Ï
log Ï
Ïâ†’0

Note that the limits may be replaced by limits over any sequence Ïn â†’ 0 such that Ïn /Ïn+1
is bounded, without affecting the values.
Theorem 27.1. Fix D âˆˆ N and let Âµ be a locally finite Borel measure on RD . Then for every
Borel set A âŠ† RD ,
â€¢
â€¢
â€¢
â€¢

If dimx (Âµ) â‰¥ s for all x âˆˆ A and Âµ(A) > 0, then dimH (A) â‰¥ s.
If dimx (Âµ) â‰¤ s for all x âˆˆ A, then dimH (A) â‰¤ s.
If dimx (Âµ) â‰¥ s for all x âˆˆ A and Âµ(A) > 0, then dimP (A) â‰¥ s.
If dimx (Âµ) â‰¤ s for all x âˆˆ A, then dimP (A) â‰¤ s.

The statement above is closest to [27, Proposition 2.3]. Readers interested in studying
further refinements are referred to Cutlerâ€™s weak and strong duality principles in [18,
Theorems 1.4 and 1.5]. See [49, Â§8] for a self-contained proof of the density theorem for
measures in the setting of metric spaces.
28. A

CHARACTERIZATION OF

H AUSDORFF

AND PACKING DIMENSIONS USING GAMES

Schmidtâ€™s game is a two-player topological game introduced in a seminal paper of
Wolfgang M. Schmidt in 1966 [57] as a technique to analyze Diophantine sets that are
exceptional with respect to both measure and category. Schmidtâ€™s paper led to a plethora
of applications at the interface of dynamical systems, Diophantine approximation and
fractal geometry, which often involve various modifications of his eponymous game. For
a small sample of such research, see [20, 50, 45, 9, 15, 1, 4, 30, 2].
The proof of our variational principle is based on a new variant of Schmidtâ€™s game
which is in principle capable of computing the Hausdorff and packing dimensions of any
Borel set. In Schmidtâ€™s original game, players take turns choosing a descending sequence
of balls and compete to determine whether or not the intersection point of these balls is
in a certain target set. The key feature of our new variant is that instead of requiring the
rate at which the playersâ€™ moves contribute information to the game to be constant, the
new variant allows the rate of information transfer to be variable, with the first player,
Alice, getting to choose the rate of information transfer. However, Alice is penalized if
she exerts too much control over the game over long periods of time without giving her
opponent Bob a chance to exert control over the game.

72

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

F IGURE 15. Three consecutive rounds of the Hausdorff/packing game. On
each round Alice presents Bob with a set of balls to choose between (represented by the set of centers of those balls), and Bob chooses one of the
balls, which are colored/shaded above.
Definition 28.1. Given 0 < Î² < 1 and Î´ > 0, Alice and Bob play the Î´-dimensional
Hausdorff (resp. packing) Î²-game as follows:
â€¢ The turn order is alternating, with the first turn being the 0th turn and Alice
playing first. Thus, Bobâ€™s kth turn occurs after Aliceâ€™s kth turn and before Aliceâ€™s
(k + 1)st turn.
â€¢ Alice begins by choosing a starting radius Ï0 > 0.
â€¢ On the kth turn, Alice chooses a nonempty finite 3Ïk -separated set18 Ak âŠ† RD , and
def
def
Bob responds by choosing a ball Bk = B(xk , Ïk ), where xk âˆˆ Ak and Ïk = Î² k Ï0 .
(We can think of Aliceâ€™s choice Ak as representing the collection of balls {B(x, Ïk ) :
x âˆˆ Ak } from which Bob chooses his ball.)
â€¢ On the 0th turn, there is no further restriction on Aliceâ€™s choice A0 , but on each
subsequent turn (k + 1), she must choose Ak+1 so as to satisfy
(28.1)

Ak+1 âŠ† B(xk , (1 âˆ’ Î²)Ïk ).
Note that this condition guarantees (see Figure 15) that
B0 âŠ‡ B1 âŠ‡ B2 âŠ‡ Â· Â· Â·

After infinitely many turns have passed, the point
(28.2)

xâˆ = lim xk âˆˆ
kâ†’âˆ

âˆ
\

Bk

k=0

is computed (note that the right-hand side is always a singleton). It is called the outcome
of the game. Also, we let A = (Ak )kâˆˆN, and we compute the number
k

(28.3)
18

1 X log #(Ai )
Î´(A) = lim inf
kâ†’âˆ k
âˆ’ log(Î²)
i=0
def

A set A is called Ï-separated if d(x, y) â‰¥ Ï for all distinct x, y âˆˆ A.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

73

resp.
k

(28.4)

1 X log #(Ai )
Î´(A) = lim sup
,
kâ†’âˆ k i=0 âˆ’ log(Î²)
def

which represents Aliceâ€™s score. Aliceâ€™s goal will be to ensure that the outcome is in a
certain set S, called the target set, and simultaneously to guarantee that her score is at
least Î´. To be precise, a set S âŠ† RD is said to be Î´-dimensionally Hausdorff (resp. packing)
Î²-winning if Alice has a strategy to simultaneously ensure that the outcome xâˆ is in S,
and that her score Î´(A) (resp. Î´(A)) is at least Î´. The set S is said to be Î´-dimensionally
Hausdorff (resp. packing) winning if it is Î´-dimensionally Hausdorff (resp. packing) Î²winning for all sufficiently small Î² > 0. (Equivalently, we could say that Aliceâ€™s score is
automatically set equal to zero whenever xâˆ âˆˆ
/ S, in which case we would say that S is
Î´-dimensionally Hausdorff Î²-winning if Alice has a strategy to ensure that her score is at
least Î´.)
The following result is one of the key ingredients in the proof of the variational principle:
Theorem 28.2. The Hausdorff (resp. packing) dimension of a Borel set S âŠ† RD is the
supremum of Î´ such that S is Î´-dimensionally Hausdorff (resp. packing) winning.
Remark 28.3. The theorem remains true (with the same proof) if RD is replaced by any
doubling19 metric space.
A key fact used in the proof is that since S is Borel, the Borel determinacy theorem
[48] implies that for all Î´, Î², the Î´-dimensional Hausdorff and packing Î²-games are determined, meaning that either Alice or Bob has a winning strategy. This follows from
[29, Theorem 3.1], since the games can be viewed as â€œgames played on complete metric spacesâ€ in the language of [29], specifically with X = RD Ã— NN (the latter factor
representing the number of balls that Alice chooses in each step).
Proof. We prove the theorem for the case of Hausdorff dimension; the argument in the
case of packing dimension is nearly identical.
We begin by proving the lower bound. Suppose that S is Î´-dimensionally Hausdorff winning, and we must show that dimH (S) â‰¥ Î´. Fix Î² > 0 such that S is Î´-dimensionally
19

A metric space is doubling if there exists constants C, r0 such that every ball of radius 0 < r â‰¤ r0 can be
covered by at most C balls of radius r/2.

74

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Hausdorff Î²-winning, and consider a strategy for Alice to win the Î´-dimensional Hausdorff Î²-game with target set S. Now for each k â‰¥ 0, let Ek denote the union of all sets Ak
that Alice might choose according to her strategy in response to some possible sequence
of moves that Bob could play, and let Ïk = Î² k Ï0 . Then the set
def

C=

âˆ [
\

B(xk , Ïk )

k=0 xk âˆˆEk

is the set of all possible outcomes of the game when Alice plays her winning strategy. It
is a closed and totally disconnected set, contained entirely in S. Note that by induction
and the restrictions on Aliceâ€™s possible moves, for all k, Ek is 3Ïk -separated.
To bound the Hausdorff dimension of C, we introduce a probability measure on C by
considering the scenario where Alice plays according to her winning strategy and Bob
plays randomly: on the kth turn, Bob chooses the point xk âˆˆ Ak uniformly at random,
independently of all previous choices. This yields a random game whose outcome is
distributed according to some probability measure Âµ on C. Now fix x âˆˆ C, and for each
k â‰¥ 0 let xk âˆˆ Ek be chosen so that x âˆˆ B(xk , Ïk ). Then since Ek is 3Ïk -separated, if Bob
plays in a way such that the final outcome is in B(x, Ïk ), then on the kth turn he must
choose the ball B(xk , Ïk ). It follows that
B(x, Ïk ) âˆ© C âŠ† B(xk , Ïk )
and thus
Âµ(B(x, Ïk )) â‰¤ Âµ(B(xk , Ïk )) =
So the lower pointwise dimension of Âµ at x is
log Âµ(B(x, Ï))
log Ï
log Âµ(B(x, Ïk ))
= lim inf
kâ†’âˆ
log Ïk
log Âµ(B(xk , Ïk ))
â‰¥ lim inf
kâ†’âˆ
log Ïk
Pk
âˆ’ i=0 log #(Ai )
= lim inf
kâ†’âˆ
k log Î² + log Ï0

k
Y
i=0

#(Ai )

!âˆ’1

.

def

dimx (Âµ) = lim inf
Ïâ†’0

(since Ïk = Î² k Ï0 )

= Î´(A) â‰¥ Î´

since Alice is using a winning strategy. Since x âˆˆ C was arbitrary and Âµ(C) = 1, applying
the Rogersâ€“Taylorâ€“Tricot Theorem 27.1 proves the lower bound dimH (S) â‰¥ Î´.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

75

To prove the upper bound, suppose that S is not Î´-dimensionally Hausdorff winning,
and we will show that dimH (S) â‰¤ Î´. Fix 0 < Î² â‰¤ 1/2 small enough so that S is not
Î´-dimensionally Hausdorff Î²-winning. Then Alice does not have a winning strategy for
the Î´-dimensional Hausdorff Î²-game with target set S. Since this game is determined as
we mentioned earlier, we know that Bob must have a winning strategy for it, which we
now fix.
Fix a radius Ï0 > 0, and for each k âˆˆ N
â€¢ let Ek be a maximal 31 Î² k Ï0 -separated subset of RD , and
S
(1)
(p)
(i)
â€¢ let Ek , . . . , Ek be disjoint 3Î² k Ï0 -separated subsets of Ek such that Ek = pi=1 Ek .
Since RD is a doubling metric space (see Footnote 19), it is possible to choose p to be
independent of k and Î². We define a family of strategies for Alice as follows. Consider
the kth turn for some k âˆˆ N, and if k â‰¥ 1 then let Bkâˆ’1 = B(xkâˆ’1 , Ïkâˆ’1 ) be the move that
Bob just played. Let
ï£±
ï£²B(x , (1 âˆ’ Î²)Ï ) k â‰¥ 1
kâˆ’1
kâˆ’1
e
Bkâˆ’1 =
,
ï£³B(0, Îº + Ï0 )
k=0
where Îº > 0 is a large constant. Next let
ekâˆ’1 ,
Xk = Ek âˆ© B
(i)

(i)

(i)

(i,j)

From then on, we define the moves Ak
(i,j)

â€¢ if Ak

(i)

Nk = #(Xk ),
(i,j)

and Bk

(i)

(i,Nk )

Ak

(i)

= Xk .

by backwards recursion as follows:

is defined for some j â‰¥ 1, then
(i,j)

Bk

(i,j)

= B(xk , Ïk )
(i,j)

is Bobâ€™s response if Alice plays Ak .
(i,j)
(i,j)
(i,j)
â€¢ if Ak and Bk = B(xk , Ïk ) are both defined for some j â‰¥ 1, then
(i,jâˆ’1) def

Ak
(i,j)

(i,j)

= Ak

(i,j)

\ {xk }.

(i)

Note that #(Ak ) = j for all j = 0, . . . , Nk .
Now consider the scenario where Bob plays according to his winning strategy and Alice
(i ,j )
plays randomly: on the kth turn, Alice chooses a move Ak k k where the integers ik and
jk are chosen independently of previous choices i1 , i2 , . . . , ikâˆ’1 and j1 , j2 , . . . , jkâˆ’1 of with
respect to a probability distribution satisfying
(28.5)

P(ik = i, jk = j) â‰¥ cj âˆ’(1+Îµ) ,

76

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

where Îµ > 0 is fixed and c > 0 is a constant depending on Îµ and p. By the Kolmogorov
extension theorem, this yields a random sequence of plays whose outcome is distributed
according to some probability measure Âµ on RD .
Ï .
Now fix x âˆˆ Sâˆ©B(0, Îº). For each k âˆˆ N, there exists xk âˆˆ Ek such that d(x, xk ) â‰¤ 1âˆ’Î²
1+Î² k
Note that x0 âˆˆ B(0, Îº + Ï0 ), and xk+1 âˆˆ B(xk , (1 âˆ’ Î²)Ïk ) for all k. It follows that Alice
(I ,J )
can guarantee that the outcome is equal to x by playing the move Ak = Ak k k on the
kth turn for some sequences of integers (Ik )kâˆˆN, (Jk )kâˆˆN. Since Bobâ€™s strategy is winning
and x âˆˆ S, it follows Aliceâ€™s score is less than Î´, i.e.
Î´(A) < Î´.
Let G1 denote the sequence of plays described above, and let G2 be a sequence of plays
(i ,j )
where on the kth turn, Alice chooses a set Ak k k , and Bob responds according to his
winning strategy, such that ik = Ik and jk = Jk for all k âˆˆ {0, . . . , â„“}. Then the â„“th ball of
G2 is equal to the â„“th ball of G1 , and thus the outcome of G2 is within 2Ïâ„“ of the outcome
of G1 , i.e. x. Thus if we think of G2 as being chosen randomly, then


Âµ B(x, 2Ïâ„“ ) â‰¥ P ik = Ik , jk = Jk âˆ€k â‰¤ â„“
â‰¥

â„“
Y

âˆ’(1+Îµ)

cJk

k=0

= câ„“ exp âˆ’(1 + Îµ)
and so
dimx (Âµ) = lim inf
â„“â†’âˆ

â„“
X

log #(Ak )

k=0

!

log Âµ(B(x, 2Ïâ„“ ))
log(2Ïâ„“ )

P
â„“ log(c) + (1 + Îµ) â„“k=0 âˆ’ log #(Ak )
â‰¤ lim inf
â„“â†’âˆ
â„“ log Î² + log(2Ï0 )
log(c)
=
+ (1 + Îµ)Î´(A)
log(Î²)
log(c)
<
+ (1 + Îµ)Î´.
log(Î²)
Since x âˆˆ S was arbitrary, applying the Rogersâ€“Taylor Theorem 27.1 again yields
dimH (S) â‰¤
Letting Î², Îµ â†’ 0 completes the proof.

log(c)
+ (1 + Îµ)Î´.
log(Î²)



A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

29. P LAYING

GAMES WITH

D IOPHANTINE

77

TARGETS

In practice, when we play the Hausdorff or packing game with a target set defined in
terms of the parametric geometry of numbers, it is helpful to use a different formalism to
encode Alice and Bobâ€™s moves. First of all, note that for each k, the ball Bk = B(xk , Ïk ) is
homeomorphic to the unit ball B(0, 1) via the similarity transformation
Tk (z) = xk + Ïk z.
By replacing Ak+1 and xk+1 by their preimages under Tk , and leaving A0 and x0 the same,
we can see that we can make the following changes to the rules of the Î´-dimensional
Hausdorff (resp. packing) Î²-game without affecting the existence of winning strategies
for either player:20
â€¢ For k â‰¥ 1, instead of requiring that Aliceâ€™s choice Ak is 3Ïk -separated, we require
that it is 3Î²-separated.
â€¢ Instead of (28.1), Alice must choose Ak+1 to satisfy
Ak+1 âŠ† B(0, 1 âˆ’ Î²).

(29.1)

â€¢ The outcome of the game, instead of being computed by (28.2), is computed by
the formula
âˆ
X
def
Î² k Ïâˆ’1 xk ,
(29.2)
xâˆ = x0 +
k=1

def

where Ïâˆ’1 = Î² âˆ’1 Ï0 (using the definition of Ïk in Definition 28.1).
We will call the version of the Hausdorff (resp. packing) game resulting from these rule
changes the modified Hausdorff (resp. packing) game. It will be the version we use in the
proof of Theorem 4.6 (Variational principle, version 2) in Part 4.
Let D = mn in Section 28, and let us identify RD with M, the space of m Ã— n matrices
with real entries. Further, we will assume that the target set is of the form (recalling
notation from below Theorem 4.2)
[
[
S = D(S) =
D(f) =
{A âˆˆ M : hA â‰+ f}
f âˆˆS

f âˆˆS

for some collection S of functions from [0, âˆ) to Rd closed under finite perturbations
(i.e. if whenever f âˆˆ S and g â‰+ f, we have g âˆˆ S). In this case, we can track the
â€œprogressionâ€ of the game by associating a unimodular lattice to each turn of the game.
20

ek and x
ek are related to the analogous moves Ak and xk in the
The moves in the new modified game A
P
ek and xk = x0 + k Î² i Ïâˆ’1 x
ei .
original game via the formulas Ak = xkâˆ’1 + Ïkâˆ’1 A
i=1

78

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Specifically, for each k â‰¥ 0 let
k

(29.3)

def

m+n

Î›k+1 = gâˆ’Î± log(Î² k+1 Ïâˆ’1 ) uYk Z

X
mn
def
, where Î± =
and Yk = X0 +
Î² i Ïâˆ’1 Xi .
m+n
i=1
def

Here, we use uppercase letters (X, Y ) instead of bold letters (x, y) because we are working with matrices rather than with vectors. Then for k â‰¥ 1, Î›k and Î›k+1 are related by
the formula
Î›k+1 = gâˆ’Î± log(Î²) uXk Î›k .

(29.4)
This is because

uX gâˆ’Î± log(Î») = gâˆ’Î± log(Î») uÎ»X for all Î», X.

(29.5)

Notation 29.1. To simplify the notation in (29.4), we let
def

def

Î³ = âˆ’ Î± log(Î²) > 0,

g = gÎ³ ,

so that
Î›k+1 = guXk Î›k .
Intuitively, this means that Î›k is well-defined at the start of turn k, and that Alice and
Bobâ€™s choices on turn k can be thought of as a process of choosing Î›k+1 indirectly by
choosing Xk .
The significance of the sequence of lattices (Î›k )âˆ
1 is given by the following lemma:
Lemma 29.2. Let j : [0, âˆ) â†’ Rd be the function defined on Î³Z by the formula
def

j(kÎ³) = h(Î›k )
and extended to [0, âˆ) via linear interpolation. Then
j â‰+ hXâˆ
where Xâˆ is as in (29.2). In particular, Xâˆ âˆˆ D(S) if and only if j âˆˆ S.
Here we use the notation
def

h(Î›) = (log Î»1 (Î›), . . . , log Î»d (Î›)).
Proof. Fix k, and write
def

Zk =

âˆ
X

Î² i Xk+i .

i=0

Then

uZk Î›k = gâˆ’Î± log(Ïâˆ’1 )+kÎ³ uXâˆ Zm+n .

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

79

Since Zk âˆˆ B(0, 1), this implies that
f(kÎ³) = h(Î›k ) â‰+ h(uZk Î›k ) = h(gâˆ’Î± log(Ïâˆ’1 )+kÎ³ uXâˆ Zm+n ) = hXâˆ (âˆ’Î± log(Ïâˆ’1 ) + kÎ³)
and thus f â‰+ hXâˆ . Since S is closed under finite perturbations, it follows that f is in S

if and only if hXâˆ is, i.e. if and only if Xâˆ âˆˆ D(S).
Part 4. Proof of the variational principle
def P
Throughout Part 4, k Â· k denotes the Euclidean norm, i.e. kxk2 = i x2i . This is allowed
since the variational principle (Theorem 4.6) is independent of the choice of norm. In
def
certain places we will use the max norm, i.e. kxkâˆ = maxi |xi |.

30. P RELIMINARIES
This section collects various notation and lemmata employed in our proof of the variational principle, viz. Theorem 4.6. Though some of these results may be considered
elementary by experts familiar with the geometry of numbers, we include such for the
benefits of self-containment. Thus, for instance, we begin by recalling Minkowskiâ€™s second theorem on successive minima for the readerâ€™s convenience.
Theorem 30.1 (Minkowski, [14, Theorem V in Â§VIII.4.3]). Let Î› be a lattice in a vector
space V âŠ† Rd . Then
dim(V )
Y
Î»j (Î›) â‰ kÎ›k,
j=1

where kÎ›k denotes the covolume of Î›, and Î»j (Î›) is the jth minimum of Î› with respect to
the unit ball of V .
Definition 30.2. Let Î› âŠ† Rd be a lattice. A subspace V âŠ† Rd is called Î›-rational if V âˆ© Î›
is a lattice in V . Denote the set of all q-dimensional Î›-rational subspaces of Rd by Vq (Î›).

Notation 30.3. If V is a Î›-rational subspace of Rd , we denote the covolume of V âˆ© Î› in
V , with respect to the Euclidean metric on V inherited from Rd , by kV k. Although this
notation is misleading since kV k depends on Î› and not just on V , in practice this should
not be a problem as it should generally be clear what Î› is (for instance, if V is Î›-rational,
then gV is gÎ›-rational, so we can take kgV k to be the covolume of g(V âˆ© Î›)).
Notation 30.4. We denote the subspace of Rd contracted by the (gt ) flow (defined in Â§
3.1) by L, i.e.
def
L = {0} Ã— Rn .

80

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

The conical Îµ-neighborhood of a subspace V âŠ† Rd will be denoted
C(V, Îµ) = {r : d(r, V ) â‰¤ Îµkrk}
where d denotes infimal distance. Given 0 < Î² < 1 in the definition of the Î´-dimensional
Hausdorff (resp. packing) Î²-game (see Definition 28.1), and following Notation 29.1 and
(29.3) from Section 29, we write
mn
Î³=âˆ’
log(Î²),
g = gÎ³ .
m+n
Following Definition 4.1, we write
Fq =

q
X

fi .

i=1

The following lemmas will be used in the proof of Theorem 4.6.
Lemma 30.5. Let Î› â‰¤ Rd be a lattice. Then there exists a basis {r1 , . . . , rd } of Î› such that
P
if Vq = qi=1 Rri , then
q
X
log Î»i (Î›).
log kVq k â‰+
i=1

Moreover,

log kri k â‰+ log Î»i (Î›) for all i.

(30.1)

Proof. Let {r1 , . . . , rd } be a Minkowski reduced basis of Î› (see [34, Proposition 5.3]).
Now let h be the change of basis matrix changing {e1 , . . . , ed } into {r1 , . . . , rd } and write
h = kan where k âˆˆ SO(d), a is a diagonal matrix, and n is an upper triangular matrix.
Since {r1 , . . . , rd } is a Minkowski reduced basis, n is bounded and thus g = k(anaâˆ’1 ) is
also bounded. Note that ri = gaei for all i. Then for all i,
kri k â‰ ai = Î»i (aZd ) â‰ Î»i (gaZd ) = Î»i (Î›).
On the other hand, for each q = 1, . . . , d, we have
log kVq k â‰+ log kaEq k = log(a1 . . . aq ) =
where Eq =

Pq

i=1

Rei .

q
X
i=1

log(ai ) â‰+

q
X

log Î»i (Î›),

i=1



Lemma 30.6. Let Î› â‰¤ Rd be a lattice, and let Vq be as in Lemma 30.5. Then
(30.2)

log kVqâ€² k

&+

qâˆ’1
X
i=1

log Î»i (Î›) + log Î»q+1 (Î›) for all Vqâ€² âˆˆ Vq (Î›) \ {Vq }.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

81

Proof. Fix Vqâ€² âˆˆ Vq (Î›) \ {Vq }. By Minkowskiâ€™s second theorem (Theorem 30.1), we have
(30.3)

log kVqâ€² k

â‰+

For all i = 1, . . . , q âˆ’ 1, we have
(30.4)

q
X
i=1

Î»i (Î› âˆ© Vqâ€² ).

Î»i (Î› âˆ© Vqâ€² ) â‰¥ Î»i (Î›).

For the i = q term, we use a different argument to get a better bound. Let E (resp. E â€² )
be a spanning set for Î› âˆ© Vq (resp. Î› âˆ© Vqâ€² ). Then E âˆª E â€² is a spanning set for Î› âˆ© (Vq + Vqâ€² ).
Since dim(Vq + Vqâ€² ) â‰¥ q + 1, it follows that
max krk â‰¥ Î»q+1 (Î›).

râˆˆEâˆªE â€²

Taking the infimum over all E, E â€² gives

max Î»q (Î› âˆ© Vq ), Î»q (Î› âˆ© Vqâ€² ) â‰¥ Î»q+1 (Î›).

On the other hand, it follows from (30.1) that Î»q (Î› âˆ© Vq ) â‰+ Î»q (Î›) â‰¤ Î»q (Î› âˆ© Vqâ€² ). Thus,
Î»q (Î› âˆ© Vqâ€² ) &+ Î»q+1 (Î›).
Combining with (30.3) and (30.4) yields (30.2).


def

Lemma 30.7. Recall that d+ = m and dâˆ’ = n. Fix LÂ± âˆˆ [0, dÂ± ] âˆ© Z and let q = L+ + Lâˆ’ .
Let Î› be a lattice and let V be a q-dimensional Î›-rational subspace such that
Lâˆ’ â‰¥ sup dim(uY V âˆ© L).
kY kâ‰¤Î²

Then for all t â‰¥ 0,
(30.5)

log kgt V k âˆ’ log kV k &+,Î²



L+ Lâˆ’
âˆ’
m
n



t.

The reverse inequality holds if dim(V âˆ© L) = Lâˆ’ .
Proof. Define a linearly independent sequence (ri )k1 in V recursively as follows: if ri =
(pi , qi ) âˆˆ V has been defined for i = 1, . . . , j, then let
def

rj+1 = (pj+1 , qj+1) âˆˆ Wj = V âˆ©

j
\

(pi , 0)âŠ¥

1

be chosen so that kpj+1 k â‰¥ Î²kqj+1k. Continue until it is not possible to continue further;
then for all r = (p, q) âˆˆ Wk , we have kpk â‰¤ Î²kqk. It follows that there exists kY k â‰¤ Î²

82

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

such that uY Wk âŠ† L, which implies that
q âˆ’ k = dim(Wk ) = dim(uY Wk ) â‰¤ dim(uY V âˆ© L) â‰¤ Lâˆ’ .
Rearranging gives k â‰¥ L+ . Finally, let (ri )qk+1 be an arbitrary basis of Wk . Then there
exists a constant Î± > 0 such that
kV k = Î±kr1 âˆ§ Â· Â· Â· âˆ§ rq k
and
kgt V k = Î±kgt r1 âˆ§ Â· Â· Â· âˆ§ gt rq k.
In particular
kV k â‰¤ Î±kr1 k Â· Â· Â· krk k Â· krk+1 âˆ§ Â· Â· Â· âˆ§ rq k .Î² Î±kp1 k Â· Â· Â· kpk k Â· krk+1 âˆ§ Â· Â· Â· âˆ§ rq k
while
kgt V k = Î±ket/m [(p1 , 0) + oÎ² (kp1 k)] âˆ§ Â· Â· Â· âˆ§ et/m [(pk , 0) + oÎ² (kpk k)] âˆ§ gt rk+1 âˆ§ Â· Â· Â· âˆ§ gt rq k.
Since (pi )k1 are orthogonal to each other and also to rk+1 , . . . , rq , it follows that if t is
sufficiently large in comparison to Î² we have
kgt V k & Î±ekt/m kp1 k Â· Â· Â· kpk k Â· kgt rk+1 âˆ§ Â· Â· Â· âˆ§ gt rq k

& Î±ekt/m kp1 k Â· Â· Â· kpk k Â· eâˆ’(qâˆ’k)t/n krk+1 âˆ§ Â· Â· Â· âˆ§ rq k
&Î² ekt/mâˆ’(qâˆ’k)t/n kV k.

Since k â‰¥ L+ , this completes the proof of (30.5).
Now suppose dim(V âˆ© L) = Lâˆ’ , and we will show that the reverse inequality of (30.5)
L
holds. Let (ri )1 âˆ’ be an orthonormal basis of V âˆ© L, and extend to an orthonormal basis
(ri )q1 of V . Then
kgt V k
â‰ kgt r1 âˆ§ Â· Â· Â· âˆ§ gt rq k
kV k
. kgt r1 k Â· Â· Â· kgt rq k

â‰¤ (eâˆ’t/n kr1 k) Â· Â· Â· (eâˆ’t/n krLâˆ’ k)(et/m krLâˆ’ +1 k) Â· Â· Â· (et/m krq k)

 
L+ Lâˆ’
â‰ exp
t .
âˆ’
m
n
This completes the proof.



A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

83

We finish with an elementary observation about the slopes of line segments appearing
in templates (see Definition 4.1) that is used in proving Lemma 31.14, which in turn is
needed in the proof of the lower bound of the variational principle.
Observation 30.8. If f is a template then for all t â‰¥ 0 we have
fjâ€² (t) âˆ’ fiâ€² (t) âˆˆ 1q Z for some q â‰¤ mnd2 .
Proof. For all i, t we have
fiâ€² (t) =

p
mnq

for some p âˆˆ Z and q = 1, . . . , d. So we have
p2
p1
p
fjâ€² (t) âˆ’ fiâ€² (t) =
âˆ’
=
mnq2 mnq1
mnq1 q2
and we have mnq1 q2 â‰¤ mnd2 .
31. P ROOF


OF

T HEOREM 4.6,

LOWER BOUND

Let f be a template. We must show that
(31.1)

dimH (D(f)) â‰¥ Î´(f),

dimP (D(f)) â‰¥ Î´(f).

To this end, we will play the modified Hausdorff and packing games with target set
S = D(f). It turns out that the same strategy will work for Alice in both games.
The proof can be divided into four basic stages:
1. Reduction: We can without loss of generality assume that the template f appearing
in the statement of the theorem is in a special form which is convenient to the later
argument.
2. Mini-strategy: For any template g (not necessarily the same as the f appearing in the
theorem), Alice can guarantee that if A is the outcome of the game, then the successive
minima function hA remains close to g for a certain interval of time before diverging
from it. This interval can be an interval of linearity of g, or the union of any fixed
number of intervals of linearity. However, the upper bound on |hA âˆ’ g| rapidly grows
as the allowed number of intervals of linearity increases.
3. Error correction: If the value of the successive minima function hA at a certain time t
is slightly off from the value of f at t, then we can perturb f into a partial template g
such that g(t) = hA (t). Alice can then follow the perturbed template g rather than the
original template f.
4. Uniform error bounds: The error correction techniques from stage (3) are sufficient to
guarantee that the final successive minima function hA remains a bounded distance

84

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

from the desired template f, and that the inequalities Î´(A) â‰¥ Î´(f) âˆ’ Îµ and Î´(A) â‰¥
Î´(f) âˆ’ Îµ are satisfied.
Stage 2 is in some sense the most important one because it makes the connection
between the parametric geometry of numbers and the theory of templates. In the other
stages, for the most part we do not deal with parametric geometry of numbers directly.
31.1. Reduction. There are two key features we would like to assume of our template
f: its corner points21 should be appropriately spaced, and each corner point should have
only one â€œpurposeâ€.
Definition 31.1. Given Î· > 0, a template f is Î·-integral if
(I) its corner points are multiples of Î·, and
Î·
Z for all 1 â‰¤ i â‰¤ d.
(II) for all t âˆˆ Î·N we have fi (t) âˆˆ mnd!
By the quantized slope condition (see Definition 4.1) it suffices to check (II) for t = 0.
Definition 31.2 (Cf. Figure 16). Let f be a template, let t > 0 be a corner point of f, and
let Iâˆ’ , I+ be the two intervals of linearity for f such that Iâˆ’ = (tâˆ’ , t) and I+ = (t, t+ ) for
some tâˆ’ < t < t+ .
â€¢ We call t a split (resp. merge) if there exists q = 1, . . . , d âˆ’ 1 such that fq (t) =
fq+1 (t), but fq < fq+1 on I+ (resp. on Iâˆ’ ).
â€¢ We call t a transfer if there exists q = 1, . . . , d âˆ’ 1 such that fq (t) < fq+1 (t) and
L+ (f, I+ , q) > L+ (f, Iâˆ’ , q) (equiv. Fqâ€² (I+ ) > Fqâ€² (Iâˆ’ )).
Finally, we call the template f simple if the sets of splits, merges, and transfers are pairwise
disjoint.
Remark 31.3. In any template, every corner point is either a split, a merge, or a transfer.
We now show that we can assume without loss of generality that the template f appearing in the statement of Theorem 4.6 is both simple and integral.
Lemma 31.4. For every Î· > 0 and for every template f, there exists a simple Î·-integral
template g which approximates f to within an additive constant, i.e. satisfies g â‰+ f. The
implied constant depends on Î· but not on f. Moreover, g can be chosen so that for all q, t, tâ€²
such that gq (t) < gq+1 (t) and |tâ€² âˆ’ t| â‰¤ Î·, we have fq+1 (tâ€² ) âˆ’ fq (tâ€² ) â‰¥ Î· and Gâ€²q (t) â‰¥ Fqâ€² (tâ€² ).
Consequently,
(31.2)
21

Î´(g) â‰¥ Î´(f),

I.e. points where the derivative of f is undefined.

Î´(g) â‰¥ Î´(f).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

t0

t1

t2

t3 t4

85

t5

F IGURE 16. In this figure of a portion of an arbitrary 1 Ã— 2 template, the
corner points t0 and t2 are splits, t1 and t5 are merges, and t3 and t4 are
transfers.

Proof. Since a similar argument will be needed for the proof of the upper bound of Theorem 4.6 (specifically, showing that a successive minima function can always be approximated by a template (cf. Lemma 31.8 below)), we prove this lemma in slightly greater
generality than may appear to be necessary. Fix Î· > 0, and let f : [0, âˆ) â†’ Rd be a map
(not necessarily a template) satisfying the following conditions:
(I) f1 â‰¤ Â· Â· Â· â‰¤ fd .
(II) For all t1 < t2 and i = 1, . . . , d we have
âˆ’

fi (t2 ) âˆ’ fi (t1 )
1
1
â‰¤
â‰¤ Â·
n
t2 âˆ’ t1
m

(III) For all q = 1, . . . , d and for every interval I such that
(31.3)

fq+1 > fq on I,

86

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

there exists a convex, piecewise linear function Fq,I : I â†’ R with slopes in Z(q) (cf.
(4.2)) which satisfies
def

Fq =

(31.4)

q
X
i=1

and if f is a template, then

fi â‰+ Fq,I on I

â€²
Fq,I
â‰¥ Fqâ€² on I.

(31.5)

Note that any template satisfies these conditions (and in fact, one can take Fq,I = Fq in
(III)).
Let Î´âˆ— = d Â· (d2 )!Î· âˆˆ Î·N, and let Î´âˆ—âˆ— = mnd4d Î´âˆ— . Fix q = 1, . . . , d, and let Iq be the
collection of all intervals satisfying (31.3) whose endpoints are in Î´âˆ—âˆ— N âˆª {âˆ}, and which
are maximal with respect to these two properties. For each I âˆˆ Iq , let Fq,I : I â†’ R be a
convex, piecewise linear function as in (III).
By first moving the corner points of Fq,I to the left and then increasing Fq,I by an
additive constant, we may without loss of generality suppose that the following hold:
(IV) the corner points of Fq,I are all integer multiples of Î´âˆ—âˆ— ; and
(V) the values of Fq,I at integer multiples of Î´âˆ—âˆ— are all in the set (d4(dâˆ’q) + d4d Z)Î´âˆ— .
(The displacement term d4(dâˆ’q) will help us guarantee that the resulting template
g is simple.)
1
Z for all q, to ensure that the conditions are
Here, we have used the fact that Z(q) âŠ† mn
not inconsistent. Moving the corner points to the left rather than to the right guarantees
that (31.5) is still satisfied. We can also assume that Fd,Iâˆ— â‰¡ 0, where Iâˆ— = [0, âˆ) is the
unique element of Id .

Claim 31.5. There exist collections of intervals Ieq and functions Feq,Ie satisfying (III)-(V) and
the following: For all 1 â‰¤ q1 < q2 â‰¤ d, I1 âˆˆ Ieq1 , and I2 âˆˆ Ieq2 , we have

(31.6)

âˆ’

Feqâ€² ,I âˆ’ Feqâ€²1 ,I1
1
1
â‰¤ 2 2
â‰¤
on I1 âˆ© I2 .
n
q2 âˆ’ q1
m

Proof. Fix a constant C2 > 0 to be determined, and let C1 = 2d2 C2 . Let Jq = {I âˆˆ Iq :
S S
|I| > C1 } and S = q IâˆˆJq Sq,I âˆ© I, where Sq,I is the set of corner points and end points
of Fq,I . Let Ïƒ : S â†’ S be defined as follows: Ïƒ(t) is the smallest element of S that can be
reached from t by jumps of size â‰¤ C2 , and if the right endpoint of I can be reached from
t by jumps of size â‰¤ C2 , then let Ïƒ(t) be the right endpoint of I. For each q = 1, . . . , d and
I âˆˆ Jq , let Feq,I be a piecewise linear function which is equal to Fq,I at the left endpoint

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

87

of I, such that if (a, b) âŠ† I is a maximal interval of linearity for Fq,I of slope z, then
(Ïƒ(a), Ïƒ(b)) is a maximal interval of linearity for Feq,I of slope z.
We claim that |Ïƒ(a) âˆ’ a| â‰¤ C1 for all a âˆˆ S. Indeed, otherwise there exist points
t0 < . . . < t2d2 in S such that ti+1 âˆ’ti â‰¤ C2 for all i. By the pigeonhole principle there exists
S
q = 1, . . . , d such that #( IâˆˆJq Sq,I âˆ© [t0 , t2d2 ]) â‰¥ 2d + 1. Since #(Sq,I ) â‰¤ #(Z(q)) + 1 =
min(q, d âˆ’ q) + 1 â‰¤ d for all I âˆˆ Iq , applying the pigeonhole principle again shows that
there exist at least 3 intervals I âˆˆ Jq such that I âˆ© [t0 , t2d2 ] 6= . But then the middle
interval is a subset of [t0 , t2d2 ], which contradicts I âˆˆ Jq , since t2d2 âˆ’ t0 â‰¤ 2d2 C2 = C1 . It
follows that Feq,I â‰+ Fq,I for all q, I. Thus, (31.4) holds with F replaced by Fe. Moreover,
since Ïƒ(S) âŠ† S âŠ† Î´âˆ—âˆ— Z, condition (IV) holds for Fe. Also, by translating each Feq,I by a
constant if necessary, we can without loss of generality assume that condition (V) holds
for Fe.
Finally, we need to show that (31.6) holds for Fe. Indeed, let (Ïƒ(a), Ïƒ(b)) âŠ† I1 âˆ© I2 be a
maximal interval of linearity for Feq,I2 âˆ’ Feq,I1 . Since Ïƒ(a) < Ïƒ(b), we have b âˆ’ a â‰¥ C2 . Let
k = q2 âˆ’ q1 . Then by condition (II) we have
q2
X
k
fi (b) âˆ’ fi (a)
k
â‰¤
âˆ’ â‰¤
n i=q +1
bâˆ’a
m
1

and thus if z is the constant value of Fqâ€²2 ,I2 âˆ’ Fqâ€²1 ,I1 on (a, b), then
âˆ’

k
k 4C3
4C3
â‰¤zâ‰¤
âˆ’
+
n
C2
m
C2

1
where C3 is the implied constant of (31.4). On the other hand, we have z âˆˆ mn
Z by
condition (III). So if we choose C2 > 4mnC3 , then we get âˆ’k/n â‰¤ z â‰¤ k/m, completing
the proof.
âŠ³

Next, let Fq,âˆ— : [0, âˆ) â†’ R âˆª {âˆ—} be defined by the formula
ï£±
ï£²Fe (t) if t âˆˆ I for some I âˆˆ Ie
q,I
q
Fq,âˆ— (t) =
ï£³âˆ—
otherwise,

and let Gq,âˆ— (t) = Fq,âˆ— (t) + q(d âˆ’ q)C4 , where C4 âˆˆ d4d Î´âˆ— N is large to be determined. Let
G0,âˆ— (t) = 0 âˆˆ (d4(dâˆ’0) +d4d Z)Î´âˆ— for all t, and note that Gd,âˆ— (t) = Î´âˆ— for all t by our condition
on Fd,Iâˆ— . In what follows we let âˆ— + x = âˆ— + âˆ— = âˆ—.
At this point, the intuitive idea is to try to define the template g by solving the equations
ï£±
ï£²Pq g (t) if g (t) < g (t)
q
q+1
i=1 i
(31.7)
Gq,âˆ— (t) =
ï£³âˆ—
if gq (t) = gq+1 (t).

88

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

However, the formula (31.7) is not necessarily solvable with respect to g, due to the fact
that the natural candidate for a solution does not necessarily satisfy g1 (t) â‰¤ Â· Â· Â· â‰¤ gd (t).
To address this issue, we introduce the concept of the convex hull function of a set:
Definition 31.6. The convex hull function of a set Î“ âŠ† R2 is the largest convex function
h : I â†’ R such that h(x) â‰¤ y for all (x, y) âˆˆ Î“, where I is the smallest interval containing
the projection of Î“ onto the first coordinate.

F IGURE
17. The
convex
hull
function
h
of
the
set
{(0, 0), (1, âˆ’1), (2, 1), (4, 0)}. Since 1 > h(2) = âˆ’2/3, the convex hull
function does not change when the point (2, 1) is removed.
We can now define g via the formula
gq (t) = ht (q) âˆ’ ht (q âˆ’ 1),
where ht : [0, d] â†’ R is the convex hull function of the set
Î“(t) = {(q, Gq,âˆ—(t)) : q = 0, . . . , d, Gq,âˆ— (t) 6= âˆ—}.
To complete the proof, we must show
â€¢ that g = (g1 , . . . , gd ) is a simple Î·-integral template,
â€¢ that g â‰+ f,
â€¢ that if f is a template, then for all q, t, tâ€² such that gq (t) < gq+1(t) and |tâ€² âˆ’ t| â‰¤ Î·,
we have fq+1 (tâ€² ) âˆ’ fq (tâ€² ) â‰¥ Î· and Gâ€²q (t) â‰¥ Fqâ€² (tâ€² ), and consequently (31.2) holds.
Claim 31.7. For all q = 1, . . . , d âˆ’ 1 and t â‰¥ 0 such that Gq,âˆ— (t) = âˆ—, we have fq (t) â‰+
fq+1 (t).
Proof. Let t âˆˆ I = (kÎ·, (k + 2)Î·) for some k âˆˆ N. If (31.3) holds, then there exists J âˆˆ Iq
such that I âŠ† J, which contradicts Gq,âˆ— (t) = âˆ—. Thus (31.3) does not hold, and so there
exists tâ€² âˆˆ I such that fq (tâ€² ) = fq+1 (tâ€² ). By condition (II), this implies fq (t) â‰+ fq+1 (t).
âŠ³
We next show that g is continuous. From this it is easy to see that it is piecewise linear,
the first step to proving that it is a template. Fix t > 0, and write h(tÂ± ) = limsâ†’tÂ± h(s).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

89

Let
Î“(tÂ± ) = limÂ± Î“(s) = {(q, Gq,âˆ—(tÂ± )) : q = 0, . . . , d, Gq,âˆ— (tÂ± ) 6= âˆ—}.
sâ†’t

We need to show that Î“(tâˆ’ ) and Î“(t+ ) have the same convex hull function. For this
purpose, it suffices to show that any point in one of these sets but not the other is not an
element of the graph of the corresponding convex hull function (which implies that the
convex hull function does not change when the point is removed).
Indeed, fix q = 1, . . . , dâˆ’1 and suppose that Gq,âˆ—(t+ ) 6= âˆ— but Gq,âˆ— (tâˆ’ ) = âˆ—. Let 0 â‰¤ p < q
and d â‰¥ r > q be maximal and minimal, respectively, such that Gp,âˆ—(t+ ), Gr,âˆ— (t+ ) 6= âˆ—.
Then by Claim 31.7 we have
fp+1 (t) â‰+ . . . â‰+ fq (t) â‰+ fq+1 (t) â‰+ . . . â‰+ fr (t)
and thus by (31.4),
Fr,âˆ— (t+ ) âˆ’ Fq,âˆ— (t+ )
Fq,âˆ— (t+ ) âˆ’ Fp,âˆ— (t+ )
â‰+ fq (t) â‰+ fq+1 (t) â‰+
Â·
qâˆ’p
râˆ’q

It follows that


r(d âˆ’ r) âˆ’ q(d âˆ’ q) q(d âˆ’ q) âˆ’ p(d âˆ’ p)
Gr,âˆ— (t+ ) âˆ’ Gq,âˆ— (t+ ) Gq,âˆ— (t+ ) âˆ’ Gp,âˆ— (t+ )
C4
âˆ’
â‰+
âˆ’
râˆ’q
qâˆ’p
râˆ’q
qâˆ’p
= âˆ’(r âˆ’ p)C4 â‰¤ âˆ’2C4 .

So if C4 is sufficiently large, then
Gr,âˆ— (t+ ) âˆ’ Gq,âˆ—(t+ )
Gq,âˆ— (t+ ) âˆ’ Gp,âˆ—(t+ )
<
râˆ’q
qâˆ’p

i.e. the slope of the line from (q, Gq,âˆ—(t+ )) to (r, Gr,âˆ— (t+ )) is less than the slope of the line
from (p, Gp,âˆ—(t+ )) to (q, Gq,âˆ— (t+ )). It follows that (q, Gq,âˆ—(t+ )) lies above the graph of the
convex hull function of Î“(t+ ). Since q was arbitrary, this shows that Î“(tâˆ’ ) and Î“(t+ ) have
the same convex hull function. Thus g(tâˆ’ ) = g(t+ ), and g is continuous at t.
We next demonstrate that g satisfies conditions (I)-(III) of Definition 4.1. (I) follows
from the fact that convex hull functions are convex, while (II) follows from Claim 31.5.
To demonstrate (III), fix q = 1, . . . , d and let I be an interval of linearity for g such that
gq < gq+1 on I. Fix t âˆˆ I. Since ht (q) âˆ’ ht (q âˆ’ 1) < ht (q + 1) âˆ’ ht (q) (with the convention
ht (d + 1) = +âˆ), the point (q, ht (q)) is an extreme point of the convex hull of Î“(t) and
thus (q, ht (q)) âˆˆ Î“(t), i.e. Gq,âˆ— (t) = ht (q). It follows that
(31.8)

q
X
i=1

gi = Gq,âˆ— on I.

90

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Since Gq,âˆ— â†¿ I is convex and piecewise linear with slopes in Z(q), it follows that the same
P
is true for q1 gi â†¿ I. Thus, g is a template.
To show that g is simple and Î·-integral, we first observe that by construction, all transfers occur at integer multiples of Î´âˆ—âˆ— . Let t be a split or a merge with corresponding index
q. Then (q, Gq,âˆ—(s)) is an extreme point of the convex hull of Î“(s) when s approaches t
from one side, but not from the other side. So there exist 0 â‰¤ p < q < r â‰¤ d such that the
point (q, Gq,âˆ—(t)) lies on the line segment connecting (p, Gp,âˆ—(t)) and (r, Gr,âˆ— (t)). Thus, we
have Î¦(t) = 0 where
Î¦(s) = (r âˆ’ q)Gp,âˆ— (s) + (q âˆ’ p)Gr,âˆ— (s) âˆ’ (r âˆ’ p)Gq,âˆ— (s).
Write t = tâ€² + tâ€²â€² where tâ€² is a multiple of Î´âˆ—âˆ— and 0 â‰¤ tâ€²â€² < Î´âˆ—âˆ— . Then by assumption
Gj (tâ€² ) âˆˆ (d4(dâˆ’j) + d4d Z)Î´âˆ— for all j. Thus Î´1âˆ— Î¦(tâ€² ) âˆˆ Z, and furthermore
1
Î¦(tâ€² )
Î´âˆ—

â‰¡ (r âˆ’ q)d4(dâˆ’p) + (q âˆ’ p)d4(dâˆ’r) âˆ’ (r âˆ’ p)d4(dâˆ’q)

â‰¡ (q âˆ’ p)d4(dâˆ’r)

(modulo d4(dâˆ’q) ).

6â‰¡ 0

In particular Î¦(tâ€² ) 6= 0 = Î¦(t), so tâ€²â€² > 0 and thus t is not a transfer. Thus, the set of splits
and the set of merges are both disjoint from the set of transfers.
Since Gp,âˆ—, Gq,âˆ— , Gr,âˆ— are linear on [tâ€² , tâ€² + Î´âˆ—âˆ— ], so is Î¦. Let z denote the constant value
of Î¦â€² on [tâ€² , tâ€² + Î´âˆ—âˆ— ], and note that
i
h
0 6= z = m1 + n1 (r âˆ’ q)L+ (p) + (q âˆ’ p)L+ (r) âˆ’ (r âˆ’ p)L+ (q)


âˆˆ m1 + n1 {âˆ’(r âˆ’ p)q, . . . , (r âˆ’ q)p + (q âˆ’ p)r} âŠ† m1 + n1 {âˆ’d2 , . . . , d2 }.
Thus

tâ€²â€² = âˆ’

Î¦(tâ€² )
âˆˆ
z

1
m

Î´âˆ— Z
Î´âˆ— Z

âŠ†
,
1
2
d Â· (d2 )!
+ n (d )!

so by letting Î´âˆ— = d Â· (d2 )!Î· we can guarantee that tâ€²â€² âˆˆ ZÎ·. Since transfers also occur
at integer multiples of Î·, this implies that condition (I) of Definition 31.1 is satisfied. To
check condition (II), note that we have Gq,âˆ— (t) âˆˆ Î´âˆ— Z whenever t âˆˆ Î´âˆ—âˆ— N, and thus since
Î·
1
Z, we have Gq,âˆ— (t) âˆˆ mn
Z whenever t âˆˆ Î·N. Now for each
Gq,âˆ— has slopes in Z(q) âŠ† mn
q = 1, . . . , d and t âˆˆ Î·N, there exist p < q â‰¤ r such that
gq (t) =
Thus g is Î·-integral.

Gr,âˆ— (t) âˆ’ Gp,âˆ— (t)
Î·
âˆˆ
Z.
râˆ’p
mnd!

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

91

Next, since tâ€²â€² > 0, it follows that Î¦ is linear in a neighborhood of t, and thus there
exist points near t for which Î¦ is strictly negative. At these points, we have gq = gq+1 . It
follows that t is not both a split and a merge with respect to the same index q.
By contradiction, suppose that t is both a split and a merge, with corresponding indices
q1 6= q2 . We can apply the above argument twice: for each i = 1, 2 we get indices
0 â‰¤ pi < qi < ri â‰¤ d, a function Î¦i , and a slope zi . We have
âˆ’
and thus

Î¦2 (tâ€² )
Î¦1 (tâ€² )
= tâ€²â€² = âˆ’
z1
z2

Î¦1 (tâ€² )
Â·
Î´âˆ—

z2
1
+
m

1
n

Î¦2 (tâ€² )
Â·
=
Î´âˆ—

1
m

z1
Â·
+ n1

So there exist a1 , a2 âˆˆ {âˆ’d2 , . . . , d2} \ {0} such that

a1 [(r1 âˆ’ q1 )d4(dâˆ’p1 ) + (q1 âˆ’ p1 )d4(dâˆ’r1 ) âˆ’ (r1 âˆ’ p1 )d4(dâˆ’q1 ) ]

â‰¡ a2 [(r2 âˆ’ q2 )d4(dâˆ’p2 ) + (q2 âˆ’ p2 )d4(dâˆ’r2 ) âˆ’ (r2 âˆ’ p2 )d4(dâˆ’q2 ) ]

(modulo d4d ).

Comparing the base d4 expansions of both sides shows that (p1 , q1 , r1 ) = (p2 , q2 , r2 ), contradicting that q1 6= q2 . Thus, the set of splits and the set of merges are disjoint.
We next show that g â‰+ f. Indeed, fix t â‰¥ 0. Let h1 , h2 , and h3 be the convex hull
functions of Î“(t), {(q, Fq (t)) : Gq,âˆ— (t) 6= âˆ—}, and {(q, Fq (t)) : q = 0, . . . , d}, respectively.
Since Gq,âˆ— (t) â‰+ Fq (t) for all q such that Gq,âˆ—(t) 6= âˆ—, we have h1 â‰+ h2 , and by Claim
31.7, we have h2 â‰+ h3 . Moreover, since f1 (t) â‰¤ Â· Â· Â· â‰¤ fd (t), the map q 7â†’ Fq (t) is convex
and thus h3 (q) = Fq (t). But then gq (t) = h1 (q) âˆ’ h1 (q âˆ’ 1) â‰+ h3 (q) âˆ’ h3 (q âˆ’ 1) = fq (t) for
all q, i.e. g(t) â‰+ f(t).
Next, suppose that f is a template, and fix q, t, tâ€² such that gq (t) < gq+1 (t) and |tâ€² âˆ’t| â‰¤ Î·.
We will show that fq+1 (tâ€² ) âˆ’ fq (tâ€² ) â‰¥ Î· and Gâ€²q (t) â‰¥ Fqâ€² (tâ€² ). Indeed, by (31.8) we have
Gq (t) = Gq,âˆ— (t) = Fq,âˆ— (t) + q(d âˆ’ q)C4 = Fq (t) + q(d âˆ’ q)C4
and on the other hand GqÂ±1 (t) â‰¤ GqÂ±1,âˆ— (t) = FqÂ±1 (t) + (q Â± 1)(d âˆ’ q âˆ“ 1)C4 . Consequently,
fq+1 (t) âˆ’ fq (t) = Fq+1 (t) + Fqâˆ’1 (t) âˆ’ 2Fq (t)
â‰¥ Gq+1 (t) + Gqâˆ’1 (t) âˆ’ 2Gq (t) + 2C4 â‰¥ 2C4 .
It follows that fq+1 (tâ€² ) âˆ’ fq (tâ€² ) â‰¥ 2C4 âˆ’ Î·. Choosing C4 â‰¥ Î·, we get fq+1 (tâ€² ) âˆ’ fq (tâ€² ) â‰¥ Î·.
â€²
On the other hand, since Fq,âˆ—
= Gâ€²q,âˆ— near t, by (31.5) we have Gâ€²q (t) â‰¥ Fqâ€² (t).
Finally, to demonstrate (31.2), let I be an interval on which both f and g are linear.
For all q such that gq < gq+1 on I, the previous argument gives Gâ€²q â‰¥ Fqâ€² on I, and thus
L+ (g, I, q) â‰¥ L+ (f, I, q) (the right-hand side being well-defined since fq < fq+1 on I). It

92

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

follows that
(31.9)



# S+ (g, I) âˆ© (0, q]Z â‰¥ # S+ (f, I) âˆ© (0, q]Z

for all q such that gq < gq+1 on I (cf. Definition 4.5). Combining with (4.8) shows that
(31.9) holds for all q = 1, . . . , d, and thus since
 
dâˆ’1
X

m
,
Î´(f, I) =
# S+ (f, I) âˆ© (0, q]Z âˆ’
2
q=1
we have Î´(g, I) â‰¥ Î´(f, I). Since I was arbitrary, we get (31.2).



Lemma 31.8. If Î› is a unimodular lattice in Rd , then the successive minima function h =
(h1 , . . . , hd ), where
hi (t) = log Î»i (gt Î›),
satisfies conditions (I)-(III)f =h appearing in the proof of Lemma 31.4, meaning that it can
be approximated by a template.
Proof. Condition (I) is immediate from the definition, while condition (II) follows from
some simple calculations which we leave to the reader. To demonstrate property (III), fix
j = 1, . . . , d âˆ’ 1 and an interval [T1 , T2 ] such that hj+1 (t) > hj (t) for all t âˆˆ [T1 , T2 ]. For
each t âˆˆ [T1 , T2 ] let22
Vj (t) = hr âˆˆ Î› : kgt rk â‰¤ ehj (t) i = hr âˆˆ Î› : kgt rk < ehj+1 (t) i.
The assumption on [T1 , T2 ] guarantees that the map t 7â†’ Vj (t) is continuous on this interval, and since this map takes only rational values, it is therefore constant. So Vj (t) is
independent of t. By Minkowskiâ€™s second theorem (Theorem 30.1), for all t âˆˆ [T1 , T2 ] we
have
j
Y
Î»i (gt Î›) â‰ Covol(gt Vj (t)) = Covol(gt Vj ).
i=1

To continue further, we use the exterior product formula for covolume:
Covol(gt Vj ) = kgt v1 âˆ§ Â· Â· Â· âˆ§ gt vj k

where v1 , . . . , vj is a basis of Vj âˆ© Î›. The expression on the right-hand side is a member
V
of the space j Rd , which has a basis of the form {eS : S âŠ† {1 . . . , d}, #(S) = j}. Thus,
Covol(gt Vj ) â‰ max hgt v1 âˆ§ Â· Â· Â· âˆ§ gt vj , eS i = max Covol(Ï€S gt Vj ),
#(S)=j

22

#(S)=j

Here, Vj (t) is the smallest subspace containing {r âˆˆ Î› : kgt rk â‰¤ ehj (t) }. See Convention 4.

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

93

where Ï€S denotes the coordinate projection from Rd to RS . The logarithm of the righthand side is the maximum of linear maps whose slopes are in the set Z(j). Thus, the
function
def
Fj,[T1 ,T2 ] (t) = max log Covol(Ï€S gt Vj )
#(S)=j

satisfies the appropriate conditions, cf. (31.4).



31.2. Mini-strategy. Suppose that Alice and Bob have played the first k turns of the
modified Hausdorff game, and that Alice wants to play so as to guarantee that the successive minima function of the outcome will be close to a given template g for some short
period of time starting at kÎ³. Whether or not she can do this depends both on the template g and on the lattice Î›k given by (29.3). Intuitively, we expect that she can do it if
h(Î›k ) is close to g(kÎ³), and Î›k is â€œpositioned in a way so as to allow Alice to continue
this correspondence for larger values of kâ€. If the lattice Î›k is positioned appropriately,
we will call it a C-match for g at time kÎ³. We give the formal definition as follow:
Definition 31.9. Let g be a Î³-integral partial template, and fix C > 0. A lattice Î› âŠ† Rd is
a C-match for g at time t âˆˆ Î³N if
(I) We have

kh(Î›) âˆ’ g(t)k < C.

(31.10)

(II) There is a family of nested Î›-rational subspaces (Vq )qâˆˆQ(t) , where
def

Q(t) = {q : gq (t) < gq+1 (t)},
such that for all q âˆˆ Q(t), we have dim(Vq ) = q,
log Î»i (Î› âˆ© Vq ) âˆ’ hi (Î›) â‰¤ C for all 1 â‰¤ i â‰¤ q,

(31.11)
and
(31.12)

dim(Vq âˆ© L) â‰¥ Lâˆ’ (g, I, q),
where I is an interval of linearity for g whose left endpoint is t.

Fix C1 > 0. We now show that if Î›k1 is a C1 -match for g at time t1 = k1 Î³, then it is
possible for Alice to follow g for any fixed number of intervals of linearity to within an
additive constant depending on C1 :
Lemma 31.10. Fix k1 , k2 âˆˆ N with k2 > k1 and let ti = ki Î³. Let g : [t1 , âˆ) â†’ Rd be a
Î³-integral partial template, and let N be the number of maximal intervals of linearity of the
function g â†¿ (t1 , t2 ). Suppose that on the k1 th turn of the dynamical game, Î›k1 is a C1 -match

94

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

for g at time t1 . Then Alice has a strategy for turns k1 , . . . , k2 âˆ’ 1 of the dynamical game
guaranteeing the following:
(i) For all k âˆˆ [k1 , k2 ]Z,
h(Î›k ) â‰+,C1 ,N,Î² g(kÎ³).

(31.13)

(ii) The final lattice Î›k2 is a C2 -match for g at time t2 , where C2 is a constant depending
only on C1 , N and Î².
(iii) We have
kX
2 âˆ’1

1
log #(Ak )
âˆ†(A, [k1 , k2 ]) =
= Î´(g, [t1 , t2 ]) + O Î³1 +
k2 âˆ’ k1 k=k âˆ’ log(Î²)
def

1

1
k2 âˆ’k1



,

where the implied constant may depend on C1 and N but does not depend on Î².
Proof. By induction, it suffices to prove the lemma in the case where N = 1, i.e. where g
is linear on I = (t1 , t2 ).
def
Let Î› = Î›k1 , and let
def

def

Qâ€² = {q : gq (t1 ) < gq+1 (t1 )},

Q = {q : gq < gq+1 on I}.

Note that using the notation from Definition 31.9, we have
Qâ€² = Q(t1 ) âŠ† Q(t1 ) âˆª Q(t2 ) = Q.
In the sequel, for each q âˆˆ Qâ€² , let Vq be as in Definition 31.9.
Claim 31.11. If Î² is sufficiently small, then there exists a family of Î›-rational subspaces
(Vq )qâˆˆQ extending (Vq )qâˆˆQâ€² with the following properties:
(i)
(ii)
(iii)
(iv)

dim(Vq ) = q for all q âˆˆ Q.
Vp âŠ† Vq for all p, q âˆˆ Q such that p < q.
P
log kVq k â‰+ q1 gi (t1 ) for all q âˆˆ Q, where the implied constant may depend on C1 .
There exists X âˆˆ BM (0, 1 âˆ’ Î²) such that for all q âˆˆ Q,
def

dim(uX Vq âˆ© L) = Lâˆ’ (q) = Lâˆ’ (g, I, q).
and
dim(uX+Y Vq âˆ© L) â‰¤ Lâˆ’ (q) for all kY k â‰¤ 2Î² 1/2 .
Proof. Fix Îµ > 0 small and independent of Î², and let SÂ± = SÂ± (g, I). We will define the family (Vq )qâˆˆQ and a sequence of linearly independent lattice vectors (ri )iâˆˆSâˆ’
by simultaneous recursion: Fix j âˆˆ Sâˆ’ and suppose that ri has been defined for all

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

95

i âˆˆ Sâˆ’ (j) := {i âˆˆ Sâˆ’ : i < j}. Let q âˆˆ Q and r âˆˆ Qâ€² be maximal and minimal, respectively, such that q < j â‰¤ r. If Vq has not been defined yet, then let Vq âŠ† Vr be a Î›-rational
subspace of dimension q such that
(31.14)

Vp âŠ† Vq

âˆ€p < q,

ri âˆˆ Vq

âˆ€Sâˆ’ âˆ‹ i â‰¤ q,

chosen so as to minimize kVq k subject to these restrictions. Then
dim(Vr âˆ© L) â‰¥ Lâˆ’ (r) = #(Sâˆ’ (r + 1)) > #(Sâˆ’ (j)).
(31.12)

Further, we observe that

since



dim Vq +



P
dim(Vr ) > dim Vq + iâˆˆSâˆ’ (j) Rri
P

iâˆˆSâˆ’ (j)



Rri â‰¤ q + #(Sâˆ’ (j)) âˆ’ #(Sâˆ’ (q + 1))
â‰¤ q + j âˆ’ (q + 1)
< j â‰¤ r.

Thus it is possible to choose rj âˆˆ Î› âˆ© Vr such that 23
(31.15)
(31.16)

âˆ¡(rj , L) â‰¤ Îµ,


P
âˆ¡ rj , Vq + iâˆˆSâˆ’ (j) Rri â‰¥ Îµ2 ,

âˆ¡(ri , rj ) â‰¥ Ï€/2 âˆ’ Îµ

âˆ€i âˆˆ Sâˆ’ (j),

log krj k .+ gj (t1 ).

Indeed, one produces rj by first choosing a unit vector
\
u1 âˆˆ Vr âˆ© L âˆ©
râŠ¥
i ,
iâˆˆSâˆ’ (j)

choosing a second unit vector u2 âˆˆ Vr so that24

ï£«

B(u2 , Îµ/3) âŠ† RBâˆ¡ (u1 , Îµ) \ N ï£­Vq +

X

iâˆˆSâˆ’ (j)

and finally choosing

ï£¶

Rri , Îµ2 ï£¸ ,

rj âˆˆ Î› âˆ© Vr âˆ© B(Ï„ u2 , Ï„ Îµ/3),
where Ï„ = CÎ»r (Î› âˆ© Vr ) for a constant C large enough to guarantee that Î› âˆ© Vr is a
(Ï„ Îµ/3)-net in Vr . Now both sides of (31.15) follow since rj âˆˆ RBâˆ¡ (u1 , Îµ). The left-hand
23

In the equations below, âˆ¡ denotes the angle between two vectors, or between a vector and a vector
subspace.
24
We use N (A, Îµ) to denote the Îµ-neighborhood of a set A âŠ† Rd .

96

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

P
side of (31.16) follows since rj âˆˆ
/ N (Vq + iâˆˆSâˆ’ (j) Rri , Îµ2 ). The right-hand side of (31.16)
follows from the fact that log Î»r (Î› âˆ© Vr ) â‰+ gj (t1 ). Note that by construction, the family
(Vq )qâˆˆQ satisfies (i) and (ii).
To demonstrate (iii), first we observe that it holds for q âˆˆ Qâ€² by Minkowskiâ€™s second
theorem (Theorem 30.1). By induction, suppose that (iii) holds for all p < q, where
q âˆˆ Q \ Qâ€² , and let p âˆˆ Q and r âˆˆ Qâ€² be maximal and minimal, respectively, such that
p < q â‰¤ r. Then by (31.16), we have
log Vp +

X

iâˆˆSâˆ’ (p,q)

Rri â‰¤ log kVp k +

X

iâˆˆSâˆ’ (p,q)

log kri k .+

X
iâ‰¤p

gi (t1 ) +

X

gi (t1 ),

iâˆˆSâˆ’ (p,q)

where Sâˆ’ (p, q) = {i âˆˆ Sâˆ’ : p < i â‰¤ q}. Thus by (31.10), it is possible to choose a
P
Î›-rational subspace Vq âŠ† Vr satisfying (31.14) such that log kVq k .+
iâ‰¤q gi (t1 ). The
reverse inequality follows directly from Minkowskiâ€™s second theorem (Theorem 30.1).
P
To demonstrate (iv), let Lâ€² = jâˆˆSâˆ’ Rrj . Then (31.15) implies that dG (L, Lâ€²) = O(Îµ),
where dG denotes distance in the Grassmannian variety of n-dimensional subspaces of Rd ,
that we denote by G = G(d, n). It follows that if Îµ is sufficiently small, then there exists
X âˆˆ BM (0, 1 âˆ’ Î²) such that uâˆ’X L = Lâ€² . Then for all q âˆˆ Q, by (31.14) we have
dim(uX Vq âˆ© L) = dim(Vq âˆ© Lâ€² ) â‰¥ #{i âˆˆ Sâˆ’ : i â‰¤ q} = Lâˆ’ (q).
Conversely, fix kY k â‰¤ 2Î² 1/2 and q âˆˆ Q. Let us define
X
def
W = u Y Vq âˆ©
Rri
Sâˆ’ âˆ‹i>q

Then
dim(uX+Y Vq âˆ© L) = dim(uY Vq âˆ© Lâ€² ) â‰¤ Lâˆ’ (q) + dim(W ).
Thus if dim(W ) = 0, then we are done with proving (iv). So by contradiction, suppose
that dim(W ) > 0, i.e. that there exists
0 6= r âˆˆ W.

P
Write r = Sâˆ’ âˆ‹i>q ci ri for some constants ci âˆˆ R. Let Sâˆ’ âˆ‹ j > q be chosen so as to
maximize Î¸âˆ’j |cj | Â· krj k, where Î¸ > 0 is small. Since r 6= 0, we have ci 6= 0 for some i, and
thus Î¸âˆ’j |cj | Â· krj k â‰¥ Î¸âˆ’i |ci | Â· kri k > 0. Then
!
X
1
râˆ’
ci r i
rj =
cj
i6=j

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

and thus

97

"
#

X
P
1
1 
kr âˆ’ uâˆ’Y rk +
|ci | Â· kri k
d rj , Vq + iâˆˆSâˆ’ (j) Rri â‰¤
krj k
|cj | Â· krj k
i>j
.

kY k Â· krk X iâˆ’j
+
Î¸
|cj | Â· krj k
i>j

. 2Î² 1/2 max
i

|ci | Â· kri k
+Î¸
|cj | Â· krj k

. Î¸1âˆ’d Î² 1/2 + Î¸.
def

def

Letting Î¸ = Î² 1/(2d) = Îµ3 gives



P
âˆ¡ rj , Vq + iâˆˆSâˆ’ (j) Rri . Îµ3 ,

which contradicts the first half of (31.16) if Îµ (or equivalently Î²) is sufficiently small.
This completes the proof of (iv), and thus of Claim 31.11.
âŠ³

Now for the purposes of defining Aliceâ€™s strategy, fix k = k1 , . . . , k2 âˆ’ 1, and suppose
that the game has progressed to turn k, so that the matrices Xk1 , . . . , Xkâˆ’1 âˆˆ BM (0, 1 âˆ’ Î²)
have all been defined. For each q âˆˆ Q let
def

Vq(k) = (guXkâˆ’1 ) Â· Â· Â· (guXk1 )Vq ,
where g = gÎ³ and Î³ is as in Notation 29.1. By the definitions of Î› and Vq , Vq is Î›k1 (k)
rational, and thus Vq is Î›k -rational.
Now let (p, q]Z be an interval of equality for g on I, and consider the quotient lattice
def

Î“k = Î›k âˆ© Vq(k) /Vp(k)
(k)

(more precisely, Î“k is the image of Î›k under the quotient map Vq
(k)
(ri )1qâˆ’p be a basis for Î“k such that

(k)

(k)

kri k â‰ Î»i (Î“k ) for all 1 â‰¤ i â‰¤ q âˆ’ p.
For each j = 1, . . . , q âˆ’ p let
(k)
Vp+j

=

Vp(k)

+

j
X

(k)

â†’ Vq /Vp ). Let

(k)

Rri .

i=1

Next, a matrix X will be called good on turn k if for all j = 1, . . . , d we have

def
(k)
(31.17)
dim uX Vj âˆ© L = Lâˆ’ (j) = #(Sâˆ’ âˆ© [1, j])

98

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

and
(31.18)

(k)

dim uX+Y Vj


âˆ© L â‰¤ Lâˆ’ (j) for all kY k â‰¤ 2Î² 1/2 .

Aliceâ€™s strategy on turn k can now be given as follows:

Let Ak be a maximal 3Î²-separated subset of the set of matrices
in BM (0, 1 âˆ’ Î²) that are good on turn k.
Note that by Claim 31.11(iv), we have Ak 6= .
Now, to prove that Aliceâ€™s strategy guarantees (i)-(iii) in Lemma 31.10, consider a
2 âˆ’1
possible sequence of responses from Bob, i.e. a sequence (Xk )kk=k
such that for each k,
1
we have Xk âˆˆ Ak . For each k = k1 , . . . , k2 let
def

Zk =

kâˆ’1
X

â„“=k1

so that for all q âˆˆ Q,

Î² â„“âˆ’k1 Xâ„“ âˆˆ B(0, 1),

Vq(k) = g kâˆ’k1 uZk Vq
def

(cf. (29.5)). Now fix q âˆˆ Q, and let LÂ± = LÂ± (g, I, q). Fix k = k1 + 1, . . . , k2. Since Xkâˆ’1 is
good, we have
dim(uZk Vq âˆ© L) = dim(Vq(k) âˆ© L) = Lâˆ’
and since Xk1 +1 is good and Î² 2 < 2Î² 1/2 (since Î² < 1), we have

dim uZk +Y Vq âˆ© L â‰¤ Lâˆ’ for all kY k â‰¤ Î² 2 .
Now by Lemma 30.7, these two formulas imply that

log kVq(k) k âˆ’ log kVq k â‰+ log kg kâˆ’k1 uZk Vq k âˆ’ log kuZk Vq k


L+ Lâˆ’
â‰+,Î²
(k âˆ’ k1 )Î³
âˆ’
m
n
q
q
X
X
gi (t1 ).
gi (kÎ³) âˆ’
=
i=1

i=1

Combining with condition (iii) of Claim 31.11 shows that
(31.19)

log kVq(k) k

â‰+,Î²

q
X

gi (kÎ³).

i=1

Now let (p, q]Z be an interval of equality for g on I, and let
def

Î“k = Î“k (p, q) = Î›k âˆ© Vq(k) /Vp(k)

(by (4.5))

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

99

as above.
Claim 31.12. We have
log Î»j (Î“k ) â‰+,Î² gp+j (kÎ³)
for all j = 1, . . . , q âˆ’ p and k = k1 , . . . , k2 .
Proof. Write
def

Î·j (k) = log Î»j (Î“k ) âˆ’ gp+j (kÎ³).
By (31.19) and Minkowskiâ€™s second theorem (Theorem 30.1), we have
(31.20)

qâˆ’p
X
i=1

Î·i (k) â‰+,Î² log kÎ“k k âˆ’

q
X

i=p+1

gi (kÎ³) â‰+ 0.

First suppose that Mâˆ’ = 0, where MÂ± = M(g, I, p, q). Then for all j, k we have
(k âˆ’ k1 )Î³
â‰¥ log Î»j (Î“k ) âˆ’ log Î»j (Î“k1 ),
m
and (31.20) implies that approximate equality holds. Similar logic works if M+ = 0.
So suppose that M+ , Mâˆ’ > 0. Let K be a large constant. To complete the proof of
Claim 31.12 we will show that
K
K
â‰¤ Î·j (k) â‰¤
(31.21)
âˆ’
M+
Mâˆ’
gp+j (kÎ³) âˆ’ gp+j (k1 Î³) =

for all j = 1, . . . , q âˆ’ p and k = k1 , . . . , k2 , by induction on k. Indeed, suppose that (31.21)
holds for k, and we will prove that it holds for k â€² = k + â„“0 , where â„“0 is a large integer. By
(31.20), we have
jÎ·j (k) â‰¥

j
X
i=1

Î·i (k) â‰+,Î² âˆ’

qâˆ’p
X

i=j+1

Î·i (k) â‰¥ âˆ’

(q âˆ’ p âˆ’ j)K
Â·
Mâˆ’

Letting j = M+ + 1 shows that
Î·M+ +1 (k) &+,Î² âˆ’

Mâˆ’ âˆ’ 1 K
K
=âˆ’
+ Î±K,
Mâˆ’ M+ + 1
M+

where Î± > 0 is a positive constant.
Note that since gp+j (t) = gq (t) for all t âˆˆ I and j = 1, . . . , q âˆ’p, we have Î·1 â‰¤ Â· Â· Â· â‰¤ Î·qâˆ’p ,
so if (31.21) fails for k â€² = k + â„“0 , then either Î·1 (k â€² ) < âˆ’K/M+ or Î·qâˆ’p (k â€² ) > K/Mâˆ’ . By
contradiction suppose that Î·1 (k â€² ) < âˆ’K/M+ (the other case is similar). Then Î·1 (k) â‰+,â„“0 ,Î²
âˆ’K/M+ and thus
Î·M+ +1 (k) âˆ’ Î·1 (k) &+,â„“0 ,Î² Î±K.

100

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

If K is sufficiently large in comparison to â„“0 , then it follows that there exists j = 1, . . . , M+
such that
Î±K
(31.22)
Î·j+1 (k) âˆ’ Î·j (k) â‰¥
.
M+ + 1
It follows from (31.22) that
(â„“)

Vj

(k)

= bk,â„“ Vj

for all â„“ = k, . . . , k â€²

def

where bk,â„“ = (guXâ„“âˆ’1 ) Â· Â· Â· (guXk ). Thus since Xk , . . . , Xâ„“âˆ’1 are good, Lemma 30.7 shows
that


L+ (p + j) Lâˆ’ (p + j)
(k â€² )
(k)
â€²
log kVp+j k âˆ’ log kVp+j k â‰+,Î² (k âˆ’ k)Î³
.
âˆ’
m
n
Subtracting (31.19) (with q = p) and using the asymptotic
(â„“)
log kVp+j k

âˆ’

log kVp(â„“) k

and the relations

â‰+,Î²

j
X

L+ (p + j) = L+ (p) + j,

log Î»i (Î“â„“ )

i=1

Lâˆ’ (p + j) = Lâˆ’ (p)

(valid since j â‰¤ M+ ) show that
j
X
i=1

log Î»i (Î“kâ€² ) âˆ’

j
X
i=1

log Î»i (Î“k ) â‰+,Î² (k â€² âˆ’ k)Î³

On the other hand, since log kbk,kâ€² k .+ (k â€² âˆ’ k)Î³/m, we have
log Î»i (Î“kâ€² ) âˆ’ log Î»i (Î“k ) .+ (k â€² âˆ’ k)Î³
and thus
log Î»i (Î“kâ€² ) âˆ’ log Î»i (Î“k ) â‰+,Î² (k â€² âˆ’ k)Î³
In particular
â€²

Î·1 (k ) âˆ’ Î·1 (k) â‰+,Î²



1
m

1
for all i = 1, . . . , j.
m

1
1
(k âˆ’ k)Î³
âˆ’
m M+ + Mâˆ’
â€²

j
Â·
m



M+ Mâˆ’
âˆ’
m
n



.

The right-hand side is strictly positive, so if â„“0 is sufficiently large, then the left-hand side
is also positive. But this contradicts our assumption that Î·1 (k â€² ) < âˆ’K/M+ â‰¤ Î·1 (k), thus
demonstrating (31.21). This concludes the proof of Claim 31.12.
âŠ³

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

101

Next, note that for any 1 â‰¤ i â‰¤ q we have that
Î»qâ€² âˆ’pâ€² (Î“k (pâ€² , q â€²)),
Î»i (Î“k (p, q)) â‰¤ Î»p+i (Î›k âˆ© Vq(k) ) . max
â€² â€²
(p ,q ]
q â€² â‰¤q

where the maximum is taken over all intervals of equality (pâ€² , q â€² ] for g that satisfy q â€² â‰¤ q.
Indeed, the first inequality can be demonstrated by observing that the projection of a set
of p + i linearly independent vectors in Î›k âˆ© Vq contains a linearly independent set of i
vectors in Î“k (p, q). For the second inequality, denote the right-hand side by Î» and note
that by pulling back vectors appropriately, we can recursively construct bases of Î›k âˆ© Vqâ€²
for all q â€² â‰¤ q, such that the largest vector in each basis has norm . Î».
Now using Claim 31.12, we have that

gqâ€² (kÎ³) = gq (kÎ³) = gp+i (kÎ³),
gp+i (kÎ³) .+,Î² log Î»p+i (Î›k âˆ© Vq(k) ) .+,Î² max
â€² â€²
(p ,q ]
q â€² â‰¤q

where the maximum is taken as before. Thus we have that for p < j â‰¤ q
(31.23)

log Î»j (Î›k âˆ© Vq ) â‰+,Î² gj (kÎ³).
(k)

To demonstrate (31.10) and (31.11), we pick r âˆˆ Î›k \Vp . Now consider the projection
map
Ï€ : Vq â†’ Vq /Vp
and note that
krk â‰¥ kÏ€(r)k â‰¥ Î»1 (Î“k (p, q)) â‰Ã—,Î² exp(gp+1 (kÎ³)).
Therefore we have that log Î»p+1 (Î›k ) &+,Î² gp+1(kÎ³). Thus for p < j â‰¤ q, we also have
log Î»j (Î›k ) &+,Î² gj (kÎ³).
On the other hand, by the monotonicity of the successive mimina functional we have
log Î»j (Î›k âˆ© Vq ) â‰¥ log Î»j (Î›k ).
Therefore, using (31.23) and the previous two display equations, we get
gj (kÎ³) â‰+,Î² log Î»j (Î›k âˆ© Vq ) â‰+,Î² log Î»j (Î›k ),
and thus (31.10), (31.11) and (31.13) hold with Î› = Î›k2 and t = t2 , as long as C is
sufficiently large. This completes the proof of condition (i) of Lemma 31.10.
We proceed to prove conditions (ii) and (iii). By (31.13), (31.10) holds with Î› = Î›k2 ,
t = t2 , and C = C2 , where C2 is the implied constant of (31.13). Observe that by (31.12)
we have
dim(Vq (Î›k2 ) âˆ© L) = dim(Vq(k2 ) âˆ© L) â‰¥ Lâˆ’ (g, I, q) â‰¥ Lâˆ’ (g, I+ , q),

102

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

where I+ is the interval of linearity for g whose left endpoint is t2 . Note that the last
inequality is due to the assumption of convexity in (III) of Definition 4.1. It follows that
condition (II) of Definition 31.9 holds with Î› = Î›k2 and t = t2 , which completes the
proof of (ii).
To demonstrate (iii), it suffices to show that
(a) #(Ak1 ) â‰¥ 1, and
(b) #(Ak ) & Î² âˆ’Î´ for all k > k1 , where Î´ = Î´(g, I).
Note that (a) is true by part (iv) of Claim 31.11. To demonstrate (b), fix k > k1 , and
observe that since Xkâˆ’1 is good on turn k âˆ’ 1, for all q âˆˆ Q we have
(31.24)

dim(Vq(k) âˆ© L) = Lâˆ’ (q)

and
dim(uY Vq(k) âˆ© L) â‰¤ Lâˆ’ (q)

We now construct a basis of Rd as follows.

âˆ€ Y âˆˆ BM (0, Î² âˆ’1/2 ).

Claim 31.13. There exists an almost orthonormal basis (ri )d1 of Rd (meaning that ri Â· rj =
Î´ij + o(1) as Î² â†’ 0 for all i, j), which contains a subset that is an orthonormal basis of L.
def

Proof. Let (p, q]Z be an interval of equality for g on I, and let MÂ± = MÂ± (p, q) (as defined
p+M
in (4.7)). Let (ri )p+1 + be an orthonormal basis of
def

W+ (p, q) = Vq(k) âˆ© (Vp(k) )âŠ¥ âˆ© (Vq(k) âˆ© L)âŠ¥
and let (ri )qp+M+ +1 be an orthonormal basis of
def

Wâˆ’ (p, q) = Vq(k) âˆ© L âˆ© (Vp(k) âˆ© L)âŠ¥ .
Such bases exist because (31.24) allows us to compute the dimensions of these spaces.
Then we claim that (ri )d1 is an almost orthonormal basis of Rd (meaning that ri Â· rj =
Î´ij + o(1) as Î² â†’ 0 for all i, j), and that (ri )iâˆˆSâˆ’ is an orthonormal basis of L (where Sâˆ’
is defined in (4.9)).
Indeed, to see why (ri )d1 is almost orthonormal, we consider four cases:
(31.25)

ri âˆˆ W+ (p1 , q1 ), rj âˆˆ W+ (p2 , q2 )

(31.26)

ri âˆˆ W+ (p1 , q1 ), rj âˆˆ Wâˆ’ (p2 , q2 )

(31.27)

ri âˆˆ Wâˆ’ (p1 , q1 ), rj âˆˆ W+ (p2 , q2 )

(31.28)

ri âˆˆ Wâˆ’ (p1 , q1 ), rj âˆˆ Wâˆ’ (p2 , q2 )

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

103

for p1 â‰¤ q1 and p2 â‰¤ q2 . In the three cases (31.25), (31.27) and (31.28), we have that
ri Â· rj = Î´ij by part (ii) of Claim 31.11. Note that since Wâˆ’ (p, q) âŠ† L, it follows from
(31.28) that (ri )iâˆˆSâˆ’ is an orthonormal basis of L.
So we are left to consider the case (31.26). Note that in this case we may assume that
p1 < q1 â‰¤ p2 < q2 (since if p1 = q1 and p2 = q2 , then (31.26) reduces to (31.27)).
def
(k)
Let V = Vp2 . Then ri âˆˆ W+ (p1 , q1 ) âŠ† V âˆ© (V âˆ© L)âŠ¥ and rj âˆˆ Wâˆ’ (p2 , q2 ) âŠ† L âˆ© (V âˆ© L)âŠ¥ .
Write ri = (p, qâ€² ) and rj = (0, q). Now let
def

Yv= âˆ’

(qâ€² Â· v)
p.
(qâ€² Â· qâ€² )

Then note that uY (p, qâ€² ) âˆˆ L and uY (V âˆ© L) = V âˆ© L. Therefore we have that
dim(uY (V ) âˆ© L) > dim(V âˆ© L).
Thus by part (iv) of Claim 31.11, we have that
kY k > 2Î² âˆ’1/2 .
Since kY k â‰¤ 1/kqâ€²k2 it follows that kqâ€² k < Î² 1/4 . Therefore
|ri Â· rj | = |q Â· qâ€² | â‰¤ kqâ€² k < Î² 1/4 .
Thus ri Â· rj = Î´ij + o(1) as Î² â†’ 0 for all i, j as claimed. This concludes the proof of Claim
31.13.
âŠ³
Let Z be the space of all d Ã— d matrices X such that for all i, j such that Xi,j 6= 0, we
have i > j, i âˆˆ Sâˆ’ , and j âˆˆ S+ . Evidently, dim(Z) = Î´(g, I). Now let R be the matrix
whose column vectors are r1 , . . . , rd . Then for all Z âˆˆ Z, the matrix R Â· (I + Z) Â· Râˆ’1
(k)
preserves the subspaces (Vq )qâˆˆQ . Now define a map Î¦ : Z â†’ M as follows: for each
Z âˆˆ Z, X = Î¦(Z) is the unique matrix such that
uX L = R Â· (I + Z) Â· Râˆ’1 L.
It is easy to check that in a neighborhood of the origin, Î¦ is a bi-Lipschitz embedding
with bi-Lipschitz constant depending only on max(kRk, kRâˆ’1k). But since the basis (ri )d1
is almost orthonormal as proved in Claim 31.13, there is a uniform bound on this constant
as long as Î² is sufficiently small.
Thus, let C be the bi-Lipschitz constant of Î¦. Let Aâ€²k be a maximal 3CÎ²-separated
subset of BZ (0, 1/C). Then Ak = Î¦(Aâ€²k ) is a 3Î²-separated subset of B(0, 1) consisting
entirely of matrices good on turn k. It follows that
#(Ak ) = #(Aâ€²k ) â‰ Î² âˆ’Î´ .

104

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

This concludes the proof of condition (iii) of Lemma 31.10, and therefore of the entire
lemma.

31.3. Error correction. Fix Î· > 0, let f be a simple Î·-integral template, fix t0 âˆˆ Î·N, and
let b = (b1 , . . . , bd ) âˆˆ Rd be a vector such that bi â‰¤ bi+1 for all i such that fi (t0 ) = fi+1 (t0 ).
Such a vector will be called a perturbation vector of f at t0 . For convenience, for each
k âˆˆ N let tk = t0 + kÎ·. We define the function a : N âˆª {âˆ’1} â†’ Rd recursively as follows:
â€¢ a(âˆ’1) = b.
â€¢ Fix k â‰¥ 0 such that a(k âˆ’ 1) has been defined, and let Ik = (tk , tk+1). If (p, q]Z is
an interval of equality for f on Ik (cf. Definition 4.5), then for all i = p + 1, . . . , q,
we let
ï£±
â€²
ï£´
ï£´
if fp+1
= . . . = fqâ€² âˆˆ { m1 , âˆ’ n1 } on (t0 , tk+1 )
ï£²ai (k âˆ’ 1)
q
(31.29)
ai (k) =
1 X
ï£´
aj (k âˆ’ 1) otherwise.
ï£´
ï£³q âˆ’ p
j=p+1

The idea is that we will construct a new template by displacing f by a(k) on each interval
Ik , and then changing the resulting function into a template by modifying it slightly
to deal with the issues that arise near multiples of Î·. The motivation for the equation
(31.29) will become apparent when we analyze when it is possible to perform such a
modification. Note that by induction, for all k we have
ka(k)kâˆ â‰¤ kbkâˆ

(31.30)
and
(31.31)

ai (k) â‰¤ ai+1 (k) whenever fi = fi+1 on Ik .

Lemma 31.14. Let the notation be as above. If kbkâˆ < CÎ· =
partial template g : [t0 , âˆ) â†’ Rd such that

Î·
, then there exists a
2mnd!

g(t0 ) = f(t0 ) + b

(31.32)
and such that for all k, we have
(31.33)
where a is as above, and


def
g = f + a(k) on Iek = tk + s, tk+1 âˆ’ s ,
def

s = 2mnd2 kbkâˆ .

Moreover, we have
(31.34)

Î´(g, t) = Î´(f, t) for t âˆˆ Iek .

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

105

The partial template g constructed in the proof below will be called the b-perturbation
of f at t0 .
Proof. We will first show that for all k â‰¥ 0, if g is any function satisfying (31.33), then
g â†¿ Iek is a partial template. Indeed, since g is linear on Iek , it suffices to check conditions
(I) and (II) of Definition 4.1, along with the following weakening of condition (III):
(IIIâ€² ) For all j = 1, . . . , d âˆ’ 1 such that gj < gj+1 on Iek , we have Gâ€²j (Iek ) âˆˆ Z(j).

Condition (II) is obvious, so we check (I) and (IIIâ€² ).

Proof of (I). Fix i = 1, . . . , d âˆ’ 1, and we will show that gi â‰¤ gi+1 on Iek . There are three
cases:

â€¢ If fi = fi+1 on Ik , then by (31.31) we have ai (k) â‰¤ ai+1 (k) and thus gi â‰¤ gi+1 on
Iek .
â€²
â€¢ If fi (tk ) = fi+1 (tk ) but fi < fi+1 on Ik , then we have fiâ€² (Ik ) < fi+1
(Ik ), and thus
â€²
fi+1 âˆ’ fi > (fi+1
(Ik ) âˆ’ fiâ€² (Ik ))s

â‰¥

1
s
mnd2

(on Iek )

(by Observation 30.8)

= 2kbkâˆ
â‰¥ |ai+1 (k) âˆ’ ai (k)|,

(by (31.30))

so gi < gi+1 on Iek . Similar logic applies if fi (tk+1 ) = fi+1 (tk+1 ) but fi < fi+1 on Ik .
â€¢ If fi (tk ) < fi+1 (tk ) and fi (tk+1 ) < fi+1 (tk+1 ), then since f is Î·-integral we have

fi+1 âˆ’ fi â‰¥ min fi+1 (tk ) âˆ’ fi (tk ), fi+1 (tk+1 ) âˆ’ fi (tk+1 )
(on Ik )
â‰¥

Î·
mnd!

(by Definition 31.1)

= 2CÎ·
> 2kbkâˆ
â‰¥ |ai+1 (k) âˆ’ ai (k)|
and thus gi < gi+1 on Iek .

(by hypothesis)
(by (31.30))

Proof of (IIIâ€² ). Fix j = 1, . . . , d âˆ’ 1 such that gj < gj+1 on Iek . There are two cases:

âŠ³

â€¢ If fj < fj+1 on Ik , then Gâ€²j (Iek ) = Fjâ€² (Ik ) âˆˆ Z(j).
â€¢ If fj = fj+1 on Ik , then aj (k) < aj+1 (k). Moreover, j and j + 1 are in the same
â€²
interval of equality (p, q]Z âˆ‹ j, j + 1 for f on Ik . By (31.29) we have fp+1
(Ik ) =
1
1
â€²
. . . = fqâ€² (Ik ) âˆˆ { m , âˆ’ n }. Without loss of generality suppose that fp+1
(Ik ) = . . . =

106

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

fqâ€² (Ik ) =

1
.
m

Then we have

L+ (f, Ik , p) + (j âˆ’ p) Lâˆ’ (f, Ik , p)
Gâ€²j (Iek ) = Fjâ€² (Ik ) =
âˆ’
âˆˆ Z(j).
m
n

(The intuition behind this calculation is that m1 and âˆ’ n1 are â€œfree slopesâ€ that can
be used by an individual fj without the need for averaging; cf. the model of
â€œparticle physicsâ€ described in the paragraph below Definition 4.5.)
âŠ³
Next, we demonstrate (31.34). Let (p, q]Z be an interval of equality for f on Ik . By the
proof of (I) above, we have gp < gp+1 and gq < gq+1 on Iek . Let
MÂ± = MÂ± (f, Ik , p, q) = LÂ± (g, Iek , q) âˆ’ LÂ± (g, Iek , p).

If M+ > 0 and Mâˆ’ > 0, then ap+1 (k) = . . . = aq (k) and thus (p, q]Z is an interval of
equality for g on Iek , which implies that S+ (f, Ik ) âˆ© (p, q]Z = S+ (g, Iek ) âˆ© (p, q]Z. On the
other hand, if M+ = 0, then S+ (f, Ik ) âˆ© (p, q]Z =  = S+ (g, Iek ) âˆ© (p, q]Z, and if Mâˆ’ = 0,
then S+ (f, Ik ) âˆ© (p, q]Z = (p, q]Z = S+ (g, Iek ) âˆ© (p, q]Z. Since (p, q]Z was arbitrary we have
S+ (f, Ik ) = S+ (g, Iek ) and thus Î´(f, Ik ) = Î´(g, Iek ).
Finally, we describe how to define g on an interval of the form
ï£±
ï£² t âˆ’ s, t + s if k > 0
k
k
def
(31.35)
Jk = 
ï£³ t0 , t0 + s
if k = 0
We now consider two cases:

Case 1. If a(k âˆ’ 1) = a(k), then we can continue to use the formula g = f + a(k) on
Jk . Minor modifications to the previous argument show that g â†¿ Iekâˆ’1 âˆª Jk âˆª Iek is a partial
template (where we use the convention that Ieâˆ’1 = ).

Case 2. Suppose that a(k âˆ’ 1) 6= a(k). By (31.29), this means that tk is either a merge,
a transfer, or t0 . We restrict our attention to the case where tk is a merge; the other cases
are similar. Define g on Jk as follows: Let (p, q]Z be an interval of equality for f on Ik
which is not an interval of equality for f on Ikâˆ’1 , and let MÂ± = MÂ± (f, Ik , p, q), so that
â€²
= fqâ€² âˆˆ
M+ + Mâˆ’ = q âˆ’ p. Note that M+ , Mâˆ’ > 0, as otherwise we would have fp+1
{ m1 , âˆ’ n1 } on Ikâˆ’1 , and thus (p, q]Z would be an interval of equality for f on Ikâˆ’1 . We define
the piecewise linear functions gp+1, . . . , gq on Jk by imposing the following conditions:
â€¢ We have
(31.36)

g(min(Jk )) = f(min(Jk )) + a(k âˆ’ 1).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

â€¢ We have
(31.37)

q
X

i=p+1

giâ€²

=

q
X

fiâ€² =

i=p+1

107

M+ Mâˆ’
âˆ’
on Jk
m
n

(the second equality holds because tk cannot be a transfer, since f is simple).
â€¢ For all p < i â‰¤ p + M+ and t âˆˆ Jk , we have giâ€² (t) = m1 unless gi (t) = gp+M+ +1 (t), in
which case giâ€² (t) = z(t).
â€¢ For all p + M+ < i â‰¤ q and t âˆˆ Jk , we have giâ€² (t) = âˆ’ n1 unless gi (t) = gp+M+ (t), in
which case giâ€² (t) = z(t).
The number z(t) appearing in the last two conditions can be computed by plugging the
values of giâ€² appearing in those conditions into (31.37) and then solving for z(t). In all of
the above formulas, derivatives should be assumed to be taken from the right.
It is easy to check that these conditions uniquely determine the functions gp+1 , . . . , gq
on the interval Jk . To ensure that this does not lead to an inconsistency with (31.33), we
need to check that
(31.38)

g(max(Jk )) = f(max(Jk )) + a(k).

Since tk is not a split, by (31.29) the map i 7â†’ fi (max(Jk )) + ai (k) is constant on (p, q]Z.
def
Suppose first that the map i 7â†’ gi (max(Jk )) is also constant on (p, q]Z. Let h(t) = (Gq âˆ’
Pq
Gp )(t) âˆ’ (Fq âˆ’ Fp )(t). Then (31.36) implies that h(min(Jk )) =
p+1 ai (k âˆ’ 1). Now
Pq
â€²
by (31.29) this gives h(min(Jk )) =
p+1 ai (k), and so using (31.36) we have h = 0
Pq
and thus h(max(Jk )) = p+1 ai (k). Rearranging gives the sum of the ith coordinate of
(31.38) over i âˆˆ (p, q]Z.
On the other hand, suppose that i 7â†’ gi (max(Jk )) is not constant on (p, q]Z. Suppose
not. Then either there exists p < i â‰¤ p + M+ such that gi (t) < gp+M+ +1 (t) for all t âˆˆ Jk ,
or there exists p + M+ < i â‰¤ q such that gi (t) > gp+M+ (t) for all t âˆˆ Jk . Without loss of
generality suppose the first case holds. Then gp+1 (t) < gp+M++1 (t) for all t âˆˆ Jk , and thus
â€²
gp+1
(t) = m1 for all t âˆˆ Jk . Now let
def

F (t) =

q
X


i=p+1
def

G(t) =

q
X


i=p+1


fi (t) âˆ’ fp+1 (t) ,


gi (t) âˆ’ gp+1 (t) .

Then F (t), G(t) â‰¥ 0, F (tk ) = 0, and




qâˆ’p
1
1
M+ Mâˆ’
def
â€²
â€²
âˆ’
.
âˆ’
= âˆ’Mâˆ’
+
F (t) â‰¥ G (t) = âˆ’Z =
m
n
m
m n

108

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

It follows that
0 â‰¤ G(max(Jk )) = G(min(Jk )) âˆ’ Z|Jk |
â‰¤ F (min(Jk )) + 2dkbkâˆ âˆ’ Z|Jk |


â‰¤ F (tk ) + Z k > 0 s + 2dkbkâˆ âˆ’ Z|Jk | = 2dkbkâˆ âˆ’ Zs < 0,

where the last inequality follows from the definition of s and the inequality Mâˆ’ â‰¥ 1. This
is a contradiction, and therefore (31.38) holds and so g is continuous in a neighborhood
of max(Jk ).
Thus g is continuous on [t0 , âˆ). Indeed, we have that g is piecewise linear on Jk
by definition and on Iek by (31.33). Further, g is continuous at the transition points
min(Jk ) âˆˆ Iekâˆ’1 âˆ© Jk and max(Jk ) âˆˆ Jk âˆ© Iek . The former follows from (31.36) and the
latter from (31.38).
Recall that we have previously shown that g â†¿ Iek is a partial template. We leave the
verification of the other conditions of Definition 4.1 as an exercise to the reader. This
concludes the proof of Lemma 31.14.

Now we combine the concept of perturbation vectors with the concept of C-matches
introduced in Â§31.2. The following lemma shows that by perturbing a template, it is
possible to improve the constant C appearing in Definition 31.9:
Lemma 31.15. Let Î› be a CÎ· -match for an Î·-integral template f at t0 âˆˆ Î·N, and let g be
the b-perturbation of f at t0 , where b âˆˆ (d3 )!Î³Zd is a perturbation vector such that
(31.39)

h(Î›) âˆ’ [f(t0 ) + b]

âˆ

< C1

for some constant C1 â‰¤ CÎ· . Suppose that t0 is not a split with respect to f. Then g is
Î³-integral and Î› is a C1 -match for g at t0 .
Proof. To show that g is Î³-integral, we need to check both conditions (I) and (II) of
Definition 31.1. To show (II), we note that since f is Î·-integral and b âˆˆ (d3 )!Î³Zd , it
follows by (31.32) that for all 1 â‰¤ i â‰¤ d we have
Î³
gi (t0 ) âˆˆ
Z.
mnd!
This is sufficient by the remark at the end of Definition 31.1. To show (I), we need to
prove that all the corner points of g are multiples of Î³. Suppose that t is a corner point
def
for g. Then t âˆˆ Jk for some k (cf. (31.35)), and we let tâˆ— = min(Jk ). Now on the interval
(tâˆ— , t), for some i â‰¤ p + M+ < j, the slopes of gp+1, ..., gi are all equal to 1/m, the slopes

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

109

of gj+1 , ..., gq are all equal to âˆ’1/n. We can without loss of generality assume that
gi+1 (t) = ... = gj (t) = z(t)
and
gi (t) = z(t) or gj+1(t) = z(t).
Note that we may choose gi (t) = z(t) over gj+1(t) = z(t), without any loss of generality.
def
(Here z(t) is the same as in proof of Lemma 31.14.) Then, letting âˆ†t = t âˆ’ tâˆ— , on the one
hand we have that
q
X

gk (t) =

p+1

i
X
p+1

gk (t) +

q
X
j+1

gk (t) + (j âˆ’ i)gi (t)



q
âˆ†t X
âˆ†t
âˆ†t
=
gk (tâˆ— ) + (i âˆ’ p)
,
gk (tâˆ— ) âˆ’ (q âˆ’ j)
+
+ (j âˆ’ i) gi (tâˆ— ) +
m
n
m
p+1
j+1
i
X

while, on the other, using (31.37), we have that


q
q
X
X
M+ Mâˆ’
âˆ†t.
âˆ’
gk (tâˆ— ) +
gk (t) =
m
n
p+1
p+1
Solving for âˆ†t gives us that
(A/m + A/n)âˆ†t âˆˆ (d3 )!Î³Z
def

where A = j âˆ’ (p + M+ ) âˆˆ (0, Mâˆ’ ]Z, and therefore that
(m + n)A(t âˆ’ tâˆ— ) âˆˆ (d3 )!Î³Z.
It thus follows that t âˆˆ Î³Z. This completes the proof that g is Î³-integral.
Since g(t0 ) = f(t0 ) + b, (31.39) implies that condition (I) of Definition 31.9 holds with
C = C1 and t = t0 . Let I+ be an interval of linearity for both f and g whose left endpoint
is t0 , and let (p, q]Z be an interval of equality for f on I+ . Then fq (t) < fq+1 (t), so since f
is Î·-integral, by (31.39) we have hq (Î›) < hq+1 (Î›). For each j âˆˆ (p, q]Z âˆ© Q(t0 ), let Vj be a
Î›-rational subspace of the linear span of {r âˆˆ Î› : krk â‰¤ Î»j (Î›)} of dimension j. Then

dim(Vj âˆ© L) â‰¥ max dim(Vp âˆ© L), dim(Vq âˆ© L) âˆ’ (q âˆ’ j)

â‰¥ max Lâˆ’ (f, I+ , p), Lâˆ’ (f, I+ , q) âˆ’ (q âˆ’ j) = Lâˆ’ (f, I+ , j) = Lâˆ’ (g, I+ , j),

where the second-to-last equality follows from the assumption that t0 is not a split for f.
This concludes the proof of Lemma 31.15.


110

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

31.4. Uniform error bounds. We are now ready to complete the proof of (31.1). First,
by Lemma 31.4 we can without loss of generality assume that f is simple and that its
corner points are all multiples of 2Î·, where Î· = kÎ· Î³, kÎ· âˆˆ N is large to be determined,
and Î³ is as above. After translating by Î·, we can assume that the corner points are at odd
multiples of Î· instead of even multiples. We can now define Aliceâ€™s strategy as follows:
Fix â„“ âˆˆ N and let kâ„“ = 2â„“kÎ· , and suppose that the game has progressed to turn kâ„“ . This
means that the lattice Î›(â„“) := Î›kâ„“ has already been defined.
â€¢ If Î›(â„“) is not a CÎ· -match for f at tâ„“ := kâ„“ Î³ = 2â„“kÎ· Î³, then Alice resigns on turn kâ„“ .
â€¢ Suppose that Î›(â„“) is a CÎ· -match for f at tâ„“ . Let b = b(â„“) be the element of (d3 )!Î³Zd
closest to h(Î›(â„“) ) âˆ’ f(tâ„“ ) (using any tiebreaking mechanism). Then b is a perturbation vector satisfying (31.39) with Î› = Î›(â„“) , t0 = tâ„“ , and C1 = (1/2)(d3)!Î³. Let
g = g(â„“) be the b-perturbation of f at tâ„“ . Then by Lemma 31.15, g is Î³-integral
and Î›(â„“) is a C1 -match for g. This allows us to apply Lemma 31.10 (setting k1
and k2 Lemma 31.10 to be kâ„“ and kâ„“+1 , respectively), and on turns kâ„“ , . . . , kâ„“+1 âˆ’ 1
Alice plays the strategy given by this lemma.
We assume that Alice does not resign at turn kâ„“ . Let tâ€²â„“ := (2â„“ + 1)Î·. Since f is linear
(â„“)
(â„“)
on I0 := [tâ„“ , tâ€²â„“ ] and I1 := [tâ€²â„“ , tâ„“+1 ], it follows that g is linear on [tâ„“ + s, tâ€²â„“ âˆ’ s] and
[tâ€²â„“ + s, tâ„“+1 ]. On the other hand, note that in the proof of Lemma 31.14, (31.37) and the
following bullet points imply that on each interval Jk = [tâ„“ , tâ„“ + s] or [tâ€²â„“ âˆ’ s, tâ€²â„“ + s], g only
changes slopes at points t such that gi < gj on (min(Jk ), t) and gi = gj on (t, max(Jk ))
for some i < j. It follows that g has at most d âˆ’ 1 maximal intervals of linearity on Jk ,
and thus at most 2d maximal intervals of linearity on Iâ„“ . In particular we have N â‰¤ 2d in
Lemma 31.10.
To compute the relation between b(â„“) and b(â„“+1) , we let a(â„“) : N âˆª {âˆ’1} â†’ Rd be the
function defined in Â§31.3, so that a(â„“) (âˆ’1) = b(â„“) . Then we have
g(â„“) = f + a(â„“) (0) on Ie0 = [tâ„“ + s, tâ€²â„“ âˆ’ s],
(â„“)

(â„“)
(â„“)
(â„“)
g(â„“) = f + a(â„“) (1) on Ie1 âˆª J2 âˆª Ie2 = [tâ€²â„“ + s, tâ€²â„“+1 âˆ’ s].
(â„“)

The second equality follows from the fact that t2 = tâ„“+1 is not a corner point, so a(â„“) (1) =
a(â„“) (2) and thus Case 1 of the proof of Lemma 31.14 applies. In particular, we have
g(â„“) (tâ„“+1 ) = f(tâ„“+1 ) + a(â„“) (1).
On the other hand, according to part (ii) of Lemma 31.10, Î›(â„“+1) := Î›kâ„“+1 is a C2 -match
for g(â„“) at tâ„“+1 , where C2 is a constant depending only on C1 . Thus, using (I) of Definition

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

111

31.9, we have
h(Î›(â„“+1) ) âˆ’ [f(tâ„“+1 ) + a(â„“) (1)]

and so by the definition of b(â„“+1) , we have

âˆ

â‰¤ C2 ,

kb(â„“+1) âˆ’ a(â„“) (1)kâˆ â‰¤ C2 + C1 ,

(31.40)

assuming that Alice does not resign on turn kâ„“+1 .
Assume now that there exists a constant B > 0 (which is independent of Bobâ€™s strategy)
such that
(31.41)

kb(â„“) kâˆ â‰¤ B for all â„“ such that Alice does not resign on or before turn kâ„“ .

Fix â„“ such that Alice does not resign on or before turn kâ„“ . Then Î›(â„“+1) is a C2 -match for
g(â„“) at tâ„“+1 , and is therefore a (C2 +B)-match for f at tâ„“+1 , since ka(â„“) (1)kâˆ â‰¤ kb(â„“) kâˆ â‰¤ B.
Letting kÎ· be large enough so that Î· â‰¥ 4mnd!(C2 + B), we see that Î›(â„“+1) is a CÎ· -match
for f at tâ„“+1 , and thus Alice does not resign on turn kâ„“+1 . So by induction Alice never
resigns.
So for all â„“ âˆˆ N, Î›(â„“) is a C-match for f at tâ„“ , where C := C2 + B. It follows from
Definition 31.9 that for all â„“ âˆˆ N
kh(Î›â„“ ) âˆ’ f (tâ„“ )k â‰¤ C
and so using Lemma 29.2 gives us that the final outcome Xâˆ (as defined by (29.2)) is in
the target set D(f).
To compute Aliceâ€™s score, we use part (iii) of Lemma 31.10 to get that

1X
1X
âˆ†(A, [0, kâ„“ ]) =
âˆ†(A, [kj , kj+1]) =
Î´(f, [tj , tj+1]) + O Î³1 +
â„“ j=0
â„“ j=0


1
1
= Î´(f, [0, tâ„“ ]) + O Î³ + kÎ·
â„“âˆ’1

â„“âˆ’1

and thus after taking liminfs on both sides we have

Î´(A) = Î´(f) + O Î³1 +

1
kÎ·



1
2kÎ·



.

Given Îµ > 0, we can choose Î² small enough (and so Î³ large enough) and kÎ· large enough
so that the last term is less than Îµ, which shows that Î´(A) â‰¥ Î´(f) âˆ’ Îµ, and thus D(f)
is (Î´(f) âˆ’ Îµ)-dimensionally Hausdorff Î²-winning. Applying Theorem 28.2 shows that
dimH (D(f)) â‰¥ Î´(f) âˆ’ Îµ. Now in the above argument we can replace all Î´s by Î´s, and
all liminfs by limsups, to prove that dimP (D(f)) â‰¥ Î´(f) âˆ’ Îµ. This completes the proof of
(31.1) assuming (31.41). In what follows we will prove (31.41).

112

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Given q = 0, . . . , d, an interval [â„“1 , â„“2 ] will be called a q-interval if either
fq < fq+1 on (tâ€²â„“1 âˆ’1 , tâ€²â„“2 )
or
â€²
= c on (tâ€²â„“1 âˆ’1 , tâ€²â„“2 ), where c âˆˆ { m1 , âˆ’ n1 }Â·
fqâ€² = fq+1

Note that every interval is both a 0-interval and a d-interval (according to our convention
that f0 = âˆ’âˆ and fd+1 = +âˆ).
Claim 31.16. Fix q = 1, . . . , d âˆ’ 1 and let [â„“1 , â„“2 ] be a q-interval. Then there exists a constant
Î± = Î±(q, â„“1, â„“2 ) such that for all â„“ = â„“1 , . . . , â„“2 , we have
q
X

(31.42)

i=1

(â„“)

bi â‰+,Î² Î±(q, â„“1 , â„“2 ).

Proof. First suppose that fq < fq+1 on (tâ€²â„“1 âˆ’1 , tâ€²â„“2 ). Since Î›(â„“) is a C2 -match for g(â„“) at tâ„“ , we
have
q
q
X
X
(â„“)
hi (Î›(â„“) ) âˆ’ Fq (tâ„“ ).
bi â‰+,Î²
i=1

i=1

Let V

(â„“)

=

(â„“)
Vq

be as in Lemma 30.5 (applied to the lattice Î›(â„“) ), and recall we have
q
X
i=1

hi (Î›(â„“) ) â‰+ log kV (â„“) k.

Since fq < fq+1 on (tâ€²â„“1 âˆ’1 , tâ€²â„“2 ), we have guXâ„“ V (â„“) = V (â„“+1) for all â„“.
Since we know that Alice is following her strategy, as defined in the proof of Lemma
31.10, then for each turn k = kâ„“1 âˆ’ kÎ· , . . . , kâ„“2 + kÎ· the matrix Xk is good on turn k (as
defined in (31.17)-(31.18)). Thus the hypotheses of Lemma 30.7 are satisfied, and it
then follows that
â€²
log kV (â„“ ) k âˆ’ log kV (â„“) k â‰+,Î² (tâ„“â€² âˆ’ tâ„“ )z

for any â„“ < â„“â€² such that Fqâ€² = z on (tâ„“ , tâ„“â€² ). Note that a similar argument appeared earlier
in the paragraph containing (31.19). Now since Fq is piecewise linear on (tâ€²â„“1 âˆ’1 , tâ€²â„“2 ) with
a bounded number of intervals of linearity, it follows that
Ë† tâ„“
(â„“)
(â„“1 )
log kV k âˆ’ log kV k â‰+,Î²
Fqâ€² = Fq (tâ„“ ) âˆ’ Fq (tâ„“1 ).
tâ„“1

Thus, letting
def

Î±(q, â„“1 , â„“2 ) = log kV (â„“1 ) k âˆ’ Fq (tâ„“1 )

completes the proof of the claim in the case fq < fq+1 on (tâ€²â„“1 âˆ’1 , tâ€²â„“2 ).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

113

â€²
Now suppose that fq = fq+1 and fqâ€² = fq+1
= m1 on I0 = (tâ€²â„“1 âˆ’1 , tâ€²â„“2 ) (the case where
â€²
fqâ€² = fq+1
= âˆ’ n1 on I0 proceeds similarly). For each interval of linearity I âŠ† I0 and for
each t âˆˆ I, let (p(t), r(t)]Z be the interval of equality for I that contains q. Since m1 is
â€²
the maximum possible derivative for any fj and since fqâ€² = fq+1
= m1 on I0 , it follows
that fq = fq+1 can only merge with fj if j > q + 1, and can only split from fj if j < q;
equivalently, p and r are increasing functions. Since p, r are integer-valued, it follows that
I0 can be decomposed into a bounded number of intervals on which p, r are constant. So
we can without loss of generality suppose that p and r are constant. But then by the same
logic as before we have
â€²

log kVp(â„“ ) k âˆ’ log kVp(â„“) k â‰+,Î² (tâ„“â€² âˆ’ tâ„“ )zp ,
â€²

log kVr(â„“ ) k âˆ’ log kVr(â„“) k â‰+,Î² (tâ„“â€² âˆ’ tâ„“ )zr ,
where zp , zr âˆˆ [âˆ’ n1 , m1 ] satisfy
zr âˆ’ zp =

(31.43)

râˆ’p
Â·
m

Now let
def

(â„“)

and note that hVj

h = (guXâ„“â€²âˆ’1 ) Â· Â· Â· (guXâ„“ )

(â„“â€² )

= Vj

. Furthermore, we have

khk . exp 2(â„“â€² âˆ’ â„“)kÎ· Â· m1 = exp (tâ„“â€² âˆ’ tâ„“ ) Â·
(â„“)

(â„“)

where k Â· k denotes the operator norm. Letting h : Vq /Vp
map, we have khk â‰¤ khk and thus

1
m



(â„“â€² )

â†’ Vq

(â„“â€² )

/Vp

be the induced

 (â„“) (â„“)
â€²
â€²
kVq(â„“ ) /Vp(â„“ ) k . khkqâˆ’p kVq(â„“) /Vp(â„“) k . exp (tâ„“â€² âˆ’ tâ„“ ) qâˆ’p
kVq /Vp k.
m

Since the covolume of a quotient space is the quotient of the covolumes, taking logarithms
gives
â€²

â€²

log kVq(â„“ ) k âˆ’ log kVq(â„“) k .+ log kVp(â„“ ) k âˆ’ log kVp(â„“) k + (tâ„“â€² âˆ’ tâ„“ ) qâˆ’p
m

qâˆ’p
â‰ (tâ„“â€² âˆ’ tâ„“ ) zp + m

A similar argument shows that
â€²

log kVq(â„“ ) k âˆ’ log kVq(â„“) k &+ (tâ„“â€² âˆ’ tâ„“ ) zr âˆ’
Next, we observe that (31.43) can be rearranged to yield
def

zq = zp +

qâˆ’p
m

= zr âˆ’

râˆ’q
m

râˆ’q
m



.

114

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

and thus we have
â€²

log kVq(â„“ ) k âˆ’ log kVq(â„“) k â‰+ (tâ„“â€² âˆ’ tâ„“ )zq .
The proof can be continued in the same way as in the earlier case. A similar argument
â€²
applies if fqâ€² = fq+1
= âˆ’ n1 on (tâ€²â„“1 âˆ’1 , tâ€²â„“2 ). This concludes the proof of Claim 31.16.

Now fix â„“ âˆˆ N and q = 1, . . . , d âˆ’ 1. If â„“ is contained in a q-interval then we let
Î±(q, â„“) = Î±(q, â„“1 , â„“2 ),
where [â„“1 , â„“2 ] is the longest q-interval containing â„“. Otherwise, we let Î±(q, â„“) = âˆ—. Next,
we let c(â„“) âˆˆ Rd be the unique vector such that
(31.44)

q
X

(â„“)

when Î±(q, â„“) âˆˆ R,

ci = Î±(q, â„“)

i=1

(31.45)

(â„“)

c(â„“)
q = cq+1

when Î±(q, â„“) = âˆ—.

Then by (31.29) and (31.42), we have
c(â„“) â‰+,Î² b(â„“) .
For convenience, we introduce a slightly modified version of intervals of equality (see
Definition 4.5). We call an interval (p, q]Z an interval of mixing for f on I if either
â€¢ (p, q]Z is an interval of equality for f on I, and fqâ€² âˆˆ
/ { m1 , âˆ’ n1 } on I, or
â€¢ q = p + 1 and fqâ€² âˆˆ { m1 , âˆ’ n1 } on I.

Note that if (p, q]Z is an interval of mixing for f on Iâ„“ := (tâ€²â„“âˆ’1 , tâ€²â„“ ), then [â„“, â„“] is both a
p-interval and a q-interval.
(â„“âˆ’1)
Let (p, q]Z be an interval of mixing for f on Iâ„“ . Then by (31.29), we have ai
(1) = a
(â„“)
for all i âˆˆ (p, q]Z, where a is a constant. By (31.40), we have |bi âˆ’ a| â‰¤ C2 + C1 for all
(â„“)
i âˆˆ (p, q]Z, and thus by (31.29), we have |ai (0) âˆ’ a| â‰¤ C2 + C1 for all i âˆˆ (p, q]Z. On the
(â„“)
other hand, for i = 1, . . . , d such that fiâ€² âˆˆ { m1 , âˆ’ n1 } on Iâ„“ , (31.29) implies that ai (0) = bi .
Thus
ka(â„“) (0) âˆ’ b(â„“) k â‰¤ 2(C2 + C1 )
and consequently a(â„“) (0) â‰+,Î² c(â„“) . On the other hand, by (31.40) we have a(â„“) (1) â‰+,Î²
c(â„“+1) , so by (31.29), for every interval of mixing (p, q]Z for f on Iâ„“+1 , we have

(31.46)

(â„“+1)
ci

â‰+,Î²

q
1 X (â„“)
c .
q âˆ’ p j=p+1 j
(â„“)

(â„“)

Let B be a large number, fix Îµ âˆˆ {Â±1}, and write ci = B + Îµci . We claim that there
exist constants C(1), . . . , C(d) â‰¥ 0, independent of B, such that if B â‰¥ maxi C(i)/i, then

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

115

for all j < k and â„“ âˆˆ N we have
k
X

(31.47)

(â„“)

i=j+1

ci â‰¥ C(k âˆ’ j).

P
(â„“)
Indeed, when â„“ = 0, we have c(0) = 0 and thus ki=j+1 ci = (k âˆ’ j)B â‰¥ C(k âˆ’ j). For
the inductive step, fix â„“ âˆˆ N and suppose that (31.47) holds for all j < k. Fix j < k, and
we will show that
k
X

(31.48)

(â„“+1)

ci

i=j+1

â‰¥ C(k âˆ’ j).

Case 1. Suppose that [â„“, â„“ + 1] is both a j-interval and a k-interval. Then Î±(j, â„“) =
Î±(j, â„“ + 1) âˆˆ R and similarly for k. So
k
X

i=j+1

(â„“)

ci = Î±(k, â„“) âˆ’ Î±(j, â„“) = Î±(k, â„“ + 1) âˆ’ Î±(j, â„“ + 1) =

and thus

k
X

(â„“+1)

ci

=

k
X

(â„“+1)

ci

i=j+1

(â„“)

i=j+1

i=j+1

k
X

ci â‰¥ C(k âˆ’ j).

Case 2. Suppose that [â„“, â„“ + 1] is a j-interval but not a k-interval. Let (p, q]Z âˆ‹ k be an
interval of mixing for f on either Iâ„“ or Iâ„“+1 . Then by (31.46), we have
(â„“+1)
ci

(31.49)

â‰+,Î²

q
1 X (â„“)
c for all i âˆˆ (p, q]Z.
q âˆ’ p i=p+1 i

In the latter case this follows directly from (31.46), while if (p, q]Z is an interval of mixing
(â„“)
for f on Iâ„“ , then by (31.46) we have ci â‰+,Î² c for all i âˆˆ (p, q]Z for some constant c, and
applying (31.46) again gives (31.49). On the other hand, since [â„“, â„“ + 1] is a j-interval we
have j â‰¤ p, and thus the previous case gives
p
X

i=j+1

(â„“)

ci =

p
X

(â„“+1)

ci

.

i=j+1

So
k
X

i=j+1

(â„“+1)
ci

â‰+,Î²

p
X

i=j+1

(â„“)
ci

q
k+1
k âˆ’ p X (â„“) 1 X (â„“) 1
+
ci â‰¥
c â‰¥ C(k + 1 âˆ’ j).
q âˆ’ p i=p+1
d i=j+1 i
d

116

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Let C denote the implied constant of the asymptotic, and let C(1), . . . , C(d) be defined
by the recursive formula
def

def

C(1) = 0,

C(k + 1) = d(C(k) + C).

Then we have demonstrated (31.48), completing the inductive step.
Case 3. If [â„“, â„“ + 1] is a k-interval but not a j-interval, or is neither a j-interval nor a
k-interval, then the proof is similar to Case 2. We leave the details to the reader.
This completes the proof of (31.47), which in turn implies (31.41), thereby completing
the proof of (31.1). Thus, we have completed proving the lower bounds in Theorem 4.6.

32. P ROOF

OF

T HEOREM 4.6,

UPPER BOUND

Let S be a class of functions from [0, âˆ) to Rd closed under finite perturbations. We
claim that
dimH (S) â‰¤

sup

Î´(f),

f âˆˆSâˆ©Tm,n

dimP (S) â‰¤

sup

Î´(f),

f âˆˆSâˆ©Tm,n

where S = D(S) is as in (4.14). As in the proof of the lower bounds, we will play the
modified Hausdorff and packing games with target set S and parameter 0 < Î² < 1. This
time, we will define a strategy for Bob for sufficiently small Î².
Definition of the strategy. Suppose that the game has progressed to turn k, with
corresponding lattice Î›k as in Â§29. Let {r1 , . . . , rd } be a Minkowski basis of Î›k (cf. Lemma
P
30.5), and for each q = 0, . . . , d let Vq = qi=1 Rri . Essentially, Bobâ€™s strategy will be to
â€œpush the subspaces Vq away from L as much as possible given Aliceâ€™s moveâ€. To make
this precise, fix X âˆˆ BM (0, 1 âˆ’ Î²), and for each q = 0, . . . , d let
(32.1)

def

âˆ’
Lâˆ’
q = Lq (k, X) =

sup dim(uX+Y Vq âˆ© L),

kY kâ‰¤2Î²

def

âˆ’
L+
q = q âˆ’ Lq .

Let
def

+
âˆ’
âˆ’
S+ = S+ (k, X) = {q = 1, . . . , d : L+
q = Lqâˆ’1 + 1 and Lq = Lqâˆ’1 },
def

âˆ’
+
+
Sâˆ’ = Sâˆ’ (k, X) = {q = 1, . . . , d : Lâˆ’
q = Lqâˆ’1 + 1 and Lq = Lqâˆ’1 },

and note that S+ âˆª Sâˆ’ = (0, d]Z and #(SÂ± ) = dÂ± , where d+ = m, dâˆ’ = n (see (4.2)). Also
note that LÂ±
q = #(SÂ± âˆ© (0, q]Z) for all q = 1, . . . , d. Finally, let Î´(k, X) = Î´(S+ , Sâˆ’ ), where

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

117

as in (4.13),
def

Î´(T+ , Tâˆ’ ) = #{(i+ , iâˆ’ ) âˆˆ T+ Ã— Tâˆ’ : i+ > iâˆ’ }.
Bobâ€™s strategy on turn k can now be given as follows: If Alice makes the move Ak âŠ†
BM (0, 1 âˆ’ Î²), then Bob responds by choosing Xk âˆˆ Ak so as to maximize Î´(k, Xk ).
Note that larger values of Î´(k, Xk ) correspond to larger values of L+
q and correspondâˆ’
ingly smaller values of Lq , which in turn correspond to the intuitive idea of â€œpushing Vq
away from L (by a distance of at least 2Î²)â€.
The following claim will be used to relate scores in the Hausdorff and packing games
with the dimensions of templates.
Claim 32.1. For all k we have
#(Ak ) . Î² âˆ’Î´(k,Xk ) .
Proof. Let Î´ = Î´(k, Xk ). Clearly,
[ 
Ak âŠ† {X : Î´(k, X) â‰¤ Î´} âŠ†
X : Lâˆ’
q (X) â‰¥ #(Tâˆ’ âˆ© (0, q]Z) for all q = 1, . . . , d ,
T+ ,Tâˆ’

where the union is taken over all sets T+ , Tâˆ’ âŠ† (0, d]Z such that T+ âˆ© Tâˆ’ = , T+ âˆª Tâˆ’ =
(0, d]Z, #(TÂ± ) = dÂ± , and
Î´(T+ , Tâˆ’ ) â‰¤ Î´.
bâˆ’ = #(Tâˆ’ âˆ© (0, q]Z). We need to
Fix T+ , Tâˆ’ as above, and for each q = 1, . . . , d let L
q
estimate the size of the set

Since Ak =

S

T+ ,Tâˆ’

def
bâˆ’
Ak (T+ , Tâˆ’ ) = {X âˆˆ Ak : Lâˆ’
q (X) â‰¥ Lq for all q}.

Ak (T+ , Tâˆ’ ), to complete the proof it suffices to show that
#(Ak (T+ , Tâˆ’ )) . Î² âˆ’Î´ .

bâˆ’
Note that for each X âˆˆ BM (0, 1 âˆ’ Î²) and q = 1, . . . , d, we have Lâˆ’
q (X) â‰¥ Lq if and only
if X is in the 2Î²-neighborhood of the algebraic set
bâˆ’ } âŠ† M.
Zq = {X : dim(uX Vq âˆ© L) â‰¥ L
q

Thus,

Ak (T+ , Tâˆ’ ) âŠ†
Let Z =
(32.2)

Td

q=1

Zq . We claim that
d
\

q=1

d
\

q=1

N (Zq , 2Î²).

N (Zq , 2Î²) âŠ† N (Z, CÎ²)

118

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

for some uniform constant C. Indeed, fix X âˆˆ
choose Xq âˆˆ Zq âˆ© B(X, 2Î²), and let

T

q

N (Zq , 2Î²). For each q = 1, . . . , d,

Vbq = uXq Vq âˆ© L.

Next, for q = 1, . . . , d we recursively define
câŠ¥ ,
Wq = Vbq âˆ© W
qâˆ’1

cq = W1 + . . . + Wq ,
W

c0 = {0}. Note that since Xq âˆˆ Zq ,
with the understanding that W

cq ) = dim W
cqâˆ’1 + (Vbq âˆ© W
c âŠ¥ ) â‰¥ dim(Vbq ) â‰¥ L
bâˆ’ .
dim(W
qâˆ’1
q

Let Z be the unique matrix such that uâˆ’Z v = uâˆ’Xq v for all q = 1, . . . , d and v âˆˆ Wq .
cd = W1 + . . . + Wd is an orthogonal decomposition, such a Z exists, and we
Since L = W
have kZ âˆ’ Xk â‰¤ CÎ² for some constant C. Now fix q = 1, . . . , d. For all p = 1, . . . , q and
cq âŠ† Vq and thus
v âˆˆ Wp , we have uâˆ’Z v = uâˆ’Xp v âˆˆ Vp âŠ† Vq . This implies that uâˆ’Z W
cq ) â‰¥ L
bâˆ’ ,
dim(uZ Vq âˆ© L) â‰¥ dim(W
q

so Z âˆˆ Zq . Since q was arbitrary, we have Z âˆˆ Z, and thus X âˆˆ N (Z, CÎ²), where C is
the constant above. This completes the proof of (32.2).
So Ak (T+ , Tâˆ’ ) âŠ† N (Z, CÎ²), where Ak (T+ , Tâˆ’ ) is a 3Î²-separated set and Z is an algebraic set whose diagram in the sense of [66, Definition 4.2] is constant (i.e. independent
of k and Î²). By [66, Corollary 5.7], it follows that
#(Ak (T+ , Tâˆ’ )) . Î² âˆ’ dim(Z) ,
whereas we wish to show that #(Ak (T+ , Tâˆ’ )) . Î² âˆ’Î´ . So to complete the proof we must
show that dim(Z) â‰¤ Î´.
Consider first the case where the subspaces Vq (q = 1, . . . , d) are all coordinate subP
bâˆ’
spaces, i.e. Vq = iâˆˆIq Rei for some Iq âŠ† (0, d]Z, and where dim(Vq âˆ© L) = L
q for all q.
P
âˆ’
In this case, we write I = {m + 1, . . . , d}, so that L = iâˆˆI âˆ’ Rei . Let Ïƒ be the unique
permutation of (0, d]Z such that for each q = 1, . . . , d, we have Iq = {Ïƒ(1), . . . , Ïƒ(q)}. Then
since
bâˆ’
#(Iq âˆ© Iâˆ’ ) = L
q = #(Tâˆ’ âˆ© (0, q]Z) for all q,
we have Iâˆ’ = Ïƒ(Tâˆ’ ).
It is readily verified that X âˆˆ Z if and only if Xi,j = 0 for all i = 1, . . . , m and j =
1, . . . , n such that
Ïƒ âˆ’1 (i) > Ïƒ âˆ’1 (m + j).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

119

Thus, dim(Z) is equal to the number of pairs (i, j) âˆˆ {1, . . . , m} Ã— {1, . . . , n} such that
Ïƒ âˆ’1 (i) < Ïƒ âˆ’1 (m + j), or equivalently the number of pairs (i+ , iâˆ’ ) âˆˆ T+ Ã— Tâˆ’ such that
i+ < iâˆ’ . In other words, dim(Z) = Î´(T+ , Tâˆ’ ) â‰¤ Î´.
For the general case, note that the map X 7â†’ uâˆ’X L is a coordinate chart for the
Grassmannian variety G = G(d, n) of n-dimensional subspaces of Rd . So it suffices to
show that dim(Z â€² ) â‰¤ Î´, where
bâˆ’
Z â€² = {W âˆˆ G : dim(Vq âˆ© W ) â‰¥ L
q for all q}.

Let W be a smooth point of Z â€² (i.e. a point where the tangent space to Z â€² at W is defined)
bâˆ’
such that the local dimension of Z â€² at W is equal to dim(Z â€² ). Then dim(Vq âˆ© W ) = L
q
for all q. Moreover, there is a basis of Rd such that the subspaces Vq (q = 1, . . . , d) and W
are all coordinate subspaces with respect to this basis. So from the previous argument, it
follows that dim(Z â€² âˆ© U) = Î´, where U is a neighborhood of W (depending on the basis).
Since the local dimension of Z â€² at W is equal to dim(Z â€² ), this shows that dim(Z â€² ) = Î´. 
Now suppose that the game is played according to Bobâ€™s strategy, let A denote the
outcome, and suppose that the corresponding successive minima function hA is in S. By
Lemma 31.4, there exists a template g such that g â‰+ hA . Fix a large constant C1 â‰¥ Î³.
Applying Lemma 31.4 again, there exists a template f such that f â‰+,C1 g and such that
for all q, t, tâ€² such that fq (t) < fq+1 (t) and |tâ€² âˆ’ t| â‰¤ C1 , we have gq+1(tâ€² ) âˆ’ gq (tâ€² ) â‰¥ C1 and
Fqâ€² (t) â‰¥ Gâ€²q (tâ€² ). Since hA âˆˆ S and S is closed under finite perturbations, we have f âˆˆ S.
Claim 32.2. We have
Î´(f) â‰¥ Î´ âˆ’ O(1/ log Î²),

Î´(f) â‰¥ Î´ âˆ’ O(1/ log Î²),

where Î´ and Î´ denote Aliceâ€™s scores (see Definition 28.1) in the Hausdorff and packing games,
respectively.
Proof. It suffices to show that for all k âˆˆ N and tâ€² âˆˆ [kÎ³, (k + 1)Î³],
Î´(f, tâ€² ) â‰¥

log #(Ak ) âˆ’ O(1)
Â·
âˆ’ log(Î²)

Indeed, fix such k, tâ€² , and let t = kÎ³. By Claim 32.1, we have
Î´(k, Xk ) â‰¥

log #(Ak ) âˆ’ O(1)
,
âˆ’ log(Î²)

so to complete the proof it suffices to show that
Î´(f, tâ€² ) â‰¥ Î´(k, Xk ).

120

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

Indeed, fix q = 1, . . . , d âˆ’ 1 such that fq (tâ€² ) < fq+1 (tâ€² ), and we will show that
L+ (f, tâ€² , q) â‰¥ L+
q .

(32.3)

Indeed, first note that by assumption, and since C1 â‰¥ Î³, the inequality fq (tâ€² ) < fq+1 (tâ€² )
implies that gq+1 (t) âˆ’ gq (t) â‰¥ C1 . Now by the definition of g and Lemma 29.2, we have
g(t) â‰+ hA (t) â‰+ h(Î›k )
and thus we in fact get log Î»q+1 (Î›k ) âˆ’ log Î»q (Î›k ) &+ C1 .
Now let
âˆ
X
Zk =
Î² â„“âˆ’k Xâ„“ âˆˆ BM (Xk , Î²) âŠ† BM (0, 1).
â„“=k

By (32.1), we have

sup dim(uZk +Y Vq âˆ© L) â‰¤ Lâˆ’
q .

kY kâ‰¤Î²

Thus by Lemma 30.7, for all s â‰¥ 0, we have
log kgs uZk Vq k &+,Î² log kVq k +

(32.4)



L+
Lâˆ’
q
q
âˆ’
m
n



s.

On the other hand, since log Î»q+1 (Î›k ) âˆ’ log Î»q (Î›k ) &+ C1 , for all Vqâ€² âˆˆ Vq (Î›k ) \ {Vq }, by
Lemma 30.6 we have
log kVqâ€² k âˆ’ log kVq k &+ C1
and thus for all 0 â‰¤ s â‰¤

mn
C,
qd 1

since log kgsâˆ’1k â‰¤ s/n, we have

q
q
log kgs uZk Vqâ€² k &+ log kVqâ€² k âˆ’ s &+ log kVq k + C1 âˆ’ s
n
n

 +
L
Lâˆ’
q
q
q
â‰¥ log kVq k + s â‰¥ log kVq k +
s.
âˆ’
m
m
n

Combining with (32.4) gives
inf

Vqâ€² âˆˆVq (Î›k )

log kgs uZk Vqâ€² k

&+,Î² log kVq k +



Lâˆ’
L+
q
q
âˆ’
m
n



s.

On the other hand, since g â‰+ hA , by Lemmas 30.5 and 29.2, we have
log kVq k â‰+
inf

Vqâ€² âˆˆVq (Î›k )

log kgs uZk Vqâ€² k â‰+

q
X
i=1
q

X
i=1

log Î»i (Î›k ) â‰+ Gq (t),
log Î»i (gs uZk Î›k ) â‰+ Gq (t + s),

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

so
Gq (t + s) &+,Î² Gq (t) +
Rearranging gives
Ë†
Suppose that Gâ€²q <

L+
q
m

âˆ’

Lâˆ’
q
n

t+s
t

&+,Î²



L+
Lâˆ’
q
q
âˆ’
m
n

Lâˆ’
L+
q
q
âˆ’
m
n





s.

s.

on [t, t + s]. Then since g is a template,

Gâ€²q â‰¤
and thus

Gâ€²q



121

L+
Lâˆ’
q âˆ’1
q +1
âˆ’
on [t, t + s]
m
n


 +

Lq
Lâˆ’
Lâˆ’
L+
q +1
q
q âˆ’1
s &+,Î²
s
âˆ’
âˆ’
m
n
m
n
which implies s â‰+,Î² 0, i.e. |s| â‰¤ C2 for some constant C2 . Let C1 , s be chosen so that
C ) and Î³ â‰¤ C1 . Then the inequality |s| â‰¤ C2 contradicts the
C2 < s â‰¤ min(C1 , mn
qd 1


definition of s, so the hypothesis that Gâ€²q <
L+
q
m

Lâˆ’
q
n

L+
q
m

âˆ’

Lâˆ’
q
n

on [t, t + s] must be incorrect, i.e. we

must have Gâ€²q (tâ€²â€² ) â‰¥
âˆ’
for some tâ€²â€² âˆˆ [t, t + s]. Now since tâ€² , tâ€²â€² âˆˆ [t, t + C1 ], we have
|tâ€²â€² âˆ’ tâ€² | â‰¤ C1 , and thus by our assumptions on f we have
L+
Lâˆ’
L+ (f, tâ€² , q) Lâˆ’ (f, tâ€² , q)
q
q
â€² â€²
â€² â€²â€²
âˆ’
= Fq (t ) â‰¥ Gq (t ) â‰¥
âˆ’
m
n
m
n
demonstrating (32.3).
To summarize, we have


# S+ (f, tâ€² ) âˆ© (0, q]Z â‰¥ # S+ (k, Xk ) âˆ© (0, q]Z

for all q such that fq (tâ€² ) < fq+1 (tâ€² ). It follows from (4.8) that the same inequality holds
for all q = 1, . . . , d âˆ’ 1. Since
 
dâˆ’1
X

m
,
Î´(T+ , Tâˆ’ ) =
# T+ âˆ© (0, q] âˆ’
2
q=1
(where Î´ is as in (4.13)), we have

Î´(f, tâ€² ) = Î´(SÂ± (f, tâ€² )) â‰¥ Î´(SÂ± (k, Xk )) = Î´(k, Xk ).



Fix Î´ > supf âˆˆSâˆ©Tm,n Î´(f). Then by the previous Claim 32.2, we have Î´ > Î´ as long as Î²
is sufficiently small. So by Theorem 28.2, we have Î´ â‰¥ dimH (S). Since Î´ was arbitrary,
we have
dimH (S) â‰¤ sup Î´(f).
f âˆˆSâˆ©Tm,n

122

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

A similar argument gives the bound for the packing dimension, thereby completing the
proof of the upper bounds in Theorem 4.6.

Part 5. Appendix and references
A PPENDIX A. T RANSLATING

BETWEEN

S CHMIDTâ€“S UMMERERâ€™ S

NOTATION AND OURS

This appendix explains the relations between certain concepts and notation in our
paper and in Schmidtâ€“Summererâ€™s [61] to provide a guide for readers of both.
Schmidtâ€“Summerer are working in the framework of simultaneous approximation, so
n = 1 for them, and further: their n is our d = m + 1, their y is our r, their Î¾ is our A. In
particular, note that they have r = (q, p) instead of r = (p, q). Their Î›(Î¾) would translate
to uA Zd in our paper, and what they call K(Q) is what we would call gâˆ’t B, where Q = et
and B = [âˆ’1, 1]d . Finally, their T is our gâˆ’1 .
Schmidtâ€“Summererâ€™s set-up encodes the same geometric information as ours since
Î»i (gt uA Zd , B) = Î»i (uA Zd , gâˆ’t B).
Therefore, in their notation the right-hand side is Î»i (Î›(Î¾), K(Q)). Similarly, Li (q) in their
notation is the same as hi (t) in our notation, where q = t/(nâˆ’1). The connection between
our notion of a template (see Definition 4.1) and Schmidtâ€“Summererâ€™s (n, Î³)-systems (see
[61, Â§2]) is as follows: if P is an (n, 0)-system then
h(t) =

n
t
P (t) âˆ’
nâˆ’1
nâˆ’1

is an (n âˆ’ 1) Ã— 1 template.
We further remark that after Schmidtâ€“Summerer consider the limiting case of an (n, 0)system in [61, Â§3], they go on, in [61, Â§4, pg. 62], to conjecture that the study of these
systems should suffice to determine the spectra of the family of exponents of approximation that they are interested in. The rest of their paper develops a theory of covers of
an (n, Î³)-system, which is then applied to prove relations between several exponents of
approximation.
Interested readers are also referred to Royâ€™s paper [53] for translating between Schmidtâ€“
Summererâ€™s notation and his. In contrast to Schmidtâ€“Summerer who work in the simultaneous approximation framework, Roy works in the dual framework of approximation
by linear forms. Roy defines the notion of a rigid system (a special case of (n, 0)-systems)
in the introduction of [53] and goes on to prove that every (n, Î³)-system can be approximated by a rigid system up to bounded additive difference (see [53, Theorem 1.3]). Royâ€™s
rigid systems translate to our Î·-integral templates (see Definition 31.1).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

123

R EFERENCES
1. Jinpeng An, 2-dimensional badly approximable vectors and Schmidtâ€™s game, Duke Math. J. 165 (2016),
no. 2, 267â€“284. MR 3457674
2. Dzmitry Badziahin, Stephen Harrap, Erez Nesharim, and David Simmons, Schmidt games and Cantor
winning sets, https://arxiv.org/abs/1804.06499, preprint 2018.
3. M. Bachir Bekka and Matthias Mayer, Ergodic theory and topological dynamics of group actions on
homogeneous spaces, London Mathematical Society Lecture Note Series, vol. 269, Cambridge University
Press, Cambridge, 2000. MR 1781937
4. Victor Beresnevich and Sanju Velani, Arbeitsgemeinschaft: Diophantine Approximation, Fractal Geometry
and Dynamics, Oberwolfach Rep. 13 (2016), no. 4, 2749â€“2792, Abstracts from the Working Session
held October 9â€“14, 2016, Organized by Victor Beresnevich and Sanju Velani. MR 3757056
5. VasiliÄ±Ì† Ivanovich Bernik and Michael Maurice Dodson, Metric Diophantine approximation on manifolds, Cambridge Tracts in Mathematics, vol. 137, Cambridge University Press, Cambridge, 1999.
MR 1727177
6. A. S. Besicovitch, Sets of fractional dimensions (IV): On rational approximation to real numbers, J.
London Math. Soc. 9 (1934), no. 2, 126â€“131.
7. Christopher J. Bishop and Yuval Peres, Fractals in probability and analysis, Cambridge Studies in Advanced Mathematics, vol. 162, Cambridge University Press, Cambridge, 2017. MR 3616046
8. John Bovey and Maurice Dodson, The Hausdorff dimension of systems of linear forms, Acta Arith. 45
(1986), no. 4, 337â€“358.
9. Ryan Broderick, Lior Fishman, Dmitry Kleinbock, Asaf Reich, and Barak Weiss, The set of badly approximable vectors is strongly C 1 incompressible, Math. Proc. Cambridge Philos. Soc. 153 (2012), no. 2,
319â€“339. MR 2981929
10. Yann Bugeaud, Approximation by algebraic numbers, Cambridge Tracts in Mathematics, vol. 160, Cambridge University Press, Cambridge, 2004.
11. Yann Bugeaud, Yitwah Cheung, and Nicolas Chevallier, Hausdorff dimension and uniform exponents in
dimension two, Math. Proc. Cambridge Philos. Soc. 167 (2019), no. 2, 249â€“284. MR 3991371
12. Yann Bugeaud and Michel Laurent, On exponents of homogeneous and inhomogeneous Diophantine approximation, Mosc. Math. J. 5 (2005), no. 4, 747â€“766, 972. MR 2266457
13. John W. S. Cassels, An introduction to Diophantine approximation, Cambridge Tracts in Mathematics
and Mathematical Physics, No. 45, Cambridge University Press, New York, 1957.
, An introduction to the geometry of numbers. Corrected reprint of the 1971 edition, Classics in
14.
Mathematics, Springer-Verlag, Berlin, 1997.
15. Jonathan Chaika, Yitwah Cheung, and Howard Masur, Winning games for bounded geodesics in moduli
spaces of quadratic differentials, J. Mod. Dyn. 7 (2013), no. 3, 395â€“427. MR 3296560
16. Yitwah Cheung, Hausdorff dimension of the set of singular pairs, Ann. of Math. (2) 173 (2011), no. 1,
127â€“167.
17. Yitwah Cheung and Nicolas Chevallier, Hausdorff dimension of singular vectors, Duke Math. J. 165
(2016), no. 12, 2273â€“2329. MR 3544282
18. Colleen D. Cutler, Strong and weak duality principles for fractal dimension in Euclidean space, Math.
Proc. Cambridge Philos. Soc. 118 (1995), no. 3, 393â€“410. MR 1342960

124

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

19. S. G. Dani, Divergent trajectories of flows on homogeneous spaces and Diophantine approximation, J.
Reine Angew. Math. 359 (1985), 55â€“89. MR 794799
20. Shrikrishna Gopal Dani, On badly approximable numbers, Schmidt games and bounded orbits of flows,
Number theory and dynamical systems (York, 1987), London Math. Soc. Lecture Note Ser., vol. 134,
Cambridge Univ. Press, Cambridge, 1989, pp. 69â€“86. MR 1043706
21. Tushar Das, Lior Fishman, David Simmons, and Mariusz UrbanÌski, A variational principle in the parametric geometry of numbers, with applications to metric Diophantine approximation, C. R. Math. Acad.
Sci. Paris 355 (2017), no. 8, 835â€“846. MR 3693502
22. Harold Davenport and Wolfgang M. Schmidt, Dirichletâ€™s theorem on diophantine approximation. II, Acta
Arith. 16 (1969/1970), 413â€“424. MR 0279040
23. P. G. Lejeune Dirichlet, Verallgemeinerung eines Satzes aus der Lehre von den KettenbruÌˆchen nebst einige
Anwendungen auf die Theorie der Zahlen, S.-B. Preuss. Akad. Wiss (1842), 93â€“95 (German).
24. M. Maurice Dodson and Simon Kristensen, Hausdorff dimension and Diophantine approximation, Fractal geometry and applications: a jubilee of BenoÄ±Ì‚t Mandelbrot. Part 1, Proc. Sympos. Pure Math.,
vol. 72, Amer. Math. Soc., Providence, RI, 2004, pp. 305â€“347. MR 2112110
25. Manfred Einsiedler and Thomas Ward, Ergodic theory with a view towards number theory, Graduate
Texts in Mathematics, vol. 259, Springer-Verlag London, Ltd., London, 2011. MR 2723325
26. Alex Eskin, GrigoriÄ±Ì† Aleksandrovitch Margulis, and Shahar Mozes, Upper bounds and asymptotics in
a quantitative version of the Oppenheim conjecture, Ann. of Math. (2) 147 (1998), no. 1, 93â€“141.
MR 1609447
27. Kenneth Falconer, Techniques in fractal geometry, John Wiley & Sons, Ltd., Chichester, 1997.
MR 1449135
, Fractal Geometry, Mathematical Foundations and Applications, Third ed., John Wiley & Sons,
28.
Ltd., Chichester, 2014. MR 3236784
29. Lior Fishman, Tue Ly, and David Simmons, Determinacy and indeterminacy of games played on complete
metric spaces, Bull. Aust. Math. Soc. 90 (2014), 339â€“351.
30. Lior Fishman, David Simmons, and Mariusz UrbanÌski, Diophantine approximation and the geometry of
limit sets in Gromov hyperbolic metric spaces, Mem. Amer. Math. Soc. 254 (2018), no. 1215, v+137.
MR 3826896
31. Oleg N. German, On Diophantine exponents and Khintchineâ€™s transference principle, Mosc. J. Comb.
Number Theory 2 (2012), no. 2, 22â€“51. MR 2988525
32. Lifan Guan and Ronggang Shi, Hausdorff dimension of divergent trajectories on homogeneous spaces,
Compos. Math. 156 (2020), no. 2, 340â€“359. MR 4044467
33. Felix Hausdorff, Dimension und aÌˆuÃŸeres MaÃŸ, Math. Ann. 79 (1918), no. 1-2, 157â€“179. MR 1511917
34. Bettina Helfrich, Algorithms to construct Minkowski reduced and Hermite reduced lattice bases, Theoret.
Comput. Sci. 41 (1985), no. 2-3, 125â€“139 (1986). MR 847673
35. VojteÌŒch JarnÄ±Ìk, Zur metrischen Theorie der diophantischen Approximationen, Prace mat. fiz. 36 (1928),
91â€“106 (German).
, Diophantische Approximationen und Hausdorffsches Mass, Mat. Sb. 36 (1929), 371â€“382 (Ger36.
man).
37.
, Zum Khintchineschen â€œUÌˆbertragungssatzâ€, Trav. Inst. Math. Tbilissi 3 (1938), 193â€“212 (German).

A VARIATIONAL PRINCIPLE IN THE PARAMETRIC GEOMETRY OF NUMBERS

125

38. Shirali Kadyrov, Dmitry Kleinbock, Elon Lindenstrauss, and GrigoriÄ±Ì† Aleksandrovitch Margulis, Singular
systems of linear forms and non-escape of mass in the space of lattices, J. Anal. Math. 133 (2017), 253â€“
277. MR 3736492
39. Aminata Keita, On a conjecture of Schmidt for the parametric geometry of numbers, Mosc. J. Comb.
Number Theory 6 (2016), no. 2-3, 166â€“176.
40. Aleksandr Khinchin, UÌˆber eine Klasse linearer diophantischer Approximationen, Rend. Circ. Mat. Palermo
50 (1926), 170â€“195 (German).
, UÌˆber singulaÌˆre Zahlensysteme, Compositio Math. 4 (1937), 424â€“431. MR 1556985
41.
, Regular systems of linear equations and a general problem of CÌŒebysÌŒev, Izvestiya Akad. Nauk
42.
SSSR. Ser. Mat. 12 (1948), 249â€“258. MR 0025513
43. Dong Han Kim and Lingmin Liao, Dirichlet uniformly well-approximated numbers, Int. Math. Res. Not.
IMRN (2019), no. 24, 7691â€“7732. MR 4043832
44. Dmitry Ya. Kleinbock and GrigoriÄ±Ì† Aleksandrovitch Margulis, Flows on homogeneous spaces and Diophantine approximation on manifolds, Ann. of Math. (2) 148 (1998), no. 1, 339â€“360. MR 1652916
45. Dmitry Ya. Kleinbock and Barak Weiss, Modified Schmidt games and Diophantine approximation with
weights, Adv. Math. 223 (2010), no. 4, 1276â€“1298. MR 2581371
46. Michel Laurent, On inhomogeneous Diophantine approximations and the Hausdorff dimension, Fundam.
Prikl. Mat. 16 (2010), no. 5, 93â€“101. MR 2804895
47. Lingmin Liao, Ronggang Shi, Omri Solan, and Nattalie Tamam, Hausdorff dimension of weighted singular vectors in R2 , J. Eur. Math. Soc. (JEMS) 22 (2020), no. 3, 833â€“875. MR 4055990
48. Donald A. Martin, A purely inductive proof of Borel determinacy, Recursion theory (Ithaca, N.Y., 1982),
Proc. Sympos. Pure Math., vol. 42, Amer. Math. Soc., Providence, RI, 1985, pp. 303â€“308. MR 791065
49. R. Daniel Mauldin, Tomasz Szarek, and Mariusz UrbanÌski, Graph directed Markov systems on Hilbert
spaces, Math. Proc. Cambridge Philos. Soc. 147 (2009), no. 2, 455â€“488. MR 2525938
50. Curtis Tracy McMullen, Winning sets, quasiconformal maps and Diophantine approximation, Geom.
Funct. Anal. 20 (2010), no. 3, 726â€“740. MR 2720230
51. Nikolay Moshchevitin, Khintchineâ€™s singular Diophantine systems and their applications, Russian Math.
Surveys 65 (2010), no. 3, 433â€“511.
, Proof of W. M. Schmidtâ€™s conjecture concerning successive minima of a lattice, J. Lond. Math.
52.
Soc. (2) 86 (2012), no. 1, 129â€“151. MR 2959298
53. Damien Roy, On Schmidt and Summerer parametric geometry of numbers, Ann. of Math. (2) 182 (2015),
no. 2, 739â€“786. MR 3418530
, Spectrum of the exponents of best rational approximation, Math. Z. 283 (2016), no. 1-2, 143â€“
54.
155. MR 3489062
55. Damien Roy and Michel Waldschmidt, Parametric geometry of numbers in function fields, Mathematika
63 (2017), no. 3, 1114â€“1135. MR 3731317
56. Johannes Schleischitz, Diophantine approximation and special Liouville numbers, Commun. Math. 21
(2013), no. 1, 39â€“76. MR 3067121
57. Wolfgang M. Schmidt, On badly approximable numbers and certain games, Trans. Amer. Math. Soc. 123
(1966), 27â€“50.
, Badly approximable systems of linear forms, J. Number Theory 1 (1969), 139â€“154. MR 248090
58.

126

TUSHAR DAS, LIOR FISHMAN, DAVID SIMMONS, AND MARIUSZ URBANÌSKI

59. Wolfgang M. Schmidt, Diophantine approximation, Lecture Notes in Mathematics, vol. 785, Springer,
Berlin, 1980. MR 568710
60. Wolfgang M. Schmidt, Open problems in Diophantine approximation, Diophantine approximations and
transcendental numbers (Luminy, 1982), Progr. Math., vol. 31, BirkhaÌˆuser Boston, Boston, MA, 1983,
pp. 271â€“287. MR 702204
61. Wolfgang M. Schmidt and Leonhard Summerer, Diophantine approximation and parametric geometry
of numbers, Monatsh. Math. 169 (2013), no. 1, 51â€“104. MR 3016519
62. David Simmons, On interpreting Pattersonâ€“Sullivan measures of geometrically finite groups as Hausdorff
and packing measures, Ergodic Theory Dynam. Systems 36 (2016), no. 8, 2675â€“2686. MR 3570029
63. Alexander Starkov, Dynamical systems on homogeneous spaces, Translations of Mathematical Monographs, vol. 190, American Mathematical Society, Providence, RI, 2000, Translated from the 1999
Russian original by the author. MR 1746847
64. Dennis P. Sullivan, Entropy, Hausdorff measures old and new, and limit sets of geometrically finite
Kleinian groups, Acta Math. 153 (1984), no. 3-4, 259â€“277. MR 766265
65. Claude Tricot, Jr., Two definitions of fractional dimension, Math. Proc. Cambridge Philos. Soc. 91
(1982), no. 1, 57â€“74. MR 633256
66. Yosef Yomdin and Georges Comte, Tame geometry with application in smooth analysis, Lecture Notes in
Mathematics, vol. 1834, Springer-Verlag, Berlin, 2004. MR 2041428
U NIVERSITY OF W ISCONSIN -L A C ROSSE , D EPARTMENT OF M ATHEMATICS & S TATISTICS , 1725 S TATE
S TREET, L A C ROSSE , WI 54601, USA
Email address: tdas@uwlax.edu
URL: https://sites.google.com/a/uwlax.edu/tdas/
U NIVERSITY OF N ORTH T EXAS , D EPARTMENT
TON , TX 76203-5017, USA
Email address: lior.fishman@unt.edu
URL: http://math.unt.edu/lior-fishman

OF

M ATHEMATICS , 1155 U NION C IRCLE #311430, D EN -

U NIVERSITY OF Y ORK , D EPARTMENT OF M ATHEMATICS , H ESLINGTON , Y ORK YO10 5DD, UK
Email address: david9550@gmail.com
URL: https://sites.google.com/view/davidsimmonsmath2/home
U NIVERSITY OF N ORTH T EXAS , D EPARTMENT
TON , TX 76203-5017, USA
Email address: urbanski@unt.edu
URL: http://www.urbanskimath.com/

OF

M ATHEMATICS , 1155 U NION C IRCLE #311430, D EN -

