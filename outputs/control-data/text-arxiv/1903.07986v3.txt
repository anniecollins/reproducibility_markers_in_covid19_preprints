A BSDE Approach to Stochastic Differential Games Involving
Impulse Controls and HJBI Equation

arXiv:1903.07986v3 [math.OC] 7 Apr 2021

Liangquan Zhang1âˆ—
1. School of Science
Beijing University of Posts and Telecommunications
Beijing 100876, China

April 8, 2021

Abstract
This paper focuses on zero-sum stochastic differential games in the framework of forwardbackward stochastic differential equations on a finite time horizon with both players adopting
impulse controls. By means of BSDE methods, in particular that of the notion from Pengâ€™s
stochastic backward semigroups, we prove a dynamic programming principle for both the
upper and the lower value functions of the game. The upper and the lower value functions
are then shown to be the unique viscosity solutions of the Hamilton-Jacobi-Bellman-Isaacs
equations with a double-obstacle. As a consequence, the uniqueness implies that the upper
and lower value functions coincide and the game admits a value.

AMS subject classifications: 93E20, 60H15, 60H30.
Key words: Dynamic programming principle (DPP for short), Forward-backward stochastic
differential equations (FBSDEs for short), Hamiltonâ€“Jacobiâ€“Bellmanâ€“Isaacs (HJBI for short),
Impulse control, Stochastic differential games, Value function, Viscosity solution.

1

Introduction

Fleming and Souganidis [28] first investigated two-player zero-sum stochastic differential games
as a pioneering work in a rigorous manner and proved that the lower and the upper value
functions of such games fulfill the dynamic programming principle shown to be the unique
viscosity solutions of the associated HJBI equations and coincide under the Isaacs condition.
This work developed the former results on differential games by Isaacs [34], Elliott and Kalton
[22], Friedman [25], Evans and Souganidis [23] from the purely deterministic into the stochastic
framework and has made a huge progress in the field of stochastic differential games. There
are many works which extend the Fleming and Souganidis approach into new contexts. For
instance, Buckdahn, Cardaliaguet and Rainer [9] prove the existence of Nash equilibrium points
for stochastic nonzero-sum differential games and characterize them. Meanwhile, the theory of
backward stochastic differential equations (BSDE) has been used to study stochastic differential
games. In this direction, the reader can see HamadeÌ€ne and Lepeltier [30] and HamadeÌ€ne,
Lepeltier, and Peng [31]. In particular, Buckdahn and Li [12] developed the findings obtained
in [30, 31] and generalized the framework in [28] to BSDE. Another direction for generalization
can be seen in Bayraktar and Poor [10] and Browne [11]. Concerning optimal stopping, the
L. Zhang acknowledges the financial support partly by the National Nature Science Foundation of China(Grant
No. 11701040, 11871010 &61871058) and the Fundamental Research Funds for the Central Universities (No.
2019XD-A11). E-mail: xiaoquan51011@163.com.
âˆ—

1

interested reader is referred to the work of EkstroÌˆm and Peskir [24], of Karatzas and Sudderth
[36], and of Karatzas and Zamfirescu [40].
Different from continuous control, impulse control is also an interesting topic in stochastic
control theory. There are three approaches to exploit it. For functional analysis methods, see
Bensoussan and Lions [6]. For direct probabilistic methods, see Robin [50] and Stettner [52].
For viscosity solution approaches concerning the study of impulse control, see Lenhart [42],
Tang and Yong [55], and Kharroubi et al. [38]. Impulse control has been found as a useful
tool for realistic models in mathematical finance, for instance, transaction costs and liquidity
risk. For more information on this direction refer, in particular, Korn [39], Ly Vath, Mnif and
Pham [43] and Bruder and Pham [13], Tang and Hou [54]. For nonzero sum impulse control
games, see [1]. Some recent advances in numerical impulse control can be seen in [2, 3, 4, 63].
Besides, the celebrated Pontryaginâ€™s maximum principle for stochastic differential games within
the framework of BSDE can be found in Wang and Yu [58] and Wang, Xiao and Xiong [59].
The related topic in this fields see Chen and Wu [19] and Xu [57].
Cosso [17] and El Asri and Mazid [26] studied a two-player zero-sum stochastic differential
game, with both players adopting impulse controls on a finite time horizon of the following type:
The state process is governed by a n-dimensional SDE of the following type:
Z s
Z s
X


t,x;u,v
t,x;u,v
Xs
= x+
b s, Xs
ds +
Ïƒ s, Xst,x;u,v dWs +
Î·l 1[Ïl ,T ] (s)
t

+

X

t

Î¾m 1[Ï„m ,T ] (s)

mâ‰¥1

Y

lâ‰¥1

1{Ï„m 6=Ïl } ,

(1)

lâ‰¥1

for all s âˆˆ [t, T ] , P -a.s., with Xtâˆ’ = x, on some filtered probability space (â„¦, F, P ), where
b : [0, T ] Ã— Rn â†’ Rn , Ïƒ (Â·, Â·) : [0, T ] Ã— Rn â†’ RnÃ—d are given deterministic functions,
(Ws )sâ‰¥0 is
P
an d-dimensional
Brownian
motion,
(x,
t)
are
initial
time
and
state.
u
=
Î¾
1
m
[Ï„m ,T ] and
mâ‰¥1
P
v = lâ‰¥1 Î·l 1[Ïl ,T ] are the impulse controls of player I and player II, respectively. The infinite
product Î lâ‰¥1 1{Ï„m 6=Ïl } has the following meaning: whenever the two players act together on the
system at the same time, we take into account only the action of player II.
The gain functional for player I (resp., cost functional for player II) of the stochastic differential game is given by
"Z
T
X
Y

f s, Xst,x;u,v ds âˆ’
J (t, x; u, v) = E
c (Ï„m , Î¾m ) 1{Ï„m â‰¤T } (s)
1{Ï„m 6=Ïl }
t

+

X
lâ‰¥1

mâ‰¥1

lâ‰¥1

#



Ï‡ (Ïl , Î·l ) 1{Ïl â‰¤T } + g XTt,x;u,v ,

(2)

where f : [0, T ] Ã— Rn â†’ R and g : Rn â†’ R are two given deterministic functions, f denoting the
running function and g the payoff. The function c is the cost function for player I and the gain
function for player II, representing that when player I performs an action he/she has to pay a
cost, resulting in a gain for player II. Analogously, Ï‡ is the cost function for player II and the
gain function for player I. Cosso [17] and El Asri and Mazid [26] (under weak assumptions) have
shown that the upper and lower value functions coincide and the game admits a value.
The theory of BSDE can be traced back to Bismut [5] who studied linear BSDE motivated
by stochastic control problems. Pardoux and Peng [45] proved the well-posedness for nonlinear
BSDE. Subsequently, Duffie and Epstein [20] introduced the notion of recursive utilities in
continuous time, which is actually a type of BSDE where the generator f is independent of z.
Then, El Karoui et al. [41] extended the recursive utility to the case where f contains z. The
term z can be interpreted as an ambiguity aversion term in the market (see Chen and Epstein
2002 [18]). Particularly, the celebrated Black-Scholes formula indeed provided an effective way
2

of representing the option price (which is the solution to a kind of linear BSDE) through the
solution of the Black-Scholes equation. Since then, BSDE have been extensively studied and
used in the areas of applied probability and optimal stochastic controls, particularly in financial
engineering (cf. [41]).
In our present work, employing BSDE methods, in particular, the notion of stochastic backward semigroups (Peng [48]), allows us to prove the dynamic programming principle for the
upper and lower value functions of the game, with both players adopting impulse controls on a
finite time horizon, and to derive from it with the help of Pengâ€™s method (similar to [48, 47])
the associated HJBI equations with a double-obstacle. To the best of our knowledge, this is the
first work studying impulse control games via BSDE.
Consider
Z T
 Z T


t,x;u,v
t,x;u,v
t,x;u,v
t,x;u,v
t,x;u,v
, Yr
, Zr
Zrt,x;u,v dWr
f r, Xr
+
dr âˆ’
Ys
= Î¦ XT
s
s
Y
X
X
âˆ’
c (Ï„m , Î¾m ) 1{Ï„m â‰¤T }
1{Ï„m 6=Ïl } +
Ï‡ (Ïl , Î·l ) 1{Ïl â‰¤T } ,
(3)
mâ‰¥1

lâ‰¥1

lâ‰¥1

where XÂ·t,x;u,v is defined in (1). The existence and uniqueness of BSDE (3) under certain
conditions can be guaranteed in the next section. We are interested in studying two-player
zero-sum stochastic differential game, with both players adopting impulse controls on a finite
time horizon driven by FBSDEs (1)-(3). Compared with above literature, our paper has several
new features. The novelty of the formulation and the contribution in this paper can be stated
as follows:
â€¢ First, in the framework of BSDE, the terminal condition will turn out to be a traditional
Î¦(XTt,x;u,v ) plus gains functions with impulses controls. This new trait makes the backward
semigroup valid and avoids the ItoÌ‚â€™s formula with jumps.
â€¢ Second, in Cosso [17] and El Asri and Mazid [26], the cost functional is defined by (2)
via linear expectation. Our paper considers a more general running cost functional, which
implies that the cost functionals will be supported by a BSDE, which in fact defines a
nonlinear expectation.
â€¢ At last, as a response to one of Cossoâ€™s closing comments (Cosso [17], 2013): â€œwe could
apply backward stochastic differential equations methods to provide a probabilistic representation, known as the nonlinear Feynmanâ€“Kac formula, for the value function of the
gameâ€, our paper aims to further perfect this theory in the framework of BSDE, with
more rigorous proofs and new techniques introduced.
The rest of this paper is organized as follows: after some preliminaries and notations in the
second section, we devote the third section to studying the regularity properties of the upper and
lower value functions. Moreover, we prove the dynamic programming principle for the stochastic
differential game with some corollaries and generalizations, which are useful in proving that the
two value functions are viscosity solutions to the HJBI equation in Section 4. Furthermore,
under certain assumptions, we establish the comparison theorem for the HJBI equation, from
which one may deduce that the game admits a value. Finally, in Section 5, we conclude and
schedule possible generalizations in future. Some proofs can be found in Appendix A.

2

Preliminaries and Notations

Throughout this paper, we denote by Rn the space of n-dimensional Euclidean space, by RnÃ—d
the space the matrices with order n Ã— d. The probability space is the classical Wiener space
3

(â„¦, F, P ), and the Brownian motion W will be the coordinate process on â„¦. Precisely:
â„¦ is

the set of continuous functions from [0, T ] to Rd starting from 0 (â„¦ = C0 [0, T ] ; Rd ), F is the
Borel Ïƒ-algebra over â„¦, completed with respect to the Wiener measure P on this space, and
W denotes the coordinate process: Ws (Ï‰) = Ï‰s , s âˆˆ [0, T ], Ï‰ âˆˆ â„¦. By F = {Fs , 0 â‰¤ s â‰¤ T },
we denote the natural filtration generated by {Ws }0â‰¤sâ‰¤T and augmented by all P-null sets, i.e.,
Fs = Ïƒ {Wr , r â‰¤ s} âˆ¨ NP , s âˆˆ [t, T ] , where NP is the set of all P -null subsets and T > 0 a
fixed real time horizon. For each t > 0, we denote by Fst , t â‰¤ s â‰¤ T the natural filtration of
the Brownian motion {Ws âˆ’ Wt , t â‰¤ s â‰¤ T }, augmented by NP . âŠ¤ appearing in this paper as
superscript denotes the transpose of a matrix. U and V are two convex cones of Rn with U âŠ‚ V .
In what follows, C represents a generic constant, which can be different from line to line.
Now, we give the following definition.
P
P
Definition 2.1 An impulse control u = mâ‰¥1 Î¾m 1[Ï„m ,T ] for player I (resp. v = lâ‰¥1 Î·l 1[Ïl ,T ]
for player II) on [t, T ] is such that
(1) (Ï„m )m (resp., (Ïl )l ), the action time, is a nondecreasing sequence of F-stopping time,
valued in [t, T ] âˆª {+âˆ} .
(2) (Î¾m )m (resp., (Î·l )l ), the actions, is a sequence of U -valued (resp., V -valued) random
variable, where each Î¾m (resp., Î·l ) is FÏ„m -measurable (resp., FÏl -measurable).
Remark 2.1 Let D ([0, T ] ; Rm ) be the space of all functions Î¾ : [0, T ] â†’ RmPthat are right limit
with left continuous. Then, the pure jump part of Î¾ is defined by Î¾ j (t) = 0â‰¤sâ‰¤t âˆ†Î¾ (s) , and
the continuous part is Î¾ c (t) = Î¾ (t) âˆ’ Î¾ j (t) . By Lebesgue decomposition Theorem that we have
Î¾ c (t) = Î¾ ac (t) + Î¾ sc (t), t âˆˆ [0, T ], where Î¾ ac (t) is called the absolutely continuous part of Î¾, and
Î¾ sc the singularly continuous part of Î¾. Thus, we obtain that
Î¾ (t) = Î¾ ac (t) + Î¾ sc (t) + Î¾ j (t) , t âˆˆ [0, T ] , unique!
If we assume that Î¾ ac (t) + Î¾ sc (t) â‰¡ 0, t âˆˆ [0, T ] , then the singular control performs a special
form of a pure jump process, so-called impulse control (see [60] for details).
We now introduce the following spaces of processes:
(
2

n

S (0, T ; R) , R -valued Ft -adapted process Ï†(t); E

"

2

sup |Ï†t |

0â‰¤tâ‰¤T


Z
n
M (0, T ; R) , R -valued Ft -adapted process Ï•(t); E

T

2

2

#

)

<âˆ ,





|Ï•t | dt < âˆ ,
0

and denote N 2 [0, T ] = S 2 (0, T ; Rn ) Ã— S 2 (0, T ; R) Ã— M2 (0, T ; Rn ). Clearly, N 2 [0, T ] forms a
Banach space.
We assume that the following conditions hold.
(A1) The coefficients b : [0, T ]Ã—Rn â†’ Rn and Ïƒ : [0, T ]Ã—Rn â†’ Rn are continuous on [0, T ]Ã—Rn ,
Lipschitz continuous in the state variable x, uniformly with respect to time, and bound
on [0, T ] Ã— Rn .
(A2) The coefficients f : [0, T ] Ã— Rn Ã— R Ã— Rd and Î¦ : Rn â†’ R are continuous on [0, T ] Ã— Rn Ã—
R Ã— Rd , Lipschitz continuous in the state variable (x, y, z) , uniformly with respect to time,
and bounded on [0, T ] Ã— Rn .
To get a well-defined gain functional, we add the following assumption and introduce the
concept of admissible impulse controls. Meanwhile, to ensure that multiple impulses occurring
at the same time are suboptimal, we put (like in Cosso [17]) the following:
4

(A3) Let cost functions c : [0, T ] Ã— U â†’ R and Ï‡ : [0, T ] Ã— V â†’ R be measurable and 1/2
HoÌˆlder continuous in time, uniformly with respect to the other variable. Furthermore,
inf

[0,T ]Ã—U

c (t, Î¾) > 0,

inf

[0,T ]Ã—V

Ï‡ (t, Î·) > 0,

(4)

and there exists a function h : [0, T ] â†’ (0, +âˆ) such that for all t âˆˆ [0, T ],
c (t, y1 + z + y2 ) â‰¤ c (t, y1 ) âˆ’ Ï‡ (t, z) + c (t, y2 ) âˆ’ h (t)

(5)

Ï‡ (t, z1 + z2 ) â‰¤ Ï‡ (t, z1 ) + Ï‡ (t, z2 ) âˆ’ h (t)

(6)

and
for y1 , z, y2 âˆˆ U and z1 , z2 âˆˆ V. Moreover,


c (t, y) â‰¥ c tÌŒ, y and Ï‡ (t, y) â‰¥ Ï‡ tÌŒ, y

(7)

for all t, tÌŒ âˆˆ [0, T ] satisfying t â‰¤ tÌŒ, y âˆˆ U and z âˆˆ V.
P
Definition 2.2 Let u = mâ‰¥1 Î¾m 1[Ï„m ,T ] be an impulse control on [t, T ], and let Ïƒ, Ï„ be two
[t, T ]-valued F-stopping times. Then we define the restriction u[Ï„,Ïƒ] of the impulse control u by
X
o (s) , Ï„ â‰¤ s â‰¤ Ïƒ,
u[Ï„,Ïƒ] (s) =
Î¾Âµt,Ï„ (u)+m 1nÏ„
(8)
mâ‰¥1

Âµt,Ï„ (u)+mâ‰¤sâ‰¤Ïƒ

where Âµt,Ï„ (u) is called the number of impulses up to time Ï„, namely, Âµt,Ï„ (u) :=
We now introduce the following subspaces of admissible controls.

P

mâ‰¥1 1{Ï„m â‰¤Ï„ } .

Definition 2.3 An admissible impulse control u for player I (resp., v for player II) on [t, T ]
is an impulse control for player I (resp., II) on [t, T ] with a finite average number of impulses,
i.e., E [Âµt,T (u)] < âˆ, resp., E [Âµt,T (v)] < âˆ, in which Âµt,T (u) is given by (8). The set of all
admissible impulse controls for player
by Ut,T (resp., Vt,T ). We
P
P I (resp., II) on [t, T ] is denoted
Î¾
1
and
uÌƒ
=
Î¾Ìƒ
identify two impulse controls u =
mâ‰¥1 m 1[Ï„Ìƒm ,T ] in Ut,T , and we
mâ‰¥1 m [Ï„m ,T ]
write u â‰¡ uÌƒ on [t, T ] if P ({u = uÌƒ, a.e. on [t, T ]}) = 1. Similarly, we interpret u â‰¡ uÌƒ on [t, T ]
in Vt,T .
Finally, we have still to define the admissible strategies for the game.
Definition 2.4 A nonanticipative strategy for player I on [t, T ] is a mapping Î± : Vt,T â†’ Ut,T
such that for any stopping time Ï„ : â„¦ â†’ [t, T ] and any v1 , v2 âˆˆ Vt,T with v1 â‰¡ v2 on [[t, Ï„ ]], it
holds that Î± (v1 ) â‰¡ Î± (v2 ) on [[t, Ï„ ]]. Nonanticipative strategies for player II on [t, T ], denoted
by Î² : Ut,T â†’ Vt,T , are defined similarly. The set of all nonanticipative strategies Î± (resp.,
Î²) for player I (resp., II) on [t, T ] is denoted by At,T (resp., Bt,T ). (Recall that [[s, Ï„ ]] =
{(r, Ï‰) âˆˆ [0, T ] Ã— â„¦, s â‰¤ r â‰¤ Ï„ (Ï‰)}).
Assume that (A1)-(A3) are in force, for any u (Â·) Ã— v (Â·) âˆˆ Ut,T Ã— Vt,T , it is easy to check that
FBSDEs (1)-(3) admit a unique Ft -adapted strong solution denoted by the triple
(X t,x;u,v , Y t,x;u,v , Z t,x;u,v ) âˆˆ N 2 [0, T ]
(See Pardoux and Peng [45]).
As in Peng in [48], given any impulse controls u (Â·) Ã— v (Â·) âˆˆ Ut,T Ã— Vt,T , we introduce the
following cost functional:
J(t, x; u (Â·) , v (Â·)) = Yst,x;u,v

s=t

5

,

(t, x) âˆˆ [0, T ] Ã— Rn .

(9)

Under assumptions (A1)-(A3), the gain functional J(t, x; u (Â·) , v (Â·)), defined by (9) is well defined for every (t, x) âˆˆ [t, T ] Ã— Rn , u âˆˆ Ut,T , and v (Â·) âˆˆ Vt,T . We are interested in two value
functions of the stochastic differential games of the following type:
V âˆ’ (t, x) = inf

sup J(t, x; u, Î² (u)), (t, x) âˆˆ [0, T ] Ã— Rn

(10)

V + (t, x) = sup

inf J(t, x; Î± (v) , v), (t, x) âˆˆ [0, T ] Ã— Rn

(11)

Î²âˆˆBt,T uâˆˆUt,T

and
Î±âˆˆAt,T vâˆˆVt,T

for every (t, x) âˆˆ [0, T ] Ã— Rn . When V âˆ’ = V + , we say that the game admits a value and
V := V âˆ’ = V + is called the value function of the game. Since the value function (10) and (11)
are defined by the solution of controlled BSDE (3), V âˆ’ (V + ) is well-defined. Moreover, they are
both bounded Ft -measurable random variables. Nonetheless, we shall prove that V âˆ’ (V + ) are
even deterministic.
Note that inf and sup in this paper should be interpreted via the essential infimum and
the essential supremum with respect to indexed families of random variables (see Karatzas and
Shreve [37]). For readerâ€™s convenience, we recall the notion of essinf of processes. Given a
family of real-valued random variables Î·Î± , Î± âˆˆ I, a random variable Î· is said to be essinfÎ±âˆˆI Î·Î± ,
if (i) Î· â‰¤ Î·Î± , P -a.s., for any Î± âˆˆ I; (ii) if there is another random variable Î¾ such that Î¾ â‰¤ Î·Î± , P a.s., for any Î± âˆˆ I, then Î¾ â‰¤ Î·, P -a.s. The random variable esssupÎ±âˆˆI Î·Î± can be introduced now
by the relation esssupÎ±âˆˆI Î·Î± = âˆ’essinfÎ±âˆˆI (âˆ’Î·Î± ). Finally, recall that essinfÎ±âˆˆI Î·Î± = inf nâ‰¥1 Î·Î±n
for some countable family (Î±n ) âŠ‚ I; esssupÎ±âˆˆI Î·Î± has the same property.
We need the following estimations for BSDE, whose proof can be seen in Proposition 3.2 of
Briand et al. [7].

Lemma 2.1 Let y i , z i , i = 1, 2, be the solution to the following
i

i

y (t) = Î¾ +

Z

T

f

i

t

i

i


s, y (s) , z (s) ds âˆ’

Z

T

z i (s) dWs ,

(12)

t

i
h

Î²
< âˆ, f i s, y i , z i satisfies the conditions (A2), and
where Î¾ i âˆˆ L2 (â„¦, FT , P ) with E Î¾ i
E

"Z

T

f
t

i

i

i


s, y (s) , z (s) ds

Î² #

< âˆ.

Then, for some Î² â‰¥ 2, there exists a positive constant CÎ² such that
ï£®
ï£¹
 Î²2
Z T
2
Î²
z 1 (s) âˆ’ z 2 (s) ds ï£»
E ï£° sup y 1 (t) âˆ’ y 2 (t) +
0â‰¤tâ‰¤T

â‰¤ CÎ² E

"

Î¾1 âˆ’ Î¾

0

2 Î²

+

Z

t

T

f1



s, y 1 (s) , z 1 (s) âˆ’ f 2 s, y 2 (s) , z 2 (s) ds

Particularly, whenever putting Î¾ 2 = 0, f 2 = 0, one has
ï£®
ï£¹
"
 Î²2
Z T
2
Î²
z 1 (s) ds ï£» â‰¤ CÎ² E Î¾ 1
E ï£° sup y 1 (t) +
0â‰¤tâ‰¤T

0

Î²

+

Z

t

T

Î² #
.

Î² #
.
f 1 (s, 0, 0) ds

We recall the following well-known comparison theorem (see Barles, Buckdahn, and Pardoux
[8], Proposition 2.6) for BSDE.
6


Lemma 2.2 (Comparison theorem) Let y i , z i , i = 1, 2, be the solution to the following
i

i

y (t) = Î¾ +

Z

T

t

f

i

s, ysi , zsi



ds âˆ’

Z

t

T

zsi dWs ,

(13)

h
i

2
where E Î¾ i
< âˆ, f i s, y i , z i satisfies the conditions (A2), i = 1, 2. Under assumption (A2),

BSDE (13) admits a unique adapted solution y i , z i , respectively, for i = 1, 2. Furthermore, if
(i) Î¾ 1 â‰¥ Î¾ 2 , a.s.; (ii) f 1 (t, y, z) â‰¥ f 2 (t, y, z) , a.e., for any (t, y, z) âˆˆ [0, T ] Ã— R Ã— Rd . Then we
have y 1 (t) â‰¥ y 2 (t) , a.s.

3

Dynamic Programming Principle

In this section, we present the DPP for our stochastic differential games in the framework of
BSDE. The following lemma announces that the values functions are deterministic, which is
important to investigate the other properties of value functions.
Lemma 3.1 Let (t, x) âˆˆ [0, T ] Ã— Rn . Under assumptions (A1)-(A3), V âˆ’ (t, x) = E [V âˆ’ (t, x)],
P -a.s. Since V âˆ’ (t, x) coincides with its deterministic version E [V âˆ’ (t, x)] , we can consider
V âˆ’ : [0, T ] Ã— Rn â†’ R as a deterministic function. An analogous statement holds for the value
function V + .
The proof is displayed in Appendix A.
We shall consider the value functions obtained by no impulse controls, which is useful to
prove the HoÌˆlder continuity of value functions in the sequel.
Lemma 3.2 Assume that (A1)-(A3) are in force, then the lower and upper value functions are
given by
(14)
V âˆ’ (t, x) = inf sup J(t, x; u, Î² (u)), (t, x) âˆˆ [0, T ] Ã— Rn
Î²âˆˆBÌ„t,T uâˆˆUÌ„t,T

and
V + (t, x) = sup
Î±âˆˆAÌ„t,T

inf J(t, x; Î± (v) , v), (t, x) âˆˆ [0, T ] Ã— Rn ,

vâˆˆVÌ„t,T

(15)

where UÌ„t,T and VÌ„t,T contain all the impulse controls in Ut,T and Vt,T , respectively, which have no
impulses at time t. Similarly, AÌ„t,T and BÌ„t,T are subsets of At,T and Bt,T , respectively. In particular, they contain all the nonanticipative strategies with values in UÌ„t,T and VÌ„t,T , respectively.
Proof We borrow the idea from Cossoâ€™s work [17]. Fix Ç« > 0. Let u âˆˆ Ut,T \UÌ„t,T and Î² âˆˆ
Bt,T \BÌ„t,T . Then, let v := Î² (u) âˆˆ Vt,T and Î²Ì„ (uÌŒ) = vÌ„ âˆˆ VÌ„t,T for any uÌŒ âˆˆ Ut,T for some Î²Ì„ âˆˆ BÌ„t,T .
Hence, we have to prove that there exist uÌ„ âˆˆ UÌ„t,T and vÌ„ âˆˆ VÌ„t,T such that
|J (t, x; u, v) âˆ’ J (t, x; uÌ„, vÌ„)|2 â‰¤ Ç«.
We may suppose v := Vt,T \VÌ„t,T ; in the other case can be proved similarly.
At the beginning, let u and v have only a single impulse at time t. Therefore, there exist
two [t, T ]-valued F-stopping times Ï„ and Ï, with
= t) > 0, such that
P P (Ï„ = t) > 0 and P (Ï P
u = Î¾1[Ï„,T ] + uÌ‚ and v = Î·1[Ï,T ] + vÌ‚, where uÌ‚ = mâ‰¥1 Î¾m 1[Ï„m ,T ] âˆˆ UÌ„t,T , vÌ‚ = lâ‰¥1 Î·l 1[Ïl ,T ] âˆˆ VÌ„t,T ,
Î¾ is an FÏ„ -measurable U -valued random variable and Î· is an FÏ -measurable V -valued random
variable. Let us introduce the following stopping times:




1
1
1{Ï„ =t} + Ï„ 1{Ï„ >t} and Ïn = Ï +
1{Ï=t} + Ï1{Ï>t}
Ï„n = Ï„ +
n
n
7

Clearly, Ï„n â†’ Ï„ and Ïn â†’ Ï, as n approaches to infinity, P -a.s. Now we define the admissible
impulse controls as follows:
un = Î¾1[Ï„n ,T ] + uÌ‚ âˆˆ UÌ„t,T and vn = Î·1[Ïn ,T ] + vÌ‚ âˆˆ VÌ„t,T .
By Proposition 3.2 in [7] and Lemma 3.1, we have the following estimate:
|J (t, x; u, v) âˆ’ J (t, x; uÌ„, vÌ„)|2
2

Ytt,x;u,v âˆ’ Ytt,x;un ,vn
"




â‰¤ CE Î¦ XTt,x;u,v âˆ’ Î¦ XTt,x;un ,vn
=

+

X

Ï‡ (Ïl , Î·l ) 1{Ïl â‰¤T } âˆ’

X

Ï‡ (Ïl , Î·l ) 1{Ïl â‰¤T } âˆ’

+

X

c (Ï„m , Î¾m ) 1{Ï„m â‰¤T }

T

t

Y

1{Ï„m 6=Ïl }

Y

1{Ï„m 6=Ïl }

lâ‰¥1

mâ‰¥1

lâ‰¥1

Z

c (Ï„m , Î¾m ) 1{Ï„m â‰¤T }

mâ‰¥1

lâ‰¥1

âˆ’

X

2

lâ‰¥1


t,x;u,v

f s, Xst,x;u,v , Yst,x;u,v , Zs


t,x;un ,vn

âˆ’ f s, Xst,x;un ,vn , Yst,x;un ,vn , Zs

ds

2 #

.

Note that, for every s âˆˆ [t, T ] by by Burkholder-Davis-Gundy (B-D-G for short, see [51]) inequality, Xst,x;un ,vn â†’ Xst,x;u,v as n â†’ âˆ, P -a.s. Therefore, from GroÌˆnwallâ€™s inequality and the dominated convergence theorem, there is an integer N â‰¥ 1 such that |J (t, x; u, v) âˆ’ J (t, x; un , vn )|2 â‰¤
Ç«. As for multiple impulses at time t, one can show the same result by using the assumptions
(A3), which actually leads to the case of the previous one with only a single impulse at time t.
We thus complete the proof.

Now we prove the two values functions are bounded.
Proposition 3.1 Assume that assumptions (A1)-(A3) are in force, Then, the lower and upper
value functions are bounded.
Proof We only consider the lower value function; the other case is analogous. Let Îµ > 0; then,
by the definition
value function (10), we have, for any (t, x) âˆˆ [0, T ] Ã— Rn , there exists
Pof lower
some Î²Îµ (u0 ) = lâ‰¥1 Î·lÎµ (u0 ) 1[ÏÎµ ,T ] âˆˆ Vt,T , where u0 âˆˆ Ut,T denotes the control with no impulses,
l

V âˆ’ (t, x) =
=

inf

Î²âˆˆBt,T uâˆˆUt,T

âˆ’

T

s

+

X

"

 Z

t,x;u,Î²(u)
+
sup E Î¦ XT

Î²âˆˆBt,T uâˆˆUt,T

Z

t,x;u,Î²(u)

sup Yt

sup J(t, x; u, Î² (u)) = inf

inf

Î²âˆˆBt,T uâˆˆUt,T

Zrt,x;u,Î²(u) dWr âˆ’

X

T
s



f r, Xrt,x;u,Î²(u) , Yrt,x;u,Î²(u) , Zrt,x;u,Î²(u) dr

c (Ï„m , Î¾m ) 1{Ï„m â‰¤T }

mâ‰¥1

Y
lâ‰¥1

Ï‡ (Ïl (u) , Î·l (u)) 1{Ïl (u)â‰¤T }

lâ‰¥1

8

#

1{Ï„m 6=Ïl (u)}

t,x;u0 ,Î²Îµ (u0 )

âˆ’Îµ
 Z

t,x;u0 ,Î²Îµ (u0 )
+
= E Î¦ XT
â‰¥ Yt
"
âˆ’

Z

s

T

s

Zrt,x;u0 ,Î²Îµ (u0 ) dWr

+

T



f r, Xrt,x;u0 ,Î²Îµ (u0 ) , Yrt,x;u0 ,Î²Îµ (u0 ) , Zrt,x;u0 ,Î²Îµ (u0 ) dr

X

#

Ï‡ (Ïl (u) , Î·l (u)) 1{Ïl (u)â‰¤T } âˆ’ Îµ

lâ‰¥1

"



t,x;u ,Î² (u )
â‰¥ E Î¦ XT 0 Îµ 0
+

Z

T

s

#


t,x;u0 ,Î²Îµ (u0 )
t,x;u0 ,Î²Îµ (u0 )
t,x;u0 ,Î²Îµ (u0 )
dr âˆ’ Îµ.
, Yr
, Zr
f r, Xr

The last inequality above is based on the condition (4) and the comparison theorem (see
Proposition 2.6 in [8]). Due to f and Î¦ are bounded, we deduce that V âˆ’ is bounded from
below. In a similar way, we can prove that V âˆ’ is also bounded from above.

After getting the first result on value functions, we now focus on (the generalized) DPP in
the framework our stochastic differential game (3), (10) and (11). To this end, we should first
define the family of (backward) semigroups associated with FBSDEs (3). As a matter of fact,
this concept of stochastic backward semigroups was first introduced by Peng [48] which was
employed to investigate the DPP for stochastic control problems.
For every the initial data (t, x) âˆˆ [0, T ] Ã— Rn , a positive number Î´ â‰¤ T âˆ’ t, two admissible impulse control processes u âˆˆ Ut,T and v âˆˆ Vt,T , and a real-valued random variable
Î· âˆˆ L2 (â„¦, Ft+Î´ , P ; R)), we define

u,v 
t,x;u,v
,
Î·
+
Î˜
Gt,x;u,v
t+Î´ := Ys
s,t+Î´
for s âˆˆ [t, t + Î´] where

Î˜u,v
s :=

X

Ï‡ (Ïl , Î·l ) 1{Ïl â‰¤s} âˆ’

the couple Yst,x;u,v , Zst,x;u,v
t + Î·:

Yst,x;u,v = Î· + Î˜u,v
t+Î´ +

c (Ï„m , Î¾m ) 1{Ï„m â‰¤s}

mâ‰¥1

lâ‰¥1



X



tâ‰¤sâ‰¤t+Î´

Z

t+Î´
s

Y

1{Ï„m 6=Ïl }

lâ‰¥1

is the solution of the following BSDE with the time horizon


f r, Xrt,x;u,v , Yrt,x;u,v , Zrt,x;u,v dr âˆ’

Z

t+Î´
s

Zrt,x;u,v dWr ,

(16)

for s âˆˆ [t, t + Î´] and X t,x;u,v is the solution to SDE (1). Then, obviously, for the solution
Y t,x;u,v , Z t,x;u,v to BSDE (3), we have
i
h
i

h 
t,x;u,v
u,v
t,x;u,v
u,v
t,x;u,v
Y
+
Î˜
=
G
+
Î˜
Î¦
X
Gt,x;u,v
T
T
t,T
t+Î´
t+Î´ .
t,t+Î´
Indeed,

i

h 
u,v
t,x;u,v
+
Î˜
Î¦
X
J (t, x; u, v) = Ytt,x;u,v = Gt,x;u,v
T
T
t,T
i
h
t,x;u,v
Yt+Î´
+ Î˜u,v
= Gt,x;u,v
t+Î´
t,t+Î´
h 
i
t,x;u,v
t,x;u,v
= Gt,t+Î´ J t + Î´, Xt+Î´ ; u, v .

Now we are ready to derive the the dynamic programming principle (DPP for short), by virtue
of backward semigroups introduced above, in which the impulse control can be regarded as
a terminal condition. This principle is important tool to character the viscosity solution of
corresponding H-J-B equation (see Section 4).
9

Theorem 3.1 Suppose that assumptions (A1)-(A3) hold. Then, the value function V âˆ’ admits
the following DPP: For any 0 â‰¤ t < t + Î´ â‰¤ T, x âˆˆ Rn ,


i
h
t,x;u,Î²(u)
u,Î²(u)
t,x;u,Î²(u)
+ Î˜t+Î´
, P -a.e.
V âˆ’ t + Î´, Xt+Î´
V âˆ’ (t, x) = inf sup Gt,t+Î´
Î²âˆˆBt,T uâˆˆUt,T

An analogous statement holds for the value function V + .
Proof We prove only the dynamic programming principle only for V âˆ’ ; the other case is
analogous.
Put


i
h
t,x;u,Î²(u)
u,Î²(u)
t,x;u,Î²(u)
sup Gt,t+Î´
+ Î˜t+Î´
.
VÎ´âˆ’ (t, x) = inf
V âˆ’ t + Î´, Xt+Î´
Î²âˆˆBt,t+Î´ uâˆˆUt,t+Î´

We proceed the proof that VÎ´âˆ’ (t, x) coincides with V âˆ’ (t, x) into the following steps.
In the first step, we shall prove VÎ´âˆ’ (t, x) â‰¥ V âˆ’ (t, x) . To this end, we have
i


h
u,Î²(u)
t,x;u,Î²(u)
t,x;u,Î²(u)
+ Î˜t+Î´
V âˆ’ t + Î´, Xt+Î´
sup Gt,t+Î´
inf
VÎ´âˆ’ (t, x) =
Î²âˆˆBt,t+Î´ uâˆˆUt,t+Î´

=

inf

Î²âˆˆBt,t+Î´

IÎ´ (t, x, Î²) ,

where the notation IÎ´ (t, x, Î²) = supuâˆˆUt,t+Î´ IÎ´ (t, x, u, Î² (u)) with
i


h
u,v
t,x;u,v
âˆ’
+
Î˜
t
+
Î´,
X
V
IÎ´ (t, x, u, v) = Gt,x;u,v
t+Î´ , P -a.s.
t+Î´
t,t+Î´


and for some sequences {Î²i }iâ‰¥1 âŠ‚ Bt,t+Î´ such that VÎ´âˆ’ (t, x) = inf iâ‰¥1 IÎ´ t, x, Î²i1 , P -a.s. Let



iâˆ’1
.
Î¥
:=
Î¥Ì„
\
âˆª
Î¥Ì„
Îµ > 0 and set Î¥Ì„i := IÎ´ t, x, Î²i1 âˆ’ Îµ â‰¤ VÎ´âˆ’ (t, x) âˆˆ Ft , i â‰¥ 1. Construct
i
i
k
k=1
P
1 âˆˆ B
Î²
Certainly, {Î¥i }iâ‰¥1 forms an (â„¦, F)-partition, moreover, Î² Îµ,1 :=
1
.
AcÎ¥
t,t+Î´
i i
iâ‰¥1

1 , Î² Îµ,1 u1
t,
x,
u
=
cording
the
existence
and
uniquenss
of
FBSDEs
(3),
it
follows
that
I
Î´

P
1 (u) , P -a.s., for each u1 âˆˆ U
1 âˆˆU
t,
x,
u,
Î²
.
Next,
for
âˆ€u
1
I
Î¥
t,t+Î´
t,t+Î´
Î´
i
i
iâ‰¥1
X

1Î¥i IÎ´ t, x, Î²i1 âˆ’ Îµ
VÎ´âˆ’ (t, x) â‰¥
iâ‰¥1

â‰¥

X
iâ‰¥1


1Î¥i IÎ´ t, x, u1 , Î²i1 âˆ’ Îµ


= IÎ´ t, x, u1 , Î² Îµ,1 âˆ’ Îµ




t,x;u1 ,Î² Îµ,1 (u1 )
t,x;u1 ,Î² Îµ,1 (u1 )
u1 ,Î² Îµ,1 (u1 )
âˆ’
= Gt,t+Î´
V
t + Î´, Xt+Î´
+ Î˜t+Î´
âˆ’ Îµ, P -a.s.. (17)
We now focus on the time interval [t + Î´, T ] . From the definition of VÎ´âˆ’ (t, x), we also deduce
that, with help of previous idea and Lemma 3.2, for any y âˆˆ Rn , there exists Î²yÎµ âˆˆ BÌ„t+Î´,T for
each u2 âˆˆ Ut+Î´,T such that

V âˆ’ (t + Î´, y) â‰¥ sup J t + Î´, y, u2 , Î²yÎµ u2 âˆ’ Îµ, P -a.s.
(18)
u2 âˆˆUt+Î´,T

Now consider a decomposition of Rn , namely,
i â‰¥ 1. Take any yi âˆˆ Oi fixed, i â‰¥ 1 and
t,x;u1 ,Î² Îµ,1

Clearly, we always have Xt+Î´

( )
u1

n
iâ‰¥1 Oi = R such
t,x;u1 ,Î² Îµ,1 (u1 )
=
define Xt+Î´

P

t,x;u1 ,Î² Îµ,1 (u1 )

âˆ’ Xt+Î´

that diam(Oi ) â‰¤ Îµ, for each
P

.
t,x;u1 ,Î² Îµ,1 (u1 )
iâ‰¥1 yi 1
âˆˆOi

â‰¤ Îµ, almost on â„¦, for each u1 âˆˆ Ut,t+Î´ .

For every yi âˆˆ Oi , one can seek Î²yÎµi âˆˆ BÌ„t+Î´,T such that (18) holds true.
10

Xt+Î´

We introduce the strategy Î²u2,Îµ
1 âˆˆ BÌ„t+Î´,T as follows:
Î²u2,Îµ
1 :=

X
iâ‰¥1

1

t,x;u1 ,Î² Îµ,1 (u1 )

Xt+Î´

âˆˆOi

Î²Îµ
yi

âˆˆ BÌ„t+Î´,T .

 P

Set Î²yÎµi u2 = lâ‰¥1 Î·li u2 1[Ïi (u2 ),T ] , for u2 âˆˆ Ut+Î´,T ; then

(19)

l

X 2,Îµ


u2 :=
Î·l,u1 u2 1hÏ2,Îµ
Î²u2,Îµ
1

l,u1

lâ‰¥1

where

X

2,Îµ
2
Î·l,u
:=
1
1 u
iâ‰¥1

and

X

u2 :=
1
Ï2,Îµ
l,u1
iâ‰¥1

(u2 ),T

t,x;u1 ,Î² Îµ,1 (u1 )
Xt+Î´
âˆˆOi

t,x;u1 ,Î² Îµ,1 (u1 )
Xt+Î´
âˆˆOi

 Î·i
l

 Ïi
l

i,

u2



(20)


u2 .

(21)



It is possible to define a new strategy Î² Îµ (u) from Î² Îµ,1 u1 âˆˆ Bt,t+Î´ and Î²u2,Îµ
u2 âˆˆ BÌ„t+Î´,T where
1
u1 = u[t,t+Î´] , u2 = u(t+Î´,T ] (see Definition 2.2), in the following way:
Let
 X 1,Îµ 1 
 X 2,Îµ

Î² Îµ,1 u1 =
u2 =
Î·l u 1[Ï1,Îµ (u1 ),T ] , Î²uÎµ,2
(22)
Î·l,u1 u2 1hÏ2,Îµ (u2 ),T i,
1
l
l,u1
lâ‰¥1

then Î² Îµ (u) =

and

P

lâ‰¥1

Îµ
lâ‰¥1 Î·l (u) 1[ÏÎµl (u),T ] ,

where



2,Îµ
2
1{l>Âµt,t+Î´ (Î² Îµ,1 (u1 ))}
Î·lÎµ (u) = Î·l1,Îµ u1 1{lâ‰¤Âµt,t+Î´ (Î² Îµ,1 (u1 ))} + Î·lâˆ’Âµ
Îµ,1 (u)),u1 u
t,t+Î´ (Î²


u2 1{l>Âµt,t+Î´ (Î² Îµ,1 (u))} ,
u1 1{lâ‰¤Âµt,t+Î´ (Î² Îµ,1 (u1 ))} + Ï2,Îµ
ÏÎµl (u) = Ï1,Îµ
l
lâˆ’Âµt,t+Î´ (Î² Îµ,1 (u)),u1

(23)

(24)

where Âµt,t+Î´ is defined in (8).
Next we shall show that Î² Îµ (u) is nonanticipating: Indeed, let Îº : â„¦ â†’ [t, T ] be an F-stopping
time and u, uâ€² âˆˆ Ut,T be such that u â‰¡ uâ€² on [t, Îº]. Decomposing u, uâ€² into u1 , uâ€²1 âˆˆ Bt,t+Î´ , u2 ,
uâ€²2 âˆˆ BÌ„t+Î´,T such that u = u1 âŠ• u2 , uâ€² = uâ€²1 âŠ• uâ€²2 where u1 âŠ• u2 (the same for uâ€²1 âŠ• uâ€²2 ) is defined
as follows:
Let
X
X
u1 =
Î·l1 1[Ï1 ,T ] , u2 =
(25)
Î·l2 1[Ï2 ,T ] .
lâ‰¥1

then u1 âŠ• u2 =

P

âŠ•
,
lâ‰¥1 Î·l 1[ÏâŠ•
l ,T ]

l

lâ‰¥1

l

where

2
Î·lâŠ• = Î·l1 1{lâ‰¤Âµt,t+Î´ (u1 )} + Î·lâˆ’Âµ
1
t,t+Î´ (u1 ) {l>Âµt,t+Î´ (u1 )}

(26)

and
2
1
(27)
ÏâŠ•
l = Ïl 1{lâ‰¤Âµt,t+Î´ (u1 )} + Ïlâˆ’Âµt,t+Î´ (u1 ) 1{l>Âµt,t+Î´ (u1 )} .


u2 for u1 = u[t,t+Î´] , u2 = u(t,T ] . We immediately have Î² Îµ,1 (u1 ) =
Thus Î² Îµ (u) = Î² Îµ,1 u1 âŠ• Î²u2,Îµ
1
Î² Îµ,1 (uâ€²1 ) since u1 = uâ€²1 on [t, Îº âˆ§ t + Î´]. On the other hand, u2 = uâ€²2 on (t + Î´, Îº âˆ¨ t + Î´] and on
t,x;uâ€² ,Î² Îµ,1 (uâ€²1 )
t,x;u ,Î² Îµ,1 (u1 )
= Xt+Î´ 1
{Îº > t + Î´}, we have Xt+Î´ 1
. This yields our desired result.

11

Fix u âˆˆ Ut,T arbitrarily and decompose into u1 = u[t,t+Î´] , u2 = u(t+Î´,T ] . Then, from (17) and
Proposition 2.6 in [8], we obtain
VÎ´âˆ’ (t, x)
â‰¥

t,x;u1 ,Î² Îµ,1 (u1 )
Gt,t+Î´



V

âˆ’





t+

t,x;u1 ,Î² Îµ,1 (u1 )
Î´, Xt+Î´



+

u1 ,Î² Îµ,1 (u1 )
Î˜t+Î´



âˆ’Îµ




u1 ,Î² Îµ,1 (u1 )
t,x;u1 ,Î² Îµ,1 (u1 )
V âˆ’ t + Î´, Xt+Î´
âˆ’ CÎµ
+ Î˜t+Î´
ï£®
ï£¹
X
1
1
Îµ,1
1
1
Îµ,1
t,x;u ,Î² (u )
u ,Î² (u )
ï£°
ï£» âˆ’ CÎµ, P -a.s.(28)
= Gt,t+Î´
1 t,x;u1,Î² Îµ,1 (u1 )  V âˆ’ (t + Î´, yi ) + Î˜t+Î´
t,x;u1 ,Î² Îµ,1 (u1 )

â‰¥ Gt,t+Î´

âˆˆOi

Xt+Î´

iâ‰¥1

From (28) and Proposition 2.6 in [8], it follows
VÎ´âˆ’ (t, x)
t,x;u1 ,Î² Îµ,1

â‰¥ Gt,t+Î´

ï£®

( ) ï£°X 
1
u1

iâ‰¥1

t,x;u1 ,Î² Îµ,1 (u1 )

Xt+Î´

âˆˆOi

J

t + Î´, yi , u2 , Î²yÎµi u


2

u1 ,Î² Îµ,1

+ Î˜t+Î´

ï£¹

( )ï£»
âˆ’ CÎµ
u1



 

u1 ,Î² Îµ,1 (u1 )
( )
t,x;u1 ,Î² Îµ,1 (u1 ) 2
Îµ
2
, u , Î²yi u
+ Î˜t+Î´
âˆ’ CÎµ
= Gt,t+Î´
J t + Î´, Xt+Î´





t,x;u1 ,Î² Îµ,1 (u1 )
t,x;u1 ,Î² Îµ,1 (u1 ) 2
u1 ,Î² Îµ,1 (u1 )
â‰¥ Gt,t+Î´
J t + Î´, Xt+Î´
, u , Î²yÎµi u2 + Î˜t+Î´
âˆ’ CÎµ
h
i
t,x;u,Î² Îµ (u)
t,x;u,Î² Îµ (u)
= Gt,t+Î´
Yt+Î´
âˆ’ CÎµ
t,x;u1 ,Î² Îµ,1

u1

t,x;u,Î² Îµ (u)

= Yt

âˆ’ CÎµ, P -a.s., for every u âˆˆ Ut,T .

Therefore, we obtain
VÎ´âˆ’ (t, x) â‰¥

sup J (t, x; u; Î² Îµ (u)) âˆ’ CÎµ
uâˆˆUt,T

â‰¥

sup J (t, x; u; Î² Îµ (u)) âˆ’ CÎµ

inf

Î²âˆˆBt,T uâˆˆUt,T

= V âˆ’ (t, x) âˆ’ CÎµ, P -a.s.
We now deal with the other case: VÎ´âˆ’ (t, x) â‰¤ V âˆ’ (t, x) .
Let Î² âˆˆ Bt,T be arbitrarily chosen and u2 âˆˆ UÌ„t+Î´,T . Define the restriction of Î² to Ut,t+Î´ as
Î² 1 (u1 ) := Î² (u1 âŠ• u2 )[t,t+Î´] , u1 âˆˆ Ut,t+Î´ . The nonanticipativity property of Î² indicates that Î² 1
is independent of the special choice of u2 âˆˆ UÌ„t+Î´,T . From the definition of VÎ´âˆ’ (t, x) ,
i

h
t,x;u ,Î² 1 (u1 )
t,x;u ,Î² 1 (u1 )
, P -a.s.
V âˆ’ t + Î´, Xt+Î´ 1
VÎ´âˆ’ (t, x) â‰¤ sup Gt,t+Î´1
u1 âˆˆUt,t+Î´



Consider IÎ´ t, x, Î² = supu1 âˆˆUt,t+Î´ IÎ´ t, x, u1 , Î² 1 u1 ; then there exists a sequence u1i iâ‰¥1 âŠ‚


1
1
1
UÌ„t,t+Î´ such that IÎ´ t, x, Î² 1 = sup
 iâ‰¥1 IÎ´ t,1 x, ui , Î² ui 1 , P1 -a.s.
With the same technique as
before, for any Îµ > 0, set Î›Ì„i := IÎ´ t, x, Î²i â‰¤ IÎ´ t, x, ui , Î² u1i + Îµ âˆˆ Ft , i â‰¥ 1. Construct

P
1
Îµ
Î›i := Î›Ì„i \ âˆªiâˆ’1
iâ‰¥1 1Î›i ui âˆˆ
k=1 Î›Ì„k . Certainly, {Î›i }iâ‰¥1 forms an (â„¦, F)-partition, moreover, u1 :=
1
Îµ
Îµ
Ut,t+Î´ . From the existence
 and uniqueness of FBSDEs (3), we deduce that IÎ´ t, x, u1 , Î² (u1 ) =
P
1
1
1
ui , P -a.s. Then,
iâ‰¥1 IÎ´ t, x, ui , Î²
 X

1Î›i IÎ´ t, x, u1i , Î² 1 u1i + Îµ
VÎ´âˆ’ (t, x) â‰¤ IÎ´ t, x, Î² 1 â‰¤

1

=

iâ‰¥1

Îµ
1
IÎ´ t, x, u1 , Î² (uÎµ1 ) +
t,x;uÎµ1 ,Î² 1

= Gt,t+Î´

( )
uÎµ1



V

âˆ’



Îµ

t+

t,x;uÎµ ,Î² 1 (uÎµ1 )
Î´, Xt+Î´ 1

12



+

uÎµ1 ,Î² 1 (uÎµ1 )
Î˜t+Î´



+ Îµ, P -a.s.

Noting that Î² 1 (Â·) := Î² (Â· âŠ• u2 ) âˆˆ Bt,t+Î´ does not depend on u2 âˆˆ UÌ„t+Î´,T , we can construct
Î² 2 (u2 ) := Î² (uÎµ1 âŠ• u2 )[t+Î´,T ] , for each u2 âˆˆ UÌ„t+Î´,T such that Î² 2 : UÌ„t+Î´,T â†’ VÌ„t+Î´,T belongs to
BÌ„t+Î´,T , due to Î² âˆˆ Bt,T . Therefore, from the definition of V âˆ’ (t + Î´, y) and Lemma 3.2, we have,
for any y âˆˆ Rn ,




t,x;uÎµ1 ,Î² 1 (uÎµ1 )
t,x;uÎµ1 ,Î² 1 (uÎµ1 )
âˆ’
2
V
t + Î´, Xt+Î´
â‰¤ sup J t + Î´, Xt+Î´
; u2 , Î² (u2 ) .
u2 âˆˆUt+Î´,T


There exists a sequence ui2

âŠ‚ Ut+Î´,T such that


t,x;uÎµ ,Î² 1 (uÎµ1 )
sup J t + Î´, Xt+Î´ 1
; u2 , Î² 2 (u2 )

iâ‰¥1

u2 âˆˆUt+Î´,T



t,x;uÎµ ,Î² 1 (uÎµ1 ) i
; u2 , Î² 2
Î´, Xt+Î´ 1

= sup J t +
iâ‰¥1

ui2





.

Then with the same technique as before, for any Îµ > 0, set


n
t,x;uÎµ1 ,Î² 1 (uÎµ1 )
2
; u2 , Î² (u2 )
Î Ì„i : =
sup J t + Î´, Xt+Î´
u2 âˆˆUt+Î´,T



â‰¤ J t+

t,x;uÎµ ,Î² 1 (uÎµ1 ) i
Î´, Xt+Î´ 1
; u2 , Î² 2

ui2





o
+ Îµ âˆˆ Ft+Î´ , i â‰¥ 1.


. Certainly, {Î i }iâ‰¥1 also forms an (â„¦, F)-partition, moreover,
Construct Î i := Î Ì„i \ âˆªiâˆ’1
Î Ì„
k
k=1
P
P
uÎµ2 := iâ‰¥1 1Î i ui2 âˆˆ Ut+Î´,T . Then, Î² 2 (uÎµ2 ) = jâ‰¥1 1Î i . We construct a new strategy Î² (uÎµ1 âŠ• uÎµ2 ) =
Î² 1 (uÎµ1 ) âŠ• Î² 2 (uÎµ2 ) . From the existence and uniqueness of FBSDEs (3), we have


1 Îµ
t,x;uÎµ
1 ,Î² (u1 ) ;uÎµ ,Î² 2 uÎµ
t+Î´,X
t,x;uÎµ1 ,Î² 1 (uÎµ1 ) Îµ
( 2)
2
2
Îµ
J t + Î´, Xt+Î´
; u2 , Î² (u2 )
= Yt+Î´ t+Î´
1 Îµ
t,x;uÎµ
1 ,Î² (u1 )

=

X

t+Î´,X
1Î i Yt+Î´ t+Î´

=

X

1Î i J

;uj2 ,Î² 2 (uj2 )

jâ‰¥1

jâ‰¥1



t

t,x;uÎµ ,Î² 1 (uÎµ1 ) j
; u2 , Î² 2
+ Î´, Xt+Î´ 1

 
uj2
. (29)

Therefore,
V

âˆ’



t+

t,x;uÎµ ,Î² 1 (uÎµ1 )
Î´, Xt+Î´ 1



â‰¤

sup

J t+

u2 âˆˆUt+Î´,T

â‰¤

X





t,x;uÎµ ,Î² 1 (uÎµ1 )
Î´, Xt+Î´ 1
; u2 , Î² 2 (u2 )

t,x;uÎµ1 âŠ•uj2 ,Î² (uÎµ1 âŠ•uj2 )

1Î i Yt+Î´

+Îµ

jâ‰¥1

t,x;uÎµ1 âŠ•uÎµ2 ,Î² (uÎµ1 âŠ•uÎµ2 )

= Yt+Î´

t,x;uÎµ ,Î²(uÎµ )

= Yt+Î´

+Îµ

+ Îµ,

(30)

where uÎµ = uÎµ1 âŠ• uÎµ2 âˆˆ Ut,T . Repeating the method before, from (29) and (30) and Proposition
2.6 in [8], we have
i
h
t,x;uÎµ ,Î² 1 (uÎµ1 )
uÎµ ,Î²(uÎµ )
t,x;uÎµ ,Î²(uÎµ )
+ CÎµ
+ Î˜t+Î´
Yt+Î´
VÎ´âˆ’ (t, x) â‰¤ Gt,t+Î´1
i
h
Îµ
Îµ
Îµ
Îµ
Îµ
1
Îµ
u ,Î²(u )
t,x;u ,Î²(u )
t,x;u ,Î² (u )
+ CÎµ
+ Î˜t+Î´
Yt+Î´
= Gt,t+Î´
t,x;uÎµ ,Î²(uÎµ )

= Yt

â‰¤

sup
uâˆˆUt,T

+ CÎµ

t,x;u,Î²(u)
Yt

13

+ CÎµ, P -a.s.,

which holds for all Î² âˆˆ Bt,T .
VÎ´âˆ’ (t, x) â‰¤ inf

t,x;u,Î²(u)

sup Yt

Î²âˆˆBt,T uâˆˆUt,T

+ CÎµ = V âˆ’ (t, x) + CÎµ

Now letting Îµ â†’ 0, we get the desired result, VÎ´âˆ’ (t, x) â‰¤ V âˆ’ (t, x). The proof is completed. 
Next, we will show that the continuity of value functions with respect to x and t. Due to
the influence of Brownian motion, the value function will proved to be Lipschitz continuity on
x, but 1/2 hoÌˆlder on t.
Proposition 3.2 Assume that assumptions (A1)-(A3) are in force. Then the lower value function V âˆ’ (t, x) is 12 -HoÌˆlder continuous in t: There exists a constant C > 0 such that, for every
(t, x) âˆˆ [0, T ) Ã— Rn

(31)
â‰¤ C x âˆ’ xâ€² ,
V âˆ’ (t, x) âˆ’ V âˆ’ t, xâ€²
1

â‰¤ C t âˆ’ tâ€² 2 .
V âˆ’ (t, x) âˆ’ V âˆ’ tâ€² , x
(32)
Proof The first property of the lower value function V âˆ’ (t, x) which we present is an immediate
consequence of Proposition 3.2 in [7].
Let (t, x) âˆˆ [0, T ) Ã— Rn and Î´ > 0 be arbitrarily given such that 0 < Î´ < T âˆ’ t. Then for
every Îµ > 0, thanks to Lemma 3.2, there exist uÎµ âˆˆ Ut,T and Î²Îµ âˆˆ BÌ„t,T (This ensures no impulse
on initial state) such that
V âˆ’ (t, x) âˆ’ V âˆ’ (t + Î´, x)

 

 
t,x;uÌ‚ ,Î² (uÌ‚ )
t,x;uÌ‚ ,Î² (uÌ‚ )
t,x;u ,Î²Ì‚ (u )
t,x;u ,Î²Ì‚ (u )
+Îµ
âˆ’ Gt+Î´,TÎµ Îµ Îµ Î¦ XT Îµ Îµ Îµ
â‰¤ Gt,T Îµ Îµ Îµ Î¦ XT Îµ Îµ Îµ

(33)

where uÌ‚Îµ âˆˆ Ut+Î´,T and Î²Ì‚Îµ âˆˆ Bt,T will be determined soon. Indeed, from (14) and (15), there
exist uÎµ âˆˆ Ut,T and Î²Îµ âˆˆ BÌ„t,T such that

 
Îµ
t,x;u ,Î²Ì‚ (u )
t,x;u ,Î²Ì‚ (u )
â‰¥ V âˆ’ (t, x) âˆ’
(34)
Gt,T Îµ Îµ Îµ Î¦ XT Îµ Îµ Îµ
2
and

 
Îµ
t,x;uÌ‚ ,Î² (uÌ‚ )
t,x;uÌ‚ ,Î² (uÌ‚ )
(35)
â‰¤ V âˆ’ (t + Î´, x) + .
Gt+Î´,TÎµ Îµ Îµ Î¦ XT Îµ Îµ Îµ
2
From (34) and (35), one can P
obtain (33) easily.
P
Îµ 1 Îµ
Îµ
We
postulate
that
u
=
Î¾
âˆˆ
U
;
now
define
uÌ‚
as
uÌ‚
=
Îµ
t,T
Îµ
Îµ
[Ï„
,T
]
m
mâ‰¥1
Ï„m â‰¤t+Î´ Î¾m 1t+Î´ +
m
P
Îµ
Îµ ,T ] . Observe that uÌ‚Îµ is an impulse control constructing from uÎµ via gathering all
Ï„m >t+Î´ Î¾m 1[Ï„m
the impulses in the interval [t, t + Î´] . To eliminate the impulses on time t + Î´ of player II, we
define vÎµ = Î²Ì‚Îµ (u) = Î²Îµ (uÌ‚Îµ ) âˆˆ VÌ„t+Î´,T for any u âˆˆ Ut,T . After this work, (33) can be written as
V âˆ’ (t, x) âˆ’ V âˆ’ (t + Î´, x)

 

 
t,x;uÌ‚Îµ ,vÎµ
t,x;uÎµ ,vÎµ
+ Îµ.
Î¦ XTt,x;uÌ‚Îµ ,vÎµ
âˆ’ Gt+Î´,T
Î¦ XTt,x;uÎµ ,vÎµ
â‰¤ Gt,T

14

(36)

We deal with

 

 
t,x;uÌ‚Îµ ,vÎµ
t,x;uÎµ ,vÎµ
Î¦ XTt,x;uÌ‚Îµ ,vÎµ
âˆ’ Gt+Î´,T
Î¦ XTt,x;uÎµ ,vÎµ
Gt,T
Z T
Z T




t,x;uÌ‚Îµ ,vÎµ
t,x;uÎµ ,vÎµ
t,x;uÌ‚Îµ ,vÎµ
Zrt,x;uÎµ ,vÎµ dWr
dWr âˆ’
Zr
dr +
âˆ’ Î¦ XT
= Î¦ T, XT
s
s
ï£® ï£«
ï£¶
ï£¹
X
X
Y
Îµ ï£¸
Îµ
Îµ
+ ï£°c ï£­t + Î´,
Î¾m
1t+Î´ +
c (Ï„m
, Î¾m
) 1[Ï„m
Îµ ,T ] ï£» 1{Ï„ Îµ â‰¤T }
1{Ï„ Îµ 6=ÏÎµ }
m
m

Ï„m â‰¤t+Î´

âˆ’

X

Ï„m >t+Î´

Îµ
Îµ
c (Ï„m
, Î¾m
) 1{Ï„m
Îµ â‰¤T }

mâ‰¥1

+

Z

T

s

âˆ’

Z

T

s

Y
lâ‰¥1

lâ‰¥1

l

1{Ï„ Îµ 6=ÏÎµ }
m
l

f r, Xrt,x;uÎµ ,vÎµ , Yrt,x;uÎµ ,vÎµ , Zrt,x;uÎµ ,vÎµ





f r, Xrt,x;uÌ‚Îµ ,vÎµ , Yrt,x;uÌ‚Îµ ,vÎµ , Zrt,x;uÌ‚Îµ ,vÎµ dr,

(37)

but from conditions (5) and (7), we have
ï£«
ï£¶
X
X
Îµ ï£¸
Îµ
Îµ
Î¾m
c ï£­t + Î´,
â‰¤
c (Ï„m
, Î¾m
) 1t+Î´ .
Ï„m â‰¤t+Î´

Ï„m â‰¤t+Î´

Hence, (37) yields


 

 
t,x;uÌ‚Îµ ,vÎµ
t,x;uÎµ ,vÎµ
Î¦ XTt,x;uÌ‚Îµ ,vÎµ
âˆ’ Gt+Î´,T
Î¦ XTt,x;uÎµ ,vÎµ
Gt,T
Z T
Z T




t,x;uÌ‚Îµ ,vÎµ
t,x;uÎµ ,vÎµ
t,x;uÌ‚Îµ ,vÎµ
Zrt,x;uÎµ ,vÎµ dWr
dWr âˆ’
Zr
dr +
âˆ’ Î¦ XT
â‰¤ Î¦ T, XT
s
s
Z T

f r, Xrt,x;uÎµ ,vÎµ , Yrt,x;uÎµ ,vÎµ , Zrt,x;uÎµ ,vÎµ
+
s
Z T 

f r, Xrt,x;uÌ‚Îµ ,vÎµ , Yrt,x;uÌ‚Îµ ,vÎµ , Zrt,x;uÌ‚Îµ ,vÎµ dr.
âˆ’

(38)

s

Taking the expectation on both sides of (38) and noting Lemma 3.1, we have

 

 
t,x;uÌ‚Îµ ,vÎµ
t,x;uÎµ ,vÎµ
Î¦ XTt,x;uÌ‚Îµ ,vÎµ
âˆ’ Gt+Î´,T
Î¦ XTt,x;uÎµ ,vÎµ
Gt,T
"




â‰¤ E Î¦ XTt,x;uÎµ ,vÎµ âˆ’ Î¦ XTt,x;uÌ‚Îµ ,vÎµ dr
+

Z

âˆ’

Z

T

s

f r, Xrt,x;uÎµ ,vÎµ , Yrt,x;uÎµ ,vÎµ , Zrt,x;uÎµ ,vÎµ

T

f

s





r, Xrt,x;uÌ‚Îµ ,vÎµ , Yrt,x;uÌ‚Îµ ,vÎµ , Zrt,x;uÌ‚Îµ ,vÎµ



#

dr .

(39)

Îµ ,vÎµ
Îµ ,vÎµ
Set ÎÌ‚r = Ît,x;u
âˆ’ Ît,x;uÌ‚
, r âˆˆ [t + Î´, T ] for Î = X, Y, Z. By B-D-G inequality and classical
r
r
method, we have
#
"
Z

E

sup

t+Î´â‰¤râ‰¤T

XÌ‚r

2

+

sup

YÌ‚r

2

t+Î´â‰¤râ‰¤T

T

+

ZÌ‚r

s

15

2

dr â‰¤ C t âˆ’ tâ€²

1
2

.

Therefore,
V âˆ’ (t, x) âˆ’ V âˆ’ (t + Î´, x)

 

 
t,x;uÌ‚Îµ ,vÎµ
t,x;uÎµ ,vÎµ
Î¦ XTt,x;uÌ‚Îµ ,vÎµ
âˆ’ Gt+Î´,T
Î¦ XTt,x;uÎµ ,vÎµ
â‰¤ Gt,T

â‰¤ C t âˆ’ tâ€²

1
2

+ Îµ.

Letting Îµ â†’ 0, we get the desired result. We thus complete the proof.

Now we are concerned on a special case of DPP, that is s = t, thanks to conditions (A3), the
multiple impulses can be neglected. It will be useful in proving that the two value functions are
viscosity solutions to the associated HJBI equation and deriving the so called lower and upper
obstacles. Whilst, it announces that our games problems can interpreted via optimal stopping
times.
Lemma 3.3 Assume assumptions (A1)-(A3) are in force. Given any (t, x) âˆˆ [0, T ] Ã— Rn , we
have
h
t,x;u,Î²(u)
sup
V âˆ’ (t, x) =
inf
âˆ’ c (t, Î¾) 1{Ï„ =t} 1{Ï=+âˆ}
Gt,t
ÏâˆˆTt,+âˆ Î·âˆˆFÏ Ï„ âˆˆTt,+âˆ ,Î¾âˆˆFÏ„

i

t,x;Î¾1[Ï„,T ] ,Î·1[Ï,T ]
,
+Ï‡ (t, Î·) 1{Ï=t} + V âˆ’ t, Xt

(40)

where Tt,+âˆ is the set of F-stopping times with values in {t, +âˆ}, Ï„ âˆˆ Tt,+âˆ , Î¾ âˆˆ FÏ„ , u = Î¾1[Ï„,T ]
and Ï âˆˆ Tt,+âˆ , Î· âˆˆ FÏ , Î² (u) = Î·1[Ï,T ] . An analogous statement holds for the upper value function
V + (t, x).
In Theorem 3.1, consider V âˆ’ with Î´ = 0:
"

Proof

V âˆ’ (t, x) =

inf

t,x;u,Î²(u)

sup Gt,t

Î²âˆˆBt,T uâˆˆUt,T

âˆ’

X

 X

t,x;u,Î²(u)
Ï‡ (Ïl , Î·l ) 1{Ïl =t}
+
V âˆ’ t, Xt

c (Ï„m , Î¾m ) 1{Ï„m =t}

mâ‰¥1

Y

lâ‰¥1

#

1{Ï„m 6=Ïl } .

lâ‰¥1

P
Given any u âˆˆ Ut,T , consider the strategy Î² (u) = Î·1[Ï,T ] . Let u =
mâ‰¥1 Î¾m 1[Ï„m ,T ] , then
constrcut a new control uÌ„ = Î¾1[Ï„,T ] , where
ï£«
ï£¶
Y
Y
X
1{Ï„m >t} ï£¸ + âˆ
Ï„ = t ï£­1 âˆ’
1{Ï„m >t} , Î¾ =
Î¾m 1{Ï„m =t} .
mâ‰¥1

mâ‰¥1

mâ‰¥1

t,x;u,Î²(u)

t,x;Î¾1

,Î·1

[Ï„,T ]
[Ï,T ]
= Xt
,
Apparently, Ï„ âˆˆ Tt,+âˆ and Î¾ âˆˆ FÏ„ . Meanwhile, we deduce that Xt
P -a.s. By means of (A3), it follows that
i

h X
t,x;u,Î²(u)
t,x;u,Î²(u)
âˆ’
c (t, Î¾m ) 1{Ï„m =t} 1{Ï=+âˆ} + Ï‡ (t, Î·) 1{Ï=t} + V âˆ’ t, Xt
Gt,t

mâ‰¥1

â‰¤

t,x;u,Î²(u)
Gt,t

h

As a result, we have

i

t,x;Î¾1[Ï„,T ] ,Î·1[Ï,T ]
.
âˆ’ c (t, Î¾) 1{Ï„ =t} 1{Ï=+âˆ} + Ï‡ (t, Î·) 1{Ï=t} + V âˆ’ t, Xt

V âˆ’ (t, x) â‰¤

inf

sup

ÏâˆˆTt,+âˆ Î·âˆˆFÏ Ï„ âˆˆTt,+âˆ ,Î¾âˆˆFÏ„

h
E âˆ’ c (t, Î¾) 1{Ï„ =t} 1{Ï=+âˆ}

i

t,x;Î¾1[Ï„,T ] ,Î·1[Ï,T ]
.
+Ï‡ (t, Î·) 1{Ï=t} + V âˆ’ t, Xt
16

The reverse inequality can be proved in the analogous way. We end the proof.

In order to prove the the two value functions satisfy, in the viscosity sense, the terminal
condition to the HJBI equation. We need a useful technical lemma.
Lemma 3.4 Assume assumption (A1)-(A3) are in force. Given any (t, x) âˆˆ [0, T ] Ã— Rn , we
have
V âˆ’ (t, x)
=

sup

inf

ÏâˆˆTt,+âˆ Î·âˆˆFÏ Ï„ âˆˆTt,+âˆ ,Î¾âˆˆFÏ„

t,x;u,Î²(u)

Gt,t

h

âˆ’ c (t, Î¾) 1{Ï„ =t} 1{Ï=+âˆ}




t,x;Î¾1[Ï„,T ] ,Î·1[Ï,T ]
+Ï‡ (t, Î·) 1{Ï=t} + V âˆ’ t, Xt
1 âˆ’ 1{Ï„ =+âˆ,Ï=+âˆ}
Z T

i


t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
f s, Xs
, Ys
, Zs
+
ds + Î¦ XT
1{Ï„ =+âˆ,Ï=+âˆ} , (41)
t

where u0 , v0 are the controls with no impulses. An analogous statement holds for the upper value
function V + .
Proof

For any Îµ > 0, from the definition of inf, there exist ÏÎµ,1 âˆˆ Tt,+âˆ , Î· Îµ,1 âˆˆ FÏÎµ,1 such that

the right side of(41)
h
t,x;u,Î²(u)
â‰¥ Gt,t
âˆ’ c (t, Î¾) 1{Ï„ =t} 1{ÏÎµ,1 =+âˆ}


t,x;Î¾1[Ï„,T ] ,Î·Îµ,1 1[ÏÎµ,1 ,T ] 


+Ï‡ t, Î· Îµ,1 1{ÏÎµ,1 =t} + V âˆ’ t, Xt
1 âˆ’ 1{Ï„ =+âˆ,ÏÎµ,1=+âˆ}
Z T


i

t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
f s, Xs
, Ys
, Zs
+
ds + Î¦ XT
1{Ï„ =+âˆ,ÏÎµ,1 =+âˆ}
t

âˆ’Îµ.

To deal with V

(42)

âˆ’



t,x;Î¾1[Ï„,T ] ,Î·Îµ,1 1[ÏÎµ,1 ,T ]

t, Xt



, let uÌŒ âˆˆ UÌ„t,T . From Theorem 3.1, there exsits a

strategy Î² Îµ,2 âˆˆ BÌ„t,T such that


 

t,x;Î¾1[Ï„,T ] ,Î·Îµ,1 1[ÏÎµ,1 ,T ]
t,x;Î¾1[Ï„,T ] ,Î·Îµ,1 1[ÏÎµ,1 ,T ]
V âˆ’ t, Xt
â‰¥ E J t, Xt
, uÌŒ, Î² Îµ,2 (uÌŒ) âˆ’ Îµ.
Define




uÎµ =
Î¾1{Ï„ =t} + v0 1{Ï„ =+âˆ} 1t + uÌŒ 1 âˆ’ 1{Ï„ =+âˆ,ÏÎµ,1=+âˆ} + u0 1{Ï„ =+âˆ,ÏÎµ,1 =+âˆ} ,
 Îµ,1



Î²Îµ =
Î· 1{ÏÎµ,1 =t} + u0 1{Ï„ =+âˆ} 1t + Î² Îµ,2 1 âˆ’ 1{Ï„ =+âˆ,ÏÎµ,1 =+âˆ} + v0 1{Ï„ =+âˆ,ÏÎµ,1 =+âˆ} .

It is easy to check that uÎµ âˆˆ Ut,T and Î² Îµ âˆˆ Bt,T . Hence, from (41), (42) and Theorem 3.1, we

17

have
t,x;u,Î²(u)

sup

inf

Gt,t

ÏâˆˆTt,+âˆ Î·âˆˆFÏ Ï„ âˆˆTt,+âˆ ,Î¾âˆˆFÏ„

h

âˆ’ c (t, Î¾) 1{Ï„ =t} 1{Ï=+âˆ}




t,x;Î¾1[Ï„,T ] ,Î·1[Ï,T ]
1 âˆ’ 1{Ï„ =+âˆ,Ï=+âˆ}
+Ï‡ (t, Î·) 1{Ï=t} + V âˆ’ t, Xt
Z T

i


t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
f s, Xs
, Ys
, Zs
+
ds + Î¦ XT
1{Ï„ =+âˆ,Ï=+âˆ}
t
h
t,x;u,Î²(u)
âˆ’ c (t, Î¾) 1{Ï„ =t} 1{ÏÎµ,1 =+âˆ}
â‰¥ Gt,t


t,x;Î¾1[Ï„,T ] ,Î·Îµ,1 1[ÏÎµ,1 ,T ]


Îµ,1
Îµ,2
1 âˆ’ 1{Ï„ =+âˆ,ÏÎµ,1=+âˆ}
+Ï‡ t, Î·
1{ÏÎµ,1 =t} + J t, Xt
, uÌŒ, Î² (uÌŒ)
Z T


i

f s, Xst,x;u0 ,v0 , Yst,x;u0 ,v0 , Zst,x;u0 ,v0 ds + Î¦ XTt,x;u0 ,v0
+
1{Ï„ =+âˆ,ÏÎµ,1 =+âˆ} âˆ’ 2Îµ
t

= J (t, x; uÎµ , Î² Îµ (uÎµ )) âˆ’ 2Îµ.
Leting Îµ â†’ 0, we get
V âˆ’ (t, x) â‰¤

inf

sup

ÏâˆˆTt,+âˆ Î·âˆˆFÏ Ï„ âˆˆTt,+âˆ ,Î¾âˆˆFÏ„

t,x;u,Î²(u)

Gt,t

h

âˆ’ c (t, Î¾) 1{Ï„ =t} 1{Ï=+âˆ}




t,x;Î¾1[Ï„,T ] ,Î·1[Ï,T ]
1 âˆ’ 1{Ï„ =+âˆ,Ï=+âˆ}
+Ï‡ (t, Î·) 1{Ï=t} + V âˆ’ t, Xt
Z T

i


t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
f s, Xs
, Ys
, Zs
+
ds + Î¦ XT
1{Ï„ =+âˆ,Ï=+âˆ} .
t

The reverse part can be obtained in the same way. We complete the proof.

4



HJBI equation: Viscosity approach

In the stochastic optimal control theory, the value function is a solution to the corresponding
Hamilton-Jacobi-Bellman equation (H-J-B in short) whenever it has sufficient regularity (Fleming and Soner [27], Krylov [35]). In other word, it requires that the HJB equation admit classical
solutions, meaning that the solutions be smooth enough (to the order of derivatives involved in
the equation). Unfortunately, this is not necessarily the case even for some very simple situations. In the stochastic environment where the diffusion is possibly degenerate, the HJB equation
may in general have no classical solutions either. To overcome this difficulty, Crandall and Lions
introduced the so-called viscosity solutions in the early 1980s (see also [16]). This new notion
is a kind of nonsmooth solutions (the value function is continuous, then, the value function is a
solution to the H-J-B equation in the viscosity sense) to partial differential equations, whose key
feature is to replace the conventional derivatives by the (set-valued) super-/subdifferentials while
maintaining the uniqueness of solutions under very mild conditions. These make the theory a
powerful tool in tackling optimal control problems.
In this section, we consider the following HJBI equation associated to our stochastic differential games, in which lead to be the same expression for the two value functions since the two
players can not operate at the same time in the systems, is described by



 âˆ‚
Ï‡
c V
= 0,
V (t, x) âˆ’ H t, x, V, DV, D 2 V , V âˆ’ Hinf
max V âˆ’ Hsup
V, min âˆ’ âˆ‚t
(43)
n
V (T, x) = Î¦ (x) , (t, x) âˆˆ [0, T ) Ã— R ,
where associated with the Hamiltonians:



1 
H (t, x, y, p, Q) = hb (t, x) , pi + tr ÏƒÏƒ âŠ¤ (t, x) Q + f t, x, y, pâŠ¤ Ïƒ (t, x)
2
18

(44)

Ï‡
c V are defined by
and the nonlocal operators Hsup
V and Hinf
Ï‡
Hsup
V (t, x) = sup [V (t, x + y) âˆ’ c (t, y)] ,
yâˆˆU

c
V
Hinf

(t, x) =

inf [V (t, x + z) + Ï‡ (t, z)] ,

zâˆˆV

for any (t, x) âˆˆ [0, T ) Ã— Rn , y âˆˆ R, p âˆˆ Rn , Q âˆˆ Sn where Sn denotes the set of n Ã— n symmetric
matrices. The coefficients b, Ïƒ, f , Î¦, Ï‡ and c are supposed to satisfy (A1)-(A3).
We next prove that the lower value function V (t, x) introduced by (43) is the viscosity
solution of (43). We extend Cossoâ€™s work [17] for stochastic differential games involving impulse
controls into Pengâ€™s BSDEâ€™s framework. The difficulties related with this extension come from
the fact that now, contrarily to the framework of stochastic control theory studied by Peng, we
have to do with stochastic differential games in which strategies are played versus controls. In
order to overcome these difficulties in the proof that V âˆ’ is a viscosity supersolution, we have, in
particular, to enrich Pengâ€™s BSDE method. On the other hand, the proof that V âˆ’ is a viscosity
subsolution is not covered by Pengâ€™s BSDE method and requires a quite new approach. The
uniqueness of the viscosity solution will be shown in the next section for the class of bounded
continuous functions. We first recall the definition of a viscosity solution of (43). The interested
reader is referred to Crandall, Ishii, and Lions [16].
Definition 4.1 Let u (t, x) âˆˆ C ([0, T ] Ã— Rn ) and (t, x) âˆˆ [0, T ]Ã—Rn . For every Ï• âˆˆ C 1,2 ([0, T ] Ã— Rn )
(1) for each local maximum point (t0 , x0 ) of u âˆ’ Ï• in the interior of [0, T ] Ã— Rn , we have




âˆ‚
Ï‡
c
V
â‰¤0
(45)
max V âˆ’ Hinf
V, min âˆ’ Ï• âˆ’ H t, x, Ï•, DÏ•, D 2 Ï• , V âˆ’ Hsup
âˆ‚t
and for each x âˆˆ Rn , we have

Ï‡
c
max V (T, x) âˆ’ Hinf
V (T, x) , min [V (T, x) âˆ’ Î¦ (x) , V (T, x) âˆ’ Hinf
V (T, x)] â‰¤ 0

i.e., u is a subsolution to HJBI equation (43).
(2) for each local minimum point (t0 , x0 ) of u âˆ’ Ï• in the interior of [0, T ] Ã— Rn , we have




âˆ‚
Ï‡
2
c
â‰¥0
max V âˆ’ Hinf V, min âˆ’ Ï• âˆ’ H t, x, Ï•, DÏ•, D Ï• , V âˆ’ Hsup V
âˆ‚t

and for each x âˆˆ Rn , we have

Ï‡
c
max V (T, x) âˆ’ Hinf
V (T, x) , min [V (T, x) âˆ’ Î¦ (x) , V (T, x) âˆ’ Hinf
V (T, x)] â‰¥ 0

(46)

(47)

(48)

i.e., u is a supersolution to HJBI equation (43).
(3) u (t, x) âˆˆ C ([0, T ] Ã— Rn ) is said to be a viscosity solution of (43) if it is both a viscosity sub
and supersolution.
We have the other definition which will be useful to verify the viscosity solutions.
Definition 4.2 Let u (t, x) âˆˆ C ([0, T ] Ã— Rn ) and (t, x) âˆˆ [0, T ]Ã—Rn . We denote by P 2,+ u (t, x),
the â€œparabolic superjetâ€ of u at (t, x) the set of triples (p, q, X) âˆˆ R Ã— Rn Ã— Sn which are such
that
u (s, y) â‰¤ u (t, x) + p (s âˆ’ t) + hq, x âˆ’ yi


1
+ hX (y âˆ’ x) , y âˆ’ xi + o |s âˆ’ t| + |y âˆ’ x|2 .
2
19

Similarly, we denote by P 2,âˆ’ u (t, x) , the â€parabolic subjetâ€ of u at (t, x) the set of triples
(p, q, X) âˆˆ R Ã— Rn Ã— Sn which are such that
u (s, y) â‰¥ u (t, x) + p (s âˆ’ t) + hq, x âˆ’ yi


1
+ hX (y âˆ’ x) , y âˆ’ xi + o |s âˆ’ t| + |y âˆ’ x|2 .
2

Definition 4.3 (i) It can be said V (t, x) âˆˆ C ([0, T ] Ã— Rn ) is a viscosity subsolution of (43) if
at any point (t, x) âˆˆ [0, T ] Ã— Rn , for any (p, q, X) âˆˆ P 2,+ V (t, x),



Ï‡
c
max V âˆ’ Hinf
V, min âˆ’p âˆ’ H (t, x, V (t, x) , q, X) , V âˆ’ Hsup
V â‰¤0
(49)
and for each x âˆˆ Rn , it holds

Ï‡
c
V (T, x)] â‰¤ 0.
max V (T, x) âˆ’ Hinf
V (T, x) , min [V (T, x) âˆ’ Î¦ (x) , V (T, x) âˆ’ Hinf

(50)

and for each x âˆˆ Rn , we have

Ï‡
c
V (T, x)] â‰¥ 0.
V (T, x) , min [V (T, x) âˆ’ Î¦ (x) , V (T, x) âˆ’ Hinf
max V (T, x) âˆ’ Hinf

(52)

(ii) It can be said V (t, x) âˆˆ C ([0, T ] Ã— Rn ) is a viscosity supersolution of (43) if at any point
(t, x) âˆˆ [0, T ] Ã— Rn , for any (p, q, X) âˆˆ P 2,+ V (t, x),



Ï‡
c
max V âˆ’ Hinf
V, min âˆ’p âˆ’ H (t, x, V (t, x) , q, X) , V âˆ’ Hsup
V â‰¥0
(51)

(iii) It can be said u (t, x) âˆˆ C ([0, T ] Ã— Rn ) is a viscosity solution of (43) if it is both a viscosity
sub and super solution.
Remark 4.1 Definition 4.1 and 4.3 are equivalent to each other. For more details, see Fleming
and Soner [28], Lemma 4.1 (page 211).
We now introduce the lower and upper obstacles with the help of the following lemms.
Lemma 4.1 Assume (A1)-(A3) are in force. Given any (t, x) âˆˆ (0, T ] Ã— Rn , the lower and
upper value functions satisfy the following equation:



Ï‡
c
max min 0, V (t, x) âˆ’ Hsup
V (t, x) , V (t, x) âˆ’ Hinf
V (t, x) = 0.
Proof

From Lemma 3.1, (40) can be expressed as
V âˆ’ (t, x) =

inf

sup

ÏâˆˆTt,+âˆ Î·âˆˆFÏ Ï„ âˆˆTt,+âˆ ,Î¾âˆˆFÏ„

h
E âˆ’ c (t, Î¾) 1{Ï„ =t} 1{Ï=+âˆ}

i

t,x;Î¾1[Ï„,T ] ,Î·1[Ï,T ]
.
+Ï‡ (t, Î·) 1{Ï=t} + V âˆ’ t, Xt

The remainder of the proof is the same as Lemma 5.3 from [17]. We omit it.



Ï‡
Remark 4.2 We have V âˆ’ (t, x) â‰¤ Hinf
V (t, x) on (0, T ] Ã— Rn from Lemma 4.1. Besides, whenÏ‡
c V (t, x) â‰¤ V âˆ’ (t, x) and Hc V (t, x) â‰¤ HÏ‡ V (t, x). So
ever V (t, x) â‰¤ Hinf V (t, x), then Hsup
sup
inf
c V (t, x) as a lower obstacle and HÏ‡ V (t, x) as an upper obstacle. Both of
we may regard Hsup
inf
them are implicit forms, since they depend on V âˆ’ . The same remark applies to V + likewise.

We shall prove that the two value functions satisfy, in the viscosity sense, the terminal
condition.
Lemma 4.2 Assume assumptions (A1)-(A3) are in force. The lower value function V âˆ’ (T, x)
is a viscosity solution of (43).
20

Proof

We shall prove

Ï‡
c
max V (T, x) âˆ’ Hinf
V (T, x) , min [V (T, x) âˆ’ Î¦ (x) , V (T, x) âˆ’ Hinf
V (T, x)] â‰¥ 0.

From Lemma 3.4, we have
V âˆ’ (t, x) =

sup

inf

E

ÏâˆˆTt,+âˆ Î·âˆˆFÏ Ï„ âˆˆTt,+âˆ ,Î¾âˆˆFÏ„

h

âˆ’ c (t, Î¾) 1{Ï„ =t} 1{Ï=+âˆ}




t,x;Î¾1[Ï„,T ] ,Î·1[Ï,T ]
1 âˆ’ 1{Ï„ =+âˆ,Ï=+âˆ}
+Ï‡ (t, Î·) 1{Ï=t} + V âˆ’ t, Xt
Z T


i

t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
t,x;u0 ,v0
f s, Xs
, Ys
, Zs
ds + Î¦ XT
+
1{Ï„ =+âˆ,Ï=+âˆ} .
t

Thanks to (A1)-(A2), it follows that
Z T


f s, Xst,x;u0 ,v0 , Yst,x;u0 ,v0 , Zst,x;u0 ,v0 ds
E
t

1
2

â‰¤ (T âˆ’ t) E

Z

t

1

T

f

s, Xst,x;u0 ,v0 , Yst,x;u0,v0 , Zst,x;u0 ,v0

â‰¤ C (T âˆ’ t) 2 ,



2

ds

 21

and
1

i


2 2
t,x;u0 ,v0
t,x;u0 ,v0
âˆ’x
â‰¤ CE XT
E Î¦ XT
âˆ’ Î¦ (x)
h

1

â‰¤ C (T âˆ’ t) 2 , uniformly in u0 , v0 .

Therefore,
V âˆ’ (t, x) â‰¥ âˆ’

inf

sup

E

ÏâˆˆTt,+âˆ Î·âˆˆFÏ Ï„ âˆˆTt,+âˆ ,Î¾âˆˆFÏ„

h

âˆ’ c (t, Î¾) 1{Ï„ =t} 1{Ï=+âˆ}




t,x;Î¾1[Ï„,T ] ,Î·1[Ï,T ]
1 âˆ’ 1{Ï„ =+âˆ,Ï=+âˆ}
+Ï‡ (t, Î·) 1{Ï=t} + V âˆ’ t, Xt
i
1
+Î¦ (x) 1{Ï„ =+âˆ,Ï=+âˆ} âˆ’ C (T âˆ’ t) 2 .

Repeating the method in Lemma 4.1, we have



Ï‡
c
max min V âˆ’ (t, x) âˆ’ Î¦ (x) , V âˆ’ (t, x) âˆ’ Hsup
V âˆ’ (t, x) , V âˆ’ (t, x) âˆ’ Hinf
V âˆ’ (t, x)
1

â‰¥ âˆ’C (T âˆ’ t) 2 .

According to (A3), namely the 1/2-HoÌˆlder continuity in time for c, Ï‡ and V âˆ’ , we deduce that

Ï‡
c
max V (T, x) âˆ’ Hinf
V (T, x) , min [V (T, x) âˆ’ Î¦ (x) , V (T, x) âˆ’ Hinf
V (T, x)]
1

+C (T âˆ’ t) 2



Ï‡
c
â‰¥ max min V âˆ’ (t, x) âˆ’ Î¦ (x) , V âˆ’ (t, x) âˆ’ Hsup
V âˆ’ (t, x) , V âˆ’ (t, x) âˆ’ Hinf
V âˆ’ (t, x)
1

â‰¥ âˆ’C1 (T âˆ’ t) 2 .

for some C1 > 0. Then, letting t = T in (53) ends the proof.
We first prove that the lower value function V âˆ’ (t, x) is a viscosity solution of (43).

(53)


Theorem 4.1 Assume assumptions (A1)-(A3) are in force, the lower value function V âˆ’ (t, x)
is a viscosity solution of (43).
21

Proof We first show that the lower value function V âˆ’ is a viscosity solution to (43); the other
case is analogous.
In Lemma 4.2, we have proved that V âˆ’ satisfies, in the viscosity sense, the terminal condition,
namely (50) and (50). Therefore, we have only to address (49). From Proposition 3.2, V âˆ’ is
continuous on [0, T ) Ã— Rn . Thus we begin by proving that V âˆ’ is a viscosity supersolution. By
c V (tÌ„, xÌ„) â‰¤
virtue of Lemma 4.1, we have to show that, given (tÌ„, xÌ„) âˆˆ [0, T ) Ã— Rn such that Hsup
Ï‡
âˆ’
âˆ’
1,2
n
V (tÌ„, xÌ„) and V (tÌ„, xÌ„) â‰¤ Hinf V (tÌ„, xÌ„) , then for every Ï• âˆˆ C ([0, T ) Ã— R ), such that (tÌ„, xÌ„) is a
local minimum of V âˆ’ âˆ’ Ï•, we have

âˆ‚
Ï• (tÌ„, xÌ„) + H t, x, Ï• (tÌ„, xÌ„) , DÏ• (tÌ„, xÌ„) , D 2 Ï• (tÌ„, xÌ„) â‰¤ 0,
âˆ‚t

where H is defiend in (44).
Without loss of generality, postulate V âˆ’ (tÌ„, xÌ„) = Ï• (tÌ„, xÌ„) . Let


Ï‡
Î» + V âˆ’ (tÌ„, xÌ„) = Hinf
V (tÌ„, xÌ„) = inf V âˆ’ (tÌ„, xÌ„ + y) + Ï‡ (tÌ„, y) .
yâˆˆV

(54)

(55)

We proceed as in [17] to derive the following result: For every random variable Î·, Fs -measurable
and values in V, there exists C > 0,

i
h 
i
h 
1
EFs V s, XstÌ„,xÌ„ â‰¤ EFs V s, XstÌ„,xÌ„ + Î· + Ï‡ (s, Î·) + C |s âˆ’ tÌ„| 2 âˆ’ Î»

with XstÌ„,xÌ„ = XstÌ„,xÌ„,u0 ,v0 for all s âˆˆ [tÌ„, T ], P -a.s., where u0 and v0 denote the controls with no
impulses.
Next recall
i


h
u,Î²(u)
tÌ„,xÌ„;u,Î²(u)
tÌ„,xÌ„;u,Î²(u)
,
+ Î˜tÌ„+Î´
V âˆ’ tÌ„ + Î´, XtÌ„+Î´
V âˆ’ (tÌ„, xÌ„) = inf sup GtÌ„,tÌ„+Î´
Î²âˆˆBtÌ„,T uâˆˆUtÌ„,T

where

:=
Î˜u,v
tÌ„+Î´

X

Ï‡ (Ïl , Î·l ) 1{Ïl â‰¤tÌ„+Î´} âˆ’

X

c (Ï„m , Î¾m ) 1{Ï„m â‰¤tÌ„+Î´}

mâ‰¥1

lâ‰¥1

Y

1{Ï„m 6=Ïl } .

lâ‰¥1

From the definition of V âˆ’ (tÌ„, xÌ„) , we have
V âˆ’ (tÌ„, xÌ„) =

tÌ„,xÌ„;u,Î²(u)

sup GtÌ„,tÌ„+Î´

inf

Î²âˆˆBtÌ„,T uâˆˆUtÌ„,T

ï£®

i


h
u,Î²(u)
tÌ„,xÌ„;u,Î²(u)
+ Î˜tÌ„+Î´
V âˆ’ tÌ„ + Î´, XtÌ„+Î´

ï£¹


X
tÌ„,xÌ„;u ,Î² Îµ (u0 ) ï£° âˆ’
tÌ„,xÌ„;u ,Î² Îµ (u0 )
â‰¥ GtÌ„,tÌ„+Î´0
+
tÌ„ + Î´, XtÌ„+Î´ 0
V
Ï‡ (Ïl , Î·l ) 1{Ïl â‰¤tÌ„+Î´} ï£» âˆ’ Îµ
lâ‰¥1

for some Î² Îµ âˆˆ BtÌ„,T , with v Îµ := Î² Îµ (u0 ) =
X

P

Îµ
lâ‰¥1 Î·l 1[ÏÎµl ,T ]

âˆˆ VtÌ„,T . Note that

Âµ[tÌ„,tÌ„+Î´]

Ï‡ (Ïl , Î·l ) 1{Ïl â‰¤tÌ„+Î´} =

lâ‰¥1

X

Ï‡ (Ïl , Î·l ) .

lâ‰¥1

By (A1)-(A2), we have the following estimate
ï£¶ï£¹
ï£®
ï£«
Âµ[tÌ„,tÌ„+Î´]


X
Îµ
tÌ„,xÌ„;u0 ,v
EFtÌ„+Î´ ï£° V âˆ’ tÌ„ + Î´, XtÌ„+Î´
Ï‡ (Ïl , Î·l )ï£¸ ï£»
âˆ’ V âˆ’ ï£­tÌ„ + Î´, XstÌ„,xÌ„ +
lâ‰¥1

1
2

h

i

â‰¤ CÎ´ EFtÌ„+Î´ 1{Âµ[tÌ„,tÌ„+Î´] â‰¥1} .

22

As a consequence, using (A3) and (54), we deduce
ï£¹
ï£¶
ï£®
ï£«
Âµ[tÌ„,tÌ„+Î´]
Âµ[tÌ„,tÌ„+Î´]
X
X
tÌ„,xÌ„
Ï‡ (Ïl , Î·l )ï£»
Ï‡ (Ïl , Î·l )ï£¸ +
EFtÌ„+Î´ ï£°V âˆ’ ï£­tÌ„ + Î´, XtÌ„+Î´
+
lâ‰¥1

lâ‰¥1

â‰¥ EFtÌ„+Î´

h

 


i
1
tÌ„,xÌ„
+ Î» âˆ’ CÎ´ 2 1{Âµ[tÌ„,tÌ„+Î´] â‰¥1} .
V âˆ’ tÌ„ + Î´, XtÌ„+Î´

Therefore, applying comparison theorem (Proposition 2.6 in [8]), we find
ï£®
ï£¹


X
Îµ
tÌ„,xÌ„;u0 ,vÎµ
0 ,v ï£° âˆ’
GtÌ„,xÌ„;u
+
Ï‡ (Ïl , Î·l ) 1{Ïl â‰¤tÌ„+Î´} ï£»
V
tÌ„ + Î´, XtÌ„+Î´
tÌ„,tÌ„+Î´
lâ‰¥1

0
â‰¥ GtÌ„,xÌ„;u
tÌ„,tÌ„+Î´

Thus

,vÎµ

h

0 ,v
V âˆ’ (tÌ„, xÌ„) â‰¥ GtÌ„,xÌ„;u
tÌ„,tÌ„+Î´

 


1
tÌ„,xÌ„
+ Î» âˆ’ CÎ´ 2 1{Âµ tÌ„,
V âˆ’ tÌ„ + Î´, XtÌ„+Î´

Îµ

} .

[ tÌ„+Î´] â‰¥1

h

i


 

1
tÌ„,xÌ„
+ Î» âˆ’ CÎ´ 2 1{Âµ
V âˆ’ tÌ„ + Î´, XtÌ„+Î´

i

} âˆ’ Îµ.

[tÌ„,tÌ„+Î´] â‰¥1

From the boundedness of f we deduce


Îµ
f s, XstÌ„,xÌ„;u0 ,v , y, z






Îµ
= f s, XstÌ„,xÌ„;u0 ,v , y, z âˆ’ f s, XstÌ„,xÌ„ , y, z + f s, XstÌ„,xÌ„ , y, z


â‰¥ f s, XstÌ„,xÌ„ , y, z âˆ’ C, for (y, z) âˆˆ R Ã— Rd .

Applying comparison theorem (Proposition 2.6 in [8]) again, we have V âˆ’ (tÌ„, xÌ„) â‰¥ YtÌ„ , where YtÌ„
is the solution to the following BSDE:
 


1
tÌ„,xÌ„
+ Î» âˆ’ CÎ´ 2 âˆ’ CÎ´ 1{Âµ
YtÌ„ = V âˆ’ tÌ„ + Î´, XtÌ„+Î´
[tÌ„,tÌ„+Î´] â‰¥1}
Z tÌ„+Î´
Z tÌ„+Î´ 

Zs dWs .
f s, XstÌ„,xÌ„ , Ys , Zs ds âˆ’
+
tÌ„

tÌ„


We shall take Î´ sufficiently small. Indeed, there exists Î´Ì„ > 0 such that for Î¶ âˆˆ 0, Î´Ì„ , we have
1
Î» âˆ’ CÎ´ 2 âˆ’ CÎ´ â‰¥ 0. Immediately, by Proposition 2.6 in [8], it follows
i

h
tÌ„,xÌ„
âˆ’
âˆ’ Îµ.
(56)
V
tÌ„
+
Î¶,
X
V âˆ’ (tÌ„, xÌ„) â‰¥ GtÌ„,xÌ„
tÌ„+Î¶
tÌ„,tÌ„+Î¶

To abbreviate notations we set, for some arbitrarily chosen but fixed Ï• âˆˆ C 1,2 ([0, T ) Ã— Rn ) ,

1 
âˆ‚
Ï• (s, x) + Tr ÏƒÏƒ âŠ¤ (s, x) D 2 Ï• + hDÏ•, b (s, x)i
F (s, x, y, z) =
âˆ‚s
2
+f (s, x, y + Ï• (s, x) , z + DÏ• (s, x) Â· Ïƒ (s, x)) ,
for (s, x, y, z) âˆˆ [0, T ] Ã— Rn Ã—R Ã— Rd .
Let us consider the following BSDE:


(
âˆ’dYs1 = F s, XstÌ„,xÌ„ , Ys1 , Zs1 ds âˆ’ Zs1 dWs ,

(57)
1
YtÌ„+Î¶
= 0.


It is not hard to check that F s, XstÌ„,xÌ„ , y, z satisfies (A1) and (A2). Thus, BSDE (57) admits

a unique adapted strong solution. We can characterize the solution process Ys1 as follows.

h 
i

tÌ„,xÌ„
tÌ„,xÌ„
.
(58)
Ï•
âˆ’
Ï•
s,
X
Ys1 = GtÌ„,xÌ„
tÌ„
+
Î¶,
X
s
s,tÌ„+Î¶
tÌ„+Î¶
23

i
h 
tÌ„,xÌ„
is defined by the solution of the following BSDE:
Ï•
Indeed, GtÌ„,xÌ„
tÌ„
+
Î¶,
X
tÌ„+Î¶
s,tÌ„+Î¶
ï£±


ï£² âˆ’dYÌ„s = f s, XstÌ„,xÌ„ , YÌ„s , ZÌ„s ds âˆ’ ZÌ„s dWs ,


ï£³ YÌ„tÌ„+Î¶ = Ï• tÌ„ + Î¶, X tÌ„,xÌ„ .
tÌ„+Î¶

(59)





Therefore, one just need to prove YÌ„s âˆ’ Ï• s, XstÌ„,xÌ„ = Ys1 . Applying ItoÌ‚â€™s formula to Ï• s, XstÌ„,xÌ„ ,


i
h

tÌ„,xÌ„
1 =
= YtÌ„+Î¶
we obtain d YÌ„s âˆ’ Ï• s, XstÌ„,xÌ„ = dYs1 , and at the terminal time YÌ„tÌ„+Î¶ âˆ’ Ï• tÌ„ + Î¶, XtÌ„+Î¶
0, as a result, they are equal in the interval [tÌ„, tÌ„ + Î¶].
Now let us introduce a more simpler BSDE than (57), i.e., XstÌ„,xÌ„ of the equation (57) is taken
place by x:


âˆ’dYs2 = F s, xÌ„, Ys2 , Zs2 ds âˆ’ Zs2 dWs ,
(60)
2
= 0.
YtÌ„+Î¶

Notice that F is a deterministic function of (s, x, y, z) therefore Ys2 , Zs2 = (Y0 (s) , 0) where
Y0 (s) is the solution of the ODE:

âˆ’YÌ‡0 (s) = F (s, xÌ„, Y0 (s) , 0) ds, s âˆˆ [tÌ„, tÌ„ + Î¶] ,
(61)
Y0 (tÌ„ + Î¶) = 0.
The following result indicates that the difference of the solutions of (57) and (60) can be neglected whenever Î¶ is sufficiently small enough. From the classical estimate on SDE,
 we have

h
pi
2
tÌ„,xÌ„
tÌ„,xÌ„
p
E supsâˆˆ[tÌ„,tÌ„+Î¶] Xs
â‰¤ C (1 + |xÌ„| ) . Moreover, applying B-D-G inequality, we get E supsâˆˆ[tÌ„,tÌ„+Î¶] Xs âˆ’ xÌ„
â‰¤

CÎ¶. Hence, when Î¶ â†’ 0, the following random variable ÎºÎ¶ := supsâˆˆ[tÌ„,tÌ„+Î¶] XstÌ„,xÌ„ âˆ’ xÌ„ converges
monotone to 0. On the one hand, employing Proposition 3.2 in [7] to BSDEs (57) and(60), we
have
#
"Z
#
"Z
2
 2

tÌ„+Î¶
tÌ„+Î¶
tÌ„,xÌ„
1
2 2
1 2
ds â‰¤ CÎ¶EÌŸ ÎºÎ¶ .
E
Ys âˆ’ Ys + Zs
ds â‰¤ CE
ÌŸ Xs âˆ’ x
tÌ„

tÌ„

On the other hand, from Lemma 3.1, we have
YtÌ„1 âˆ’ YtÌ„2

=
=

E YtÌ„1
#
"Z
i

tÌ„+Î¶ h 

F s, XstÌ„,xÌ„ , Ys1 , Zs1 âˆ’ F s, xÌ„, Ys2 ds
E
tÌ„

â‰¤ CE

"Z

tÌ„

tÌ„+Î¶



 
ÌŸ XstÌ„,xÌ„ âˆ’ x + Ys1 âˆ’ Ys2 + Zs1 ds

 2
1
â‰¤ CÎ¶EÌŸ ÎºÎ¶ + CÎ¶ 2

( "Z
E

tÌ„

  
 
2
Î¶
â‰¤ CÎ¶E ÌŸ Îº
+ ÌŸ ÎºÎ¶ ,

tÌ„+Î¶



Ys1

âˆ’

2
Ys2

+

#

2
Zs1



#) 1

2

ds

(62)


with ÌŸ (Ç«) â†’ 0 as Ç« â†’ 0. Note that, for each Î¶ > 0, ÌŸ ÎºÎ¶ is square integrable, we set
  
 
2
Î¶
+ ÌŸ ÎºÎ¶ .
ÌŸ0 (Î¶) = E ÌŸ Îº

Hence,

YtÌ„1 âˆ’ YtÌ„2 â‰¤ CÎ¶ÌŸ0 (Î¶)
24

(63)

From the monotonicity of G [Â·] ,

i
h
tÌ„,xÌ„
âˆ’
âˆ’ Îµ.
V
tÌ„
+
Î¶,
X
Ï• (tÌ„, xÌ„) = V âˆ’ (tÌ„, xÌ„) â‰¥ GtÌ„,xÌ„
tÌ„+Î¶
tÌ„,tÌ„+Î¶
i
h 
tÌ„,xÌ„
âˆ’ Îµ.
â‰¥ GtÌ„,xÌ„
tÌ„,tÌ„+Î¶ Ï• tÌ„ + Î¶, XtÌ„+Î¶

From (58) and letting Îµ â†’ 0,

i
h 
tÌ„,xÌ„
âˆ’ Ï• (tÌ„, xÌ„) = YtÌ„1 .
Ï•
tÌ„
+
Î¶,
X
0 â‰¥ GtÌ„,xÌ„
tÌ„+Î¶
tÌ„,tÌ„+Î¶

By (63) we further have Y0 (tÌ„) = YtÌ„2 â‰¤ CÎ¶ÌŸ0 (Î¶) . Therefore, it follows easily that F (tÌ„, xÌ„, 0, 0) â‰¤ 0
and from the definition of F we see that V âˆ’ is a viscosity supersolution of (43). The proof is
similar for the viscosity sub-solution.

Next, we shall prove that the HJBI equation (43) has a unique viscosity solution. Consequently, the lower and upper value functions coincide, since they are both viscosity solutions to
(43). Thus, the stochastic differential game admits a value.
Before introducing the comparison principle, we need the following two technical lemmas,
mainly taken from [17].
Lemma 4.3 Assume that (A3) is in force. Let U , V : [0, T ] Ã— Rn â†’ R a viscosity
supersolution

and a viscosity subsolution to the HJBI equation (43), respectively. Let tÌ‚, x0 âˆˆ [0, T ] Ã— Rn be
such that




Ï‡
c
U tÌ‚, x0 ,
V tÌ‚, x0 , U tÌ‚, x0 â‰¤ Hinf
V tÌ‚, x0 â‰¤ Hsup

or



Ï‡
U tÌ‚, x0 .
U tÌ‚, x0 â‰¥ Hinf

Then for every Îµ > 0, there exists xÌ‚ âˆˆ Rn such that




V tÌ‚, x0 âˆ’ U tÌ‚, x0 â‰¤ V tÌ‚, xÌ‚ âˆ’ U tÌ‚, xÌ‚ + Îµ
and





Ï‡
c
U tÌ‚, xÌ‚ .
V tÌ‚, xÌ‚ , U tÌ‚, xÌ‚ < Hinf
V tÌ‚, xÌ‚ > Hsup

Lemma 4.4 Assume that (A3) is in force. Let U , V : [0, T ] Ã— Rn â†’ R a viscosity
supersolution

and a viscosity subsolution to the HJBI equation (43), respectively. Let tÌ‚, xÌ‚ âˆˆ [0, T ] Ã— Rn be
such that




Ï‡
c
U tÌ‚, xÌ‚ ,
V tÌ‚, xÌ‚ , U tÌ‚, xÌ‚ < Hinf
V tÌ‚, xÌ‚ > Hsup
then there exists Ç« > 0 for which

Ï‡
c
V (t, x) > Hsup
V (t, x) , U (t, x) < Hinf
U (t, x) ,

where (t, x) âˆˆ






tÌ‚ âˆ’ Î´ âˆ¨ 0, tÌ‚ + Î´ âˆ§ T Ã— BÌ„Î´ (xÌ‚) .

In order to get the uniqueness, we add the following assumption:
(A4) Assume that f is strictly monotone in y, that is, f (t, x, y1 , z) < f (t, x, y2 , z) , for âˆ€y1 ,
y2 âˆˆ R with y1 < y2 , âˆ€ (t, x, z) âˆˆ [0, T ] Ã— Rn Ã— Rd .
Theorem 4.2 Let U , V : [0, T ] Ã— Rn â†’ R a viscosity supersolution and a viscosity subsolution
to the HJBI equation (43), respectively. Assume that (A1)-(A4) are in force and that U , V are
uniformly continuous on [0, T ) Ã— Rn . Then, we have U â‰¥ V on [0, T ] Ã— Rn .
25

Proof

We prove our result by contradiction. Suppose that
sup (V âˆ’ U ) > 0.
[0,T ]Ã—Rn

Fix Î¸ > Cf > 0 where Cf denotes the Lipschitz constant of f.
Define
UÌ„ (t, x) = eÎ¸t U (t, x) , VÌ„ (t, x) = eÎ¸t V (t, x) , (t, x) âˆˆ [0, T ] Ã— Rn .
It is fairly easy to check that UÌ„ (t, x) (VÌ„ (t, x)) is a viscosity supersolusion (subsolution) to the
following HJBI equation:



Ï‡
c
Â¯
max W âˆ’ HÌ„sup
W, min Î¸W âˆ’ âˆ‚W
= 0,
âˆ‚t âˆ’ LW âˆ’ f , W âˆ’ HÌ„inf W
(64)
n
W (T, x) = Î¦Ì„ (x) , (t, x) âˆˆ [0, T ) Ã— R ,
where
i
1 h
LW (t, x) = hb (t, x) , DW (t, x)i + tr ÏƒÏƒ âŠ¤ (t, x) D 2 W (t, x) ,
2


Î¸t
âˆ’Î¸t
âˆ’Î¸t
Â¯
f (t, x, W, DW Â· Ïƒ (t, x)) = e f t, x, e W, e DW Â· Ïƒ (t, x) ,

(65)

Î¦Ì„ (x) = eÎ¸T Î¦ (x) ,
h
i
Ï‡
HÌ„sup
W (t, x) = sup W (t, x + z) + eÎ¸t Ï‡ (t, z) ,
zâˆˆV
h
i
c
HÌ„inf W (t, x) = inf W (t, x + y) âˆ’ eÎ¸t c (t, z) .
yâˆˆU


Assume that there exists x0 âˆˆ Rn such
that UÌ„ âˆ’ VÌ„ (T, x0 ) < 0. Then, from Lemma 4.3,

There exists xÌƒ âˆˆ Rn such that UÌ„ âˆ’ VÌ„ (T, xÌƒ) < 0. On the other hand, from the subsolution
property of VÌ„ , we know VÌ„ (T, xÌƒ) â‰¤ Î¦Ì„ (xÌƒ). Similarly, uitilizing the supersolution property of
UÌ„ , we have UÌ„ (T, xÌƒ) â‰¥ Î¦Ì„ (xÌƒ). Therefore, UÌ„ (T, xÌƒ) â‰¥ VÌ„ (T, xÌƒ) which leads a contradition to
UÌ„ âˆ’ VÌ„ (T, xÌƒ) < 0.

Now postulate that there exists (tÌ„, xÌ„) âˆˆ [0, T ] Ã— Rn such that UÌ„ âˆ’ VÌ„ (tÌ„, xÌ„) < 0. Then, from
Lemma 4.4, there exist tÌ‚, xÌ‚ âˆˆ [0, T ] Ã— Rn and Î´ > 0 such that

sup VÌ„ âˆ’ UÌ„ (t, x) > 0
IÃ—BÌ„Î´ (xÌ‚)

and

Ï‡
c
UÌ„ (t, x) , (t, x) âˆˆ I Ã— BÌ„Î´ (xÌ‚)
VÌ„ (t, x) > HÌ„sup
V (t, x) , UÌ„ (t, x) < HÌ„inf




with I := tÌ‚ âˆ’ Î´ âˆ¨ 0, tÌ‚ + Î´ âˆ§ T .
We define
M
16 |x âˆ’ xÌ‚|4 M
,
1{|xâˆ’xÌ‚|> Î´ } +
VÌƒ (t, x) = VÌ„ (t, x) âˆ’
2
15Î´4
15

where M := supIÃ—BÌ„Î´ (xÌ‚) VÌ„ âˆ’ UÌ„ (t, x) . It is easy to check that


16 |x âˆ’ xÌ‚|4 m
m
1{|xâˆ’xÌ‚|> Î´ } âˆ’
VÌ„ âˆ’ UÌ„ (t, x) âˆ’
4
2
15Î´
15
â‰¤ M.



VÌƒ âˆ’ UÌ„ (t, x) =

So withoutloss of generality, we may assume that


VÌƒ âˆ’ UÌ„ (t, x) â‰¤ 0, (t, x) âˆˆ I Ã— âˆ‚ BÌ„Î´ (xÌ‚) .
26

Note that P 2,+ VÌ„ (t, x) = P 2,+ VÌƒ (t, x) for all (t, x) âˆˆ [0, T ] Ã— Rn , VÌƒ can be replaced with VÌ„ .
Now choose (tâ€² , xâ€² ) âˆˆ I Ã— BÌ„Î´ (xÌ‚) such that



sup VÌ„ âˆ’ UÌ„ (t, x) = VÌ„ âˆ’ UÌ„ tâ€² , xâ€² > 0.
(66)
IÃ—BÌ„Î´ (xÌ‚)

Define the following text function:
Ï†n (t, x, y) = VÌ„ (t, x) âˆ’ UÌ„ (t, y) âˆ’ Ïˆn (t, x, y) , n âˆˆ N
with

n
2
2
|x âˆ’ y|2 + x âˆ’ xâ€² + t âˆ’ tâ€²
2
for every (t, x, y) âˆˆ [0, T ] Ã— Rn Ã— Rn . Clearly, given any n â‰¥ 1, there exists (tn , xn , yn ) âˆˆ
I Ã— BÌ„Î´ (xÌ‚) Ã— BÌ„Î´ (xÌ‚) attaining the maximum of Ï†n on I Ã— BÌ„Î´ (xÌ‚) Ã— BÌ„Î´ (xÌ‚). Up to a subsequence,
(tn , xn , yn ) âˆˆ I Ã— BÌ„Î´ (xÌ‚) Ã— BÌ„Î´ (xÌ‚) â†’ (t0 , x0 , y0 ) âˆˆ I Ã— BÌ„Î´ (xÌ‚) Ã— BÌ„Î´ (xÌ‚) as n â†’ âˆ. Nonetheless, for
every n â‰¥ 1, we have



VÌ„ âˆ’ UÌ„ tâ€² , xâ€² = Ï†n tâ€² , xâ€² , xâ€² â‰¥ Ï†n (tn , xn , yn ) .
Ïˆn (t, x, y) =

It yields that

VÌ„ âˆ’ UÌ„



t â€² , xâ€²



â‰¤ sup limÏ†n (tn , xn , yn )
nâ†’âˆ

â‰¤ VÌ„ (t0 , x0 ) âˆ’ UÌ„ (t0 , y0 ) âˆ’ inf limn |xn âˆ’ yn |2
nâ†’âˆ

âˆ’ x0 âˆ’ x

â€² 2

âˆ’ t0 âˆ’ t

â€² 2

,

(67)

from which, up to a subsequence, inf limn |xn âˆ’ yn |2 < âˆ. Then it follows that x0 = y0 . From
nâ†’âˆ

(67), we derive that
ï£±
ï£² 1) (tn , xn , yn ) â†’ (tâ€² , xâ€² , xâ€² ) ,
2) n |xn âˆ’ yn |2 â†’ 0
ï£³
3) VÌ„ (tn , xn ) âˆ’ UÌ„ (tn , yn ) â†’ VÌ„ (tâ€² , xâ€² ) âˆ’ UÌ„ (tâ€² , xâ€² ) ,

(68)

as n â†’ âˆ. By virtue of Ishiiâ€™s lemma (Theorem 8.3 in [16]), up to a subsequence, we may find
sequence p1n , qn1 , Q1n âˆˆ P 2,+ VÌ„ (tn , xn ) and p2n , qn2 , Q2n âˆˆ P 2,âˆ’ UÌ„ (tn , yn ) such that

p1n âˆ’ p2n = 2 tn âˆ’ tâ€² ,
qn1 = Dx Ïˆn (tn , xn , yn ) = n (xn âˆ’ yn ) ,

qn2 = âˆ’Dy Ïˆn (tn , xn , yn ) = n (xn âˆ’ yn )

and



Q1n
O
O âˆ’Q2n



â‰¤ An +

where
An = Dxy Ïˆn (tn , xn , yn ) = n
Then,


O
Q1n
O âˆ’Q2n



â‰¤ 2n

27





1 2
A
2n n
I âˆ’I
âˆ’I I

I âˆ’I
âˆ’I I



.



.

(69)

From UÌ„ (t, x) (VÌ„ (t, x)) is a viscosity supersolusion (subsolution) to the following HJBI equation
(64), we have


â‰¥ 0,
(70)
Î¸ UÌ„ (tn , yn ) âˆ’ p2n âˆ’ LUÌ„ (tn , yn ) âˆ’ fÂ¯ tn , yn , eâˆ’Î¸tn UÌ„ , eâˆ’Î¸tn D UÌ„ Â· Ïƒ (tn , yn )


Î¸ VÌ„ (tn , xn ) âˆ’ p1n âˆ’ LVÌ„ (tn , xn ) âˆ’ fÂ¯ tn , xn , eâˆ’Î¸tn VÌ„ , eâˆ’Î¸tn D VÌ„ Â· Ïƒ (t, xn )
â‰¤ 0,
(71)
where L is defined in (65). From (70) and (71), we immediately get

Î¸ VÌ„ (tn , xn ) âˆ’ Î¸ UÌ„ (tn , xn ) + p2n âˆ’ p1n + LUÌ„ (tn , xn ) âˆ’ LVÌ„ (tn , yn )


+fÂ¯ tn , yn , eâˆ’Î¸tn UÌ„ (tn , yn ) , eâˆ’Î¸tn qn2 Â· Ïƒ (tn , yn )


âˆ’fÂ¯ tn , xn , eâˆ’Î¸tn VÌ„ (tn , xn ) , eâˆ’Î¸tn qn1 Â· Ïƒ (tn , xn )

â‰¤ 0.

(72)

Clearly,
p1n âˆ’ p2n â†’ 0, as n â†’ âˆ.

(73)

hb (tn , yn ) , n (xn âˆ’ yn )i âˆ’ hb (tn , xn ) , n (xn âˆ’ yn )i â†’ 0,

(74)

and
since (1)-(2) in (68).
For simplicity, set Ïƒ1 = Ïƒ (tn , yn ) , Ïƒ2 = Ïƒ (tn , xn ) . We deal with

=
â‰¤
â‰¤
=

 1

1
Tr ÏƒÏƒ âˆ— (tn , yn ) Q1n âˆ’ Tr ÏƒÏƒ âˆ— (tn , xn ) Q2n
2 
 2 1

1
Ïƒ1 Ïƒ1âŠ¤ Ïƒ1 Ïƒ2âŠ¤
0
Qn
Tr
Ïƒ2 Ïƒ1âŠ¤ Ïƒ2 Ïƒ2âŠ¤
0 âˆ’Q2n
2




Ïƒ1 Ïƒ1âŠ¤ Ïƒ1 Ïƒ2âŠ¤
I âˆ’I
nTr
Ïƒ2 Ïƒ1âŠ¤ Ïƒ2 Ïƒ2âŠ¤
âˆ’I I
i
h
nTr Ïƒ1 Ïƒ1âŠ¤ âˆ’ Ïƒ1 Ïƒ2âŠ¤ âˆ’ Ïƒ2 Ïƒ1âŠ¤ + Ïƒ2 Ïƒ2âŠ¤
i
h
nTr (Ïƒ1 âˆ’ Ïƒ2 ) (Ïƒ1 âˆ’ Ïƒ2 )âŠ¤

â‰¤ nC |Ïƒ1 âˆ’ Ïƒ2 |2

â‰¤ nC |xn âˆ’ yn |2 â†’ 0, as n â†’ âˆ,

(75)

where we have used the the assumption that Lipschitz condition on Ïƒ, (69)
(2) in (68). 
 and
â€²
Thanks to (3) in (68), the left-hand side of inequality (72) goes to Î¸ VÌ„ (t , xâ€² ) âˆ’ UÌ„ (tâ€² , xâ€² ) ,
as n â†’ âˆ, moreover, by (A4), we have





 
 
â€²
â€²
Î¸ VÌ„ tâ€² , xâ€² âˆ’ UÌ„ tâ€² , xâ€²
â‰¤ fÂ¯ tâ€² , xâ€² , eâˆ’Î¸t UÌ„ tâ€² , xâ€² , 0 âˆ’ fÂ¯ tâ€² , xâ€² , eâˆ’Î¸t VÌ„ tâ€² , xâ€² , 0
< 0

which leads to a contradiction to (66). Our proof is thus completed.



Remark 4.3 To get a uniqueness result for viscosity solution of (43), we adapt some techniques
from [17]. We have to mention that there is another approach developed by Barles, Buckdahn
and Pardoux [8]. The value function can be considered in given class of continuous functions
satisfying
o
n
lim |u (t, x)| exp âˆ’A [log (|x|)]2 = 0,
|x|â†’âˆ

28

uniformly for t âˆˆ [0, T ] , for some A > 0. The space of continuous functions endowed with a
growth condition is slightly weaker than the assumption of polynomial growth but more restrictive
than that of exponential growth. This growth condition was first introduced by Barles, Buckdahn,
and Pardoux [8] to prove the uniqueness of the viscosity solution of an integro-partial differential
equation associated with a decoupled FBSDEs with jumps. It has been shown in [8] that this kind
of growth condition is optimal for the uniqueness and can, in general, not be weakened. These
techniques have been applied in [5, 56] for the uniqueness for viscosity solutions of recursive
control of the obstacle constraint problem and Hamilton-Jacobi-Bellman-Isaacs equations related
to stochastic differential games, respectively. However, as you may have observed, in our HJBI
equation, there appears two obstacles, which are implicit obstacles, in the sense that they depend
on V âˆ’ . It is worth to pointing out that the smooth supersolution built in [8], namely



Ï‡ (t, x) = exp CÌŒ (T âˆ’ t) + A Ïˆ (x) ,
whilst

2
 
1
2
2
Ïˆ (x) = log |x| + 1 + 1 ,

where CÌŒ and A are positive constants. One can show

min {L (t, x, v) Ï‡ (t, x) + C |Ï‡| + C |âˆ‡Ï‡Ïƒ (t, x, v)|} â‰¤ 0,
vâˆˆU

where C is the Lipschitz constant of f. Following the idea in [8], whenever considering the
difference of u1 âˆ’ u2 where u1 (u2 ) is a subsolution (supersolution) of (43). It is hard to check
the obstacles of viscosity solution (45)-(48). This is the reason we borrow the idea from Fleming,
Soner [28] and Cosso [17] to handle the uniqueness.
Remark 4.4 As observed in our paper, we put somewhat strong assumptions on coefficients,
namely, boundedness. On the one hand, it simplifies our proof of existence. Recently, El Asri
and Mazid [26] also investigate the solution to the zero-sum stochastic differential games, but
under rather weak assumptions on the cost functions (c and Ï‡ are not decreasing in time). In
the future, we shall adopt the idea developed by El Asri and Mazid [26] to exploit the recursive
utilities.

5

Concluding remarks

In this paper, we study on zero-sum stochastic differential games in the framework of backward
stochastic differential equations on a finite time horizon with both players adopting impulse
controls. By means of stochastic backward semigroups and comparison theorem of BSDE, we
prove a dynamic programming principle for both the upper and the lower value functions of
the game. The upper and the lower value functions are then shown to be the unique viscosity
solutions of the Hamilton-Jacobi-Bellman-Isaacs equations with a double-obstacle. As a result,
the uniqueness implies that the upper and lower value functions coincide and the game admits a
value. In future work, we plan to relax our assumptions and to try to find a smooth solution for
the HJBI (43) in order to obtain uniqueness as Remark 4.3. Besides, as in Zhang [62], we will
consider problems in which one player adopts impulse controls and the other adopts continuous
controls, finite/infinite horizons, etc. These possible extensions promise to be interesting research
directions. We shall response these challenging topics in our future work.

29

A

The Proof of Lemma 3.1

Proof. We adopt the idea from [12]. Let H denote the Cameronâ€“Martin space of all absolutely
continuous elements h âˆˆ â„¦ whose derivative hÌ‡ belongs to L2 [0, T ] , Rd . For any h âˆˆ H, we
define the mapping Ï„h Ï‰ := Ï‰ + h, Ï‰ âˆˆ â„¦. Clearly, Ï„h : â„¦ â†’ â„¦ is a bijection, and its law is given
by

Z T
Z
2
1 T
âˆ’1
hÌ‡s ds P.
hÌ‡s dWs âˆ’
P â—¦ (Ï„h ) = exp
2 0
0

Let (t, x) âˆˆ [0, T ] Ã— Rn be arbitrarily fixed, and put Ht = {h âˆˆ H|h (Â·) = h (Â· âˆ§ t)}. Let u âˆˆ Ut,T ,
v âˆˆ Vt,T , and h âˆˆ Ht , we first show that J (t, x; u, v) (Ï„h ) = J (t, x; u (Ï„h ) , v (Ï„h )), P -a.s. Indeed,
substitute the transformed control processes u (Ï„h ) and v (Ï„h ) for u and v into FBSDEs (1)-(3)
and take the Girsanov transformation to (1)-(3), finally compare the obtained equation with the
previous ones. Then from the uniqueness of the solution of (1)-(3), we conclude with
Xst,x;u,v (Ï„h ) = Xst,x;u(Ï„h ),v(Ï„h ) ,
Yst,x;u,v (Ï„h ) = Yst,x;u(Ï„h ),v(Ï„h ) ,
Zst,x;u,v (Ï„h ) = Zst,x;u(Ï„h ),v(Ï„h )

for any s âˆˆ [t, T ], P -a.s., which indicates that J (t, x; u, v) (Ï„h ) = J (t, x; u (Ï„h ) , v (Ï„h )) , P -a.s.
For Î² âˆˆ Bt,T , h âˆˆ Ht , let Î² h (u) := Î² (u (Ï„âˆ’h )) (Ï„h ), u âˆˆ Ut,T . Then Î² h âˆˆ Bt,T , which makes Ut,T
into Vt,T . Moreover, it is easy to check that this mapping is nonanticipating and verify
)
(
sup J (t, x; u, Î² (u)) (Ï„h ) = sup {J (t, x; u, Î² (u)) (Ï„h )} , P -a.s.
uâˆˆUt,T

uâˆˆUt,T

Now let h âˆˆ Ht ,
V âˆ’ (t, x) (Ï„h ) =
=
=
=

inf

sup {J (t, x; u, Î² (u)) (Ï„h )}

inf

sup

inf

sup

inf

sup {J (t, x; u, Î² (u))}

Î²âˆˆBt,T uâˆˆUt,T

Î²âˆˆBt,T uâˆˆUt,T
Î²âˆˆBt,T uâˆˆUt,T

n 
o
J t, x; u (Ï„h ) , Î² h (u (Ï„h ))
n 
o
J t, x; u, Î² h (u)

Î²âˆˆBt,T uâˆˆUt,T

= V âˆ’ (t, x) , P -a.s.,
which holds even for all h âˆˆ H. Recall the definition of the filtration, the Ft -measurable random
variable V âˆ’ (t, x) (Ï‰), Ï‰ âˆˆ â„¦, depends only on the restriction of Ï‰ to the time interval [0, t]. We
complete our proof with help of Lemma 3.4 in [12].

Acknowledgements. The author wishes to thank the AE and referees for their careful reading
and helpful comments that improved the first version of the paper. The author also thanks the
department of applied mathematics, The Hong Kong Polytechnic University, for its hospitality
during his visit in Jan. 2019.

References
[1] AÄ±Ìˆd R, Basei M, Callegaro G, Campi L and Vargiolu T, Nonzero-Sum Stochastic Differential
Games with Impulse Controls: A Verification Theorem with Applications, Mathematics of
Operations Research, 2019, Vol. 45, No. 1: 1-29.
30

[2] Altarovici A, Reppen M and Soner H M, Optimal Consumption and Investment with Fixed
and Proportional Transaction Costs, SIAM J. Control Optim., 2017,55(3): 1673â€“1710.
[3] Azimzadeh P and Forsyth P A, Weakly Chained Matrices, Policy Iteration, and Impulse
Control, SIAM J. Numer. Anal., 2016, 54(3): 1341â€“1364.
[4] Azimzadeh P, Bayraktar E and Labahn G, Convergence of Implicit Schemes for HamiltonJacobi-Bellman Quasi-Variational Inequalities, SIAM J. Control Optim., 2018, 56(6): 3994â€“
4016.
[5] Bismut J M, â€œTheÌorie Probabiliste du ControÌ‚le des Diffusionsâ€, Memoirs of the American
Mathematical Society, 176, Providence, Rhode Island, 1973.
[6] Bensoussan A, Lions J L, Applications des IneÌquations Variationnelles en ControÌ‚le Stochastique, Dunod, Paris, 1978.
[7] Briand P, Delyon B and Hu Y, Pardoux E, Stoica L, Lp solutions of backward stochastic
differential equations. Stochastic Process. Appl., 2003, 108: 109â€“129.
[8] Barles G, Buckdahn R and Pardoux E, Backward stochastic differential equations and
integral-partial differential equations, Stochastics Stochastics Rep., 1997, Volume 60, Issue
1-2: 57-83.
[9] Buckdahn R, Cardaliaguet P and Rainer C, Nash equilibrium payoffs for nonzero-sum
stochastic differential games, SIAM J. Control Optim., 2004 43: 624â€“642.
[10] E. Bayraktar and H. V. Poor, Stochastic differential games in a non-Markovian setting,
SIAM J. Control Optim., 2005, 43: 1737â€“1756.
[11] Browne S, Stochastic differential portfolio games, J. Appl. Probab., 2000, 37: 126â€“147.
[12] Buckdahn R and Li J, Stochastic differential games and viscosity solutions of HamiltonJacobi-Bellman-Isaacs equations, SIAM J. Control Optim., 2008, 47: 444-475.
[13] Bruder B and Pham H, Impulse control problem on finite horizon with execution delay,
Stochastic Process. Appl., 2009, 119: 1436â€“1469.
[14] CvitanicÌ J and Karatzas I, Backward stochastic differential equations with reflection and
Dynkin games, Ann. Probab., 1996, 24: 2024â€“2056.
[15] Carmona R and Ludkovski M, Swing options, Encyclopedia of quantitative finance, R. Cont,
ed., Wiley, New York, 2009.
[16] Crandall M G, Ishii H and Lions P-L, Userâ€™s guide to viscosity solutions of second order
partial differential equations, Bull. Amer. Math. Soc., 1992 (N.S.) 27: 1â€“67.
[17] Cosso A, Stochastic differential games involving impulse controls and double-obstacle quasivariational inequalities, SIAM J. Control Optim., 2013, Vol. 51, No. 3: 2102â€“2131.
[18] Chen Z and Epstein L, Ambiguity, risk, and asset returns in continuous time. Econometrica,
2002 70: 1403â€“1443.
[19] Chen, L., Wu, Z, Stochastic Optimal Control Problem in Advertising Model with Delay. J
Syst Sci Complex 33, 968â€“987 (2020). https://doi.org/10.1007/s11424-020-8185-1
[20] Duffie D, Epstein L, Stochastic differential utility, Econometrica, 1992, 60: 353â€“394.

31

[21] Y. Dolinsky, Y. Iron, and Y. Kifer, Perfect and partial hedging for swing game options in
discrete time, Math. Finance, 2011, 21: 447â€“474.
[22] Elliott R J and Kalton N J, The existence of value in differential games, Memoirs of the
American Mathematical Society, No. 126, American Mathematical Society, Providence, RI,
1972.
[23] Evans L C and Souganidis P E, Differential games and representation formulas for solutions
of Hamilton-Jacobi-Isaacs equations, Indiana Univ. Math. J., 1984, 33: 773â€“797.
[24] EkstroÌˆm E and Peskir G, Optimal stopping games for Markov processes, SIAM J. Control
Optim., 2008, 47(2): 684â€“702.
[25] Friedman A, Differential Games, Wiley, New York, 1971.
[26] El Asri B, Mazid S, Zero-Sum Stochastic Differential Game in Finite Horizon Involving
Impulse Controls, Appl Math Optim., 2020, 81: 1055-1087.
[27] W. Fleming and H. Soner, Controlled Markov Processes and Viscosity Solutions, SpringerVerlag, New York, 1993.
[28] Fleming W H and Souganidis P E, On the existence of value functions of two-player, zerosum stochastic differential games, Indiana Univ. Math. J., 1989, 38: 293â€“314.
[29] HamadeÌ€ne S and Hassani M, BSDEs with two reflecting barriers: The general result, Probab.
Theory Related Fields, 2005, 132: 237â€“264.
[30] HamadeÌ€ne S and Lepeltier J-P, Zero-sum stochastic differential games and backward equations, Systems Control Lett., 24 (1995): 259â€“263.
[31] HamadeÌ€ne S, Lepeltier J-P, and Peng S G, BSDEs with continuous coefficients and stochastic differential games. in Backward Stochastic Differential Equations, N. El Karoui and L.
Mazliak eds., Pitman Res. Notes Math. Ser., 364, Longman, Harlow 1997, 115â€“128.
[32] HamadeÌne S, Lepeltier J P, Reflected backward stochastic differential equations and mixed
game problem, Stochastic Process. Appl., 2000, 85: 177â€“188.
[33] Iron Y and Kifer Y, Hedging of swing game options in continuous time, Stochastics, 83
(2011): 365â€“404.
[34] Isaacs R, Differential Games. A Mathematical Theory with Applications to Warfare and
Pursuit, Control and Optimization, John Wiley & Sons, Inc., New York-London-Sydney,
1965.
[35] Krylov N, Controlled Diffusion Processes, Springer-Verlag, New York, 1980.
[36] Karatzas I and Sudderth W, The controller-and-stopper game for a linear diffusion, Ann.
Probab., 2001, 29: 1111â€“1127.
[37] Karatzas I and Shreve S E, Methods of Mathematical Finance, Springer-Verlag, New York,
1998.
[38] Kharroubi I, Ma J, Pham H and Zhang J, Backward SDEs with constrained jumps and
quasi-variational inequalities, Ann. Probab., 2010, 38:794â€“840.
[39] Korn R, Some applications of impulse control in mathematical finance, Math. Methods
Oper. Res., 1999 50: 493â€“518.
32

[40] Karatzas I and Zamfirescu M, Martingale approach to stochastic control with discretionary
stopping, Appl. Math. Optim., 2006, 53: 163â€“184.
[41] El Karoui N, Peng S and Quenez M C, Backward stochastic differential equations in finance,
Math. Finance, 1997, 7: 1â€“71.
[42] Lenhart S M, Viscosity solutions associated with impulse control problems for piecewisedeterministic processes, Internat. J. Math. Math. Sci., 1989, 12: 145â€“157.
[43] Ly Vath V, Mnif M and Pham H, A model of optimal portfolio selection under liquidity
risk and price impact, Finance and Stochastics, 2007, 11: 51â€“90.
[44] Peng S, Backward stochastic differential equations and applications to optimal control.
Appl. Math. Optim., 1993, 27: 125â€“144.
[45] Pardoux E, Peng S, Adapted solution of a backward stochastic differential equation, Systems
Control Lett., 1990, 14: 55â€“61.
[46] Peng S, Probabilistic interpretation for systems of quasilinear parabolic partial differential
equations, Stochastics Stochastics Rep., 1991, 37: 61â€“74.
[47] Peng S, A generalized dynamic programming principle and HJB equation, Stochastics
Stochastics Rep., 1992, 38: 119â€“134.
[48] Peng S, BSDE and stochastic optimizations, in: J. Yan, S. Peng, S. Fang, L. Wu, Topics
in Stochastic Analysis, Science Press, Beijing, 1997 (Chapter 2) (in Chinese).
[49] Palczewski J and Stettner L, Finite horizon optimal stopping of time-discontinuous functionals with applications to impulse control with delay, SIAM J. Control Optim., 2010, 48:
4874â€“4909.
[50] Robin M, Controle impulsionnel des processus de Markov, Thesis, INRIA, Paris, France,
1978. Available online at http://tel.archives-ouvertes.fr/tel-00735779.
[51] Revuz D, Yor M, Continuous Martingales and Brownian Motion, Third Edition With 8
Figures, Springer, 1999.
[52] Stettner L, Zero-sum Markov games with stopping and impulsive strategies, Appl. Math.
Optim., 1982, 9: 1â€“24.
[53] L. Stettner, Penalty method for finite horizon stopping problems, SIAM J. Control Optim.,
2011, 49: 1078â€“1099.
[54] Tang S and Hou S-H, Switching games of stochastic differential systems, SIAM J. Control
Optim., 2007, 46: 900â€“929.
[55] Tang S and Yong J M, Finite horizon stochastic optimal switching and impulse controls
with a viscosity solution approach, Stochastics Stochastics Rep., 1993, 45: 145â€“176.
[56] Z. Wu, Z. Yu, Dynamic programming principle for one kind of stocastic recursive optimal
control problem and Hamilton-Jacobi-Bellman equation, SIAM J. Control Optim., 2008
Vol. 47, No. 5: 2616â€“2641.
[57] Xu, X, Fully Coupled Forward-Backward Stochastic Functional Differential Equations and
Applications to Quadratic Optimal Control. J Syst Sci Complex 33, 1886â€“1902 (2020).
https://doi.org/10.1007/s11424-020-9027-x.
33

[58] Wang G, Yu Z, A partial information non-zero sum differential game of backward stochastic
differential equations with applications. Automatica, 2012, 48(2),342-352.
[59] Wang G, Xiao H and Xiong J, A kind of LQ non-zero sum differential game of backward
stochastic differential equation with asymmetric information, Automatica, 2018, 97, 346352.
[60] Yong J M, Zhou X Y, Stochastic Controls. Hamiltonian Systems and HJB Equations,
Springer-Verlag, New York, 1999.
[61] Yong J M, Zero-sum differential games involving impulse controls, Appl. Math. Optim.,
1994. 29 : 243â€“261.
[62] Zhang F, Stochastic differential games involving impulse controls, ESAIM Control Optim.
Calc. Var., 2011, 17: 749â€“760.
[63] Zabaljauregui D, A fixed-point policy-iteration-type algorithm for symmetric nonzero-sum
stochastic impulse games, Appl Math Optim: 2020.

34

