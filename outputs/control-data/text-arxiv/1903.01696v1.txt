arXiv:1903.01696v1 [math.ST] 5 Mar 2019

Measuring and Controlling Bias for Some
Bayesian Inferences and the Relation to
Frequentist Criteria
Michael Evans and Yang Guo
Department of Statistical Sciences
University of Toronto
Abstract
A common concern with Bayesian methodology in scientific contexts is that
inferences can be heavily influenced by subjective biases. As presented here,
there are two types of bias for some quantity of interest: bias against and bias
in favor. Based upon the principle of evidence, it is shown how to measure and
control these biases for both hypothesis assessment and estimation problems.
Optimality results are established for the principle of evidence as the basis of the
approach to these problems. A close relationship is established between measuring bias in Bayesian inferences and frequentist properties that hold for any
proper prior. This leads to a possible resolution to an apparent conflict between
these approaches to statistical reasoning. Frequentism is seen as establishing a
figure of merit for a statistical study, while Bayesianism plays the key role in
determining inferences based upon statistical evidence.
Keywords and phrases: principle of evidence, bias against, bias in favor, plausible region, frequentism, confidence.

1

Introduction

A serious concern with Bayesian methodology is that the choice of the prior
could result in conclusions that to some degree are predetermined before seeing
the data. In certain circumstances this is correct. This can be seen by considering the problem associated with what is known as the Jeffreys-Lindley paradox
where posterior probabilities of hypotheses, as well as associated Bayes factors,
will produce increasing support for the hypothesis as the prior becomes more
diffuse. So, while one may feel that a very diffuse prior is putting in very little
information, it is in fact biasing the results in favor of the hypothesis. It has
been argued, see Baskurt and Evans (2013) and Evans (2015), that the measurement and control of bias is a key element of a Bayesian analysis as without it,
and the assurance that bias is minimal, the validity of any inference is suspect.
1

While attempts have been made to avoid the Jeffreys-Lindley paradox through
the choice of the prior, modifying the prior to avoid bias is contrary to the ideals of a Bayesian analysis which requires the elicitation of a prior based upon
knowledge of the phenomenon under study. Why should one change such a
prior because of bias? Indeed, as will be discussed, there is bias in favor and
bias against and typically choosing a prior to minimize one type of bias simply increases the other. The real method for controlling bias of both types is
through the amount of data collected. So controlling bias is an aspect of design. Bias can be measured post-hoc and it then provides a way to assess the
weight that should be given the results of an analysis. For example, if a study
concludes that there is evidence in favor of a hypothesis, but it can be shown
that there was a high prior probability that such evidence would be obtained,
then the results of such an analysis canâ€™t be considered to be reliable.
Previous discussion concerning bias was focused on hypothesis assessment
and in many ways this is a natural starting point. This paper is concerned with
adding some aspects to those developments and to extending the approach to
estimation and prediction problems. Furthermore, it is shown here that measuring and controlling bias establishes close links between a frequentist approach
to statistics and Bayesian inference. In essence frequentism is concerned with
design while inferences are Bayesian. Bayesian inference is based upon the evidence in the observed data and is unconcerned, at least for inference, about
data sets that could have been obtained. Frequentism is concerned with the
behavior of inferences as applied to unobserved data sets and this is entirely appropriate before the data is observed. So consideration of bias leads to a degree
of unification between different ways of thinking about statistical reasoning.
The measurement of bias, and thus its control, is dependent upon measuring
evidence. The principle of evidence is adopted here: evidence in favor of a
specific value of an unknown occurs when the posterior probability of the value
is greater than its prior probability, evidence against occurs when the posterior
probability of the value is less than its prior probability and there is no evidence
either way when these are equal. The major part of what is discussed here
depends only on this simple principle but sometimes a numerical measure of
evidence is needed and for this we use the relative belief ratio defined as the
ratio of the posterior to prior probability. The relative belief ratio is related to
the Bayes factor but has some nicer properties such as providing a measure of
the evidence for each value of a parameter without the need to modify the prior.
There is not much discussion in the Bayesian literature of the notion of
bias in the sense that is meant here. There is considerable discussion, however,
concerning the Jeffreys-Lindley paradox and our position is that bias plays a
key role in the issues that arise. Relevant recent papers on this include Shafer
(1982), Spanos (2013), Sprenger (2013), Robert (2014), Cousins (2017) and Villa
and Walker (2017) and these contain extensive background references. Gu et
al. (2019) is concerned with the validation of quantum theory using Bayesian
methodology applied to well-known data sets and the principle of evidence and
an assessment of the bias in the prior plays a key role in the argument.
In Section 2 the concepts are defined, their properties are considered and
2

illustrated via a simple example where the Jeffreys-Lindley paradox is relevant.
Also, it is seen that a well-known p-value does not satisfy the principle of evidence but can still be used to characterize evidence for or against but requires
significance levels that go to 0 with increasing sample size or increasing diffuseness of the prior. In Section 3 the relationship with frequentism is discussed and
a number of optimality results are established for the approach taken here to
measuring and controlling bias, namely, via the principle of evidence. In Section
4, a variety of examples are considered and analyzed from the point-of-view of
bias. All proofs of theorems are in the Appendix.

2

Evidence and Bias

For the discussion here there is a model {fÎ¸ : Î¸ âˆˆ Î˜}, given by densities fÎ¸ ,
for data x and a proper prior probability distribution given by density Ï€. It is
supposed that interest is in inferences about Ïˆ = Î¨(Î¸) where Î¨ : Î˜ â†’ Î¨ is onto
and for economy the same notation is used for the function and its range. For
the most part it is safe to assume all the probability distributions are discrete
with results for the continuous case obtained by taking limits.
A measure of the evidence that Ïˆ âˆˆ Î¨ is the true value is given by the
relative belief ratio
RBÎ¨ (Ïˆ | x) = lim

Î´â†’0

Î Î¨ (NÎ´ (Ïˆ) | x)
Ï€Î¨ (Ïˆ | x)
=
Î Î¨ (NÎ´ (Ïˆ))
Ï€Î¨ (Ïˆ)

(1)

where Î Î¨ , Î Î¨ (Â· | x) are the prior and posterior probability measures of Î¨ with
densities Ï€Î¨ and Ï€Î¨ (Â· | x), respectively, and NÎ´ (Ïˆ) is a sequence of sets converging nicely to {Ïˆ}. The last equality in (1) requires some conditions but the
prior density positive and continuous at Ïˆ is enough. So RBÎ¨ (Ïˆ | x) > 1 implies
evidence for the true value being Ïˆ, etc. Any valid measure of evidence should
satisfy the principle of evidence, namely, the existence of a cut-off value that
determines evidence for and against as prescribed by the principle. Naturally,
this cut-off is 1 for the relative belief ratio. The Bayes factor is also a valid measure of evidence and with the same cut-off. When Î Î¨ (A) > 0 then the Bayes
factor of A equals RB(A | x)/RB(Ac | x) and so can be defined in terms of the
relative belief ratio, but not conversely. Also, RB(A | x) > 1 iff RB(Ac | x) < 1
and so the Bayes factor is not really a comparison of the evidence for A being
true with the evidence for its negation. In the continuous case, if we define
the Bayes factor for Ïˆ as a limit as in (1), then this limit equals RBÎ¨ (Ïˆ | x).
Further discussion on the choice of a measure of evidence can be found in Evans
(2015) as there are other candidates beyond these two. It is important to note,
however, that the discussion of bias depends only on the principle of evidence
and is the same no matter what valid measure of evidence is used.
The following example is carried along as it illustrates a number of things.
Example 1. Location normal.
Suppose x = (x1 , . . . , xn ) is i.i.d. N (Âµ, Ïƒ02 ) with Ï€ a N (Âµ0 , Ï„02 ) prior. Then

3

âˆ’1
) so
(nxÌ„/Ïƒ02 + Âµ0 /Ï„02 ), n/Ïƒ02 + 1/Ï„02
ï£±

 âˆš
2 ï£¼

1/2
Ïƒ0 (Âµ0 âˆ’Âµ)
n(xÌ„âˆ’Âµ)
ï£² âˆ’ 1 1 + Ïƒ02
ï£½
âˆš 2
+
nÏ„02
2
2
Ïƒ0
nÏ„0
nÏ„0
RB(Âµ | x) = 1 + 2
exp
.
2
ï£³
ï£¾
Ïƒ0
+ (Âµâˆ’Âµ20 )

Âµ | x âˆ¼ N ( n/Ïƒ02 + 1/Ï„02

âˆ’1

2Ï„0

2.1

Bias in Hypothesis Assessment Problems

The value RBÎ¨ (Ïˆâˆ— | x) tells us if we have evidence for or against H0 : Î¨(Î¸) = Ïˆâˆ— .
Example 1. Location normal (continued).
Observe that as Ï„02 â†’ âˆ, then RB(Âµ | x) â†’ âˆ for every Âµ and in particular
for a hypothesized value H0 = {Âµâˆ— }. So it would appear that overwhelming
evidence is obtained for the hypothesis when the prior is very diffuse and this
holds
irrespective of what the data says. Also, when the standardized value
âˆš
n|xÌ„ âˆ’ Âµâˆ— | is fixed, then RB(Âµâˆ— | x) â†’ âˆ as n â†’ âˆ. This phenomenon also
occurs if a Bayes factor (which equals RB(Âµâˆ— | x) in this case) or a posterior
probability based upon a discrete prior mass at Âµâˆ— is used to assess H0 . Accordingly all these
âˆš measures lead to a sharp disagreement with the frequentist
p-value 2(1 âˆ’ Î¦( n|xÌ„ âˆ’ Âµâˆ— |/Ïƒ0 )) when it is small. This is the Jeffreys-Lindley
paradox and it arises quite generally.
The Jeffreys-Lindley paradox shows that the strength of evidence cannot be
measured strictly by the size of the measure of evidence. A logical way to assess
this is to compare the evidence for Ïˆâˆ— with the evidence for the other possible
values for Ïˆ. The strength of the evidence can then be measured by
Î Î¨ (RBÎ¨ (Ïˆ | x) â‰¤ RBÎ¨ (Ïˆâˆ— | x) | x),

(2)

the posterior probability that the true value has evidence no greater than the
evidence for Ïˆâˆ— . So if RBÎ¨ (Ïˆâˆ— | x) < 1 and (2) is small, then there is strong evidence against Ïˆâˆ— while, if RBÎ¨ (Ïˆâˆ— | x) > 1 and (2) is large, then there is strong
evidence in favor of Ïˆâˆ— . The inequalities Î Î¨ ({Ïˆâˆ— } | x) â‰¤ Î Î¨ (RBÎ¨ (Ïˆ | x) â‰¤
RBÎ¨ (Ïˆâˆ— | x) | x) â‰¤ RBÎ¨ (Ïˆâˆ— | x) hold and so when RBÎ¨ (Ïˆâˆ— | x) is small there is
strong evidence against Ïˆâˆ— and when RBÎ¨ (Ïˆâˆ— | x) > 1 and Î Î¨ ({Ïˆâˆ— } | x) is big,
then there is strong evidence in favor of Ïˆâˆ— . Note, however, that Î Î¨ ({Ïˆâˆ— } | x) â‰ˆ 1
does not guarantee RBÎ¨ (Ïˆâˆ— | x) > 1 and if RBÎ¨ (Ïˆâˆ— | x) < 1 this means that
there is weak evidence against Ïˆâˆ— . There is no reason why multiple measures of
the strength of the evidence canâ€™t be used (see the discussion in Section 2.2).
There are some issues with (2) in the continuous case that require a modification
and we refer to Evans (2015) for this as the strength does not play a key role in
the discussion here. The important point is to somehow calibrate the measure
of evidence using probability to measure how strong belief in the evidence is.
Example 1. Location normal (continued).
âˆš
A simple
with n|xÌ„âˆ’Âµâˆ— | fixed, then (2) converges to
âˆš calculation shows that,
2(1 âˆ’ Î¦( n|xÌ„ âˆ’ Âµâˆ— |/Ïƒ0 )) as nÏ„02 â†’ âˆ. So, if the p-value is small, this indicates
that a large value of RBÎ¨ (Âµâˆ— | âˆš
x) is only weak evidence in favor of Âµâˆ— . It is to be
noted that the p-value 2(1âˆ’Î¦( n|xÌ„âˆ’Âµâˆ— |/Ïƒ0 )) is not a valid measure of evidence
4

as described here because there is no cut-off that corresponds to evidence for
and evidence against. So its appearance as a measure of the strength of the
evidence is not in any sense circular.
âˆš
Simple algebra shows, however, that 2(1âˆ’Î¦( n|xÌ„âˆ’Âµâˆ— |/Ïƒ0 ))âˆ’2(1âˆ’Î¦([log(1+
âˆ’1
(xÌ„ âˆ’ Âµ0 )2 /Ï„02 ]1/2 ), a difference of two p-values, is a
nÏ„02 /Ïƒ02 ) + 1 + nÏ„02 /Ïƒ02
valid measure of evidenceâˆšvia the cut-off 0. From this it is seen that the values of
the first p-value 2(1 âˆ’ Î¦( n|xÌ„ âˆ’ Âµâˆ— |/Ïƒ0 ) that lead to evidence against generally
become
smaller as nÏ„02 â†’ âˆ. For example, with n = 10, Ïƒ02 = 1, Âµâˆ— = 0 and
âˆš
n|xÌ„ âˆ’ Âµâˆ— | = 1.96, then the p-value equals 0.05. Setting Âµ0 = 0 and Ï„02 = 1
the second p-value equals 0.119 and so there is evidence against, with Ï„02 = 10
the the second term equals 0.032 and with Ï„02 = 100 it equals 0.009, so there is
evidence in favor in both cases. When n increases these values become smaller
as with n = 50 the first p-value equal to 0.05 is always evidence in favor. Similar
results are obtained with a uniform prior on (âˆ’m, m), reflecting perhaps a desire
to treat many values equivalently, as
âˆš m â†’ âˆ or n â†’ âˆ. For example, with
m = 10 and n = 10, Ïƒ02 = 1, Âµâˆ— = 0, n|xÌ„ âˆ’ Âµâˆ— | = 1.96, then the second p-value
equals 0.002 and there is evidence in favor. These conclusions are similar to
those found in Berger and Selke (1987) and Berger and Delampady (1987).
It is very simple to elicit (Âµ0 , Ï„02 ) based on prescribing an interval that contains the true Âµ with some high probability such as 99.9%, taking Âµ0 to be the
mid-point and so Ï„02 is determined. There is no reason to take Ï„02 to be arbitrarily large. But still one wonders if the choice made is inducing some kind of
bias into the problem as taking Ï„02 too large clearly does.
Certainly default choices of priors should be avoided when possible, but even
when eliciting, how can we know if the chosen prior is inducing bias? To assess
this a numerical measure is required. The principle of evidence suggests that
bias against H0 is measured by
M (RBÎ¨ (Ïˆâˆ— | X) â‰¤ 1 | Ïˆâˆ— )

(3)

where M (Â· | Ïˆâˆ— ) is the prior predictive distribution of the data given that the
hypothesis is true. So (3) is the prior probability that evidence in favor of Ïˆâˆ—
will not be obtained when Ïˆâˆ— is the true value. If (3) is large, then there is an
a priori bias against H0 .
For the bias in favor of H0 it is necessary to assess if evidence against H0
will not be obtained with high prior probability even when H0 is false. One
possibility is to measure bias in favor by
Z
M (RBÎ¨ (Ïˆâˆ— | X) â‰¥ 1 | Ïˆ) Î Î¨ (dÏˆ)
Î¨\{Ïˆâˆ— }

= M (RBÎ¨ (Ïˆâˆ— | X) â‰¥ 1) âˆ’ M (RBÎ¨ (Ïˆâˆ— | X) â‰¥ 1 | Ïˆâˆ— )Î Î¨ ({Ïˆâˆ— })

(4)

which is the prior probability of not obtaining evidence against Ïˆâˆ— when it is
false. When Î Î¨ ({Ïˆâˆ— }) = 0, then (4) equals M (RBÎ¨ (Ïˆâˆ— | X) â‰¥ 1) where M is
the prior predictive for the data. For continuous parameters it can be argued
that it does not make sense to consider values of Ïˆ so close to Ïˆâˆ— that they
5

are practically speaking indistinguishable. Suppose then there is a measure of
distance dÎ¨ on Î¨ and a value Î´ > 0 such that, if dÎ¨ (Ïˆâˆ— , Ïˆ) < Î´, then Ïˆâˆ— and
Ïˆ are indistinguishable in the application. The bias in favor of H0 can then be
measured by replacing Î¨\{Ïˆâˆ— } in (4) by {Ïˆ : dÎ¨ (Ïˆâˆ— , Ïˆ) â‰¥ Î´} which has upper
bound bound
sup
M (RBÎ¨ (Ïˆâˆ— | X) â‰¥ 1 | Ïˆ).
(5)
Ïˆ:dÎ¨ (Ïˆâˆ— ,Ïˆ)â‰¥Î´

Typically M (RBÎ¨ (Ïˆâˆ— | X) â‰¥ 1 | Ïˆ) decreases as Ïˆ moves away from Ïˆâˆ— so (5)
can be computed by finding the supremum over the set {Ïˆ : dÎ¨ (Ïˆâˆ— , Ïˆ) = Î´} and,
when Ïˆ is real-valued and dÎ¨ is Euclidian distance, this equals {Ïˆâˆ— âˆ’ Î´, Ïˆâˆ— + Î´}.
It is to be noted that the measures of bias given by (3), (4) and (5) do
not depend on using the relative belief ratio to measure evidence. Any valid
measure of evidence will determine the same values when the relevant cut-off
is substituted for 1. It is only (2) that depends on the specific choice of the
relative belief ratio as the measure of evidence.
Under general circumstances, see Evans (2015), both biases will converge
to 0 as the amount of data increases and so both biases can be controlled by
design. Clearly there is no point in reporting the results of an analysis when
there is a lot of bias unless the evidence actually contradicts the bias.
Example 1. Location normal (continued).
Under M (Â· | Âµ), then xÌ„ âˆ¼ N (Âµ, Ï„02 + Ïƒ02 /n). So, putting
âˆš
a(Âµâˆ— , Âµ0 , Ï„02 , Ïƒ02 , n) = Ïƒ0 (Âµâˆ— âˆ’ Âµ0 )/ nÏ„02 ,
(
#)1/2
" 

2
Ïƒ02
nÏ„02
(Âµâˆ— âˆ’ Âµ0 )
2
2
b(Âµâˆ— , Âµ0 , Ï„0 , Ïƒ0 , n) =
1+ 2
log 1 + 2 +
,
nÏ„0
Ïƒ0
Ï„02
then (3) is given by

M (RB(Âµâˆ— | X) â‰¤ 1 | Âµâˆ— ) = 1âˆ’Î¦ a(Âµâˆ— , Âµ0 , Ï„02 , Ïƒ02 , n) + b(Âµâˆ— , Âµ0 , Ï„02 , Ïƒ02 , n) +

Î¦ a(Âµâˆ— , Âµ0 , Ï„02 , Ïƒ02 , n) âˆ’ b(Âµâˆ— , Âµ0 , Ï„02 , Ïƒ02 , n) . (6)

This goes to 0 as n â†’ âˆ or as Ï„02 â†’ âˆ. So bias against can be controlled by
sample size n or by the diffuseness of the prior although, as subsequently shown,
a diffuse prior induces bias inâˆšfavor. It is also the case that (6) converges to 0
when Âµ0 â†’ Â±âˆ or when Ïƒ0 / nÏ„0 is fixed and Ï„0 â†’ 0. So it would appear that
using a prior with location quite different than the hypothesized value or a prior
that was much more concentrated than the sampling distribution, can be used
to lower bias against. These are situations, however, where one can expect to
have prior-data conflict after observing the data.
The entries in Table 1 record the bias against for a specific case and illustrate
that increasing n does indeed reduce bias. The entries also show that bias
against can be greater when the prior is centered on the hypothesis. Figure
1 contains a plot of the bias against H0 = {Âµâˆ— }, as a function of Âµâˆ— , when
using a N (0, 1) prior. Note that the maximum bias against occurs at the mean
of the prior (and equals 0.143) and this typically occurs when Ïƒ02 /nÏ„02 < 1,
6

n
5
10
20
50
100

Âµ0 = 1, Ï„0 = 1
0.095
0.065
0.044
0.026
0.018

Âµ0 = 0, Ï„0 = 1
0.143
0.104
0.074
0.045
0.031

0.2
0.0

0.1

bias against

0.3

0.4

Table 1: Bias against for the hypothesis H0 = {0} with a N (Âµ0 , Ï„02 ) prior for
different sample sizes n with Ïƒ0 = 1.

âˆ’10

âˆ’5

0

5

10

Âµ

Figure 1: Plot of bias against H0 = {Âµ} with a N (0, 1) prior (- - -) and a
N (0, 0.01) prior (â€”) with n = 5, Ïƒ0 = 1.
namely, when the data is more concentrated than the prior. Figure 1 also
contains a plot of the bias against when using a prior more concentrated than
the data distribution. That the bias against is maximized, as a function of the
hypothesized mean Âµâˆ— , when Âµâˆ— equals the value associated with the strongest
belief under the prior seems odd. This phenomenon arises quite often, and
the mathematical explanation for this is that the greater the amount of prior
probability assigned to a value, the harder it is for the posterior probability to
increase and so it is quite logical when considering evidence. It will be seen
that this phenomenon is very convenient for the control of bias in estimation
problems and could be used as an argument for using a prior centered on the
hypothesis, although this is not necessary as beliefs may be different.
Now consider (5), namely, bias in favor of H0 = {Âµâˆ— }. Putting
âˆš
c(Âµâˆ— , Âµ, Âµ0 , Ï„02 , Ïƒ02 , n) = n(Âµâˆ— âˆ’ Âµ)/Ïƒ0 + a(Âµâˆ— , Âµ0 , Ï„02 , Ïƒ02 , n),
7

0.8
0.6
bias in favor

0.4
0.2
0.0

âˆ’4

âˆ’2

0

2

4

Âµ

Figure 2: Plot of M (RB(0 | X) â‰¥ 1 | Âµ) when n = 20, Âµ0 = 1, Ï„0 = 1, Ïƒ0 = 1.

then (5) equals max M (RB(Âµâˆ— | X) â‰¥ 1 | Âµâˆ— Â± Î´) where

M (RB(Âµâˆ— | X) â‰¥ 1 | Âµ) = Î¦ c(Âµâˆ— , Âµ, Âµ0 , Ï„02 , Ïƒ02 , n) + b(Âµâˆ— , Âµ0 , Ï„02 , Ïƒ02 , n) âˆ’

Î¦ c(Âµâˆ— , Âµ, Âµ0 , Ï„02 , Ïƒ02 , n) âˆ’ b(Âµâˆ— , Âµ0 , Ï„02 , Ïƒ02 , n)
(7)

which converges to 0 as n â†’ âˆ and also as Âµ â†’ Â±âˆ. But (7) converges to 1
as Ï„02 â†’ âˆ, so if the prior is too diffuse there will be bias in favor of Âµâˆ— . So
resolving the Jeffreys-Lindley paradox requires choosing the sample size n, after
choosing the prior, so that (7) is suitably small. Note that choosing Ï„02 larger
reduces bias against but increases bias in favor and so generally bias cannot be
avoided by choice of prior. Figure 2 is a plot of M (RB(Âµâˆ— | X) â‰¥ 1 | Âµ) for a
particular case and this strictly decreases as Âµ moves away from Âµâˆ— .
In Table 2 we have recorded some specific values of the bias in favor using
(4) and using (5) where dÎ¨ is Euclidean distance. It is seen that bias in favor
can be quite serious for small samples. When using (5) this can be mitigated by
making Î´ larger. For example, with (Âµ0 , Ï„0 ) = (0, 1), Î´ = 1.0, n = 20 the bias in
favor equals 0.004. Note, however, that Î´ is not chosen to make the bias in favor
small, rather it is determined in an application as the difference from the null
that is just practically important. The virtues of determining a suitable value
of Î´ are also readily apparent as (5) is much smaller than (4) for larger n.
A comparison of Tables 1 and 2 shows that a study whose purpose is to
demonstrate evidence in favor of H0 is much more demanding than one whose
purpose is to determine whether or not there is evidence against H0 .

8

n
5
10
20
50
100

(Âµ0 , Ï„0 ) = (1, 1)
0.323 (0.871)
0.259 (0.747)
0.215 (0.519)
0.153 (0.125)
0.116 (0.006)

(Âµ0 , Ï„0 ) = (0, 1)
0.451 (0.631)
0.371 (0.516)
0.299 (0.327)
0.219 (0.062)
0.168 (0.002)

Table 2: Bias in favor of the hypothesis H0 = {0} with a N (Âµ0 , Ï„02 ) prior for
different sample sizes n with Ïƒ0 = 1 using (4) (and using (5) with Î´ = 0.5).

2.2

Bias in Estimation Problems

The relative belief estimate of Ïˆ = Î¨(Î¸) is the value that maximizes the measure of evidence, namely, Ïˆ(x) = arg sup RBÎ¨ (Ïˆ | x). It is easy to show that
RBÎ¨ (Ïˆ(x) | x) â‰¥ 1 with the inequality strict except in trivial contexts. The
accuracy of this estimate can be measured by the â€sizeâ€ of the plausible region
P lÎ¨ (x) = {Ïˆ : RBÎ¨ (Ïˆ | x) > 1}, the set of values of Ïˆ that have evidence
in their favor and note Ïˆ(x) âˆˆ P lÎ¨ (x). To say that Ïˆ(x) is an accurate estimate, requires that P lÎ¨ (x) be â€smallâ€, perhaps as measured by V ol(P lÎ¨ (x))
where V ol is some measure of volume, and also have high posterior content
Î Î¨ (P lÎ¨ (x) | x) which measures the belief that the true value is in P lÎ¨ (x). Note
that P lÎ¨ (x) does not depend on the specific measure of evidence chosen, in this
case the relative belief ratio. Any valid estimator must satisfy the principle of
evidence and so be in P lÎ¨ (x). It is argued that in an estimation problem, bias
is measured by various coverage probabilities for the plausible region.
Note too that if there is evidence in favor of H0 : Î¨(Î¸) = Ïˆâˆ— , then Ïˆâˆ— âˆˆ
P lÎ¨ (x) and so represents the natural estimate of Ïˆ provided there was a clear
reason for assessing the evidence for this value. The strength of the evidence
in favor of Ïˆâˆ— can then also be measured by the size of P lÎ¨ (x). Similarly, if
evidence against H0 is obtained then Ïˆâˆ— âˆˆ ImÎ¨ = {Ïˆ : RBÎ¨ (Ïˆ | x) < 1}, the
implausible region and then there is strong evidence against H0 provided P lÎ¨ (x)
has small volume and large posterior probability. A virtue of this approach to
measuring the strength of the evidence is that it does not depend upon using
the relative belief ratio to measure evidence.
2.2.1

Bias Against

The prior probability that the plausible region does not cover the true value
measures bias against when estimating Ïˆ. For if this probability is large, then
the estimate and the plausible region are a priori likely to be misleading as to
the true value. The prior probability that P lÎ¨ (x) doesnâ€™t contain Ïˆ = Î¨(Î¸)
when Î¸ âˆ¼ Î , X âˆ¼ PÎ¸ is
/ P lÎ¨ (X) | Ïˆ)) = EÎ Î¨ (M (RBÎ¨ (Ïˆ | X) â‰¤ 1 | Ïˆ))
EÎ Î¨ (M (Ïˆ âˆˆ

(8)

which is also the average bias against over all hypothesis testing problems H0 :
/ P lÎ¨ (X) | Ïˆ)) = EÎ Î¨ (M (Ïˆ âˆˆ P lÎ¨ (X) | Ïˆ))
Î¨(Î¸) = Ïˆ. Note that 1âˆ’EÎ Î¨ (M (Ïˆ âˆˆ
9

n
5
10
20
50
100

Ï„0 = 1
0.107
0.075
0.051
0.031
0.021

Ï„0 = 0.5
0.193
0.146
0.107
0.067
0.046

Table 3: Average bias against H0 = 0 when using aN (0, Ï„02 ) prior for different
sample sizes n.
= EM (Î Î¨ (P lÎ¨ (X) | X)) which is the prior coverage probability of P lÎ¨ . Also,
sup M (Ïˆ âˆˆ
/ P lÎ¨ (X) | Ïˆ) = sup M (RBÎ¨ (Ïˆ | X) â‰¤ 1 | Ïˆ),
Ïˆ

(9)

Ïˆ

is an upper bound on (8). Therefore, controlling (9) controls the bias against
in estimation and all hypothesis assessment problems involving Ïˆ. Also 1 âˆ’
supÏˆ M (Ïˆ âˆˆ
/ P lÎ¨ (X) | Ïˆ) = inf Ïˆ M (Ïˆ âˆˆ P lÎ¨ (X) | Ïˆ) â‰¤ EM (Î Î¨ (P lÎ¨ (X) | X))
so using (9) implies lower bounds for the coverage probability and for the expected posterior content of the plausible region. In general, both (8) and (9)
converge to 0 with increasing amounts of data. So it is possible to control for
bias against in estimation problems by design.
Example 1. Location normal (continued).
The value of M (RB(Âµ | X) â‰¤ 1 | Âµ) is given in (6) and examples are plotted
in Figure 1. When Âµ âˆ¼ N (Âµ0 , Ï„02 ) then z = (Âµ âˆ’ Âµ0 )/Ï„0 âˆ¼ N (0, 1) so
EÎ  (M (RB(Âµ | X) â‰¤ 1 | Âµ))
ï£® 
n
h 

io1/2 
Ïƒ02
nÏ„02
Ïƒ0
2
âˆš
Z + 1 + nÏ„ 2 log 1 + Ïƒ2 + Z
+
ï£¯ Î¦
nÏ„0
0
0


=1âˆ’Eï£¯
io

h


n
1/2
ï£°
nÏ„ 2
Ïƒ2
0
Z âˆ’ 1 + nÏ„02 log 1 + Ïƒ20 + Z 2
Î¦ âˆšÏƒnÏ„
0
0

0

ï£¹
ï£º
ï£º
ï£»

which is notably independent of the prior mean Âµ0 . The dominated convergence
theorem implies EÎ  (M (RB(Âµ | X) â‰¤ 1 | Âµ)) â†’ 0 as n â†’ âˆ or as Ï„02 â†’ âˆ. So
provided nÏ„02 /Ïƒ02 is large enough, there is no estimation bias against. Table 3
illustrates some values of this bias measure. Subtracting the probabilities in
Table 3 from 1 gives the prior probability that the plausible region covers the
true value and the expected posterior content of the plausible region. So when
n = 20, Ï„0 = 1, the prior probability of the plausible region containing the true
value is 1 âˆ’ 0.051 = 0.949 so P l(x) is a 0.949 Bayesian confidence interval for Âµ.
To use (9) it is necessary to maximize M (RB(Âµ | X) â‰¤ 1 | Âµ) as a function
of Âµ and it is seen that, at least when the prior is not overly concentrated, that
this maximum occurs at Âµ0 . Figure 1 shows that when using the N (0, 1) prior
the maximum occurs at Âµ = 0 when n = 5 and from the second column of Table
1, the maximum equals 0.143. The average bias against is given by 0.107, as
recorded in Table 3. Note that the maximum also occurs at Âµ = 0 for the other
values of n recorded in Table 1.
10

2.2.2

Bias in Favor

Bias in favor occurs when the prior probability that ImÎ¨ does not cover a false
value is large, namely, when
Z Z
M (Ïˆâˆ— âˆˆ
/ ImÎ¨ (X) | Ïˆ) Î Î¨ (dÏˆ) Î Î¨ (dÏˆâˆ— )
Î¨ Î¨\{Ïˆâˆ— }
Z Z
M (RBÎ¨ (Ïˆâˆ— | X) â‰¥ 1 | Ïˆ) Î Î¨ (dÏˆ) Î Î¨ (dÏˆâˆ— )
(10)
=
Î¨

Î¨\{Ïˆâˆ— }

is large as this would seem to imply that the plausible region will cover a randomly selected false value from the prior with high prior probability.R Note that
/
(10) is the prior mean of (4) and in the continuous case equals Î¨ M (Ïˆâˆ— âˆˆ
ImÎ¨ (X)) Î Î¨ (dÏˆâˆ— ). As previously discussed, however, it often doesnâ€™t make
sense to distinguish values of Ïˆ that are close to Ïˆâˆ— . The bias in favor for estimation can then be measured by
!
sup

EÎ Î¨

Ïˆ:dÎ¨ (Ïˆ,Ïˆâˆ— )â‰¥Î´

M (Ïˆâˆ— âˆˆ
/ ImÎ¨ (X) | Ïˆ)

sup

= EÎ Î¨

Ïˆ:dÎ¨ (Ïˆ,Ïˆâˆ— )â‰¥Î´

!

M (RBÎ¨ (Ïˆâˆ— | X) â‰¥ 1 | Ïˆ) .

(11)

An upper bound on (11) is commonly equal to 1 as illustrated in Figure 3 and
so is not useful.
It is the size and posterior content of P lÎ¨ (x) that provides a measure of
the accuracy of the estimate Ïˆ(x). As discussed in Section 2.2.1 the a priori
expected posterior content of P lÎ¨ (x) can be controlled by bias against. The a
priori expected volume of P lÎ¨ (x) satisfies
Z Z
M (Ïˆâˆ— âˆˆ P lÎ¨ (X) | Ïˆ) Î Î¨ (dÏˆ) V ol(dÏˆâˆ— ).
(12)
EM (V ol(P lÎ¨ (X))) =
Î¨

Î¨

Notice that when Î Î¨ ({Ïˆ}) = 0 for every Ïˆ, this can be interpreted as a kind of
average of the prior probabilities of the plausible region covering a false value.
Example 1. Location normal (continued).
It follows from (7) that
sup M (RB(Âµâˆ— | X) â‰¥ 1 | Âµâˆ— Â± Î´)
 

Î¦ c(Âµâˆ— , Âµâˆ— Â± Î´, Âµ0 , Ï„02 , Ïƒ02 , n) + b(Âµâˆ— , Âµ0 , Ï„02 , Ïƒ02 , n) âˆ’
= sup
Î¦ c(Âµâˆ— , Âµâˆ— Â± Î´, Âµ0 , Ï„02 , Ïƒ02 , n) âˆ’ b(Âµâˆ— , Âµ0 , Ï„02 , Ïƒ02 , n)

Note that as Âµâˆ— â†’ Â±âˆ, then M (RB(Âµâˆ— | X) â‰¥ 1 | Âµâˆ— Â±Î´) â†’ 1 when nÏ„02 /Ïƒ02 > 1,
see Figure 3, and converges to 0 if nÏ„02 /Ïƒ02 < 1, so it would appear that the better
circumstance for guarding against bias in favor is when the prior is putting in
more information than the data. As previously noted, however, this is a situation
where we might expect prior data-conflict to arise and, except in exceptional
11

1.0
0.9
0.8
0.7

bias in favor

0.6
0.5
0.4
âˆ’10

âˆ’5

0

5

10

Âµ*

Figure 3: Bias in favor of Âµ maximized over Âµ Â± Î´ based on a N (0, 1) prior and
Ïƒ0 = 1, n = 20, Î´ = 0.5.

n
5
10
20
50
100

(Âµ0 , Ï„0 ) = (0, 1), Î´ = 1.0
0.451
0.185
0.025
0.000
0.000

(Âµ0 , Ï„0 ) = (0, 1), Î´ = 0.5
0.798
0.690
0.486
0.131
0.009

Table 4: Average bias in favor for estimation based on (11) when using a N (0, Ï„02 )
prior for different sample sizes n and difference Î´.

12

n
5
10
20
50
100

Ï„0 = 1
0.625 (0.893)
0.499 (0.925)
0.393 (0.949)
0.281 (0.969)
0.215 (0.979 )

Ï„0 = 0.5
0.491 (0.807)
0.389 (0.854)
0.312 (0.893)
0.231 (0.933)
0.181 (0.954)

Table 5: Expected half-widths (coverages) of the plausible interval when using
aN (Âµ0 , Ï„02 ) prior for different sample sizes n.
circumstances should be avoided. Table 4 contains values of (7) for this situation
with different values of Î´.
Some elementary calculations give P l(x) = xÌ„ Â± w(xÌ„, n, Ïƒ02 , Âµ0 , Ï„02 ) with
w(xÌ„, n, Ïƒ02 , Âµ0 , Ï„02 )

2 )1/2
âˆ’1/2 (


 
nÏ„02
nÏ„02
nÏ„02
xÌ„ âˆ’ Âµ0
Ïƒ0
âˆš
1+ 2
1 + 2 log 1 + 2 +
=âˆš
n
Ïƒ0
Ïƒ0
Ïƒ0
Ïƒ0 / n
âˆš
where z = n(xÌ„ âˆ’ Âµ0 )/Ïƒ0 âˆ¼ N (0, 1) under M. It is notable that the prior
distribution of the width is independent of the prior mean. Table 5 contains
some expected half-widths together with the coverage probabilities of P l(x).

3

Frequentist and Optimal Properties

Consider now the bias against H0 = {Ïˆâˆ— }, namely, M (RBÎ¨ (Ïˆâˆ— | X) â‰¤ 1 | Ïˆâˆ— ). If
we repeatedly generate Î¸ âˆ¼ Ï€(Â· | Ïˆâˆ— ), X âˆ¼ fÎ¸ , then this probability is the longrun proportion of times that RBÎ¨ (Ïˆâˆ— | X) â‰¤ 1. This frequentist interpretation
depends on the conditional prior Ï€(Â· | Ïˆâˆ— ) and when Î¨(Î¸) = Î¸, so there are no nuisance parameters, this is a â€pureâ€ frequentist probability. Even in the latter case
there is some dependence on the prior, however, as RB(Î¸âˆ— | x) R= fÎ¸âˆ— (x)/m(x)
so x satisfies RBÎ¨ (Î¸âˆ— | x) â‰¤ 1 iff fÎ¸âˆ— (x) â‰¤ m(x) where m(x) = Î˜ fÎ¸ (x) Î (dÎ¸).
So in general the region {x : RBÎ¨ (Ïˆâˆ— | x) â‰¤ 1} depends on Ï€ but the probability
M (RBÎ¨ (Ïˆâˆ— | X) â‰¤ 1 | Ïˆâˆ— ) dependsRonly on the conditional prior predictive given
Î¨(Î¸) = Ïˆâˆ— , namely, m(x | Ïˆâˆ— ) = Î˜ fÎ¸ (x) Î (dÎ¸ | Ïˆâˆ— ), and not on the marginal
prior Ï€Î¨ on Ïˆ. We refer to probabilities that depend only on M (Â· | Ïˆâˆ— ) as frequentist, for example, coverage probabilities are called confidences, and those
that depend on the full prior Ï€ as Bayesian confidences. The frequentist label is
similar to use of the confidence terminology when dealing with random effects
models as nuisance parameters have been integrated out.
Suppose now that some other general rule, not necessarily the principle of
evidence, is used to determine whether there is evidence for or against Ïˆâˆ— and
this leads to the set D(Ïˆâˆ— ) âŠ‚ X as those data sets that do not give evidence in
favor of H0 = {Ïˆâˆ— }. The rules of potential interest will satisfy M (D(Ïˆâˆ— ) | Ïˆâˆ— ) â‰¤
M (RBÎ¨ (Ïˆâˆ— | X) â‰¤ 1 | Ïˆâˆ— ) since this implies better performance a priori in terms
13

of identifying when data has evidence in favor of H0 via the set Dc (Ïˆâˆ— ) than
the principal of evidence. For example, D(Ïˆâˆ— ) = {x : RBÎ¨ (Ïˆâˆ— | x) â‰¤ q} for some
q < 1 satisfies this but note that a value satisfying q < RBÎ¨ (Ïˆâˆ— | x) â‰¤ 1 violates
the principle of evidence if it is claimed there is evidence in favor of Ïˆâˆ— . Putting
R(Ïˆâˆ— ) = {x : RBÎ¨ (Ïˆâˆ— | x) â‰¤ 1} leads to the following result.
Theorem 1. (i) The prior probability M (D(Ïˆâˆ— )) is maximized among all
D(Ïˆâˆ— ) âŠ‚ X satisfying M (D(Ïˆâˆ— ) | Ïˆâˆ— ) â‰¤ M (R(Ïˆâˆ— ) | Ïˆâˆ— ) by D(Ïˆâˆ— ) = R(Ïˆâˆ— ). (ii)
If Î Î¨ ({Ïˆâˆ— }) = 0, then R(Ïˆâˆ— ) maximizes the prior probability of not obtaining
evidence in favor of Ïˆâˆ— when it is false and otherwise maximizes this probability
among all rules satisfying M (D(Ïˆâˆ— ) | Ïˆâˆ— ) = M (R(Ïˆâˆ— ) | Ïˆâˆ— ).
When Î Î¨ ({Ïˆâˆ— }) 6= 0, rules may exist having greater prior probability of not
getting evidence in favor of Ïˆâˆ— when it is false but the price paid for this is the
violation of the principle of evidence. Also, when comparing rules based on their
ability to distinguish falsity it only seems fair that the rules perform the same
under the truth. So Theorem 1 is a general optimality result for the principle
of evidence applied to hypothesis assessment when considering bias against.
Now consider C(x) = {Ïˆ : x âˆˆ
/ D(Ïˆ)} which is the set of Ïˆ values for
which there is evidence in their favor after observing x according to some
alternative evidence rule. Since M (Ïˆâˆ— âˆˆ
/ C(X) | Ïˆ) = M (D(Ïˆâˆ— )) | Ïˆ), then
/ C(X) | Ïˆ)) = 1âˆ’EÎ Î¨ (M (D(Ïˆ) | Ïˆ))
EÎ Î¨ (M (Ïˆ âˆˆ C(X) ) | Ïˆ)) = 1âˆ’EÎ Î¨ (M (Ïˆ âˆˆ
â‰¥ 1 âˆ’ EÎ Î¨ (M (R(Ïˆ) | Ïˆ)) = EÎ Î¨ (M (Ïˆ âˆˆ P lÎ¨ (X) ) | Ïˆ)) and so the Bayesian
coverage of C is at least as large as that of P lÎ¨ and so represents a viable
alternative to using P lÎ¨ .
The following establishes an optimality result for P lÎ¨ .
Theorem 2. (i) The prior probability that the region C doesnâ€™t cover a value Ïˆâˆ—
/ C(X))), is maximized among
generated from the prior, namely, EÎ Î¨ (M (Ïˆâˆ— âˆˆ
all regions satisfying M (Ïˆâˆ— âˆˆ
/ C(X) | Ïˆâˆ— ) â‰¤ M (Ïˆâˆ— âˆˆ
/ P lÎ¨ (X) | Ïˆâˆ— ) for every
Ïˆâˆ— , by C = P lÎ¨ . (ii) If Î Î¨ ({Ïˆâˆ— }) = 0 for all Ïˆâˆ— , then P lÎ¨ maximizes the prior
probability of not covering a false value and otherwise maximizes this probability
among all C satisfying M (Ïˆâˆ— âˆˆ
/ C(X) | Ïˆâˆ— ) = M (Ïˆâˆ— âˆˆ
/ P lÎ¨ (X) | Ïˆâˆ— ) for all Ïˆâˆ— .
Again when Î Î¨ ({Ïˆâˆ— }) 6= 0 the existence of a region with better properties
with respect to not covering false values than P lÎ¨ canâ€™t be ruled out but, when
considering such a property, it seems only fair to compare regions with the same
coverage probability and in that case P lÎ¨ is optimal. So Theorem 2 is also a
general optimality result for the principle of evidence applied to estimation
when considering bias against. Also, if there is a value Ïˆ0 = arg inf Ïˆ M (Ïˆ âˆˆ
P lÎ¨ (X) ) | Ïˆ), then Î³0 = M (Ïˆ0 âˆˆ P lÎ¨ (X) ) | Ïˆ0 ) serves as a lower bound on
the coverage probabilities, and thus P lÎ¨ is a Î³0 -confidence region for Ïˆ and
this is a pure frequentist Î³0 -confidence region when Î¨(Î¸) = Î¸. Since M (Ïˆ âˆˆ
P lÎ¨ (X) ) | Ïˆ) = 1 âˆ’ M (Ïˆ âˆˆ
/ P lÎ¨ (X) ) | Ïˆ) = 1 âˆ’ M (R(Ïˆâˆ— ) | Ïˆ), then Example 1
shows that it is reasonable to expect that such a Ïˆ0 exists.
The principle of evidence leads to the following satisfying properties which
connect the concept of bias as discussed here with the frequentist concept..
Theorem 3. (i) Using the principle of evidence, the prior probability of getting
evidence in favor of Ïˆâˆ— when it is true is greater than or equal to the prior
14

probability of getting evidence in favor of Ïˆâˆ— given that Ïˆâˆ— is false. (ii) The
prior probability of P lÎ¨ covering the true value is always greater than or equal
to the prior probability of P lÎ¨ covering a false value.
The properties stated in Theorem 3 are similar to a property called unbiasedness
for frequentist procedures. For example, a test is unbiased if the probability
of rejecting a null is always larger when it is false than when it is true and
a confidence region is unbiased if the probability of covering the true value
is always greater than the probability of covering a false value. While the
inferences discussed here are â€unbiasedâ€ in this generalized sense, they could
still be biased against or in favor in the practical sense of this paper, as it is the
amount of data that controls this.
Now consider bias in favor and suppose there is an alternative characterization of evidence that leads to the region E(Ïˆâˆ— ) consisting of all data sets that
do not lead to evidence against Ïˆâˆ— . Putting A(Ïˆâˆ— ) = {x : RBÎ¨ (Ïˆâˆ— | x) â‰¥ 1, we
restrict attention to regions satisfying M (E(Ïˆâˆ— ) | Ïˆâˆ— ) â‰¥ M (A(Ïˆâˆ— ) | Ïˆâˆ— ). Using
(4) to measure bias in leads to the following results.
Theorem 4. (i) The prior probability M (E(Ïˆâˆ— )) is minimized among all
E(Ïˆâˆ— ) âŠ‚ X satisfying M (E(Ïˆâˆ— ) | Ïˆâˆ— ) â‰¥ M (A(Ïˆâˆ— ) | Ïˆâˆ— ) by E(Ïˆâˆ— ) = A(Ïˆâˆ— ). (ii) If
Î Î¨ ({Ïˆâˆ— }) = 0, then the set A(Ïˆâˆ— ) minimizes the prior probability of not obtaining evidence against Ïˆâˆ— when it is false and otherwise minimizes this probability
among all rules satisfying M (E(Ïˆâˆ— ) | Ïˆâˆ— ) = M (A(Ïˆâˆ— ) | Ïˆâˆ— ).

Theorem 5. (i) The prior probability region C covers a value Ïˆâˆ— generated
from the prior, namely, EÎ Î¨ (M (Ïˆâˆ— âˆˆ C(X))), is minimized among all regions
satisfying M (Ïˆâˆ— âˆˆ C(X) | Ïˆâˆ— ) â‰¥ M (Ïˆâˆ— âˆˆ P lÎ¨ (X) | Ïˆâˆ— ) for every Ïˆâˆ— , by C =
P lÎ¨ . (ii) If Î Î¨ ({Ïˆâˆ— }) = 0 for all Ïˆâˆ— , then P lÎ¨ minimizes the prior probability of
covering a false value and otherwise minimizes this probability among all rules
satisfying M (Ïˆâˆ— âˆˆ C(X) | Ïˆâˆ— ) = M (Ïˆâˆ— âˆˆ P lÎ¨ (X) | Ïˆâˆ— ) for all Ïˆâˆ— .
So Theorems 4 and 5 are optimality results for the principle of evidence when
considering bias in favor.
Clearly the bias against H0 is playing a role similar to size in frequentist
statistics and the bias in favor is playing a role similar to power. A study that
found evidence against H0 , but had a high bias against, or a study that found
evidence in favor of H0 but had a high bias in favor, could not be considered to
be of high quality. Similarly, a study concerned with estimating a quantity of
interest could not be considered of high quality if there is high bias against or
in favor. There are some circumstances, however, where some bias is perhaps
not an issue. For example, in a situation where sparsity is to be expected,
then allowing for high bias in favor of certain hypotheses accompanied by low
bias against, may be tolerable although this does reduce the reliability of any
hypotheses where evidence is found in favor.

4

Examples

A number of examples are now considered.

15

Example 2. Binomial.
Suppose x = (x1 , . . . , xn ) is a sample from the Bernoulli(Î¸) with Î¸ âˆˆ [0, 1]
unknown so nxÌ„ âˆ¼ binomial(n, Î¸) and interest is in Î¸. For the prior let Î¸ âˆ¼
beta(Î±0 , Î²0 ) where the hyperparameters are elicited as in, for example, Evans,
Guttman and Li (2017), so Î¸ | nxÌ„ âˆ¼ beta(Î±0 + nxÌ„, Î²0 + n(1 âˆ’ xÌ„)). Then
RB(Î¸ | nxÌ„) =

Î“(Î±0 + Î²0 + n)
Î“(Î±0 )Î“(Î²0 ) nxÌ„
Î¸ (1 âˆ’ Î¸)n(1âˆ’xÌ„)
Î“(Î±0 + nxÌ„)Î“(Î²0 + n(1 âˆ’ xÌ„)) Î“(Î±0 + Î²0 )

is unimodal with mode at xÌ„, so P l(x) is an interval containing xÌ„. Note that
M (Â· | Î¸) is the binomial(n, Î¸) probability measure and the bias against Î¸ is given
by M (RB(Î¸ | nxÌ„) â‰¤ 1 | Î¸) while the bias in favor of Î¸, using (5), is given by
max M (RB(Î¸ | nxÌ„) â‰¥ 1 | Î¸ Â± Î´)for Î¸ âˆˆ [Î´, 1 âˆ’ Î´].
Consider first the prior given by (Î±0 , Î²0 ) = (1, 1). Figure 4 gives the plots of
the bias against for n = 10 (max. = 0.21, average = 0.11), n = 50 (max.= 0.07,
average = 0.05) and n = 100 (max. = 0.05, average = 0.03). Therefore, when
n = 10, then P l(x) is a 0.79-confidence interval for Î¸, when n = 50 it is a 0.93confidence interval for Î¸ and when n = 100 it is a 0.95-confidence interval for Î¸.
For the informative prior given by (Î±0 , Î²0 ) = (5, 5), Figure 5 gives the plots of
the bias against for n = 10 (max. = 0.36, average = 0.21), n = 50 (max. = 0.16,
average = 0.10) and n = 100 (max. = 0.11, average = 0.07). So when n = 10
then P l(x) is a 0.64-confidence interval for Î¸, when n = 50 it is a 0.84-confidence
interval for Î¸ and when n = 100 it is a 0.93-confidence interval for Î¸. One feature
immediately stands out, namely, when using a more informative prior the bias
against increases. As previously explained this phenomenon occurs because
when the prior probability of Î¸ is small, it is much easier to obtain evidence in
favor than when the prior probability of Î¸ is large.
Now consider bias in favor using (11). When (Î±0 , Î²0 ) = (1, 1) and Î´ = 0.1,
Figure 6 gives the plots of the bias in favor with Î´ = 0.1 for n = 10 (max. =
1.00, average = 0.84), n = 50 (max. = 0.72, average = 0.51) and n = 100 (max.
= 0.50, average = 0.35). Therefore, when n = 10 the maximum probability that
P l(x) contains a false value at least Î´ away from the true value is 1, when n = 50
this probability is 0.72 and when n = 100 it is a 0.50. When (Î±0 , Î²0 ) = (5, 5)
Figure 7 gives the plots of the bias in favor for n = 10 (max. = 1.00, average =
0.68), for n = 50 (max. = 1.00, average = 0.71) and for n = 100 (max. = 1.00,
average = 0.49). So in this case the maximum probability that P l(x) contains
a false value at least Î´ away from the true value is always 1, but when averaged
with respect to the prior the values are considerably less. It is necessary to either
increase n or Î´ to decrease bias in favor. For example, with (Î±0 , Î²0 ) = (5, 5),
Î´ = 0.1 and n = 400 the maximum bias in favor is 0.02 and the average bias in
favor is 0.02 and when n = 600 these quantities equal 0 to two decimals. When
Î´ = 0.2 and n = 50 the maximum bias in favor is 0.29 and the average bias
in favor is 0.11 and when n = 100 the maximum bias in favor is 0.01 and the
average bias in favor is 0.01.
Example 3. Location-scale normal - quantiles.
Suppose x = (x1 , . . . , xn ) is a sample from N (Âµ, Ïƒ 2 ) with (Âµ, Ïƒ 2 ) âˆˆ R1 Ã—
(0, âˆ) unknown with prior Âµ | Ïƒ 2 âˆ¼ N (Âµ0 , Ï„02 Ïƒ 2 ), Ïƒ âˆ’2 âˆ¼ gammarate (Î±0 , Î²0 ). The
16

0.04

0.07
0.06

0.20

0.03
bias against

0.01

0.02

0.01

0.03

0.02

0.04

bias against

0.05

0.15
bias against

0.10
0.05
0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

Î¸

0.6

0.8

1.0

0.0

0.2

Î¸

0.4

0.6

0.8

1.0

Î¸

0.06

bias against

bias against

0.20
0.00

0.00

0.00

0.05

0.02

0.10

0.05

0.04

0.15

bias against

0.10

0.25

0.08

0.30

0.10

0.15

0.35

Figure 4: Plots of bias against as a function of Î¸ for n = 10, 50 and 100 when
using beta(1, 1) prior.

0.0

0.2

0.4

0.6
Î¸

0.8

1.0

0.0

0.2

0.4

0.6
Î¸

0.8

1.0

0.0

0.2

0.4

0.6

0.8

1.0

Î¸

Figure 5: Plots of bias against as a function of Î¸ for n = 10, 50 and 100 when
using beta(5, 5) prior.

17

0.70

0.50

1.00

0.65

0.45

0.95

0.40

0.55

bias in favor

0.60

bias in favor

0.90
0.85

bias in favor

0.50

0.35

0.80

0.45

0.30

0.75
0.2

0.4

0.6

0.8

0.2

0.4

Î¸

0.6

0.8

0.2

0.4

Î¸

0.6

0.8

Î¸

0.7

bias in favor

0.6

bias in favor

0.6

0.4

0.6

0.5

0.7

0.7

0.8

bias in favor

0.8

0.8

0.9

0.9

0.9

1.0

1.0

1.0

Figure 6: Plots of bias in favor as a function of Î¸ for n = 10, 50 and 100 when
using beta(1, 1) prior with Î´ = 0.1.

0.2

0.4

0.6
Î¸

0.8

0.2

0.4

0.6
Î¸

0.8

0.2

0.4

0.6

0.8

Î¸

Figure 7: Plots of bias in favor as a function of Î¸ for n = 10, 50 and 100 when
using beta(5, 5) prior with Î´ = 0.1.

18

hyperparameters (Âµ0 , Ï„02 , Î±0 , Î²0 ) can be obtained via an elicitation as, for example, discussed in Evans and Tomal (2018) for the more general regression
model. This example is easily generalized to the regression context. A MSS is
T (x) = (xÌ„, ||x âˆ’ xÌ„1||2 ) with the posterior distribution given by Âµ | Ïƒ 2 , T (x) âˆ¼
âˆ’1 2 âˆ’2
Ïƒ ), Ïƒ | T (x) âˆ¼ gammarate (Î±0 + n/2, Î²0x ) where Âµ0x =
N (Âµ0x , n + 1/Ï„02
(n + 1/Ï„02 )âˆ’1 (nxÌ„ + Âµ0 /Ï„02 ) and Î²0x = Î²0 + ||x âˆ’ xÌ„1||2 /2 + n(xÌ„ âˆ’ Âµ0 )2 /2(nÏ„02 + 1).
Suppose interest is in the Î³-th quantile Ïˆ = Î¨(Âµ, Ïƒ 2 ) = Âµ + ÏƒzÎ³ , where zÎ³ =
âˆ’1
Î¦ (Î³). To determine the bias for or against Ïˆ we need the prior and posterior
of Ïˆ which in this case cannot be worked out in closed form. It is easy, however,
to work with the discretized Ïˆ by simply generating from the prior and posterior
of (Âµ, Ïƒ 2 ), estimate the contents of the relevant intervals and then approximate
the relative belief ratio using these. A natural approach to the discretization
1/2
is to base it on the prior mean E(Ïˆ) = Âµ0 + Î²0 (Î“(Î±0 âˆ’ 1/2)/Î“(Î±0 ))zÎ³ and
2
2
variance V ar(Ïˆ) = E(Ïˆ ) âˆ’ (E(Ïˆ)) where E(Ïˆ 2 ) = (zÎ³2 + Ï„02 )Î²0 /(Î±0 âˆ’ 1). So
for a given Î´, we discretize using 2k + 1 intervals (E(Ïˆ) + iÎ´, E(Ïˆ) + (i + 1)Î´]
where k = cSD(Ïˆ)/Î´ and c is chosen so that the collection of intervals covers
the effective support of Ïˆ which is easily assessed as part of the simulation. For
example, with the prior given by hyperparameters Âµ0 = 0, Ï„02 = 1, Î±0 = 2, Î²0 = 1
and Î³ = 0.5, Î´ = 0.1, c = 5, then k = 50 and, on generating 105 values from
the prior, these intervals contained 99, 699 of the values and with c = 6, then
k = 60 and these intervals contained 99, 901 of the generated values. Similar
results are obtained for more extreme quantiles and this is because the intervals
shift with the quantile.
For the bias against for estimation the value of M (RBÎ¨ (Ïˆ | X) â‰¤ 1 | Ïˆ)
is needed for a range of Ïˆ values. For this we need to generate from the
conditional prior distribution of T given Î¨(Âµ, Ïƒ 2 ) = Ïˆ and an algorithm for
generating from the conditional prior of (Âµ, Ïƒ 2 ) given Ïˆ is needed. Putting
Î½ = 1/Ïƒ 2 , the transformation (Âµ, Î½) â†’ (Ïˆ, Î½) = (Âµ + Î½ âˆ’1/2 zÎ³ , Î½) has Jacobian
equal to 1, so the conditional prior distribution of Î½ | Ïˆ has density proportional
2
to Î½ Î±0 âˆ’1/2 exp{âˆ’Î²0 Î½} exp{âˆ’Î½ Ïˆ âˆ’ Âµ0 âˆ’ Î½ âˆ’1/2 zÎ³ /2Ï„02 }. The following gives a
rejection algorithm for generating from this distribution:

1. generate Î½ âˆ¼ gamma(Î±0 + 1/2, Î²0 ), 2. generate u âˆ¼ unif(0, 1) independent
2
of Î½, 3. if u â‰¤ exp{âˆ’Î½ Ïˆ âˆ’ Âµ0 âˆ’ Î½ âˆ’1/2 zÎ³ /2Ï„02 } return Î½, else go to 1.
As Ïˆ moves away from the prior expected value E(Ïˆ) this algorithm becomes
less efficient but even when the expected number of iterations is 86 (when Î³ =
0.95, Ïˆ = 12), generating a sample of 104 is almost instantaneous. Figure 8 is
a plot of the conditional prior of Î½ given that Ïˆ = 2. After generating Î½ then
generate ||x âˆ’ xÌ„1||2 âˆ¼ Î½ âˆ’1 chi-squared(n âˆ’ 1) and xÌ„ âˆ¼ N (Ïˆ âˆ’ Î½ âˆ’1/2 zÎ³ , Î½ âˆ’1 /n)
to complete the generation of a value from MT (Â· | Ïˆ).
The bias against as a function of Ïˆ = Âµ + Ïƒz0.95 , has maximum value 0.151
when n = 10 and so P lÎ¨ (x) is a 0.849-confidence region for Ïˆ while the average
bias against is 0.104 so the Bayesian coverage is 0.896. Table 6 gives the coverages
for other values of n as well. Figure 9 is a plot of the bias in favor as a function
of Ïˆ with Î´ = Â±0.5 and n = 10. The average bias in favor is 0.629304. When
19

0.005
0.004
0.003

conditional prior density

0.002
0.001
0.000
0

2

4

6

8

10

Î½

Figure 8: Conditional prior density of Î½ = 1/Ïƒ 2 given Ïˆ = 2 when Î³ = 0.95 and
Âµ0 = 0, Ï„02 = 1, Î±0 = 2, Î²0 = 1.
n
10
20
50
100

Frequentist coverage
0.849
0.895
0.934
0.955

Bayesian coverage
0.896
0.927
0.958
0.973

Table 6: Coverage probabilities for P lÏˆ (x) for the 0.95 quantile in Example 2.
n = 50 the average bias in favor is 0.3348178.
The case Î³ = 0.50, so Ïˆ = Î¨(Âµ, Ïƒ 2 ) = Âµ, is also of interest. For n = 10
then P lÎ¨ (x) has 0.878 frequentist coverage and 0.926 Bayesian coverage, when
n = 20 the coverages are 0.916 and 0.952 while when n = 50 the coverages are
0.950 and 0.973. When n = 10, Î´ = 0.5 the average bias in favor is 0.619, when
n = 20 this is 0.4206 and for n = 100 the average bias in favor is 0.091.
Example 4. Normal Regression - prediction.
Prediction problems have some unique aspects when compared to inferences
about parameters. To see this consider first the location normal model of Example 1 and suppose the problem is to make inference about a future value
y âˆ¼ N (Âµ, Ïƒ02 ). The prior predictive distribution is y âˆ¼ N (Âµ0 , Ï„02 + Ïƒ02 ) and the
posterior predictive is y âˆ¼ N (Âµx , Ïƒn2 + Ïƒ02 ) where Âµx = Ïƒn2 (nxÌ„/Ïƒ02 + Âµ0 /Ï„02 ), Ïƒn2 =
âˆ’1
and so
n/Ïƒ02 + 1/Ï„02
RB(y | xÌ„) =



Ï„02 + Ïƒ02
Ïƒn2 + Ïƒ02

1/2




(y âˆ’ Âµ0 )2
1 (y âˆ’ Âµx )2
.
âˆ’ 2
exp âˆ’
2 Ïƒn2 + Ïƒ02
Ï„0 + Ïƒ02

For a given y the bias against is given by M (RB(y | xÌ„) â‰¤ 1 | y) and for this
we need the conditional prior predictive of xÌ„ | y. The joint prior predictive is
20

1.0
0.9
0.8
0.7

bias in favor

0.6
0.5

0

2

4

6

8

Ïˆ

Figure 9: The bias in favor as a function of Ïˆ when n = 10, Î´ = 0.5 and using
a prior with hyperparameters Âµ0 = 0, Ï„02 = 1, Î±0 = 2, Î²0 = 1.

(xÌ„, y) âˆ¼ N2 (Âµ0 12 , Î£0 ) where
Î£0 =



Ï„02 + Ïƒ02 /n
Ï„02
2
2
Ï„0
Ï„0 + Ïƒ02




and so xÌ„ | y âˆ¼ N (Âµ0 + Ï„02 (y âˆ’ Âµ0 )/(Ï„02 + Ïƒ02 ), Ïƒ02 Ï„02 /(Ï„02 + Ïƒ02 ) + 1/n ). From this
we see that, as n â†’ âˆ the conditional prior distribution
of Âµx | y converges

to the N Âµ0 + Ï„02 (y âˆ’ Âµ0 )/(Ï„02 + Ïƒ02 ), Ïƒ02 Ï„02 /(Ï„02 + Ïƒ02 ) distribution. Then with
Z âˆ¼ N (0, 1) and r = Ï„02 /Ïƒ02 , putting d((y âˆ’ Âµ0 )/Ïƒ0 , r) = (1 + 1/r) log (1 + r) +
râˆ’1 (y âˆ’ Âµ0 )2 /Ïƒ02
 ï£¹ï£¶
ï£«
ï£®

âˆ’1/2 yâˆ’Âµ0
Â±
râˆ’1/2 (1 + r)

Ïƒ0
ï£»ï£¸
M (RB(y | xÌ„) â‰¤ 1 | y) â†’ 1 âˆ’ P ï£­Z âˆˆ ï£°
1/2 yâˆ’Âµ0
d
Ïƒ0 , r
as n â†’ âˆ. So the bias against does not go to 0 as n â†’ âˆ and there is a
limiting lower bound to the prior probability that evidence in favor of a specific
y will not be obtained. This baseline is dependent on both (y âˆ’ Âµ0 )/Ïƒ0 and r.
As r = Ï„02 /Ïƒ02 â†’ âˆ this baseline bias against goes to 0 and so it is necessary
to ensure that the prior variance is not too small. Table (7) gives some values
for the bias against and it is seen that if Ï„02 /Ïƒ02 is too small, then there is
substantial bias against even when y is a reasonable value from the distribution.
When Ï„02 /Ïƒ02 = 1, (y âˆ’ Âµ0 )/Ïƒ0 = 0 and n = 10 the bias against is computed to
be 0.248 which is quite close to the baseline so increasing sample size will not
reduce bias against by much and similar results are obtained for the other cases.
Now consider bias in favor of y, namely, M (RB(y | xÌ„) â‰¥ 1 | y Â± Î´) for some
choice of Î´. False values for y correspond to values in the tails so we consider,
21

0
bias against yâˆ’Âµ
Ïƒ0 = 0
0.239
0.104
0.031
0.270
0.316

Ï„02 /Ïƒ02
1
10
100
1/2
1/100

0
bias against yâˆ’Âµ
Ïƒ0 = 1
0.213
0.100
0.031
0.263
0.460

0.6
0.4
0.0

0.2

baseline bias in favor

0.8

1.0

Table 7: Baseline bias against values for prediiction for location normal in Example 4.

âˆ’10

âˆ’5

0

5

10

std y

Figure 10: Plot of the baseline bias in favor for values of (y âˆ’ Âµ0 )/Ïƒ0 when
Ï„02 /Ïƒ02 = 1 when Î´ = 5.

for example, y + Î´ as a value in the central region of the prior and then a large
value of Î´ puts y in the tails. Again the bias in favor has a baseline value as
n â†’ âˆ. A similar argument leads to the bias in favor of y satisfying
M (RB(y | xÌ„) â‰¥ 1 | y Â± Î´)






y âˆ’ Âµ0
Î´
y âˆ’ Âµ0
âˆ’1/2
Â± d1/2
Â±r
,r
.
â†’ P Z âˆˆ râˆ’1/2 (1 + r)
Ïƒ0
Ïƒ0
Ïƒ0
Figure 10 is a plot of sup M (RB(y | xÌ„) â‰¥ 1 | y Â± Î´). So the bias in favor is
reasonably low for central values of y but it is to be noted that once again there
is a trade-off as when Ï„ increases the bias in favor goes to 1.
Prediction plays a bigger role in regression problems but we can expect the
same issues to apply as in the location problem. Suppose y âˆ¼ Nn (XÎ², Ïƒ 2 I)
where X âˆˆ RnÃ—k is of rank k, (Î², Ïƒ 2 ) âˆˆ Rk Ã— (0, âˆ) is unknown, our interest is in predicting a future value ynew âˆ¼ N (wt Î², Ïƒ 2 ) for some fixed known
w and, putting Î½ = 1/Ïƒ 2 , the conjugate prior Î² | Î½ âˆ¼ Nk (Î²0 , Î½ âˆ’1 Î£0 ) , Î½ âˆ¼
22

gammarate (Î±0 , Î·0 ) is used. Specifying the hyperparameters (Î²0 , Î£0 , Î±0 , Î·0 ) can
be carried out using an elicitation algorithm such as that discussed in Evans
and Tomal (2018).
For the bias calculations it is necessary to generate values of the MSS
(b, s2 ) = ((X t X)âˆ’1 X t y, ||yâˆ’Xb||2) from the conditional prior predictive M (Â· | ynew ).
This is accomplished by generating from the conditional prior of (Î², Î½) | ynew
and then generating b âˆ¼ Nk (Î², Î½ âˆ’1 (X t X)âˆ’1 ) independent of s2 âˆ¼ Î½ âˆ’1 chisquared(n âˆ’ k). The conditional prior of (Î², Î½) | ynew is proportional to
Î½ Î±0 âˆ’1/2 exp{âˆ’Î·0 (ynew )Î½}Ã—


t


Î½
âˆ’1
âˆ’1
âˆ’1
t
t âˆ’1
k/2
Î£0 + ww (Â·)
Î² âˆ’ Î£0 + ww
(Î£0 Î²0 + ynew w)
Î½
exp âˆ’
2


t âˆ’1
where, using Î£âˆ’1
= Î£0 âˆ’ (1 + wt Î£0 w)âˆ’1 Î£0 wwt Î£0 , Î·0 (ynew ) = Î·0 +
0 + ww
t
âˆ’1
t
2
(1 + w Î£0 w) (w Î² âˆ’ ynew ) /2. So generating (Î², Î½) | ynew is accomplished via
Î½ âˆ¼ gammarate (Î±0 + 1/2, Î·0 (ynew )),




Î£0 wwt
Î£0 wwt Î£0
âˆ’1
Iâˆ’
Î² | Î½ âˆ¼ Nk
Î£0 âˆ’
(Î²0 + ynew Î£0 w), Î½
.
1 + w t Î£0 w
1 + w t Î£0 w
For each generated (b, s2 ) it is necessary to compute the relative belief ratio
RB(ynew | b, s2 ) and determine if it is less than or equal to 1. There are closed
forms for the prior and conditional densities of ynew since

1/2
t2Î±0 ,
ynew âˆ¼ wt Î²0 + Î·0 (1 + wt Î£0 w)/Î±0
(
âˆ’1 )1/2
âˆ’1
2
t
t
Î·
(b,
s
)(1
+
w
Î£
+
X
X
w)
0
0
t2Î±0 +n
ynew | (b, s2 ) âˆ¼ wt Î²0 (b, s2 ) +
Î±0 + n/2
where tÎ» denotes a Student(Î») random variable and
âˆ’1 âˆ’1

t
Î²0 (b, s2 ) = Î£âˆ’1
Î£0 Î²0 + X t Xb
0 +X X



âˆ’1
t
2
2
2 t
Î·0 (b, s2 ) = Î·0 + s2 + ||Xb||2 + ||Î£âˆ’1
0 Î²0 || âˆ’ Î²0 (b, s ) Î£0 + X X Î²0 (b, s ) /2.

These results permit the calculation of the biases as in the location problem.

5

Conclusions

There are several conclusions that can be drawn from the discussion here. First,
it is necessary to take bias into account when considering Bayesian procedures
and currently this is generally not being done. Depending on the purpose of the
study, some values concerning both bias against and bias in favor need to be
quoted as these are figures of merit for the study. The approach to Bayesian inferences via a characterization of evidence makes this relatively straight-forward
conceptually. Second, frequentism plays a role in Bayesian statistical reasoning, not through the inferences, but rather through the design as it how we
23

determine and control the biases. Overall this makes sense because, before the
data is seen, it is natural to be concerned about what inferences can be reliably
drawn. Once the data is observed, however, it is the evidence in this data set
that matters and not the evidence in the data sets not seen. Still, if we ignore
the latter it may be that the existence of bias makes the inferences drawn of
very low quality. Third, the results concerning the standard p-value in Example
1 can be seen to apply quite generally and this makes any discussion about how
to characterize and measure evidence of considerable importance. The principle
of evidence makes a substantial contribution in this regard as was shown in a
variety of results. The major purpose of this paper, however, is to deal with
a key criticism of Bayesian methodology, namely, that inferences can be biased
because of their dependence on the subjective beliefs of the analyst. This criticism is accepted, but we also assert that this can be dealt with in a logical and
scientific fashion as has been demonstrated in this paper.

6

References

Baskurt, Z. and Evans, M. (2013) Hypothesis assessment and inequalities for
Bayes factors and relative belief ratios. Bayesian Analysis, 8, 3, 569-590.
Berger, J.O. and Selke, T. (1987) Testing a point null hypothesis: the irreconcilability of p values and evidence. Journal of the American Statistical Association,
82, 397, 112-122.
Berger, J.O. and Delampady, M. (1987) Testing precise hypotheses. Statistical
Science, 2, 3, 317-335.
Cousins, R.D. (2017) The Jeffreysâ€“Lindley paradox and discovery criteria in
high energy physics. Synthese, 194, 2, 395â€“432.
Evans, M. (2015) Measuring Statistical Evidence Using Relative Belief. Monographs on Statistics and Applied Probability 144, CRC Press.
Evans, M., Guttman, I. and Li, P. (2017) Prior elicitation, assessment and inference with a Dirichlet prior. Entropy 2017, 19(10), 564; doi:10.3390/e1910056.
Evans, M. and Tomal, J. (2018) Multiple testing via relative belief ratios.
FACETS, 3: 563-583, DOI: 10.1139/facets-2017-0121.
Gu, Y., Li, W. Evans, M. and Englert, B-G. (2019) Very strong evidence in
favor of quantum mechanics and against local hidden variables from a Bayesian
analysis. Physical Review A 99, 022112(1-17).
Robert, C. P. (2014) On the Jeffreys-Lindley paradox. Philosophy of Science,
81, 216â€“232.
Shafer, G. (1982) Lindleyâ€™s paradox (with discussion). Journal of the American
Statistical Association, 77, 378, 325-351.
Spanos, A. Who should be afraid of the Jeffreys-Lindley paradox? Philosophy
of Science, 80, 1, 73 - 93.
Sprenger, J. (2013) Testing a precise null hypothesis: The case of Lindleyâ€™s
paradox. Philosophy of Science, 80, 733-744.
Villa, C. and Walker, S. (2017) On the mathematics of the Jeffreysâ€“Lindley

24

paradox. Communications in Statistics - Theory and Methods, 46, 24, 1229012298.

7

Appendix

Proof of Theorem 1. The Savage-Dickey ratio result implies RBÎ¨ (Ïˆâˆ— | x) =
mÏˆâˆ— (x)/m(x) and note R(Ïˆâˆ— ) = {x : mÏˆâˆ— (x) â‰¤ m(x)}. Now X1 = {x :
IR(Ïˆâˆ— ) (x) âˆ’ ID(Ïˆâˆ— ) (x) < 0} = {x : IR(Ïˆâˆ— ) âˆ’ ID(Ïˆâˆ— ) (x) < 0, mÏˆâˆ— (x) > m(x)}
and X2 = {x : IR(Ïˆâˆ— ) (x) âˆ’ ID(Ïˆâˆ— ) (x) > 0} = {x R: IR(Ïˆâˆ— ) (x) âˆ’ ID(Ïˆâˆ— ) (x) â‰¥
0, mÏˆâˆ— (x) â‰¤ m(x)}. Then M (R(Ïˆâˆ— )) âˆ’ M (D(Ïˆâˆ— )) = X1 (IR(Ïˆâˆ— ) (x) âˆ’ ID(Ïˆâˆ— ) (x))
R
M (dx)+ X2 (IR(Ïˆâˆ— ) (x)âˆ’ID(Ïˆâˆ— ) (x)) M (dx) â‰¥ M (R(Ïˆâˆ— ) | Ïˆâˆ— )âˆ’M (D(Ïˆâˆ— ) | Ïˆâˆ— ) â‰¥ 0
R
establishing (i). Also, M (D(Ïˆâˆ— )) = M (D(Ïˆâˆ— ) | Ïˆâˆ— )Î Î¨ ({Ïˆâˆ— })+ Î¨\{Ïˆâˆ— } M (D(Ïˆâˆ— ) |
Ïˆ) Î Î¨ (dÏˆ) and the integral is the prior probability of not getting evidence in
favor of Ïˆâˆ— when it is false and this establishes (ii).
/ C(X))) = EÎ 2Î¨ (M (Ïˆâˆ— âˆˆ
/ C(X) | Ïˆ)) =
Proof of Theorem 2. Now EÎ Î¨ (M (Ïˆâˆ— âˆˆ
R
EÎ 2Î¨ (M (D(Ïˆâˆ— )) | Ïˆ)) = Î¨ M (D(Ïˆâˆ— )) Î Î¨ (dÏˆâˆ— ) and (i) follows from Theorem 1.
R
R
Also, Î¨ M (D(Ïˆâˆ— )) Î Î¨R(dÏˆâˆ— ) = EÎ Î¨ ( Î¨ M (D(Ïˆâˆ— ) | Ïˆ) Î Î¨ (dÏˆ)) = EÎ Î¨ (M (D(Ïˆâˆ— )
/ C(X) | Ïˆâˆ— )
| Ïˆâˆ— )Î Î¨ ({Ïˆâˆ— }))+EÎ Î¨ ( Î¨\{Ïˆâˆ— } M (D(Ïˆâˆ— ) | Ïˆ) Î Î¨ (dÏˆ)) = EÎ Î¨ (M (Ïˆâˆ— âˆˆ
R
/ C(X) | Ïˆ) Î Î¨ (dÏˆ)) establishing (ii).
Î Î¨ ({Ïˆâˆ— })) + EÎ Î¨ ( Î¨\{Ïˆâˆ— } M (Ïˆâˆ— âˆˆ
R
R
Proof of Theorem 3. Now
R M (R(Ïˆâˆ— ) | Ïˆâˆ— ) = IR(Ïˆâˆ— ) (x) MÏˆâˆ— (dx) â‰¤ IR(Ïˆâˆ— ) (x)
= M (R(Ïˆâˆ— ) | Ïˆâˆ—R)Î Î¨ ({Ïˆâˆ— }) +
RM (dx) = M (R(Ïˆâˆ— )) = Î¨ M (R(Ïˆâˆ— ) | Ïˆ) Î (dÏˆ)
c
M
(R(Ïˆ
)
|
Ïˆ)
Î 
(dÏˆ)
and
so
Î 
({Ïˆ
}
)M
(R(Ïˆâˆ— ) | Ïˆâˆ— ) â‰¤ Î¨\{Ïˆâˆ— }
âˆ—
Î¨
Î¨
âˆ—
Î¨\{Ïˆâˆ— }
M (R(Ïˆâˆ— ) | Ïˆ) Î Î¨ (dÏˆ) which implies (i). Furthermore, (ii) is implied by
/ P lÎ¨ (X) | Ïˆâˆ— )) = EÎ Î¨ (M (R(Ïˆâˆ— ) | Ïˆâˆ— ))
EÎ Î¨ (M (Ïˆâˆ— âˆˆ
!
Z
â‰¤ EÎ Î¨
M (R(Ïˆâˆ— ) | Ïˆ) Î Î¨ (dÏˆ)/Î Î¨ ({Ïˆâˆ— }c
Î¨\{Ïˆâˆ— }

= EÎ Î¨

Z

Î¨\{Ïˆâˆ— }

M (Ïˆâˆ— âˆˆ
/ P lÎ¨ (X) | Ïˆ) Î Î¨ (dÏˆ)/Î Î¨ ({Ïˆâˆ— }

c

!

.

Proof of Theorem 4. It is easy to see that the proof of Theorem 1 can be modified to show that among all regions Dint (Ïˆâˆ— ) âŠ‚ X satisfying M (Dint (Ïˆâˆ— ) | Ïˆâˆ— ) â‰¤
M (RBÎ¨ (Ïˆâˆ— | X) < 1 | Ïˆâˆ— ) the prior probability M (Dint (Ïˆâˆ— )) is maximized by
Dint (Ïˆâˆ— ) = {x : RBÎ¨ (Ïˆâˆ— | x) < 1}. This clearly implies (i) and (ii) follows
similarly.
Proof of Theorem 5. Now EÎ Î¨ (M (Ïˆâˆ— âˆˆ C(X))) = EÎ 2Î¨ (M (Ïˆâˆ— âˆˆ C(X) | Ïˆ)) =
EÎ 2Î¨ (M (Dc (Ïˆâˆ— )) | Ïˆ)) = EÎ Î¨ (M (Dc (Ïˆâˆ— )) and (i) follows from Theorem 1(i).
R
c
by EÎ Î¨ (M (Dc (Ïˆâˆ— )) = Î¨ M
R (D (Ïˆâˆ— ) | Ïˆâˆ— )Î Î¨ ({Ïˆâˆ— }) Î Î¨ (dÏˆâˆ— )+
RAlso,
R (ii) is implied
c
(D (Ïˆâˆ— ) | Ïˆ) Î Î¨ (dÏˆ) Î Î¨ (dÏˆâˆ— ) = Î¨ M (Ïˆâˆ— âˆˆ C(X) | Ïˆâˆ— )Î Î¨ ({Ïˆâˆ— })
Î¨ Î¨\{Ïˆâˆ— } M
R R
Î Î¨ (dÏˆâˆ— ) + Î¨ Î¨\{Ïˆâˆ— } M (Ïˆâˆ— âˆˆ C(X) | Ïˆ) Î Î¨ (dÏˆ) Î Î¨ (dÏˆâˆ— ).
25

