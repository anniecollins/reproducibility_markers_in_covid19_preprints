Convergence of the rescaled Whittaker stochastic
differential equations and independent sums
arXiv:1910.05333v4 [math.PR] 10 Jan 2021

Yu-Ting Chenâˆ—â€ 
January 12, 2021
Abstract
We study some SDEs derived from the q â†’ 1 limit of a 2D surface growth model called the qWhittaker process. The fluctuations are proven to exhibit Gaussian characteristics that â€œcome down
from infinityâ€: After rescaling and re-centering, convergence to the time-inverted stationary additive
stochastic heat equation holds. The point of view in this paper is a probabilistic representation of
the SDEs by independent sums. By this connection, the normal and Poisson approximations and
the in-between slow decorrelation, all in particular integrated forms, explain the convergence of the
re-centered covariance functions. With bounds and divergent constants from these approximations,
the proof of the process-level convergence identifies additional divergent terms in the dynamics and
considers cancellation arguments that treat the independent sums as discrete spin systems.
Keywords: Surface growth models; additive stochastic heat equation; pure death processes; normal
approximations; Poisson approximations.
Mathematics Subject Classification (2000): 60J27, 60K35, 60F05

Contents

âˆ—
â€ 

1 Introduction

2

2 The
2.1
2.2
2.3

Whittaker SDEs
Connections to the q-Whittaker process . . . . . . . . . . . . . . . . . . . . . . . . . .
Explicit solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Representation by independent sums . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6
6
8
9

3 Rescaled limit of the covariance function
3.1 Integrated Poisson approximations . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Integrated normal approximations . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

11
14
23

4 Convergence to the additive stochastic heat equation
4.1 Weak formulations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.2 Identification of the limit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

31
31
34

5 Tightness of the rescaled Whittaker SDEs

35

6 Stationary additive stochastic heat equation

45

7 References

46

Department of Mathematics and Statistics, University of Victoria, British Columbia, Canada.
Email: chenyuting@uvic.ca

1

a2

Î»(5, 5)

Î»(4, 5)Î»(3, 5)

Î»(4, 4)

Î»(3, 4)

Î»(3, 3)

Î»(2, 5) Î»(1, 5)
Î»(2, 4) Î»(1, 4)
Î»(2, 3) Î»(1, 3)

Î»(2, 2)

Î»(1, 2)

Î»(1, 1)

Z
Figure 1.1: The figure shows a configuration Î» = {Î»(a1 , a2 ); (a1 , a2 ) âˆˆ T5 } under the q-Whittaker
process. Here, TL is defined in (1.2). For example, the position of the 2nd particle at level 3 is
Î»(2, 3) âˆˆ Z. Any blue particle can jump to the right with pushing whenever chosen. The red particle
is blocked by the particle at level 1 to maintain the inequalities Î»(2, 2) â‰¤ Î»(1, 1) â‰¤ Î»(1, 2) in the
interlacing relation.

1

Introduction

The original model behind this paper is the q-Whittaker process which goes back to Borodin
and Corwin [6]. The process is a discrete interacting particle system modeling surface growth
dynamics. In the limit of q â†’ 1, a recent work of Borodin, Corwin and Ferrari [7] proves
a convergence of the fluctuations by taking an iterated scaling limit. Our objective in this
paper is the final stage of the limiting scheme. It obtains a pointwise limit of the (space-time)
covariance functions of the following SDEs:
dÎ¾t (a) = tâˆ’1 (AL Î¾t )(a)dt + dBt (a),

a âˆˆ TL , 0 < t < âˆ,

(1.1)

where L is an integer â‰¥ 3 and TL is the following upper triangular lattice:
TL = {a = (a1 , a2 ) âˆˆ N2 ; 1 â‰¤ a1 â‰¤ a2 â‰¤ L}.

(1.2)

In (1.1), AL can be identified as a generator matrix. The corresponding Markov chain is given
by the invertible linear transformation (m1 , m2 ) 7â†’ (m1 + 1, m1 + m2 + 1) of two independent
linear pure death processes, such that the sum of the populations does not exceed L âˆ’ 1. The
noise terms are given by a standard Brownian motion {Bt (a); a âˆˆ TL }. Due to the original
discrete dynamics, we call these SDEs from [7] the Whittaker SDEs.
Our goal in this paper is to prove a rescaled limit of the Whittaker SDEs at the process level.
For the convergence of the covariance functions, we choose a method very different from the
method in [7] by turning to a probabilistic representation of solutions of the SDEs. Hence, the
entire spectrum of limit theorems for sums of Bernoulli random variables enters and becomes
the point of departure of the present proofs.
Let us begin by explaining connections between the Whittaker SDEs and surface growth
dynamics in terms of the original discrete model. First, given an integer L â‰¥ 3, the q-Whittaker
process is a stochastic dynamic model of particles living in L rising levels. Each level is a copy
of the one-dimensional integer lattice. The number of particles at each level is the same as the
level number. The particles at each level are ordered from the right to the left. Accordingly, a
configuration of the whole system takes values in ZTL with respect to the finite triangular lattice
2

TL defined above. The particle system evolves according to some special rates depending on q
and local configurations. The updates also respect an interlacing relation induced by TL on the
overall particle positions. See Figure 1.1 for an example of the eligible configurations. More
specifically, when a particle, say, at a âˆˆ TL is chosen for a transition according to the rates, it
attempts to jump to the right lattice point. This jump is successful if the chosen particle is
not â€œblockedâ€, in a sense that the jump does not break the assumed interlacing relation. In
this case, the chosen particle also â€œpushesâ€ to the right, by one lattice point, the entirety of
the vertical string of particles above it in terms of positions and indices. In other words, these
particles being pushed originally occupy the same integer site at the respective levels as the
chosen particle and are indexed by a + (0, 1), Â· Â· Â· , a + (0, â„“ âˆ’ 1), such that â„“ â‰¥ 1 is maximal.
See Section 2.1 for the details of these mechanisms.
The q-Whittaker process has an important meaning of being a model of surface growth.
Configurations of the interlacing particles can be mapped to discrete surfaces (via lozenge
tilings). So transitions of particle configurations correspond to transitions of heights in the
discrete surfaces [9, Section 1.1]. From a broader perspective, the pushing mechanism and the
blocking mechanism define the q-Whittaker process as a generalization of the totally asymmetric simple exclusion process (TASEP) that plays an important role in the 1D Kardarâ€“
Parisiâ€“Zhang universality class [24]. Moreover, since the pushing mechanism induces a special
tilt direction in the discrete surfaces, it is believed that the q-Whittaker process falls in the
anisotropic Kardarâ€“Parisiâ€“Zhang universality class. In this direction, Wolfâ€™s conjecture [32]
from the physics
âˆš literature expects that the large time fluctuations in this class are universally
of the order ln t. Moreover, the probabilistic counterpart of this magnitude is the 2D Gaussian
free field [9, Section 1.4]. See [1, 30] for more backgrounds.
For the q-Whittaker process, the proof of this physical relation is first obtained in an insightful work by Borodin and Ferrari [9] for the case q = 0. For the q â†’ 1 dynamics, an
intermediate step of the proof in [7] leads to the Whittaker SDEs. See (2.4) for a summary of
the limiting schemes. In particular, though introduced with a probabilistic interpretation by
pure death processes above, in [7], the matrices AL in the drift coefficients of the SDEs appear
with the explicit algebraic forms, and the methods are developed accordingly.
In the direction of universality, Wolfâ€™s conjecture is also proven in [8] for the q-Whittaker
driven particle system [13]. This model is defined on periodic lattices in two dimensions. It
gives another discrete surface growth dynamics that include a special tilt direction. For the
q â†’ 1 fluctuations, an intermediate step of the proof in [8] derives some Ornsteinâ€“Uhlenbeck
finite-dimensional SDEs (called the Whittaker driven SDEs in [12]) similar to the Whittaker
SDEs. The constant matrices in the drift coefficients of the Whittaker driven SDEs continue to
incorporate some characteristics of the discrete dynamics. But they are structurally different
from the matrices AL . Not all of the off-diagonal entries are nonnegative. In this case, discrete
Fourier transforms are the central tool for proving the convergence. By contrast, the method
to be discussed below for the Whittaker SDEs considers different properties, mainly the probabilistic interpretation of AL and some limiting stationarity. Consequently, except for the use of
a divergent characteristic direction for space and time to be specified below, the present proofs
show very mild technical overlaps with those in [12]. On the other hand, another investigation
toward the universality in Wolfâ€™s conjecture by unifying [12] and the present paper may be
possible, given the entrance of the central limit theorem to be explained below. It shall develop
along a comparison of the proofs with the classical counterparts that use Fourier transforms in
proving the central limit theorem. We do not pursue the details here, though.
3

The main result of this paper proves a rescaled limit of the Gaussian stochastic integral parts
{Î¶t (a); a âˆˆ TL } in the solutions of the Whittaker SDEs. It can be summarized informally as
the theorem below. See Theorems 3.2 and 4.5 for the precise statements. For convenience, the
proof works with an infinite-dimensional Gaussian process from consistently extending these
parts of all finite L (see Proposition 2.1 and the discussion below it). The limiting process is
based on the 2D additive stochastic heat equation [31]:
âˆ†
âˆ‚X
(x, t) = X(x, t) + WÌ‡ (x, t),
âˆ‚t
2

(1.3)

where WÌ‡ is space-time white noise. Note that various rescaled limits of the covariance functions
of the Whittaker SDEs are already obtained in [7]. But these results are with forms and methods
all different from those introduced here. See Remark 3.3 (2â—¦ ). Connections to the stationary
2D additive stochastic heat equation are also pointed out in [7].
Theorem (Informal version). Let {Î¶t (a); a âˆˆ Tâˆ } denote the Gaussian stochastic integral
part in the solution of the infinite-level Whittaker SDE, and let X(x, t) denote the stationary
solution of the 2D additive stochastic heat equation (1.3). Then as N â†’ âˆ,

j

x1 k j
x2 k 
x 7â†’ Î¶N t Nt + Nt Â· 1/2 , Nt + Nt Â· 1/2
âˆ’â†’ x 7â†’ X(x, tâˆ’1 ) t>0
(1.4)
N
N
t>0
holds in the following two modes of convergence: (1) pointwise convergence of space-time
covariance functions modulo constants, and (2) convergence in distribution as caÌ€dlaÌ€g processes
that take values in the space of tempered distributions on R2 modulo constants.

Let us explain the theorem in more detail. First, the rescaling in (1.4) is along the
characteristic direction (x, t) 7â†’ (t + tx, t) followed by the Edwardsâ€“Wilkinson scaling [15]:
(x, t, Î¶) 7â†’ (N âˆ’1/2 x, Nt, N 0 Î¶). For the limiting process, stationarity holds in the form that the
initial condition is given by the massless 2D log-correlated Gaussian free field (Section 4.2). Due
to the time inversion (t 7â†’ tâˆ’1 ), the informal process-level picture thus shows that the limiting
fluctuations â€œcome down from infinityâ€ along the clock of the additive stochastic heat equation.
In particular, this result should be an answer to the inquiry in [7, Section 1.2] whether, for time
varying over the entire half-line, the fluctuations of the q-Whittaker process can be related to
the stationary additive stochastic heat equation. There in [7], the relation is established over
the time interval [0, 1].
For the proof, we first consider a rescaled limit of the covariance functions. We follow an
initial step in [7, Lemma 5.7] but subsequently turn to a method that entirely circumvents the
use of complex contour integrals and special functions in the original method of [7]. That step
from [7] identifies AL as the generator matrix of a linear transformation of two i.i.d. Markov
chains with linearly decreasing rates. The method of our choosing starts with the interpretation
that the latter two Markov chains are linear pure death processes and model the population size
of individuals with i.i.d. exponential lifetimes. Moreover, the chains can be represented as sums
of independent Bernoulli variables that keep track of the numbers of survivors. The central
limit theorem thus leads to the Gaussian characteristic of the limit. It induces a natural choice
of the rescaling scheme, and its local version gives approximations by Gaussian densities. The
additive stochastic heat equation arises since its solution is structurally similar to the solutions
of the Whittaker SDEs.
4

Given the crucial connection to independent sums, we are still faced with the basic question of whether the normal approximations are enough. The issue arises from the following
representation of the covariance functions of the rescaled processes in (1.4):
Z

0

2
Ns Y
j=1


P S

N s+N sÂ·

xj
N 1/2



 r 
 r 
â€²

=S
dr,
yj
N t+N tÂ· 1/2
Ns
Nt
N

(1.5)

â€²
â€²
where x, y âˆˆ R2 , 0 â‰¤ s â‰¤ t < âˆ, and Sm (p) and Sm
â€² (p ) are independent binomial random variâ€²
ables such that Sm (p) has parameters (m, p), and Smâ€² (pâ€² ) is similarly defined (Proposition 2.4).
In (1.5), the parameters of the Bernoulli random variables in the order-N sums are integrated
out up to order 1. With this manner, the convergence of the probabilities has to be proven
for essentially all the possible values of the parameters simultaneously. Therefore, the above
sketch of proof actually leaves out the Poisson approximations, and more importantly, the â€œslow
decorrelationâ€ of sums of Bernoulli variables from the Poisson limit to the Gaussian limit. The
slow decorrelation raises most of the technicality in this stage. The key is to carry it out by
calculating the asymptotics of an integral of probabilities as in (1.5), the associated interval
being changed to 1 â‰ª r â‰ª N where an integrated Poisson approximation and an integrated
local central limit theorem are joined. The proof also needs to quantify these â‰ª-bounds of r.
In particular, one ingredient to get the integrated Poisson approximation is a bound from the
Steinâ€“Chen method [3, 4]. Along this way, some logarithmically divergent constants, which also
appear in [7], and the stationarity in the limiting equation arise from integrating the decorrelating probabilities. See Section 3. Let us stress that we do not pursue the optimality of error
bounds for these integrated approximations. Our interest is to investigate possible connections
between the normal and Poisson approximations and the universality in Wolfâ€™s conjecture. This
direction is in the same spirit as the comparison with the proof in [12] for the Whittaker drive
SDEs mentioned above.
The process-level convergence of the rescaled processes considers the weak formulation by
integrating out space. In this form, the main result proves the uniform HoÌˆlder continuity in
time on compacts of the covariance functions. The method begins when proving the pointwise
convergence of the covariance functions already discussed above, as we quantify appropriate
bounds throughout. For the next step (Section 5), the divergent constants from integrating
decorrelating probabilities are removed by re-centering. The main work then bounds the HoÌˆlder
coefficients by removing some additional divergent terms (Lemma 5.5). The issue here arises
since it is not clear how these divergent terms can cancel each other without further transformations. The integral structures of these terms appear to be special and different from those
in the decorrelation. To find ways for the cancellations, the binomial integration by parts,
and some recursive identities for the independent sums enter as the central tools. Essentially,
by involving these tools, we treat the independent sums of Bernoulli random variables in the
covariance functions as discrete spin systems. In summary, this part of the present paper shows
a different application of the probabilistic presentation of the Whittaker SDEs. Moreover, as in
[12], it deals with dynamical singularities in the surface growth, along a divergent characteristic
direction and not present in proving the convergence of covariance functions.
Finally, we remark that asymptotic expansions for the Poisson approximations [2] and the
normal approximations [22] apply to the independent sums in this paper. Given this background, it may be of interest to investigate higher-order asymptotics of the fluctuations of the
Whittaker SDEs at the process level.

5

Organization. Section 2 discusses the Whittaker SDEs for more detailed connections to
the q-Whittaker process, the solutions, and the key probabilistic representation giving (1.5).
Section 3 proves the convergence of the covariance function. In particular, the main technical
conditions in the proofs of Sections 3 and 5 are imposed in Assumption 3.4 and Definition 3.5.
Some notations for binomial random variables used throughout this paper are defined in (3.12).
In Section 4, we relate the limiting process to the additive stochastic heat equation. The proof
of the tightness of the SDEs is in Section 5. Finally, Section 6 collects some basic properties of
the 2D stationary additive stochastic heat equation.
Convention for constants. C(T ) âˆˆ (0, âˆ) is a constant depending only on T and can change
from inequality to inequality. Other constants are defined analogously. We write A . B or
A & B if A â‰¤ CB for a universal constant C âˆˆ (0, âˆ). A â‰ B means both A . B and A & B.
Acknowledgments. The author would like to thank three referees for suggestions concerning
the presentation and comparison with related results and thank Andrew D. Barbour for answering questions on Poisson and normal approximations. Support from the Simons Foundation
before the authorâ€™s present position and from the Natural Science and Engineering Research
Council of Canada is gratefully acknowledged.

2

The Whittaker SDEs

In this section, we recall more details of the Whittaker SDEs derived in [7, Proposition 5.5].
Then we show that these SDEs can be solved explicitly by the driving Brownian motion and
sums of i.i.d. Bernoulli random variables. Due to this connection, we turn to limit theorems of
independent sums in the next section.

2.1

Connections to the q-Whittaker process

For fixed q âˆˆ [0, 1) and integer L â‰¥ 3, the q-Whittaker process (Î›qt )tâ‰¥0 considers L(L + 1)/2
many particles indexed by TL , where TL is defined by (1.2). In any state Î» âˆˆ ZTL of the system,
the following interlacing relation of particles holds:
Î»(a1 + 1, a2 ) â‰¤ Î»(a1 , a2 âˆ’ 1) â‰¤ Î»(a1 , a2 ), âˆ€ a = (a1 , a2 ) âˆˆ TL , a2 â‰¥ 2, a2 â‰¥ a1 + 1.

(2.1)

For q > 0, the particle labelled by a âˆˆ TL attempts to jump to the right (Î»(a) 7â†’ Î»(a) + 1)
and, if successful, pushes other particles in the way described in Section 1, with rate


1 âˆ’ q Î»(a1 âˆ’1,a2 âˆ’1)âˆ’Î»(a1 ,a2 ) 1 âˆ’ q Î»(a1 ,a2 )âˆ’Î»(a1 +1,a2 )+1
.
(2.2)
cq (a, Î») =
1 âˆ’ q Î»(a1 ,a2 )âˆ’Î»(a1 ,a2 âˆ’1)+1
Here in (2.2), 1 âˆ’ q Î»(a1 âˆ’1,a2 âˆ’1)âˆ’Î»(a1 ,a2 ) is understood to be 1 if (a1 âˆ’ 1, a2 âˆ’ 1) âˆˆ
/ TL ; a similar
Î»(a1 ,a2 )âˆ’Î»(a1 +1,a2 )+1
Î»(a1 ,a2 )âˆ’Î»(a1 ,a2 âˆ’1)+1
convention applies to 1 âˆ’ q
and 1 âˆ’ q
. That is, the following
reduction applies when a is a point on the left or right boundary of TL :
ï£±
1,
a1 = a2 = 1;
ï£´
ï£´
ï£´
ï£²
1 âˆ’ q Î»(a2 âˆ’1,a2 âˆ’1)âˆ’Î»(a2 ,a2 ) , a1 = a2 > 1;
cq (a, Î») =
(2.3)
Î»(1,a2 )âˆ’Î»(2,a2 )+1
ï£´
ï£´
1
âˆ’
q
ï£´
ï£³
, a1 = 1, a2 > 1.
1 âˆ’ q Î»(1,a2 )âˆ’Î»(1,a2 âˆ’1)+1
6

5
4
3
2
1
0

1

2

3

4

5

Figure 2.1: The possible trajectories of the Markov chain on T5 with generator A5 .

One key feature of cq (a, Î») is that it is zero when Î»(a1 âˆ’ 1, a2 âˆ’ 1) = Î»(a1 , a2 ). The particle
labelled by a is thus â€œblockedâ€ by the particle labelled by (a1 âˆ’ 1, a2 âˆ’ 1), as illustrated in
Figure 1.1. This condition ensures that the interlacing relation in (2.1) is maintained. For
q = 0, the rates are extended by continuity so that c0 (a, Î») = 1 whenever the particle labelled
by a under Î» is not blocked, and c0 (a, Î») = 0 otherwise. (This case is not used in the present
paper.) See [9, Section 1.1] (for q = 0), [6, Definition 3.28], and [7, Section 2.5.2].
Given an integer L â‰¥ 3, the following iterated limit in distribution

 âˆ’Îµ
def
e 1
âˆ’1
âˆ’1
Î›
(2.4)
âˆ’
Îµ
Î¾t = lim lim (Îµ2 Îµ1 )1/2 Î›(Îµ
âˆ’1 t
(Îµ2 Îµ1 ) t
1
2 Îµ1 )
Îµ2 â†’0+ Îµ1 â†’0+

is proven under the initial conditions that Î›q0 (a) = 0 for all a âˆˆ TL . Here, the process
âˆ’Îµ
def
Î›t = limÎµ0 â†’0+ Îµ0 Î›Îµeâˆ’10t for re-centering is deterministic and so gives a law of large numbers
0
for the particle system. Second, the limit in (2.4) for Îµ1 â†’ 0+ considers the q-Whittaker prodef S
cess with q = eâˆ’Îµ1 â†’ 1. Finally, with Tâˆ = Lâ‰¥3 TL , the limiting fluctuation (Î¾t ) in (2.4) obeys
the SDE defined by (1.1) such that the matrix AL in the drift vector is
AL = Aâ†¾(TL Ã— TL );

ï£±
a1 âˆ’ 1,
ï£´
ï£´
ï£²
a2 âˆ’ a1 ,
âˆ€ a, b âˆˆ Tâˆ , A(a, b) =
ï£´ 0, P
ï£´
ï£³
âˆ’ bâ€² 6=a A(a, bâ€² ),

b = a âˆ’ (1, 1);
b = a âˆ’ (0, 1);
for other b 6= a;
b = a.

(2.5)

See [7, Sections 3 and 4] for the limits in (2.4).
Note that A has nonnegative off-diagonal entries by the definition of Tâˆ . Hence, A is a
generator matrix. The semigroup (etA ; t â‰¥ 0) is Markovian. Moreover, given any integer L â‰¥ 3,
AL depends only on the lattice points in TL . It also holds that AL is a generator and (etAL ; t â‰¥ 0)
is Markovian. See Figure 2.1 for an example. Moreover, AL shows the special jump rates (2.2)
in the limit and how the SDEs remember where the pushing and blocking come from in the
discrete dynamics. For example, in (2.5), b = a âˆ’ (1, 1) is the label of the particle that can
block a jump of the particle labelled by a, and b = a âˆ’ (0, 1) is the label of the particle that
can push the particle labelled by a or propagate a push.

7

2.2

Explicit solutions

The following proposition solves the Whittaker SDEs.
Proposition 2.1. Consider the Whittaker SDE defined in (1.1) for an integer L â‰¥ 3.
(1â—¦ ) For any solution (Î¾t ; 0 < t < âˆ), the following properties hold almost surely:
def

Î¾0 = lim e(âˆ’ log t)AL Î¾t

exists,

tâ†’0+

(2.6)

and Î¾t = Î·t + Î¶t , where
def

(log t)AL

Î·t (a) = e

XZ

def

Î¾0 (a) & Î¶t (a) =

bâˆˆTL

t

e[log(t/r)]AL (a, b)dBr (b),

0

âˆ€ a âˆˆ TL .

(2.7)

(2â—¦ ) For any Î¾0 âˆˆ RTL , (Î¾t ; 0 < t < âˆ) defined by (2.7) satisfies both (1.1) and (2.6).
Proof. The proofs of (1â—¦ ) and (2â—¦ ) both rely on the following almost-sure identity:
Z t+s
âˆ’tAL
âˆ’(t+s)AL
Î¾et +
e
Î¾et+s = e
eâˆ’rAL dr Ber , âˆ€ s â‰¥ 0, t âˆˆ R.

(2.8)

t

To see (2.8), first, note that for any solution (Î¾t ) of (1.1) and for any fixed t âˆˆ R, by changing
variables, (Î¾et+s ; s â‰¥ 0) satisfies the following linear equation:
Z s
Î¾et+s = Î¾et +
AL Î¾et+r dr + Bet+s âˆ’ Bet .
0

Rr

Here, since Wr = 0 eâˆ’v/2 dv (Bet+v âˆ’ Bet ) is a standard Brownian
R s r/2 motion by LeÌvyâ€™s characterization of Brownian motion, we can write Bet+s âˆ’ Bet = 0 e dr Wr . Hence, (2.8) follows from
a standard result of linear SDEs [17, the last paragraph of p.354].
(1â—¦ ). First, we prove that the limit in (2.6) exists almost surely. It suffices to show that the
stochastic integral in (2.8) with t + s = 0 converges almost surely as t â†’ âˆ’âˆ. First, note that
by the Riemann-sum approximations of stochastic integrals [17, Section 3.2.B],
Z 0
Z âˆ’t
âˆ’rAL
e
dr Ber =
erAL dr Mr , âˆ€ t â‰¤ 0.
(2.9)
t

0

Here, by time reversal, (Ms = B1 âˆ’ Beâˆ’s ; s â‰¥ 0) is a continuous vector martingale with
ds hM(b), M(bâ€² )is = Î´b,bâ€² eâˆ’s ds. For all a, aâ€² âˆˆ TL and s â‰¥ 0, the last stochastic integral satisfies
Z Â·

Z Â·


Z s
rAL
rAL
â€²
e dr Mr (a),
e dr Mr (a ) =
[(erAL )(erAL )âŠ¤ ](a, aâ€² )eâˆ’r dr.
(2.10)
0

0

s

0

Since erAL for r â‰¥ 0 are stochastic matrices, the integral on the right-hand side of (2.10)
converges as s â†’ âˆ. The existence of this limit and the martingale convergence theorem
[17, Problem 3.19 in Section 1.3] imply the almost-sure convergence of the improper vector
R0
stochastic integral âˆ’âˆ eâˆ’rAL dr Ber by (2.9), and hence, the limit in (2.6) by (2.8).
8

Now, we pass t â†’ âˆ’âˆ in (2.8) and deduce that, for any t0 âˆˆ R,
Î¾

et0

t0 AL

=e

Î¾0 +

Z

t0

(t0 âˆ’r)AL

e

t0 AL

dr B = e
er

Î¾0 +

âˆ’âˆ

Z

et0

t

e[log(e 0 /r)]AL dr Br .

(2.11)

0

The last equality is enough for (2.7). We have proved (1â—¦ ).
(2â—¦ ). Given Î¾0 âˆˆ RTL , reversing the above arguments for (2.11) and (2.8) proves that Î¾t = Î·t +Î¶t
defined by (2.7) satisfies both (1.1) and (2.6). The proof is complete.

Since AL = Aâ†¾(TL Ã— TL ) for all L, we can construct stochastic integral parts of solutions of
the Whittaker SDEs on TL for all L â‰¥ 3 simultaneously from an infinite-dimensional standard
Brownian motion {Bt (a); a âˆˆ Tâˆ }. This extension defines an infinite-dimensional Gaussian
process {Î¶t (a); a âˆˆ Tâˆ } such that for a âˆˆ TL , Î¶t (a) equals the sum in (2.7). In this case, AL
and TL in the sum can be replaced by A and Tâˆ , respectively.
In the rest of this paper, we study the rescaled limits of {Î¶t (a); a âˆˆ Tâˆ } at the
process level, not just the rescaled limits of their marginal distributions.

2.3

Representation by independent sums

In this subsection, we discuss a probabilistic representation of the Markovian semigroup (etA ; t â‰¥
0) in terms of sums of i.i.d. Bernoulli random variables. This representation uses two sets of
ingredients defined as follows.
First, define a sum function Î£ : Z2+ â†’ Tâˆ and a difference function âˆ† : Tâˆ â†’ Z2+ by
def

Î£ : (m1 , m2 ) 7â†’ (Î£1 (m1 , m2 ), Î£2 (m1 , m2 )) = (m1 + 1, m1 + m2 + 1),
def

âˆ† : (a1 , a2 ) 7â†’ (âˆ†1 (a1 , a2 ), âˆ†2 (a1 , a2 )) = (a1 âˆ’ 1, a2 âˆ’ a1 ).

(2.12)
(2.13)

The map Î£ is bijective with âˆ† being its inverse. (We abuse notation a bit since âˆ† has been
used to denote the Laplacian in the context of SPDEs.) For the following result, see the proof
of [7, Lemma 5.7].
Lemma 2.2. The Markov chain with generator A can be represented as Î£D. Here, D =
(D (1) , D (2) ), and D (1) and D (2) are independent linear pure death chains on Z+ such that
k â†’ k âˆ’ 1 with rate k, for any k âˆˆ Z+ .
Proof. A jump in D (1) changes Î£D = (Î£1 D, Î£2 D) to (Î£1 D âˆ’ 1, Î£2 D âˆ’ 1) with rate D (1) =
Î£1 D âˆ’ 1. Similarly, a jump in D (2) changes Î£D = (Î£1 D, Î£2 D) to (Î£1 D, Î£2 D âˆ’ 1) with rate
D (2) = Î£2 D âˆ’ Î£1 D. These rates recover the entries of A.

To introduce the second set of ingredients, we write Sm (p) for a binomial random variable
with parameters m âˆˆ Z+ and p âˆˆ [0, 1]. Then take a sequence of i.i.d. exponential variables
{en } under P and represent the binomial random variables explicitly as
âˆ’t

def

Sm (e ) =

m
X

1(t,âˆ) (en ),

n=1

9

t âˆˆ [0, âˆ],

(2.14)

P
with the convention that 0n=1 â‰¡ 0. We let eâˆ’t parametrize Sm since E[1(t,âˆ) (en )] = eâˆ’t . The
independent sum in (2.14) is applied in the form that, as processes with caÌ€dlaÌ€g paths,
(d)

(j)

(Dt ; t â‰¥ 0) = SD(j) (eâˆ’t ); t â‰¥ 0
0

(j)



(2.15)

for any deterministic initial condition D0 âˆˆ Z+ . Recall that this probabilistic representation
follows because memorylessness of exponential random variables supplies the Markov property
and the property that en â€™s are independent with E[en ] = 1 gives the linear death rates. See
[23, Section 6.2.1, pp.287â€“290].
The probabilistic representation of (etA ) is now defined as follows: By Lemma 2.2, the
identity âˆ†Î£ = Id and (2.15), we have
âˆ€ a, b âˆˆ Tâˆ ,

etA (a, b) = P(Î£Dt = b|Î£D0 = a)
= P(Dt = âˆ†b|D0 = âˆ†a)


= P Sâˆ†1 a (eâˆ’t ) = âˆ†1 b P Sâˆ†2 a (eâˆ’t ) = âˆ†2 b .

(2.16)

By (2.16), the pure death processes D j and the independent sums Sm (eâˆ’t ) furnish a probabilistic
representation of the solutions of the Whittaker SDEs. For this reason, we view these auxiliary
random elements as being defined on a probability space, with probability P and expectation
E, separate from the probability space for the Whittaker SDEs.
Remark 2.3. Alternatively, the reader may choose to think of the Brownian motions B(a)â€™s
collectively as the â€œrandom environmentâ€ driving the Whittaker SDEs. In this case, all the
random elements need to be defined on the same probability space.

We close this section with an immediate application of (2.16), which is the starting point of
the next section. From now on, write Î¶Î£(m1 , m2 ) for the value of Î¶ : Tâˆ â†’ R at Î£(m1 , m2 ) âˆˆ
Z2 , S â€² for an independent copy of the process S defined by (2.14), and Cov[U; V ] = E[UV ] âˆ’
E[U]E[V ] for random variables U and V .
Proposition 2.4. The mean-zero Gaussian process {Î¶t (a); a âˆˆ Tâˆ } defined below Proposition 2.1 has a covariance function satisfying the following probabilistic representation:
Cov



Î¶s Î£(m1 , m2 ); Î¶t Î£(mâ€²1 , mâ€²2 )



=

Z sY
2
0

 r 

r
â€²
= Smâ€²j
dr
P Smj
s
t
j=1

(2.17)

for all (m1 , m2 ), (mâ€²1 , mâ€²2 ) âˆˆ Z2+ and 0 < s â‰¤ t < âˆ.

Rt
P
Proof. Recall that for any L and a âˆˆ TL , Î¶t (a) = bâˆˆTâˆ 0 e[log(t/r)]A (a, b)dBr (b). See (2.7).
Hence, by ItoÌ‚â€™s isometry and the bijectivity of Î£ : Z2+ â†’ Tâˆ ,


Cov Î¶s Î£(m1 , m2 ); Î¶t Î£(mâ€²1 , mâ€²2 )
X Z s


e[log(s/r)]A Î£(m1 , m2 ), Î£(n1 , n2 ) e[log(t/r)]A Î£(mâ€²1 , mâ€²2 ), Î£(n1 , n2 ) dr
=
=

n1 ,n2 âˆˆZ+ 0
Z s X
0 n ,n
1 2

r
r
r
 
 
 

r

= n1 P Sm2
= n2 P Smâ€²1
= n1 P Smâ€²2
= n2 dr,
P Sm1
s
s
t
t
âˆˆZ
+

10

where the last equality follows from (2.16) and the identity Î£âˆ† = Id. Summing over n1 , n2 in
the last equality proves (2.17).


3

Rescaled limit of the covariance function

In this section, we prove convergence of the covariance function in (2.17) and quantify the error
bounds for the forthcoming applications to tightness of the fluctuation of the Whittaker SDEs.
First, the rescaling can be chosen from the central limit theorem if we consider the probabilities in (2.17). Write

r
 r 

r 
 r 
r
r 
â€²
â€²
â€²
P Smj
= Smâ€²j
= P S mj
âˆ’ S mâ€²j
= âˆ’mj
+ mj
,
(3.1)
s
t
s
t
s
t

with the shorthand notation

W = W âˆ’ E[W ].

Then a nontrivial limit of the random variable in (3.1) follows if we set mj and mâ€²j to be
Mj = M(xj , s) & Mjâ€² = M(yj , t),
respectively, where, for a fixed integer N â‰¥ 1,
j
def
M(u, r) = MN (u, r) = Nr + Nr Â·

u k
,
N 1/2

(u, r) âˆˆ R Ã— R+ .

(3.2)

(3.3)

Under this setup, the central limit theorem applies to the sequence
 r 
r 
1 
â€²
âˆ’ SMjâ€²
, N â‰¥ 1,
SM j
N 1/2
s
t
since, with

Mj ( rs ) âˆ’ Mjâ€² ( rt )
r  Mjâ€²  r  
r
Mj  r  
2
1
âˆ’
+
1
âˆ’
,
,
Ïƒ
(r;
N)
=
j
N 1/2
N s 
s
N
t
t
r r
Âµj (r) = Âµ(xj âˆ’ yj , r) = (xj âˆ’ yj )r, Ïƒj (r)2 = r 2 âˆ’ âˆ’
,
s t

Âµj (r; N) =

(3.4)
(3.5)

for Ïƒj (r; N), Ïƒj (r) â‰¥ 0, we have

 r 
r 
1 
â€²
Âµj (r; N) = E
âˆ’ SMjâ€²
âˆ’âˆ’âˆ’â†’ Âµj (r),
SM j
N â†’âˆ
N 1/2
s
t







r
r
1
â€²
âˆ’ SM
âˆ’âˆ’âˆ’â†’ Ïƒj (r)2 .
SM j
Ïƒj (r; N)2 = Var
â€²
1/2
j
N â†’âˆ
N
s
t

At the process level, we consider a rescaled version of Î¶ (Proposition 2.1) defined by
j
x2 k
x1 k j
def
Î¶ N (x, s) = Î¶N s Î£ Ns + Ns Â· 1/2 , Ns + Ns Â· 1/2
(3.6)
N
N
11

for all x = (x1 , x2 ) âˆˆ R2 and s âˆˆ R+ such that M1 , M2 â‰¥ 0 (recall (3.2)). We always assume
this condition M1 , M2 â‰¥ 0 on the space-time points when considering Î¶ N . See also
Remark 3.6. Then by Proposition 2.4, we have
Z Ns Y
2

 r 
 r 
 N

N
â€²
Cov Î¶ (x, s); Î¶ (y, t) =
P SM j
= SM
dr
(3.7)
â€²
j
Ns
Nt
0
j=1
Z sY
2
 r 

r
â€²
1/2
= SMjâ€²
dr
(3.8)
=
N P SM j
s
t
0 j=1

for x, y âˆˆ R2 and 0 â‰¤ s â‰¤ t < âˆ. Notice that the integral representation in (3.8) corresponds
to the â€œideal caseâ€ discussed above for (3.1). If r, s, t are fixed such that Ïƒj (r) 6= 0, the above
view for the probability in (3.1) applies to the integrand in the form of the local central limit
theorem. But due to the integral nature of the covariance function, we cannot neglect the
contribution of r â‰ˆ 0 as N â†’ âˆ. This is where the local central limit theorem can break
down. A similar issue arises if r â‰ˆ s = t under (3.8). Poisson approximations will apply
over these two ranges of r. The integral representation in (3.7) is suitable for this purpose.
Nevertheless, the central issue is the slow decorrelation.

Remark 3.1 (Edwardsâ€“Wilkinson scaling). In terms of the above approximations, the
covariance function in (3.7) has a natural generalization in other spatial dimensions d:
Z sY
Z Ns Y
d
d

r

 r 
 r 
 r 
dâˆ’2
â€²
â€²
N 1/2 P SMj
P SM j
N 2
= SMjâ€²
dr =
= SM
dr.
â€²
j
Ns
Nt
s
t
0
0
j=1
j=1
dâˆ’2

That is, introducing the factor N 2 enables the application of the local central limit theorem.
Accordingly, one could consider generalizations of the Whittaker SDEs to other spatial dimensions, starting with multi-dimensional generalizations of the triangular lattices TN . We do not
pursue these generalizations here. On the other hand, the foregoing display suggests that the
rescaled process Î¶ N defined in (3.6) can be seen as
j
j
dâˆ’2
x2 k
xd k
x1 k j
Î¶ N (x, s) = N 4 Î¶N s Î£ Ns + Ns Â· 1/2 , Ns + Ns Â· 1/2 , Â· Â· Â· , Ns + Ns Â· 1/2 ,
N
N
N
N
with d = 2. From this aspect, Î¶ is subject to the Edwardsâ€“Wilkinson scaling exponents for
interface growth models.

The following theorem summarizes the results of this section. Here and in what follows,
we write V (Î») and V â€² (Î»â€² ) for independent Poisson random variables with means Î» and Î»â€² ,
respectively. Also, (Qt ) stands for the probability semigroup of the two-dimensional standard
Brownian motion.
Theorem 3.2. Let Î¶ N be defined by (3.6). For all 0 < s â‰¤ t < âˆ and x, y âˆˆ R2 such that
either s < t or x 6= y, it holds that




lim Cov Î¶ N (x, s); Î¶ N (y, t) âˆ’ CN
N â†’âˆ
Z Z

1
Qsâˆ’1 (y â€², x) âˆ’ ln |y â€² âˆ’ y â€²â€² | Qtâˆ’1 (y â€²â€², y)dy â€²dy â€²â€²
=
(3.9)
2Ï€ R2 R2
Z tâˆ’1 Z
Qsâˆ’1 âˆ’r (z, x)Qtâˆ’1 âˆ’r (z, y)dzdr,
+
0

R2

12

where CN is given by
ln N
;
CN = C1 +
4Ï€
def

def

C1 =

Z

0

âˆ

1

2 eâˆ’ 4r âˆ’ 21[1,âˆ)(r) 
â€²
dr.
P V (r) = V (r) +
4Ï€r

(3.10)

Theorem 3.2 combines the more detailed results, Theorems 3.13 and 3.20, to be proven in
the rest of this section.
Remark 3.3. (1â—¦ ). For Î», Î»â€² âˆˆ (0, âˆ), V (Î») âˆ’ V â€² (Î»â€² ) is distributed as the Skellam distribution [29]: with the modified Bessel function of the first kind denoted by Ik ,
â€²

â€²

âˆ’(Î»+Î»â€² )

P (V (Î») âˆ’ V (Î» ) = k) = e



Î»
Î»â€²

k/2

âˆš
Ik (2 Î»Î»â€² ),

k âˆˆ Z.

(2â—¦ ). We recall once again that various rescaled limits of the covariance functions are already
obtained in [7]. See [7, Theorem 5.9, Proposition 5.28, and Proposition 5.29] in particular.
Whereas the first two results of this list are stated as complex contour integrals, [7, Proposition 5.29] appears to be similar to Theorem 3.2. These two results can be compared as follows.
By a scaling of time and (2.17), that limit from [7] can be restated as
! Z
Q(tâˆ’1)/t (0, y)
ln(N/d)
p
=
(âˆ’ ln |x âˆ’ y|2)dy
(3.11)
lim Cov[UN ; VN ] âˆ’ p
N â†’âˆ
2
Ï€d a(1 âˆ’ a)
Ï€d
a(1
âˆ’
a)
R
for fixed d > 0, a âˆˆ (0, 1), t > 1 and x âˆˆ R2 , where we use the shorthand notation:

UN = Î¶N t âŒŠ(1 âˆ’ a)dNtâŒ‹, âŒŠdNtâŒ‹ ,
p
p
âˆš

VN = Î¶N âŒŠ(1 âˆ’ a)dN + (1 âˆ’ a)dN Â· x1 âŒ‹, âŒŠdN + (1 âˆ’ a)dN Â· x1 + adN Â· x2 âŒ‹ .

Compared to (3.6) (where the map Î£ is used), the lattice points defining UN do not include
space and terms of the order O(N 1/2 ), among several other differences. See also [7, Remark
5.30, and Corollary 5.31] for results related to [7, Proposition 5.29].

Recall the notation M(xj , s) defined in (3.3). In the rest of this paper, we mostly write
N,j

b

 r 

 r 
â€²
(xj , yj ; r, u, v) = P SM (xj ,u)
= SM
,
(yj ,v)
Nu
Nv
def

 r 

r
def
â€²
1/2
= SM (yj ,v)
,
bN,j (xj , yj ; r, u, v) = N P SM (xj ,u)
u
v

N

b =

2
Y

bN,j ;

j=1

bN =

2
Y

(3.12)
bN,j .

j=1

(These probabilities involve both S and S â€² , not just one binomial variable.)
For the proofs of Theorems 3.13 and 3.20, we apply two schemes of integration which
formalize the consideration below (3.8): For 0 < â„“N < rN < 1 and 0 < Ï„N < 1, we subdivide
r âˆˆ [0, s] into the following three intervals:
r âˆˆ [0, sâ„“N ], r âˆˆ [sâ„“N , srN ], and r âˆˆ [srN , s]
13

if 0 â‰¤ t âˆ’ s â‰¤ Ï„N ,

(3.13)

or into the following two intervals:
r âˆˆ [0, sâ„“N ] and r âˆˆ [sâ„“N , s]

if t âˆ’ s > Ï„N .

(3.14)

We use the notation in (3.12). Then under (3.13), we work with the following decomposition:
Z N sâ„“N
Z srN
 N

N
N
Cov Î¶ (x, s); Î¶ (y, t) =
b (x, y; r, s, t)dr +
bN (x, y; r, s, t)dr
0
sâ„“N
(3.15)
Z Ns
N
+
b (x, y; r, s, t)dr.
N srN

The decomposition corresponding to (3.14) is
Z N sâ„“N
Z
 N

N
N
Cov Î¶ (x, s); Î¶ (y, t) =
b (x, y; r, s, t)dr +
0

s

bN (x, y; r, s, t)dr.

(3.16)

sâ„“N

Assumption 3.4. Fix Î· âˆˆ (0, 1/2). For all integers N â‰¥ 16, set â„“N = 1 âˆ’ rN = Ï„N =
N âˆ’(1/2+Î·) .

Lastly, we introduce some conditions on x1 , x2 , y1, y2 , s, t, N for the forthcoming proofs.
Definition 3.5. Fix 0 < T0 < 1 < T1 < âˆ and let Î· âˆˆ (0, 1/2) be the constant fixed in
Assumption 3.4. The primary condition (over [T 0 ,T 1 ]) refers to the following condition:
ï£±
ï£² (x1 , x2 , y1 , y2 ) : x1 , x2 , y1, y2 âˆˆ [âˆ’ 12 N Î· , 21 N Î· ];
(s, t) : T0 â‰¤ s â‰¤ t â‰¤ T1 ;
(3.17)
ï£³
N : N âˆ‹ N â‰¥ 16, âŒŠ 12 T0 N 1/2âˆ’Î· âŒ‹ â‰¥ 1.

The secondary condition (over [T 0 ,T 1 ]) refers to the following condition:
(x1 , x2 , y1, y2 ): |x1 âˆ’ y1 | âˆ§ |x2 âˆ’ y2 | â‰¥

4
N âˆ’1/2 .
T0

(3.18)

Remark 3.6. Given Î· âˆˆ (0, 1/2), the primary condition has two simple implications: First,
âŒŠ 12 T0 NâŒ‹ â‰¤ Mj , Mjâ€² â‰¤ âŒŠ 23 T1 NâŒ‹, for Mj , Mjâ€² defined in (3.2). These bounds follow from the choice
of xj , yj , s, t. Second, the lower bound of Mj , Mjâ€² and the choice of N imply Mj , Mjâ€² â‰¥ 1.

The secondary condition will be used only in the proofs of Proposition 3.12 (4â—¦ ) and Theorem 4.3. (The proof of Proposition 5.2 uses a variation of this condition.) From now on,
whenever either of the two conditions in Definition 3.5 is in use, Assumption 3.4
is imposed automatically.

3.1

Integrated Poisson approximations

In this subsection, we study the integrals
Z N sâ„“N
bN (x, y; r, s, t)dr,
0

Z

Ns

bN (x, y; r, s, t)dr

(3.19)

N srN

that appear in (3.15) and (3.16), where bN is defined in (3.12). From now on, we begin to use
the convention for constants specified at the end of Section 1.
14

Lemma 3.7. Fix 0 < T0 < 1 < T1 < âˆ and assume the primary condition (3.17). Then for
any L, R âˆˆ (0, s), we have
Z

NL

 
 â€² 



Mj r
Mj r
1 1
â€²
2
b (x, y; r, s, t) âˆ’
P V
=V
dr . NL
+
Ns
Nt
s
t
j=1
N

0

2
Y

(3.20)

and
 M â€² Nt âˆ’ r  
 M Ns âˆ’ r  
j
j
â€²
N
=V
+ Mj âˆ’ Mjâ€²
b (x, y; r, s, t) âˆ’
P V
Ns
Nt
NR
j=1




1 1
tâˆ’s
. N(s âˆ’ R)2
+ N(s âˆ’ R)
.
+
s t
t
Z

2
Y

Ns

!

dr
(3.21)

Proof. We state some preliminary results first. Write dTV for the total variance distance of
probability measures defined on the same space. The central tool of this proof is the following
bound for Poisson approximations from [4, Theorem 1]: for independent Bernoulli random
variables Î²n with E[Î²n ] = pn ,
!
!
!! 
P
 m
m
m
X
X
1 âˆ’ exp{âˆ’ m
pn } X 2
n=1
Pm
pn .
(3.22)
dTV P
Î²n âˆˆ Â· , P V
pn âˆˆ Â·
â‰¤
p
n
n=1
n=1
n=1
n=1
See also [3]. We only use the particular case that pn = p for all n, for which the bound is
reduced to (1 âˆ’ eâˆ’mp )p and so can be bounded by p. Also, we recall the following standard
result: for probability distributions Âµ1 , Âµ2 , Î½1 , Î½2 on Z,
dTV (Âµ1 âŠ— Âµ2 , Î½1 âŠ— Î½2 ) â‰¤ dTV (Âµ1 , Î½1 ) + dTV (Âµ2 , Î½2 )

(3.23)

(e.g. [14, Lemma 3.6.5 on p.147]). See [10, Proposition 2.3] for an
R improved
R bound.
1
We are ready to prove (3.20). Recall that dTV (Âµ, Î½) = 2 sup | hdÂµ âˆ’ hdÎ½| for probability
measures Âµ, Î½ on Z, where h ranges over all functions such that khkâˆ â‰¤ 1 [11, (7.2) on p.221].
By (3.22) and (3.23), for all m, mâ€² âˆˆ N, n âˆˆ Z, and p, pâ€² âˆˆ (0, 1), it holds that



p + pâ€²
â€²
â€²
â€² â€²
â€²
.
â‰¤
P Sm (p) = Sm
â€² (p ) + n âˆ’ P V (mp = V (m p ) + n
2

(3.24)

The foregoing inequality and the discrete product rule

XY âˆ’ AB = (X âˆ’ A)(Y âˆ’ B) + (X âˆ’ A)B + (Y âˆ’ B)A

(3.25)

imply that
Z
.

NL
0

Z

0

NL

 â€² 
 

2

 r 
 r  Y
Mj r
Mj r
â€²
â€²
P SM j
= SMjâ€²
âˆ’
P V
=V
dr
Ns
Nt
Ns
Nt
j=1
j=1


r 1 1
dr
+
N s t
2
Y

since the X, Y, A, B in this application of (3.25) are all bounded by 1. The required bound in
(3.20) follows.
15

The proof of (3.21) is similar. If X is binomial with parameters (M, p), then M âˆ’ X is
binomial with parameters (M, (1 âˆ’ p)). Hence,


â€²
â€²
â€²
â€²
(3.26)
P Sm (p) = Sm
â€² (p ) + n = P Sm (1 âˆ’ p) = Smâ€² (1 âˆ’ p ) + m âˆ’ m âˆ’ n .
By (3.24) and (3.25), the integral on the left-hand side of (3.21) can be .-bounded by


Z Ns 
Z N (sâˆ’R) 
Ns âˆ’ r Nt âˆ’ r
r
Nt âˆ’ Ns + r
dr =
dr.
+
+
Ns
Nt
Ns
Nt
NR
0

This is enough for the required bound in (3.21). The proof is complete.



In the sequel, the discrete product rule in (3.25) will be used repeatedly without
being mentioned. As an immediate result of Lemma 3.7, we obtain the following integrated
Poisson approximations.
Proposition 3.8. Fix 0 < T0 < 1 < T1 < âˆ. Under the primary condition (3.17),
Z

N sâ„“N

0

 â€² 

 
Mj r
Mj r
â€²
=V
dr . C(T0 , T1 )Nâ„“2N .
b (x, y; r, s, t) âˆ’
P V
Ns
Nt
j=1
2
Y

N

If, in addition, we assume 0 â‰¤ t âˆ’ s â‰¤ Ï„N , then it holds that
Z

Ns

N srN

 M â€² (Nt âˆ’ r) 
 M (Ns âˆ’ r) 
j
j
â€²
N
=V
+ Mj âˆ’ Mjâ€²
b (x, y; r, s, t) âˆ’
P V
Ns
Nt
j=1
2
Y

!

dr

. C(T0 , T1 )N(1 âˆ’ rN )2 .

Since Assumption 3.4 is in force, these integrals converge to zero as N â†’ âˆ.
In the context of Proposition 3.8 (which is under the primary condition, and hence, under
Assumption 3.4), its first inequality gives an estimate of the first integral in (3.19). To calculate
the limit of this integral of Poisson probabilities, note that Nsâ„“N â†’ âˆ for s > 0, and we need
to pass the limit of the Poisson probabilities under the integral sign. For (3.19), the additional
assumption 0 â‰¤ t âˆ’ s â‰¤ Ï„N yields an estimate by the integral of Poisson probabilities from the
second inequality of Proposition 3.8. This integral can be written as
!
Z N (sâˆ’srN ) Y
2
 M â€² (Nt âˆ’ Ns) M â€² r 
M r
j
j
j
=Vâ€²
+ Mj âˆ’ Mjâ€² dr,
(3.27)
+
P V
Ns
Nt
Nt
0
j=1
where N(s âˆ’ srN ) â†’ âˆ for s > 0. In this case, lim inf N inf (s,t) |Mj âˆ’ Mjâ€² |/N 1/2 > 0 for fixed
xj 6= yj , where (s, t) ranges over all the pairs satisfying the standing assumptions. Also, with
r in the range of integration, the parameters of V and V â€² in (3.27) are o(N 1/2 ). Hence, by
scaling, the probability indexed by j in (3.27) is zero in the limit for each j.
We use the next three lemmas to pass limits for the first integral of Poisson probabilities
from Proposition 3.8 and the one in (3.27) in the manner mentioned above. The first and
the last of these lemmas consider the property that due to the infinite divisibility, the Poisson
distributions with large parameters are eligible for normal approximations. For the local central
16

limit theorem in the first lemma, see Remark 3.16 for a discussion and also [5]. From now on,
write, for all Ïƒ âˆˆ (0, âˆ) and x âˆˆ R,
Z
n
n Ïƒ 2 Î¸2 o
x2 o
1
1
def
2
g(Ïƒ ; x) = âˆš exp âˆ’ 2 =
eâˆ’iÎ¸x exp âˆ’
dÎ¸.
(3.28)
2Ïƒ
2Ï€ R
2
Ïƒ 2Ï€

Lemma 3.9. For all Î», Î»â€² âˆˆ (0, âˆ), it holds that

sup P V (Î») = V (Î» ) + a âˆ’
â€²

â€²

aâˆˆZ



1
âˆ’Î» + Î»â€² + a
1
g
1;
.
.
(Î» + Î»â€² )1/2
(Î» + Î»â€² )1/2
(Î» + Î»â€² )

Proof. Recall that by Fourier inversions,
Z Ï€
X
1
f (a) =
f (b)eiÎ¸b dÎ¸,
eâˆ’iÎ¸a
2Ï€ âˆ’Ï€
bâˆˆZ

âˆ€ a âˆˆ Z.

(3.29)

(3.30)

â€²

Writing Ï†Î»,Î»â€² (Î¸) for E exp{iÎ¸[ V (Î») âˆ’ V (Î»â€² )]}, we obtain from (3.28) and (3.30) that



âˆ’Î» + Î»â€² + a
â€² 1/2
â€² â€²
âˆ€ a âˆˆ Z,
(Î» + Î» ) P V (Î») = V (Î» ) + a âˆ’ g 1;
(Î» + Î»â€² )1/2



 2 
Z
â€² +a
Î¸
Î¸
1
âˆ’iÎ¸ âˆ’Î»+Î»â€² 1/2
Ï†Î»,Î»â€²
e (Î»+Î» )
dÎ¸
âˆ’
exp
âˆ’
=
2Ï€ |Î¸|â‰¤Ï€(Î»+Î»â€²)1/2
(Î» + Î»â€² )1/2
2
 2
Z
â€² +a
Î¸
1
âˆ’iÎ¸ âˆ’Î»+Î»â€² 1/2
(Î»+Î»
)
e
dÎ¸
exp âˆ’
+
2Ï€ |Î¸|â‰¥Ï€(Î»+Î»â€² )1/2
2
= I3.31 + II3.31 .

(3.31)

We show that the decomposition in (3.31) implies (3.29). To bound I3.31 , consider
 

 2


iÎ¸
Î¸
Î¸
iÎ¸/(Î»+Î»â€² )1/2
= exp Î» e
âˆ’1âˆ’
exp
Ï†Î»,Î»â€²
(Î» + Î»â€² )1/2
8
(Î» + Î»â€² )1/2


 
Î¸2
iÎ¸
âˆ’iÎ¸/(Î»+Î»â€² )1/2
â€²
+
âˆ’1+
Ã— exp Î» e
(Î» + Î»â€² )1/2
8
(
 
)

2
Î¸
Î¸
= exp (Î» + Î»â€² ) cos
âˆ’1+
â€²
1/2
(Î» + Î» )
8(Î» + Î»â€² )
(

)
 
Î¸
Î¸
âˆ’
.
Ã— exp i(Î» âˆ’ Î»â€² ) sin
â€²
1/2
(Î» + Î» )
(Î» + Î»â€² )1/2
(3.32)
By the inequality
|ez1 âˆ’ ez2 | â‰¤ max{e|z1 | , e|z2 | } Â· |z1 âˆ’ z2 |,

âˆ€ z1 , z2 âˆˆ C,

and Taylorâ€™s theorem, (3.32) implies that, for all real |Î¸| â‰¤ Ï€(Î» + Î»â€² )1/2 ,




 2
3Î¸2
Î¸
|Î¸|3
Î¸
â€²
Ï†Î»,Î»â€²
âˆ’
exp
âˆ’
.
(Î»
+
Î»
)
Â·
exp
.
(Î» + Î»â€² )1/2
8
8
(Î» + Î»â€² )3/2
17

(3.33)

(3.34)

(In more detail, we have used the inequality cos(y) âˆ’ 1 + y 2 /8 â‰¤ 0, for all real |y| â‰¤ Ï€, when
bounding the exponentials from the right-hand side of (3.33).) Hence,
 2
Z
|Î¸|3
1
Î¸
dÎ¸ .
.
(3.35)
|I3.31 | .
exp âˆ’
â€²
1/2
8 (Î» + Î» )
(Î» + Î»â€² )1/2
|Î¸|â‰¤Ï€(Î»+Î»â€² )1/2
To bound II3.31 , we use the following simple inequality for any fixed a âˆˆ (0, âˆ):
 2
Z âˆ
Î¸
a
x
exp âˆ’
dÎ¸ â‰¤ C(a), âˆ€ x â‰¥ 0.
2
x

(3.36)

With a = 1/2 and x = Ï€(Î» + Î»â€² )1/2 , we get

1
|II3.31 | .
.
(Î» + Î»â€² )1/2

(3.37)

The bound in (3.29) follows upon applying (3.35) and (3.37) to (3.31).



Lemma 3.10. For all 0 < a â‰¤ b < âˆ and x, y âˆˆ R, it holds that

|b âˆ’ a| |x âˆ’ y|
+
.
a3/2
b
Proof. The required inequality follows if we apply the mean value theorem and the next two
bounds to [g(a; x) âˆ’ g(b; x)] + [g(b; x) âˆ’ g(b; y)]:
âˆš
 2


 2
d 1
d 1
1
u
2
1 âˆ’1
x
1
âˆš
âˆš
âˆš
â‰¤âˆš
â‰¤
exp
âˆ’
,
,
+
e
exp âˆ’
dv 2Ï€v
2v
du 2Ï€b
2b
2Ï€ 2v 3/2 v 3/2
2Ï€b2
|g(a; x) âˆ’ g(b; y)| .

2

by ueâˆ’u â‰¤ eâˆ’1 and ueâˆ’u â‰¤ 1 (both are valid for all u â‰¥ 0), respectively.



For the next lemma, let Î»j (r), Î»â€²j (r), Î›j (r), Î›â€²j (r) be increasing functions taking values in
Q
(0, âˆ) for all r âˆˆ [1, âˆ) and let aj , Aj âˆˆ Z. Next, define an auxiliary function g(r) = 2j=1 gj (r)
Q
by gj (r) = g(Î»j (r) + Î»â€²j (r); âˆ’Î»j (r) + Î»â€²j (r) + aj ) and G(r) = 2j=1 Gj (r) for similarly defined
heat kernels Gj (r) using Î›j , Î›â€²j , Aj in place of Î»j , Î»â€²j , aj , respectively.
Lemma 3.11. Under the above setup, the following two inequalities hold for all r âˆˆ [1, âˆ):
2


Y


P V Î»j (r) = V â€² Î»â€²j (r) + aj âˆ’ g(r)
j=1

X
1
1
+
;
â€²
â€²
[Î»i (r) + Î»i (r)][Î»j (r) + Î»â€²j (r)]1/2
j=1 [Î»j (r) + Î»j (r)]
1â‰¤i,jâ‰¤2

. Q2
2
Y

(3.38)

i6=j

|Î»j (r) âˆ’ Î›j (r)| + |Î»â€²j (r) âˆ’ Î›â€²j (r)| + |aj âˆ’ Aj |
|g(r) âˆ’ G(r)| .
Kj
[Î»j (r) + Î»â€²j (r)] âˆ§ [Î›j (r) + Î›â€²j (r)]
j=1
+

X

1â‰¤i,jâ‰¤2
i6=j

Ã—

Ki

|Î»i (r) âˆ’ Î›i (r)| + |Î»â€²i (r) âˆ’ Î›â€²i (r)| + |ai âˆ’ Ai |
[Î»i (r) + Î»â€²i (r)] âˆ§ [Î›i (r) + Î›â€²i (r)]

[Î»j (r) +

Î»â€²j (r)]1/2

1
,
âˆ§ [Î›j (r) + Î›â€²j (r)]1/2
18

(3.39)

def

where Kj = {[Î»j (1) + Î»â€²j (1)]1/2 âˆ§ [Î›j (1) + Î›â€²j (1)]1/2 }âˆ’1 + 1.
Proof. By Lemma 3.9, the left-hand side of (3.38) is .-bounded by
2
Y

X
1
1
+
gj (r).
â€²
â€²
Î»
(r)
+
Î»
(r)
Î»
(r)
+
Î»
(r)
j
i
j
i
j=1
1â‰¤i,jâ‰¤2
i6=j

Hence, (3.38) follows from the foregoing bound and the definition of gj .
The proof of (3.39) is similar. It is enough to note that by Lemma 3.10 and the assumed
monotonicity of the functions in r, for all r âˆˆ [1, âˆ),


g Î»j (r) + Î»â€²j (r); âˆ’Î»j (r) + Î»â€²j (r) + aj âˆ’ g Î›j (r) + Î›â€²j (r); âˆ’Î›j (r) + Î›â€²j (r) + Aj
|Î»j (r) + Î»â€²j (r) âˆ’ Î›j (r) âˆ’ Î›â€²j (r)|
|Î»j (r) âˆ’ Î»â€²j (r) âˆ’ aj âˆ’ Î›j (r) + Î›â€²j (r) + Aj |
.
+
[Î»j (r) + Î»â€²j (r)]3/2 âˆ§ [Î›j (r) + Î›â€²j (r)]3/2
[Î»j (r) + Î»â€²j (r)] âˆ§ [Î›j (r) + Î›â€²j (r)]
|Î»j (r) âˆ’ Î›j (r)| + |Î»â€²j (r) âˆ’ Î›â€²j (r)| + |aj âˆ’ Aj |
,
. Kj
[Î»j (r) + Î»â€²j (r)] âˆ§ [Î›j (r) + Î›â€²j (r)]
where Kj is defined below (3.39). The proof is complete.



The next proposition is the last step for the integrated Poisson approximations. Recall the
discussion below Proposition 3.8.
Proposition 3.12. Fix 0 < T0 < 1 < T1 < âˆ and let Assumption 3.4 be in force.
(1â—¦ ) For all 0 < s â‰¤ t < âˆ and x, y âˆˆ R2 ,
!
 â€² 
 

Z N sâ„“N Y
2
Mj r
1[1,âˆ)(r)
Mj r
â€²
=V
âˆ’
dr
lim
P V
N â†’âˆ 0
Ns
Nt
4Ï€r
j=1
!
Z âˆ Y
2

1
(r)
[1,âˆ)
dr.
=
P V (r) = V â€² (r) âˆ’
4Ï€r
0
j=1

(2â—¦ ) Under the primary condition over [T0 , T1 ], it holds that
 â€² 

 
Z N sâ„“N Y
2
Mj r
1[1,âˆ)(r)
Mj r
â€²
=V
âˆ’
P V
dr â‰¤ C(T0 , T1 )(1 + |x|2 + |y|2).
Ns
Nt
4Ï€r
0
j=1
(3â—¦ ) For all s = t âˆˆ (0, âˆ) and x, y âˆˆ R2 with x 6= y, we have
 â€² 

 
Z Ns Y
2
Mj r
Mj r
â€²
=V
dr = 0.
lim
P V
N â†’âˆ N sr
Ns
Nt
N j=1
(4â—¦ ) Under the primary and secondary conditions over [T0 , T1 ], and in addition, the assumption
0 â‰¤ t âˆ’ s â‰¤ Ï„N , it holds that
 
 â€² 

Z Ns Y
2
Mj r
1[1,âˆ)(r)
Mj r
â€²
P V
=V
âˆ’
dr
Ns
Nt
4Ï€r
N srN j=1

â‰¤ C(T0 , T1 ) 1 + |x|2 + |y|2 + ln |x âˆ’ y| .
19

Proof. We present the proofs of the first two statements and the last two separately.
(1â—¦ ) and (2â—¦ ). We choose
Î»j (r) =

Mj r
,
Ns

Î»â€²j (r) =

Mjâ€² r
,
Nt

Î›j (r) = Î›â€²j (r) = r,

aj = Aj = 0

in the setup of Lemma 3.11 and impose the primary condition. Then by Remark 3.6 and (3.38),
we get
 
 â€² 

2
Y
Mj r
Mj r
C(T0 , T1 )
â€²
P V
=V
âˆ’ g(r) â‰¤
, âˆ€ r âˆˆ [1, âˆ).
(3.40)
Ns
Nt
r 3/2
j=1
The required limit in (1â—¦ ) follows
Q2 from the dominated convergence theorem.
Next, notice that G(r) = j=1 g(2r; 0) = 1/(4Ï€r). Hence, by Remark 3.6, (3.39) and (3.40),
we get the following bound for all r âˆˆ [1, âˆ):
 â€² 

 
2
Y
Mj r
1
Mj r
â€²
=V
âˆ’
P V
Ns
Nt
4Ï€r
j=1
"
!
2
Y
Mjâ€²
1
Mj
â‰¤ C(T0 , T1 ) 3/2 +
âˆ’1 +
âˆ’1
r
Ns
Nt
j=1
!#
2
Mjâ€²
Mj
1 X
âˆ’1 +
âˆ’1
+ 1/2
r
Ns
Nt
j=1
!
1
1
1
â‰¤ C(T0 , T1 ) 3/2 + (1 + |x| + |y|)2 + 1/2 1/2 (1 + |x| + |y|) ,
(3.41)
r
N
r N
where the last inequality follows since by the primary condition over [T0 , T1 ],
|Mj /(Ns) âˆ’ 1| â‰¤ C(T0 , T1 )(N âˆ’1 + N âˆ’1/2 |xj |)

(3.42)

and a similar bound for |Mjâ€² /(Nt) âˆ’ 1| holds. The bound in (2â—¦ ) follows upon integrating both
sides of (3.41) over r âˆˆ [1, Nsâ„“N ]. Here, we drop a multiplicative constant that tends to zero
as N â†’ âˆ since this bound is considered for the tightness proof in Section 5.
(3â—¦ ) and (4â—¦ ). Now, we work with the alternative expressions in (3.27) for the integrals under
consideration. Choose
Mjâ€² (Nt âˆ’ Ns) Mjâ€²
=
+
r,
Nt
Nt
(3.43)
(Nt + N 1/2 tyj )(Nt âˆ’ Ns)
â€²
â€²
+ r, aj = Aj = Mj âˆ’ Mj
Î›j (r) = r, Î›j (r) =
Nt
for the setup of Lemma 3.11 and impose both the primary and secondary conditions and the
assumption that 0 â‰¤ t âˆ’ s â‰¤ Ï„N . (We remove the floor function in Mjâ€² in choosing Î›â€²j .) We
proceed with the following steps.
Step 1. First, by Remark 3.6 and (3.38), we have
!
2
M r 
 M â€² (Nt âˆ’ Ns) M â€² r 
Y
C(T0 , T1 )
j
j
j
P V
= Vâ€²
+ Mj âˆ’ Mjâ€² âˆ’ g(r) â‰¤
+
Ns
Nt
Nt
r 3/2
j=1
Mj
Î»j (r) =
r,
Ns

Î»â€²j (r)

20

for all r â‰¥ 1. Hence,
Z N (sâˆ’srN ) Y
2

M r
 M â€² (Nt âˆ’ Ns) M â€² r 
j
j
j
â€²
P V
=V
+ Mj âˆ’ Mjâ€²
+
Ns
Nt
Nt
j=1

1

!

âˆ’ g(r) dr

is bounded by C(T0 , T1 ), and in the case that s = t and x 6= y, tends to zero by dominated
convergence as N â†’ âˆ for the reason pointed out below Proposition 3.8.
R N (sâˆ’srN )
Step 2. We handle 1
|g(r) âˆ’ G(r)|dr by using (3.39). To this end, note that under the
setup in (3.43),
|Î»j (r) âˆ’ Î›j (r)| + |Î»â€²j (r) âˆ’ Î›â€²j (r)| + |aj âˆ’ Aj |
Mjâ€²
Mj
1
â‰¤r
âˆ’1 +
Â· N(t âˆ’ s) + r
âˆ’1
Ns
Nt
Nt

â‰¤ C(T0 , T1 ) Ï„N + rN âˆ’1 + rN âˆ’1/2 |xj | + rN âˆ’1/2 |yj |




â‰¤ C(T0 , T1 ) rN âˆ’1/2 + rN âˆ’1 + rN âˆ’1/2 |xj | + rN âˆ’1/2 |yj | ,

âˆ€ r â‰¥ 1,

where the second inequality uses (3.42) and the assumption 0 â‰¤ t âˆ’ s â‰¤ Ï„N , and the last one
uses N 1/2 Ï„N â‰¤ 1 by Assumption 3.4. Hence, (3.39) in the present case simplifies to
|g(r) âˆ’ G(r)| â‰¤ C(T0 , T1 )

2
Y
j=1

+ C(T0 , T1 )

N âˆ’1/2 + N âˆ’1/2 |xj | + N âˆ’1/2 |yj |

2
X
N âˆ’1/2 + N âˆ’1/2 |xj | + N âˆ’1/2 |yj |
j=1

so that

Z



r 1/2

N (sâˆ’srN )
1

|g(r) âˆ’ G(r)|dr

2
2
X
Y
(1 + |xj | + |yj |)
â‰¤ C(T0 , T1 ) (1 âˆ’ rN ) (1 + |xj | + |yj |) + (1 âˆ’ rN )1/2
j=1

j=1

â‰¤ C(T0 , T1 )(1 âˆ’ rN )

1/2

2

!

2

(1 + |x| + |y| ).

Step 3. Recall the setup in (3.43) and the assumption 0 â‰¤ t âˆ’ s â‰¤ Ï„N . We consider
Z N (sâˆ’srN )
Z N (sâˆ’srN ) Y
2
(Nt + N 1/2 tyj )(Nt âˆ’ Ns)
G(r)dr =
g 2r +
;
Nt
1
1
j=1
!
(Nt + N 1/2 tyj )(Nt âˆ’ Ns)
+ Mj âˆ’ Mjâ€² dr.
Nt

(3.44)

(3.45)

This step is where we use the secondary condition (3.18).
To bound the Gaussian densities in (3.45), we first note that the variances therein satisfy
the following bounds:
(Nt + N 1/2 tyj )(Nt âˆ’ Ns)
Nt
â€²
â‰¤ 2r + C (T0 , T1 )N(t âˆ’ s),

2r + C(T0 , T1 )N(t âˆ’ s) â‰¤ 2r +

21

(3.46)

where the primary condition (3.17) is used. For the spatial variables in the Gaussian densities,
we consider
(Nt + N 1/2 tyj )(Nt âˆ’ Ns)
+ Mj âˆ’ Mjâ€²
Nt
 
(Nt + N 1/2 tyj )(Nt âˆ’ Ns) 
xj
yj 
â‰¥
+ Ns + Ns Â· 1/2 âˆ’ 1 âˆ’ Nt + Nt Â· 1/2
Nt
N
N
1/2
1/2
1/2
= N yj (t âˆ’ s) + N s(xj âˆ’ yj ) âˆ’ 1 âˆ’ N (t âˆ’ s)yj
â‰¥ âˆ’N 1/2 Ï„N |yj | + N 1/2 s(xj âˆ’ yj ) âˆ’ 1 âˆ’ N 1/2 Ï„N |yj |
â‰¥ N 1/2 s(xj âˆ’ yj ) âˆ’ 2,

(3.47)

where the second inequality uses the assumption 0 â‰¤ t âˆ’ s â‰¤ Ï„N and the last inequality uses
the primary condition (3.17) and the definition of Ï„N in Assumption 3.4. Similarly,
âˆ’

(Nt + N 1/2 tyj )(Nt âˆ’ Ns)
âˆ’ Mj + Mjâ€² â‰¥ N 1/2 t(yj âˆ’ xj ) âˆ’ 2.
Nt

By (3.47) and the foregoing inequality, the secondary condition (3.18) implies that
2 
X
(Nt + N 1/2 tyj )(Nt âˆ’ Ns)

Nt

j=1

+ Mj âˆ’

Mjâ€²

2

1
â‰¥ NT02 |x âˆ’ y|2.
2

Recall that 1 âˆ’ rN = Ï„N . Applying (3.46) and (3.48) to (3.45), we get
)
(
Z N (sâˆ’srN )
Z N T1 Ï„N
â€²
2
C(T0 , T1 )
C (T0 , T1 )N|x âˆ’ y|
G(r)dr â‰¤
dr
exp âˆ’
r + N(t âˆ’ s)
r + N(t âˆ’ s)
1
1
)
(
Z T1 Ï„N +(tâˆ’s)
â€²
2
C(T0 , T1 )
C (T0 , T1 )|x âˆ’ y|
=
dr
exp âˆ’
r
r
1/N +(tâˆ’s)
)
(
Z (T1 +1)Ï„N /|xâˆ’y|2
â€²
C(T0 , T1 )
C (T0 , T1 )
â‰¤
dr,
exp âˆ’
r
r
0

(3.48)

(3.49)

where we have changed variable in the last two lines and the last inequality uses 0 â‰¤ tâˆ’s â‰¤ Ï„N .
Besides, since N âˆ’1 â‰¤ Ï„N â‰¤ N âˆ’1/2 â‰¤ C(T0 , T1 )|x âˆ’ y| under the secondary condition (3.18), the
last inequality implies that
Z

1

N (sâˆ’srN )


G(r)dr â‰¤ C(T0 , T1 ) 1 + ln |x âˆ’ y| .

(3.50)

Step
4. Finally, (3â—¦ ) follows from the second conclusion of Step 1, (3.44) and (3.49) (since
R
âˆ’1 âˆ’r âˆ’1
r e
dr < âˆ). As for (4â—¦ ), it is enough to prove the required inequality with the term
0+
1[1,âˆ)(r)/(4Ï€r) removed. Then we apply the other conclusion of Step 1, (3.44) and (3.50) to
the equivalent integral presented in (3.27). The proof is complete.

The following theorem summarizes the asymptotic results proven in Propositions 3.8 and 3.12.

22

Theorem 3.13. Let Assumption 3.4 be in force, and recall the notation bN in (3.12).
(1â—¦ ) For all 0 < s â‰¤ t < âˆ and x, y âˆˆ R2 ,
!
!
Z âˆ Y
Z N sâ„“N
2
 1[1,âˆ)(r)
1[1,âˆ)(r)
â€²
N
dr =
dr.
P V (r) = V (r) âˆ’
lim
b (x, y; r, s, t) âˆ’
N â†’âˆ 0
4Ï€r
4Ï€r
0
j=1
(2â—¦ ) For all s = t âˆˆ (0, âˆ) and x, y âˆˆ R2 with x 6= y,
Z Ns
bN (x, y; r, s, t)dr = 0.
lim
N â†’âˆ

3.2

N srN

Integrated normal approximations

We study the remaining integrals in (3.15) and (3.16):
Z srN
Z s
bN (x, y; r, s, t)dr,
bN (x, y; r, s, t)dr
sâ„“N

(3.51)

sâ„“N

by normal approximations. Here and in what follows, recall the notation in (3.12) for binomial
probabilities. Let us begin with the following elementary result. For a Bernoulli random variable

def 
Î²(p) with mean p, we set Ïˆp (u) = E eiuÎ²(p) = peiu(1âˆ’p) + (1 âˆ’ p)eâˆ’iup , where Î²(p) = Î²(p) âˆ’ p.
Lemma 3.14. It holds that

|Ïˆp (u)|2 = 1 âˆ’ 2p(1 âˆ’ p)(1 âˆ’ cos u),
sup sup |Ïˆp (u) âˆ’ 1| < 1.

âˆ€ p âˆˆ (0, 1), u âˆˆ R;

(3.52)
(3.53)

pâˆˆ(0,1) u:|u|â‰¤1

Proof. For (3.53), note that |Ïˆp (u) âˆ’ 1| â‰¤ p|eiu(1âˆ’p) âˆ’ 1| + (1 âˆ’ p)|eâˆ’iup âˆ’ 1|, u 7â†’ |eiu âˆ’ 1|2 =
2 âˆ’ 2 cos u is strictly increasing on [0, Ï€], and |eiÏ€/3 âˆ’ 1| = 1.

The next step is a counterpart of Lemma 3.7 in the context of normal approximations. Recall
the notation in (3.28) for Gaussian densities. Note that the next lemma is not the binomial
local central limit theorem (the de Moivreâ€“Laplace theorem), and the forthcoming application
needs the sum form (3.54) of Ïƒ 2 for the bound in (3.55). See also Remark 3.16.
Lemma 3.15. Given q, q â€² âˆˆ (0, 1) and integers M, M â€² , N â‰¥ 1, define
Âµ=

Mq âˆ’ M â€² q â€²
N 1/2

& Ïƒ2 =

M
Mâ€² â€²
q(1 âˆ’ q) +
q (1 âˆ’ q â€² ).
N
N

(3.54)

Then


â€²
â€²
sup N 1/2 P SM (q) = SM
Ïƒ2 ;
â€² (q ) + a âˆ’ g
aâˆˆZ


a
1
âˆ’
Âµ
. 1/2 2 .
1/2
N
N Ïƒ

(3.55)



(3.56)

In particular, if the primary condition (3.17) holds to ensure that Mj , Mjâ€² â‰¥ 1 (Remark 3.6)
and 0 < s â‰¤ t < âˆ, then for all r âˆˆ (0, s) and 1 â‰¤ j â‰¤ 2,
bN,j (xj , yj ; r, s, t) âˆ’ g Ïƒj (r; N)2 ; Âµj (r; N)
23

.

1
N 1/2 Ïƒj (r; N)2

.

Proof. We reconsider the proof of Lemma 3.9 and proceed with the following identity: By
(3.28), (3.30), and the definition of Âµ in (3.54), it holds that for all a âˆˆ Z,



a
â€²
â€²
Ïƒ 2 ; 1/2 âˆ’ Âµ
N 1/2 P SM (q) = SM
â€² (q ) + a âˆ’ g
N
" 
 2 2 #
M
M â€²

Z
a
Î¸
1
Ïƒ Î¸
Î¸
+iÎ¸Âµ
âˆ’iÎ¸
â€²
Ïˆq
=
e N 1/2
âˆ’
exp
âˆ’
dÎ¸
Ïˆ
âˆ’
q
2Ï€ |Î¸|â‰¤N 1/2
N 1/2
N 1/2
2
" 
 2 2 #
M
M â€²

Z
a
Ïƒ Î¸
Î¸
Î¸
1
âˆ’iÎ¸
+iÎ¸Âµ
â€²
e N 1/2
âˆ’
exp
âˆ’
dÎ¸
Ïˆ
âˆ’
Ïˆq
+
q
2Ï€ N 1/2 <|Î¸|â‰¤N 1/2 Ï€
N 1/2
N 1/2
2
 2 2
Z
a
1
Ïƒ Î¸
+iÎ¸Âµ
âˆ’iÎ¸ 1/2
+
exp âˆ’
e N
dÎ¸
2Ï€ |Î¸|â‰¥N 1/2 Ï€
2
= I3.57 + II3.57 + III3.57 .

(3.57)

The required bound in (3.55) then follows upon applying (3.63) and (3.64), to be proven below,
to (3.57).
Step 1. For I3.57 , we view
Ïˆq



Î¸
N 1/2

M

 2 2


M â€²

3Ïƒ 2 Î¸2
Ïƒ Î¸
Î¸
exp
âˆ’ exp âˆ’
, âˆ€ |Î¸| â‰¤ N 1/2 ,
Ïˆqâ€² âˆ’ 1/2
N
5
10

(3.58)

as |ez1 âˆ’ ez2 | and bound this difference in the way of (3.33). This use of (3.33) is legitimate
since we can take the logarithms of Ïˆq (Î¸/N 1/2 ) and Ïˆqâ€² (âˆ’Î¸/N 1/2 ) by (3.53).
Step 1-1. To bound the term corresponding to max{|ez1 |, |ez2 |} in (3.33), we use (3.52) and
the inequality 1 âˆ’ v â‰¤ eâˆ’v for all v â‰¥ 0. They give





M

Î¸
Î¸
Î¸2
Mq(1 âˆ’ q)Î¸2
Ïˆq
â‰¤ exp 2Mq (1 âˆ’ q) cos 1/2 âˆ’ 1 +
exp
N 1/2
5N
N
10N


2
Mq(1 âˆ’ q)Î¸
,
(3.59)
â‰¤ exp âˆ’
5N
where the last inequality holds whenever |Î¸| â‰¤ N 1/2 since cos v âˆ’ 1 + v 2 /5 â‰¤ 0 for |v| â‰¤ 1.
Plainly, the same bound with (q, M) replaced by (q â€² , M â€² ) on both sides holds.
Step 1-2. Next, for (3.58), we bound the term corresponding to |z1 âˆ’ z2 | in (3.33). We expand
Îº(iu) = Log Ïˆp (u) for u âˆˆ R around 0, where Îº denotes the cumulant of Î²(p). We have Îº(0)=0.
Also, by definition, Î²(p) has a zero mean and variance p(1 âˆ’ p), and so the first two derivatives
of u 7â†’ Îº(iu) at u = 0 are given by 0 and i2 p(1 âˆ’ p), respectively.
The next bound is for the third-order derivative of u 7â†’ Îº(iu). It is chosen to incorporate the
parameters of the Bernoulli random variables: Observe that (d/du)Îº(iu) = E[iÎ²(p)eiuÎ²(p) ]/E[eiuÎ²(p) ].
This expression implies that every higher-order derivative is a ratio where the denominator
is a power of Ïˆp (u) and the numerator is a sum of products of expectations of the form
Â±E[(iÎ²(p))â„“ eiuÎ²(p) ]. Each product carries at least one such expectation with â„“ â‰¥ 1 and so
can be bounded by E[|Î²(p)|] = 2p(1 âˆ’ p). Hence, by (3.53),
sup
u:|u|â‰¤1

d3
Îº(iu) . p(1 âˆ’ p),
du3
24

âˆ€ p âˆˆ (0, 1).

(3.60)

Up to this point, we have proved that
Log Ïˆp (u) +

p(1 âˆ’ p) 2
u . p(1 âˆ’ p)|u|3,
2

âˆ€ |u| â‰¤ 1, p âˆˆ (0, 1).

(3.61)

We remark that the factor p(1 âˆ’ p) in the bound of (3.61) will be useful.
Now, an application of the definition (3.54) of Ïƒ 2 and (3.61) shows that the term |z1 âˆ’ z2 |
in (3.33) for bounding (3.58) satisfies





Î¸
q(1 âˆ’ q) Î¸2
q â€² (1 âˆ’ q â€² ) Î¸2
â€²
M Log Ïˆq
+ M Log Ïˆqâ€² âˆ’ 1/2 +
+
2
N
N
2
N


Mâ€² â€²
|Î¸|3
|Î¸|3 M
q(1 âˆ’ q) +
q (1 âˆ’ q â€² ) = 1/2 Ïƒ 2 , âˆ€ |Î¸| â‰¤ N 1/2 ,
(3.62)
. 1/2
N
N
N
N




Î¸
N 1/2



where the last equality applies (3.54) again.
Step 1-3. To finish the proof of Step 1, we put together (3.59), the analogous bound with
(q, M) replaced by (q â€² , M â€² ), and (3.62). Then we deduce that
Ïˆq



Î¸
N 1/2

M

 2 2
 2 2
M â€²

Ïƒ Î¸
Ïƒ Î¸
|Î¸|3 2
Î¸
âˆ’ exp âˆ’
. exp âˆ’
Ïƒ , âˆ€ |Î¸| â‰¤ N 1/2 .
Ïˆqâ€² âˆ’ 1/2
N
2
5
N 1/2

We arrive at the following bound:
Ïƒ2
|I3.57 | . 1/2
N

Z

N 1/2
0



Ïƒ 2 Î¸2
Î¸ exp âˆ’
5
3



dÎ¸ =

1
N 1/2 Ïƒ 2

Z

0

N 1/2 Ïƒ



Î¸2
Î¸ exp âˆ’
5
3

Step 2. Finally, we bound II3.57 + III3.57 . Notice that


u2
4p(1 âˆ’ p)u2
2
|Ïˆp (u)| â‰¤ 1 âˆ’ 4p(1 âˆ’ p) Â· 2 â‰¤ exp âˆ’
,
Ï€
Ï€2



dÎ¸ .

1
N 1/2 Ïƒ 2

.

(3.63)

âˆ€ |u| â‰¤ Ï€,

where the first inequality follows from (3.52) and the inequality 1 âˆ’ cos u âˆ’ 2u2 /Ï€ 2 â‰¥ 0 for all
|u| â‰¤ Ï€, and the second inequality uses 1 âˆ’ v â‰¤ eâˆ’v for all v â‰¥ 0. It follows that



Z
2Î¸2 M
Mâ€² â€²
1
â€²
exp âˆ’ 2
q(1 âˆ’ q) +
q (1 âˆ’ q ) dÎ¸
|II3.57 + III3.57 | â‰¤
2Ï€ N 1/2 <|Î¸|â‰¤N 1/2 Ï€
Ï€
N
N
 2 2
 2 2
Z
Z
1
Ïƒ Î¸
1
Ïƒ Î¸
+
exp âˆ’
dÎ¸ +
exp âˆ’
dÎ¸
2Ï€ N 1/2 <|Î¸|â‰¤N 1/2Ï€
2
2Ï€ |Î¸|â‰¥N 1/2 Ï€
2
 2 2
 2
Z âˆ
Z
Ïƒ Î¸
1 âˆ
1
Î¸
â‰¤
exp âˆ’
dÎ¸ =
dÎ¸ . 1/2 2 .
exp âˆ’
(3.64)
5
Ïƒ N 1/2 Ïƒ
5
N Ïƒ
N 1/2
In (3.64), the definition (3.54) of Ïƒ 2 is used. The proof is complete.

25



Remark 3.16. The proofs of Lemmas 3.9 and 3.15 extend the methods in [16, Chapters XV
and XVI] for proving the local central limit theorem of general lattice distributions. Here, we
rely on the explicit forms of the characteristic functions to get the rates of convergence. Besides,

â€²
â€²
in contrast to (3.31), we decompose the Fourier integral for N 1/2 P SM (q) = SM
into
â€² (q ) + a
two parts in (3.57). This validates (3.61) since Ïˆ1/2 (Ï€) = 0 by (3.52). On the other hand,
although it is not clear to us whether (3.31) can be deduced from the known existing results,
[21, Theorem 9] proves the rate of convergence for sums of i.i.d. general lattice-valued random
variables (also by the Fourier analytic method). It may be possible to extend the proof in [21]
to (3.55) by elaborating its use of the absolute third moments of the random variables in the
Fourier integral decomposition. See also [27, Section 1] for a general discussion for such rates.

The next proposition proves integrated normal approximations for the integrals in (3.51).
Proposition 3.17. Fix 0 < T0 < 1 < T1 < âˆ, and assume the primary condition (3.17).
(1â—¦ ) It holds that
sup
s,t:T0 â‰¤sâ‰¤tâ‰¤T1

Z

srN
sâ„“N

bN (x, y; r, s, t) âˆ’

2
Y


C(T0 , T1 )
g Ïƒj (r)2 ; Âµj (r) dr â‰¤
.
(Nâ„“N )1/2
j=1

(3.65)

(2â—¦ ) If we add the condition t âˆ’ s > Ï„N to the supremum in (3.65) and change the upper limit
srN of the integral on the left-hand side to s, then the same bound holds.
(3â—¦ ) The suprema in (1â—¦ ) and (2â—¦ ) tend to zero as N â†’ âˆ for all x, y âˆˆ R2 .
Proof. Recall the quantities Ïƒj (r; N) â‰¥ 0 and Ïƒj (r) â‰¥ 0 defined in (3.4) and (3.5). We
write Ij (r; N) for the right-hand side of (3.56), j âˆˆ {1, 2}, and define Ïƒ(q) â‰¥ 0 by Ïƒ(q)2 =
min{Ïƒj (sq; N)2 , Ïƒj (sq)2 ; 1 â‰¤ j â‰¤ 2}. We stress that Ïƒ(q) still depends on s and t.
For the proof of the proposition, we consider the following four integrals for every choice of
(L, R) such that 0 < L â‰¤ 1/2 â‰¤ R â‰¤ 1:
Z sR
I1 (r; N)I2 (r; N)dr;
sL
Z sR

Ij (r; N)g Ïƒj â€² (r; N)2 ; Âµj â€² (r; N) dr, 1 â‰¤ j, j â€² â‰¤ 2, j 6= j â€² ;
(3.66)
sL

Z

sR

sL

2
Y
j=1

2
 Y

g Ïƒj (r; N)2 ; Âµj (r; N) âˆ’
g Ïƒj (r)2 ; Âµj (r) dr.
j=1

The proof of (1â—¦ ) below chooses (L, R) to be (â„“N , 1/2) and (1/2, rN ). The sum of the corresponding eight integrals from (3.66) bounds the integral in (1â—¦ ). For the proof of (2â—¦ ), the
integral can be bounded in the same way by using (â„“N , 1/2) and (1/2, 1).
Let us simplify the task of bounding the sum of the four integrals in (3.66) by making some
observations. First, using the explicit form of Ij (r; N) and changing variable r to q = r/s, we
can bound the sum of the first three integrals in (3.66) by the sum of the following integrals
up to a multiplicative constant C(T0 , T1 ) > 0:
Z
Z R
Z R
Z R
1
Î±(q)
dq
1 R dq
,
dq = 1/2
.
(3.67)
Î±(q)Î±(q)dq =
4
3
N L Ïƒ(q)
N
L Ïƒ(q)
L Ïƒ(q)
L
26

where Î±(q) = 1/(N 1/2 Ïƒ(q)2 ) and Ïƒ(q) (depending on s and t) is as defined at the beginning
of the proof. Also, to bound the last integral in (3.66), we use Lemma 3.10 and the estimates
|Ïƒj (sq; N)2 âˆ’ Ïƒj (sq)2 | â‰¤ 2/N and |Âµj (sq; N) âˆ’ Âµj (sq)| â‰¤ 2/N 1/2 , which gives
Z
.

R
L

Z

j=1

R

L

.

2
Y



4 Z
X
k=1



2

g Ïƒj (sq; N) ; Âµj (sq; N) âˆ’

1
1
+ 1/2
2
3/2
N[Ïƒ(q) ]
N [Ïƒ(q)2 ]
R

L

dq
N k/2 [Ïƒ(q)2 ]k/2+1

2

2
Y
j=1

+


g Ïƒj (sq)2 ; Âµj (sq) dq



1
1
+ 1/2
2
3/2
N[Ïƒ(q) ]
N [Ïƒ(q)2 ]



Â·

1
dq
[Ïƒ(q)2 ]1/2

.

(3.68)

By the preceding considerations, we focus on the integrals in (3.67) and (3.68), with L and R
to be specified, in the rest of the proof.
R s/2 R sr
R sr
(1â—¦ ). We give the proof according to the decomposition sâ„“NN = sâ„“N + s/2N of the integral under
consideration. We first consider the case L = â„“N and R = 1/2 for the setup above. In view
of the contribution of (Mj /N)(r/s)(1 âˆ’ r/s) in Ïƒj2 (r; N) and Ïƒj2 (r) and the change of variable
q = r/s, the following bound for Ïƒ(q)2 holds:
Ïƒ(q)2 â‰¥ C(T0 , T1 )q,

âˆ€ q âˆˆ (0, 1/2].

(3.69)

(The primary condition (3.17) is used to get this bound and the analogues (3.70) and (3.71)
below.) Hence, by (3.67) and (3.68),
Z 1/2
C(T0 , T1 )
C(T0 , T1 )
Î±(q)
C(T0 , T1 )
â‰¤
,
dq â‰¤
,
Î±(q)Î±(q)dq â‰¤
1/2
Nâ„“N
(Nâ„“N )
Ïƒ(q)
(Nâ„“N )1/2
â„“N
â„“N
Z 1/2 Y
2
2
 Y

C(T0 , T1 )
g Ïƒj (sq; N)2 ; Âµj (sq; N) âˆ’
g Ïƒj (sq)2 ; Âµj (sq) dq â‰¤
.
1/2
(Nâ„“
)
N
â„“N
j=1
j=1
Z

1/2

Note that these bounds are for integrals of functions exploding at q = 0.
For the second case, we take L = 1/2 and R = rN = 1 âˆ’ â„“N . The lower bound for Ïƒ(q)2 is
now taken to be
Ïƒ(q)2 â‰¥ C(T0 , T1 )(1 âˆ’ q),

âˆ€ q âˆˆ [1/2, 1).

(3.70)

In this case, the singularities in the integrals from (3.67) and (3.68) are changed to q = 1.
However, since â„“N = 1 âˆ’ rN , a change of variable with 1 âˆ’ q replaced by q shows that the
bounds in the above case apply. Putting together the bounds in the two cases yields (1â—¦ ).
Rs
R s/2 R s
(2â—¦ ). We use the decomposition sâ„“N = sâ„“N + s/2 of the integral under consideration. The
R s/2
same argument for sâ„“N in the proof of (1â—¦ ) applies in this case.
We change the argument for the second case in Step 1 by taking t âˆ’ s > Ï„N , L = 1/2 and
R = 1. By considering 1 âˆ’ sq/t = [t âˆ’ s + s(1 âˆ’ q)]/t in bounding (Mjâ€² /N)(r/t)(1 âˆ’ r/t), the
lower bound in (3.70) is replaced by
Ïƒ(q)2 â‰¥ C(T0 , T1 )[Ï„N + (1 âˆ’ q)],
27

âˆ€ q âˆˆ [1/2, 1).

(3.71)

Hence, with a translation of (1 âˆ’ q) by Ï„N in the domains of integration, we can still use the
bounds for the second case in the proof of (1â—¦ ), except that â„“N is replaced by Ï„N . Since Ï„N = â„“N
by assumption, we have proved (2â—¦ ).

(3â—¦ ). The required limits hold under Assumption 3.4. The proof is complete.
Finally, we pass limit under the integral sign by the following proposition. Note that the
first integral in (3.73) converges absolutely by the inequality 1 âˆ’ eâˆ’v â‰¤ v for all v â‰¥ 0.
Proposition 3.18. Let Assumption 3.4 be in force.
(1â—¦ ) Let 0 < s â‰¤ t < âˆ and x, y âˆˆ R2 be such that either s < t or x 6= y. Then for 1/2 < reN â‰¤ 1
with reN â†’ 1, it holds that
!
Z serN Y
2

1
(Nr)
[1,âˆ)
lim
g Ïƒj (r)2 ; Âµj (r) âˆ’
dr
N â†’âˆ sâ„“
4Ï€r
N
j=1
(3.72)

Z âˆ âˆ’1
4v
âˆ’ 1[1,âˆ)(v)
e
ln s
+
âˆ’
dv
4Ï€
4Ï€v
Z Z 0

1
Qsâˆ’1 (y â€², x) âˆ’ ln |y â€² âˆ’ y â€²â€² | Qtâˆ’1 (y â€²â€², y)dy â€²dy â€²â€²
=
2Ï€ R2 R2
(3.73)
Z tâˆ’1 Z
+
Qsâˆ’1 âˆ’r (z, x)Qtâˆ’1 âˆ’r (z, y)dzdr.
R2

0

(2â—¦ ) Fix 0 < T0 < 1 < T1 < âˆ. Under the primary condition (3.17), it holds that,
Z s Y
2

 1[1,âˆ)(Nr)
dr â‰¤ C(T0 , T1 ) 1 + |x|2 + |y|2 + ln |x âˆ’ y| .
g Ïƒj (r)2 ; Âµj (r) âˆ’
4Ï€r
sâ„“N j=1
The proof uses the following property.

Lemma 3.19. For all y â€² , y â€²â€² âˆˆ R2 with y â€² 6= y â€²â€² and T âˆˆ (0, âˆ), it holds that

Z T
Z âˆ âˆ’1
4v âˆ’ 1
e
(v)
1
[1,âˆ)
Q2r (y â€², y â€²â€²)dr =
dv âˆ’
ln |y â€² âˆ’ y â€²â€²|
4Ï€v
2Ï€
0
0
3
ln T X
+
Îµj (y â€² , y â€²â€²; T )
+
4Ï€
j=1

for error functions

(3.74)


1
âˆ’ 4v
e
âˆ’
1
(v)
[1,âˆ)
Îµ1 (y â€², y â€²â€² ; T ) = âˆ’
dv,
T
4Ï€v
â€²
â€²â€²
2
|y âˆ’y |


1
T
â€² â€²â€²
Â·
ln T,
Îµ2 (y , y ; T ) = âˆ’1(0,1)
â€²
â€²â€²
2
|y âˆ’ y |
4Ï€


T
1
â€² â€²â€²
Îµ3 (y , y ; T ) = 1(0,1)
Â·
ln |y1 âˆ’ y2 |
|y â€² âˆ’ y â€²â€²|2
2Ï€
Z

âˆ

satisfying the following limits for all 1 â‰¤ j â‰¤ 3, x, y âˆˆ R2 , and 0 < s â‰¤ t < âˆ:
Z Z
lim
Qsâˆ’1 (y â€², x) Îµj (y â€², y â€²â€²; T ) Qtâˆ’1 (y â€²â€² , y)dy â€²dy â€²â€² = 0.
T â†’âˆ

R2

R2

28

(3.75)

Proof. To see (3.74), note that by changing variables,
Z

0

T


1
eâˆ’ 4v âˆ’ 1[1,âˆ) (v)
Q2r (y , y )dr =
dv
4Ï€v
0




1
T
T
Â·
.
ln
+ 1[1,âˆ)
|y â€² âˆ’ y â€²â€²|2
4Ï€
|y â€² âˆ’ y â€²â€²|2
â€²

â€²â€²

Z

T
|y â€² âˆ’y â€²â€² |2

Hence, Îµj â€™s in (3.74) are introduced as error terms for large T /|y â€² âˆ’ y â€²â€² |2 .
Now, the convergence in (3.75) for j = 1 holds by dominated convergence. For the other
cases, let B, B â€² be two independent copies of the two-dimensional standard Brownian motion.
Then for j = 2 and T > 1,


Z Z
ln T
T
â€²
0â‰¤
Qtâˆ’1 (y â€²â€² , y)dy â€²dy â€²â€²
Qsâˆ’1 (y , x)1(0,1)
4Ï€ R2 R2
|y â€² âˆ’ y â€²â€² |2

ln T
=
P |x + Bsâˆ’1 âˆ’ y âˆ’ Btâ€²âˆ’1 | > T 1/2
4Ï€

ln T
P |x âˆ’ y + Bsâˆ’1 +tâˆ’1 | > T 1/2
=
4Ï€
ln T |x âˆ’ y| + E[|Bsâˆ’1 +tâˆ’1 |]
Â·
(3.76)
â‰¤
4Ï€
T 1/2
by the Markov inequality. Passing T â†’ âˆ in the foregoing inequality, we see that the required
limit is zero. For the required limit with j = 3, the dominated convergence theorem applies
since |Îµ3 (y â€², y â€²â€²; T )| â‰¤ ln |y â€² âˆ’ y â€²â€²| for all T > 0 and, for any Î± âˆˆ (0, 1],
Z Z
Qsâˆ’1 (y â€² , x) ln |y â€² âˆ’ y â€²â€² | Qtâˆ’1 (y â€²â€² , y)dy â€²dy â€²â€²
R2 R2


Z Z
C(Î±)
â€²
â€²
â€²â€²
.
Qsâˆ’1 (y , x) |y âˆ’ y | + â€²
Qtâˆ’1 (y â€²â€² , y)dy â€²dy â€²â€²
|y âˆ’ y â€²â€² |Î±
R2 R2
Z
â€²
Qsâˆ’1 (y â€² , x)
â‰¤ E [|x + Bsâˆ’1 âˆ’ y âˆ’ Btâˆ’1 |] + C(Î±)
R2
Z

Z
(3.77)
1
â€²â€²
â€²â€²
â€²
â€²â€²
Ã—
Qtâˆ’1 (y , y)dy + kQtâˆ’1 (Â·, y)kâˆ
dy dy < âˆ.
â€²
â€²â€² Î±
|y â€² âˆ’y â€²â€² |â‰¤1 |y âˆ’ y |
R2
The proof is complete.



Proof of Proposition 3.18. (1â—¦ ) Recall (3.5) for Ïƒj (r) and Âµj (r). Write
Z

s

2
Y

sâ„“N j=1


g Ïƒj (r) ; Âµj (r) dr =
2

=

Z

s

sâ„“N

Z



2
2 1 1
1 Y
g
âˆ’ âˆ’ ; xj âˆ’ yj dr
r 2 j=1
r s
t

sâˆ’1 (â„“âˆ’1
N âˆ’1)

Q2râ€² +sâˆ’1 âˆ’tâˆ’1 (x, y)dr â€²,

(3.78)

0

where we change variable by r â€² = r âˆ’1 âˆ’ sâˆ’1 . The foregoing integral is finite whenever s < t
or x 6= y. Hence, the proof of (1â—¦ ) for reN = 1 suffices by dominated convergence. We consider
this case in the rest of the proof of (1â—¦ ).
29

âˆ’1
Whenever N is large enough such that sâˆ’1 (â„“âˆ’1
N âˆ’1) > t , by using the Chapmanâ€“Kolmogorov
â€²
âˆ’1
equation and changing variables as r = r âˆ’ t and r = tâˆ’1 âˆ’ r â€², we can write the last integral
as
Z sâˆ’1 (â„“âˆ’1 âˆ’1) Z tâˆ’1 !
N
+
Q2râ€² +sâˆ’1 âˆ’tâˆ’1 (x, y)dr â€²
tâˆ’1

=

Z

R2

+

Z

0

Z

Qsâˆ’1 (y â€² , x)

R2

Z

tâˆ’1

0

Z

âˆ’1
sâˆ’1 (â„“âˆ’1
N âˆ’1)âˆ’t

!

Q2r (y â€², y â€²â€²)dr Qtâˆ’1 (y â€²â€² , y)dy â€²dy â€²â€²

0

(3.79)

Qsâˆ’1 âˆ’r (z, x)Qtâˆ’1 âˆ’r (z, y)dzdr.
R2

The first term on the right-hand side of (3.79) shows the integral on the left-hand side of (3.74)
âˆ’1
with T = sâˆ’1 (â„“âˆ’1
N âˆ’ 1) âˆ’ t . Recall (3.78) and Nâ„“N â†’ âˆ by Assumption 3.4. By using
âˆ’1 âˆ’1
âˆ’1 âˆ’1
âˆ’1
s â„“N âˆ¼ s (â„“N âˆ’ 1) âˆ’ t as N â†’ âˆ and then applying Lemma 3.19 to (3.79),
!
Z s
2
Y

1
(Nr)
[1,âˆ)
g Ïƒj (r)2 ; Âµj (r) âˆ’
lim
dr
N â†’âˆ sâ„“
4Ï€r
N
j=1
!
Z s Y
2
âˆ’1 âˆ’1
âˆ’1

ln[s
(â„“
âˆ’
1)
âˆ’
t
]
ln
s
N
âˆ’
g Ïƒj (r)2 ; Âµj (r) dr âˆ’
= lim
N â†’âˆ
4Ï€
4Ï€
sâ„“N j=1

Z âˆ âˆ’1
e 4v âˆ’ 1[1,âˆ)(v)
ln s
=âˆ’
+
dv
4Ï€
4Ï€v
0
Z Z

1
(3.80)
Qsâˆ’1 (y â€² , x) âˆ’ ln |y â€² âˆ’ y â€²â€²| Qtâˆ’1 (y â€²â€² , y)dy â€²dy â€²â€²
+
2Ï€ R2 R2
Z tâˆ’1 Z
Qsâˆ’1 âˆ’r (z, x)Qtâˆ’1 âˆ’r (z, y)dzdr.
+
0

R2

We have obtained (3.73) for the case reN = 1 from (3.80).
(2â—¦ ). By the primary condition (3.17), NT0 â„“N â‰¥ 1. Hence, the indicator function in the
integral under consideration can only take the value 1. We bound this integral according to
Rs
R s/2 R s
= sâ„“N + s/2 . First, consider
sâ„“N
Z

â‰¤

s/2

sâ„“N

Z

s/2

sâ„“N

2
Y


1
g Ïƒj (r)2 ; Âµj (r) âˆ’
dr
4Ï€r
j=1


1
|x âˆ’ y|2r 2
1
âˆ’
dr
exp âˆ’
2Ï€r(2 âˆ’ r/s âˆ’ r/t)
2r(2 âˆ’ r/s âˆ’ r/t)
2Ï€r(2 âˆ’ r/s âˆ’ r/t)

+ C(T0 , T1 )
â‰¤ C(T0 , T1 )(1 + |x âˆ’ y|2 ) â‰¤ C(T0 , T1 )(1 + |x|2 + |y|2),

where (3.81) uses the inequality 1 âˆ’ eâˆ’v â‰¤ v, which is valid for all v â‰¥ 0. Also,
Z

s

2
Y

s/2 j=1


g Ïƒj (r) ; Âµj (r) dr â‰¤
2

Z

s

s/2

(3.81)



|x âˆ’ y|2
1
dr
exp âˆ’
2Ï€r 2 (2/r âˆ’ 1/s âˆ’ 1/t)
2(2/r âˆ’ 1/s âˆ’ 1/t)
30

=

Z

3sâˆ’1 âˆ’tâˆ’1
|xâˆ’y|2
sâˆ’1 âˆ’tâˆ’1
|xâˆ’y|2


1 âˆ’1
e 2v dv â‰¤ C(T0 , T1 ) 1 + ln |x âˆ’ y| .
4Ï€v

The required inequality follows upon combining (3.81) and (3.82).

(3.82)


The following theorem summarizes Proposition 3.17 (3â—¦ ) and Proposition 3.18 (1â—¦ ).
Theorem 3.20. Let Assumption 3.4 be in force, and recall the notation bN in (3.12).
(1â—¦ ) For all 0 < s < t < âˆ and x, y âˆˆ R2 ,

Z s 
Z âˆ âˆ’1
e 4v âˆ’ 1[1,âˆ)(v)
1[1,âˆ) (Nr) 
ln s
lim
bN (x, y; r, s, t) âˆ’
dr +
âˆ’
dv
N â†’âˆ sâ„“
4Ï€r
4Ï€
4Ï€v
0
N
Z Z

1
=
Qsâˆ’1 (y â€² , x) âˆ’ ln |y â€² âˆ’ y â€²â€²| Qtâˆ’1 (y â€²â€² , y)dy â€²dy â€²â€²
2Ï€ R2 R2
Z tâˆ’1 Z
+
Qsâˆ’1 âˆ’r (z, x)Qtâˆ’1 âˆ’r (z, y)dzdr.
0

R2

(2â—¦ ) For all s = t âˆˆ (0, âˆ) and x, y âˆˆ R2 with x 6= y, the same limit in (1â—¦ ) holds if we change
the upper limits s of the integrals on the left-hand side to srN .

4

Convergence to the additive stochastic heat equation

In this section, we relate the limiting covariance function in Theorem 3.2 to the covariance
function of an additive stochastic heat equation. Whereas some of these connections are already
pointed out in [7], we proceed with the weak formulation.
From now on, S(R2 ) denotes the space of real-valued Schwartz functions on R2 and S â€² (R2 )
denotes the space of bounded linear functionals on S(R2 ) over R. By convention, S â€² (R2 ) is
equipped with the weak topology [25].

4.1

Weak formulations

With respect to the process Î¶ N (x, s) in (3.6), we define
Z
N
Î¶s (Ï†) =
Ï†(x)Î¶ N (x, s)dx,
xâ‰¥âˆ’N 1/2 1

Ï† âˆˆ S(R2 ).

(4.1)

Here, 1 = (1, 1). The constraint x â‰¥ âˆ’N 1/2 1 is maximal for using the Whittaker SDEs since
for any s > 0, M(xj , s) â‰¥ 0 if and only if xj â‰¥ âˆ’N 1/2 . (Recall (3.3) for the notation M(xj , s).)
In this subsection, we show some basic growth properties of the process Î¶ N (x, s) and then
translate Theorem 3.2 to a convergence result under the weak formulation.
By Proposition 2.4, the metric induced by the covariance function of Î¶s Î£(m1 , m2 ) can be
represented as follows: for every (m1 , m2 ), (mâ€²1 , mâ€²2 ) âˆˆ Z2+ and 0 â‰¤ s â‰¤ t < âˆ,
E[|Î¶s Î£(m1 , m2 ) âˆ’ Î¶t Î£(mâ€²1 , mâ€²2 )|2 ]

31

=

Z tY
2

r

 r 
â€²
P Smâ€²j
= Sm
dr
â€²
j
t
t
s j=1
#
"Z 2
Z sY
2
 r 
 r 

r

r
sY
â€²
â€²
= Sm
dr âˆ’
= Sm
dr
P Smj
âˆ’
P Smj
â€²
j
j
s
t
s
s
0 j=1
0 j=1
#
"Z 2
Z sY
2
 r 
 r 
r


r
sY
â€²
â€²
= Sm
dr âˆ’
= Sm
dr .
P Smâ€²j
âˆ’
P Smj
â€²
â€²
j
j
s
t
t
t
0 j=1
0 j=1

(4.2)

Here, the general identity in use is
Z s
Z s
Z t
f (r; s, s)ds âˆ’ 2
f (r; s, t)dr +
f (r; t, t)dr
0
0
0
Z s
 Z s

Z t
Z s
Z s
=
f (r; t; t) âˆ’
f (r; s, t)dr âˆ’
f (r; s, s)dr âˆ’
f (r; s, t)dr âˆ’
f (r; t, t)dr .
s

0

0

0

0

â—¦

Lemma 4.1. (1 ) Given 0 < r < a and integers m, n â‰¥ 0, it holds that
 1h
 r

 r 
i
âˆ‚  r
=n =
(n + 1)P Sm
= n + 1 âˆ’ nP Sm
=n .
P Sm
âˆ‚a
a
a
a
a

(4.3)

(2â—¦ ) Given T âˆˆ (0, âˆ), it holds that


E[|Î¶s Î£(m1 , m2 ) âˆ’ Î¶t Î£(m1 , m2 )|2 ] â‰¤ C(T ) k(m1 , m2 )kâˆ âˆ¨ 1 Ã— |t âˆ’ s|,

(4.4)

for all 0 â‰¤ s, t â‰¤ T and (m1 , m2 ) âˆˆ Z2+ , where k(m1 , m2 )kâˆ = max{|m1 |, |m2 |}.

Proof. To obtain (4.3), we may assume that 0 â‰¤ n â‰¤ m and then consider:

âˆ‚  r
=n
P Sm
âˆ‚a
   a   
  

r nâˆ’1 âˆ’r
m
r n
r mâˆ’n
m
r mâˆ’nâˆ’1 r
n
=
1âˆ’
+
(m âˆ’ n) 1 âˆ’
n
n
a
a2
a
a
a
a2








n+1
r
r
n
=n +
=n+1 .
P Sm
= âˆ’ P Sm
a
a
a
a

Next, we show that (4.3) implies (4.4). In the case s = 0 or m1 = m2 = 0, the required
bound holds obviously, since then the second and third terms on the right-hand side of (4.2)
with (mâ€²1 , mâ€²2 ) = (m1 , m2 ) are zero. For 0 < s â‰¤ t < âˆ and nonzero (m1 , m2 ) âˆˆ Z2+ , (4.3)
implies the following bound for the second term in (4.2) with (mâ€²1 , mâ€²2 ) = (m1 , m2 ):
Z s Y
2
2
r 

 r  Y
 r 

r
â€²
â€²
P Smj
= Smj
âˆ’
P Smj
= Sm
dr
j
s
s
s
t
0
j=1
j=1
Z s
2

h

i

r
|t âˆ’ s| X
â€²
E Sm
+ 1 dr . k(m1 , m2 )kâˆ Ã— |t âˆ’ s|.
.
j
s j=1
s
0
The third term in (4.2) with (mâ€²1 , mâ€²2 ) = (m1 , m2 ) can be bounded similarly. Hence, (4.4) holds
whenever 0 < s â‰¤ t < âˆ and (m1 , m2 ) is nonzero. We have proved (4.4).

As an application, we obtain the a.s. polynomial growth of Î¶ in the following lemma.
32

Lemma 4.2. (1â—¦ ) For all Î± âˆˆ (1, âˆ), we can find C(Î±) âˆˆ (0, âˆ) such that
"
#
|Î¶s Î£(m1 , m2 )|2Î±
E
sup
sup
< âˆ, âˆ€ T âˆˆ (0, âˆ).
C(Î±)
(m1 ,m2 )âˆˆZ2+ sâˆˆ[0,T ] 1 + k(m1 , m2 )kâˆ
(2â—¦ ) For each N â‰¥ 1, the following statement holds with probability one: the integral in (4.1)
converges absolutely for all s âˆˆ [0, âˆ) and Ï† âˆˆ S(R2 ), and Î¶ N takes values in D(R+ , S â€² (R2 )).
Proof. (1â—¦ ). We modify the proof of [12, Proposition 4.1] as follows. For any integer n â‰¥ 1,
set En = {(m1 , m2 ) âˆˆ Z2+ ; 2nâˆ’1 â‰¤ k(m1 , m2 )kâˆ < 2n }. For any Î² âˆˆ (0, âˆ) and Î± âˆˆ (1, âˆ),
"
#
|Î¶s Î£(m1 , m2 )|2Î±
E
sup
sup
Î²
(m1 ,m2 )âˆˆZ2+ sâˆˆ[0,T ] 1 + k(m1 , m2 )kâˆ
#
"
#
"
âˆ
X
X
1
â‰¤ E sup |Î¶s Î£(0, 0)|2Î± +
E sup |Î¶s Î£(m1 , m2 )|2Î± .
(4.5)
Î²(nâˆ’1)
1
+
2
sâˆˆ[0,T ]
sâˆˆ[0,T ]
n=1
(m1 ,m2 )âˆˆEn

Since Î¶ is a Gaussian process, Lemma 4.1 (2â—¦ ) is enough for the application of Kolmogorovâ€™s theorem of continuity [26, (2.1)Theorem in Chapter I]. Moreover, we can find C â€² (Î±, T ), C(Î±) such
C(Î±)
that the expected supremum in (4.5) indexed by (m1 , m2 ) is bounded by C â€² (Î±, T )k(m1, m2 )kâˆ .
We get the required result upon setting Î² = 3 + C(Î±) in (4.5).
(2â—¦ ). For xj â‰¥ âˆ’N 1/2 , s 7â†’ sN + sN Â· xj /N 1/2 is nondecreasing on [0, âˆ) and so s 7â†’ Mj is
caÌ€dlaÌ€g. For these xj â€™s, we also have 0 â‰¤ Mj â‰¤ Ns + Ns Â· |xj |/N 1/2 . Hence, by (1â—¦ ), Î¶sN (Ï†) is
absolutely convergent as an integral, for any s, and is caÌ€dlaÌ€g in s. The weak topology of S â€² (R2 )
gives the required path property of Î¶ N .

Now we extend Theorem 3.2 to a convergence under the weak formulation.
Theorem 4.3. Let Î¶ N be the S â€² (Rd )-valued processes defined by (4.1). Then it holds that

Z
 Z

N
N
lim Cov[Î¶s (Ï†1 ); Î¶t (Ï†2 )] âˆ’ CN
Ï†1
Ï†2
N â†’âˆ
Z Z

1
=
Qsâˆ’1 Ï†1 (y â€² ) âˆ’ ln |y â€² âˆ’ y â€²â€² | Qtâˆ’1 Ï†2 (y â€²â€² )dy â€² dy â€²â€²
(4.6)
2Ï€ R2 R2
Z tâˆ’1 Z
+
Qsâˆ’1 âˆ’r Ï†1 (z)Qtâˆ’1 âˆ’r Ï†2 (z)dzdr, âˆ€ Ï†1 , Ï†2 âˆˆ S(R2 ), 0 < s â‰¤ t < âˆ,
0

R2

where CN is defined in (3.10).
Proof. First, we state a preliminary bound by summarizing those in Propositions 3.8, 3.12,
3.17 and 3.18 via (3.15) and (3.16): Fix 0 < T0 < 1 < T1 < âˆ. Let the primary condition
(3.17) be in force. If 0 â‰¤ t âˆ’ s â‰¤ Ï„N , we also require the secondary condition (3.18). Then it
holds that
Z Ns

1[1,âˆ)(r)
bN (x, y; r, s, t) âˆ’
(4.7)
dr â‰¤ C(T0 , T1 ) 1 + |x|2 + |y|2 + ln |x âˆ’ y| .
4Ï€r
0
33

We show the main term of the required limit. First, recall that Theorem 3.2 is obtained by
summing the limits in Theorems 3.13 and 3.20. Next, we shift the integrand of the integral in
(3.7) by 1[1,âˆ)(r)/(4Ï€r) (as in Theorem 3.13) and define an integral IN (x, y; s, t) accordingly.
Let GN denote the set of (x, y) that
R satisfies the assumption for (4.7). By dominated convergence, we can pass the limit limN GN IN (x, y; s, t)Ï†1(x)Ï†2 (y)dxdy under the integral sign. The
limit is given by the right-hand
side of (4.6).
R
It remains to show Gâˆ IN (x, y; s, t)Ï†1(x)Ï†2 (y)dxdy â†’ 0. We consider two cases. To handle
N
the integral overR(x, y) that fails to satisfy the primary condition (3.17), note that for any p > 0
and Ï† âˆˆ S(R2 ), ([âˆ’N Î· /2,N Î· /2]2 )âˆ |Ï†(x)|dx â‰¤ C(Î·, p, Ï†)N âˆ’p . Next, let BN denote the set of (x, y)
that fails the secondary condition (3.18). Recall that the secondary condition is only required
in Proposition 3.12 (4â—¦ ) in getting (4.7). Then it is enough to note that for that integral in
Proposition 3.12,

Z Z N s
dr |Ï†1 (x)Ï†2 (y)|dxdy â‰¤ C(T0 , T1 , Ï†1 , Ï†2 )N âˆ’1/2 Â· N(1 âˆ’ rN ) = N âˆ’Î· âˆ’âˆ’âˆ’â†’ 0,
BN

N â†’âˆ

N srN

where the choice of 1 âˆ’ rN in Assumption 3.4 is used. This completes the proof.



This proof shows that it can be reinforced a bit to get the following implication.
Corollary 4.4. For all 0 < T0 < 1 < T1 < âˆ and Ï†1 (x; r, s, t), Ï†2(x; r, s, t) such that
|Ï†j (x; r, s, t)| â‰¤ C(T0 , T1 , Ï†j )/(1 + |x|n ),

âˆ€ n âˆˆ N, j âˆˆ {1, 2},

it holds that
sup
T0 â‰¤sâ‰¤tâ‰¤T1
N â‰¥16

4.2

Z Z Z

R2 R2 0

N s

1[1,âˆ)(r)
b (x, y; r, s, t) âˆ’
4Ï€r
N



drÏ†1 (x; r, s, t)Ï†2 (y; r, s, t)dxdy < âˆ.

Identification of the limit

Given X0 âˆˆ S â€² (R2 ), the additive stochastic heat equation is defined by


Z t
Z tZ
âˆ†
Xt (Ï†) = X0 (Ï†) +
Xs
Ï† ds +
Ï†(x)W (dx, dr),
2
0
0
R2

(4.8)

where W (dx, dr) is a space-time white noise. For (4.8) and in what follows, âˆ† refers to the
Laplacian (rather than the operator defined in (2.13)). The solution is
Z tZ
Xt (Ï†) = X0 [Qt (Ï†)] +
Qtâˆ’r Ï†(x)W (dx, dr),
(4.9)
0

R2

where Qt = etâˆ†/2 is the transition semigroup of the two-dimensional standard Brownian motion
and W is a space-time white noise. See [31, pp.339â€“343 in Chapter 5].
Theorem 4.3 and (4.9) suggest that the limiting process of the rescaled Whittaker SDEs is
the solution X of an additive stochastic heat equation: if X0 is independent of the space-time
white noise such that{X0 (Ï†)} is a family of centered Gaussian variables with
Z Z

1
Ï†1 (y â€² )Ï†2 (y â€²â€²) âˆ’ ln |y â€² âˆ’ y â€²â€²| dy â€² dy â€²â€² ,
(4.10)
E[X0 (Ï†1 )X0 (Ï†2 )] =
2Ï€ R2 R2
34

then for 0 < s â‰¤ t < âˆ,

 Z

Z
N
N
Ï†2
= Cov[Xsâˆ’1 (Ï†1 ); Xtâˆ’1 (Ï†2 )]
lim Cov[Î¶s (Ï†1 ); Î¶t (Ï†2 )] âˆ’ CN
Ï†1
N â†’âˆ

(4.11)

and (Xtâˆ’1 ; t > 0) is a centered Gaussian process. To be precise, recall that (4.10)
R well defines
2
2
X0 as a centered Gaussian random field indexed by S0 (R ) = {Ï† âˆˆ S(R ); Ï† = 0}. See
[19] and the references therein for a reproducing kernel approach of the construction of X0 .
Alternatively, X0 can
R 0 be
R defined as the stationary solution of the additive stochastic heat
equation: X0 (Ï†) = âˆ’âˆ R2 Qâˆ’r Ï†(x)W (dx, dr), which converges a.s. See Section 6.
Given the conditionally positive definiteness of (x, y) 7â†’ âˆ’ ln |x âˆ’ y|, the relation in (4.10)
cannot apply on the full space S(R2 ). To avoid unnecessary
technical issues from this restriction
R
of domain, first we fix Ïˆ âˆˆ S(R2 ) such that
Ïˆ
=
1
and
define a re-centering operator
R
2
2
R = RÏˆ : S(R ) â†’ S0 (R ) by RÏ† = Ï† âˆ’ ( Ï†)Ïˆ. Note that R is a projection onto S0 (R2 ):
R2 Ï† = RÏ†. Then with the Gaussian random field X0 specified above, we modify the choice of
the limiting process in (4.11) to the following S â€² (R2 )-valued continuous process:
Z tZ
Xt (Ï†) = X0 [Qt RÏ†] +
Qtâˆ’r RÏ†(x)W (dx, dr), Ï† âˆˆ S(R2 ).
(4.12)
0

R2

Here, X0 [Qt RÏ†], and hence, the process X are well-defined since the Lebesgue measure is
an invariant measure of (Qt ). Note that for Ï† âˆˆ S0 (R2 ), this Xt (Ï†) still satisfies (4.8). (For
example, [28, 5â—¦ in the proof of Theorem 2.1 on page 430] allows for a straightforward extension
beyond one dimension to this case.) By (4.11), it holds that for all Ï†1 , Ï†2 âˆˆ S(R2 ) and 0 < s â‰¤
t < âˆ,
lim Cov[Î¶sN â—¦ R(Ï†1 ); Î¶tN â—¦ R(Ï†2 )] = Cov[Xsâˆ’1 (Ï†1 ); Xtâˆ’1 (Ï†2 )].

N â†’âˆ

(4.13)

Theorem 4.5. As N â†’ âˆ, the sequence of laws of (Î¶tN â—¦ R; t > 0) converges weakly to the law
of (Xtâˆ’1 ; t > 0) as probability measures on D((0, âˆ), S â€²(R2 )), where X is defined by (4.12).
For the proof of this theorem, the convergence of finite-dimensional marginals follows readily
from (4.13). To obtain the convergence at the process level, Mitomaâ€™s theorem [20] requires
the tightness of Î¶ N (Ï†) for all fixed Ï† âˆˆ S0 (R2 ). The proof of this property is the subject of the
next section.

5

Tightness of the rescaled Whittaker SDEs

Our goal in this section is to prove that the family of laws of the continuous Gaussian processes Î¶ N (Ï†) defined by (4.1) is tight, for a fixed Ï† âˆˆ S0 (R2 ). It is enough to show that
(s, t) 7â†’ E[|Î¶sN (Ï†) âˆ’ Î¶tN (Ï†)|2 ] are uniformly HoÌˆlder continuous on compacts. The major argument appears in the proof of Lemma 5.5, where several exact identities are introduced to cancel
new divergent terms. Throughout this section, we continue to use the notations in (3.12) for
binomial probabilities.
Consider the explicit expressions of these metrics by applying the rescaling under consideration. Recall (3.6), (3.8) and (4.1). By (4.2), we have
E[|Î¶sN (Ï†) âˆ’ Î¶tN (Ï†)|2 ] = IN (s, t) âˆ’ JN (s, t) âˆ’ KN (s, t),
35

(5.1)

where
IN (s, t) =
JN (s, t) =
KN (s, t) =

Z

t

dr
s

dr

0

Z

0

dxÏ†(x)

xâ‰¥âˆ’N 1/2 1

s

Z

Z

s

dr

Z

Z

dxÏ†(x)
xâ‰¥âˆ’N 1/2 1

dxÏ†(x)
xâ‰¥âˆ’N 1/2 1

Z

dyÏ†(y)bN (x, y; r, t, t),
yâ‰¥âˆ’N 1/2 1

Z

Z

yâ‰¥âˆ’N 1/2 1

dyÏ†(y)[bN (x, y; r, s, t) âˆ’ bN (x, y; r, s, s)],

yâ‰¥âˆ’N 1/2 1

dyÏ†(y)[bN (x, y; r, s, t) âˆ’ bN (x, y; r, t, t)].

Then the job is to show that each of the three terms on the right-hand side of (5.1) satisfies
the following property for some Î± âˆˆ (0, 1]:
sup

sup

N â‰¥16 s,t:T0 â‰¤s<tâ‰¤T1

|LN (s, t)|/(t âˆ’ s)Î± < âˆ,

âˆ€ 0 < T0 < 1 < T1 < âˆ.

(5.2)

The results are presented as Propositions 5.2, 5.6, and 5.7 below. The use of uniform HoÌˆlder
continuity is only for IN ; the other two functions are uniformly Lipschitz.
Notation 5.1. Write jâˆ— for the coordinate in {1, 2} different from j âˆˆ {1, 2}.



Proposition 5.2. (5.2) is satisfied by LN = IN for Î± = 1/2.
Proof. We bound the integrand of IN (s, t), for r âˆˆ [s, t], according to r/t â‰¥ 1 âˆ’ (1/2)N âˆ’1/2
and the complementary case. The point here is that since r is bounded away from zero, we do
not need to deal with divergent re-centering constants as in Section 3.
Step 1. First, we assume the primary condition (3.17) and
r âˆˆ [s, t] such that r/t â‰¥ 1 âˆ’ (1/2)N âˆ’1/2 .

(5.3)

Under (5.3), we obtain from (3.24) and (3.26) that
 r 
  
 

 r 
r 
r 
1
â€²
P Sm
= Sm
âˆ’P V m 1âˆ’
= V â€² mâ€² 1 âˆ’
+ m âˆ’ mâ€² â‰¤
â€²
t
t
t
t
2N 1/2
(5.4)
for m = M(xj , t), mâ€² = M(yj , t), and j âˆˆ {1, 2}. To bound the foregoing Poisson probabilities,
notice that for all xj , yj âˆˆ R and t â‰¥ T0 ,
|M(xj , t) âˆ’ M(yj , t)| â‰¥ T0 N 1/2 |xj âˆ’ yj | âˆ’ 1.

(5.5)
âˆ’1/4

âˆ’1/4 (V

m
Then it follows from the elementary inequalities P(V âˆ’ V â€² â‰¥ m) â‰¤ eâˆ’N
E[eN
and ev âˆ’ 1 â‰¤ v + v 2 for all v âˆˆ [âˆ’1, 1] that the next two inequalities hold:



 

r 
r 
= V â€² M(yj , t) 1 âˆ’
+ M(xj , t) âˆ’ M(yj , t)
N 1/2 P V M(xj , t) 1 âˆ’
tn
t
o
â‰¤ 1{M (xj ,t)âˆ’M (yj ,t)â‰¥0} N 1/2 exp âˆ’ N âˆ’1/4 [M(xj , t) âˆ’ M(yj , t)]+

o
n

r
r  âˆ’1/4
âˆ’1/4
âˆ’ 1) + M(yj , t) 1 âˆ’ (eâˆ’N
âˆ’ 1)
Ã— exp M(xj , t) 1 âˆ’ (eN
t
t

36

âˆ’V â€² )

]

n
o
+ 1{M (xj ,t)âˆ’M (yj ,t)<0} N 1/2 exp âˆ’ N âˆ’1/4 [M(xj , t) âˆ’ M(yj , t)]âˆ’
n


o
r  âˆ’1/4
r
âˆ’1/4
Ã— exp M(yj , t) 1 âˆ’ (eN
âˆ’ 1) + M(xj , t) 1 âˆ’ (eâˆ’N
âˆ’ 1)
t
t
n
o
1/2
âˆ’1/4
â‰¤ N exp âˆ’ N
|M(xj , t) âˆ’ M(yj , t)|


o
n
r
r
Ã— exp 1 âˆ’ N âˆ’1/4 |M(xj , t) âˆ’ M(yj , t)| + 1 âˆ’ N âˆ’1/2 [M(xj , t) + M(yj , t)]
t
t
o
n 1
â‰¤ N 1/2 exp âˆ’ T0 N 1/4 |xj âˆ’ yj | + C(T1 ) ,
2

where the last inequality uses the primary condition (3.17), (5.3) and (5.5). Combining (5.4)
and the last inequality proves that under the primary condition (3.17) and (5.3),
1

bN,j (xj , yj ; r, t, t) â‰¤ 1 + C(T1 )N 1/2 eâˆ’ 2 T0 N

1/4 |x

j âˆ’yj |

.

(5.6)

Step 2. We assume the primary condition (3.17) and the complementary case of (5.3):
r âˆˆ [s, t] such that 1 âˆ’ r/t > (1/2)N âˆ’1/2 .

(5.7)

Then C(T0 , T1 ) â‰¤ N 1/2 Ïƒj (r; N)2 for all j âˆˆ {1, 2} (recall (3.4)). Furthermore, if
|xj âˆ’ yj | â‰¥ (4/T0 )N âˆ’1/2

for fixed j âˆˆ {1, 2},

(5.8)

then |M(xj , t)âˆ’M(yj , t)| â‰¥ C(T0 , T1 )N 1/2 |xj âˆ’yj | by (5.5). Hence, under the primary condition
(3.17), (5.7) and (5.8), Lemma 3.15 gives

bN,j (xj , yj ; r, t, t) â‰¤ g Ïƒj (r; N)2 ; C(T0 , T1 )(xj âˆ’ yj ) + C â€² (T0 , T1 ).
(5.9)
Step 3. Up to this point, we have a bound of |IN (s, t)| given by the sum of the following six
terms, up to a multiplicative constant C(T0 , T1 , Ï†) âˆˆ (0, âˆ):
Ï„1 =

Z

t

dr

Ï„2 =

t

dr

Z

2 Z t
X

dx|Ï†(x)|

j=1

dr

Z

R2

R2

s

Ï„3 =

dx|Ï†(x)|

R2

s

Z

Z

Z

j=1

2
Y

dy|Ï†(y)|

R2

Z

dx|Ï†(x)|

R2

s

2
Y


1
1/4
dy|Ï†(y)|1{1âˆ’r/tâ‰¤(1/2)N âˆ’1/2 }
1 + N 1/2 eâˆ’ 2 T0 N |xj âˆ’yj | ,

j=1

Z




g Ïƒj (r; N)2 ; C(T0 , T1 )(xj âˆ’ yj ) + 1 ,

dy|Ï†(y)|

R2




g Ïƒj (r; N)2 ; C(T0 , T1 )(xj âˆ’ yj ) + 1 Ã— N 1/2 1{|xjâˆ— âˆ’yjâˆ— |<(4/T0 )N âˆ’1/2 } ,
!
!
Z t
2
2
Y
Y
Ï„4 =
dr
N âˆ’1/2 Â·
N 1/2 ,
s

Ï„5 =

Z

j=1

t

dr

s

Ï„6 =

Z

s

t

dr

Z

j=1

([âˆ’ 21 N Î· , 21 N Î· ]2 )âˆ

Z

R2

dx|Ï†(x)|

Z

dx|Ï†(x)|

Z

dy|Ï†(y)|

R2

2
Y
j=1

dy|Ï†(y)|

([âˆ’ 12 N Î· , 21 N Î· ]2 )âˆ

2
Y
j=1

37

!

N 1/2 ,
!

N 1/2 ,

where the definition of Ï„3 uses Notation 5.1. Let us explain how these six terms arise from
bounding |IN (s, t)|. First, Ï„1 follows from (5.6). We get Ï„2 from (5.9) by enforcing (5.8) for
all j âˆˆ {1, 2}, whereas Ï„3 follows from (5.9) under (5.8) for exactly one j âˆˆ {1, 2}. Then we
need Ï„4 when (5.8) fails for all j âˆˆ {1, 2}. Now that Ï„1 , Ï„2 , Ï„3 , Ï„4 are obtained by assuming the
primary condition, Ï„5 , Ï„6 handle the failure of the primary condition.
We are ready to prove the required uniform HoÌˆlder continuity. It is immediate that
6
X
j=2

Ï„j â‰¤ C(T0 , T1 , Ï†)|t âˆ’ s|,

(5.10)

by using the fast decay property of Ï† or the property that
Rwhere Ï„2 , 2Ï„3 , Ï„5 , Ï„6 are bounded
2
dxj g(Ïƒ ; xj ) = 1 for all Ïƒ > 0. The argument in Step 1 is insufficient to yield such uniform
R
Lipschitz continuity of Ï„1 , but we can still prove
R t its HoÌˆlder continuity
R t as follows. First, by
the Cauchyâ€“Schwarz inequality with respect to s dr and the bound s dr1{1âˆ’r/tâ‰¤(1/2)N âˆ’1/2 } â‰¤
C(T0 , T1 )N âˆ’1/2 ,
Z t Z
Z
1
1/4
dr
dx|Ï†(x)|
dy|Ï†(y)|1{1âˆ’r/tâ‰¤(1/2)N âˆ’1/2 } N 1/2 eâˆ’ 2 T0 N |xj âˆ’yj |
R2

s

â‰¤

R2



C(T0 , T1 )N âˆ’1/2 N 1/2

Z

dx|Ï†(x)|

R2

â‰¤ C(T0 , T1 , Ï†)(t âˆ’ s)1/2 ,

Z

âˆ’ 21 T0 N 1/4 |xj âˆ’yj |

dy|Ï†(y)|e

R2

2 !1/2

(t âˆ’ s)1/2

R
1
1/4
where the .-inequality follows since supN N 1/4 R dxj eâˆ’ 2 T0 N |xj | < âˆ. Hence, Ï„1 . C(T0 , T1 , Ï†)(tâˆ’

s)1/2 . This HoÌˆlder continuity and (5.10) are enough for the proposition.
The main theme of this section is to bound JN . We start with an interpolation to represent
this term:
Z t Z s Z
Z
âˆ‚
JN (s, t) =
dv
dr
dxÏ†(x)
dyÏ†(y)bN (x, y; r, s, v).
(5.11)
âˆ‚v yâ‰¥âˆ’N 1/2 1
s
0
xâ‰¥âˆ’N 1/2 1
For the foregoing derivative, we change variables with N 1/2 y â€² = vN 1/2 (y + N 1/2 1):
Z


 r 
r
â€²
dyÏ†(y)
N P SM (xj ,s)
= SM (yj ,v)
,
s
v
yâ‰¥âˆ’N 1/2 1
j=1
 â€²
Y
Z
2
 r 

r 
âˆ‚ 1
y
â€²
â€²
1/2
1/2
=
=
S
.
dy
Ï†
âˆ’
N
1
N
P
S
â€²
1/2
M (xj ,s)
âŒŠN
yj âŒ‹
âˆ‚v v 2 yâ€² â‰¥0
v
s
v
j=1
âˆ‚
âˆ‚v

2
Y

1/2

(5.12)

To proceed, we differential under the integral sign and then change the variable y â€² back to y.
Hence, by (5.11) and (5.12), we get
JN (s, t) = âˆ’2JN,1 (s, t) âˆ’ JN,2(s, t) + JN,3 (s, t).

38

(5.13)

Here, since dy â€² = dyv 2 ,
Z t Z s Z
Z
ï£±
ï£´
ï£´
JN,k (s, t) =
dv
dr
dxÏ†(x)
dyv 2 Ã— aN,k
ï£´
ï£´
1/2
1/2
ï£´
s
0
xâ‰¥âˆ’N
1
yâ‰¥âˆ’N
1
ï£´
ï£´
ï£´
ï£´
ï£²
v(y + N 1/2 1) Â· âˆ‡Ï†(y)
Ï†(y)
bN (x, y; r, s, v),
for aN,1 = 3 bN (x, y; r, s, v), aN,2 =
v
v4
ï£´
ï£´
ï£´
ï£´
2
ï£´
 r 
r 
ï£´
Ï†(y) âˆ‚ Y 1/2 
ï£´
â€²
ï£´
ï£´
N
P
S
=
S
.
a
=
â€²
M (xj ,s)
N,3
mj
ï£³
v 2 âˆ‚v
s
v
mâ€² =M (y ,v),mâ€² =M (y ,v)
1

j=1

1

2

2

We handle JN,1 and âˆ’JN,2 + JN,3 separately.

Lemma 5.3. (5.2) is satisfied by LN = JN,1 for Î± = 1.
Proof. We undo the change of variables below (5.11) to rewrite JN,1 (s, t) as
Z

t

dv
s v
Z
+

Z

s

dxÏ†(x)

xâ‰¥âˆ’N 1/2 1

t

dv
v

Z

Z

dyÏ†(y)
yâ‰¥âˆ’N 1/2 1

dxÏ†(x)

xâ‰¥âˆ’N 1/2 1

Z

Z

Ns

0

dyÏ†(y)
yâ‰¥âˆ’N 1/2 1


1[1,âˆ)(r) 
N
dr b (x, y; r, s, v) âˆ’
4Ï€r

ln(Ns)
1{N sâ‰¥1} .
4Ï€

By Corollary 4.4, the first term in the foregoing equality is bounded by C(T0 , T1 , Ï†)|t âˆ’ s|. The
second term can be bounded in the same way since the assumption Ï† âˆˆ S0 (R2 ) enables the
s)
cancellation of ln(N
up to an error term that can be subdued by using the fast decay of Ï†. We
4Ï€
have proved the proposition.

For the remaining terms in (5.13) for JN , we first state some elementary results.
Lemma 5.4. Let F : R â†’ R be bounded, p âˆˆ (0, 1), and m âˆˆ Z+ .
(1â—¦ ) The independent sums Sm = Sm (p)â€™s satisfy

p E [F (Sm )] âˆ’ E [F (Sm + 1)] = E [F (Sm )] âˆ’ E [F (Sm+1 )] ,
2(1 âˆ’ p)
(1 âˆ’ p)2
1
E[F
(S
)]
+
E[F (Sm )].
E[F (Sm + 2)] = 2 E[F (Sm+2 )] âˆ’
m+1
p
p2
p2

(5.14)
(5.15)

(2â—¦ ) (Binomial integration by parts). E [Sm F (Sm )] = E[Sm ]E [F (Smâˆ’1 + 1)].
(3â—¦ ) For all Ï† âˆˆ S(R2 ), L âˆˆ [âˆ’âˆ, âˆ], v âˆˆ (0, âˆ), â„“ âˆˆ Z and j âˆˆ {1, 2}, it holds that
Z âˆ
Z âˆ



dxj Ï†(x)F M(xj , v) + â„“ =
dxj Ï† x âˆ’ â„“ej /(vN 1/2 ) F M(xj , v) ,
L

L+â„“/(vN 1/2 )

where {e1 , e2 } is the standard basis of R2 .

Proof. Conditioning Sm+1 on Sm yields (5.14). To get (5.15), note that
1
1âˆ’p
E[F (Sm + 1)] = E[F (Sm+1 )] âˆ’
E[F (Sm )]
p
p
39

(5.16)

by rearranging
(5.14), and then iterate
the identity in (2â—¦ ) is equivalent to

 Next, mâˆ’1âˆ’j
P
Pmâˆ’1 (5.16).
m
m j
mâˆ’1 j
mâˆ’j
jF (j) = mp j=0
p (1 âˆ’ p)
F (j + 1). For (3â—¦ ), observe that
j=1 j p (1 âˆ’ p)
j
M(xj , a) + â„“ = M(xj + â„“/(aN 1/2 ), a) by (3.3), and then change variables.

Lemma 5.5. (5.2) is satisfied by LN = âˆ’JN,2 + JN,3 for Î± = 1.
Proof. We divide the proof into a few steps. Step 1 is for JN,2 , whereas we need Steps 2,
2-1â€“2-2 to handle JN,3 . A summary is given in Step 3 to complete the proof.
Step 1. According to (y + N 1/2 1) Â· âˆ‡Ï†(y) = y Â· âˆ‡Ï†(y) + N 1/2 divÏ†(y), we can write
JN,2 (s, t) = JN,2,1(s, t) + JN,2,2 (s, t).

(5.17)

Here,
Z
ï£±
ï£´
ï£² JN,2,j (s, t) =
ï£´
ï£³

t

s

dv
v

Z

s

dr
0

Z

dxÏ†(x)

xâ‰¥âˆ’N 1/2 1

for aN,2,1 = y Â· âˆ‡Ï†(y)bN (x, y; r, s, v),

Z

dyaN,2,j
yâ‰¥âˆ’N 1/2 1

aN,2,2 = N 1/2 divÏ†(y)bN (x, y; r, s, v).

Since y 7â†’ y Â· âˆ‡Ï†(y) âˆˆ S0 (R2 ) by integration by parts, the proof in Lemma 5.3 shows that (5.2)
for LN = JN,2,1 and Î± = 1 holds. We handle JN,2,2(s, t) in Step 3.
In the rest of this proof, we write RN,j = RN,j (xjâˆ— , yjâˆ— ; r, s, v) for a function such that
sup

sup

N âˆˆN s,vâˆˆ[T0 ,T1 ]

Z

0

s

dr

Z

âˆ

dxjâˆ—

âˆ’N 1/2

Z

âˆ

dyjâˆ— RN,j (xjâˆ— , yjâˆ— ; r, s, v)bN,jâˆ— (xjâˆ— , yjâˆ— ; r, s, v) < âˆ.

âˆ’N 1/2

(Recall Notation 5.1 for the index jâˆ— .) The â€œremainderâ€ RN,j may change from term to term
unless otherwise specified.
Step 2. We consider JN,3 in Steps 2â€“4. First, we compute the derivative
in its definition. By

r
â—¦
â—¦
Lemma 4.1 (1 ) and then Lemma 5.4 (2 ) with Sm (p) = SM (xj ,s) s ,
 r 
r 
âˆ‚ 1/2 
â€²
= Sm
N P SM (xj ,s)
â€²
j
mâ€²j =M (yj ,v)
âˆ‚v
s
v




r 
N 1/2

=
+1 1
E SM (xj ,s)
r
â€²
SM (xj ,s) ( rs )+1=SM
v
s
(yj ,v) ( v )


r 
N 1/2
âˆ’
1
E SM (xj ,s)
r
â€²
SM (xj ,s) ( rs )=SM
v
s
(yj ,v) ( v )
 r 
r
N 1/2 M(xj , s)r 
â€²
=
+ 2 = SM
P SM (xj ,s)âˆ’1
(yj ,v)
vs
s
v

 r 


1/2
N M(xj , s)r
r
â€²
âˆ’
+ 1 = SM
P SM (xj ,s)âˆ’1
(yj ,v)
vs
s
v





1/2
N
r
r
â€²
+
+ 1 = SM
P SM (xj ,s)
(yj ,v)
v
s
v
= aN,3,j,1(xj , yj ; r, s, v) âˆ’ aN,3,j,2(xj , yj ; r, s, v),
40

(5.18)

where the last equality applies (5.14) for F (n) = P(SM (xj ,s)âˆ’1 ( rs ) + 2 = n) and Sm (p) =
r
â€²
SM
(yj ,v) ( v ) so that
 r 

r
M(xj , s)
â€²
+ 2 = SM
Ã— N 1/2 P SM (xj ,s)âˆ’1
(yj ,v)
Ns
s
v
 r 



M(xj , s)
r
â€²
1/2
âˆ’N Ã—
+ 2 = SM (yj ,v)+1
,
Ã— N P SM (xj ,s)âˆ’1
Ns
s
v





r
r
1
â€²
+ 1 = SM
.
aN,3,j,2(xj , yj ; r, s, v) = Ã— N 1/2 P SM (xj ,s)
(yj ,v)
v
s
v

aN,3,j,1(xj , yj ; r, s, v) = N Ã—

Note that aN,3,j,k are written out this way to make clear the property that limN M(xj , s)/(Ns) =
1. By the definition of JN,3 and (5.18), we have shown that
JN,3 (s, t) =
2 Z âˆ
X
k=1

2 Z
X
j=1

âˆ’N 1/2

t

dv

s

Z

s

dr

0

dxj Ï†(x)

Z

Z

âˆ

âˆ’N 1/2

dxjâˆ—

Z

âˆ
âˆ’N 1/2

âˆ

âˆ’N 1/2

dyjâˆ—
!

(5.19)

dyj Ï†(y)aN,3,j,k (xj , yj ; r, s, v) bN,jâˆ— (xjâˆ— , yjâˆ— ; r, s, v).

To bound JN,3 (s, t) according to (5.19), we consider the following two sets of integrals
separately in the next two steps:
Z âˆ

Z âˆ
dxj Ï†(x)
dyj Ï†(y)aN,3,j,k (xj , yj ; r, s, v); j = 1, 2 , k = 1, 2.
(5.20)
âˆ’N 1/2

âˆ’N 1/2

Step 3. For the set in (5.19) with k = 2, applying Corollary 4.4 as in the proof of Lemma 5.3
yields that
Z âˆ
Z âˆ
dxj Ï†(x)
dyj Ï†(y)aN,3,j,2(xj , yj ; r, s, v) = RN,j , âˆ€ j âˆˆ {1, 2}.
(5.21)
âˆ’N 1/2

âˆ’N 1/2

In more detail for (5.21), the binomial probabilities in aN,3,j,2 differ slightly from those in
â€²
Corollary 4.4 since those in aN,3,j,2 are for events of the form {Sm + 1 = Sm
â€² } rather than {Sm =
â€²
Sm
â€² }. However, the proof of the corollary relies on the bounds obtained in Sections 3.1 and 3.2,
and these bounds carry over to the present case after slight modifications: See the algebra of
Step 3 of the proof of Proposition 3.12 up to (3.48). The other changes are straightforward.
Step 4. In this step, we consider the set of integrals in (5.20) with k = 1. In contrast to aN,3,j,2,
each of the two terms defining aN,3,j,1 as a difference is of a larger order in N. We aim to let
aN,3,j,1 (after appropriate integrations according to (5.19)) and JN,2,2 (still unsettled) cancel
each other. Then the task is to get an estimate of aN,3,j,1 that can be used to match JN,2,2 .
We begin by simplifying the integrals in (5.20) with k = 1, in view of the property that there
are additional Â±1 in the numbers of summands in the random sums defining aN,3,j,1. These
unwanted integers can be removed by using Lemma 5.4 (3â—¦ ) to translate variables:
Z âˆ
Z âˆ
dxj Ï†(x)
dyj Ï†(y)aN,3,j,1(xj , yj ; r, s, v)
âˆ’N 1/2

âˆ’N 1/2

41

Z


M(xj , s) + 1
ej 
Ã—Ï† x+
Ns
sN 1/2
âˆ’N 1/2 âˆ’ 11/2
sN
Z âˆ
 r 

r 
â€²
+ 2 = SM
Ã—
dyj Ï†(y) Ã— N 1/2 P SM (xj ,s)
(yj ,v)
s
v
âˆ’N 1/2
Z âˆ


M(xj , s) + 1
ej
âˆ’N
dxj
Ã—Ï† x+
Ns
sN 1/2
âˆ’N 1/2 âˆ’ 11/2
sN
Z âˆ
 r 


r 
ej 
â€²
1/2
+
2
=
S
dyj Ï† y âˆ’
Ã—
N
P
S
Ã—
M (xj ,s)
M (yj ,v)
vN 1/2
s
v
âˆ’N 1/2 + 11/2
vN
Z

N 1/2 âˆ
M(xj , s) + 1
ej 
=
dxj
Ã—Ï† x+
v
Ns
sN 1/2
âˆ’N 1/2 âˆ’ 11/2
sN
Z âˆ
h

ej i
vN 1/2
Ã—
dyj Ï†(y) âˆ’ Ï† y âˆ’
1/2
vN
1/2
âˆ’N

 r 
r
â€²
Ã— N 1/2 P SM (xj ,s)
+ 2 = SM
+ RN,j .
(yj ,v)
s
v
=N

âˆ

dxj

(5.22)

(5.23)

Let us explain (5.23). The two terms defining the right-hand side of (5.22) as a difference
are not the same only for the integrations with respect to yj , and they share the same binomial
e
probability. So we extract a discrete partial derivative [Ï†(y) âˆ’ Ï†(y âˆ’ vN j1/2 )]vN 1/2 from this
difference, as shown in (5.23). Additionally, in (5.23), RN,j arises from taking the difference of
the ranges of yj in (5.22) and using the fast decay property of Ï†.
In the rest of Step 4, we show that the first term in (5.23) can be used to cancel JN,2,2
left unsettled in Step 1. The plan is to reduce this term in (5.23) to an integral showing only
â€²
binomial probabilities of the form P(Sm = Sm
â€² ), now that these probabilities enter JN,2,2 .
To this end, we apply the higher-order expansion (5.15), and then we remove +2 and +1 in
the numbers of summands on the right-hand side of (5.15) by changing variables according to
Lemma 5.4 (3â—¦ ). (The latter is similar to how we obtain (5.22).)
In Steps 4-1 and 4-2 below, we consider (5.23) for 1 > r/s â‰¥ 1/2 and r/s < 1/2 separately.
Step 4-1. We restrict our attention to r such that 1 > r/s â‰¥ 1/2. This condition on r is used
to bound away from zero the denominators (r/s)2 in aN,3,j,1,k defined below.
To lighten notation for the application of (5.23), we write
Z âˆ

 r 
h

ej i
1/2
1/2
â€²
.
(5.24)
vN
Ã—
N
P
n
=
S
Fe(n) =
dyj Ï†(y) âˆ’ Ï† y âˆ’
M (yj ,v)
vN 1/2
v
âˆ’N 1/2
Second, we apply the method outlined before Step 4-1, with p = r/s, m = M(xj , s), and the
notation aN,3,j,1,k = aN,3,j,1,k (x, yjâˆ— ; r, s, v) defined by

h 
 r i
ej  1
M(xj , s) âˆ’ 1
e
,
Ã—Ï† xâˆ’
E F SM (xj ,s)
aN,3,j,1,1(x, yjâˆ— ; r, s, v) =
Ns
sN 1/2 (r/s)2
s
 r i
M(xj , s)
2(1 âˆ’ r/s) h e 
aN,3,j,1,2(x, yjâˆ— ; r, s, v) = (âˆ’1) Ã—
,
Ã— Ï†(x)
E F SM (xj ,s)
Ns
(r/s)2
s

 r i
ej  (1 âˆ’ r/s)2 h e 
M(xj , s) + 1
.
Ã—Ï† x+
E
F
S
aN,3,j,1,3(x, yjâˆ— ; r, s, v) =
M
(x
,s)
j
Ns
sN 1/2
(r/s)2
s
42

These two considerations yield the next two equalities:
Z âˆ
Z âˆ
dxj Ï†(x)
dyj Ï†(y)aN,3,j,1(xj , yj ; r, s, v) âˆ’ RN,j
âˆ’N 1/2
âˆ’N 1/2
Z
r 
i

N 1/2 âˆ
M(xj , s) + 1
ej  h e 
S
F
=
+
2
E
dxj
Ã—Ï† x+
M (xj ,s)
v
Ns
sN 1/2
s
âˆ’N 1/2 âˆ’ 11/2
sN
Z
Z
N 1/2 âˆ
N 1/2 âˆ
dxj aN,3,j,1,1 +
=
dxj aN,3,j,1,2
v
v
âˆ’N 1/2 + 11/2
âˆ’N 1/2
sN
Z
N 1/2 âˆ
+
dxj aN,3,j,1,3
v
âˆ’N 1/2 âˆ’ 11/2
sN
 r i
h 
1/2 Z âˆ
N
=
dxj Ï†N (x; r, s, v)E Fe SM (xj ,s)
v
s
âˆ’N 1/2
1
Z
Z
1/2
1/2
N 1/2 âˆ’N + sN 1/2
N 1/2 âˆ’N
âˆ’
dxj aN,3,j,1,3.
dxj aN,3,j,1,1 +
v
v
âˆ’N 1/2 âˆ’ 11/2
âˆ’N 1/2

(5.25)

(5.26)

(5.27)

sN

For (5.27), to sum the integrands in (5.26) with the expectations excluded, we write

ej  1
M(xj , s)
2(1 âˆ’ r/s)
M(xj , s) âˆ’ 1
Ã—Ï† xâˆ’
âˆ’
Ã— Ï†(x)
Ï†N (x; r, s) =
1/2
2
Ns
sN
(r/s)
Ns
(r/s)2


ej
(1 âˆ’ r/s)2
M(xj , s) + 1
Ã—Ï† x+
.
+
Ns
sN 1/2
(r/s)2
def

Recalling (5.24), we obtain from (5.27) that
Z âˆ
Z âˆ
dxj Ï†(x)
dyj Ï†(y)aN,3,j,1(xj , yj ; r, s, v)
âˆ’N 1/2
âˆ’N 1/2
Z
Z âˆ
h

N 1/2 âˆ
ej i
=
dxj Ï†N (x; r, s)
vN 1/2
dyj Ï†(y) âˆ’ Ï† y âˆ’
1/2
v
vN
âˆ’N 1/2
âˆ’N 1/2
 r 

r
â€²
= SM
+ RN,j .
Ã— N 1/2 P SM (xj ,s)
(yj ,v)
s
v

(5.28)

(5.29)

Here, the new contribution to the RN,j in (5.29) comes from the last two terms in (5.27): We
use the condition r/s â‰¥ 1/2 to bound the denominators (r/s)2 in aN,3,j,1,1 and aN,3,j,1,3 away
from zero. The fast decay property of Ï† is also used.
Let us approximate Ï†N and show two more RN,j -terms in (5.29). First, note that âˆ‚xj Ï† âˆˆ
S(R2 ), and the sum of the coefficients of the expectations in (5.15) is 1. By these properties,
(3.42) and r/s â‰¥ 1/2, an approximation of Ï†N by Ï† with an O(1/N 1/2 )-error holds:
C(T0 , T1 , Ï†, n)
, âˆ€ n âˆˆ N.
(5.30)
N 1/2 (1 + |x|n )
R
e
Next, to get the two RN,j -terms, we first use the mean-zero property, dy[Ï†(y)âˆ’Ï†(yâˆ’ vN j1/2 )] =
0. So the first term in (5.29) is not changed after we subtract 1[1,âˆ) (r)/(4Ï€r). Then we apply
0
Corollary 4.4 to this re-centered term: Replacing Ï†N by Ï†N results in an RN,j -term, thanks to
0

0

Ï†N (x; r, s) = Ï†(x) + Ï†N (x; r, s), where |Ï†N (x; r, s)| â‰¤

43

0

e

j
)]vN 1/2
the bounds for Ï†N in (5.30). We get another RN,j -term from replacing [Ï†(y)âˆ’Ï†(yâˆ’ vN 1/2
with âˆ‚yj Ï†(y), since their difference can be bounded uniformly in v âˆˆ [s, t] and T0 â‰¤ s â‰¤ t â‰¤ T1
0
in the same way as Ï†N .
Our conclusion of Step 4-1 is as follows. By the observations in the last paragraph, (5.29),
and (5.30), the following estimate holds for all r and v such that r/s â‰¥ 1/2 and s â‰¤ v â‰¤ t:
Z âˆ
Z âˆ
dxj Ï†(x)
dyj Ï†(y)aN,3,j,1(xj , yj ; r, s, v)
âˆ’N 1/2
âˆ’N 1/2
(5.31)
Z
Z âˆ
N 1/2 âˆ
=
dxj Ï†(x)
dyj âˆ‚yj Ï†(y)bN,j (xj , yj ; r, s, v) + RN,j .
v
âˆ’N 1/2
âˆ’N 1/2

Step 4-2. For the case r/s < 1/2 complementary to that considered in Step 4-1, we turn to
â€²
â€²
(3.26) to change parameters of Sm (p) and Sm
â€² (p ) and consider probabilities of Sm (1 âˆ’ p) and
â€²
â€²
Sm
â€² (1 âˆ’ p ) alternatively. This replacement is reversible. In this way, the argument from (5.25)
to (5.29) applies similarly.
In more detail, the modification of Step 4-1 begins with the following replacement for (5.23)
from using (3.26):
 r 

r
â€²
+ 2 = SM
P SM (xj ,s)
(yj ,v)
v

s r 


(5.32)
r
â€²
= P SM (xj ,s) 1 âˆ’
+ M(yj , v) âˆ’ M(xj , s) = SM
1
âˆ’
+
2
.
(yj ,v)
s
v
Then we modify Fe in (5.24) such that the binomial probability is replaced by



r
P SM (xj ,s) 1 âˆ’
+ M(yj , v) âˆ’ M(xj , s) = n .
s

The condition r/s < 1/2 ensures that the denominators in the analogues of aN,3,j,1,k satisfy
(1 âˆ’ r/v)2 â‰¥ (1/2)2 for all s â‰¤ v â‰¤ t. In the corresponding analogue of (5.29), we reverse the
replacements by writing



r 
r
â€²
+ M(yj , v) âˆ’ M(xj , s) = SM
1
âˆ’
P SM (xj ,s) 1 âˆ’
(yj ,v)
v

r s
 r 
(5.33)
â€²
= P SM (xj ,s)
= SM (yj ,v)
.
s
v

Hence, for the present case, we have the same estimate in (5.31), except that the applicable r
and v now have to satisfy r/s < 1/2 and s â‰¤ v â‰¤ t.
Step 5. Finally, we apply (5.21), (5.31), and the analogue of (5.31) from Step 4-2 to the sum
over j âˆˆ {1, 2} in (5.19). Since divÏ†(y) = âˆ‚y1 Ï†(y) + âˆ‚y2 Ï†(y), it follows that
e N (s, t),
JN,3(s, t) = JN,2,2 (s, t) + R

(5.34)

e N (s, t)| â‰¤ C(T0 , T1 , Ï†)(t âˆ’ s) for all T0 â‰¤ s â‰¤ t â‰¤ T1 by the definition of RN,j â€™s in the
where |R
last paragraph before Step 2. By (5.17) and the validity of (5.2) for LN = JN,2,1 and Î± = 1
from Step 1, (5.34) is enough for the proof of the lemma.

By (5.13), Lemmas 5.3 and 5.5 can be summarized as the following proposition.
44

Proposition 5.6. (5.2) for LN = JN and Î± = 1 holds.
The same result holds for KN by an almost identical argument if we restart from (5.11). We
omit the details.
Proposition 5.7. (5.2) for LN = KN and Î± = 1 holds.

6

Stationary additive stochastic heat equation

In this section, we collect some basic results for the stationary additive stochastic heat equation
which are mentioned in Section 4, since they seem difficult to find in the literature.
Let W be a two-sided space-time white noise. For any Ï† âˆˆ L2 (R2 , dx), W (Ï†) is a two-sided
Brownian motion with W0 (Ï†) = 0 and E[W1 (Ï†)2 ] = E[Wâˆ’1 (Ï†)2 ] = kÏ†k2L2(R2 ,dx) . An inspection
of the proof of Proposition 3.18, especially (3.79), shows that, without the re-centering function,
we would obtain the following divergent integral instead of the first integral in (3.9):
Z âˆ

Z Z
â€²
â€²
â€²â€²
Qtâˆ’1 (y , x)
Q2r (y , y )dr Qsâˆ’1 (y â€²â€² , y)dy â€²dy â€²â€² .
R2

R2

0

e0 (Ï†) =
Then at least formally, the initial condition X0 below (4.10) needs to be replaced by X
R0 R
Qâˆ’r Ï†(x)W (dx, dr) so that the process corresponding to (4.9) is
âˆ’âˆ R2
Z t Z
e
Xt (Ï†) =
Qtâˆ’r Ï†(x)W (dx, dr).
(6.1)
âˆ’âˆ

R2

The process in (6.1) is an analogue of the classical stationary solution of the Ornsteinâ€“Uhlenbeck
process. The next proposition shows that it is well-defined whenever Ï† âˆˆ S0 (R2 ).

Proposition 6.1. For every Ï† âˆˆ S0 (R2 ), the improper stochastic integral in (6.1) converges
a.s. for any fixed t â‰¥ 0 and, as a process, has the same finite-dimensional marginals as X(Ï†)
defined by (4.12). In particular, (Xt ; t â‰¥ 0) as an S â€² (R2 )-valued process is stationary.
e note that, for âˆ’âˆ < âˆ’S â‰¤ âˆ’T â‰¤ 0 â‰¤ t < âˆ,
Proof. To get the first property of X,
Z t Z

Z t Z
Cov
Qtâˆ’r Ï†(x)W (dx, dr);
Qtâˆ’r Ï†(x)W (dx, dr)
âˆ’S R2
âˆ’T R2
Z T +t

Z Z
=
Ï†(x)Ï†(y)
Q2r (x, y)dr dxdy
R2 R2
0
 

Z Z
Z âˆ
1
dr dxdy
Ï†(x)Ï†(y)
Q2r (x, y) âˆ’ 1[1,âˆ)(r)
âˆ’âˆ’âˆ’â†’
T â†’âˆ
4Ï€r
R2 R2
0

(6.2)

by dominated convergence since Ï† âˆˆ S0 (R2 ) and 1 âˆ’ eâˆ’u â‰¤ u for all u â‰¥ 0. The improper
stochastic integral in (6.1) converges in L2 (P) by (6.2), and so, almost surely by the martingale
convergence theorem as in the proof of Proposition 2.1.
e
To see that X(Ï†) and X(Ï†)
have the same finite-dimensional marginals, we use Lemma 3.19
to rewrite the log kernel in the definition (4.10) of X0 . For all 0 â‰¤ s â‰¤ t < âˆ,
Cov[Xs (Ï†); Xt (Ï†)]

45



â€²â€²
â€²
â€²â€²
Qs (y , x) âˆ’ ln |y âˆ’ y | Qt (y , y)dy dy dxdy
Ï†(x)Ï†(y)
R2 R2
R2 R2
Z s Z

Z
Ï†(x)Ï†(y)
Qsâˆ’r (z, x)Qtâˆ’r (z, y)dzdr dxdy
R2 R2
0
R2
Z Z

Z Z
Z T
â€²
â€² â€²â€²
â€²â€²
â€²
â€²â€²
Ï†(x)Ï†(y)
Qs (y , x)
= lim
Q2r (y , y )drQt (y , y)dy dy dxdy
T â†’âˆ R2 R2
R2 R2
0
Z s Z

Z Z
+
Ï†(x)Ï†(y)
Qr (z, x)Qtâˆ’s+r (z, y)dzdr dxdy
R2 R2
0
R2
Z T +s

Z Z
Ï†(x)Ï†(y)
Qtâˆ’s+2r (x, y)dr dxdy
= lim
T â†’âˆ R2 R2
0
Z s Z

Z t Z
= lim Cov
Qsâˆ’r Ï†(x)W (dx, dr);
Qtâˆ’r Ï†(x)W (dx, dr) ,

1
=
2Ï€
Z
+

Z

T â†’âˆ

Z

Z

âˆ’T

Z

â€²

â€²

R2

âˆ’T

â€²â€²

R2

where in the second equality, we use Lemma 3.19, the assumption Ï† âˆˆ S0 (R2 ), and the domies (Ï†); X
et (Ï†)],
nated convergence theorem. The last equality shows that Cov[Xs (Ï†); Xt (Ï†)] = Cov[X
which is enough for the required identity in finite-dimensional marginals.
Finally, given Ï†1 , Ï†2 âˆˆ S0 (R2 ), Cov[Xt (Ï†1 ); Xt (Ï†2 )] is given by (6.2) with Ï†(x)Ï†(y) replaced
by Ï†1 (x)Ï†2 (y). Hence, Cov[Xt (Ï†1 ); Xt (Ï†2 )] does not depend on t. This proves the stationarity
of X.


7

References

[1] BarabaÌsi, A.-L. and Stanley, H. E. (1995). Fractal Concepts in Surface Growth.
Cambridge University Press. doi:10.1017/CBO9780511599798
[2] Barbour, A. D. (1987). Asymptotic expansions in the Poisson limit theorem. Annals of
Probability 15 748â€“766. doi:10.1214/aop/1176992169
[3] Barbour, A. D. and Eagleson, G. K. (1983). Poisson approximation for some
statistics based on exchangeable trials. Advances in Applied Probability 15 585â€“600.
doi:10.2307/1426620
[4] Barbour, A. D. and Hall, P. (1984). On the rate of Poisson convergence. Mathematical Proceedings of the Cambridge Philosophical Society 95 473â€“480.
doi:10.1017/S0305004100061806
[5] Barbour, A. D., RoÌˆllin, A. and Ross, N. (2019). Error bounds in local limit theorems
using Steinâ€™s method. Bernoulli 25, 1076â€“1104. doi:10.3150/17-BEJ1013
[6] Borodin, A. and Corwin, I. (2014). Macdonald processes. Probability Theory and Related Fields 158 225â€“400. doi:10.1007/s00440-013-0482-3
[7] Borodin, A., Corwin, I. and Ferrari, P. L. (2018). Anisotropic (2 + 1)d growth
and Gaussian limits of q-Whittaker processes. Probability Theory and Related Fields 172
245â€“321. doi:10.1007/s00440-017-0809-6
[8] Borodin, A., Corwin, I. and Toninelli, F. L. (2017). Stochastic heat equation
limit of a (2 + 1)d growth model. Communications in Mathematical Physics 350 957â€“
984. doi:10.1007/s0022MR-3607467
46

[9] Borodin, A. and Ferrari, P. L. (2014). Anisotropic growth of random surfaces in 2 + 1 dimensions. Communications in Mathematical Physics 325 603â€“684.
doi:10.1007/s00220-013-1823-x
[10] Chen, G.-Y. and Kumagai, T. (2018). Cutoffs for product chains. Stochastic Processes
and Their Applications 128 3840â€“3879. doi:10.1016/j.spa.2018.01.002
[11] Chen, L. H. Y., Goldstein, L. and Shao, Q.-M. (2011). Normal Approximation by
Steinâ€™s Method. Springer-Verlag. doi:10.1007/978-3-642-15007-4
[12] Chen, Y.-T. (2019). Rescaled Whittaker driven stochastic differential equations converge
to the additive stochastic heat equation. Electronic Journal of Probability 24 paper no.
36. doi:10.1214/19-EJP289
[13] Corwin, I. and Toninelli, F. L. (2016). Stationary measure of the driven twodimensional q-Whittaker particle system on the torus. Electronic Communications in Probability 21 paper no. 44. doi:10.1214/16-ECP4624
[14] Durrett, R. (2019). Probability: Theory and Examples, 5th ed. Cambridge Series in Statistical and Probabilistic Mathematics 49. Cambridge University Press.
doi:10.1017/9781108591034
[15] Edwards, S. F. and Wilkinson, D. R. (1982). The surface statistics of a granular aggregate. Proceedings of the Royal Society of London. Series A, Mathematical and Physical
Sciences 381 17â€“31. doi: 10.1098/rspa.1982.0056 MR-0661715
[16] Feller, W. (1991). An Introduction to Probability Theory and Its Applications. Vol. 2,
2nd ed. Wiley Series in Probability and Statistics. John Wiley & Sons, Inc. MR0270403
[17] Karatzas, I. and Shreve, S. E. (1998). Brownian Motion and Stochastic Calculus, 2nd
ed. Springer-Verlag. doi:10.1007/978-1-4612-0949-2
[18] Kardar, M., Parisi, G., and Zhang, Y.-C. (1986). Dynamic scaling of growing interfaces. Physical Review Letters 56 889â€“892. doi:10.1103/physrevlett.56.889
[19] Lodhia, A., Sheffield, S., Sun, X. and Watson, S. S. (2016). Fractional Gaussian
fields: A survey. Probability Surveys 13 1â€“56. doi:10.1214/14-PS243
[20] Mitoma, I. (1983). Tightness of probabilities on C([0, 1]; S â€² ) and D([0, 1]; S â€² ). Annals
of Probability 11 989â€“999. doi:10.1214/aop/1176993447
[21] Petrov, V. V. (1962). On local limit theorems for sums of independent random variables.
Theory of Probability & Its Applications 9, 312â€“320. doi:10.1137/1109044
[22] Petrov, V. V. (1975). Sums of Independent Random Variables. Springer-Verlag.
doi:10.1007/978-3-642-65809-9
[23] Pinsky, M. A. and Karlin, S. (2011). An Introduction to Stochastic Modeling, 4th ed.
Academic Press. doi:10.1016/C2009-1-61171-0
[24] Quastel, J. (2013). Introduction to KPZ. Current Developments in Mathematics, Volume
2011. doi:10.4310/CDM.2011.v2011.n1.a3
[25] Reed, M. and Simon, B. (1980). Methods of Modern Mathematical Physics. I: Functional
Analysis, 2nd ed. Academic Press. MR751959
[26] Revuz, D. and Yor, M. (1999). Continuous Martingales and Brownian Motion, 3rd ed. Grundlehren der mathematischen Wissenschaften 293. Springer-Verlag.
doi:10.1007/978-3-662-06400-9
47

[27] RoÌˆllin, A. and Ross, N. (2015). Local limit theorems via Landauâ€“Kolmogorov inequalities. Bernoulli 21 851â€“880. doi:10.3150/13-BEJ590
[28] Shiga, T. (1994). Two contrasting properties of solutions for one-dimensional stochastic partial differential equations. Canadian Journal of Mathematics 46 415â€“437.
doi:10.4153/CJM-1994-022-8
[29] Skellam, J. G. (1946). The frequency distribution of the difference between two Poisson
variates belonging to different populations. Journal of the Royal Statistical Society 109
296. doi:10.2307/2981372
[30] Toninelli, F. L. (2018). (2 + 1)-dimensional interface dynamics: mixing time,
hydrodynamic limit and Anisotropic KPZ growth. Proceedings of the International
Congress of Mathematics â€“ 2018 â€“ Rio de Janeiro 2 2719â€“2744. Available at
https://eta.impa.br/dl/080.pdf
[31] Walsh, J. B. (1983). An Introduction to Stochastic Partial Differential Equations. In:
Hennequin P.L. (eds). EÌcole dâ€™EÌteÌ de ProbabiliteÌs de Saint Flour XIV-1984. Lecture Notes
in Mathematics 1180. Springer-Verlag. doi:10.1007/BFb0074920
[32] Wolf, D. E. (1991). Kinetic roughening of vicinal surfaces. Physical Review Letters 67
1783â€“1786. doi:10.1103/PhysRevLett.67.1783

48

