arXiv:1911.06943v2 [math.PR] 26 Nov 2019

The Overlap Gap Property and Approximate Message Passing
Algorithms for p-spin models
David Gamarnikâˆ—and Aukosh Jagannathâ€ 
November 27, 2019

Abstract
We consider the algorithmic problem of finding a near ground state (near optimal solution) of
a p-spin model. We show that for a class of algorithms broadly defined as Approximate Message
Passing (AMP), the presence of the Overlap Gap Property (OGP), appropriately defined, is a barrier.
We conjecture that when p â‰¥ 4 the model does indeed exhibits OGP (and prove it for the space of
binary solutions). Assuming the validity of this conjecture, as an implication, the AMP fails to find
near ground states in these models, per our result. We extend our result to the problem of finding
pure states by means of Thouless, Anderson and Palmer (TAP) based iterations, which is yet another
example of AMP type algorithms. We show that such iterations fail to find pure states approximately,
subject to the conjecture that the space of pure states exhibits the OGP, appropriately stated, when
p â‰¥ 4.

1

Introduction

Given an N -tensor A = (Ai1 ,...,ip , 1 â‰¤ i1 , . . . , ip â‰¤ N ) âˆˆ (RN )âŠ—p of order p and an N -vector u âˆˆ RN ,
define the usual inner tensor product by
X
Ai1 ,...,ip ui1 Â· Â· Â· uip .
A(u) ,
(1)
1â‰¤i1 ,...,ip â‰¤N

Consider the associated normalized variational problem over the binary cube BN , {âˆ’1, 1}N :
Î·N ,

1
min A(Ïƒ).
N ÏƒâˆˆBN

(2)

The case when
A consists of i.i.d. zero mean Gaussian random entries with variance 1/N pâˆ’1 that is

1
corresponds to the problem of finding a ground state of a p-spin model with Gaussian couN 0, N pâˆ’1
plings and the (unique) vector uâˆ— achieving the minimization value is called the ground state [Pan13].
The choice of variance 1/N pâˆ’1 and the normalization 1/N is dictated by the associated Gibbs distribution defined by assigning probability weight proportional to exp (âˆ’Î²A(Ïƒ)) to each Ïƒ âˆˆ BN for some
fixed inverse temperature parameter Î² âˆˆ R+ . In this case the partition function
X
Z,
exp(âˆ’Î²A(Ïƒ))
ÏƒâˆˆBN

âˆ—

Operations research Center and Sloan School of Management, MIT. Email: gamarnik@mit.edu
Department of Statistics and Actuarial Sciences and Department of Applied Mathematics, University of Waterloo.
Email:a.jagannath@uwaterloo.ca
â€ 

1

is well approximated by N Î·N as Î² increases and Î·N is known to converge to a strictly negative limiting
value Î· âˆ— < 0 with high probability (w.h.p.) as N â†’ âˆ. For us though the details of the choice of
scaling are immaterial and the variational problem above is equivalent to the case when A consists of
i.i.d. standard normal entries and the normalization 1/N is skipped. Another standard assumption in
the literature is to assume a symmetry of A, for example assuming that entries are fully determined by
i.i.d. entries corresponding to i1 â‰¤ Â· Â· Â· â‰¤ ip . This difference is again immaterial. Indeed, consider the
tensor AÌ„ defined by
AÌ„i1 ,...,ip =

1 Ï€
A ,
p!

where AÏ€ is defined by
AÏ€i1 ,...,ip = AÏ€(i1 ,...,ip ) ,

1 â‰¤ i1 , . . . , ip â‰¤ N,

for any permutation Ï€ of 1, . . . , p. Note that AÌ„ is symmetric and satisfies AÌ„(u) = AÏ€ (u) for every Ï€.
In the present paper we focus on the algorithmic question of solving the minimization problem
(2) approximately and efficiently (in polynomial time). That is, the question is one of existence of a
polynomial time algorithm which for every Ç« > 0 produces a sequence of solution ÏƒN âˆˆ BN satisfying
A(ÏƒN )/N â‰¤ (1 âˆ’ Ç«)Î· âˆ— ,
as N â†’ âˆ, ideally w.h.p. as N â†’ âˆ. This problem was successfully solved recently by Montanari [Mon18] in the case of the Sherrington-Kirkpatrick model, which is the special case corresponding
to p = 2. The result though assumes the validity of a (widely believed) conjecture that the overlap
distribution function is strictly increasing. In particular, it assumes the absence of an interval [Î½1 , Î½2 ]
inside the support of the overlap distribution with zero mass, namely that the overlap distribution does
not exhibit the Overlap Gap Property (OGP). The algorithm is based on a variant of Approximate
Message Passing (AMP) type algorithms, which in the context of spin glasses is well motivated by the
so-called Thouless, Anderson and Palmer (TAP) equation describing the magnetization of spins in spin
glass models. AMP, as a class of algorithms was also found to be one of the most effective classes of algorithm in many models of signal processing [Kab03, DMM09, Bol14, BM11, JM13, BLM+ 15, BMN17],
specifically models involving a â€planted signalâ€ (which does not apply to our p-spin model). The algorithmic result of [Mon18] in its order was inspired by a similar result by Subag [Sub18] regarding
the problem of finding a near ground states in a sphericalâ€œmixed p-spinâ€ model. Here one considers a
linear combination of objectives of the form (1) as one varies p, with the coefficients being fixed, and
optimizing over the unit sphere {u : kuk2 â‰¤ 1} instead of BN . Here a polynomial time constrictions of
near optimal solutions is provided, under the assumption that the model does not exhibit OGP (see part
(2) of Proposition 1 in [Sub18]). For the case of spherical models, the necessary and sufficient conditions
for the OGP are known [CS17, JT17a, Tal06]. Both p-spin and spherical p-spin models are related to
the Random Energy Model (REM) considered from the algorithmic perspective by Addario-Berry and
Maillard [ABM18], where in contrast to [Mon18] and [Sub18] algorithmic hardness is established away
from the ground state value. One should note, however that REM is an oracle based optimization
problem and thus does not fit classical input size based algorithmic complexity questions arising in the
context of p-spin and spherical p-spin models.
At the same time it is known that the OGP does take place in p-spin models when p â‰¥ 4, as was
established in [CGP+ 19, Theorem 3]. In particular, it was shown that for every even p â‰¥ 4, there exists
Âµ > 0, 0 < Î½1 < Î½2 < 1 such that w.h.p. for every pair of solutions Ïƒ1 , Ïƒ2 satisfying A(Ïƒj )/N â‰¤ Î· âˆ— +Âµ for
j = 1, 2, the associated normalized overlap, defined simply as the normalized absolute value of the inner
product (1/N )|hÏƒ1 , Ïƒ2 i| is either at most Î½1 or at least some Î½2 . This naturally raises the question as to
2

whether the OGP creates a barrier to the success of AMP when p â‰¥ 4. The main result of our paper,
Theorem 3.3, is to establish precisely this fact under the assumption that a certain relaxed version of the
OGP takes place when p â‰¥ 4. The relaxed version concerns the optimization problem min A(u) when u
is relaxed to be in Hilbert cube u âˆˆ [âˆ’1, 1]N , HN , and otherwise is defined in the same way as for BN .
This relaxed version would be a rather straightforward implication of the OGP for binary solutions if
one could show that every nearly optimal solution in HN is nearly binary. Unfortunately, even this fact
is not known, and we leave it as an interesting, though, as we believe, an approachable open problem.
As a consequence of our main result, we show that extension of the AMP result of [Mon18] to the case
p â‰¥ 4 is not possible. As another implication, we show that a natural iterative scheme of computing the
fixed point of the TAP equations fails as well in the case p â‰¥ 4. We note, that this iterative scheme is
known to succeed in the high temperature regime due to the result of [Bol14]. Another important class
of algorithms ruled out by our negative result is gradient descent type algorithms. Since the gradient
of A(u) is a linear combination of the vectors of the form A(Â·, u) defined below in (3), then a discrete
implementation of the gradient descent algorithm in the form ut = utâˆ’1 + Î·tâˆ’1 âˆ‡A(utâˆ’1 ) for some step
choices Î·t is also a special case of our class of AMP algorithms.
One challenge in establishing our result formally is the formalization of the class of AMP algorithms
to begin with. Unfortunately, there is no one formal definition for it, but rather there is a vaguely
proposed scheme for a class of iterations inspired by the Belief Propagation type algorithms. The
iterations take the form ut+1 = Ft (Gt (ut ), Gtâˆ’1 (utâˆ’1 ), . . . , G0 (u0 )), t â‰¥ 0 and are performed for some
constant number of rounds t = 0, 1, . . . , T , where F t is an in general t-dependent function involving
vector A(Â·, u) âˆˆ RN defined by
ï£«
ï£¶
X
(3)
A(Â·, u) , ï£­
Ai,i2 ,...,ip ui2 Â· Â· Â· uip , 1 â‰¤ i â‰¤ N ï£¸ ,
i2 ,...,ip

for any u âˆˆ RN , as well other non-linear operators Gt : RN â†’ RN defined typically through some kind
of univariate or t variant non-linear functions gt : Rt â†’ R applied coordinate-wise in some way. We
note that (3) is simply a matrix vector product Au when p = 2.
Thus, as a first step, we introduce a precise class of such iterative algorithms (functions) F t , and
associate it with a precise set of assumptions. We show separately that the algorithm of [Mon18] is
a special case. We assume that the results U t , 0 â‰¤ t â‰¤ T of each iterations are truncated so that
the resulting vector always belongs to k Â· kâˆ bounded region of the form [âˆ’M, M ]N for some constant
M . The rational for the truncation is as follows. In the implementation of the AMP the iterations
F t , 0 â‰¤ t â‰¤ T produce a real valued vector U T âˆˆ RN which is then projected to a vector in BN in
a way discussed below. The idea here is that U T is a vector which is â€close enoughâ€ to some vector
Ïƒ âˆˆ BN which is a near-ground state. In particular, the typical entries of U t are â€not too farâ€ from
interval [âˆ’1, 1], and in particular are bounded by M . We restrict every vector U t to be in [âˆ’M, M ]N for
technical convenience. The rounding scheme [âˆ’M, M ]N â†’ BN assumed to be adopted by our class of
AMP is similar the one that was used in [Mon18]: first U T is projected to vector V âˆˆ HN via a natural
truncation x â†’ min(max(x, âˆ’1), 1), and then some rounding scheme Î  : HN â†’ BN is adopted by the
algorithm designer, which is guaranteed asymptotically to never lower the quality of the solution, that
is, it guarantees that A(Î (V ))/N â‰¤ A(V )/N + o(1). Our main result, stated more precisely, says that
for any AMP algorithm thus defined, the vector V is w.h.p. sub-optimal, namely A(V )/N exceeds Î· âˆ—
by some fixed constant Âµ > 0, w.h.p. as N â†’ âˆ. Thus we establish that the vector V obtained in the
pen-ultimate (before Î ) step of the AMP is sub-optimal. We note that it is precisely this vector which
is shown to be nearly optimal in the case p = 2 in the argument of [Mon18]. The last step of converting
a real vector V âˆˆ HN to Î (V ) âˆˆ BN is just used there in order to obtain a genuinely binary vector.
We do not establish that the ultimate vector Î (V ) âˆˆ BN is sub-optimal, and this is a limitation of our
3

technique. We note however that showing near optimality of Ï€(V ) without showing near optimality of
V would amount to believing that the rounding Î  is somehow mysteriously capable of producing near
optimal binary solution Î (V ) from a presumably far from optimal fractional solution V âˆˆ HN , which
is something which does not seem to be plausible, and something which not established in [Mon18].
Nevertheless, it would be admittedly a more complete result to show directly that Î (V ) is far from
optimal, without assuming the same for V , but we are currently unable to make this argument rigorous,
and leave it for further investigation.
Proof of the main result. Outline
We now describe the main ingredients of our proof. First, as a consequence of a result established
in [CGP+ 19], we show that theOGP holds w.h.p.
not just for one instance of A, but for a continuous
âˆš
âˆš 
1 âˆ’ Ï„ A + Ï„ AÌ‚ , Ï„ âˆˆ [0, 1] where AÌ‚ is an independent instance of A.
family of sets of the form A =
Note that for each fixed Ï„ , the corresponding tensor has the same distribution as A. An easy consequence
of the OGP result in [CGP+ 19] and the chaos result of [CHL18], is the fact, which we prove in this
paper (Theorem 3.4), that the OGP holds for A as well in the sense that for any two AÏ„1 , AÏ„2 âˆˆ A and
any Ïƒ1 , Ïƒ2 âˆˆ BN satisfying AÏ„j (Ïƒj )/N â‰¤ Î· âˆ— + Âµ, it is again the case that N âˆ’1 |hÏƒ1 , Ïƒ2 i| âˆˆ [0, Î½1 ] âˆª [Î½2 , 1],
for the same values Î½1 , Î½2 , Âµ. The chaos property roughly speaking says for any fixed Ï„1 6= Ï„2 near
optimal solutions of AÏ„1 and AÏ„2 are nearly orthogonal, see Theorem 3.5 below. Our main conjecture
regarding OGP (Conjecture 3.2), which we use as an assumption of the main result, is the conjecture
that OGP holds in fact for near optimal solutions in HN as opposed to those in BN , for the same family
of instances. Establishing this conjecture is an interesting open question.
Our main ingredient of the proof is then to show that the iterations U T = U T (A) as function of A
are sufficiently â€continuousâ€ to perturbation of the entries of A. Specifically, we obtain an upper bound
on N âˆ’1 kU T (AÏ„ ) âˆ’ U T (A0 )k2 for the interpolation scheme A which is sufficiently continuous in Ï„ . This
result is the subject of Theorem 5.1. A straightforward implication is that the same bound applies to
N âˆ’1 kV (AÏ„ ) âˆ’ V (A0 )k2 , where, as we recall V (A) is projection of U T (A) through the truncation x â†’
min(max(x, âˆ’1), 1). Separately, we use the independence of A and AÌ‚ to argue the near orthogonality
of V (A) and V (AÌ‚). The continuity result above then is used to show that for an appropriate choice of
Ï„ , it will hold that N âˆ’1 hV (AÏ„ ), V (A)i âˆˆ (Î½1 , Î½2 ). The (conjectured) OGP property implies that this
choice of Ï„ corresponds to a sufficiently sub-optimal solution V (AÏ„ ), which contradicts concentration
property of A(V (AÏ„ )), which we establish separately using standard techniques, including Gaussian
concentration of measure and Kirszbraunâ€™s Theorem.
Prior results on OGP and algorithmic implications
The concept of OGP originates in the study of spin glass models, specifically the study of overlap distribution of replicas generated according to some associated Gibbs distribution, such as the one described
above. Understanding the limiting distribution of overlaps is of an utmost importance to spin glass theory and has recieved significant attention [AC15, ACZ17, JT17b, JT18]. The first connections between
to study of the overlaps and algorithms were made in the context of random constraint satisfaction
problems, such as random K-SAT problem and many other similar problems. These problems exhibit
an â€infamousâ€ gap between the range of parameters for which a satisfying assignment exists vs those
for which solutions can be found in polynomial time. The apparent hardness was linked conjecturally
to the clustering (shattering) property of these models which were discovered to appear roughly in the
regime where known polynomial time algorithms fail [ACO08, ACORT11, MMZ05, MPZ02, COE11].
The clustering property says, roughly speaking, that a large part of the set of satisfying assignments
can be partitioned into clusters separated by Hamming distance, which is of the order of the size of
the model itself. It is notable that the proof technique used to establish such a clustering property
4

actually shows something more: the overlaps between pairs of typical (random in some appropriate
sense) satisfying assignments lie in a disconnected union of intervals [0, Î½1 ] âˆª [Î½2 , 1]. Thus the set of
solutions is disconnected not only with respect to its ambient metric space, but also with respect to its
one-dimensional projection onto the set of possible overlap values. The proof technique relies on fairly
standard application of the moment method. The disconnectivity of overlaps (that is the presence of the
overlap gaps of the form (Î½1 , Î½2 )) was later used as an obstruction to a class of local algorithms defined
as so-called Factors of IID in [GS17a, RV+ 17, GS17b, CGP+ 19], and for random walk type algorithms
in [COHH17]. It is this line of work which the closest in spirit to the present one, as one can think of
AMP as a natural definition for â€localâ€ algorithms defined on dense instances â€“ instances not defined
on sparse graphs and hypergraphs.
It is important to note that while OGP implies the clustering property, the converse in general is
not true. Indeed if the OGP takes place then one can partition the set of all solutions of interest into
those which have overlap at least Î½2 with some arbitrarily marked solution Ïƒ o (thus marked â€Cluster
1â€), vs solutions with overlap at most Î½1 with Ïƒ o (thus marked â€other clustersâ€), leading to a set of at
least two clusters separated by a significant distance. On the other hand, one can easily create a subset
of BN for which the set of all overlaps spans the entire interval [0, 1], though at the same time admits
clustering partition.
The OGP was further established for some other models, some involving planted signals [GL18,
DI17, GJS19]. It was shown in [GJS19] to be an obstruction to Glauber Dynamics type algorithms
by showing that OGP implies the existence of a free energy well, a property which was shown to be a
barrier for Markov chain type algorithms in problems involving planted signals [BAGJ18a]. A related
notion of free energy barriers associated with these gaps were also shown to be obstructions for local
Markov chain type algorithms for problems of the class considered here in [BAJ18], where it was also
shown that these free energy barriers occur in a broad class of models including both the p-spin and
spherical p-spin models. It can be shown that OGP implies the existence of a free energy barrier at
sufficiently low temperatures. It is of interest to establish the broadest class of algorithms for which
OGP is a provable barrier.
The remainder of the paper is structured as follows. In the next section we introduce the formalism of
the AMP algorithms. In Section 3 we give the definition of the OGP, state the corresponding conjecture
and state our main result. The validity of OGP for binary solutions is proven in the same section. Some
preliminary technical results are established in Section 4. Our main technical result is Theorem 5.1
which is stated and proven in Section 5. We note that it is a purely deterministic result showing that
the output of the AMP depends on the values of the tensor A sufficiently continuously. In Section 6 we
establish the concentration property of the solution V produced by the AMP around its expectation.
Our main theorem is proven in Section 7. In Section 8 we consider TAP solutions and show that a
natural class of iterations suggested by TAP fails to find the fixed point of TAP, modulo the same
Conjecture 3.2, since the iterations are a special case of the class of AMP algorithms we define. This
result is a direct implication of our main result, Theorem 3.3. It contrasts with the positive result of
Bolthausen [Bol14], which establishes that these iterations do converge to the solution of TAP equations
in the high-temperature setting. In Section 9 we verify that the AMP algorithm constructed in [Mon18]
also fit the general definition of AMP introduced in this paper. Finally, we conclude in Section 10 where
we state some open questions.

5

2

Approximate Message Passing iterations formalism

xi yi denotes inner product of vectors x, y âˆˆ RN . For any tensor B âˆˆ (RN )âŠ—p kBk2
qP
2
denotes the Frobenius norm
1â‰¤i1 ,...,ip â‰¤N Bi1 ,...,ip , and kBkop denotes the operator norm
hx, yi =

P

1â‰¤iâ‰¤N

max B(u1 , . . . , up )

u1 ,...,up

where the maximum is over all u1 , . . . , up âˆˆ RN , kuj k2 = 1, 1 â‰¤ j â‰¤ p. By Cauchy-Schwartz inequality
kBkop â‰¤ kBk2 .
Throughout the paper A âˆˆ (RN )âŠ—p denotes N -size order p tensor consisting of N (0, N âˆ’(pâˆ’1) ) i.i.d.
entries. For any u1 , . . . , upâˆ’1 âˆˆ RN let
X
A(u1 , . . . , up ) =
Ai1 ,i2 ,...,ipâˆ’1 u1i1 Â· Â· Â· upip ,
1â‰¤i1 ,...,ip â‰¤N

so that for any u âˆˆ RN , A(u) = A(u, Â· Â· Â· , u) as in (1). Here ur = (ur1 , . . . , urN ). For any u1 , . . . , upâˆ’1 âˆˆ
RN we also introduce
y = A(Â·, u1 , . . . , upâˆ’1 ) âˆˆ RN

(4)

defined by
X

yi =

1â‰¤i1 ,...,ipâˆ’1 â‰¤N

Ai,i1 ,...,ipâˆ’1 u1i1 Â· Â· Â· upâˆ’1
ipâˆ’1

1 â‰¤ i â‰¤ N.

Similarly, for any u âˆˆ RN we write A(Â·, u) instead of A(Â·, u, u, . . . , u) for short. We recall the definition
of Î·N from (2). Observe that we may view A(u) as a centered Gaussian process indexed by HN , which
has covariance
 hu, vi p
.
E[A(u)A(v)] = N
N
In particular, |E[A(u)A(v)] | â‰¤ N for any u, v âˆˆ RN with kuk2 , kvk2 â‰¤ 1. The following concentration
result is then an immediate consequence of the Borell-TIS inequality, Theorem 2.1.11 of [AT09].
Theorem 2.1. For every Î´ > 0
P (|Î·N âˆ’ E[Î·N ] | â‰¥ Î´) â‰¤ exp(âˆ’(1/4)Î´2 N ),
for all sufficiently large N .
A major consequence of the development in spin glass theory is the existence of the limit
lim E[Î·N ] = Î· âˆ— < 0,

N â†’âˆ

(5)

which by Theorem 2.1 also implies that the limit Î·N â†’ Î· âˆ— holds w.h.p. as N â†’ âˆ.
We now introduce a set of assumptions which are used to define a class of AMP algorithms. Fix
a positive integer T and an M > 0. Consider two sequences of functions ft : [âˆ’M, M ]t â†’ R and
Ft : R Ã— [âˆ’M, M ]t â†’ R, 1 â‰¤ t â‰¤ T .
Assumption 2.2. ft (0) = 0. Furthermore, functions ft , Ft are Lipschitz continuous on their respective
domains. More precisely, there exists Î¶ âˆˆ R+ such that for all 1 â‰¤ t â‰¤ T ,
|ft (u) âˆ’ ft (v)| â‰¤ Î¶ku âˆ’ vk2 ,

(6)

|Ft (u) âˆ’ Ft (v)| â‰¤ Î¶ku âˆ’ vk2 .

(7)

sup
u,vâˆˆ[âˆ’M,M ]t

sup
u,vâˆˆRÃ—[âˆ’M,M ]t

6

The assumption (7) says that the function Ft is Lipschitz on an infinite rectangle R Ã— [âˆ’M, M ]t This
will be required due to the special role played by the first variable of Ft .
Fix a positive constant M > 1. Let xM = max(âˆ’M, min(x, M )) denote an M -truncation for any
x âˆˆ R. When x is a vector, xM is assumed to be applied coordinate-wise. We now define the iterations
forming the basis of AMP. Fix U 0 âˆˆ [âˆ’M, M ]N and define the sequence U t âˆˆ RN , 1 â‰¤ t â‰¤ T as follows


U t = Ft (A(Â·, ft (U 0 , . . . , U tâˆ’1 )), U 0 , . . . , U tâˆ’1 ) M âˆˆ [âˆ’M, M ]N ,
(8)

where Ft , ft and M are applied component-wise. In other words, in step t, first a vector ft (U 0 , . . . , U tâˆ’1 ) âˆˆ
RN is formed by applying ft coordinate-wise (recall that the domain of ft is Rt ). Then this vector is
used to define vector A(Â·, ft (U 0 , . . . , U tâˆ’1 )) via (3). This vector is concatinated with prior vectors
U 0 , . . . , U tâˆ’1 to form an N Ã— (t + 1) matrix A(Â·, ft (U 0 , . . . , U tâˆ’1 )), U 0 , . . . , U tâˆ’1 âˆˆ RN Ã—(t+1) . Then
function Ft is applied coordinate-wise. Finally the M -truncation is applied to each of the N coordinates
of the vector thus obtained, resulting in U t .
We now describe an algorithm which uses AMP to generate a solution in BN . For this purposes we
assume that the algorithm designer has access to some (computable) projection function Î N : HN â†’
BN . We discuss this further below.
Algorithm 2.3 (AMP Algorithm). The algorithm is parametrized by U 0 , M, T, (ft , 1 â‰¤ t â‰¤ T ), (Ft , 1 â‰¤
t â‰¤ T ), Î N .
Input A âˆˆ (RN )âŠ—p .

Step 1 Compute U T using (8).
Step 2 Project U T to HN by applying transformation x â†’ [x]1 = max(min(x, 1), âˆ’1), coordinate-wise.
Denote the resulting vector by V âˆˆ HN .
Step 3 Output Ïƒ = Î (V ) âˆˆ BN .
In some sense the details of the projection Î N are immaterial to us since our negative result will be
concerned with the quality of the solution V itself and not its projection. Nevertheless, for completeness
we describe now the projection used in ([Mon18]), which we denote by Î sign
N . The projection was defined
only for p = 2 which was the case of interest. But it is straightforward to extend the idea to the case
of general p. Set z (0) = V . For j = 1, . . . , N , construct z (j) by making all coordinates â„“ 6= j of z (j) to
be the same as of z (jâˆ’1) , and setting the j-th coordinate of z (j) to be the sign opposite of
X
(jâˆ’1)
Aj,i1 ,i2 ,...,ipâˆ’1 zi1 ,...,ipâˆ’1 .
(9)
j6=i1 6=i2 6=Â·Â·Â·6=ipâˆ’1

In particular, the first j coordinates of z (j) are Â±1, but the remaining coordinates are real valued in
(N ) .
general. Set Î sign
N (V ) = z
Let us comment on the meaning and motivation behind the steps of the AMP algorithm above and
also the motivation behind the projection Î N described above and used in ([Mon18]). The idea is that
when the AMP algorithm succeeds, the vector V , while not being an element of the binary cube BN ,
should be nearly optimal in the sense that
A(V ) â‰ˆ inf A(w),
wâˆˆBN

and should not be too far from HN , so that the projecting U T to V âˆˆ HN does not change the objective
value significantly. That is A(V ) â‰ˆ A(U T ). Next one observes that Î sign
effectively rounds V to a
N
7

vector z (N ) in BN in such a way that the objective value only decreases asymptotically. This is verified
by observing that for each coordinate j, the dependence of A(V ) on variable Vj is linear in Vj , except for
terms Ai1 ,...,ip with repeating coordinates (i.e. such that iâ„“ = ir for some 1 â‰¤ â„“ 6= r â‰¤ p). Since V âˆˆ HN
and thus |Vj | â‰¤ 1, the linearity allows to round Vj to âˆ’1 or 1 while only decreasing the objective value.
This is done trivially by setting Vj to be the sign opposite of the one of the multiplier of Vj , which is
(9). This is done iteratively over all N coordinates. The terms corresponding to repeating coordinates
are easily shown to be of lower order of magnitude than the objective value. As a result one obtains a
vector z = z (N ) âˆˆ BN satisfying
A(z) . A(V ) â‰ˆ inf A(Ïƒ).
ÏƒâˆˆBN

But since z belongs to the solution space itself (the binary cube BN ), it must be the case that in fact
A(z) â‰ˆ A(V ) â‰ˆ inf A(Ïƒ),
ÏƒâˆˆBN

and thus the success of AMP is validated. Importantly, the near optimality of z is argued from the near
optimality of V itself. This discussion is of key essence to the main result of our work, which is stated
in the next section.

3

The OGP conjecture and the main result

Consider an arbitrary set A of tensors A âˆˆ (RN )âŠ—p .
Definition 3.1. The set A satisfies the Overlap Gap Property (OGP) with domain SN âŠ‚ RN , and
parameters Âµ > 0, 0 < Î½1 < Î½2 < 1 if for every pair Aj âˆˆ A, j = 1, 2 and every uj , j = 1, 2 satisfying
1
1
Aj (uj ) â‰¤
inf Aj (w) + Âµ,
N
N wâˆˆSN

j = 1, 2,

it holds
|hu1 , u2 i|
âˆˆ [0, Î½1 ] âˆª [Î½2 , 1].
ku1 k2 ku2 k2

(10)

Namely, every pair of nearly (Âµ-close) optimal solutions with respect to any two members of A
cannot have normalized inner product in the interval (Î½1 , Î½2 ).

Consider two independent random tensors A and AÌ‚ in (RN )âŠ—p both with i.i.d. N 0, 1/N pâˆ’1
âˆš
âˆš
entries. Introduce the interpolated set of tensors AÏ„ , 1 âˆ’ Ï„ A + Ï„ AÌ‚ with Ï„ varying in [0, 1]. Note
that for each fixed Ï„ , AÏ„ is distributed as A. Our main conjecture regarding the OGP concerns the set
A , (AÏ„ , 0 â‰¤ Ï„ â‰¤ 1).
Conjecture 3.2. For every even p â‰¥ 4 here exists Âµ > 0, 0 < Î½1 < Î½2 < 1 such that A described above
satisfies the OGP with domain SN = HN and parameters Âµ, Î½1 , Î½2 , with probability at least 1âˆ’exp(âˆ’cN ),
for some c > 0 for all sufficiently large N . Furthermore, for every Î´ > 0 and every v1 , v2 âˆˆ HN
satisfying A(v1 )/N â‰¤ (1 âˆ’ Î´)E[Î·N ] , AÌ‚(v2 )/N â‰¤ (1 âˆ’ Î´)E[Î·N ], it holds |hv1 , v2 i| â‰¤ Î´N with probability at
least 1 âˆ’ exp(âˆ’cN ) for some c > 0 and all large N .
Our main result stated below assumes the validity of this conjecture. To state this result, let us
introduce the following. Let M1 ([âˆ’M, M ]N ) denote the space of probability measures on [âˆ’M, M ]N .
Let V (A, T, U 0 ) denote the output of the first two steps of Algorithm 2.3 after T steps with coefficient
matrix A and initial data U 0 , where the entires of A âˆˆ (RN )âŠ—p are i.i.d. N (0, N âˆ’(pâˆ’1) ). Then the
following holds.
8

Theorem 3.3. Let p â‰¥ 4 be even. Let M â‰¥ 1 and Î¶ > 0. Assume that (ft ), (Ft ) satisfy Assumption 2.2
with Lipschitz constant Î¶ and that Conjecture 3.2 holds. Then there exists ÂµÌ„ > 0 and c > 0, such that
for N sufficiently large and any Î½ âˆˆ M1 ([âˆ’M, M ]N ), if U 0 âˆ¼ Î½, then V = V (A, T, U 0 ) satisfies


A(V )
minÏƒâˆˆBN A(Ïƒ)
P
â‰¥
+ ÂµÌ„ â‰¥ 1 âˆ’ exp(âˆ’cN ).
N
N
Thus we argue the failure of the AMP to find a vector V âˆˆ HN which is a near optimizer of A. As
discussed earlier, this is a negative result regarding the performance of AMP, since finding such near
optimal V is a key step towards finding a near optimal member z of the binary cube BN . Ideally, one
would establish that the vector z obtained from V via any projection scheme, such as the one described
above is also Âµ-away from optimality. Unfortunately, our proof technique stops short of that due to
the potential sensitivity of the sign function used on obtaining z to perturbation of A, thus potentially
violating stability used crucially in the proof of our main result. We leave this as an interesting open
question.
A partial support to the validity of Conjecture 3.2 above is its validity for the domain SN = BN as
we now establish.
Theorem 3.4. For every even p â‰¥ 4 here exists Âµ > 0, 0 < Î½1 < Î½2 < 1 such that A described above
satisfies the OGP with domain S = BN and parameters Âµ, Î½1 , Î½2 , with probability at least 1 âˆ’ exp(âˆ’cN ),
for some c > 0 for all sufficiently large N . Furthermore, for every Î´ > 0 and every Ïƒ1 , Ïƒ2 âˆˆ BN
satisfying A(Ïƒ1 )/N â‰¤ (1 âˆ’ Î´)E[Î·N ] , AÌ‚(Ïƒ2 )/N â‰¤ (1 âˆ’ Î´)E[Î·N ], it holds |hÏƒ1 , Ïƒ2 i| â‰¤ Î´N with probability at
least 1 âˆ’ exp(âˆ’cN ) for some c > 0 and all large N .
Proof. We note that in the case SN = BN , since kÏƒk2 = N for each Ïƒ âˆˆ BN , the requirement (10) in
definition of OGP simplifies to
|hÏƒ1 , Ïƒ2 i|
âˆˆ [0, Î½1 ] âˆª [Î½2 , 1].
N
It was established in [CGP+ 19], Theorem 3 that the OGP holds for a single instance of a tensor A, i.e.
A = {A}, with probability at least 1 âˆ’ exp(âˆ’cN ) for some c > 0 and all large N . At the same time the
following chaos property was established in [CHL18]:
Theorem 3.5 ([CHL18], Theorem 2). For every Ç« > 0 and Ï„ âˆˆ (0, 1) there exists C,ÂµÌƒ > 0 such that
with probability 1 âˆ’ exp(âˆ’CN )/C, for every Ïƒ1 , Ïƒ2 âˆˆ BN satisfying A(Ïƒ1 )/N â‰¤ E[Î·N ] + ÂµÌƒ, AÏ„ (Ïƒ2 )/N â‰¤
E[Î·N ] + ÂµÌƒ it holds |hÏƒ1 , Ïƒ2 i| â‰¤ Ç«N .
We now combine these two results. We first claim that it suffices to establish OGP for a discrete
finite subsets. Fix Î´ > 0 such that 1/Î´ is an integer and consider AÏ„ for Ï„ = 0, Î´, 2Î´, . . . , Î´(1/Î´). We
assume OGP holds for this set for some Âµ, Î½1 , Î½2 for every sufficiently small such Î´. Now for any Ïƒ âˆˆ BN
âˆš
âˆš
AÏ„ (Ïƒ) âˆ’ A(Ïƒ) = ( 1 âˆ’ Ï„ âˆ’ 1)A(Ïƒ) + Ï„ A(Ïƒ).
In light of concentration bound of Theorem 2.1, for any Ç« > 0 we can find small enough Î´ so that
max

sup max |AkÎ´+Ï„ (Ïƒ) âˆ’ AkÎ´ (Ïƒ)| â‰¤ Ç«N

0â‰¤kâ‰¤(1/Î´)âˆ’1 0â‰¤Ï„ â‰¤Î´ ÏƒâˆˆBN

with probability at least 1 âˆ’ exp(âˆ’cN ), for some c > 0 and large N . This means that modulo exponentially small probability, every Ïƒ satisfying AkÎ´+Ï„ (Ïƒ)/N â‰¤ E[Î·N ]+ Ç« also satisfies AkÎ´ (Ïƒ)/N â‰¤ E[Î·N ]+ 2Ç«.
Thus if Ç« < Âµ âˆ’ 2Ç« then the set (AÏ„ , Ï„ âˆˆ [0, 1]) satisfies OGP with ÂµÌ‚ = Âµ âˆ’ 2Ç« > 0 and the same Î½1 , Î½2 ,
9

provided that the discrete set (AkÎ´ , 0 â‰¤ k â‰¤ 1/Î´) satisfies OGP with Âµ, Î½1 , Î½2 . Thus we now prove OGP
for this discrete set.
Let Âµ, Î½1 , Î½2 be OGP parameters for a single instance A. By the union bounds over k = 0, 1, . . . , 1/Î´,
the OGP holds for each AkÎ´ modulo exponentially small probability. Fix Î´ > 0. Applying Theorem 3.5,
we find ÂµÌƒ so that the theorem claim holds for Ç« = Î½1 and Ï„ = Î´. By union bounds this also holds
for all pairs Ak1 Î´ , Ak2 Î´ , k1 6= k2 modulo exponentially small probability. Then OGP holds for ÂµÌ„ ,
min(ÂµÌƒ, Âµ), Î½1 , Î½2 by considering separately the cases k1 = k2 and k1 6= k2 , where in the latter case for
every Ïƒj , j = 1, 2 satisfying Akj Î´ (Ïƒj )/N â‰¤ E[Î·N ] + ÂµÌ„, j = 1, 2, we simply have |hÏƒ1 , Ïƒ2 i| â‰¤ Î½1 N .
The second part of the theorem follows immediately from the chaos property of Theorem 3.5 in the
special case Ï„ = 1.
Conjecture 3.2 would follow from Theorem 3.4 if we could establish that every nearly optimal solution
in HN is actually close to a point in BN . This is quite plausible as one does not expect nearly optimal
solutions to exist â€deepâ€ inside the Hilbert cube HN . Unfortunately, we are not able to show this and
thus state it as an interesting open problem.
Conjecture 3.6. Suppose the entries of A âˆˆ (RN )âŠ—p are generated i.i.d. according to N (0, N âˆ’(pâˆ’1) ).
For every Ç« > 0 there exists Î´ > 0 such that with probability at least 1 âˆ’ exp(âˆ’cN ) for some c > 0âˆšand
large enough N , every u âˆˆ HN satisfying A(u)/N â‰¤ (1âˆ’Î´)E[Î·N ] also satisfies minvâˆˆBN kuâˆ’vk2 â‰¤ Ç« N .

4

Preliminary technical results

In this section we establish several preliminary results. We begin by recalling the following operator
norm bound
Lemma 4.1. There exist constants C, c > 0 , such that
P(kAkop > CN 1âˆ’p/2 ) â‰¤ eâˆ’cN ,
for all sufficiently large N .
Proof. The proof of this result is verbatim that from [BAGJ18b, Lemma 4.7]. We include this for
completeness.
Let SN = {x : kxk2 = 1} denote the unit â„“2 - ball. We may then view A as a centered Gaussian
process on (SN )Ã—p , with covariance
E[A(x1 , .., xp )A(y1 , ..., yp )] =

1
N (pâˆ’1)

Y

1â‰¤iâ‰¤p

hxi , yi i.

This process is rotationally invariant. Fix an Ç« > 0, let Î£Ç« denote an Ç«âˆ’net for SN with respect to k Â· k2
norm, and let Î£pÇ« denote is p-fold cartesian product. By multilinearity of A,
kAkop â‰¤

sup

(x1 ,...,xk )âˆˆÎ£pÇ«

A(x1 , ..., xp ) + Ç«pkAkop .

If we choose Ç« so that 2pÇ« â‰¤ 1, we have

P (kAkop > Î») â‰¤ P âˆªxâˆˆÎ£pÇ« {A(x1 , ..., xp ) â‰¥ Î»/2} .

To bound the right hand side, note that for any fixed (x1 , .., xp ) âˆˆ (SN )p , A(x1 , ..., xp ) is a centered
Gaussian with variance N âˆ’p+1 , so that
2 /2

P(A(x1 , ..., xp ) â‰¥ Î»N 1âˆ’p/2 ) â‰¤ eâˆ’N Î»
10

.

where in the second line, (x1 , ..., xp ) is any point in Î£p , |Î£k | denotes its cardinality, and the final
inequality comes from a Gaussian tail bound since A(x1 , .., xp ) is a centered Gaussian with variance
N âˆ’p+1 . Note furthermore that we may choose this net so that |Î£Ç« | â‰¤ (4/Ç«)N , [Ver18, Lemma 5.1].
Thus by rotation invariance and a union bound, we see that
 pN
2
4
1âˆ’p/2
eâˆ’N Î» /2 .
P(kAkop â‰¥ Î»N
)â‰¤
Ç«
Choosing Î» sufficiently large yields the result.
Proposition 4.2. There exists c2 , c > 0 which depend on M such that
P(

max

u,vâˆˆ[âˆ’M,M ]N

kA(Â·, u) âˆ’ A(Â·, v)k2
â‰¥ c2 ) â‰¤ exp(âˆ’cN ),
ku âˆ’ vk2

for all sufficiently large N .
Proof. By multilinearity of A, the triangle inequality, and the definition of the operator norm,
kA(Â·, u, . . . , u) âˆ’ A(Â·, v, . . . , v)k2 â‰¤ kA(Â·, u âˆ’ v, . . . , u)k2 + ... + kA(Â·, v, . . . , v, u âˆ’ v)k2

pâˆ’2
â‰¤ kAkop max{kvkpâˆ’2
2 , kuk2 }ku âˆ’ vk2 .
âˆš
Since u, v âˆˆ [âˆ’M, M ]N , it follows that kvk2 , kuk2 â‰¤ M N . Applying the bound from Lemma 4.1, we
obtain the result.

Lemma 4.3. There exist c, C > 0 such that with probability for every at least 1 âˆ’ exp(âˆ’cN ) for all
large N the following
holds: for every Î· > 0, every u âˆˆ HN satisfying A(u) â‰¤ âˆ’Î·N also satisfies
âˆš
1/p
N.
kuk2 â‰¥ CÎ·
Proof. Note that by Lemma 4.1, with probability at least 1 âˆ’ exp(âˆ’cN )
|

p

maxâˆš A(u)| â‰¤ Î´p N 2 Â· kAkop â‰¤ CÎ´p N.

kuk2 â‰¤Î´ N

Thus if A(u) â‰¤ âˆ’Î·N , it must be that kukp2 kAkop â‰¥ Î·N, so that
kuk2 â‰¥

1 1/p 1/2
Î· N ,
C

where C is as in Lemma 4.1.

5

Continuous dependence

When we view Algorithm 2.3 as a discrete time dynamical system, it is natural to expect that this
admits a similar dependence on the tensor A as a time-inhomogenous differential equation of the same
form. Thus our proof of continuous dependence of iterations on the tensor A can be viewed as a discrete
analogue of similar standard result for differential equations, see, e.g., [Tes12, Section 2.4].
Given any tensor B âˆˆ (RN )âŠ—p , let
c2 (B) ,

sup
u6=vâˆˆ[âˆ’M,M ]N

kB(Â·, u) âˆ’ B(Â·, v)k2
.
ku âˆ’ vk2

We now state the main result of this section.
11

(11)

âŠ—p
, and let VÌ‚ t , V t denote the corresponding sequences output by Step 2
Theorem 5.1. Let B, BÌ‚ âˆˆ RN
of Algorithm 2.3, with the same initial vector U 0 = UÌ‚ 0 . Under Assumption 2.2, there is some constant
K which depends only on Î¶ and c2 (BÌ‚), such that for every T â‰¥ 1 and U 0 ,

pâˆ’1
âˆš
sup kVÌ‚ t âˆ’ V t k â‰¤ K T kBÌ‚ âˆ’ Bkop Î¶M N T
.
1â‰¤tâ‰¤T

 
Proof. Define U t and UÌ‚ t as in Step 1 of Algorithm 2.3, and let Ut = (U s )0â‰¤sâ‰¤t and UÌ‚t = UÌ‚ s

0â‰¤sâ‰¤t

.

Since the map f (x) = [x]M is 1-Lipschitz for any M , we see that the claim of the theorem follows,
provided that
sX
kU s âˆ’ UÌ‚ s k22
Î²N (t) , kUt âˆ’ UÌ‚t k2 =
sâ‰¤t

satisfies

âˆš p
Î²N (t) â‰¤ (K(c2 (BÌ‚) + 1))t kBÌ‚ âˆ’ Bkop Î¶M N t ,

as trivially kUÌ‚ t âˆ’ U t k2 â‰¤ Î²N (t).
Thus we establish (12). By 1-Lipschitz continuity of [Â·]M we have
kUÌ‚ t+1 âˆ’ U t+1 k2 â‰¤

kFt+1 (BÌ‚(Â·, ft+1 (UÌ‚ t , UÌ‚ tâˆ’1 , . . . , UÌ‚0 )), UÌ‚ 0 , ..., UÌ‚ t ) âˆ’ Ft+1 (B(Â·, ft+1 (U 0 , ..., U t )), U0 , . . . , U t )k2 .
Applying the part of Assumption 2.2 regarding Ft , we see that
q
t+1
t+1
2 (t) + kBÌ‚(Â·, f
2
kUÌ‚
âˆ’ U k2 â‰¤ Î¶ Î²N
t+1 (UÌ‚t )) âˆ’ B(Â·, ft+1 (Ut ))k2 ,

so that

q
2 (t) + kBÌ‚(Â·, f
2
Î²N (t + 1) â‰¤ (1 + Î¶ 2 ) Î²N
t+1 (UÌ‚t )) âˆ’ B(Â·, ft+1 (Ut ))k2 .

By the triangle inequality,

kBÌ‚(Â·, ft+1 (UÌ‚t )) âˆ’ B(Â·, ft+1 (Ut ))k2

â‰¤ kBÌ‚(Â·, ft+1 (UÌ‚t )) âˆ’ BÌ‚(Â·, ft+1 (Ut ))k2 + kBÌ‚(Â·, ft+1 (Ut )) âˆ’ B(Â·, ft+1 (Ut ))k2

= I + II.
By definition of c2 (BÌ‚),

I â‰¤ c2 (BÌ‚)kft+1 (UÌ‚t ) âˆ’ ft+1 (Ut )k2 â‰¤ Î¶c2 (BÌ‚)Î²N (t).
We now analyze II. Note that by Assumption 2.2
X
kU i k22 â‰¤ Î¶ 2 (t + 1)M 2 N.
kft+1 (Ut )k22 â‰¤ Î¶ 2
0â‰¤iâ‰¤t

Then
II â‰¤ kBÌ‚ âˆ’ Bkop (M Î¶
Combining these bounds, we obtain,

p

N (t + 1))pâˆ’1 .

pâˆ’1

p
.
kB(Â·, ft+1 (Ut )) âˆ’ BÌ‚(Â·, ft+1 (UÌ‚t ))k2 â‰¤ Î¶c2 (BÌ‚)Î²N (t) + kBÌ‚ âˆ’ Bkop Î¶M N (t + 1)
12

(12)

Plugging this in to the above, yields
s
2

Î²N (t + 1) â‰¤ (1 + Î¶ )

2 (t) +
Î²N





âˆš pâˆ’1 2
Î¶c2 (BÌ‚)Î²N (t) + kBÌ‚ âˆ’ Bkop Î¶M N t
.

We can write the inequality above in the form
Î²N (t + 1) â‰¤ KÎ²N (t) + b(t),
where b(t) is non-decreasing, and K > 1 which depends only on c2 (BÌ‚) and Î¶. The inequality above is
a discrete version of Gronwallâ€™s inequality and using Î²N (0) = 0, easily leads to a bound

âˆš pâˆ’1
.
Î²N (t) â‰¤ K t b(t) = K t kBÌ‚ âˆ’ Bkop Î¶M N t

6

Concentration property of the AMP solution

In this section we establish that the value associated with the solution V produced by the AMP is
concentrated around its expectation.
Theorem 6.1. Suppose that Assumption 2.2 holds. For any Ç«, M, T, Î¶, there exists c > 0 such that such
that the value A(V ) associated with the solution V produced in Step 2 of Algorithm 2.3 satisfies



P |A(V ) âˆ’ E A(V )|U 0 | â‰¥ Ç«N |U 0 â‰¤ exp(âˆ’cN ),
sup
U 0 âˆˆ[âˆ’M,M ]N

for all sufficiently large N .
Proof. Fix U 0 . Our approach is based on Gaussian concentration combined with Kirszbraunâ€™s Theorem.
pâˆ’1
Let Z âˆˆ (RN )âŠ—p denote a tensor consisting of i.i.d. standard normal entries, so that A = Z/N 2
pâˆ’1
pâˆ’1
in distribution. We let f (Z) = A(V (A)) = Z(V (Z/N 2 ))/N 2 , where V = V (Z) is again the
solution produced by AMP viewed as a function of Z, and thus introduce f : (RN )âŠ—p â†’ R defined
pâˆ’1
pâˆ’1
by f (z) = z(V (z/N 2 ))/N 2 . We first establish that this function is Lipschitz with an appropriate
constant on an appropriate subspace of (RN )âŠ—p . Recall the constant c2 introduced in Proposition 4.2.
Let




z
N âŠ—p
K2,N = z âˆˆ (R ) : c2
â‰¤ c2 .
pâˆ’1
N 2
In particular, a random Z with i.i.d. standard normal entries satisfies
P (Z âˆˆ K2,N ) â‰¥ 1 âˆ’ exp(âˆ’cN ),
for all large enough N , where c is as in the proposition.
Lemma 6.2. There exists a constant c = c(M, c2 , Î¶, T ) such that for every z1 , z2 âˆˆ K2,N
âˆš
|f (z2 ) âˆ’ f (z1 )| â‰¤ c N kz2 âˆ’ z1 k2 .

13

(13)

Proof. Applying Theorem 5.1, for any z1 , z2 âˆˆ K2,N we have
kV (z2 /N

pâˆ’1
2

pâˆ’1
2

) âˆ’ V (z1 /N

)k2 â‰¤ cN

pâˆ’1
2

kN âˆ’

pâˆ’1
2

= ckz2 âˆ’ z1 kop ,

(z2 âˆ’ z1 )kop

(14)

where c = c(M, c2 , Î¶, T ) is an appropriate constant.
Next,
|f (z1 ) âˆ’ f (z2 )| = N âˆ’
â‰¤N
+N

pâˆ’1
2

âˆ’ pâˆ’1
2

âˆ’ pâˆ’1
2

|z2 (V (z2 /N
|z2 (V (z2 /N
|z1 (V (z2 /N

pâˆ’1
2
pâˆ’1
2
pâˆ’1
2

)) âˆ’ z1 (V (z1 /N
)) âˆ’ z1 (V (z2 /N
)) âˆ’ z1 (V (z1 /N

pâˆ’1
2
pâˆ’1
2
pâˆ’1
2

))|
))|
))|

We first analyze the second summand above. For simplicity we use v1 , v2 in place of V (z1 /N
pâˆ’1
V (z2 /N 2 ). Note z1 (u) = hu, z(Â·, u)i. Thus

(15)
pâˆ’1
2

) and

|z1 (v2 ) âˆ’ z1 (v1 )| = |hv2 , z1 (Â·, v2 )i âˆ’ hv1 , z1 (Â·, v1 )i|

â‰¤ |hv2 , z1 (Â·, v2 )i âˆ’ hv2 , z1 (Â·, v1 )i| + |hv2 , z1 (Â·, v1 )i âˆ’ hv1 , z1 (Â·, v1 )i|.

Then
|hv2 , z1 (Â·, v2 )i âˆ’ hv2 , z1 (Â·, v1 )i| = |hv2 , z1 (Â·, v2 ) âˆ’ z1 (Â·, v1 )i|

â‰¤ kv2 k2 kz1 (Â·, v2 ) âˆ’ z1 (Â·, v1 )k2
âˆš
pâˆ’1
pâˆ’1
â‰¤ M N N 2 c2 (z1 /N 2 )kv2 âˆ’ v1 k2 .

Since z1 âˆˆ K2,N , we obtain instead a bound
âˆš
âˆš
pâˆ’1
pâˆ’1
M N N 2 c2 kv2 âˆ’ v1 k2 â‰¤ M N N 2 c2 ckz2 âˆ’ z1 kop ,
where the inequality follows from (14).
For the second term we have
|hv2 , z1 (Â·, v1 )i âˆ’ hv1 , z1 (Â·, v1 )i| â‰¤ kv2 âˆ’ v1 k2 kz1 (Â·, v1 )k2
Since z1 âˆˆ K2,N and z1 (Â·, 0) = 0, then
kz1 (Â·, v1 )k2 â‰¤ N

pâˆ’1
2

c2 kv1 k2 â‰¤ N

pâˆ’1
2

âˆš
c2 M N .

âˆš
pâˆ’1
Using (14) to kv2 âˆ’ v1 k2 , we obtain a bound ckz2 âˆ’ z1 kop N 2 c2 M N .
Applying both bounds to (15) and using k Â· kop â‰¤ k Â· k2 we complete the proof.
We now complete the proof of the theorem. For every z âˆˆ (RN )âŠ—p , define


âˆš
f (zÌ‚) + c N kzÌ‚ âˆ’ zk2 ,
g(z) = inf
zÌ‚âˆˆK2,N

where c is âˆš
as in Lemma 6.2. Kirszbraunâ€™s Theorem says that g is a Lipschitz continuous function with
constant c N and g = f on K2,N . This is easy to verify. Indeed, fix any z1 , z2 âˆˆ (RN )âŠ—p and Ç« > 0.
Find zÌ‚1 âˆˆ K2,N such that


âˆš
|g(z1 ) âˆ’ f (zÌ‚1 ) + c N kzÌ‚1 âˆ’ z1 k2 | â‰¤ Ç«.
14

Then


âˆš
âˆš
g(z2 ) âˆ’ g(z1 ) â‰¤ f (zÌ‚1 ) + c NkzÌ‚1 âˆ’ z2 k2 âˆ’ f (zÌ‚1 ) + c N kzÌ‚1 âˆ’ z1 k2 + Ç«
âˆš
= c N (kzÌ‚1 âˆ’ z2 k2 âˆ’ kzÌ‚1 âˆ’ z1 k2 ) + Ç«
âˆš
â‰¤ c N kz2 âˆ’ z1 k2 .
Using a similar reversed inequality, the Lipschitz continuity of g is established. Now if z âˆˆ K2,N then
by Lemma 6.2 for every zÌ‚ âˆˆ K2,N
âˆš
f (zÌ‚) + c N kzÌ‚ âˆ’ zk2 â‰¥ f (z),
implying that the infimum is achieved by zÌ‚ = z, establishing the Kirszbraunâ€™s
Theorem.
âˆš
In conclusion, g is a Lipschitz continuous function with constant c N . Thus by Gaussian concentration (see, e.g., [Ver18]), for every t â‰¥ 0
 2 



t N
0
0
P |g(Z) âˆ’ E g(Z)|U | â‰¥ tN |U â‰¤ exp âˆ’ 2 .
4c

We now use the fact that f = g on the high probability set K2,N . Specifically








E g(Z)|U 0 = E f (Z)|U 0 âˆ’ E f (Z)1 (Z âˆˆ
/ K2,N ) |U 0 + E g(Z)1 (Z âˆˆ
/ K2,N ) |U 0 .

âˆš
âˆš
Using g(Z) â‰¤ f (0) + c N kZk2 = c N kZk2 we have
âˆš


/ K2,N )]
E g(Z)1 (Z âˆˆ
/ K2,N ) |U 0 â‰¤ c N E[kZk2 1 (Z âˆˆ
âˆš
1


1
/ K2,N )
â‰¤ c N E kZk22 2 P 2 (Z âˆˆ
â‰¤ exp(âˆ’c4 N ),

for some appropriately chosen c > 0 and all sufficiently large N , where in the second
line, we used that U 0


and A are independent, and the last inequality follows from (13) and from E kZk22 = N O(1) . Similarly,




pâˆ’1 P
|Zi1 ,...,ip |, we also have E f 2 (Z)|U 0 = N O(1) and thus E f (Z)1 (Z âˆˆ
/ K2,N ) |U 0
since f (Z) â‰¤ N âˆ’ 2
is at most exp(âˆ’c4 N ) for all large enough N , where we used the same notation for constant c4 as above
for convenience. We conclude




|E g(Z)|U 0 âˆ’ E f (Z)|U 0 | â‰¤ exp(âˆ’c5 N ),
for some c5 > 0 and all large N .
Thus for any t > 0



P (|f (Z)âˆ’ E f (Z)|U 0 | â‰¥ tN



â‰¤ P |g(Z) âˆ’ E f (Z)|U 0 | â‰¥ tN, 1 (Z âˆˆ K2,N ) + P(Z âˆˆ
/ K2,N )






0
0
â‰¤ P |g(Z) âˆ’ E g(Z)|U | â‰¥ tN âˆ’ E g(Z)|U âˆ’ E f (Z)|U 0
+ exp(âˆ’CN )



â‰¤ P |g(Z) âˆ’ E g(Z)|U 0 | â‰¥ (t/2)N + exp(âˆ’CN ),
â‰¤ exp(âˆ’c6 N ),

for all large enough N and appropriately chosen c6 > 0. As U 0 was arbitrary the result then follows.

15

7

OGP is an obstruction to AMP. Proof of the main result

In this section we complete the proof of the main result, Theorem 3.3. Let us begin by first conditioning
on the value of U 0 . Let A âˆˆ (RN )âŠ—p be a tensor with i.i.d. N (0, 1/N pâˆ’1 ) entries. Recall that by
assumption A and U 0 are independent. Let V = V (A) be the result of the Step 2 of Algorithm 2.3 after
T steps. Applying the concentration properties given by Theorems 2.1 and 6.1, it suffices to show that
for every Ç« > 0,


E A(V )|U 0
â‰¥ E[Î·N ] + Âµ âˆ’ Ç«,
N
for all large enough N , where Âµ is as in Conjecture 3.2, as in this case the main result would be
established for ÂµÌ„ = Âµ âˆ’ 2Ç« for every Ç« > 0.
Thus for the purposes of contradiction, assume


E A(V )|U 0 /N â‰¤ E[Î·N ] + Âµ2 .
(16)

for some Âµ2 < Âµ for infinitely many N .
Generate a tensor AÌ‚ âˆˆ (RN )âŠ—p distributed as A and independent from A and U 0 . Consider the
interpolated set A = (AÏ„ , Ï„ âˆˆ [0, 1]) described in Section 3. Denote by EOGP the high probability OGP
event defined in Conjecture 3.2 with parameters Âµ, Î½1 , Î½2 . Let VÏ„ be the vector produced by AMP when
run on tensor AÏ„ , Ï„ âˆˆ [0, 1]. For any Ï„ âˆˆ [0, 1] we have
âˆš
âˆš
âˆš
âˆš
k 1 âˆ’ Ï„ A(Â·, u) + Ï„ AÌ‚(Â·, u) âˆ’ ( 1 âˆ’ Ï„ A(Â·, v) + Ï„ AÌ‚(Â·, v))k2
c2 (AÏ„ ) =
sup
ku âˆ’ vk2
u6=vâˆˆ[âˆ’M,M ]N
âˆš
âˆš
â‰¤ 1 âˆ’ Ï„ c2 (A) + Ï„ c2 (AÌ‚)
â‰¤ c2 (A) + c2 (AÌ‚).

Applying Proposition 4.2 we have c2 (A) + c2 (AÌ‚) â‰¤ 2c2 modulo exponentially small in N probability.
We conclude that supÏ„ âˆˆ[0,1] c2 (AÏ„ ) â‰¤ 2c2 modulo exponentially small probability.
By Theorem 5.1 then modulo exponentially small probability, using k Â· kop â‰¤ k Â· k2 , we have that for
any Ï„1 , Ï„2 âˆˆ [0, 1]
kV Ï„1 âˆ’ V Ï„2 k2 â‰¤ C T N

pâˆ’1
2

kAÏ„1 âˆ’ AÏ„2 k2 ,

for some constant C > 0 which incorporates c2 , Î¶, and M (and which may change from line to line).
We have
âˆš
âˆš
âˆš
âˆš
kAÏ„1 âˆ’ AÏ„2 k2 = k 1 âˆ’ Ï„1 A âˆ’ 1 âˆ’ Ï„2 A + Ï„1 AÌ‚ âˆ’ Ï„2 AÌ‚k2

âˆš
âˆš
âˆš 
âˆš
â‰¤ | 1 âˆ’ Ï„1 âˆ’ 1 âˆ’ Ï„2 | + | Ï„1 âˆ’ Ï„2 | kAk2 + kAÌ‚k2 .

P
Since kAk22 is distributed as N âˆ’pâˆ’1 1â‰¤iâ‰¤N p Zi2 , which is N in expectation, then by standard large
deviations
estimates, P(kAk2 â‰¥ cN ) is exponentially small for any c > 1. In particular, kAk2 + kAÌ‚k2 â‰¤
âˆš
4 N , modulo exponentially small probability.
âˆš
âˆš
âˆš
âˆš
Combining and letting h(Ï„1 , Ï„2 ) = | 1 âˆ’ Ï„1 âˆ’ 1 âˆ’ Ï„2 | + | Ï„1 âˆ’ Ï„2 | we obtain
p

|kV Ï„1 k2 âˆ’ kV Ï„2 k2 | â‰¤ kV Ï„1 âˆ’ V Ï„2 k2 â‰¤ C T N 2 h(Ï„1 , Ï„2 ),
for all Ï„1 , Ï„2 modulo exponentially small in N probability.
16

(17)

Next, for any Ï„1 , Ï„2 âˆˆ [0, 1]
hV 0 , V Ï„2 i
hV 0 , V Ï„1 i
kV Ï„1 k2 hV 0 , V Ï„2 i âˆ’ kV Ï„2 k2 hV 0 , V Ï„1 i
âˆ’
=
.
kV 0 k2 kV Ï„2 k2 kV 0 k2 kV Ï„1 k2
kV 0 k2 kV Ï„1 k2 kV Ï„2 k2
For the numerator, applying the Cauchy-Scwhartz inequality
|kV Ï„2 k2 hV 0 , V Ï„1 i âˆ’ kV Ï„1 k2 hV 0 , V Ï„2 i|

= |kV Ï„2 k2 hV 0 , V Ï„1 i âˆ’ kV Ï„1 k2 hV 0 , V Ï„1 i + kV Ï„1 k2 hV 0 , V Ï„1 i âˆ’ kV Ï„1 k2 hV 0 , V Ï„2 i|
â‰¤ |kV Ï„2 k2 âˆ’ kV Ï„1 k2 | kV 0 k2 kV Ï„1 k2 + kV Ï„1 k2 kV 0 k2 kV Ï„2 âˆ’ V Ï„1 k2

Provided (17) holds, we obtain
p

hV 0 , V Ï„1 i
2C T N 2 h(Ï„1 , Ï„2 )
hV 0 , V Ï„2 i
âˆ’
.
â‰¤
kV 0 k2 kV Ï„2 k2 kV 0 k2 kV Ï„1 k2
kV Ï„2 k2
Next we fix Î± > 0, to be specified later, let Î´ = N âˆ’Î± . We assume for convenience that 1/Î´ = N Î± is
an integer. Introduce a discrete sequence Ï„nâˆš= nÎ´, 0 â‰¤ n â‰¤ 1/Î´. By Lemma 4.3, applying union in
N Î± terms bound, we have that kV Ï„n k â‰¥ C2 N for some C2 > 0 for all sufficiently large N , modulo
exponentially small probability. Provided this holds, the bound above can be replaced by
p

pâˆ’1
2C T N 2 h(Ï„1 , Ï„2 )
âˆš
= C T h(Ï„1 , Ï„2 )N 2 .
C2 N

Now we have
Î±

Î±

Î±

h(Ï„n1 , Ï„n2 ) â‰¤ C T N 2 (Ï„n2 âˆ’ Ï„n1 ) = C T N 2 N âˆ’Î± (n2 âˆ’ n1 ) = C T N âˆ’ 2 (n2 âˆ’ n1 ).
for all n1 , n2 and some C > 0.
Combining, we conclude that modulo exponentially small in N probability, for all n = 0, . . . , N Î± ,
pâˆ’1
Î±
hV 0 , V Ï„n i
hV 0 , V Ï„n+1 i
âˆ’
â‰¤ CT N 2 N âˆ’ 2
kV 0 k2 kV Ï„n+1 k2 kV 0 k2 kV Ï„n k2

and provided Î± > pâˆ’1 the bound above is o(1), and in particular is smaller than Î½2 âˆ’Î½1 for N sufficiently
large.
0
Ï„n i
Î±
Next we examine kVhV0 k2,V
kV Ï„n k2 in the extreme case n = 0 and n = N . The value is clearly 1 when
n = 0. Applying the second part of Conjecture 3.2 we have that for every Ç«, this value is at most
Ç«/C 2 modulo exponentially small probability, where C is the constant from Lemma 4.3. In particular
at n = N Î± this value is at most Î½1 . It follows that there must exist an index nâˆ— , (which is random in
general) such that
hV 0 , V Ï„nâˆ— i
âˆˆ (Î½1 , Î½2 ).
kV 0 k2 kV Ï„nâˆ— k2
Now in the event that OGP holds, which by Conjecture 3.2 holds modulo exponentially small probability,
this implies A(V Ï„nâˆ— )/N â‰¥ E[Î·N ] + Âµ and therefore the larger event
max A(V Ï„n )/N â‰¥ E[Î·N ] + Âµ.

0â‰¤nâ‰¤N Î±

However, this contradicts assumption (16) and the concentration bound of Theorem 6.1 applied in the
union over n = 0, . . . , N Î± bound. This yields the result conditionally on U 0 . Since the lower bound we
obtain does not depend on U 0 , we can take the expectation in U 0 , and obtain the main result.
17

8

TAP-type iteration schemes

One motivations for the AMP algorithm discussed in the introduction is the prediction that the minimizers of A(u) satisfy a self-consistent equation, called a â€œmean-fieldâ€ equation. In this setting, equations
of this type are called Thoulessâ€“Andersonâ€“Palmer (TAP) equations, after the work of those three authors in [TAP77], on mean-field equations in the case p = 2 on BN , in a certain physically motivated
relaxation. For a discussion of these and related results see also [MPV87]. In this section, we show
that, as an implication of Theorem 3.3, the iterative methods designed to produce solutions to TAP-like
equations fail, modulo Conjecture3.2.
More precisely, consider the following modification of the objective. Recall the Bernoulli entropy,
S : [âˆ’1, 1] â†’ R+
1
1
S(x) = (1 + x) log(1 + x) + (1 âˆ’ x) log(1 âˆ’ x).
2
2
For any Î² > 0, let fÎ² : [âˆ’1, 1] â†’ R
fÎ² (x) =

Î²2
(1 âˆ’ xp âˆ’ pxpâˆ’1 (1 âˆ’ x)),
2

Finally, define the one-parameter family of functions FÎ² : HN â†’ RN given by
FÎ² (x) = Î²A(x) âˆ’ S(x) + fÎ² (
Observe that as Î² â†’ âˆ,

FÎ² (u)
â†’
Î²

(
A(x)
âˆ

kxk2
).
N

x âˆˆ BN ,
x âˆˆ HN \ B N .

Thus one expects that for Î² very large, minimizers of FÎ² are near minimizers for A(u). In particular,
one approach to computing near minimizers for (2) would be to produce minimizers of F .
Differentiating FÎ² , we see that the critical points of F satisfy the fixed point equation
 


2
â€² kxk
x .
(18)
x = tanh Î²âˆ‡A(x) + 2f
N
Thus one approach to produce these minimizers is to construct solutions of these fixed point equations.
The AMP algorithm is one such method, based off of a deep intuition in the physics literature that
suggests that in the case p = 2.
Another approach, would be a more naive approach, in the spirit of standard AMP iterations would
be to simply iteratively construct solutions to (18) as in [Bol14]. It is expected that the critical points
of this equation satisfy,
kxk2
= qâˆ— (Î²),
N
where qâˆ— (Î²) is an explicit constant, called the Edwards-Anderson order parameter and is given by as in
[Mon18]. Motivated by this, consider the following class of AMP iterations,

U t = tanh Î²A(Â·, U tâˆ’1 ) + atâˆ’2 U tâˆ’2 , U0 = 1N q, Uâˆ’1 = 0 1 â‰¤ t â‰¤ T.

where q > 0 is a fixed constant and at is any bounded sequence. For instance, we may take at = 2f â€² (qâˆ— )
and q = qâˆ— . One might make the replacement at 7â†’ f â€² (kU t k22 /N ), however, one can show that this
will not change the performance if the original sequence was chosen appropriately. See Section 9 for a
similar argument in the more detailed case of the AMP iteration from [Mon18].
As a consequence of OGP, we see that the above iteration will fail to produced fixed points which
are also near optimizers of A(u) for Î² large. More precisely we have the following.
18

Corollary 8.1. Suppose that the entries of A âˆˆ (RN )âŠ—p are i.i.d. N (0, N âˆ’p+1 ) and p â‰¥ 4 is even.
Assuming the validity of Conjecture 3.2, there exists a ÂµÌ„ > 0 such that for any M, T > 0 and Î²
sufficiently large, if V = V (A) is the result of the firs two steps of the AMP algorithm after T iterations,
then
minxâˆˆHN F (x)
1
FÎ² (V ) â‰¥
+ ÂµÌ„.
Î²
N
Proof. First note that this iteration is of the form (8), for some functions Ft , ft satisfying Assumption 2.2.
Indeed, let
ft (u1 , . . . , ut ) = ut
Ft (u0 , . . . , ut ) = tanh(Î²u0 + atâˆ’2 utâˆ’2 ).
These functions are Lipschitz on the relevant domains as tanh(x) is smooth with bounded derivatives.
Thus by Theorem 3.3,
A(V ) â‰¥ min A(x)/N + ÂµÌ„.
xâˆˆBN

Now observe that FÎ² (x) satisfies FÎ² (x) â‰¥ Î²A(x) âˆ’ log(2) on HN . In particular, this is an equality
on BN . As a result,
A(x)
A(V ) log 2
1
FÎ² (V ) â‰¥
âˆ’
â‰¥ min
+ ÂµÌ„
xâˆˆBN N
NÎ²
N
Î²N
FÎ² (x)
FÎ² (x)
log(2)
â‰¥ min
+ ÂµÌ„ +
â‰¥ min
+ ÂµÌ„/2,
xâˆˆBN Î²N
xâˆˆHN Î²N
2Î²

where in the last line we take Î² >

9

log(2)
2ÂµÌ„

by assumption.

Verification for AMP for p-spin models

In this section we show that the AMP algorithm defined in [Mon18] is a special case of the AMP
defined in Section 2, modulo some truncation and averaging steps which we discuss below. Here p = 2
so A âˆˆ RN Ã—N is a matrix. The algorithm constructed in [Mon18] is as follows. A one-dimensional
measure Âµ is fixed which is a solution of the minimization problem of the Parisi functional. A function
Î¦ : [0, 1] Ã— R â†’ R is a solution of the associated PDF. It is known that âˆ‚x Î¦(t, x) and âˆ‚xx Î¦(t, x) of this
function are Lipschitz continuous. A certain value qâˆ— âˆˆ [0, 1] is fixed (it is Edward-Anderson parameter).
d

Let uâˆ’1 = 0 âˆˆ RN , u0 be i.i.d. standard normal vector in RN : u0 = N (0, IN ), g âˆ’2 = 0 âˆˆ RN , gâˆ’1 =
1N âˆˆ RN , b0 = 0 âˆˆ RN . Given a, b âˆˆ RN , a Â· b âˆˆ RN denotes a coordinate-wise product of a and b. Then
for t = 0, 1, . . . , âŒŠqâˆ— /Î´âŒ‹ , T ,
ut+1 = A(gtâˆ’1 Â· ut ) âˆ’ bt gtâˆ’2 Â· utâˆ’1 ,
t

tâˆ’1

2

tâˆ’1

âˆš

(19)
t

x =x
+ Î² Âµ(tÎ´)âˆ‚x Î¦(tÎ´, x )Î´ + Î² Î´u ,
âˆš
t
g = N âˆ‚xx Î¦(tÎ´, xt )/kâˆ‚xx Î¦(tÎ´, xt )k2 ,
X
git ,
bt = N âˆ’1

(20)
(21)
(22)

1â‰¤iâ‰¤N

where everywhere the functions are applied coordinate-wise.
We first consider modifications of these iterations and justify them. First set M to be a large
d
constant. Since u0 = N (0, IN ), then the fraction of coordinates of u0 with absolute values larger than
N decreases to zero as a function of M . Replace (19) by
ut+1 = [A(gtâˆ’1 Â· ut ) âˆ’ bt gtâˆ’2 Â· utâˆ’1 ]M .
19

(23)

In the final step of algorithm in [Mon18], the resulting vectors u1 , . . . , ut are used to construct
X
âˆš
z= Î´
gtâˆ’1 Â· ut ,
1â‰¤tâ‰¤âŒŠqâˆ— /Î´âŒ‹

and then z is rounded to a vector in HN via max(âˆ’1, min(1, Â·)) operator. It is thus expected that the
truncation of ut in (23) by a value M does not affect the result significantly provided M is large, though
we do not prove this fact.
t
Next, as an implication of the analysis in [Mon18], as N â†’ âˆ,
âˆšthe norm kÎ¦(tÎ´, x )k2 is concentrated
around a deterministic function of P
t, which which has value Î˜( N ). In particular, there it is argued
t = 1
Î´xti converges to some deterministic limit E t weakly almost surely.
that the empirical measure EN
N
Since âˆ‚xx Î¦ is smooth and bounded [JT16, Theorem 4], it then follows that
sZ
âˆš
t
t (y) â†’ h(t).
kâˆ‚xx Î¦(tÎ´, x )k/ N =
âˆ‚xx Î¦(tÎ´, y)dEN
Denoting this function by

âˆš

N h(t), t = 0, 1, . . . , T , we thus rewrite (21) as
gt = hâˆ’1 (t)âˆ‚xx Î¦(tÎ´, xt ).

(24)

Similarly, bt , which per (22) is defined as coordinate-wise average of g t , as N â†’ âˆ is concentrated
around a deterministic function of t, which we denote by Î·(t), t = 0, 1, . . . , T . Thus we replace (22) by
bt = Î· t .
We now fit these iterations into our framework defined in Section 2. We begin by defining ft . In
light of (24) replacing (21) we may define ft : Rt+1 â†’ R as follows
ft (u0 , . . . , ut ) = gtâˆ’1 (u0 , . . . , utâˆ’1 )ut ,

(25)

where the function gt : Rt â†’ R is a one-dimensional version of g t , namely
gt (u0 , . . . , ut ) = hâˆ’1 (t)âˆ‚xx Î¦(tÎ´, xt ),
where xt is defined through a one-dimensional version of (20):
âˆš
xt = xtâˆ’1 + Î² 2 Âµ(tÎ´)âˆ‚x Î¦(tÎ´, xtâˆ’1 )Î´ + Î² Î´ut .
Since âˆ‚xx Î¦ and âˆ‚xx Î¦ are Lipschitz continuous in the second argument for each fixed first argument, it
is then immediate to verify that gt : Rt â†’ R is Lipschitz continuous as a function of u0 , . . . , ut , wrt
k Â· kâˆ norm, say with constant Ct and satisfies gt (0) = 0. This implies kgt (x)kâˆ â‰¤ Ct kxkâˆ . Then by
(25) we have for every u0 , . . . , ut and v 0 , . . . , v t
|ft (u0 , . . . , ut ) âˆ’ ft (v 0 , . . . , v t )| = |gtâˆ’1 (u0 , . . . , utâˆ’1 )ut âˆ’ gtâˆ’1 (v 0 , . . . , v tâˆ’1 )v t |

â‰¤ Ct max(max(|uj |, |v j |)k(u0 , . . . , ut ) âˆ’ (v 0 , . . . , v t )kâˆ .
j

Thus ft is Lipschitz continuous on [âˆ’M, M ]t+1 , and thus satisfies the first part of Assumption 2.2.
Now motivated by (19) or rather (23) we define Ft : Rt+1 â†’ R by
Ft (y, u0 , . . . , ut ) = y âˆ’ bt g tâˆ’2 Â· utâˆ’1

= y âˆ’ Î·(t)hâˆ’1 (t âˆ’ 2)âˆ‚xx Î¦((t âˆ’ 2)Î´, xt ) Â· utâˆ’1

We see that Ft is Lipschitz continuous on R Ã— [âˆ’M, M ]t+1 and thus satisfies the second part of Assumption 2.2.
20

10

Some open questions

We now list some questions which remain open. First validating Conjectures 3.2 and 3.6 is of interest.
It is conceivable that the first of these conjectures can be approached by analyzing the Parisi measure
directly on the Hilbert cube HN , as opposed to the binary cube BN . Carrying out the corresponding
technical analysis of the associated variational problem could be quite daunting though. Another
interesting question left open in this work is establishing the negative result for the binary output Î (V )
of the AMP scheme (Step 3) directly, as opposed to one for the pen-ultimate state V . Lifting the
truncation [Â·]M assumption adopted by our class of AMP algorithms is another question which remains
open.
Next, it would be interesting to extend the main result of this paper to the p-spin spherical spin
glass model and complement the positive result of Subag [Sub18]. We expect that our negative result
extends to this model within the same scope of algorithms almost verbatim. Furthermore, by similar
arguments one can show that (continuous time) gradient flow started from a uniform at random point
fails to reach near minimizers of the spherical p-spin model in log(N ) time with probability tending to
1. That being said, it is important to note that Subagâ€™s algorithm is based on an iterative sequence
of computations which involve linear projections of gradient and Hessians of A(u) to the linear space
orthogonal to u. As such this computational scheme does not formally fit our framework of algorithms.
It is conceivable though that the projection step can be approximated well by iterations of the form
we consider, say perhaps by imitating the power iteration approach for spectral computations. Perhaps
as an easier challenge, one could try to show that Subagâ€™s scheme specifically fails to find near ground
states in models exhibiting OGP. A related question is whether there exists a connection between the
OGP and the algorithmic hardness of the REM model discussed in [ABM18].
Our approach was formulated in terms of bounded (N -independent) number of iterations T . It is
easy to see though that the proof method extends without a change to the case T â‰¤ c log N for small
enough constant c. At the same time we believe that AMP scheme is not effective in computing near
ground states, regardless of the scale of the number of iterations. Thus an interesting open question is
to see whether an AMP scheme achieving near ground states can be designed say when T = N O(1) .
Finally, perhaps the most intriguing question which remains open is one regarding the genuine
hardness of the problem of finding ground states in models exhibiting the OGP. While formal hardness of
problems associated with spin glass models is known, in particular it is shown in [GK18] that computing
the partition function of the p-spin models is hard on average even in p = 2 regime, these results are
established using more â€standardâ€ average case hardness proof approaches, and do not take advantage
of the intricate solution space topology, such as the one expressed by OGP. At the same time, as of now
we have very compelling consistence of the presence of OGP and the apparent hardness of the associated
optimization problem in many models. What is lacking, however, is the formal link between the two
within a class of algorithms which is broader than AMP. An interesting and challenging conjecture is
that the OGP implies formal average case hardness of the underlying optimization problem, perhaps
even within the class of all polynomial time algorithms.

Acknowledgements
The first author acknowledges the support from the Office of Naval Research Grant N00014-17-1-2790.
The second author acknowledges the partial support of the National Science Foundation Grant NSF
OISE-1604232.

21

References
[ABM18]

Louigi Addario-Berry and Pascal Maillard, The algorithmic hardness threshold for continuous random energy models, arXiv preprint arXiv:1810.05129 (2018).

[AC15]

Antonio Auffinger and Wei-Kuo Chen, On properties of Parisi measures, Probab. Theory
Related Fields 161 (2015), no. 3-4, 817â€“850. MR 3334282

[ACO08]

Dimitris Achlioptas and Amin Coja-Oghlan, Algorithmic barriers from phase transitions,
Foundations of Computer Science, 2008. FOCSâ€™08. IEEE 49th Annual IEEE Symposium
on, IEEE, 2008, pp. 793â€“802.

[ACORT11] D. Achlioptas, A. Coja-Oghlan, and F. Ricci-Tersenghi, On the solution space geometry of
random formulas, Random Structures and Algorithms 38 (2011), 251â€“268.
[ACZ17]

Antonio Auffinger, Wei-Kuo Chen, and Qiang Zeng, The sk model is full-step replica symmetry breaking at zero temperature, arXiv preprint arXiv:1703.06872 (2017).

[AT09]

Robert J Adler and Jonathan E Taylor, Random fields and geometry, Springer Science &
Business Media, 2009.

[BAGJ18a] Gerard Ben Arous, Reza Gheissari, and Aukosh Jagannath, Algorithmic thresholds for
tensor pca, arXiv preprint arXiv:1808.00921 (2018).
, Bounding flows for spherical spin glass dynamics, arXiv preprint arXiv:1808.00929

[BAGJ18b]
(2018).
[BAJ18]

GeÌrard Ben Arous and Aukosh Jagannath, Spectral gap estimates in mean field spin glasses,
Comm. Math. Phys. 361 (2018), no. 1, 1â€“52.

[BLM+ 15]

Mohsen Bayati, Marc Lelarge, Andrea Montanari, et al., Universality in polytope phase
transitions and message passing algorithms, The Annals of Applied Probability 25 (2015),
no. 2, 753â€“822.

[BM11]

Mohsen Bayati and Andrea Montanari, The dynamics of message passing on dense graphs,
with applications to compressed sensing, IEEE Transactions on Information Theory 57
(2011), no. 2, 764â€“785.

[BMN17]

Raphael Berthier, Andrea Montanari, and Phan-Minh Nguyen, State evolution for approximate message passing with non-separable functions, arXiv preprint arXiv:1708.03950
(2017).

[Bol14]

Erwin Bolthausen, An iterative construction of solutions of the tap equations for the
sherringtonâ€“kirkpatrick model, Communications in Mathematical Physics 325 (2014),
no. 1, 333â€“366.

[CGP+ 19]

Wei-Kuo Chen, David Gamarnik, Dmitry Panchenko, Mustazee Rahman, et al., Suboptimality of local algorithms for a class of max-cut problems, The Annals of Probability 47
(2019), no. 3, 1587â€“1618.

[CHL18]

Wei-Kuo Chen, Madeline Handschy, and Gilad Lerman, On the energy landscape of the
mixed even p-spin model, Probability Theory and Related Fields, 171 (2018) no.1-2, 53-95

22

[COE11]

A. Coja-Oghlan and C. Efthymiou, On independent sets in random graphs, Proceedings of
the Twenty-Second Annual ACM-SIAM Symposium on Discrete Algorithms, SIAM, 2011,
pp. 136â€“144.

[COHH17]

Amin Coja-Oghlan, Amir Haqshenas, and Samuel Hetterich, Walksat stalls well below
satisfiability, SIAM Journal on Discrete Mathematics 31 (2017), no. 2, 1160â€“1173.

[CS17]

Wei-Kuo Chen and Arnab Sen, Parisi formula, disorder chaos and fluctuation for the
ground state energy in the spherical mixed p-spin models, Comm. Math. Phys. 350 (2017),
no. 1, 129â€“173. MR 3606472

[DI17]

Gamarnik David and Zadik Ilias, High dimensional regression with binary coefficients.
estimating squared error and a phase transtition, Conference on Learning Theory, 2017,
pp. 948â€“953.

[DMM09]

David L Donoho, Arian Maleki, and Andrea Montanari, Message-passing algorithms for
compressed sensing, Proceedings of the National Academy of Sciences 106 (2009), no. 45,
18914â€“18919.

[GJS19]

David Gamarnik, Aukosh Jagannath, and Subhabrata Sen, The overlap gap property in
principal submatrix recovery, arXiv preprint arXiv:1908.09959 (2019).

[GK18]

David Gamarnik and Eren Kizildag, Computing the partition function of the sherringtonkirkpatrick model is hard on average, arXiv preprint arXiv:1810.05907 (2018).

[GL18]

David Gamarnik and Quan Li, Finding a large submatrix of a gaussian random matrix,
The Annals of Statistics 46 (2018), no. 6A, 2511â€“2561.

[GS17a]

David Gamarnik and Madhu Sudan, Limits of local algorithms over sparse random graphs,
Annals of Probability 45 (2017), 2353â€“2376.

[GS17b]

, Performance of sequential local algorithms for the random nae-k-sat problem,
SIAM Journal on Computing 46 (2017), no. 2, 590â€“619.

[JM13]

Adel Javanmard and Andrea Montanari, State evolution for general approximate message
passing algorithms, with applications to spatial coupling, Information and Inference: A
Journal of the IMA 2 (2013), no. 2, 115â€“144.

[JT16]

Aukosh Jagannath and Ian Tobasco, A dynamic programming approach to the parisi functional, Proceedings of the American Mathematical Society 144 (2016), no. 7, 3135â€“3150.

[JT17a]

, Low Temperature Asymptotics of Spherical Mean Field Spin Glasses, Comm.
Math. Phys. 352 (2017), no. 3, 979â€“1017. MR 3631397

[JT17b]

, Some properties of the phase diagram for mixed p-spin glasses, Probability Theory
and Related Fields 167 (2017), no. 3-4, 615â€“672.

[JT18]

, Bounds on the complexity of replica symmetry breaking for spherical spin glasses,
Proceedings of the American Mathematical Society 146 (2018), no. 7, 3127â€“3142.

[Kab03]

Yoshiyuki Kabashima, A cdma multiuser detection algorithm on the basis of belief propagation, Journal of Physics A: Mathematical and General 36 (2003), no. 43, 11111.

23

[MMZ05]

M. MeÌzard, T. Mora, and R. Zecchina, Clustering of solutions in the random satisfiability
problem, Physical Review Letters 94 (2005), no. 19, 197205.

[Mon18]

Andrea Montanari, Optimization of the sherrington-kirkpatrick hamiltonian, arXiv preprint
arXiv:1812.10897 (2018).

[MPV87]

M. Mezard, G. Parisi, and M. A. Virasoro, Spin-glass theory and beyond, vol 9 of Lecture
Notes in Physics, World Scientific, Singapore, 1987.

[MPZ02]

Marc MeÌzard, Giorgio Parisi, and Riccardo Zecchina, Analytic and algorithmic solution of
random satisfiability problems, Science 297 (2002), no. 5582, 812â€“815.

[Pan13]

Dmitry Panchenko, The sherrington-kirkpatrick model, Springer Science & Business Media,
2013.

[RV+ 17]

Mustazee Rahman, Balint Virag, et al., Local algorithms for independent sets are halfoptimal, The Annals of Probability 45 (2017), no. 3, 1543â€“1577.

[Sub18]

Eliran Subag, Following the ground-states of full-rsb spherical spin glasses, arXiv preprint
arXiv:1812.04588 (2018).

[Tal06]

Michel Talagrand, Free energy of the spherical mean field model, Probab. Theory Related
Fields 134 (2006), no. 3, 339â€“382. MR 2226885 (2007i:82034)

[TAP77]

David J Thouless, Philip W Anderson, and Robert G Palmer, Solution of â€™solvable model
of a spin glassâ€™, Philosophical Magazine 35 (1977), no. 3, 593â€“601.

[Tes12]

Gerald Teschl, Ordinary differential equations and dynamical systems, vol. 140, American
Mathematical Soc., 2012.

[Ver18]

Roman Vershynin, High-dimensional probability: An introduction with applications in data
science, vol. 47, Cambridge University Press, 2018.

24

