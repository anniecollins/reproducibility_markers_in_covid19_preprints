medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

1

Manuscript title: The Integrated Voxel Analysis Method (IVAM) to Diagnose Onset of

2

Alzheimerâ€™s Disease and Identify Brain Regions through Structural MRI Images.

3

Authors/Affilitiations: Matthew Hur1,*, Armen Aghajanyan2

4

1

5

Park, CA 94025. *Corresponding author.

Yale University, New Haven, CT 06520. 2Facebook Research, Facebook Corporation, Menlo

6

NOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 2
7

Abstract: Magnetic Resonance Imaging (MRI) provides three-dimensional anatomical and

8

physiological details of the human brain. We describe the Integrated Voxel Analysis Method

9

(IVAM) which, through machine learning, classifies MRI images of brains afflicted with early

10

Alzheimerâ€™s Disease (AD). This fully automatic method uses an extra trees regressor model in

11

which the feature vector input contains the intensities of voxels, whereby the effect of AD on a

12

single voxel can be predicted. The resulting tree predicts based on the following two steps: a K-

13

nearest neighbor (KNN) algorithm based on Euclidean distance with the feature vector to classify

14

whole images based on their distribution of affected voxels and a voxel-by-voxel classification by

15

the tree of every voxel in the image. An Ising model filter follows voxel-by-voxel tree-

16

classification to remove artifacts and to facilitate clustering of classification results which identify

17

significant voxel clusters affected by AD. We apply this method to T1-weighted MRI images

18

obtained from the Open Access Series of Imaging Studies (OASIS) using images belonging to

19

normal and early AD-afflicted individuals associated with a Client Dementia Rating (CDR) which

20

we use as the target in the supervised learning. Furthermore, statistical analysis using a pre-labeled

21

brain atlas automatically identifies significantly affected brain regions. While achieving 90% AD

22

classification accuracy on 198 images in the OASIS dataset, the method reveals morphological

23

differences caused by the onset of AD.

24

Introduction: Alzheimerâ€™s Disease (AD) is a prevalent degenerative disorder in todayâ€™s society

25

as the 7th leading cause of death in America (Speert et al., 2012). As the causes and inner

26

mechanisms underlying AD-related brain abnormalities are not fully understood, no cure has yet

27

been found; however, treatments such as pharmacology that inhibit acetylcholinerase have

28

successfully prolonged the lifespan of affected individuals by slowing down the degeneration of

29

acetylcholine-releasing neurons (Bianchetti et al., 2006). Other biomolecular phenomena

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 3
30

including the formation of beta-amyloid plaques and tao-fibrillary tangles have been implicated,

31

but its relation to macroscopic mechanisms concerning brain regions is still nebulous.

32

Computational methods for classification and segmentation can facilitate and supplement clinical

33

diagnoses.

34

In order to reveal these macroscopic mechanisms between brain regions, many current

35

image classification and segmentation algorithms incorporate an essential step of feature extraction.

36

For example, the widely used and effective Voxel-Based Morphometry (VBM) method is designed

37

for feature extraction to determine specific anatomic patterns of cerebral atrophy (Ashburner and

38

Friston, 2000). However, this method suffers from its dependence on a precise registration and

39

warping of MRI images to a priori probability maps (Veress et al., 2013). Its high sensitivity to

40

accurate registration creates a limitation because the templates inherently differ with various MRI

41

images due to structural variance of brain shape. Additionally, its high computational complexity

42

leads to complex implementation and long run-time. Other methods for segmentation such as the

43

Hybrid Watershed Algorithm (HWA) and the skull-stripping Brain Extraction Methods (BEM and

44

BEM2DE) rely on accurate iterative thresholding and on assumptions about brain shape that limit

45

their practical use when analyzing variegated brain shapes belonging to subjects of various

46

demographic groups (Fennema-Notestine et al., 2006). Fully automatic methods need to quickly

47

and effectively account for individual differences in brain shape without human supervision.

48

The essential steps that improve the results in these automatic methods are energy-based

49

deformation fields which identify regions of interest, whereby a driving force pushes an objective

50

function to convergence. Success of the energy methods can be attributed to the utilization of

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 4
51

information about local differences as well as about global trends of the image.

52
53

Figure 1: A flowchart outlining the Integrated Voxel Analysis Method (IVAM) with cross-sections

54

resembling certain steps. The preprocessing step incorporates spatial normalization and (not shown)

55

skull-stripping to create a dataset applicable to sampling for IVAM. The machine learning section

56

utilizes a K-Nearest Neighbor (KNN) classifier which takes as input the voxel-by-voxel classified

57

brain from an extra-randomized regressor tree.

58

We propose a multifaceted algorithm that utilizes methods for decision-tree learning to

59

robustly and automatically classify AD affected brains as well as cluster and segment classification

60

results of individual voxels to yield severely affected brain regions (Figure 1). First, the method,

61

termed the Integrated Voxel Analysis Method (IVAM), skull-strips each test and training MRI

62

image and spatially normalizes to the MNI152 brain-masked, i.e. skull-stripped, template. At the

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 5
63

center of our framework of integrated processes is a trained extra-randomized trees regressor

64

known to be highly effective for supervised learning of complex data (Geurts et al., 2006). The

65

trained model is used to estimate the distribution of Alzheimer affected voxels, which are sampled

66

from the MRI. A second model placed on top of the distributions predicts the CDR of the whole

67

brain. The aggregated learning model can also automatically relay information about specifically

68

affected brain regions allowing for novel insights into the inner neurological workings of AD

69

tailored to accurately diagnose AD in its early stages.

70

Methods:

71

A. Data Set.

72

We obtain 233 anonymous MRI images from the Open Access Series of Imaging Studies

73

(OASIS) (Buckner et al., 2004). Their age range is from 18-96 years with a mean of 53 years with

74

each clinically diagnosed with a Client Dementia Rating (CDR) which rates subjects based on 6

75

criteria: memory, orientation, judgment and problem solving, function in the community, home

76

and hobbies, and personal care (Buckner et al., 2004). The values range from 0 to 3 where 0

77

indicates no dementia while 0.5 and 1 indicate very mild and mild dementia respectively. In order

78

to specifically analyze the onset of AD and due to the sparsity of the dataset of images labeled

79

with a CDR > 1, we use images labeled with a CDR of 0, 0.5, and 1. All images are T1-weighted

80

prepared rapid echo-gradient and obtained on a 1.5-T vision scanner by the OASIS study. (Buckner

81

et al., 2004). Acquisition matrix was [256 256] with 128 contiguous saggital slices of thickness of

82

1.25 mm.

83

B. Skull-Stripping

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 6

84
85

Figure 2: (A) Left panel illustrates the raw rendering of the 3D image obtained from OASIS.

86

Right panel illustrates a brain with its skull image removed leaving behind gray and white

87

matter in the image.

88

We perform two gray-level thresholds on the raw MRI images using Matlab. Then, we

89

dilate the image with a ball structuring image, perform a third gray-level threshold, and isolate the

90

main part of the head by taking the largest connected component in 3D.

91

C. Spatial Normalization.

92

One of the most essential components to accurate analysis of MRI images is the spatial

93

normalization of the dataset. Through co-registration, processing of MRI images can be compared

94

across multiple subjects, especially important for brain Region of Interest (ROI) analysis in

95

pinpointing the affected regions. The images were normalized to the template provided by the

96

Montreal Neuroimaging Institute known as the MNI152 template built by averaging across 152

97

brains. The images were first converted to the same voxel resolution of 1mm x 1mm x 1mm and

98

symmetrically zero-padded to transform to the same dimensions. Next, each image was registered

99

to the MNI152 template using a one plus one evolutionary optimizer to maximize the mutual

100

information metric provided by David Mattes (Mattes et al., 2001).

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 7
101

D. Feature Selection

102

Feature selection algorithm relied on the assumption that the level of Alzheimerâ€™s projected

103

at a voxel depends on the surrounding voxels as well as the three-dimensional coordinate of the

104

voxel. Our feature vector included the values of all voxels around the voxel of interest with a preset

105

radius and the appended 3D coordinates of the voxels of interest as well as the gender of the subject

106

as male and female brain anatomy have been shown to exhibit structural differences (Ritchie et al.

107

2018). For each MRI image we enumerate all coordinates where the surrounding points are not all

108

zeros. For each voxel we selected features as described above. Because of the sheer size of MRI

109

images, we added a variable step constant throughout the whole aggregated model. Instead of

110

enumerating every point, the step dictates step incrementation in the coordinates for the voxel of

111

interest.

112

E. Building the Model.

113

The label of each feature vector is simply the CDR rating of respective patient. Once we

114

built the data-set, we randomly sampled half of the data and used that to train a the ensemble, Extra

115

Random Trees Regressor (Geurts et al., 2006) using the popular sklearn library (Pedregosa et al.,

116

2011). Although traditionally combined with an ensemble method such as Random Forests, these

117

Extra Random Tree Regressors (ERTR) tend to exhibit losses in accuracy observed through

118

computational trials we conducted compared to the ERTR alone. The ERTR now predicts the CDR

119

rating of single voxels in the MRI image.

120

F. Predicting the CDR.

121

Our method for predicting the CDR arises from our axiomatic assumption that the severity

122

of Alzheimerâ€™s disease in a patient, will be represented by the distribution of individual CDR

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 8
123

regressed voxels. Our first intuition was to use the Kullback-Leibler divergence as a tool to

124

compare the distributions. Although this gave us promising results, the utilization of K-Nearest

125

Neighbor (Bentley, 1975) achieved much greater accuracy than the Kullback-Leibler divergence.

126

Voxel sampling from the brain proceeded in the same way as feature selection, using the same

127

function. After sampling, the regression model predicted the CDR of each individual voxel. The

128

label or target for the KNN algorithm arises as a function of the CDR of the respective patient.

129

The accuracy will be introduced at the Discussion section below.

130

G. Identifying Severely Affected Brain Regions.

131

The process of pinpointing severely affected brain regions from MRIâ€™s can be seen as a

132

pipelining process. A sagittal half-brain slice of a normalized MRI image compares to the

133

following CDR classified image: the classified image depicts the results of the denoising model

134

applied to the CDR voxel predictions. Black, grey, and white correspond to CDR predictions of 0,

135

0.5, and 1 respectively.

136
137

H. Denoising via Ising Model
Using Murphyâ€™s derivation of the Ising model, we define the probability of the update as
log ğ‘Ìƒ(ğ‘¦) = âˆ’ âˆ‘ğ‘ â‰ ğ‘¡ ğ‘¦ğ‘  ğ‘¤ğ‘ ğ‘¡ ğ‘¦ğ‘¡ (1)

138
139

(Murphy, 2012).

140

The weight wst signifies the amount we attribute to the difference between the two pixels

141

from each 2D slice and yğ‘› represents the intensity value of voxel y. To simplify the calculations,

142

we modify our equation to:

143

1

log ğ‘Ìƒ(ğ‘¦) = 2 y ğ‘‡ Wy (2),

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 9
144

where W is a Toeplitz matrix. We define our objective function as

145

argmax p(y, x) = p(x)p(y|x) (3).

146

Continuing, by Murphyâ€™s derivation, the unnormalized prior develops as follows:
1

1

147

p(x) = Z eâˆ’E0(x) = ğ‘ eâˆ‘ğ‘– âˆ‘ğ‘—âˆˆğ‘›ğ‘â„ğ‘‘(ğ‘–) ğ‘Šğ‘–ğ‘—ğ‘¥ğ‘– ğ‘¥ğ‘— (4),

148

where nbhd denotes the immediate neighborhood of the two-dimensional pixel j. The Z0 is not

149

needed since we are using the unnormalized prior. On the other hand, our unnormalized posterior

150

will be:

0

p(x|y) =

151

152

p(x,y)

1

= Z eâˆ‘ğ‘– ğ¿ğ‘– (ğ‘¥ğ‘– )âˆ’ğ¸0 (ğ‘¥) (5).

log qj (xj) = Eâˆ’qğ‘— [log pÌƒ(x)] + const (6).
and since
Eâˆ’ğ‘ğ‘— (f) = âˆ‘ğ‘˜â‰ ğ‘— ğ‘(ğ‘¥ğ‘— , ğœ‡ğ‘— |ğ‘¥ğ‘— )ğ‘“(ğ‘—) = âˆ‘ğ‘˜â‰ ğ‘— ğ‘(ğœ‡ğ‘— )ğ‘“(ğ‘—) (7),

155

156

p(y|x)p(x)

For the mean field update, we need to compute (see Murphy section 21.3.1 for details)

153

154

0

we have

157

q ğ‘– (xğ‘– ) âˆ ğ‘’ ğ‘¥ğ‘– âˆ‘ğ‘—âˆˆğ‘›ğ‘â„ğ‘‘ ğ‘Šğ‘–ğ‘—ğœ‡ğ‘—+ğ¿ğ‘– (ğ‘¥ğ‘– ) (8).

158

which yields the important theoretical step. Murphy derives an actual update. In Murphyâ€™s

159

(Murphy, 2012) derivation (page 738), note that it uses

160

L + i â‰¡ Li(+1) and L âˆ’ i â‰¡ Li(âˆ’1) (9).

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 10
161

which are the log likelihood functions centered at each of these two values. The variance in the

162

likelihood controls the strength of the prior. This is the final update, which also incorporates a

163

damping term:

164

Âµğ‘¡ğ‘– = (1 âˆ’ Î»)Âµğ‘– + Î» tanh (xğ‘–

âˆ‘ Wğ‘–ğ‘— Âµğ‘— + 0.5(L+ğ‘– âˆ’ Lâˆ’ğ‘– )) (10)
ğ‘—âˆˆğ‘›ğ‘â„ğ‘‘

165

To convert this algorithm into a tertiary denoiser, we introduced this function to convert CDR to

166

Ising denoiser values,

167
168

(2 âˆ— CDR) â€“ 1 (11).
I. Clustering and Segmentation Model.

169

Our clustering and segmentation model bases on Wardâ€™s method (Ward, 1963). We input

170

the connectivity matrix of the denoised image into Wardâ€™s hierarchical clustering method. The

171

connectivity matrix can be defined as a matrix where each sample is defined through the

172

neighboring samples following a given structure of the data. The connectedness structure of the

173

data consisted of the one-voxel neighborhood of each voxel.

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 11
174

Results:

175
176

Figure 3: Shown are three sagittal cross-sections of brains afflicted by Alzheimerâ€™s Disease with

177

a CDR of 0.5. Two brains show high severity near the hippocampus while all three show moderate

178

to severe severity near the inferior sagittal sinus. OASIS 339 illustrates how many brains afflicted

179

by Alzheimerâ€™s Disease show severity near the cortices separating brain lobes.

180

The hippocampus, heavily involved in memory storage, appears highly affected at both 0.5

181

and 1.0 CDR according to IVAM. In a sagittal cross-section, the streak above the hippocampus

182

known as the inferior sagittal sinus appears slightly less but still highly affected by early

183

Alzheimerâ€™s Disease.

184

To automate the finding of affected brain regions, we downloaded the Talairach labeled

185

database and registered it to the MNI template, then through a series of 90 degree 3D rotations,

186

matched it to the orientation of 3D classified brains. Testing the difference between brain regions

187

of CDRs of 0 (n = 51) and 0.5 (n = 11), the results are shown in Table 1.

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 12
Table 2: Significances between brains with CDR of 0 (n = 51) and 0.5 (n = 11).
Region Name
1
'Left Cerebrum.Limbic Lobe.Inferior Temporal Gyrus.White Matter.*'
2
'Left Cerebrum.Frontal Lobe.*.*.*'
3
'Right Cerebrum.Frontal Lobe.*.*.*'
4
'Left Cerebellum.Anterior Lobe.Pyramis.Gray Matter.*'
'Right Cerebrum.Limbic Lobe.Fusiform Gyrus.Gray Matter.Brodmann
5
area 20'
6
'Right Cerebrum.Limbic Lobe.Fusiform Gyrus.White Matter.*'
'Right Cerebrum.Frontal Lobe.Orbital Gyrus.Gray Matter.Brodmann
7
area 47'
8
'Right Cerebrum.Frontal Lobe.Middle Frontal Gyrus.*.*'
'Left Cerebrum.Limbic Lobe.Parahippocampal Gyrus.Gray
9
Matter.Amygdala'
10
'Left Cerebrum.Frontal Lobe.Medial Frontal Gyrus.*.*'
'Left Cerebrum.Occipital Lobe.Fusiform Gyrus.Gray Matter.Brodmann
11
area 19'
12
'Left Cerebrum.Frontal Lobe.Subcallosal Gyrus.*.*'
13
'Right Cerebrum.Frontal Lobe.Subcallosal Gyrus.White Matter.*'
'Right Cerebrum.Frontal Lobe.Subcallosal Gyrus.Gray
14
Matter.Brodmann area 47'
15
'Right Cerebrum.Occipital Lobe.Middle Occipital Gyrus.*.*'
'Right Cerebrum.Occipital Lobe.Parahippocampal Gyrus.Gray
16
Matter.Brodmann area 37'
17
'Left Cerebrum.Sub-lobar.Third Ventricle.Cerebro-Spinal Fluid.*'
'Right Cerebrum.Temporal Lobe.Sub-Gyral.Gray Matter.Brodmann area
18
13'
19
'Left Cerebrum.Frontal Lobe.Extra-Nuclear.*.*'
'Right Cerebrum.Frontal Lobe.Superior Frontal Gyrus.Gray
20
Matter.Brodmann area 10'
21
'*.*.Sub-Gyral.*.*'
22
'Right Cerebrum.Sub-lobar.Caudate.Gray Matter.Caudate Head'
'Right Cerebrum.Sub-lobar.Inferior Frontal Gyrus.Gray
23
Matter.Brodmann area 47'
24
'Right Cerebrum.Frontal Lobe.*.Gray Matter.Brodmann area 10'
'Right Cerebrum.Occipital Lobe.Inferior Temporal Gyrus.Gray
25
Matter.Brodmann area 18'
26
'Right Cerebrum.Midbrain.Extra-Nuclear.White Matter.*'
27
'Left Cerebrum.Frontal-Temporal Space.Superior Temporal Gyrus.*.*'
'Right Cerebrum.Frontal Lobe.Sub-Gyral.Gray Matter.Brodmann area
28
10'
29
'Right Cerebrum.*.Cuneus.Gray Matter.*'
'Right Cerebrum.Temporal Lobe.Lingual Gyrus.Gray Matter.Brodmann
30
area 19'

p-value
0.047568
0.041913
0.035739
0.010867
0.025399
0.027071
0.045191
0.00947
0.037748
0.03215
0.032959
0.02893
0.042401
0.028412
0.043875
0.018895
0.021665
0.035569
0.045111
0.047755
0.049801
0.025211
0.006871
0.034613
0.043662
0.025544
0.049101
0.027311
0.003708
0.033767

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 13

31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60

'Right Cerebrum.Temporal Lobe.Superior Temporal Gyrus.Gray
Matter.*'
'Right Cerebrum.Sub-lobar.Extra-Nuclear.White Matter.Medial Globus
Pallidus'
'Left Cerebrum.Sub-lobar.Inferior Frontal Gyrus.Gray Matter.Brodmann
area 47'
'Left Cerebrum.Sub-lobar.Thalamus.Gray Matter.Pulvinar'
'Left Cerebrum.Sub-lobar.Inferior Frontal Gyrus.*.*'
'Left Cerebrum.Limbic Lobe.Posterior Cingulate.Gray Matter.Brodmann
area 30'
'Left Cerebrum.Occipital Lobe.Middle Temporal Gyrus.Gray
Matter.Brodmann area 19'
'Right Cerebrum.Occipital Lobe.Middle Temporal Gyrus.Gray
Matter.Brodmann area 39'
'Right Cerebrum.Temporal Lobe.Superior Temporal Gyrus.Gray
Matter.Brodmann area 39'
'Left Cerebrum.Temporal Lobe.Transverse Temporal Gyrus.Gray
Matter.Brodmann area 41'
'Left Cerebrum.Sub-lobar.Transverse Temporal Gyrus.Gray
Matter.Brodmann area 41'
'Left Cerebrum.Sub-lobar.Thalamus.Gray Matter.Lateral Posterior
Nucleus'
'Right Cerebrum.Temporal Lobe.Precentral Gyrus.White Matter.*'
'Left Cerebrum.Frontal Lobe.Insula.White Matter.*'
'Left Cerebrum.Limbic Lobe.Extra-Nuclear.*.*'
'Inter-Hemispheric.Limbic Lobe.Anterior Cingulate.*.*'
'Left Cerebrum.*.Middle Frontal Gyrus.*.*'
'Left Cerebrum.Limbic Lobe.Posterior Cingulate.Gray Matter.*'
'Right Cerebrum.Limbic Lobe.Posterior Cingulate.Gray Matter.*'
'Right Cerebrum.Parietal Lobe.Precentral Gyrus.*.*'
'Left Cerebrum.Frontal Lobe.Inferior Frontal Gyrus.Gray
Matter.Brodmann area 6'
'Left Cerebrum.*.Inferior Frontal Gyrus.*.*'
'Right Cerebrum.Occipital Lobe.Precuneus.Gray Matter.Brodmann area
18'
'Left Cerebrum.Occipital Lobe.Superior Occipital Gyrus.Gray
Matter.Brodmann area 19'
'Right Cerebrum.Temporal Lobe.Cuneus.White Matter.*'
'Right Cerebrum.Temporal Lobe.Inferior Parietal Lobule.*.*'
'Right Cerebrum.Parietal Lobe.Inferior Parietal Lobule.*.*'
'Right Cerebrum.Parietal Lobe.Postcentral Gyrus.Gray
Matter.Brodmann area 3'
'Inter-Hemispheric.*.Superior Frontal Gyrus.*.*'
'Right Cerebrum.Frontal Lobe.Inferior Parietal Lobule.White Matter.*'

0.007284
0.000862
0.017253
0.04674
0.037133
0.026286
0.0116
0.046534
0.035883
0.009321
0.009155
0.005067
0.031295
0.046733
0.030946
0.020917
0.005934
0.013244
0.032718
0.030813
0.045349
0.022252
0.029092
0.033095
0.017632
0.04041
0.026267
0.048072
0.026462
0.010282

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 14
61
62
63
64

188

'Right Cerebrum.Limbic Lobe.Medial Frontal Gyrus.*.*'
0.038014
'Left Cerebrum.Occipital Lobe.Angular Gyrus.*.*'
0.041118
'Right Cerebrum.Occipital Lobe.Angular Gyrus.*.*'
0.029264
'Left Cerebrum.Parietal Lobe.Precuneus.Gray Matter.Brodmann area 39' 0.040566
'Left Cerebrum.Parietal Lobe.Angular Gyrus.Gray Matter.Brodmann
65
area 40'
0.041285
'Right Cerebrum.Parietal Lobe.Sub-Gyral.Gray Matter.Brodmann area
66
40'
0.049041
67
'Left Cerebrum.Frontal Lobe.Sub-Gyral.Gray Matter.Brodmann area 6'
0.044811
'Right Cerebrum.Frontal Lobe.Superior Frontal Gyrus.Gray
68
Matter.Brodmann area 8'
0.027852
69
'Left Cerebrum.Parietal Lobe.Superior Parietal Lobule.*.*'
0.028557
'Right Cerebrum.Parietal Lobe.Superior Parietal Lobule.Gray
70
Matter.Brodmann area 7'
0.048063
71
'Left Cerebrum.Frontal Lobe.Paracentral Lobule.*.*'
0.006011
Table 2: Significances between brains with CDR of 0 (n = 24) and 1 (n = 8).
Brain Region
P-Value
1
'Right Cerebrum.Temporal Lobe.Insula.Gray Matter.*'
0.019939
2
'Left Cerebrum.Frontal Lobe.Middle Frontal Gyrus.Gray Matter.*'
0.037358
'Right Cerebrum.Sub-lobar.Inferior Frontal Gyrus.Gray
3
Matter.Brodmann area 45'
0.045422
4
'Left Cerebrum.Sub-lobar.Transverse Temporal Gyrus.White Matter.*'
0.015406
'Right Cerebrum.Temporal Lobe.Transverse Temporal Gyrus.Gray
5
Matter.Brodmann area 42'
0.018149
'Right Cerebrum.Limbic Lobe.Posterior Cingulate.Gray
6
Matter.Brodmann area 31'
0.031017
'Left Cerebrum.Limbic Lobe.Posterior Cingulate.Gray Matter.Brodmann
7
area 18'
0.040112
8
'Left Cerebrum.Parietal Lobe.Postcentral Gyrus.*.*'
0.036241
9
'Left Cerebrum.Parietal Lobe.Postcentral Gyrus.Gray Matter.*'
0.049764
'Left Cerebrum.Frontal Lobe.Postcentral Gyrus.Gray Matter.Brodmann
10
area 4'
0.040556
'Right Cerebrum.Parietal Lobe.Postcentral Gyrus.Gray
11
Matter.Brodmann area 3'
0.034089
12
'Right Cerebrum.Occipital Lobe.Cuneus.Gray Matter.Brodmann area 31' 0.019641
13
'*.*.Angular Gyrus.*.*'
0.031262
14
'Left Cerebrum.Parietal Lobe.Sub-Gyral.Gray Matter.Brodmann area 2'
0.035837
15
'Left Cerebrum.Parietal Lobe.Superior Parietal Lobule.*.*'
0.049594
'Right Cerebrum.Parietal Lobe.Paracentral Lobule.Gray
16
Matter.Brodmann area 5'
0.037892
'Right Cerebrum.Parietal Lobe.Postcentral Gyrus.Gray
17
Matter.Brodmann area 5'
0.015352
The Python code is freely available on Github: https://github.com/mattonics/IVAM.

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 15
189

Conclusion:

190

We created the best performing algorithm to-date for classifying 3D images taken of

191

patients of neurodegenerative and neuropsychiatric diseases. In addition, the accuracy for voxel-

192

by-voxel classification hovers around 83% as we labeled each voxel with the CDR of the brain.

193

These diseases and disorders exhibit classification through many types of benchmarks that rate

194

their severity. The IVAM code can be easily modified to accommodate different rating scales.

195

Discussion:

196

The skull-stripping algorithm we developed performs extremely well visually as shown for

197

a single MRI image (Figure 2) separating the cortices from the skull as well as the cerebellum and

198

lower brain from the skull in most instances. It performed successfully on a lot of the 380 images.

199

There are examples of a missing lower brain, but nevertheless the algorithm achieved up to 90.0%

200

classification accuracy. Adjustment of the dimensions of the structuring element could improve

201

the results as well as a more robust thresholding algorithm such as a modified IsoData algorithm.

202

A previously running version of IVAM which ran on spatially normalized images performed by

203

OASIS authors but not skull-stripped by us achieved 92.2%. These data were pre-processed as a

204

non-linear warping to the MNI152 template by OASIS authors.

205

After running IVAM on nearly 200 images in the OASIS dataset, we find that a single

206

extra-randomized tree regressor predicts with 90.0% accuracy when trained on around 90% of the

207

dataset and tested on around 10% of the dataset, which represents the highest accuracy reported

208

to-date on structural MRI images of Alzheimerâ€™s Disease patients, as a tertiary regression on CDRs

209

of 0, 0.5, and 1 in early AD and 83.3% accuracy as a binary regression of 0 and any higher CDR.

210

We also find that the extra-randomized trees regressor as a forest (a bag of trees) predicts with

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 16
211

89.7% accuracy as a tertiary regression and 83.8% accuracy as a binary regression. We found that

212

the single extra-randomized regressor tree predicts better than a bag of them. Current state-of-the-

213

art prediction methods include a maximum of around 85% in binary classification as explained by

214

Moscoso et al. 2019.

215

Next steps include improving the KNN part of the algorithm to accept non-integer values,

216

i.e. CDR of 0.5, which should theoretically yield higher accuracy than the current tertiary

217

classification, and improving identification of severely affected areas to a probabilistic map using

218

the labeled MNI152 atlas which can be retrieved by installing MindBoggle.

219

Acknowledgements:

220

We would like to thank Dr. Nigel S. Bamford for giving critiques on the performance of our

221

algorithm and reviewing our writing.

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 17
222

References

223

Ashburner, J. and Friston, K. J. (2000). Voxel-based morphometry- the methods. Neuroimage,

224

11:805â€“821.

225

Babu, S. G. and Suresh, S. (2013). Meta-cognitive rbf network and its projection based learning

226

algorithm for classification problems. Cognitive Computation, 6(2).

227

Bentley, J. L. (1975). Multidimensional binary search trees used for associative searching.

228

Commun. ACM, 18(9):509â€“ 517.

229

Bianchetti, A., Ranieri, P., Margiotta, A., and Trabucchi, M. (2006). Pharmacological treatment of

230

Alzheimerâ€™s Disease. Aging clinical and experimental research, 18(2)(158-162).

231

Buckner, R. L., Head, D., Parker, J., Fotenos, A. F., Marcus, D., Morris, J. C., and Snyder, A. Z.

232

(2004). A unified approach for morphometric and functional data analysis in young, old, and

233

demented adults using automated atlasbased head size normalization: reliability and validation

234

against manual measurement of total intracranial volume. Elsevier, 23(2)(724-738).

235

Fennema-Notestine, C., Ozyurt, I. B., Clark, C. P., Morris, S., Bischoff-Grethe, A., Bondi, M. W.,

236

Geurts, P., Ernst, D., and Wehenkel, L. (2006). Extremely randomized trees. Machine Learning,

237

63(1):3â€“42.

238

Jernigan, T. L., Fischl, B., Segonne, F., Shattuck, D. W., Leahy, R. M., Rex, D. E., Toga, A. W.,

239

Zou, K. H., and Brown, G. G. (2006). Quantitative evaluation of automated skull-stripping

240

methods applied to contemporary and legacy images: effects of diagnosis, bias correction, and

241

slice location. Hum Brain Mapp, 27(2):99â€“113.

242

Kullback, S. and Leibler, R. A. (1951). On information and sufficiency. Ann. Math. Statist.,

243

22(1):79â€“86.

medRxiv preprint doi: https://doi.org/10.1101/19009597; this version posted October 29, 2019. The copyright holder for this preprint (which was
not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
All rights reserved. No reuse allowed without permission.

Hur 18
244

Mattes, D., David, H., Vessele, H., Lewellyn, T., and Eubank, W. (2001). Nonrigid multimodality

245

image registration. Medical Imaging. Murphy, K. P. (2012). Machine learning: a probabilistic

246

perspective. Cambridge, MA.

247

Moscoso, A., Silva-Rodriguez J., Aldrey M., J., Cortes, J., Fernandez-Ferreiro A., Gomez-Lado,

248

N., Ruibal, A., Aguiar, P. (2019). Prediction of Alzheimerâ€™s disease dementia with MRI beyond

249

the short-term: Implications for the design of predictive models. Neuroimage Clin. 23: 101837

250

Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M.,

251

Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M.,

252

Perrot, M., and Duchesnay, E. (2011). Scikitlearn: Machine learning in Python. Journal of Machine

253

Learning Research, 12:2825â€“2830.

254

Scholkopf, B. and Smola, A. J. (2002). Learning with kernels. MIT Press.

255

Speert, D., Benson, T., Cameron, J., Kaplan, B., Parfitt, D., and Roskams, A. J. (2012). BrainFacts

256

A Primer on the Brain and Nervous System. Society for Neuroscience.

257

Veress, A. I., Klein, G., and Gullberg, G. T. (2013). A comparison of hyperelastic warping of pet

258

images with tagged mri for the analysis of cardiac deformation. Int. J. Biomedical Imaging, 2013.

259

Ward, J. H. (1963). Hierarchical grouping to optimize an objective function. Journal of the

260

American Statistical Association, 58(301):236â€“244

