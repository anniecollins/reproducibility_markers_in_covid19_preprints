arXiv:2103.07240v1 [eess.IV] 12 Mar 2021

Longitudinal Quantitative Assessment of
COVID-19 Infection Progression
from Chest CTs
Seong Tae Kim1,2,? , Leili Goli3,? , Magdalini Paschali1 , Ashkan Khakzar1 ,
Matthias Keicher1 , Tobias Czempiel1 , Egon Burian4 , Rickmer Braren4 , Nassir
Navab1,5 ,Thomas Wendler1
1

Computer Aided Medical Procedures and Augmented Reality, Technical University
of Munich, Germany
2
Department of Computer Science and Engineering, Kyung Hee University,
Republic of Korea
3
Department of Computer Engineering, Sharif University of Technology, Iran
4
Department of Diagnostic and Interventional Radiology, Technical University of
Munich, Germany
5
Computer Aided Medical Procedures, Johns Hopkins University, USA

Abstract. Chest computed tomography (CT) has played an essential
diagnostic role in assessing patients with COVID-19 by showing diseasespecific image features such as ground-glass opacity and consolidation.
Image segmentation methods have proven to help quantify the disease
burden and even help predict the outcome. The availability of longitudinal CT series may also result in an efficient and effective method to
reliably assess the progression of COVID-19, monitor the healing process
and the response to different therapeutic strategies. In this paper, we propose a new framework to identify infection at a voxel level (identification
of healthy lung, consolidation, and ground-glass opacity) and visualize
the progression of COVID-19 using sequential low-dose non-contrast CT
scans. In particular, we devise a longitudinal segmentation network that
utilizes the reference scan information to improve the performance of disease identification. Experimental results on a clinical longitudinal dataset
collected in our institution show the effectiveness of the proposed method
compared to the static deep neural networks for disease quantification.
Keywords: Longitudinal Analysis ¬∑ COVID-19 ¬∑ Disease Progression

1

Introduction

The Coronavirus Disease 2019 (COVID-19) has infected more than 113 million
people worldwide (as of February 28th, 20216 ) and caused more than 2.52 million
deaths. Although many cases present only mild symptoms, some of them evolve
into serious illnesses that require intensive medical treatment or lead to death [7].
?
6

First two authors contributed equally to this work.
https://coronavirus.jhu.edu/map.html

2

Kim and Goli et al.

Chest X-ray computed tomography (CT) has played an essential diagnostic
role in the assessment of patients with COVID-19 by showing specific image patterns such as ground-glass opacity (GGO), crazy paving, and consolidation [20].
Several studies have proposed to automatically analyze COVID-19 infection
on CT images with deep learning [5,24,19]. Zhou et al. [24] introduce a 2.5D
segmentation model with a novel data augmentation method to alleviate the
limited number of training data issues. Fan et al. [5] propose a semi-supervised
learning approach for segmenting ground-glass opacity and consolidation on lung
CT scans. Wang et al. [19] offer a noise-robust training method for segmentation
of COVID-19 pneumonia on lung CT scan.
However, it is still challenging to automatically identify and quantify CT
image findings associated with COVID-19 due to the subtle anatomical boundaries, pleural-based location, and variations in size, density, location, and texture [12,17,25]. Moreover, it is vital to develop an efficient and effective method to
reliably assess the progression of COVID-19 and response to therapy [6,21]. Also,
given the availability of multiple therapy options and to understand anatomical changes during the healing process, a longitudinal evaluation of CT images
would be beneficial [6,9].
Only a few studies have devoted to developing a deep learning-based approach to assess the progression and response to therapy from longitudinal CT
scans [23,15]. Zhang et al. propose a static segmentation model to classify the
patients into mild and severe patients based on the features extracted from longitudinal CT scans [23]. Pu et al. propose a framework consisting on the following steps (1) segment the lung boundary and vessels, (2) register the boundary
between serial scans using deformable registration, (3) identify regions with morphological changes due to the disease, and (4) assess disease progression [15]. The
registered longitudinal CT scans are used to generate a heatmap visualizing the
difference in diseased vs. healthy areas between scans. Yet, the identification of
affected regions is performed in a static way, i.e., the information between serial
scans is not taken into account. Besides, they do not differentiate image features
of consolidation and ground-glass opacity, even though these pathologies provide
different information of infection in COVID-19 cases [26].
In this paper, we propose a novel framework to identify infection at a finegrained level (identification of healthy lung, consolidation, GGO, and pleural
effusion) by leveraging spatio-temporal cues between longitudinal scans and visualize the progression of COVID-19. In particular, we devise a longitudinal
segmentation network that utilizes the reference scan information to improve
the performance of disease segmentation. Even though longitudinal scans share
structural information, differences exist due to the progression of the disease.
We investigate and propose ways to use this information during the segmentation based on a limited dataset collected during the first COVID-19 wave of our
institution. The following is the summary of the main contributions
‚Äì To the best of our knowledge, this is the first study to explore the longitudinal
segmentation of CTs of COVID-19 patients. By designing a deep neural
network to use the information provided in the reference scan, we show

Longitudinal Quantitative Assessment of COVID-19
Longitudinal
Segmentation Networks

Longitudinal
scans and masks

Encoder

ùëøùüé

ùëøùüè

ùë¥ùüé

ùë¥ùüè

Longitudinal
Registration

Segmentation
mask

Decoder

ùíìùíÜùíà

[ùëøùüè , ùëøùüé ]

3

Progression
map

‡∑°ùüé
ùíÄ
Shared weights

Progression
Analysis

‡∑°ùüè ‚àí ùíÄ
‡∑°ùüé
ùíÄ
Encoder

ùíìùíÜùíà

[ùëøùüé , ùëøùüè ]

Decoder

‡∑°ùüè
ùíÄ

Fig. 1. Progression Analysis Framework: The framework is comprised of three modules: (a) Longitudinal registration, (b) Longitudinal fine-grained segmentation to identify pathologies, and (c) Progression analysis. The inputs are two consecutive (t=0,
reference and t=1, follow-up).

that the performance of segmentation can be improved compared to the
static segmentation model. Further, our method shows promising results
with limited data.
‚Äì We propose a framework to analyze the progression of COVID-19 infection
over time, which is crucial for the course of the disease and the patient‚Äôs
recovery.
‚Äì We present comprehensive analysis and ablation studies to verify our longitudinal analysis framework‚Äôs design choice.

2

Methodology

This section describes our approaches for incorporating spatio-temporal features
into the framework of segmentation and progression quantification. Figure 1
showcases the overall framework of our method, which consists of the following
three components: 1) longitudinal registration, 2) longitudinal deep learningbased segmentation, and 3) progression analysis. The analyses are performed
based on two different time points, namely t=0, the reference scan and t=1, a
later follow-up scan.
2.1

Longitudinal Registration

Due to the nature of chest CT scans, the initial volumes of data between different
time points are highly misaligned. Aspects like patient positioning, variations
of the imaging parameters or devices, different phases in the breathing cycle,
and the disease progression are the main reasons. This misregistration cannot
be described as a linear transformation composed of translation and rotation
between the time points of data and can only be expressed through non-linear
transformations. Misalignment can make the network incapable of using the
longitudinal information present between different time points of data.

4

Kim and Goli et al.

As a solution for this problem, we utilize a deformable registration algorithm [14] where a BSpline Transform is defined using a sparse set of grid points
overlaid onto the fixed domain of the image domain to deform it. Using this
algorithm we register the reference scan lung mask M0 to the follow up scan
lung mask M1 and this transform function is defined by RM0 ‚ÜíM1 (¬∑). Based
on this function, the transformations are applied to the respective CT-scans
as X0reg = RM0 ‚ÜíM1 (X0 ). Using the lung masks, we avoid registration errors
due to the pathological changes in the lung parenchyma while compensating for
positioning, breathing phase, and acquisition-related differences.
2.2

Longitudinal Segmentation

Because of the challenge of training a 3D model with a limited number of training
data, 2.5D approaches [2,22,16,4] have shown state-of-the-art results on various
medical segmentation problems. For the 3D approach, it is challenging to directly
process a full 3D volume by using current GPU memory limitations [16], which
forces people to operate on 3D patches [18,8]. However, patch-wise training limits
the overall spatial context for accurate semantic segmentation.
In this study, we adopt the 2.5D approach of Denner et al. for the segmentation for magnetic resonance scans in multiple sclerosis, a completely different indication [4]. As a baseline 2D segmentation model, a fully convolutional
DenseNet is used [10]. The model is trained for all three views (coronal, sagittal,
and axial view). At test time, for each given voxel, the segmentation is conducted
on all three orthogonal views. Afterward, the predicted probability of a given
voxel is averaged among views to assign a final predicted probability.
We extend the aforementioned 2.5D segmentation to deal with longitudinal
information by modifying its architecture. To capture subtle spatio-temporal
cues, We concatenate two registered scans from two different time-points as input
for the longitudinal segmentation network: [X0reg , X1 ] for segmenting pathologies
on X1 or [X1 , X0reg ] for X0 . This enables the segmentation network to capture
temporal changes as shown in Figure 1. For subjects who have more than two
scans, we select only consecutive scans for the segmentation.
2.3

Progression Analysis

To monitor the progression of the COVID-19 infection and the response to therapy, we extract the segmented pathologies from consecutive longitudinal CT
scans and quantify the volume differences between them.
Our approach is capable of quantifying all combinations of changes between
different pathologies and healthy lung parenchyma. In this work‚Äôs scope, we
define two classes as consolidation and non-consolidation since consolidation has
shown to be a robust biomarker for COVID-19 [13].
The progression of consolidation is computed by subtracting two registered
longitudinal CT-scans. The resulting residual voxel values could be either positive or negative. Positive voxels indicate that a healthy, GGO or pleural effusion
region progresses to consolidation (Progression), and negative voxels suggest

Longitudinal Quantitative Assessment of COVID-19

5

that an area recovers from the severe infection of consolidation from t=0 to t=1
(Recovery).
2.4

Training with Progression Information

For the optimization of our model, we define an overall loss function combining a
segmentation Lseg and a progression loss Lprog . Note that as shown in Fig. 1, the
outputs of our model consist of the segmentation masks for reference (t=0) and
follow-up (t=1) scans and the subtracted volume between reference and followup scans for presenting progression of the COVID-19 infection. The overall loss
is defined as: L = Lseg + Lprog .
The segmentation loss is defined as Lseg = LM SE (Y0 , YÀÜ0 ) + LM SE (Y1 , YÀÜ1 )
where LM SE denotes a mean squared error loss [22,4]. In our evaluation this
metric yielded better results in comparison to the more common dice score. Y0
and YÀÜ0 denote a ground truth pathology segmentation map and a predicted
segmentation mask for t=0 scan respectively. Y1 and YÀÜ1 denote a ground truth
pathology segmentation map and a predicted segmentation mask for t=1 scan,
respectively.
The progression loss is defined as Lprog = LM SE (Y1con ‚àí Y0con , YÃÇ1con ‚àí YÃÇ0con )
where Y con denotes a ground truth consolidation map and YÃÇ con denotes a predicted consolidation map. In those binary maps, consolidation is mapped to 1
and non-consolidation to 0. As explained above, the progression map is calculated by Y1con ‚àí Y0con .

3
3.1

Experiment Setup
Dataset

To our knowledge there is no publicly available longitudinal CT dataset for
COVID-19. Accordingly, to evaluate the proposed method, we used an in-house
clinical dataset which consists of longitudinal low-dose CT-scans from 38 patients
(64¬±18 years old, 16 females, 22 males) with positive PCR from the first COVID19 wave (March-June 2020). 28 patients had two scans and 10 had three. The CTs
were separated 17¬±10 days (1-43 days) and were taken at admission and during
the hospital stay (33¬±21 days, 0-71 days). 8 patients of the 38 died; 30 recovered
from COVID-19, 20 of them needing intensive care. All scans were performed inhouse using two different CT devices (IQon Spectral CT and iCT 256, Philips,
Hamburg, Germany) with the same parameters (X-ray current 140-210 mA,
voltage 120 kV peak, slice thickness 0.9mm, no contrast media) and covered the
complete lung. The data was collected retrospectively with the approval of the
institutional review board of our institution (ethics approval 111/20 S-KH).
The dataset was annotated at a voxel-level by a single expert radiologist (5
years experience), generating lung masks (lung parenchyma vs. other tissues) and
pathology masks including four classes: healthy lung (HL), ground-glass opacity
(GGO) and consolidation (CONS), pleural effusion (PLEFF). For segmentation,
the radiologist used the software ImFusion Labels (ImFusion, Munich, Germany).

6

Kim and Goli et al.

The dataset was split into a training set of 16 patients (37 volumes) and an
independent test set of 22 patients (49 volumes). From the training set, 12 patient
scans are used for model training and 4 patient scans are used for validation.
The model is finally evaluated on the unseen test set.
3.2

Implementation Details

The raw CT volumes highly vary in intensity range, size, and alignment. Therefore, we perform the following pre-processing steps on the raw volumes to enable
effective use of the longitudinal data:
Cropping. Since different body regions can be present between time points and
patients we crop the volumes to the lung regions, using the manually-annotated
lung masks.
Clipping and Normalization. To alleviate different intensity ranges among
CT-scans, intensity values outside the range (‚àí1024, 600) are clipped and then
min-max normalization is performed on each volume.
Resizing. After Cropping, resulting volumes vary in size in all three dimensions,
ranging from 100 pixels to 580 pixels. Therefore all volumes are afterward resized
to a fixed size of 300√ó300√ó300 with 300 being the median among the croppedvolume sizes.
Slicing and Removing Empty Slices. Finally, the volumes are sliced in each
of the three dimensions to 300 slices, generating sagittal, coronal, and axial views
of the lung. Slices that have a voxel-value variation smaller than 0.001% between
their maximum and the minimum value are considered empty and are removed.
Model Training. For training, Adam optimizer [11] with a learning rate of
0.0001 and a decay rate of 0.1 for every 50 steps was used. The model was trained
over 100 epochs with early stopping if no decrease in the validation loss was
computed for 5 epochs. Our method was implemented in PyTorch 1.4 and our
models were trained on an NVIDIA Titan V 12GB GPU using Polyaxon7 . The
source code will be made publicly available upon acceptance. Our longitudinal
model had 1.3752M parameters in comparison to its static counterpart 1.3748M.

4

Results and Discussion

Effectiveness of Longitudinal Segmentation First, we conduct comparative
experiments to verify the effectiveness of our longitudinal segmentation method.
In Table 1, we compare our method with a static network as in [24,22] based on
FC-DenseNet-57 [10] and with a longitudinal network without progression loss.
This simpler longitudinal network has the same architecture as our proposed
one, i.e., it concatenates longitudinal CT scans as an input for the segmentation
model, but it is trained using only the segmentation loss. As shown in Table 1,
both longitudinal networks achieved a higher Dice Similarity Coefficient (DSC)
than the static network. The difference was statistically significant for all classes
7

https://polyaxon.com/

Longitudinal Quantitative Assessment of COVID-19

7

Table 1. Comparison of different methodologies for segmenting CoViD-19 infection on
the independent test set. Dice similarity coefficient is used for metric. The average and
standard error are calculated. ‚àó denotes the case that the difference with the proposed
method is statistically significant (p<0.05).
Method
HL
CONS
GGO
PLEFF
Static Network
0.796¬±0.021‚àó 0.322¬±0.031‚àó 0.380¬±0.028‚àó 0.210 ¬± 0.033‚àó
Longitudinal Network
0.835¬±0.019 0.402¬±0.034 0.435¬±0.029‚àó 0.266¬±0.041‚àó
(without progression loss)
Proposed
0.837¬±0.022 0.406¬±0.035 0.447¬±0.030 0.246¬±0.040

Table 2. Ablation study to investigate the effectiveness of the registration and using
temporal information in our longitudinal segmentation model. Dice similarity coefficient is measured on the independent test set.
Method
Registration Long. Input
Without Registration
X
Static Input
X
X
X
Proposed

HL
0.761
0.774
0.837

CONS
0.311
0.327
0.406

GGO PLEFF
0.388 0.146
0.224 0.160
0.447 0.246

(p<0.05 by paired t-test [1]). This implies that using longitudinal information
from the reference CT scan is informative to segment pathology on the target
CT scan. In our longitudinal network with progression loss, the DSC was further
improved for HL, CONS, and GGO. But for PLEFF, the performance slightly
decreased. This can be attributed to the fact that the progression loss encourages
the model to focus on CONS rather than on PLEFF. Additionally, PLEFF is a
challenging, under-represented class in our dataset averaging only 2.17% of the
voxels per volume.
Effect of Longitudinal Registration. To showcase the importance of registration among the longitudinal scans, we report results with and without deformable registration. As seen in Table 2 the performance after registration substantially improves across the board with the increase ranging from 0.07 to 0.10.
Importance of Temporal Information in Longitudinal Network. In this
experiment, we highlight the importance of the longitudinal scans for the performance of the model. Specifically, we concatenate two duplicates of the reference
scan instead of the reference and follow-up scan as input to our model. As shown
in Table 2, the ‚Äôlongitudinal input‚Äô outperforms the ‚Äôstatic input‚Äô for all classes,
ranging from a 0.06 for HL to 0.22 for GGO DSC improvement.
Progression Analysis Finally, we evaluate our method for progression analysis
by comparing with a static network [15], a longitudinal network with multi-view
approach [3] and our model trained without the proposed progression loss. As

8

Kim and Goli et al.

Table 3. Comparison of different methodologies for predicting progression of CoViD19 infection on the independent test set. Dice similarity coefficient is used for metric.
The average and standard error are calculated. ‚àó denotes the case that the proposed
method outperforms the baseline methods with statistical significance (p<0.05).
Method
Static Network [15]
Longitudinal Network
(multi-view [3])
Longitudinal Network
(without progression loss)
Proposed

Reference
scan

Follow-up
scan

GT reference
scan

Recovery Progression Average
0.266¬±0.030‚àó 0.471¬±0.021‚àó 0.368¬±0.015‚àó
0.287¬±0.031‚àó 0.491¬±0.028 0.389¬±0.023‚àó
0.299¬±0.032‚àó 0.505¬±0.019 0.402¬±0.014‚àó
0.327¬±0.033 0.506¬±0.026 0.416¬±0.017

Segmentation
reference scan

GT follow-up
scan

Segmentation
follow-up scan

GT progression
Predicted
map
progression map

Fig. 2. Qualitative results of the proposed method for 3 patients from different views.
For the segmentation maps, blue, green, red and yellow denote HL, CONS, GGO, and
PLEFF, respectively. For the progression map, red denotes Progression and the green
Recovery.

shown in 3, our approach achieves the highest DSC across the board, showcasing
the effectiveness of temporal information and the progression loss.
Fig. 2 showcases qualitative results of the segmentation and progression analysis of our method for all 3 different views. As shown in Fig. 2, our method
successfully provides segmentation and progression maps for both reference and
follow-up scans across views and patients. Even the under-represented class of
PLEFF is successfully segmented. Regarding the progression, the fine-grained
regions of recovered and progressed consolidation are also correctly identified.

5

Conclusion

In this work, we proposed a new longitudinal segmentation and progression
analysis model for assessing COVID-19 disease over time. Comprehensive ex-

Longitudinal Quantitative Assessment of COVID-19

9

periments were conducted to verify the effectiveness of the longitudinal model.
By designing the model to exploit the reference CT scan, our method can achieve
higher segmentation and progression analysis performance compared to the baseline methods. What makes our approach especially interesting is the ability to
monitor the development of the infection and healing process in COVID-19, and
possibly in other lung diseases, but also serve as a quantitative measure to evaluate different therapy approaches. We will further investigate and improve the
clinical usability of the method for a larger patient cohort.

Acknowledgements
This paper was funded by the Bavarian Research Foundation (BFS) under grant
agreement AZ-1429-20C.

References
1. Altman, D.G.: Practical statistics for medical research. CRC press (1990)
2. Aslani, S., Dayan, M., Storelli, L., Filippi, M., Murino, V., Rocca, M.A., Sona, D.:
Multi-branch convolutional neural network for multiple sclerosis lesion segmentation. NeuroImage 196, 1‚Äì15 (2019)
3. Birenbaum, A., Greenspan, H.: Multi-view longitudinal cnn for multiple sclerosis
lesion segmentation. Engineering Applications of Artificial Intelligence 65, 111‚Äì118
(2017)
4. Denner, S., Khakzar, A., Sajid, M., Saleh, M., Spiclin, Z., Kim, S.T., Navab, N.:
Spatio-temporal learning from longitudinal data for multiple sclerosis lesion segmentation. arXiv preprint arXiv:2004.03675 (2020)
5. Fan, D.P., Zhou, T., Ji, G.P., Zhou, Y., Chen, G., Fu, H., Shen, J., Shao, L.:
Inf-net: Automatic covid-19 lung infection segmentation from ct images. IEEE
Transactions on Medical Imaging 39(8), 2626‚Äì2637 (2020)
6. Feng, X., Ding, X., Zhang, F.: Dynamic evolution of lung abnormalities evaluated
by quantitative CT techniques in patients with COVID-19 infection. Epidemiol
Infect 148, e136 (2020)
7. Harmon, S.A., Sanford, T.H., Xu, S., Turkbey, E.B., Roth, H., et al.: Artificial
intelligence for the detection of COVID-19 pneumonia on chest CT using multinational datasets. Nature Communications 11(1), 4080 (2020)
8. Hashemi, S.R., Salehi, S.S.M., Erdogmus, D., Prabhu, S.P., Warfield, S.K.,
Gholipour, A.: Asymmetric loss functions and deep densely-connected networks
for highly-imbalanced medical image segmentation: Application to multiple sclerosis lesion detection. IEEE Access 7, 1721‚Äì1735 (2018)
9. Huang, Y., Li, Z., Guo, H., Han, D., Yuan, F., Xie, Y., et al.: Dynamic changes in
chest CT findings of patients with coronavirus disease 2019 (COVID-19) in different
disease stages: a multicenter study. Ann Palliat Med 10(1), 572‚Äì583 (2021)
10. JeÃÅgou, S., Drozdzal, M., Vazquez, D., Romero, A., Bengio, Y.: The one hundred
layers tiramisu: Fully convolutional densenets for semantic segmentation. In: CVPR
Workshop. pp. 11‚Äì19 (2017)
11. Kingma, D.P., Ba, J.: Adam: A method for stochastic optimization. International
Conference on Learning Representations (ICLR) (2014)

10

Kim and Goli et al.

12. Lei, J., Li, J., Li, X., Qi, X.: Ct imaging of the 2019 novel coronavirus (2019-ncov)
pneumonia. Radiology 295(1), 18‚Äì18 (2020)
13. Li, K., Wu, J., Wu, F., Guo, D., Chen, L., Fang, Z., Li, C.: The clinical and chest
ct features associated with severe and critical covid-19 pneumonia. Investigative
radiology (2020)
14. Lowekamp, B.C., Chen, D.T., IbaÃÅnÃÉez, L., Blezek, D.: The design of simpleitk.
Frontiers in neuroinformatics 7, 45 (2013)
15. Pu, J., Leader, J.K., Bandos, A., Ke, S., Wang, J., Shi, J., Du, P., Guo, Y., Wenzel,
S.E., Fuhrman, C.R., et al.: Automated quantification of covid-19 severity and
progression using chest ct images. European Radiology 31(1), 436‚Äì446 (2021)
16. Roy, A.G., Conjeti, S., Navab, N., Wachinger, C., Initiative, A.D.N., et al.: Quicknat: A fully convolutional network for quick and accurate segmentation of neuroanatomy. NeuroImage 186, 713‚Äì727 (2019)
17. Shi, H., Han, X., Jiang, N., Cao, Y., Alwalid, O., Gu, J., Fan, Y., Zheng, C.:
Radiological findings from 81 patients with covid-19 pneumonia in wuhan, china:
a descriptive study. The Lancet infectious diseases 20(4), 425‚Äì434 (2020)
18. Wachinger, C., Reuter, M., Klein, T.: Deepnat: Deep convolutional neural network
for segmenting neuroanatomy. NeuroImage 170, 434‚Äì445 (2018)
19. Wang, G., Liu, X., Li, C., Xu, Z., Ruan, J., Zhu, H., Meng, T., Li, K., Huang,
N., Zhang, S.: A noise-robust framework for automatic segmentation of covid-19
pneumonia lesions from ct images. IEEE Transactions on Medical Imaging 39(8),
2653‚Äì2663 (2020)
20. Wong, H.Y.F., Lam, H.Y.S., Fong, A.H.T., Leung, S.T., Chin, T.W.Y., Lo, C.S.Y.,
Lui, M.M.S., Lee, J.C.Y., Chiu, K.W.H., Chung, T.W.H., et al.: Frequency and distribution of chest radiographic findings in patients positive for covid-19. Radiology
296(2), E72‚ÄìE78 (2020)
21. Wu, M.Y., Yao, L., Wang, Y., Zhu, X.Y., Wang, X.F., Tang, P.J., Chen, C.: Clinical
evaluation of potential usefulness of serum lactate dehydrogenase (LDH) in 2019
novel coronavirus (COVID-19) pneumonia. Respir Res 21(1), 171 (Jul 2020)
22. Zhang, H., Valcarcel, A.M., Bakshi, R., Chu, R., Bagnato, F., Shinohara, R.T.,
Hett, K., Oguz, I.: Multiple sclerosis lesion segmentation with tiramisu and 2.5 d
stacked slices. In: MICCAI. pp. 338‚Äì346 (2019)
23. Zhang, X., Yu, Z., Han, X., Zhao, B., Zhuo, Y., Ren, Y., Xue, X., Lamm, L., Feng,
J., Marr, C., et al.: Dabc-net for robust pneumonia segmentation and prediction
of covid-19 progression on chest ct scans (2020)
24. Zhou, L., Li, Z., Zhou, J., Li, H., Chen, Y., Huang, Y., Xie, D., Zhao, L., Fan,
M., Hashmi, S., et al.: A rapid, accurate and machine-agnostic segmentation and
quantification method for ct-based covid-19 diagnosis. IEEE transactions on medical imaging 39(8), 2638‚Äì2652 (2020)
25. Zhou, S., Wang, Y., Zhu, T., Xia, L.: Ct features of coronavirus disease 2019 (covid19) pneumonia in 62 patients in wuhan, china. American Journal of Roentgenology
214(6), 1287‚Äì1294 (2020)
26. Zhou, X., Pu, Y., Zhang, D., Xia, Y., Guan, Y., Liu, S., Fan, L.: CT findings and
dynamic imaging changes of COVID-19 in 2908 patients: a systematic review and
meta-analysis. Acta Radiol p. 284185121992655 (2021)

