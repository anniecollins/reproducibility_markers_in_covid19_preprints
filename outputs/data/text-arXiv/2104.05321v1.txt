Combining exogenous and endogenous signals with a
semi-supervised co-attention network for early detection
of COVID-19 fake tweets

arXiv:2104.05321v1 [cs.CL] 12 Apr 2021

Rachit Bansal1? William Scott Paka2? Nidhi3
Shubhashis Sengupta3 Tanmoy Chakraborty2
1

Delhi Technological University, 2 IIIT-Delhi, 3 Accenture Labs, India
rachitbansal 2k18ee152@dtu.ac.in
{william18026, tanmoy}@iiitd.ac.in
{nidhi.sultan, shubhashis.sengupta}@accenture.com

Abstract. Fake tweets are observed to be ever-increasing, demanding immediate
countermeasures to combat their spread. During COVID-19, tweets with misinformation should be flagged and neutralised in their early stages to mitigate the
damages. Most of the existing methods for early detection of fake news assume
to have enough propagation information for large labelled tweets â€“ which may
not be an ideal setting for cases like COVID-19 where both aspects are largely
absent. In this work, we present ENDEMIC, a novel early detection model which
leverages exogenous and endogenous signals related to tweets, while learning
on limited labelled data. We first develop a novel dataset, called ECTF for early
COVID-19 Twitter fake news, with additional behavioural test-sets to validate
early detection. We build a heterogeneous graph with follower-followee, usertweet, and tweet-retweet connections and train a graph embedding model to aggregate propagation information. Graph embeddings and contextual features constitute endogenous, while time-relative web-scraped information constitutes exogenous signals. ENDEMIC is trained in a semi-supervised fashion, overcoming
the challenge of limited labelled data. We propose a co-attention mechanism to
fuse signal representations optimally. Experimental results on ECTF, PolitiFact,
and GossipCop show that ENDEMIC is highly reliable in detecting early fake
tweets, outperforming nine state-of-the-art methods significantly.

1

Introduction

Over the past couple of years, several social networking platforms have seen drastic
increase in the number of users and their activities online [1]. Due to the lockdown situations and work from home conditions during COVID-19 pandemic, the screen time
on social media platforms is at an all time high. Twitter is one such micro-blogging
platform where users share opinions and even rely on news updates. Twitter users exposed to unverified information and opinions of others often get influenced and become
contributors to further spreading. The characteristics of fake news spreading faster farther and deeper than genuine news is well-studied [12]. Fake news on health during
COVID-19 might endanger peopleâ€™s lives as a few of them call for action. Although our
?

Equal Contribution. The work was done when Rachit was an intern at IIIT-Delhi.

2

Bansal et al., 2021

proposed method is highly generalised, we choose to specifically focus on the ongoing
pandemic situation of COVID-19 as it is timely and needs scaleable solutions.
State-of-the-art fake news detection models for Twitter have proved useful when
trained on a sufficient amounts of labelled data. Any emerging fake news in its initial
stages could not be detected by such models due to the lack of corresponding labelled
data. Moreover, these models tend to fail when the fake news is not represented largely
in the training set. By the time the fake news is detected, it has spread and caused damages to a wide range of users. Detecting a fake news in an early stage of its spread gives
us the advantage of flagging it early. A few state-of-the-art models for early fake news
detection use propagation based methods [9], i.e., they are based on how a particular
news event (fake/genuine) spreads (both wider and deeper); retweet chain in Twitter is
one such example. These models work with the propagation chains and require sufficient historical data (retweet/reply cascade) of each tweet, which are very hard to collect
within limited time.
In this work, we design ENDEMIC, a novel approach to detect fake news in its early
stage. To this end, we developed an Early COVID-19 Twitter Fake news dataset, called
ECTF with additional test set (early-test) for early detection. We collected vast amount
of COVID-19 tweets and label them using trusted information, transformer models and
human annotation. We finally curate a standard training dataset, composed of numerous
rumour clusters, while simulating a scenario of emerging fake news through early-test
set. Next, we extract exogenous signals in form of most suitable stances from relevant external web domains, relative to the time the tweet is posted. Unlike existing
studies which extract propagation paths per tweet, we create a massive heterogeneous
graph with follower-followee, tweet-retweet and tweet-user connections and obtain the
node representations in an unsupervised manner. The graph embeddings (both users
and tweets) constitute the major component of the endogenous signals (within Twitter).
The time-variant contextual tweet and user features are used to provide additional context, and a few of them are masked to validate the model for early detection. Lastly,
to overcome the challenge of limited labelled dataset, we setup the whole model in a
semi-supervised fashion, learning in an adversarial setting to utilise the vast unlabelled
data.
In Summary, fake news on Twitter is an inevitable threat especially during COVID19 pandemic, where inaccurate or deviating medical information could be harmful. As
a result, a timely model which can detect fake news in its early stages is important
due to the current conditions of emerging fake news. We propose ENDEMIC, a semisupervised co-attention network which utilises both exogenous and endogenous signals.
Experimental results show that ENDEMIC outperforms nine state-of-the-art models in
the task of early fake tweet detection. ENDEMIC produces 93.7% accuracy, on ECTF for
fake tweet detection and 91.8% accuracy for early detection, outperforming baselines
significantly. We also show the generalisation of ENDEMIC by showing its efficacy
on two publicly available fake news datasets, PolitiFact and GossipCop; ENDEMIC
achieves 91.2% and 84.7& accuracy on the two datasets, respectively.
In particular, our major contributions are as follows:

ENDEMIC

3

â€“ We introduce ECTF, an Early COVID-19 Twitter Fake news dataset with additional
early-test set to evaluate the performance of fake tweet detection models for early
detection.
â€“ As propagation paths for tweets might not be available in all scenarios, we build
connections of follower-followee, tweet-retweet and user-tweet network and extract
representations upon learning the graph, constituting of our endogenous signals.
â€“ We use exogenous signals which informs the model on the realities of information
available on the web at tweet time, and helps in learning from weak external signals.
â€“ Adding an effort towards early detection, time variant features are masked at test
time for further evaluation on early detection.
â€“ We further show the generalisation of ENDEMIC by presenting its superior performance on two other general fake news datasets .
Reproducibility: The code and the datasets are public at: https://github.com/
LCS2-IIITD/ENDEMIC.

2

Related Work

Our work focuses majorly on early detection of fake tweets. As our model involves
techniques such as graphs and semi-supervised learning, we present related studies pertaining to our model.
Fake news detection. Proliferation of fake news over the Internet has given rise to
many research, and hence there exist an abundance of literature. Early studies on fake
news relied on linguistic features of texts to detect if the content is fake [3]. Wang et
al. [27] used textual embeddings and weak labels with reinforcement learning to detect
fake news. They leveraged an annotator component to obtain fresh and high-quality labelled samples to overcome the challenge of limited labelled data. Recent approaches
have started exploring directed graph and Weisfeiler-Lehman Kernel based model for
social media dataset that use similarity between different graph kernels [21]. A recent
survey [31] shows that there are four approaches to detect fake news: (i) knowledgebased methods, where the content is verified with known facts, (ii) style-based methods, by analysing the writing style of the content, (iii) propagation methods, based on
how a particular news event spreads, and (iv) source-based methods, by verification of
credibility of sources. As studies show, each of these methods used individually is not
enough to build an efficient classifier [16].
Semi-supervised learning. Semi-supervised models have been used often in the past
to leverage vast unlabelled datasets in various fields. Helmstetter et al. [8] explored
weakly supervised learning for fake news detection which automatically collects large
scale noisy dataset to aid the classification task . Yu et al. [29] used constrained semisupervised learning for social media spammer detection. Tensor embeddings are used
to design a semi-supervised model for content based fake news detection [6]. A few
studies leveraged variational auto-encoders in the form of sequence-to-sequence modelling on text classification and sequential labelling [7]. Nigam et al. [18] classified
the text using a combination of Naive Bayes and Expectation Maximisation algorithms
and demonstrated substantial performance improvements. Miyato et al. [15] utilised adversarial and virtual adversarial training to the text domain by applying perturbations

4

Bansal et al., 2021

to the word embeddings. Chen et al. [4] introduced MixText that combines labelled,
unlabelled and augmented data for the task of text classification.
Early detection. Early fake news detection methods detect fake news at an initial stage
where the news has not yet been popularised. There exist very limited studies on early
detection. Liu et al. [9] built an early detection model using propagation paths of news
spreading as a multivariate time series and then training a recurrent and convolution
classifier on user features. Rosenfeld et al. used graph kernels on Twitter cascades to
capture intricate details of the data-set for fake news detection without feeding user
identity and time for an early detection model [21]. Shu et al. used content engagement
and cleaned labelled dataset for early detection with deep neural network [24].

3

Our Proposed Dataset: ECTF

As there is no publicly available COVID-19 Twitter dataset particularly for early detection, we attempt to develop our own dataset, ECTF, specifically crafting it for early
detection. We expand on CTF, a general COVID-19 Twitter fake news dataset, proposed
by Paka et al. [19]. CTF was formed using multiple sources- unlabelled Twitter datasets
that are publicly released [2, 22, 26], hydration of tweets using predefined hashtags, and
governmental health organisations and fact checking websites for verified news. They
considered statements released by the latter to be true, and applied Sentence-BERT [20]
and RoBERTa [11] to convert these tweets and verified news into contextual embeddings, pairwise cosine similarity is then computed to assign a label â€˜fakeâ€™ or â€˜genuine.
This way, CTF composes of 72, 578 labelled and 2, 59, 469 unlabelled tweets, partially
verified manually.
We took a sample of labelled and unlabelled tweets from CTF, forming our train set.
A â€˜general-testâ€™ set is created by randomly sampling from the remaining labelled and
unlabelled tweets. The training dataset, which contains a wide variety of rumour clusters, is kept constant. We identified small rumour clusters in the labelled dataset and use
those to form additional test set, called â€˜early-testâ€™ set, to perform behavioural analysis of our algorithm for early detection. These small rumour clusters contain the fake
news that are not popularised yet (having chance of getting popular), simulating early
stages of fake news events. We extracted more tweets belonging to these rumour clusters, while keeping an upper limit on the time since they were posted. This ensures that
the tweets belonging to this early-test set are in their early stages.
We refer to the complete dataset composed of the train and test sets as ECTF, Early
COVID-19 Twitter Fake news dataset.

4

Our Proposed Methodology: ENDEMIC

Here we present our model, called ENDEMIC (Exogenous and eNDogenous signals
with sEMI-supervised Co-attention network). Figure 1 represents the model architecture. Here we show various input features, each of which passes through separate modules before being concatenated. Our approach towards early detection relies on simulating the early stages of the news event testing with time invariant features.
4.1

Exogenous signals

Traditional supervised fake news detection methods are bounded by the knowledge
present in the data they are trained on [30]. This makes them incapable of classifying

ENDEMIC
Tweet Node
Embedding

User Node
Embedding

Linear

Linear

dTG

dUG

^
dUG

^

^

dEK
dTT
Co-Attention
dEK

Sentence
BERT

External
Knowledge

dTT

Softmax

^

dTG

Dropout

dTU

Linear

Feed-Forward
Network

...

Contextual
Features
(Tweet + User)

LML + L AT

Concatenation

Co-Attention

5

L VAT

Bi-LSTM

Embedded
Tweet Text

Fig. 1: A schematic architecture of ENDEMIC. The encoded interpolations of external
knowledge (dEK ), tweet text (dT T ), contextual features (dT U ), and tweet (dT G ) and
user node embeddings (dU G ) are shown. bÂ· represents an output from co-attention.
tweets on information the model is not trained on. This is particularly challenging for
domains where large amount of new theories and their consequent studies arrive rapidly
within small duration. Very often, the general stance of such news also changes radically
over time. Just as a human expert, classification models too need to be well-aware of
current information in a domain in order to be reliable and efficient. To address this
problem, we make use of exogenous signals through external knowledge.
We curate exogenous content using web-scraped articles from various sources. In
order to simulate the early stages of detection, this knowledge base is collected differently for training and testing instances. We build the external knowledge for training as
a static knowledge base composed of various sources for each input. We hypothesise
that collecting this external knowledge in accordance with the time the post was made
simulates an early detection scenario, consequently making the model adapt to such
scenarios better where the information about an emerging fake news will be limited.
Using this, the model learns the weak signals that are present to perform a classification. In case of testing, the external knowledge is scraped for every test instance at
the time of testing itself. The dynamic nature of building the external knowledge base
during testing ensures that the model makes use of latest sources to make the prediction.
We perform a web scraping with tweets as queries using Google Web API. Since
a large amount of information in form of web pages are available per query, and the
content per page could also be excessively large, selecting the right content is vital.
We do so by firstly tokenizing each web page xEK,i into sentences. The j th sentence of
xEK,i , denoted by xEK,i
, is encoded using Sentence-BERT [20] to obtain its contextual
j
K
representation, dEK,i
âˆˆ
R
, where K is the dimension of the encoding. This represenj

6

Bansal et al., 2021

tation is then compared with the representation of the tweet text, xT T â†’ dTx T âˆˆ RK ,
encoded using the same Sentence-BERT model. This comparison is made using cosine
similarity. If the cosine similarity between these two encodings, cos(dEK,i
||dTx T ), is
j
EK,i
greater than a threshold  (set as 0.8), then the sentence xj
is added to the set of
is
input external knowledge for that particular tweet. The same representation, dEK,i
j
used as the corresponding input to the model for all sentences belonging to the tweet.
This process is done for the entire set of input queries, until we obtain 50 such sentences
for each, with the amount of phrases per web-source being limited to 10. Thus, the net
external knowledge input to ENDEMIC during training is obtained by concatenating the
encoding for each input in 2D fashion and is given by dEK âˆˆ RnÃ—50Ã—K , where n is the
input size. For most of our experiments, we keep K = 512.
4.2

Endogenous signals

Input tweet embedding. The original tweet text xTi T of sequence length N (say) is
first represented by a one-hot vector using a vocabulary of size V . A word embedding
look-up table transforms these one-hot vectors into a dense tensor. This embedding
vector is further encoded using a Bidirectional LSTM. A final state output d âˆˆ RK/2 is
obtained at both the forward and backward layers, which are then concatenated to give
a 2D vector corresponding to each text input. The final representation of the tweet text
input to the model is, thus, dT T âˆˆ RnÃ—N Ã—K .
Graph embeddings. Extracting the propagation chain of retweets has been proven effective by the existing early detection models [9, 14]. However, these methods limit
the training as for each training or test sample, the entire set of retweet chains needs
to be extracted which is often computationally expensive. Here we build a heterogeneous graph G(V, E) as follows: the set of nodes V can be users or tweets, and edges E
are formed in the following ways: two users are connected via follower-followee link, a
user is connected to her posted tweet, two tweets are connected if one is a retweet of another. We keep G as undirected intentionally ignoring the direction of some edge types
(follower-followee) in order to maintain uniformity. The formed heterogeneous graph
contains around 51M nodes and 70M edges. Such huge connections, when added into
one graph, form many disconnected clusters. In our graph, we observe one giant cluster
with almost millions of nodes and edges, which stands dominating compared to other
small (and disconnected) clusters.
We obtain the embedding of the graph using GraphSAGE [17] in an unsupervised
fashion due to its capability to scale and learn large graphs easily. We label each node
with its characteristics such as parent, tweet, retweet, user, fake tweet. The generalisability of GraphSAGE helps in extracting the embeddings of unseen users and tweets.
We use a teleportation probability of 0.3 for the graph to randomly jump across nodes,
which helps with clusters having less number of connections or being disconnected
from the rest. In this work, we show that using the embeddings of both users and tweets
in combination with co-attention leads to better supervision and learning of the model.
We represent the tweet and user graph embeddings as dT G and dU G âˆˆ RnÃ—G respectively, where G represents the embedding dimension, and is kept as G = 768, for
most of our experiments.

ENDEMIC

7

Contextual features. Social media platforms like Twitter offer a variety of additional
features that can play a crucial role in identifying the general sentiment and stance on
a post by the users. Moreover, some features of user could also be used as indicative
measures of their social role and responsibility, in general. Therefore, we use a variety
of such tweet and user features to provide additional context regarding the input tweet
and the corresponding users who interact with it. Some of the tweet features used are
number of favourites, number of retweets, PageRank reliability score of domains mentioned in the tweet, text harmonic sentiment1 , etc. Some of the user features include
follower and followee counts, verified status, and number of tweets made by the user.
Note that majority of these features continually change over time and can be regarded as time-variant and accordingly, the inferences drawn also would change over
time. Therefore, for early detection, it is vital not to rely too heavily on such features.
For instance, the number of likes and retweets for a tweet changes over time. Similarly,
such additional features for a new user cannot be expected to give a proper indicative
measure of a userâ€™s tendency of believing, spreading, or curbing misinformation. And
masking the time-variance during evaluation is better explained in Section 5.3.
Throughout this study, we represent these contextual tweet and user features as
xT F âˆˆ RnÃ—NT F and xT F âˆˆ RnÃ—NU F , respectively, where NT F and NU F indicate the
number of such features. As shown in Fig. 1, these input features are concatenated and
F
passed across a common feed-forward network (FFN), which interpolates xTi F âŠ•xU
âˆˆ
i
1Ã—(NT F +NU F )
TU
C
R
to di âˆˆ R , where C is the output dimension of FFN.
4.3

Connecting components and training

Co-attention. In order to jointly attend and reason about various interpolated inputs,
we use the parallel co-attention mechanism [13] (Figure 2). As shown in Figure 1, this
is done at two places of ENDEMIC, namely, to co-attend between external knowledge
dEK
âˆˆ R50Ã—K and tweet text dT T âˆˆ RN Ã—K in 2D, and tweet dT G âˆˆ R1Ã—G and
i
user dU G âˆˆ R1Ã—G graph embeddings in 1D. The same process is followed for two;
therefore, to unify the notation, we use dA âˆˆ RXÃ—Z and dB âˆˆ RY Ã—Z to explain the
mechanism used.
>
Firstly, an affinity matrix C âˆˆ RY Ã—X is obtained as, C = tanh(dA Wb dB ). Here
Z,Z
Wb âˆˆ R
represents the learnable weight matrix. Further the corresponding attention
maps between A and B are calculated as follows:
>

>

H A = tanh(WA dA + (WB dB )C),

>

>

H B = tanh(WB dB + (WA dA )C > )

where, WA , WB âˆˆ RkÃ—Z again represent the learnable weight matrices. Further, to
compute the attention probabilities of each element in A with each element of B, we
use,
aA = Sof tmax(whA > H A ), aB = Sof tmax(whB > H B )
where, whA , whB âˆˆ Rk represent the weight parameters, while aA âˆˆ RX and aB âˆˆ RY
represent the resultant attention probabilities. Finally, the net attention vectors between
A and B are computed as a weighted sum of the corresponding features, i.e.,
1

obtained from the textblob tool in Python.

8

Bansal et al., 2021

b=
A

X
X

A
aA
i di ,

b=
B

i=1

b and B
b âˆˆ R1Ã—Z are the learned feature
A
vectors obtained through co-attention. This,
for instance, represents how each representation in the tweet graph embeddings attends
to the user graph embeddings, when A represents tweet graph embeddings (T G), and B
represents user graph embeddings (U G).
The interpolations of the various inputs, obtained through the separate smaller
pipelines are combined using a unified head
pipeline in the model architecture. Considering a single input, firstly, the representations
EK and
from the two co-attention layers, dd
d
T T âˆˆ R1Ã—K , and d
T G & dd
U G âˆˆ R1Ã—G , are
dd
concatenated along with dT U âˆˆ R1Ã—C .

Y
X

B
aB
i di

(1)

i=1

âˆ‘

^A

^B

â€¢

â€¢

whA â€¢
HA

C â€¢
WA â€¢
dA

âˆ‘

â€¢ whB
HB

â€¢ C
â€¢ WB
dB

d
d
EK âŠ• d
TT âŠ• d
T G âŠ• dd
U G âŠ• dT U
d = dd

Fig. 2: The co-attention mechanism.
This net representation, d âˆˆ R2K+2G+C ,
then passes onto a dropout (pdrop = 0.2) regularised feed-forward layer with an output
size of 2, and finally a Softmax function, to give the probability per output class.
Training. In order to overcome the limitations produced by scarce labelled data, we
use the Virtual Adversarial Loss (VAT) across both labelled and unlabelled data. VAT
introduces a small perturbation in the input embedding and computes the loss using
weak labels. Maximum Likelihood (ML) loss and Adversarial Training (AT) losses are
further used to train ENDEMIC on the labelled data [15]. These additional losses allow
ENDEMIC to be more robust, and the abundant unlabelled data being used this way
allow it to form better understanding and representation of the domain-specific texts.

5

Experimental Setup and Results

Here we present our comparative analysis by empirically comparing ENDEMIC with
state-of-the-art models, including techniques for general fake news detection, early detection, and text classification.
5.1 Baseline methods
We consider nine baselines as follows. Liu and Wu [9] introduced a GRU and CNNbased model which relies on the propagation path (PP) of a news source to classify its
veracity, and is termed as PPC (Propagation Path Classification). FNED [10] makes
use of a PU-learning framework to perform weak classification, and is claimed to be
suitable in data scarce settings with large amount of unlabelled data, as is the scenario
we deal with in this study. Further, Shu et al. [25] proposed to learn from Multiplesources of weak Social Supervision (MWSS), on top of a classifier such as CNN and

ENDEMIC
Model
HAN
MixText
GCAN
CSI
dEFEND
CNN-MWSS
RoBERTa-MWSS
FNED
PPC
ENDEMIC

9

Feature used
Performance
TG UG EK UL Accuracy Precision Recall F1 Score
X
X
X
X

X
X
X
X
X

X
X X X X

0.865
0.875
0.852
0.873
0.890
0.805
0.825
0.911
0.861
0.937

0.685
0.835
0.817
0.805
0.830
0.785
0.815
0.907
0.860
0.922

0.865
0.843
0.820
0.915
0.891
0.810
0.852
0.920
0.832
0.943

0.762
0.847
0.813
0.854
0.862
0.790
0.840
0.915
0.845
0.932

Table 1: Features used and performance comparison on general-test dataset of ECTF
(TG: Tweet Graph, UG: User Graph, EK: External Knowledge, UL: Unlabelled Data).
RoBERTa [11]. They too relied on weak labelling, but constructed them through social
engagements. Both dEFEND and CSI deployed an RNN-based framework for classifying news; the former makes use of user comments with co-attention, while the latter
relies on a three-step process of capturing, scoring and integrating the general user response. Furthermore, GCAN [14] presents a dual co-attention mechanism over source
and retweet tweet representations, relying on interaction and propagation for detecting fake news. Finally, we also make some interesting observations by employing text
classification models, namely MixText [4] and HAN [28], as additional baselines.
5.2

Evaluating on general-test set

Table 1 shows the performance comparison of ENDEMIC compared to the baselines
on the general-test set of ECTF. We observe that all the features (graph based, external knowledge and unlabelled data) play a major role in determining the corresponding
performance of detecting fake tweets. While general fake news detection models like
dEFEND and CSI strive to integrate more such features, early detection models like
FNED and PPC tend to rely more on the time-invariant features like text alone. The effect produced by the absence of one over the other is apparent from Table 1. In general,
ENDEMIC shows a benchmark performance of 0.937 accuracy, outperforming all the
baselines across all the evaluation measures significantly.
5.3

Evaluating on early detection

Early-test. Table 2 shows the comparative results on the specially curated evaluation
set (early-test) for early detection of fake news. Even though the change in accuracy
(âˆ†Acc) of ENDEMIC as compared to its performance on general fake news (as shown
in Table 1) is not least among the rest of the models, it can be seen that it still comfortably outperforms all other baselines. Interestingly, the general purpose text classifiers,
which are not particularly designed for fake news detection, show a relatively lesser
âˆ†Acc, while dEFEND [5] suffers from the largest difference of 9%. We attribute this
to the heavy reliance of these models on time-variant features which provide critically
less context in early stages. At the same time, as shown in Table 1, only text-based and
closely related non-time-variant features are not enough to reliably detect fake news.
Thus, the set of input features used by ENDEMIC optimises the trade-off between reliability and time-variance.

10

Bansal et al., 2021

Model

Model

Performance
Acc. Prec. Rec.

F1 âˆ†Acc

MixText

MixText

0.865 0.832 0.851 0.844 1.0%

GCAN

GCAN

0.809 0.800 0.785 0.795 4.3%

CSI

CSI

0.808 0.821 0.795 0.815 6.5%

dEFEND

dEFEND 0.800 0.790 0.815 0.790 9.0%
MWSS

MWSS

0.798 0.800 0.812 0.805 2.7%

FNED

0.901 0.887 0.913 0.895 1.0%

PPC

0.831 0.805 0.797 0.810 3%

ENDEMIC 0.918 0.910 0.923 0.920 1.9%

Features

HAN

0.850 0.692 0.841 0.751 1.5%

HAN

Time-variant

Performance
Acc. Prec. Rec.

F1 âˆ†Acc

â€“

0.858 0.705 0.850 0.755 1.2%

â€“
Tweet
Propagation
User
Response
User
Comments
â€“

0.860 0.815 0.833 0.820 1.0&
0.792 0.812 0.775 0.805 6.0%
0.783 0.701 0.745 0.725 9.0%
0.768 0.750 0.804 0.774 12.2%
0.810 0.800 0.835 0.844 1.5%

FNED

â€“
0.892 0.890 0.925 0.905 1.9%
Propagation
PPC
0.855 0.810 0.790 0.805 0.6%
Paths
Contextual
ENDEMIC
0.928 0.920 0.930 0.927 0.9%
Features

Table 3: Performance comparison for mask-detect on

Table 2: Comparing model performance on
ECTF. The masked features and corresponding metric
early-test set of ECTF.
scores are shown.

Masking time variance. To further verify our modelâ€™s prowess in detecting early fake
news, we introduce a unique masking approach to be applied upon the early-test evaluation set. For this technique, the tweets belonging to the smaller rumour clusters (as
defined in Section 3) are further simulated as actual early tweets for a model, by masking all time-variant features used by the model. We call this approach â€˜mask-detectâ€™.
Most of the existing techniques for fake news detection make use of some particular input features which are time-variant. In case of ENDEMIC, these are the additional
contextual tweet features and user features, which rapidly change over time. When such
features are masked, there is effectively no way to distinguish an old tweet from a new
one. Therefore, we perform mask-detect by replacing the numerical values of the relevant time-variant features with a common masking token. These features are different
for each model. Therefore, we first identify such features and then perform the masking.
Table 3 shows the features masked for the various fake news detection models and their
corresponding performance.
5.4

Evaluating on general-domain fake news

Although we tested our model on COVID-19, ENDEMIC is highly generalised to other
domains. And to prove the generalisability, we also evaluate ENDEMIC on the FakeNewsNet [23] datasets â€“ PolitiFact and GossipCop. Both of these datasets are obtained
from the respective sources and contain labelled textual news content along with the
social context. Evaluating on these datasets allows us to validate ENDEMICâ€™s generalisation across domains outside of COVID-19 and beyond ECTF.
Table 4 shows that ENDEMIC outperforms all baselines with more than 0.5% accuracy on PolitiFact and 1.5% on GossipCop. The performance of ENDEMIC is highly
comparable compared to other baselines w.r.t. other evaluation metrics. These results
clearly establish that ENDEMIC generalises well on any fake news domain and dataset.

6

Conclusion

In this work, we introduced the task of early detection of COVID-19 fake tweets. We
developed a COVID-19 dataset with additional test set to evaluate models for early

ENDEMIC
Model

PolitiFact

11

GossipCop

Accuracy Precision Recall F1 Score Accuracy Precision Recall F1 Score

HAN

0.863

0.730

0.855

0.790

0.800

0.685

0.775

0.770

MixText

0.870

0.840

0.860

0.853

0.785

0.805

0.795

0.813

GCAN

0.867

0.855

0.880

0.875

0.790

0.805

0.795

0.803

CSI

0.827

0.847

0.897

0.871

0.772

0.732

0.638

0.682

dEFEND

0.904

0.902

0.956

0.928

0.808

0.729

0.782

0.755

CNN-MWSS

0.823

0.811

0.830

0.820

0.770

0.793

0.815

0.795

RoBERTa-MWSS

0.825

0.833

0.795

0.805

0.803

0.815

0.810

0.807

FNED

0.907

0.910

0.922

0.916

0.832

0.830

0.825

0.830

PPC

0.885

0.887

0.870

0.880

0.791

0.805

0.832

0.811

ENDEMIC

0.912

0.910

0.904

0.915

0.847

0.835

0.822

0.840

Table 4: Performance comparison on two general-domain datasets to check the generalisability of the models.
detection. We took measures to simulate the early stages of the fake news events by
extracting the external knowledge relative to the time the tweet is posted. Our proposed
model, ENDEMIC overcomes the challenges of limited dataset in a semi-supervised
fashion. We adhere to co-attention as a better information fusion tested on time invariant features. ENDEMIC outperformed nine baselines in both the tasks of general and
early-stage fake news detection. Experimental results compared to nine state-of-the-art
models show that ENDEMIC is highly capable for early detection task. We also showed
the generalisability of ENDEMIC on two other publicly available fake news dataset
which are not specific to COVID-19.

Acknowledgements
The work was partially supported by Accenture Labs, SPARC (MHRD) and CAI, IIITDelhi. T. Chakraborty would like to thank the support of the Ramanujan Fellowship.

References
1. Bruna, J., Zaremba, W., Szlam, A., LeCun, Y.: Spectral networks and locally connected networks on graphs. arXiv preprint arXiv:1312.6203 (2013)
2. Carlson: Coronavirus Tweets, Tweets (json) for Coronavirus on Kaggle. https://www.
kaggle.com/carlsonhoo/coronavirus-tweets (2020), online; accessed 2020
3. Castillo, C., Mendoza, M., Poblete, B.: Information credibility on twitter. In: WWW. pp.
675â€“684 (2011)
4. Chen, J., Yang, Z., Yang, D.: Mixtext: Linguistically-informed interpolation of hidden space
for semi-supervised text classification. arXiv preprint arXiv:2004.12239 (2020)
5. Cui, L., Shu, K., Wang, S., Lee, D., Liu, H.: defend: A system for explainable fake news
detection. In: CIKM. pp. 2961â€“2964 (2019)
6. Guacho, G.B., Abdali, S., Shah, N., Papalexakis, E.E.: Semi-supervised content-based detection of misinformation via tensor embeddings. In: ASONAM. pp. 322â€“325. IEEE (2018)
7. Gururangan, S., Dang, T., Card, D., Smith, N.A.: Variational pretraining for semi-supervised
text classification. arXiv preprint arXiv:1906.02242 (2019)
8. Helmstetter, S., Paulheim, H.: Weakly supervised learning for fake news detection on twitter.
In: ASONAM. pp. 274â€“277. IEEE (2018)
9. Liu, Y., Wu, Y.: Early detection of fake news on social media through propagation path
classification with recurrent and convolutional networks. In: AAAI. pp. 354â€“361 (2018)

12

Bansal et al., 2021

10. Liu, Y., Wu, Y.F.B.: Fned: A deep network for fake news early detection on social media.
ACM Trans. Inf. Syst. 38(3) (May 2020)
11. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy, O., Lewis, M., Zettlemoyer,
L., Stoyanov, V.: Roberta: A robustly optimized bert pretraining approach. arXiv preprint
arXiv:1907.11692 (2019)
12. Lohr, S.: Itâ€™s true: False news spreads faster and wider. and humans are to blame. The New
York Times 8 (2018)
13. Lu, J., Yang, J., Batra, D., Parikh, D.: Hierarchical question-image co-attention for visual
question answering. In: Lee, D., Sugiyama, M., Luxburg, U., Guyon, I., Garnett, R. (eds.)
NIPS. vol. 29, pp. 289â€“297. Curran Associates, Inc. (2016)
14. Lu, Y.J., Li, C.T.: GCAN: Graph-aware co-attention networks for explainable fake news
detection on social media. In: ACL. pp. 505â€“514. Online (Jul 2020)
15. Miyato, T., Dai, A.M., Goodfellow, I.: Adversarial training methods for semi-supervised text
classification. arXiv preprint arXiv:1605.07725 (2016)
16. Monti, F., Frasca, F., Eynard, D., Mannion, D., Bronstein, M.M.: Fake news detection on
social media using geometric deep learning. arXiv preprint arXiv:1902.06673 (2019)
17. Niepert, M., Ahmed, M., Kutzkov, K.: Learning convolutional neural networks for graphs.
In: ICML. pp. 2014â€“2023 (2016)
18. Nigam, K., McCallum, A.K., Thrun, S., Mitchell, T.: Text classification from labeled and
unlabeled documents using em. Machine learning 39(2-3), 103â€“134 (2000)
19. Paka, W.S., Bansal, R., Kaushik, A., Sengupta, S., Chakraborty, T.: Cross-sean: A crossstitch semi-supervised neural attention model for covid-19 fake news detection. arXiv
preprint arXiv:2102.08924 (2021)
20. Reimers, N., Gurevych, I.: Sentence-BERT: Sentence embeddings using Siamese BERTnetworks. In: EMNLP-IJCNLP. pp. 3982â€“3992. Hong Kong, China (2019)
21. Rosenfeld, N., Szanto, A., Parkes, D.C.: A kernel of truth: Determining rumor veracity on
twitter by diffusion pattern alone. In: The WebConf. pp. 1018â€“1028 (2020)
22. Shane Smith: Coronavirus (covid19) Tweets - early April. https://www.kaggle.
com/smid80/coronavirus-covid19-tweets-early-april (2020), online;
accessed 2020
23. Shu, K., Mahudeswaran, D., Wang, S., Lee, D., Liu, H.: Fakenewsnet: A data repository
with news content, social context and dynamic information for studying fake news on social
media. arXiv preprint arXiv:1809.01286 8 (2018)
24. Shu, K., Wang, S., Liu, H.: Understanding user profiles on social media for fake news detection. In: MIPR. pp. 430â€“435. IEEE (2018)
25. Shu, K., Zheng, G., Li, Y., Mukherjee, S., Awadallah, A.H., Ruston, S., Liu, H.: Leveraging multi-source weak social supervision for early detection of fake news. arXiv preprint
arXiv:2004.01732 (2020)
26. Sven Celin: COVID-19 tweets afternoon 31.03.2020. https://www.kaggle.com/
svencelin/covid19-tweets-afternoon-31032020 (2020), online; accessed
2020
27. Wang, Y., Yang, W., Ma, F., Xu, J., Zhong, B., Deng, Q., Gao, J.: Weak supervision for fake
news detection via reinforcement learning. In: AAAI. vol. 34, pp. 516â€“523 (2020)
28. Yang, Z., Yang, D., Dyer, C., He, X., Smola, A., Hovy, E.: Hierarchical attention networks
for document classification. In: NAACL. pp. 1480â€“1489 (2016)
29. Yu, D., Chen, N., Jiang, F., Fu, B., Qin, A.: Constrained nmf-based semi-supervised learning
for social media spammer detection. Knowledge-Based Systems 125, 64â€“73 (2017)
30. Zhou, X., Jain, A., Phoha, V.V., Zafarani, R.: Fake news early detection: A theory-driven
model. Digital Threats: Research and Practice 1(2) (Jun 2020)
31. Zhou, X., Zafarani, R.: A survey of fake news: Fundamental theories, detection methods, and
opportunities. ACM CSUR 53(5), 1â€“40 (2020)

