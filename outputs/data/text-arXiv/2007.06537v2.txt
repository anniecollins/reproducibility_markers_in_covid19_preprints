1

Blockchain-Federated-Learning and Deep Learning
Models for COVID-19 detection using CT Imaging

arXiv:2007.06537v2 [eess.IV] 8 Dec 2020

Rajesh Kumar*, Abdullah Aman Khan, Sinmin Zhang, Jay Kumar, Ting Yang, Noorbakhsh Amiri Golilarz,
Zakria, Ikram Ali, Sidra Shafiq and WenYong Wang

Abstract‚ÄîWith the increase of COVID-19 cases worldwide,
an effective way is required to diagnose COVID-19 patients.
The primary problem in diagnosing COVID-19 patients is the
shortage and reliability of testing kits, due to the quick spread of
the virus, medical practitioners are facing difficulty identifying
the positive cases. The second real-world problem is to share
the data among the hospitals globally while keeping in view the
privacy concerns of the organizations. Building a collaborative
model and preserving privacy are major concerns for training a
global deep learning model. This paper proposes a framework
that collects a small amount of data from different sources
(various hospitals) and trains a global deep learning model
using blockchain based federated learning. Blockchain technology
authenticates the data and federated learning trains the model
globally while preserving the privacy of the organization. First,
we propose a data normalization technique that deals with the
heterogeneity of data as the data is gathered from different
hospitals having different kinds of CT scanners. Secondly, we
use Capsule Network-based segmentation and classification to
detect COVID-19 patients. Thirdly, we design a method that can
collaboratively train a global model using blockchain technology
with federated learning while preserving privacy. Additionally,
we collected real-life COVID-19 patients‚Äô data, which is, open to
the research community. The proposed framework can utilize
up-to-date data which improves the recognition of computed
tomography (CT) images. Finally, our results demonstrate a
better performance to detect COVID-19 patients.
Index Terms‚ÄîCOVID-19, Privacy-Preserved Data Sharing ,
Deep Learning, Federated-Learning, Blockchain

I. INTRODUCTION
A. Background
A new type of Coronavirus emerged in the city of Wuhan in
China. Unfortunately, within weeks this coronavirus ( COVID19) speared to several countries and it has been proven fatal.
With an estimated 325,000 deaths in 4 months, the COVID-19
virus is considered one of the most deadly viruses [1]. The first
confirmed death from COVID-19 infection was recorded in
early January this year. The Coronavirus family is categorized
into 7 categories i.e. Human Coronavirus 229e (HCOV -229e),
Human Coronavirus OC43 (hcov-OC43), SARS-CoV, Human
Coronavirus NL63 (HcoV-NL63, New Haven Coronavirus),
Human Coronavirus HKU1, Middle East Respiratory Syndrome Coronavirus (MERS-Cov), and Wuhan Coronavirus.
R. Kumar, A. A. Khan, W. Wang and Y. Ting are with the School of
Computer Science and Engineering, University of Electronic Science and
Technology of China, Chengdu, 611731, China.
J. Kumar is with the Data Mining Lab, School of Computer Science
and Engineering, University of Electronic Science and Technology of China,
Chengdu, 611731, China
Corresponding author: WenYong Wang (wangwy@uestc.edu.cn) and Rajesh
Kumar (rajakumarlohano@gmail.com)

This novel coronavirus is the seventh type ( COVID-19). Some
coronavirus has mild symptoms while others such as SARS
(severe acute respiratory or syndrome-related Coronavirus),
and MERS (middle east respiratory) are much more dangerous.
Coronavirus can be easily transmitted between humans mainly
through social interaction with an active patient or direct
contact with an infected animal.
Without any warning, the number of COVID-19 patients
suddenly started to increase leaving the governments and
medical practitioners unprepared to handle such a situation.
Consequently, there is a shortage of testing kit supplies, and
many hospitals worldwide are facing a challenge in identifying
COVID-19 positive patients. The following criteria are used
to diagnose COVID-19 patients: Clinical symptoms, Epidemiological history, and Positive CT and Pathogenic Testing.
Radiological imaging is also one of the COVID-19s‚Äô major
diagnosis method. Most COVID-19 cases exhibit common
features (visual symptoms) on CT images, including early
ground-glass opacity, and late-stage pulmonary consolidation.
There is also a rounded morphology and a peripheral lung
distribution [2], [3]. While typical CT images may help to
screen suspected COVID-19 cases at an early stage, CT images
of various viral pneumonia are similar and overlap with other
infectious and inflammatory lung diseases [4], [5], [6], [7]. It
is worth noting that radiologists distinguish between COVID19 and other viral pneumonia. The previous work focus on to
diagnose the COVID-19 patients using computed tomography
[8], [9], [10], [11], [12]. Therefore, these previous work do not
focus on collaboratively learn model and also do not consider
the privacy issue of the hospitals.
B. Motivations
The motivation of our study is inspired by some fundamental problems. COVID-19 is spreading rapidly having different
symptoms with different symptoms with different patients.
Thus, hospitals can share their data for the accurate diagnosis
of COVID-19 patients. Sharing data securely (without leakage
the privacy of users) and train the global model for detection of
the positive cases, is a challenging task. Moreover, the existing
studies are not capable enough to share the data collaboratively
and train the model accurately. Collecting data from various
sources is a big challenge and a bottleneck in the advancement
of AI-based techniques. The availability of such confidential
data is not possible due to the absence of privacy-preserving
approach for the health care centers [13], [14], [15], [16],
[17], [18], [19], [20], [21], [22]. Furthermore, to train the

2

deep learning model collaboratively, over a public network,
is another challenge.
The latest report of the World Health Organization reveals
that COVID-19 is an infectious disease that primarily affects
the lungs such as SARS, giving them a honeycomb-like
appearance [23]. Even after recovering from COVID-19, some
patients have to live with permanent lung damage [24]. First
motivation of our work to find small infected areas in the
lungs by COVID-19, it benefits the professional radiologists
do not missed infection. Second motivations to share the data
to train a better deep learning model, while keeping in view
the privacy concern of the data providers. The advantage to
share the data is feasible to develop a deep learning-based
model for automatic detection of COVID-19.
‚Ä¢ The First challenge is the availability of confidential data
is not possible due to the absence of privacy.
‚Ä¢ The second challenge is to train the global model (Federated model) via blockchain network.
‚Ä¢ The third challenge is the unavailability of a dataset, it
is quite challenging to collect enough amount of training
data and make it better predication model with the privacy
concerns of hospitals.
‚Ä¢ Finally, to recognize the patterns of the lung screening of
COVID-19 is also a challenging task.
C. Our approach
In this paper, we propose a framework that builds an accurate collabroative model using data from multipile hospitals
to recognize CT scans of COVID-19 patients. The proposed
blockchain based federated learning framework learns collaboratively from multiple hospitals having different kinds of CT
scanners. Firstly, we propose a data normalization process to
normalize the data obtained from the different sources. Then
we employ deep learning models to recognize the COVID-19
patterns of lung CT scans. We use segcaps for image segmentation and further train a Capsule Network [25] for better
generalization. We found the capsule network achieved better
performance as compared to other learning models. Finally, we
train the global model and solve the privacy issue using the
federated learning technique. The proposed framework collects
the data and collaboratively trains an intelligent model then
shares this intelligent model in a decentralized manner over
the public network.
By using federated learning, the hospitals keep can their
data private and share only weights and gradients while
blockchain technology is used to distribute the data among
the hospitals. The decentralized architecture for data sharing
among multiple hospitals shares the data securely without
leakage the privacy of the hospitals. Additionally, this article
introduces a new dataset, named CC-19, related to the latest
family of coronavirus i.e. COVID-19. The dataset contains
the Computed Tomography scan (CT) slices for 89 subjects.
Out of these 89 subjects, 68 were confirmed patients (positive
cases) of the COVID-19 virus, and the rest 21 were found
to be negative cases. The dataset contains 34,006 CT scan
slices (images) belonging to 89 subjects. The data for these
patients were collected on various days having about 231 CT
scan volumes in total.

D. Contributions
The main contributions of the paper are not limited to:
1) This paper proposes a data normalization technique (to
accurately train the federated learning model) as the data
is collected from different sources (i.e, Hospitals) and
devices (CT scanner machines).
2) The proposed technique detects the patterns of COVID19 from the lung CT scans using Capsule Network based
segmentation and classification.
3) This paper proposed a blockchain empowered method to
collect the dataset collaboratively from different sources
while keeping in view the organizations‚Äô privacy concerns. Federated learning employed is to protect the
organizations‚Äô data privacy and train the global deep
learning model using less accurate local models.
4) Additionally, we introduce a new dataset that consists
of 89 subjects out of which 68 subjects are confirmed
COVID-19 patients. The dataset contains 34,006 CT
scan slices (images) belonging to 89 subjects.
E. Applications
The proposed approach is practical for big data analysis
(i.e., lung CT scans), and it efficiently process the data using
blockchain and deep learning model. Consider a scenario of
the real-time use case of a hospital having some new symptoms
of the COVID-19 virus. To find out new symptoms or new
information regarding COVID-19, the data needs to be stored
on a decentralized network without leakage of the privacy of
the patients and securely share the knowledge of the latest
symptoms. The federated learning secures data through the
decentralized network and distributes the training task to train
a better model using the latest available patients data.
The proposed framework collects a small amount of data
from various sources and to train the deep learning model,
The blockchain combined the each trained model via federated
learning. The trained model blockchain network provides more
better and accurate predication beacuse it holds the the newest
information about COVID-19 symptoms.
F. Structure of paper
The rest of this paper is organized as follows: In Section
II, this paper proposes a Capsule Network based segmentation and classification model and blockchain based federated
learning for secure data sharing without leakage the privacy. In
Section III, we describe the dataset and experiment results for
our proposed scheme. In Section IV, we present an overview of
the studies related to deep learning, COVID-19, and federated
learning. Finally, Section V concludes this paper.
II. P ROPOSED M ODEL
In reality, hospitals and other relevant organizations are
reluctant to share their patients‚Äô data to preserve privacy of
the patients. Moreover, it is a known fact that deep learning
models required a large amount of data to train a model that
can handle real-world problems. For that reason, this paper
considers collecting multiple hospitals‚Äô data without leakage of

3

data privacy. This paper proposes blockchain based federated
learning framework to train and share a collaborative model.
Federated learning is used to combine the weights of the
locally trained model by the hospital referred as to a global
or collaborative model.
As the data is collected from multiple sources, for that
reason, we design a normalization technique to deal with
different kinds of CT scanners (Brilliance ICT, Samatom
definition Edge, Brilliance 16P CT) data. After normalization
of the data, we segmented the images and then train the model
for recognization of COVID-19 suspects using the Capsule
Network.
We divided the methodology into two parts i) Local model
ii) Federated learning. First, we solve the problem of heterogeneous CT scan data. Then, we use the Segcps [26] for
segmentation and train the local model to detect the patterns
of COVID-19. Finally, we share the local model weights to
the blockchain network to train the global model.

A. Data Normalization
A major issue with federated learning is to deal with input
data from multiple sources and various machines with different
parameters. Most of the existing techniques are not efficient
enough to deal with this problem for federated learning. To
solve this issue, we propose a normalization technique that
can deal with any CT scan and bring the images to the same
standard. Because of this normalization, federated learning can
deal with the heterogeneity of the dataset and train a better
learning model. The normalization method has two phases
i) spatial normalization, and ii) signal normalization. Spatial
normalization deal with the dimension and resolution of the
CT scan. Signal normalization deals with the intensity of each
voxel of the CT scanners which is based on the lung window.
1) Spatial Normalization: As already discussed, different
CT scanners have different parameters for CT scans such as
high-resolution scan volume is 0.31 √ó 0.31 √ó 0.31 mm3 and
low resolution 0.98 √ó 0.98 √ó 2.5 mm3 . In our case, we used
federated learning for the data obtained from multiple sources.
We use the standardized volume 334 √ó 334 √ó 512 mm3 for
human lung. Moreover, we use the Lanczos interpolation [27]
to resale the standard resolutions.
2) Signal Normalization: As every CT scan has Hounsfield
Units (HU) and the data collected from different hospitals have
different HU (i.e.,-400 HU to -600 HU). In medical practice,
radiologists set the lung window for every CT scanner. There
are different types of windows the one is window Level (W L)
and the other is window width (W W ) are mostly used. Where
W L is defined as the central signal value and W W defines
the width of this window. The proposed Equation 1 represents
the upper bound and the lower bound of the voxel.
Ioriginal ‚àí WL
(1)
WW
Ioriginal is the intensity of the data and Inormalized is the final
intensity. We set the range of the lung window is [‚àí0.5, 0.5]
to standardized the embedding space.
Inormalized =

B. Segmentation and Classification Model
This section proposes the segmentation based on [26].
Further, the Capsule Network is trained for the detection of
COVID-19 using the segmented CT scan images.
1) Segmentation: We take 2D slices for the segmentation.
A standardized volume 334 √ó 334 √ó 512 mm3 for human lung
segmentation is used. Each CT scan volume (3D) has three
planes XY , XZ, and Y Z. We formalize the XZ or Y X
planes to easily differentiated the lung infection (as shown in
first row of Figure 10).


B
B
probB = g P rxy
, P rB
(2)
yz , P rxz
Where probB defines as probability and B is the infection
point. g is the method to define the voxel of three dimensions
views. g is aggregation function to predict the Pxy , Pyz , and
Pxz voxel. Thus, the traditional Equation is time-consuming,
so, we modify the Equation 2 to:


ÀÜ B = g pr
ÀÜB
ÀÜB
prob
ÀÜB
xz
yz , pr
xy , pr







B
B
B
B
B
B
= g fxy prxy , fyz pryz , fxz prxz

(3)

2) Capsule Networks for Classification of COVID-19:
A deep learning framework usually has a feature extraction
pipeline that estimates and extracts prominent features. Afterward, a learning process such as MLP (multi-layer perceptron)
is applied to learn the appropriate class on the extracted
features. Over the past few years, researchers have used and
fine-tuned the feature extraction pipeline of these robust deep
learning frameworks. We design a Capsule Network because
it achieves high performance in detecting diseases in the
medical images. The previous technique needs lots of data to
train a more accurate model. The Capsule Network improves
the deep learning models‚Äô performance inside the internal
layers of the deep learning models. The architecture of our
modified Capsule Network is shown in Figure 1, which is
similar to Hinton‚Äôs Capsule Network. The Capsule Network
contains four layers: i)convolutional layer, ii) hidden layer, iii)
PrimaryCaps layer, and iv) DigitCaps layer.
A capsule is created when input features are in the lower
layer. Each layer of the Capsule Network contains many
capsules. To train the Capsule Network, the activation layer
represents instantiate parameters of the entity and compute
the length of the Capsule Network to re-compute the scores
for the feature part. Capsule Networks is a better replacement
for Artificial Neural Network (ANN). Here, the capsule acts
as a neuron. Unlike ANN where a neuron outputs a scalar
value, Capsule Networks tend to describe an image at a
component level and associate a vector with each component.
The probability of the existence of a component is represented
by this vector‚Äôs length and replaces max-pooling with ‚Äùrouting
by agreement‚Äù. As capsules are independents the probability of
correct classification increases when multiple capsules agree
on the same parameters. Every component can be represented
by a pose vector Ui rotated and translated by a weighted matrix

4

Wi,j to a vector uÃÇi|j . Moreover, the prediction vector can be
calculated as:
uÃÇi|j = Wi,j ui

(4)

The next higher level capsule i.e. sj processes the sum of
predictions from all the lower level capsules with ci,j as a
coupling coefficient. Capsules sj can be represented as:
X
Sj =
ci,j uÃÇi|j
(5)
i

where ci,j can be represented as a routing softmax function
given as:
ebij
(6)
ci,j = P b
ik
ke
As can be seen from the Figure 1, the parameter c, A squashing
function is applied to scale the output probabilities between 0
and 1 which can be represented as:
a=

kak2
a
2
1 + kak kak

(7)

For further details, refer to the original study [25]. We perform
the routing by agreement using the Algorithm 1
Algorithm 1 Routing algorithm.
1:
2:
3:
4:
5:

Forall capsules i in layer l and capsule in layer l + 1) do bi,j ‚Üê
‚àí0
For k iterations do
Forall capsule i in layer l do ci,j
Forall capsule j in layer l + 1 do Sj
Forall capsule j in layer l + 1 do Sj State Forall capsule i in layer l, j in layer
l + 1 do bi,j ‚Üê
‚àí bi,j + uÃÇi|j .vj
6: Return vj

C is an array after softmax, and it can be determined
by dynamic routing by agreement. There are quite a few
introductions to this method, the main meaning is that through
several iterations, the distribution of the output of the lowlevel capsule to the high-level capsule is gradually adjusted
according to the output of the high-level capsule, and finally
an ideal distribution will be reached. The detailed training
algorithm is shown in the paper [27]. We use the Capsule
Network to train the model and compare it with the state of art
deep learning networks. Table 1 shows the difference between
traditional and Capsule Network. In section III, we compare
traditional deep learning with the Capsule Network classifiers.
C. Federated Learning to train the global model
In this section, we consider a decentralized data sharing
scenario with multiple hospitals. Each hospital is willing to
share its model (weights), our proposed method assists in
hiding the user data and share the model over a decentralized
network. Further, federated learning is used to combine the
net effect of different models shared by different hospitals.
The base architecture of federated learning is shown in Figure
2. The main goal is to utilize federated learning to share
the data among the hospitals without leakage of privacy. We
consider H is the hospitals and d is the union dataset. Each
of the hospital H agrees to share the data without leakage
of private information. First, we train the global model M ,
without leaking the privacy, then we alter a small part of

TABLE I: A comparison between capsule and traditional
neural network.
Operation

Neuron (scalar)

Capsule (vector)

Affine
transformation

NA

uÃÇi|j = Wi,j ui

Weighted
sum

aj =

Activation
Output
Graphical
representation

P3

Sj =

P

hw,b (x) = f (aj )

aj =

aj
kaj k2
1+kaj k2 kaj k

scalar

vector(aj )

i=1

Wi xi + b

x1
x2

w1
w2

f(x):tanh,relu,etc.

u1
u2

x3

w3
b

f(x)

u3

hw,b(x)

+1

i ci,j uÃÇi|j

u^1
u^2

u^3

Squash

aj

+1

the randomized mechanism through 1) Random sub-sampling,
2) Distorting. The random sub-sampling model can get final
weights R(M ) and share the data globally. 1) Random subsampling: Let H be the number of hospitals. In every round of
the communication, a subset of Xt of size mt ‚â§ H is sampled.
Then, distribute the weights (wt) among the
The
 hospitals.
mt
blockchain stores the local hospitals models wH H=0 . The
difference between the local and distributed model is referred
to as H 0 s update ‚àÜwk = wk ‚àí wt . The updated weights are
sent to the decentralized network for each round.
2) Distorting: A Gaussian method was utilized to disorder the sum of updates. It requires information about
the sensitivity information to sum all operations. The sensitivity of 
the updatedversion is measured by ‚àÜwh =
k‚àÜwh k2
‚àÜwh / max 1,
. Scaling helps to ensure the limited
S
second standard ‚àÄH, ‚àÜwÃÑH 2 < S. The sensitivity of the
update bound operation by S. The updated model is defined
as:

wt+1 = wt +

+



1
mt

mt
X

‚àÜwH
‚àÜw / max 1,
S
H=0
|
{z
H

!
2

}

Gaussian
mechanism approximation sum of updates

2 2

N 0, œÉ S
|
{z
}

Sum of update sclipped at S

(8)
We noticed that the distortion of 1/mt in the Gaussian
process is regulated by the S 2 œÉ 2 /m noise variance. But this
distortion should not surpass a certain amount. Otherwise,
the additional noise removes too much detail from the subsampled average and no learning improvement can be gained.
Gaussian mechanism and sub-sampling are distributed processes. Nevertheless, it is used for gradient averaging covering
a single data point gradient at each iteration. This m and
œÉ often describes the lack of privacy suffered when the
randomized process produces an average estimate.
The preference will then be based on an upper limit at
the r-distortion rate and a lower limit on the number of

5

Negative

prediction

Œª

Positive
Capsule

Capsule

Output
segmentation
32 √ó 32
512 √ó 512 √ó 2 √ó 16

512 √ó 512 √ó 1 √ó 16

2D 5 √ó 5 Conv.

2D 5 √ó 5 Conv.

16

16

16
SegCaps

2D 5 √ó 5 Conv.

2D 4 √ó 4 DC, R3

16
16
Capsule

2D 5 √ó 5 Conv.

32

32

32
Capsule

32

2D 4 √ó 4 DC, R3
2D 5 √ó 5 CC, R3

2D 5 √ó 5 CC, R3

64 √ó 64 √ó 8 √ó 64

2D 4 √ó 4 DC, R3

128 √ó 128 √ó 4 √ó 32

128 √ó 128 √ó 8 √ó 32

128 √ó 128 √ó 8 √ó 32

16
Capsule

64

32

64 √ó 64 √ó 8 √ó 32

2D 5 √ó 5 CC, R3

128 √ó 128 √ó 4 √ó 32

2D 5 √ó 5 CC,
R3

2D 5 √ó 5 CC, R3

16
Capsule

256 √ó 256 √ó 4 √ó 16

256 √ó 256 √ó 2 √ó 16

2D 5 √ó 5 CC, R1

256 √ó 256 √ó 4 √ó 16

256 √ó 256 √ó 4 √ó 16

2D 5 √ó 5 CC, R3

2D 5 √ó 5 CC, R1

512 √ó 512 √ó 1 √ó 16

2 √ó 16

2D 5 √ó 5 CC, R3

Input

Fig. 1: Our proposed, capsule-based (SegCaps) segmentation and classification model. Further, CC, DC, and Conv. represent
convolution capsule, Deconvolution capsule, and convolution respectively.

Hospital 1

PH
H
where ¬µx,y = H1 H=1 ‚àÜwx,y
Vc is defined as the sum of all variances in the update
matrix:

Step 1: Blockchain sharing the initial learning

Learned Delta 1
Step 3: Averaging the
new learning
Step 2: Uploading the local models and
generating new learning using private data

Vc =

q
p


1 XX
V AR ‚àÜwx,y
b √ó a x=0 y=0

(10)

Finally, the Us update can be expressed as:
q
p
1 XX 2
Us =
¬µ
b √ó a x=0 y=0 x,y

Learned Delta 2
Step 1: Blockchain sharing the initial learning

‚àÜwx,y describes the (x, y) ‚àí th parameters of the updates
from ‚àÜw ‚àà Rb√óa for the communication round. Moreover, S
defines trade-off. If S has a smaller value then the noise will
be smaller.

Hospital 2

Fig. 2: Overview of the Federated Learning process.

data provider sub-samples. Therefore describe the V c variance
between patients as a measure of similarity among hospital
updates shown in the below Equation. The parameters (x, y)
is the throughout of H hospitals is defined as:
H
2


1 X
H
V AR ‚àÜwx,y =
‚àÜwx,y
‚àí ¬µx,y
H
H=0

(11)

(9)

D. Blockchain based fast and effective Federated Learning
As patients‚Äô data is sensitive and the volume is high,
placing data on the blockchain with its limited storage space
is expensive both financially and for computational resources.
Thus, the actual CT scan data is stored by the hospital, while,
blockchain helps to retrieve the trained model. When a new

6

ID

BC- Bloc k

Private Key

BC- Bloc k

BC- Bloc k

Transac tion Data

Retrival
Rec ord

Hash
Value

Provider
ID

Data

Tim e
Stamp

TC

Data
Sharing
Rec ord

Request
or Type

Request
or ID

Data

Tim e
Stamp

TC

To secure the privacy of data in a decentralized manner
the randomized method for two hospitals nodes is shown in
Equation 14. Where R andR0 is the neighboring records of
data. O is the outcome set of data. A(R) ‚àà S achieves the
privacy of the data.
i
h

(14)
Hr[A(R) ‚àà S] ‚â§ exp() ¬∑ Hr A R0 ‚àà O
However, to achieve data privacy for multiple hospitals,
Laplace is applied for the local model training (mi ):

ID

BC- Bloc k

Private Key

BC- Bloc k

BC- Bloc k

mÃÇi = mi + Laplace(s/)

where s shows the sensitivity as expressed by Equation 16:

Transac tion Data

Retrival
Rec ord

Hash
Value

Provider
ID

Data
Sharing
Rec ord

Request
or Type

Request
or ID

Data

Tim e
Stamp

TC

Data

Tim e
Stamp

TC

s = max0 f (H) ‚àí f H 0
H,H

ID
N blocks

Private Key

Fig. 3: Overview of the Blockchain record storing process. TC
represents the transaction count.

hospital provides the data, it stores a transaction in the block
to verify the owner of the data. The hospital data include
the type of data and the size of the data. Each transaction
for data sharing and retrieval process is shown in Figure 3.
The proposed model solves data-sharing retrieval requests.
Multiple hospitals can collaboratively share the data and train
the collaborative model which can be used to predict optimal
results. The retrieval mechanism does not violate the privacy
of hospitals. Inspired by Maymounkov et al. [28], we present
multi-organization architecture using blockchain technology.
All hospitals H are partitioned share data in various categories.
Each category has a different community. Each community
maintains the log table Log(n). The blockchain stores the all
unique IDs for every hospital.
Retrieving data into the physically present nodes is expressed by Equation 12. We measure the distance between
two nodes as Equation 12, where, H is the data categories to
retrieve the data among the
 hospitals. Moreover, the distance
of two
nodes
d
H
,
H
i i
j measured to the retrieve of data,

H

j
i
and xH
are the attributes of the weight matrix for
pq + xpq
the node Hi and Hj , respectively. Every hospital generates its
unique ID according to the logic and distance of the nodes.

P


di Hi , Hj =


p,q‚àà{Hi‚à™Hj ‚àíHi ‚à©Hj }

P

pq‚ààHi ‚à™Hj



¬∑ log dp Hi , Hj



i
xH
pq



H

j
i
xH
pq + xpq

H
+ xpqj


(12)

Provided two nodes Hi and Hj with unique IDs Hi (id) and
Hj (id) shown in the Equation 13.

d Hi , Hj = Hi (id) ‚äï Hj (id)

(15)

(13)


1

(16)

The consensus algorithm is executed to train the global
model by using the local models. As all nodes collaboratively
train the model, we provide proof of work to share the data
between the different nodes. During the training phase, the
consensus algorithm checks the quality local models and the
accuracy is measured by mean absolute error (MAE). F (xi )
shows predicated data and mi , yi is the original data. The
high accuracy of mi shows the low mean absolute error of mi .
The voting process consensus algorithm among the hospitals
shown in Equation 17 and 18. Where Equation 17 M AE (mi )
shows the locally trained model and Œ≥ shows the global models
weights in Equation 18.
n

M AE (mi ) =

1X
yi ‚àí f (xi )
n i=1

(17)


 1X
M AE Hj = Œ≥ ¬∑ M AE mj +
M AE (mi ) (18)
n
To preserve the hospitals‚Äô data privacy, all data is encrypted
and signed using public and private keys (PKi , SKi ), MAE
calculates all transactions and broadcast Hj . M AE(M )
calculates each transaction of the model. If all transactions
are approved then the record is stored in the distributed
ledger. More precisely, the training of the consensus algorithm
describes as follows:
1) Node Hi transfers the local model mi transaction to the
Hj .
2) Node Hj transfers the local model mi to the leader.
3) The leader broadcast the block the node to the Hi and
Hj .
4) Verify the Hi and Hj and wait for the approval.
5) Finally, store the blocks in the retrieval blockchain
database.
1) Data Sharing Process: Current approaches use encryption to protect data. It is a risk for data providers to share
personal data because of certain security attacks. A simple
solution is to transmit the data to the requester with legitimate
details and to preserve the data holders‚Äô privacy. Instead
of sharing original data, data providers such as hospitals,
exchange only the learned models with the requester. Figure
4 shows the process of data sharing. The nodes are com-

7

Hash vector based hospital ID is
generated for every hospital to encourage
participation

Initialization

The hospital public key, and data for
registration.
Then retrieve record through blockchain

Registering retrieval records

1

for(each hospital
hi ÔÉé H )

False

2

3

Req={f1, f2, , fx}
Request data with time stamp and Private
Key with singed by owner

Launching data sharing
requests

First, authenticate requester ID and
search in decentralized blockchain
database

Data retrieval

4

True

While(accuracy <
Threshold)

False

True

If (iter =0)

5

A training set is built based on
hospitals local data Fx(D),DT=<fx,fx(D)>
and returned as a global model

Data model learning

True
6

7

Data providers broadcast the local
model and transactions are generated
blockchain database

Generating data sharing records

Relevant nodes perform a consensus
process for data retrival

Carrying out consensus

Fig. 4: Data Sharing Process.

Create a differential in a data
privacy mode using received
models

Broadcast models
participating hosptitals
according
to local retrieval tables

Broadcast local models to
participating hospitals

ÔÄΩ

municating with each other and the consensus process learns
from federated data. The provider, and requester search and
store the data into the blockchain nodes. More precisely, the
steps of data sharing are shown in Figure 4. To integrate
the blockchain with federated learning retrieved data securely
for the multiple world-wide hospitals which can provide an
effective prediction.
To protect the privacy of the data, we share the trained
model instead of the original image data. The objective of
the proposed architecture is to train the global model by using
locally trained models. The secure data sharing is illustrated in
Figure 5. In the first phase, we select the training data and then
use the private federated learning algorithm for collaborative
multi-hospital learning. In other words, the hospital shares
the locally trained model weights to the blockchain network
and federated learning combines the local model into a global
model.
III. E XPERIMENTS R ESULTS
A. CC-19 Dataset
In the past, Artificial intelligence (AI) has gained a reputable
position in the field of clinical medicine. And in such chaotic
situations, AI can help the medical practitioners to validate
the disease detection process, hence increasing the reliability
of the diagnosis methods and save precious human lives.
Currently, the biggest challenge faced by AI-based methods
is the availability of relevant data. AI cannot progress without
the availability of abundant and relevant data. In this paper,
we collected the data CT scan data for 34006 slices from
the 3 different hospitals. The data is scanned by 6 different
scanners shown in Table II. In addition, we collected the third
party dataset [29], [30] from different sources to validate the
federated learning methods. Moreover, the collected dataset is

False

Closest centroid each sample
calculated mi nosed on noiseadded vector data

1
k

ÔÉ•mÀÜ

Iter=iter+1

i

k

Stop

Fig. 5: Private Federated Learning Algorithm.
publicly available via GitHub (https://github.com/abdkhanstd/
COVID-19). The collected data set contains the Computed
Tomography scan (CT) slices for 89 subjects. Out of these
89 subjects, 68 were confirmed patients (positive cases) of the
COVID-19 virus, and the rest 21 were found to be negative
cases. The proposed dataset CC-19 contains 34,006 CT scan
slices (images) belonging to 89 subjects out of which 28,395
CT scan slices belong to positive COVID-19 patients. Figure
6 shows some 2D slices taken from CT scans of the CC19 dataset. Moreover, some selected 3D samples from the
dataset are shown in Figure 7. The Hounsfield unit (HU) is
the measurement of CT scans radiodensity as shown in Table
III. Usually, CT scanning devices are carefully calibrated to
measure the HU units. This unit can be employed to extract
the relevant information in CT Scan slices. The CT scan
slices have cylindrical scanning bounds. For unknown reasons,
the pixel information that lies outside this cylindrical bound
was automatically discarded by the CT scanner system. But
fortunately, this discarding of outer pixels eliminates some
steps for preprocessing.
Collecting dataset is a challenging task as there are many
ethical and privacy concerns observed the hospitals and medical practitioners. Keeping in view these norms, this dataset
was collected in the earlier days of the epidemic from various
hospitals in Chengdu, the capital city of Sichuan. Initially, the
dataset was in an extremely raw form. We preprocessed the
data and found many discrepancies with most of the collected

8

TABLE II: CC-19 dataset collected from three different hospitals (A, B, and C).
Hospital ID
CT scanner ID
Number of Patients
Infecation annotation
CT scanner

A
1
30
Voxel-level
SAMATOM
scope

Lung Window level (LW)
Lung Window Witdh (WW)
Slice thickness (mm)
Slice increment (mm)
Collimation(mm)
Rotation time (second)
Pitch
Matrix
Tube Voltage (K vp)

-600
1200
5
5
128*0.6
1.2
1.0
512*512
120

A
2
10
Voxel-level
Samatom
Definitation
Edge
-600
1200
5
5
16*1.2
1.0
1.0
512*512
120

Fig. 6: Some random samples of CT scan 2D slices taken from
CC-19 dataset.
CT scans. Finally, the CT scans, with discrepancies, were
discarded from the proposed dataset. All the CT scans are
different from each other i.e. CT scans have a different number
of slices for different patients. We believe that the possible
reasons behind the altering number of slices are the difference
in height and body structure of the patients. Moreover, upon
inspecting various literature, we found that the volume of
the lungs of an adult female is, comparatively, ten to twelve
percent smaller than a male of the same height and age [31].
B. Evaluation Measures
Specificity and sensitivity are the abilities of a model that
how correctly the model identifies a subject with disease and
without a disease. In our case, it is critical to detect a COVID19 patient as missing a COVID-19 patient can have disastrous
consequences. The formulas of the measures are given as
follows:
Precision =

TP
TP + FP

B
3
13
Voxel-level
Brilliance
16P iCT

B
4
7
Voxel-level
Brilliance
iCT

C
5
20
Voxel-level
Brilliance
iCT

C
6
9
Voxel-level
GE 16-slice
CT scanner

-600
1600
5
5
128*0.625
0.938
1.2
512*512
120

-600
1600
5
5
16*1.5
1.5
0.938
512*512
110

-600
1600
5
5
128*0.6
1.0
1.75
512*512
120

-500
1500
5
5
16*1.25
1.75
1.0
512*512
120

S/No
1
2
3
4
5
6
7
8
9
10
11
12
13

Substance
Air
Bone
Lungs
Water
Kidney
Blood
Grey matter
Liver
White matter
Muscle
Soft Tissue
Fat
Cerebrospinal fluid(CSF)

Hounsfield Unit (HU)
-1000
+700 to +3000
-500
0
30
+30 to +45
+37 to +45
+40 to +60
+20 to +30
+10 to +40
+100 to +300
-100 to -50
15

TABLE III: Various values of Hounsfield unit (HU) for different substances.

sensitivity=recall =
specificity =

TP
TP + FN

TN
TN + FP

TP + TN
TP + TN + FP + FN
A medical diagnosis based system needs to have high sensitivity and recall. We present a comprehensive overview of various
famous deep learning frameworks. The results presented in
Table IV indicate the superiority of our proposed method.
Total accuarcy =

C. Results of the pattern recognition with the benchmark
algorithms
We performed comprehensive experiments using different
kinds of deep learning models i.e.,(VGG16, AlexNet, Inception V3, ResNet 50-152 layers, MobileNet, DenseNet). We

9

Fig. 7: This figure shows some selected samples from the ‚ÄúCC-19 dataset‚Äù. Each row represents different patient samples with
various Hounsfield Unit (HU) for CT scans. The first there columns represent the XY, XZ, and YX plane of the 3D- volume
respectively. The fourth column represents a whole 3D-Volume followed by a bone structure in the fifth column.

used deep learning models and different layers for comparing
the performance models on the COVID-19 dataset, which
is shown in Table IV. We evaluate the performance of the
Capsule Network for the detection of COVID-19 lung CT
image accuracy. Figure 8 shows the deep learning models; the
Capsule Network achieves high sensitivity and less specificity,
we achieved high detection performance through the Capsule
Network. Figure 9 shows the Segcaps based Capsule Network
achieved the best performance and provide the highest sensitivity and lowest specificity. These models were tested using three
different test lists containing about 11,450 CT scan slices.
The COVID-19 infection segmentation shown in Figure 10,
indicates our method outperforms the baseline methods. The
proposed techniques‚Äô results are close to the ground truth. In
contrast, U Net++s‚Äô performance is near to our results.

D. Federated Learning Security analysis and Results
As the dataset has been gathered from different sources
and different hospitals having various kinds of machines. To
measure the performance of federated learning, we distribute
the datasets over three hospitals. In this model, multiple
hospitals can share the data and learn from federated learning.
The performance of our proposed model is distributed shown
in Figure 11, accuracy was changed when the hospitals or
providers were increases. It is better to use more data providers
for better results. Figure 12 shows that model loss convergence. As we can see in Figure 11 the accuracy does not
change smoothly because the samples from different hospitals
are not the same. The accuracy depends on the number of
patients or slices. The same is the process for the model loss.
Also, it can be seen that the number of providers is increasing.
The global model aggregate the local models, each local model
normalizes the data before training a local model. The number

10

0.8294

0.1561

AlexNet [33]

MLP

Scratch

0.833

0.831

0.191

Xception V1 [34]

MLP

Imagenet

0.830

0.894

0.110

VGG19 [32]

MLP

Imagenet

0.827

0.8616

0.128

ResNet50 [35]

MLP

Imagenet

0.833

0.771

0.249

ResNet50 V2 [36]

MLP

Imagenet

0.830

0.837

0.166

Resnet152 V2[36]

MLP

Imagenet

0.828

0.861

0.134

Inception V3 [37]

MLP

Imagenet

0.828

0.833

0.159

MobileNet [38]

MLP

Imagenet

0.830

0.912

0.089

MobileNet V2 [39]

MLP

Imagenet

0.828

0.873

0.118

DenseNet121 [40]

MLP

Imagenet

0.832

0.903

0.113

DenseNet169 [40]

MLP

Imagenet

0.831

0.886

0.126

DenseNet201 [40]

MLP

Imagenet

0.829

0.844

0.152

Ours (SegCaps)

Capsule Network

-

0.830

0.987

0.004

0 .8

8 0

5 0
V G
G 1
6
A L
E X
N E
X c
T
ep t
io n
V 1
V G
G 1
9
R e
sN
e t5
R e
0
sN
e t5
0 V
R e
2
sn e
t1 5
2 V
In c
2
ep t
io n
V 3
M o
b il
eN
M o
et
b il
eN
et V
D e
2
n se
N e
t 1
D e
2 1
n se
N e
t 1
D e
6 9
n se
N e
t2 0
1

0 .5

of hospitals affects the performance of the collaborative model.
Additionally, the run time is shown in Figure 13. It varies for
the datasets and number of iteration in different sub-datasets.
We compare the federated learning with the local model as
shown in Figure 9. The local model is trained on the whole
dataset and the federated learning model learns from the local
models. Figure 11 and 12 indicates that performance increases
significantly when data providers are increasing. However,
federated learning does not affect the accuracy but it achieves
privacy while sharing the data.
Differences-Privacy: Figure 5 describes the differences
in privacy analysis, where a principled approach that

8 3 .1 6

8 2 .9 4

0 .9 8

6 0

V G
G 1
6
A L
E X
N E
X c
T
ep t
io n
V 1
V G
G 1
9
R e
sN
e t5
R e
0
sN
e t5
0 V
R e
2
sn e
t1 5
2 V
In c
2
ep t
io n
V 3
M o
b il
eN
M o
et
b il
eN
et V
D e
2
n se
N e
t 1
D e
2 1
n se
N e
t 1
D e
6 9
n se
N e
t 2
0 1
O u
rs

0 .6

Fig. 8: Sensitivity/Recall of the COVID-19 dataset over the
decentralized network.

‚Ä¢

7 0

0 .8 4

0 .9

0 .8 9

0 .9 1

0 .8 7

0 .8 6

0 .8 3

0 .8 4
0 .7 7

0 .9
0 .8 3

0 .8 6

0 .7

8 8 .6

9 0

O u
rs

0 .9

8 8 .6

1 0 0

A c c u ra c y %

1 .0

9 8 .6 8

0.8269

9 0 .2 5 3

Imagenet

9 1 .2 4

MLP

8 7 .3

VGG16 [32]

8 6 .0 7

Specicivity

8 2 .3 2

Sensitivity / Recall

8 3 .7 8

Precision

8 3 .7 1

Pre-trained

8 6 .1 6 1

Learnable node

7 7 .0 9

Feature extraction network

0 .8 3

S e n s itiv ity

TABLE IV: The performance of some famous deep learning networks. The bold values represent the best performance. It can
be seen that the Capsule Network exhibited the highest sensitivity while ResNet has the best specificity.

Fig. 9: Accuracy of the COVID-19 Images.

‚Ä¢

‚Ä¢

enables organizations to learn from most data while
ensuring that these results do not allow data to be
distinguished or re-identified by any individual. On the
other hand, Equation 14 obtains the value in the data to
ensure strong data security.
Trust: The decentralized trust mechanism of the
blockchain allows everything to run automatically
through a preset program, which improves data security.
Relying on a strict set of algorithms, the decentralized
blockchain technology can ensure that the data is true,
accurate, transparent, traceable, and cannot be tampered
with.
Data security: Data providers have the authority to

Ground Truth

Ours

U-NET ++

U-NET

CT Image

11

Fig. 10: A visual comparison (segmentation) of our method with other studies. The first row (CT-Images) represents the original
images taken from different datasets. The first two columns show the overlay segmentation result while the rest of the columns
represent the masks.

control their data. Actual data is uploaded with the
signature of the owner in the blockchain database. The
owner has the right to control and change the policy of
the data using the smart contract. The blockchain uses
cryptographic algorithms that enable the security of the
data.

them with the deep learning models shown in Figure V.
Moreover, we compare federated learning with the state-ofart deep learning models such as VGG, RESNET, ImageNet,
MobileNet, Desnet, Capsule Network. The results show the
accuracy is similar to train the local model with the whole
dataset or divide data into different hospitals and combine the
model weights using blockchain based federated learning.

E. Comparison with other methods
A lot of previous studies have been carried out for detecting
the COVID-19 such as [41], [8], [42], [43], [44], these
techniques do not consider data sharing to train the better
prediction model. However, some techniques used GAN and
data augmentation for generating fake images. The performance of such methods is not reliable in the case of medical
images. Due to the small number of data patients [45] the
data analytic is difficult. Our proposed model collects a huge
amount of real-time data to build a better prediction model.
Firstly, we compare with the state of art studies and compare

Finally, we compare our work with blockchain-based
data sharing techniques. [46] proposed a deep learning and
blockchain-based technique to share the medical images, but
the main weakness of the model is that it is not based on
federated learning and do not aggregates the neural network
weights over the blockchain. Moreover, [47], [48] design a
framework based on federated learning but they only consider
share vehicle data. Our proposed framework trains the global
model to collect data from different hospitals and train a
collaborative global model.

12

TABLE V: A comparison with the state-of-the-art studies related to COVID-19 patients‚Äô detection
Study

Backbone method

Tasks

Number of cases

Performance

Sharing Privacy
protection

Chen et al.
[49]

2D Unet++

COVID-19, viral,
baterial and Pneu.
classification

106 cases

95.2 %(Accuracy)
100% (Senstivity)
93.6%(Specificity)

No

No

Shi et al. [50]

Random Forest

COVID-19, viral/
baterial Pneu. and
normal classification

2685 cases

87.9 %(Accuracy)
90.7% (Senstivity)
83.3%(Specificity)

No

No

Zheng et al.
[51]

2D Unet and 2D
CNN

COVID-19, viral,
baterial and Pneu.
classification

499 Training /
132 Validation

90.7% (Senstivity)
91.1%(Specificity)

No

No

Li et al. [52]

2D-Resnet 50

COVID-19, viral/
baterial Pneu. and
normal classification

3920 Training/436
Testing

90.0% (Senstivity)
96.0%(Specificity)

No

No

Jin et al. [53]

2D Unet++ and
2D-CNN

COVID-19, viral,
baterial and Pneu.
classification

1136 Training /
282 Testing

97.4% (Senstivity)
92.2%(Specificity)

No

No

Song et al
[54].

2D-Resnet 50

COVID-19, baterial
Pneu. and normal
classification

164 Training/ 27
Validation/ 83
Testing

86.0% (Accuracy)

No

No

Xu et al. [55]

2D-CNN

Normal, Influenza-A
and viral/bacterial
Pneu. classification

528 Training / 90
Testing

86.7% (Accuracy)

No

No

Jin et al.[56]

2D-CNN

COVID-19, viral,
baterial and Pneu.
classification

312 Training/ 104
Validation/ 1255
Testing

94.1% (Senstivity)
95.5%(Specificity)

No

No

Wang et al.
[57]

2D-CNN

COVID-19 and viral
Pneu. classification

250 cases

82.9% (Accuracy)

No

No

Wang et al.
[58]

3D-ResNet +
attention

COVID-19, viral
Pneu. and normal
classification

3997 5-fold
validation / 60
validation/ 600
testing

93.3 %(Accuracy)
87.6% (Senstivity)
95.5%(Specificity)

No

No

Ours

Federated
Blockchain and
Capsule Network

COVID-19, viral
Pneu. and normal
classification

182 Training/ 45
Testing (patients
per hospital)

98.68%(Accuracy)
98% (Senstivity)

Yes

Yes

IV. R ELATED W ORK
A. AI in COVID-19
Artificial Intelligence (AI) based techniques have played
an essential role in the domain of medical image processing,
computer-aided diagnosis, image interpretation, image fusion,
image registration, image segmentation, image-guided therapy,
image retrieval, and analysis techniques. Artificial Intelligence
aids in extracting information from the images and represent
information effectively and efficiently. Artificial Intelligence
facilitates and assists doctors and other medical practitioners
to diagnose various diseases while eliminating human error

and increasing the speed and accuracy of detection. These
techniques enhance the abilities of doctors and researchers
to understand how to analyze the generic variations which
cause the disease in the first place. Deep learning is the
core technology of the rising artificial intelligence and has
reported significantly diagnostic accuracy in medical imaging
for automatic detection of lung diseases [59], [60], [61] .
Deep learning surpassed human- performance on the ImageNet
image classification task, with one million images for training
in 2015 [62], which showed dermatologist-level performance
on classifying skin lesions in 2017 [63] and obtained re-

13

9 5
9 0

C la s s ific a tio n a c c u ra c y (% )

8 5
8 0
7 5
7 0
6 5
6 0
5 5

H o s p ita l 1
H o s p ita l 2
H o s p ita l 3

5 0
4 5
4 0
0

1 0

2 0

3 0

4 0

5 0

6 0

7 0

8 0

N u m b e r o f ite ra tio n s

Fig. 11: The accuracy of dataset COVID-19 for different
providers.

markable results for lung cancer screening in 2019 [59].
Pneumonia can be diagnosed using Computed Tomography
(CT) scans of the chest of the subject. Artificial Intelligence
(AI) based automated CT image analysis tools for the detection, quantification, and monitoring of coronavirus and to
distinguish patients with coronavirus from disease-free have
been developed [6]. In a study by Fei et al., they developed
a deep learning-based system for automatic segmentation of
all lung and infection sites using chest CT [7]. Xiaowei et
al. aimed to establish an early screening model to distinguish
COVID-19 pneumonia and Influenza-A viral pneumonia from
healthy cases using pulmonary CT images and deep learning
techniques [24]. Shuai et al., their study was based on the
COVID-19 radiographic changes from CT images. They developed a deep learning method that can extract the graphical
features of COVID-19 to provide a clinical diagnosis before
pathogenic testing and thus save critical time for the disease
diagnosis. Recently, C. Zheng et al. [11] developed a deep
learning-based model for automatic COVID-19 detector using
3D CT volumes.
B. Federated Learning

2 .5

H o s p ita l 1
H o s p ita l 2
H o s p ita l 3

2 .0

L o ss

1 .5

1 .0

0 .5

0 .0
0

1 0

2 0

3 0

4 0

5 0

6 0

7 0

8 0

N u m b e r o f ite ra tio n s

Fig. 12: The Loss of dataset COVID-19 for different providers.

Federated learning was proposed by McMahan et al. [64]
to learn from the shared model while protecting the privacy of data. In this context, federated learning is used to
secure data and aggregates the parameters for the multiple
organizations[65], [66], [67], [68], [69]. The hospitals can
share the dataset during training and information about their
dataset is revealed through analyzing the distributed model
[70], [16], [71], [72], [73], [74], [75], [76], [77]. This decentralized approach to train models preserves privacy and security. A lot of research has been done in federated learning for
transferring the matrices of weights of deep neural networks.
The previous studies do not consider to share the medical
data without compromising the privacy of organizations[78],
[79]. In this article, we simulate our model to collect the
data from different sources using federated learning combined
with blockchain technology while sharing data without privacy
leakage.
V. C ONCLUSION

H o s p ita l 1
H o s p ita l 2
H o s p ita l 3

8 0

R u n n in g tim e (m in )

7 0
6 0
5 0
4 0
3 0
2 0
1 0
0
0

1 0

2 0

3 0

4 0

5 0

6 0

7 0

8 0

N u m b e r o f ite ra tio n s

Fig. 13: The time of dataset COVID-19 for different providers.

This paper proposed a framework that can utilize up-todate data to improve the recognition of computed tomography
(CT) images and share the data among hospitals while preserving privacy. The data normalization technique deals with
the heterogeneity of data. Further, Capsule Network based
segmentation and classification is used to detect COVID-19
patients along with a method that can collaboratively train
a global model using blockchain technology with federated
learning. Also, we collected real-life COVID-19 patients‚Äô data
and made it publically available to the research community.
Extensive experiments were performed on various deep learning models for training and testing the datasets. The Capsule
Network achieved the highest accuracy. The proposed model
is smart as it can learn from the shared sources or data
among various hospitals. Conclusively, the proposed model
can help in detecting COVID-19 patients using lung screening

14

as hospitals share their private data to train a global and better
model.
D ECLARATION OF C OMPETING I NTEREST
The authors report no declarations of interest.
ACKNOWLEDGEMENT
This work was supported by China Postdoctoral scine Science Foundation and Department of Science and Technology
of Sichuan Province , Project Number: Y03019023601016201,
H04W200533. Authors‚Äô contributions
R EFERENCES
[1] Coronavirus, ‚Äúhttps://coronavirus.jhu.edu/map.html,‚Äù 2020.
[2] M. Chung, A. Bernheim, X. Mei, N. Zhang, M. Huang, X. Zeng, J. Cui,
W. Xu, Y. Yang, Z. A. Fayad, A. Jacobi, K. Li, S. Li, and H. Shan, ‚ÄúCT
imaging features of 2019 novel coronavirus (2019-NCoV),‚Äù Radiology,
2020.
[3] C. Huang, Y. Wang, X. Li, L. Ren, J. Zhao, Y. Hu, L. Zhang, G. Fan,
J. Xu, X. Gu, Z. Cheng, T. Yu, J. Xia, Y. Wei, W. Wu, X. Xie, W. Yin,
H. Li, M. Liu, Y. Xiao, H. Gao, L. Guo, J. Xie, G. Wang, R. Jiang,
Z. Gao, Q. Jin, J. Wang, and B. Cao, ‚ÄúClinical features of patients
infected with 2019 novel coronavirus in Wuhan, China,‚Äù The Lancet,
2020.
[4] J. Choe, S. M. Lee, K. H. Do, G. Lee, J. G. Lee, S. M. Lee, and J. B.
Seo, ‚ÄúDeep Learning‚Äìbased Image Conversion of CT Reconstruction
Kernels Improves Radiomics Reproducibility for Pulmonary Nodules or
Masses,‚Äù Radiology, 2019.
[5] D. S. Kermany, M. Goldbaum, W. Cai, C. C. Valentim, H. Liang, S. L.
Baxter, A. McKeown, G. Yang, X. Wu, F. Yan, J. Dong, M. K. Prasadha,
J. Pei, M. Ting, J. Zhu, C. Li, S. Hewett, J. Dong, I. Ziyar, A. Shi,
R. Zhang, L. Zheng, R. Hou, W. Shi, X. Fu, Y. Duan, V. A. Huu, C. Wen,
E. D. Zhang, C. L. Zhang, O. Li, X. Wang, M. A. Singer, X. Sun, J. Xu,
A. Tafreshi, M. A. Lewis, H. Xia, and K. Zhang, ‚ÄúIdentifying Medical
Diagnoses and Treatable Diseases by Image-Based Deep Learning,‚Äù
Cell, 2018.
[6] M. Negassi, R. Suarez-Ibarrola, S. Hein, A. Miernik, and A. Reiterer,
‚ÄúApplication of artificial neural networks for automated analysis of
cystoscopic images: a review of the current status and future prospects,‚Äù
2020.
[7] V. Gulshan, L. Peng, M. Coram, M. C. Stumpe, D. Wu,
A. Narayanaswamy, S. Venugopalan, K. Widner, T. Madams, J. Cuadros,
R. Kim, R. Raman, P. C. Nelson, J. L. Mega, and D. R. Webster,
‚ÄúDevelopment and validation of a deep learning algorithm for detection
of diabetic retinopathy in retinal fundus photographs,‚Äù JAMA - Journal
of the American Medical Association, 2016.
[8] D. Wang, B. Hu, C. Hu, F. Zhu, X. Liu, J. Zhang, B. Wang, H. Xiang, Z. Cheng, Y. Xiong, Y. Zhao, Y. Li, X. Wang, and Z. Peng,
‚ÄúClinical Characteristics of 138 Hospitalized Patients with 2019 Novel
Coronavirus-Infected Pneumonia in Wuhan, China,‚Äù JAMA - Journal of
the American Medical Association, 2020.
[9] N. Chen, M. Zhou, X. Dong, J. Qu, F. Gong, Y. Han, Y. Qiu, J. Wang,
Y. Liu, Y. Wei, J. Xia, T. Yu, X. Zhang, and L. Zhang, ‚ÄúEpidemiological
and clinical characteristics of 99 cases of 2019 novel coronavirus
pneumonia in Wuhan, China: a descriptive study,‚Äù The Lancet, 2020.
[10] Q. Li, X. Guan, P. Wu, X. Wang, L. Zhou, Y. Tong, R. Ren, K. S. Leung,
E. H. Lau, J. Y. Wong, X. Xing, N. Xiang, Y. Wu, C. Li, Q. Chen, D. Li,
T. Liu, J. Zhao, M. Liu, W. Tu, C. Chen, L. Jin, R. Yang, Q. Wang,
S. Zhou, R. Wang, H. Liu, Y. Luo, Y. Liu, G. Shao, H. Li, Z. Tao,
Y. Yang, Z. Deng, B. Liu, Z. Ma, Y. Zhang, G. Shi, T. T. Lam, J. T.
Wu, G. F. Gao, B. J. Cowling, B. Yang, G. M. Leung, and Z. Feng,
‚ÄúEarly Transmission Dynamics in Wuhan, China, of Novel CoronavirusInfected Pneumonia,‚Äù The New England journal of medicine, 2020.
[11] C. Zheng, X. Deng, Q. Fu, Q. Zhou, J. Feng, H. Ma, W. Liu, and
X. Wang, ‚ÄúDeep Learning-based Detection for COVID-19 from Chest
CT using Weak Label,‚Äù medRxiv, 2020.
[12] A. Waheed, M. Goyal, D. Gupta, A. Khanna, F. Al-Turjman, and P. R.
Pinheiro, ‚ÄúCovidgan: Data augmentation using auxiliary classifier gan
for improved covid-19 detection,‚Äù IEEE Access, pp. 1‚Äì1, 2020.

[13] M. A. Azad, J. Arshad, S. M. A. Akmal, F. Riaz, S. Abdullah, M. Imran,
and F. Ahmad, ‚ÄúA first look at privacy analysis of covid-19 contact
tracing mobile applications,‚Äù IEEE Internet of Things Journal, pp. 1‚Äì1,
2020.
[14] H. Xu, L. Zhang, O. Onireti, Y. Fang, W. J. Buchanan, and M. A. Imran,
‚ÄúBeeptrace: Blockchain-enabled privacy-preserving contact tracing for
covid-19 pandemic and beyond,‚Äù IEEE Internet of Things Journal, pp.
1‚Äì1, 2020.
[15] T.-C. Chiu, Y.-Y. Shih, A.-C. Pang, C.-S. Wang, W. Weng, and C.-T.
Chou, ‚ÄúSemi-supervised distributed learning with non-iid data for aiot
service platform,‚Äù IEEE Internet of Things Journal, 2020.
[16] Y. Lu, X. Huang, Y. Dai, S. Maharjan, and Y. Zhang, ‚ÄúBlockchain
and Federated Learning for Privacy-Preserved Data Sharing in Industrial
IoT,‚Äù IEEE Transactions on Industrial Informatics, vol. 16, no. 6, pp.
4177‚Äì4186, 2020.
[17] J. Pang, Y. Huang, Z. Xie, Q. Han, and Z. Cai, ‚ÄúRealizing the
heterogeneity: A self-organized federated learning framework for iot,‚Äù
IEEE Internet of Things Journal, 2020.
[18] H. Sun, S. Li, F. R. Yu, Q. Qi, J. Wang, and J. Liao, ‚ÄúTowards
communication-efficient federated learning in the internet of things with
edge computing,‚Äù IEEE Internet of Things Journal, 2020.
[19] K. Yang, T. Jiang, Y. Shi, and Z. Ding, ‚ÄúFederated learning via overthe-air computation,‚Äù IEEE Transactions on Wireless Communications,
vol. 19, no. 3, pp. 2022‚Äì2035, 2020.
[20] Z. Zhou, S. Yang, L. J. Pu, and S. Yu, ‚ÄúCefl: Online admission control,
data scheduling and accuracy tuning for cost-efficient federated learning
across edge nodes,‚Äù IEEE Internet of Things Journal, 2020.
[21] G. Xu, H. Li, S. Liu, K. Yang, and X. Lin, ‚ÄúVerifynet: Secure and verifiable federated learning,‚Äù IEEE Transactions on Information Forensics
and Security, vol. 15, pp. 911‚Äì926, 2019.
[22] G. Xu, H. Li, Y. Dai, K. Yang, and X. Lin, ‚ÄúEnabling efficient and
geometric range query with access control over encrypted spatial data,‚Äù
IEEE Transactions on Information Forensics and Security, vol. 14, no. 4,
pp. 870‚Äì885, 2018.
[23] W. Zhang, ‚ÄúImaging changes of severe COVID-19 pneumonia in advanced stage,‚Äù 2020.
[24] T. Ai, Z. Yang, H. Hou, C. Zhan, C. Chen, W. Lv, Q. Tao, Z. Sun,
and L. Xia, ‚ÄúCorrelation of Chest CT and RT-PCR Testing in Coronavirus Disease 2019 (COVID-19) in China: A Report of 1014 Cases,‚Äù
Radiology, 2020.
[25] S. Sabour, N. Frosst, and G. E. Hinton, ‚ÄúDynamic routing between
capsules,‚Äù in Advances in Neural Information Processing Systems 30:
Annual Conference on Neural Information Processing Systems 2017, 4-9
December 2017, Long Beach, CA, USA, 2017, pp. 3856‚Äì3866.
[26] R. LaLonde and U. Bagci, ‚ÄúCapsules for object segmentation,‚Äù arXiv
preprint arXiv:1804.04241, 2018.
[27] Y. Wang, L. Huang, S. Jiang, Y. Wang, J. Zou, H. Fu, and S. Yang,
‚ÄúCapsule networks showed excellent performance in the classification
of herg blockers/nonblockers,‚Äù Frontiers in Pharmacology, vol. 10, p.
1631, 2020. [Online]. Available: https://www.frontiersin.org/article/10.
3389/fphar.2019.01631
[28] P. Maymounkov and D. MazieÃÄres, ‚ÄúKademlia: A peer-to-peer information system based on the XOR metric,‚Äù Lecture Notes in Computer
Science (including subseries Lecture Notes in Artificial Intelligence and
Lecture Notes in Bioinformatics), 2002.
[29] M. Rahimzadeh, A. Attar, and S. M. Sakhaei, ‚ÄúA fully automated
deep learning-based network for detecting covid-19 from a new and
large lung ct scan dataset,‚Äù medRxiv, 2020. [Online]. Available: https:
//www.medrxiv.org/content/early/2020/06/12/2020.06.08.20121541
[30] J. Zhao, Y. Zhang, X. He, and P. Xie, ‚ÄúCovid-ct-dataset: a ct scan dataset
about covid-19,‚Äù arXiv preprint arXiv:2003.13865, 2020.
[31] F. Bellemare, A. Jeanneret, and J. Couture, ‚ÄúSex differences in thoracic
dimensions and configuration,‚Äù American journal of respiratory and
critical care medicine, vol. 168, pp. 305‚Äì12, 09 2003.
[32] K. Simonyan and A. Zisserman, ‚ÄúVery deep convolutional networks
for large-scale image recognition,‚Äù in 3rd International Conference on
Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9,
2015, Conference Track Proceedings, Y. Bengio and Y. LeCun, Eds.,
2015.
[33] A. Krizhevsky, I. Sutskever, and G. E. Hinton, ‚ÄúImagenet classification
with deep convolutional neural networks,‚Äù in Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural
Information Processing Systems 2012. Proceedings of a meeting held
December 3-6, 2012, Lake Tahoe, Nevada, United States, P. L. Bartlett,
F. C. N. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds.,
2012, pp. 1106‚Äì1114.

15

[34] F. Chollet, ‚ÄúXception: Deep learning with depthwise separable convolutions,‚Äù in 2017 IEEE Conference on Computer Vision and Pattern
Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017. IEEE
Computer Society, 2017, pp. 1800‚Äì1807.
[35] K. He, X. Zhang, S. Ren, and J. Sun, ‚ÄúDeep residual learning for image
recognition,‚Äù CoRR, vol. abs/1512.03385, 2015.
[36] ‚Äî‚Äî, ‚ÄúIdentity mappings in deep residual networks,‚Äù in Computer
Vision - ECCV 2016 - 14th European Conference, Amsterdam, The
Netherlands, October 11-14, 2016, Proceedings, Part IV, ser. Lecture
Notes in Computer Science, vol. 9908. Springer, 2016, pp. 630‚Äì645.
[37] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna, ‚ÄúRethinking
the inception architecture for computer vision,‚Äù in 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las
Vegas, NV, USA, June 27-30, 2016. IEEE Computer Society, 2016, pp.
2818‚Äì2826.
[38] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand,
M. Andreetto, and H. Adam, ‚ÄúMobilenets: Efficient convolutional neural
networks for mobile vision applications,‚Äù CoRR, vol. abs/1704.04861,
2017.
[39] M. Sandler, A. G. Howard, M. Zhu, A. Zhmoginov, and L. Chen,
‚ÄúMobilenetv2: Inverted residuals and linear bottlenecks,‚Äù in 2018 IEEE
Conference on Computer Vision and Pattern Recognition, CVPR 2018,
Salt Lake City, UT, USA, June 18-22, 2018. IEEE Computer Society,
2018, pp. 4510‚Äì4520.
[40] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, ‚ÄúDensely
connected convolutional networks,‚Äù in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 4700‚Äì4708.
[41] A. Kuzdeuov, D. Baimukashev, A. Karabay, B. Ibragimov, A. Mirzakhmetov, M. Nurpeiissov, M. Lewis, and H. A. Varol, ‚ÄúA Network-Based
Stochastic Epidemic Simulator: Controlling COVID-19 with RegionSpecific Policies,‚Äù IEEE Journal of Biomedical and Health Informatics,
vol. 24, no. 10, pp. 2743‚Äì2754, 2020.
[42] L. Zhou, Z. Li, J. Zhou, H. Li, Y. Chen, Y. Huang, D. Xie, L. Zhao,
M. Fan, S. Hashmi, F. Abdelkareem, R. Eiada, X. Xiao, L. Li, Z. Qiu,
and X. Gao, ‚ÄúA Rapid, Accurate and Machine-Agnostic Segmentation
and Quantification Method for CT-Based COVID-19 Diagnosis,‚Äù IEEE
Transactions on Medical Imaging, vol. 39, no. 8, pp. 2638‚Äì2652, 2020.
[43] X. Wang, X. Deng, Q. Fu, Q. Zhou, J. Feng, H. Ma, W. Liu, and
C. Zheng, ‚ÄúA Weakly-Supervised Framework for COVID-19 Classification and Lesion Localization from Chest CT,‚Äù IEEE Transactions on
Medical Imaging, vol. 39, no. 8, pp. 2615‚Äì2625, 2020.
[44] L. Sun, Z. Mo, F. Yan, L. Xia, F. Shan, Z. Ding, W. Shao, F. Shi,
H. Yuan, H. Jiang, D. Wu, Y. Wei, Y. Gao, W. Gao, H. Sui, D. Zhang, and
D. Shen, ‚ÄúAdaptive Feature Selection Guided Deep Forest for COVID19 Classification with Chest CT,‚Äù arXiv, vol. 24, no. 10, pp. 2798‚Äì2805,
2020.
[45] R. M. Inciardi, L. Lupi, G. Zaccone, L. Italia, M. Raffo, D. Tomasoni,
D. S. Cani, M. Cerini, D. Farina, E. Gavazzi et al., ‚ÄúCardiac involvement
in a patient with coronavirus disease 2019 (covid-19),‚Äù JAMA cardiology,
2020.
[46] R. Kumar, W. Wang, J. Kumar, T. Yang, A. Khan, W. Ali, and I. Ali, ‚ÄúAn
integration of blockchain and ai for secure data sharing and detection
of ct images for the hospitals,‚Äù Computerized Medical Imaging and
Graphics, p. 101812, 2020.
[47] L. Kong, X.-Y. Liu, H. Sheng, P. Zeng, and G. Chen, ‚ÄúFederated tensor
mining for secure industrial internet of things,‚Äù IEEE Transactions on
Industrial Informatics, vol. 16, no. 3, pp. 2144‚Äì2153, 2019.
[48] Y. Lu, X. Huang, K. Zhang, S. Maharjan, and Y. Zhang, ‚ÄúBlockchain
empowered asynchronous federated learning for secure data sharing
in internet of vehicles,‚Äù IEEE Transactions on Vehicular Technology,
vol. 69, no. 4, pp. 4298‚Äì4311, 2020.
[49] J. Chen, L. Wu, J. Zhang, L. Zhang, D. Gong, Y. Zhao, S. Hu, Y. Wang,
X. Hu, B. Zheng et al., ‚ÄúDeep learning-based model for detecting 2019
novel coronavirus pneumonia on high-resolution computed tomography:
a prospective study,‚Äù MedRxiv, 2020.
[50] F. Shi, L. Xia, F. Shan, D. Wu, Y. Wei, H. Yuan, H. Jiang, Y. Gao, H. Sui,
and D. Shen, ‚ÄúLarge-scale screening of covid-19 from community
acquired pneumonia using infection size-aware classification,‚Äù arXiv
preprint arXiv:2003.09860, 2020.
[51] C. Zheng, X. Deng, Q. Fu, Q. Zhou, J. Feng, H. Ma, W. Liu, and
X. Wang, ‚ÄúDeep learning-based detection for covid-19 from chest ct
using weak label,‚Äù medRxiv, 2020.
[52] L. Li, L. Qin, Z. Xu, Y. Yin, X. Wang, B. Kong, J. Bai, Y. Lu, Z. Fang,
Q. Song et al., ‚ÄúUsing artificial intelligence to detect covid-19 and
community-acquired pneumonia based on pulmonary ct: evaluation of
the diagnostic accuracy,‚Äù Radiology, vol. 296, no. 2, 2020.

[53] S. Jin, B. Wang, H. Xu, C. Luo, L. Wei, W. Zhao, X. Hou, W. Ma,
Z. Xu, Z. Zheng et al., ‚ÄúAi-assisted ct imaging analysis for covid-19
screening: Building and deploying a medical ai system in four weeks,‚Äù
medRxiv, 2020.
[54] Y. Song, S. Zheng, L. Li, X. Zhang, X. Zhang, Z. Huang, J. Chen,
H. Zhao, Y. Jie, R. Wang et al., ‚ÄúDeep learning enables accurate
diagnosis of novel coronavirus (covid-19) with ct images,‚Äù medRxiv,
2020.
[55] X. Xu, X. Jiang, C. Ma, P. Du, X. Li, S. Lv, L. Yu, Q. Ni, Y. Chen,
J. Su et al., ‚ÄúA deep learning system to screen novel coronavirus disease
2019 pneumonia,‚Äù Engineering, 2020.
[56] C. Jin, W. Chen, Y. Cao, Z. Xu, X. Zhang, L. Deng, C. Zheng, J. Zhou,
H. Shi, and J. Feng, ‚ÄúDevelopment and evaluation of an ai system for
covid-19 diagnosis,‚Äù medRxiv, 2020.
[57] S. Wang, B. Kang, J. Ma, X. Zeng, M. Xiao, J. Guo, M. Cai, J. Yang,
Y. Li, X. Meng et al., ‚ÄúA deep learning algorithm using ct images to
screen for corona virus disease (covid-19),‚Äù MedRxiv, 2020.
[58] J. Wang, Y. Bao, Y. Wen, H. Lu, H. Luo, Y. Xiang, X. Li, C. Liu, and
D. Qian, ‚ÄúPrior-attention residual learning for more discriminative covid19 screening in ct images,‚Äù IEEE Transactions on Medical Imaging,
2020.
[59] D. Ardila, A. P. Kiraly, S. Bharadwaj, B. Choi, J. J. Reicher, L. Peng,
D. Tse, M. Etemadi, W. Ye, G. Corrado, D. P. Naidich, and S. Shetty,
‚ÄúEnd-to-end lung cancer screening with three-dimensional deep learning
on low-dose chest computed tomography,‚Äù 2019.
[60] K. Suzuki, ‚ÄúOverview of deep learning in medical imaging,‚Äù 2017.
[61] N. Coudray, P. S. Ocampo, T. Sakellaropoulos, N. Narula, M. Snuderl,
D. FenyoÃà, A. L. Moreira, N. Razavian, and A. Tsirigos, ‚ÄúClassification
and mutation prediction from non‚Äìsmall cell lung cancer histopathology
images using deep learning,‚Äù Nature Medicine, 2018.
[62] K. He, X. Zhang, S. Ren, and J. Sun, ‚ÄúDelving deep into rectifiers:
Surpassing human-level performance on imagenet classification,‚Äù in
Proceedings of the IEEE International Conference on Computer Vision,
2015.
[63] A. Esteva, B. Kuprel, R. A. Novoa, J. Ko, S. M. Swetter, H. M. Blau,
and S. Thrun, ‚ÄúDermatologist-level classification of skin cancer with
deep neural networks,‚Äù Nature, 2017.
[64] H. Brendan McMahan, E. Moore, D. Ramage, S. Hampson, and
B. AguÃàera y Arcas, ‚ÄúCommunication-efficient learning of deep networks
from decentralized data,‚Äù in Proceedings of the 20th International
Conference on Artificial Intelligence and Statistics, AISTATS 2017, 2017.
[65] X. Lu, Y. Liao, P. Lio, and P. Hui, ‚ÄúPrivacy-preserving asynchronous
federated learning mechanism for edge network computing,‚Äù IEEE
Access, vol. 8, pp. 48 970‚Äì48 981, 2020.
[66] M. Yan, B. Chen, G. Feng, and S. Qin, ‚ÄúFederated cooperation and
augmentation for power allocation in decentralized wireless networks,‚Äù
IEEE Access, vol. 8, pp. 48 088‚Äì48 100, 2020.
[67] D. Ye, R. Yu, M. Pan, and Z. Han, ‚ÄúFederated learning in vehicular
edge computing: A selective model aggregation approach,‚Äù IEEE Access,
vol. 8, pp. 23 920‚Äì23 935, 2020.
[68] N. I. Mowla, N. H. Tran, I. Doh, and K. Chae, ‚ÄúFederated learningbased cognitive detection of jamming attack in flying ad-hoc network,‚Äù
IEEE Access, 2019.
[69] B. Brik, A. Ksentini, and M. Bouaziz, ‚ÄúFederated learning for uavsenabled wireless networks: Use cases, challenges, and open problems,‚Äù
IEEE Access, vol. 8, pp. 53 841‚Äì53 849, 2020.
[70] B. McMahan and D. Ramage, ‚ÄúFederated Learning : Collaborative
Machine Learning without centralized training data,‚Äù Post, 2017.
[71] Y. Lu, X. Huang, K. Zhang, S. Maharjan, and Y. Zhang, ‚ÄúBlockchain
Empowered Asynchronous Federated Learning for Secure Data Sharing
in Internet of Vehicles,‚Äù IEEE Transactions on Vehicular Technology,
vol. 69, no. 4, pp. 4298‚Äì4311, 2020.
[72] B. Yin, H. Yin, Y. Wu, and Z. Jiang, ‚ÄúFDC: A Secure Federated Deep
Learning Mechanism for Data Collaborations in the Internet of Things,‚Äù
IEEE Internet of Things Journal, vol. 4662, no. c, pp. 1‚Äì1, 2020.
[73] W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y. C. Liang,
Q. Yang, D. Niyato, and C. Miao, ‚ÄúFederated Learning in Mobile Edge
Networks: A Comprehensive Survey,‚Äù IEEE Communications Surveys
and Tutorials, no. c, pp. 1‚Äì33, 2020.
[74] K.-Y. Lin and W.-R. Huang, ‚ÄúUsing Federated Learning on Malware
Classification,‚Äù 2020 22nd International Conference on Advanced Communication Technology (ICACT), pp. 585‚Äì589, 2020.
[75] K. Yang, T. Jiang, Y. Shi, and Z. Ding, ‚ÄúFederated learning via overthe-air computation,‚Äù IEEE Transactions on Wireless Communications,
vol. 19, no. 3, pp. 2022‚Äì2035, 2020.

16

[76] Y. J. Kim and C. S. Hong, ‚ÄúBlockchain-based Node-aware Dynamic
Weighting Methods for Improving Federated Learning Performance,‚Äù
2019 20th Asia-Pacific Network Operations and Management Symposium: Management in a Cyber-Physical World, APNOMS 2019, pp. 1‚Äì4,
2019.
[77] Q. Yang, Y. Liu, T. Chen, and Y. Tong, ‚ÄúFederated machine learning:
Concept and applications,‚Äù ACM Transactions on Intelligent Systems and
Technology, vol. 10, no. 2, pp. 1‚Äì19, 2019.
[78] T. Li, A. K. Sahu, A. Talwalkar, and V. Smith, ‚ÄúFederated Learning:
Challenges, Methods, and Future Directions,‚Äù pp. 1‚Äì21, 2019. [Online].
Available: http://arxiv.org/abs/1908.07873
[79] Q. Li, Z. Wen, Z. Wu, S. Hu, N. Wang, and B. He, ‚ÄúA Survey
on Federated Learning Systems: Vision, Hype and Reality for
Data Privacy and Protection,‚Äù pp. 1‚Äì41, 2019. [Online]. Available:
http://arxiv.org/abs/1907.09693

Rajesh Kumar was born in Sindh Province of
Pakistan in November 1991. He received his B.S.
and M.S. degree in computer science from University of Sindh, Jamshoro, Pakistan. He received
his Ph.D. in computer science and engineering from
the University of Electronic Science and Technology
of China (UESTC). He has currently pursing Post
Doctor in Information Security at the University of
Electronic Science and Technology of China. His
research interests include machine learning, deep
leaning, malware detection, Internet of Things (IoT)
and blockchain technology. In addition, he has published more than 20 articles
in various International journals and conference proceedings.

Abdullah Aman Khan Khan received his master‚Äôs degree in the field of Computer Engineering
from National University of Science and Technology
(NUST), Punjab, Pakistan in 2014. He is currently
perusing PhD degree in the field of Computer Science and Technology form the school of computer
science and engineering, University of Electronic
Science and Technology, Sichuan, Chengdu, P.R.
China. His main area of research includes electronics
design, machine vision and intelligent systems.

Simin Zhang received her Master‚Äôs degree in
Sichuan University, China. Currently, she is pursuing
her Ph.D. in Medical imaging and nuclear medicine
from West China Hospital of Sichuan University.
Her research interests include machine learning and
multi-model MRI applied to glioma.

Jay Kumar received his Master‚Äôs degree in Computer Science from Quaid-i-Azam University, Pakistan. Currently, he is pursuing his Ph.D. in computer
science and engineering from the University of Electronic Science and Technology of China (UESTC).
His research interests include text classification and
subspace clustering in stream mining applied to
various domains.

Professor Ting Yang He obtained Bachelor Degree
of communication engineering from UESTC; He
obtained Master Degree from School of Computer
Science and Engineering of UESTC, His Ph.D. in
electronics engineering from the University of Electronic Science and Technology of China (UESTC).
His research interests include computer network architecture, software defined networking, and Internet
of Things (IoT).

Noorbakhsh Amiri Golilarz received the M.Sc. degree from Eastern Mediterranean University, Cyprus,
in 2017. He is currently pursuing the Ph.D. degree
with the School of Computer Science and Engineering, University of Electronic Science and Technology of China (UESTC). His main research interests include image processing, satellite and hyperspectral image de-noising, biomedical, signal processing, optimization algorithms, control, systems,
pattern recognition, neural networks, and deep learning.

Zakria received the M.S. degree in Computer Science and Information from N.E.D University in
2017. He is currently pursuing the Ph.D. degree with
the School of Information and Software Engineering,
University of Electronic Science and Technology
of China. He has a vast academic, technical, and
professional experience in Pakistan. His research interests include artificial intelligence, computer vision
particularly vehicle re-identification

Professor Wenyong Wang was born in 1967. Currently, He is working as a professor of Computer
Science at University of Electronic Science and
Technology of China (UESTC). He holds a B.E. in
Computer Science from Beijing University of Aeronautics and Astronautics, Beijing, China, an M.E. in
Computer Science and a Ph.D. in Communications
Engineering from UESTC. His research interests
include computer network architecture, software defined networking, and Internet of Things (IoT).

