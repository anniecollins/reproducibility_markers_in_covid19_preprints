arXiv:2105.08848v1 [math.OC] 18 May 2021

Optimal Control of the SIR Model with
Constrained Policy, with an Application to
COVID-19
Yujia Ding, Henry Schellhorn
May 20, 2021
Abstract
This article considers the optimal control of the SIR model with both
transmission and treatment uncertainty. It follows the model presented
in Gatto and Schellhorn (2021). We make four significant improvements
on the latter paper. First, we prove the existence of a solution to the
model. Second, our interpretation of the control is more realistic: while
in Gatto and Schellhorn the control Î± is the proportion of the population
that takes a basic dose of treatment, so that Î± > 1 occurs only if some patients take more than a basic dose, in our paper, Î± is constrained between
zero and one, and represents thus the proportion of the population undergoing treatment. Third, we provide a complete solution for the moderate
infection regime (with constant treatment). Finally, we give a thorough
interpretation of the control in the moderate infection regime, while Gatto
and Schellhorn focussed on the interpretation of the low infection regime.
Finally, we compare the efficiency of our control to curb the COVID-19
epidemic to other types of control.

1

Introduction

This article extends the analysis of the model presented in Gatto and Schellhorn
(2021).We make four significant improvements on the latter paper. First, we
prove existence of a solution. Second, In Gatto and Schellhorn (2021) the optimal control Î± has the interpretation of the proportion of the population that
takes a basic dose of treatment, so that Î± > 1 occurs only if a proportion of
the population takes more than a basic dose of treatment. In the low infection
regime part of our paper, Î± is constrained to be between zero and one, and represents thus the proportion of the population undergoing treatment. The latter
interpretation is much more realistic, as it is uncommon to ration treatment.
Third, we provide a complete solution for the moderate infection regime (with
constant treatment). The final improvement is a thorough numerical analysis and sensitivity analysis of the moderate infection regime, while Gatto and
Schellhorn (2021) focused exclusively on the interpretation of the control in the
1

low infection regime. This enables us to discover some errors in the secondorder term of the solution in Gatto and Schellhorn (2021), which we correct
here. Finally, we compare the efficiency of our control to curb the COVID-19
pandemic to other types of control. While our solution is complex, it allows to
satisfy the objective better. Also, our analytical solutions allow for an intuitive
understanding of the optimal control compared to a purely numerical solution.
The structure of the article is as follows. In section 2 we briefly introduce
the model in Gatto and Schellhorn (2021), and provide a proof of existence of
the solution. In section 3, we show our results for the low infection regime. In
section 4, we extend and analyze the solution in the moderate infection regime.
Section 5 shows our experimental results when applying our methodology to the
COVID-19 in the US in 2020. We draw the conclusion in Section 6. We refer the
reader to our earlier paper, Gatto and Schellhorn (2021) for a literature review.

2

A Stochastic SIR Model with Treatment Uncertainty

Let S, I, R be the proportions of susceptible, infected, and out of infection
(recovered, and dead), respectively. Let Î² be the transmission rate and Âµ be
the death rate.
In the SIR model, the rate of decrease dS
dt of the proportion of susceptible is
equal to the constant transmission
rate
Î²
time
SI. As in Gatto and Schellhorn
âˆš
dB1
1
(2021), we add a term ÏƒS SI dB
,
where
is
white noise, in order to model
dt
dt
the error in the transmission rate:
âˆš dB1
dS
= âˆ’Î²SI + ÏƒS SI
dt
dt
The optimal policy Î± is the proportion of the infected population that received treatement, thus Î±(t) âˆˆ [0, 1]. The presence of this constraint is an
important addition to the model in Gatto and Schellhorn (2021). Depending
whether the individual is treated or not, there are then four different ways for
an infected individual to exit the pool of infected:
â€¢
â€¢
â€¢
â€¢

not treated and recover
not treated and die
treated and recover
treated and died.

Thus, the â€out of infection rateâ€ will be:
dR(t)
= (1 âˆ’ Î±(t))I(t)K0 + (1 âˆ’ Î±(t))I(t)Âµ0 + Î±(t)I(t)K1 (t)
|
{z
}
|
{z
}
|
{z
}
dt
not treated and recover

+ Î±(t)I(t)Âµ1 âˆ’
| {z }
treated and die

not treated and die

dB2
Î±(t)I(t)Ïƒ
|
{z dt }

treated and recover

treatment measurement error

2

(1)

For simplicity, we assume that the Brownian motion driving transmission
uncertainty (B1 ) is independent from the Brownian motion driving treatment
uncertainty (B2 ). We suppose that Âµ0 â‰¥ Âµ1 (people die faster without treatment
than with treatment), but the reader will not lose any intuition by supposing
that Âµ0 = Âµ1 . Most of the time K1 (t) > K0 (treatment is better than no treatment), but not necessarily. We relax this requirement somewhat by requiring:
P (K0 < K1 (t)) is close to one

(2)

We model the treatment rate as an Ornstein-Uhlenbeck process:
dK1 (t) = Î»k (kÌ„1 âˆ’ K1 (t))dt + Ïƒk dB2 (t)
with the mean-reversion rate Î»k > 0 and the long run value of the treatment
rate kÌ„1 . It is well-known that K1 is Gaussian, with variance equal to:
Var[K1 (t)] =

Ïƒk2
(1 âˆ’ eâˆ’2Î»k t )
2Î»k

Thus, if mean-reversion is large compared to volatility Ïƒk , constraint (2) is
satisfied. We simplify (1) by:
dR(t)
dt

I(t)

= K0 + Âµ0 + Î±(t)(âˆ’K0 + K1 (t) âˆ’ Âµ0 + Âµ1 ) âˆ’ Î±(t)Ïƒ

dB2
dt

Putting everything together, the dynamics of the infected is:
p
dR(t)
dB1
dI(t)
= Î²S(t)I(t) âˆ’
âˆ’ ÏƒS S(t)I(t)
dt
dt
dt
We try to minimize a measure of the infected over our horizon T . To model
risk-aversion to unfavorable treatment decisions, the decision-maker is supposed
to minimize the expected value of a convex and increasing function of I(T ).
Alternately, one can maximize the negative thereof, i.e., maximize the expected
value of a concave and decreasing function of I(T ). Such a function U is called
a utility function in financial economics. The policy obtained in maximizing
the expected value of a concave utility function can be showed, under certain
conditions, to maximize the expected value of the outcome (here âˆ’I) under a
constraint on the dispersion of the outcome. Out of the universe of concave
decreasing utility functions, we choose the power utility function:
U (I) = âˆ’

I 1âˆ’Î³
1âˆ’Î³

The coefficient Î³ is often called the risk-aversion parameter. When Î³ = 0
the decision-maker is risk-neutral, meaning that the uncertainty does not have
an influence on her decisions. It is straightforward to check that this power
utility function is concave in I when Î³ < 0,which we will assume. Taking for
instance Î³ = âˆ’1, we see that the objective is to
 I2 
max E âˆ’
2
3

which returns the same policy as:
 I2 
min E
2
The importance of analytic formulations is that other figures of interest in
this model, like the expected number of deaths from treatment can be analytically calculated, and depend on Î³. Thus, a decision-maker can calibrate its
risk-aversion parameter Î³ on other goals. Expected number of deaths is only
one type of goal and economic factors that can be easily added. We define
Ï„ = min{t > 0|I(t) â‰¤ 0 or I(t) â‰¥ 1}
Our controlled SIR model is thus:
 I(min(Ï„, T ))1âˆ’Î³ 
E âˆ’
1âˆ’Î³
0â‰¤Î±(t)â‰¤1
p
dS(t) = âˆ’Î²S(t)I(t)dt + ÏƒS S(t)I(t)dB1 (t)
sup

(3)

dI(t) = (Î²S(t) âˆ’ (K0 + Âµ0 ) + Î±(t)(K0 âˆ’ K1 (t) + Âµ0 âˆ’ Âµ1 )) I(t)dt
p
+ Î±(t)I(t)ÏƒdB2 (t) âˆ’ ÏƒS S(t)I(t)dB1 (t)
(4)
dK(t) = Î»k (KÌ„ âˆ’ K(t))dt + Ïƒk dB2 (t)

(5)

The relative sign of our volatilities Ïƒ and Ïƒk is important. We will assume
without loss of generality that Ïƒ < 0. The sign of Ïƒk is the sign of covariance
between the measured value of todayâ€™s treatment rate and the change in value
of the treatment rate between today and a future date. An example may help
illustrate the difference. Suppose that over a week one performs daily measurements of the treatment recovery rate as well as daily forecasts of the evolution
of the treatment recovery rate over the next day. The two quantities measured
each day t are proportional to the same white noise B2 (t+1 day) âˆ’ B2 (t). One
then calculates weekly estimates ÏƒÌ‚ of Ïƒ and ÏƒÌ‚k of Ïƒk over these 7 daily observations. Since we arbitrarily choose Ïƒ > 0, a positive ÏƒÌ‚k shows a correlation of +1
between the measurement (of todayâ€™s treatment rate) and the forecast. Figure
1 is a depiction of our model.
Theorem 1. For any given intial value (S(0), I(0), R(0)) and any X(0) there
exists a unique solution of (3)(4)(5) up to time Ï„ .
The proof of Theorem 1, included in Appendix A, follows the proof of a
theorem of Yamada and Watanabe (1971), as exposed in the book by Karatzas
and Shreve (2014, Prop. 2.13, Sec. 5.2).

3

Results in the Low Infection Regime

We assume S(t) close to one and ÏƒS = 0. Thus the term:
r = Î²S(t) âˆ’ (K0 + Âµ0 ) ' Î² âˆ’ K0 âˆ’ Âµ0
4

Figure 1: A stochastic SIR model
is assumed constant. With this simplification, we give an analytical solution
to the constrained problem, i.e., the case where 0 â‰¤ Î±(t) â‰¤ 1, a significant
improvement over Gatto and Schellhorn, who considered the unconstrained case.
We define the impact of treatment risk X:
X(t) =

K0 + Âµ0 âˆ’ Âµ1 âˆ’ K1 (t)
Ïƒ

as well as the long run impact of the treatment risk XÌ„:
XÌ„ =

K0 + Âµ0 âˆ’ Âµ1 âˆ’ kÌ„1
Ïƒ

We define Î»x = Î»k and Ïƒx = Ïƒk /Ïƒ. For simplicity we write Âµ = K0 + Âµ0 .
We consider first the case where the treatment rate is constant, and then the
case where it follows an Ornstein Uhlenbeck process.

3.1

Constant Treatment Rate

Let b = Î² âˆ’ Âµ1 âˆ’ kÌ„1 . The problem is:

5

 I(T )1âˆ’Î³ 
E âˆ’
1âˆ’Î³
0â‰¤Î±(t)â‰¤1
sup

(6)

dI(t) = (r + Î±(t)(b âˆ’ r))I(t)dt + Î±(t)ÏƒI(t)dB2 (t)
Theorem 2. The optimal control is constant, and satisfies

kÌ„1 âˆ’ K0 
Î± = min 1, max 0,
Ïƒ 2 |Î³|
The proof is the Appendix B, and follows closely CvitanicÌ and Karatzas
(1992).

3.2

Treatment Rate as Ornstein-Uhlenbeck Process

The problem is
 I(T )1âˆ’Î³ 
sup E âˆ’
1âˆ’Î³
dI(t) = (r + Î±(t)ÏƒX(t))I(t)dt + Î±(t)ÏƒI(t)dB2 (t)

(7)

dX(t) = Î»x (XÌ„ âˆ’ X(t))dt âˆ’ Ïƒx dB2 (t)
In the low infection regime our solution will depend on a kernel H0 (Xt , Ï„ )
with Ï„ = T âˆ’ t, while in the moderate infection regime it will also depend on
two other kernels H1 (Xt , Ï„ ) and H2 (Xt , Ï„ ) that are closely related. In order to
unify notation we define the kernels. Define
 

1 A1 (Ï„, Î³)Xt2
H0 (Xt , Ï„ ) = exp
+ A2 (Ï„, Î³)Xt + A3 (Ï„, Î³) + (1 âˆ’ Î³)(Âµ + r)Ï„
Î³
2
(8)
and, for i > 0
 

i A1 (Ï„, Î³/i)Xt2
Hi (Xt , Ï„ ) = exp
+ A2 (Ï„, Î³/i)Xt + A3 (Ï„, Î³/i)
(9)
Î³
2
where
A1 (Ï„, Î³) =

2(1 âˆ’ exp(âˆ’Î¸(Î³)Ï„ ))
1âˆ’Î³
Î³ 2Î¸(Î³) âˆ’ (b2 (Î³) + Î¸(Î³))(1 âˆ’ exp(âˆ’Î¸(Î³)Ï„ ))
2

(10)

4Î»x XÌ„b1 (Î³) (1 âˆ’ exp (âˆ’Î¸(Î³)Ï„ /2))
(11)
Î¸(Î³) (2Î¸(Î³) âˆ’ (Î¸(Î³) + b2 (Î³))(1 âˆ’ exp(âˆ’Î¸(Î³)Ï„ )))

Z Ï„ 2
Ïƒx
Ïƒ2
A3 (Ï„, Î³) =
+ Î»x XÌ„ A22 (s, Î³) + x A1 (s, Î³) + (Î³ âˆ’ 1)Âµds (12)
2Î³
2
0

1âˆ’Î³
Ïƒ2
Î³âˆ’1
b1 (Î³) =
b2 (Î³) = 2
Ïƒx âˆ’ Î» x
b3 (Î³) = x
Î³
Î³
Î³
q
Î¸(Î³) = b22 (Î³) âˆ’ 4b1 (Î³)b3 (Î³)
A2 (Ï„, Î³) =

6

We provide an explicit formula for A3 (Ï„, Î³) in Appendix C. The solution to
(7) is shown in Gatto and Schellhorn (2021, Prop. 1), but with some typos in
the expression of H0 (Xt , Ï„ ), hence we correct the mistake by providing (8) in
this paper.

4

Results in the Moderate Infection Regime

We first handle the Ornstein-Uhlenbeck treatment rate case, which was presented in Gatto and Schellhorn (2021, Prop. 2). In this work, we aim to correct
the typos and provide more detials for the Proposition 2 in Gatto and Schellhorn
(2021).

4.1

Treatment Rate as Ornstein-Uhlenbeck Process

The problem is defined in Section 2. We rewrite here for convenience,
 I(min(Ï„, T ))1âˆ’Î³ 
sup E âˆ’
1âˆ’Î³
p
dS(t) = âˆ’Î²S(t)I(t)dt + ÏƒS S(t)I(t)dB1 (t)
dI(t) = (Î²S(t) âˆ’ Âµ + Î±(t)ÏƒX(t)) I(t)dt + Î±(t)I(t)ÏƒdB2 (t)
p
âˆ’ ÏƒS S(t)I(t)dB1 (t)

(13)

dX(t) = Î»x (XÌ„ âˆ’ X(t))dt âˆ’ Ïƒx dB2 (t)
To express the solution of (13), we further define
1

2Î¸(Î³)e 2 (b2 (Î³/2)âˆ’b2 (Î³)âˆ’Î¸(Î³))(Ï„ âˆ’t)

MÌƒ (t, Ï„ ) =
2Î¸(Î³) âˆ’ (b2 (Î³) + Î¸(Î³)) 1 âˆ’ eâˆ’Î¸(Î³)(Ï„ âˆ’t)
Z Ï„
Ïƒ2
mY (Ï„, x) = xMÌƒ (t, Ï„ ) +
MÌƒ (s, Ï„ )(Î»x XÌ„ + Î³x A2 (Ï„ âˆ’ s, Î³))ds

(14)

s=t

A2 (T âˆ’ Ï„, Î³)
+
A1 (T âˆ’ Ï„, Î³)
Z Ï„
VY (Ï„, x) = Ïƒx2
MÌƒ 2 (s, Ï„ )ds
t

Z

T

H2 (X, Ï„ âˆ’ t)

g(X, t) =
Ï„ =t

Ã— exp

1 Î²2
1
p
2
2 ÏƒS Î³ 1 âˆ’ 2VY (Ï„, X)A1 (T âˆ’ Ï„, Î³)/Î³

A22 (T âˆ’ Ï„, Î³)
Î³
Î³A1 (T âˆ’ Ï„, Î³)
2
mY (Ï„, X)A1 (T âˆ’ Ï„, Î³) 
+
dÏ„
Î³ âˆ’ 2VY (Ï„, X)A1 (T âˆ’ Ï„, Î³)

2

A3 (T âˆ’ Ï„, Î³) âˆ’

7

(15)

From this, we can calculate:
Z T
âˆ‚g
1 Î²2
1
=
H2 (X, Ï„ âˆ’ t) 2 p
âˆ‚X
2 ÏƒS Î³ 1 âˆ’ 2VY (Ï„, X)A1 (T âˆ’ Ï„, Î³)/Î³
Ï„ =t


2
A2 (T âˆ’ Ï„, Î³)
m2Y (Ï„, X)A1 (T âˆ’ Ï„, Î³)
Ã— exp
A3 (T âˆ’ Ï„, Î³) âˆ’ 2
+
Î³
Î³A1 (T âˆ’ Ï„, Î³) Î³ âˆ’ 2VY (Ï„, X)A1 (T âˆ’ Ï„, Î³)
 A (Ï„ âˆ’ t, Î³/2)X(t) + A (Ï„ âˆ’ t, Î³/2)
1
2
Ã—
Î³/2

2mY (Ï„, X)A1 (T âˆ’ Ï„, Î³)
+
MÌƒ (t, Ï„ ) dÏ„
Î³ âˆ’ 2VY (Ï„, X)A1 (T âˆ’ Ï„, Î³)
Theorem 3. Let I(0) = Îµ. Suppose I(t) â‰¤ 1. If Ïƒx < 0 then the problem (13)
has a solution such that
I(t) = ÎµZ 1/Î³ (t)H1 (X(t), T âˆ’ t) + Îµ2 Z 2/Î³ (t)S(t)g(X(t), t) + O(Îµ3 )
where Z(t) satisfies:
âˆš
Î² 2 SI
Î² SI
dZ
2
= (âˆ’Âµ + X +
)dt âˆ’
dB1 + XdB2
Z
ÏƒS2
ÏƒS
!Î³
p
âˆ’H1 (X(0), T ) + H12 (X(0), T ) âˆ’ 4ÎµS(0)g(X(0), 0)(O(Îµ2 ) âˆ’ 1)
Z(0) =
2ÎµS(0)g(X(0), 0)
The optimal control Î±âˆ— (t) = Î±0 (t) + ÎµÎ±1 (t) + O(Îµ2 ) where:
X(t)
Ïƒx
âˆ’
(A1 (T âˆ’ t, Î³)X(t) + A2 (T âˆ’ t, Î³))
Î³Ïƒ
Î³Ïƒ
Z 1/Î³ (t)S(t)  g(X(t), t)X(t)
âˆ‚g
Î±1 (t) =
âˆ’ Ïƒx
H1 (X(t), T âˆ’ t)Ïƒ
Î³
âˆ‚X

g(X(t), t)
+Ïƒx
(A1 (T âˆ’ t, Î³)X(t) + A2 (T âˆ’ t, Î³))
Î³
Î±0 (t) =

The proof is in Appendix D. We refer to Gatto and Schellhorn (2021) for a
discussion of Î±0 . The sign of Î±1 is determined by the signs of Ïƒ and

g(X(t), t) 
âˆ‚g
X(t) + Ïƒx (A1 (T âˆ’ t, Î³)X(t) + A2 (T âˆ’ t, Î³)) âˆ’ Ïƒx
(16)
Î³
âˆ‚X
More specifically, Î±1 is positive if Ïƒ and (16) are both positive or negative. Î±1
is negative if one of them is positive and the other one is negative.
âˆ‚g
It is obvious that the magnitude of both g(X(t), t) and âˆ‚X
decrease with time
and are equal to zero when t = T . Therefore, the importance of Î±1 decreases
as time increases.
To further discuss the sign of (16), we rewrite it by


Ïƒx A2 (T âˆ’ t, Î³)
âˆ‚g
g(X(t), t)
(1 + |Ïƒx A1 (T âˆ’ t, Î³)|) X(t) + XÌ„
+ |Ïƒx |
Î³
âˆ‚X
XÌ„
8

âˆ‚g
Thus, suppose âˆ‚X
, X(t), and XÌ„ are all positive, (16) is positive, and vice versa.
In the following cases, we provide two simple cases that we can easily discuss
the sign of Î±1 :

â€¢ if

âˆ‚g
âˆ‚X Ïƒ

> 0, Âµ âˆ’ Âµ1 > max(K1 (t), kÌ„1 ), then Î±1 is positive.

â€¢ if

âˆ‚g
âˆ‚X Ïƒ

< 0, Âµ âˆ’ Âµ1 < min(K1 (t), kÌ„1 ), then Î±1 is negative.

In the following, we discuss the full expansion of the solution in Theorem 3.
Consider equation (57) in Gatto and Schellhorn (2021):
âˆ‚

+ L1 + ÎµL2 f = 0
âˆ‚t
This time we use full asymptotic expansion:
f = f1 + Îµf2 + . . . =

âˆ
X

fi Îµiâˆ’1

i=1

and obtain:
0

âˆ 


âˆ‚

X
âˆ‚
+ L1 f1 +
+ L1 fi+1 + L2 fi Îµi
âˆ‚t
âˆ‚t
i=1

=

The terms of our asymptotic expansion are thus determined by:

âˆ‚
+ L1 f1 = 0
âˆ‚t
âˆ‚

+ L1 fi+1 = âˆ’L2 fi
i = 1, 2, . . .
âˆ‚t

(17)
(18)

We use the Ansatz:
fi (Z(t), X(t), t) = Z(t)2

iâˆ’1

/Î³

iâˆ’1

S(t)2

âˆ’1

gi (X(t), t)

i = 1, 2, . . .

We have showed that g1 = H1 and g2 = g in the proof of Theorem 3. By the
same process, we can also calculate the expressions for g3 , g4 , . . . in the sequel.

4.2

Constant Treatment Rate

The problem is:
 I(T )1âˆ’Î³ 
sup E âˆ’
1âˆ’Î³
p
dS(t) = âˆ’Î²S(t)I(t)dt + ÏƒS S(t)I(t)dB1 (t)
dI(t) = (r + Î±(t)(b âˆ’ r))I(t)dt + Î±(t)ÏƒI(t)dB2 (t) âˆ’ ÏƒS

(19)
p

S(t)I(t)dB1 (t)

Let Ï„ = T âˆ’ t, the solution kernels hi (Ï„ ) for i = 1, 2, . . . are given by:
hi (Ï„ ) = exp

 2iâˆ’1  a

i,1

Î³

2
9

 
b âˆ’ r 2
+ ai,2 Ï„
Ïƒ

(20)

where
ai,1

=

1 âˆ’ Î³/2iâˆ’1
Î³/2iâˆ’1

(21)

ai,2

=

(Î³/2iâˆ’1 âˆ’ 1)Âµ

(22)

Theorem 4. Let I(0) = Îµ, then the problem (19) has a solution such that
I(t) =

âˆ
X

iâˆ’1

Z(t)2

/Î³

iâˆ’1

S(t)2

âˆ’1

gi (t)Îµi

i=1

where g1 (t) = h1 (T âˆ’ t), gi (t), i > 1 can be obtained by (44), and Z(t) satisfies:
âˆš

b âˆ’ r 2 Î² 2 SI 
Î² SI
bâˆ’r
dZ
= âˆ’Âµ+
+
dt âˆ’
dB2
dB1 +
Z
Ïƒ
ÏƒS2
ÏƒS
Ïƒ
âˆ
X
iâˆ’1
iâˆ’1
Z(0)2 /Î³ S(0)2 âˆ’1 gi (0)Îµiâˆ’1
1=
i=1

Moreover the optimal proportion undergoing treatment Î±âˆ— (t) equal to Î±0 (t) +
ÎµÎ±1 (t) + O(Îµ2 ), where Î±0 (t) and Î±1 (t) are equal to
Î±0 =

bâˆ’r
Î³Ïƒ 2

Î±1 =

Z 1/Î³ (t)S(t) b âˆ’ r
h1 (T âˆ’ t)g2 (t) Î³Ïƒ 2

The proof is in Appendix E, where we also provide a formula for g3 . Observe
that
g2 (t) =

Î²2
2ÏƒS2

h2 (T

bâˆ’r 2
(a1,1
Ïƒ

âˆ’ t) âˆ’ h21 (T âˆ’ t)
âˆ’ a2,1 ) + 2(a1,2 âˆ’ a2,2 )

=

Î² 2 h2 (T âˆ’ t) âˆ’ h21 (T âˆ’ t)
2
2ÏƒS2
Î³Âµ âˆ’ bâˆ’r
/Î³
Ïƒ

is always positive because the signs of h2 (T âˆ’ t) âˆ’ h21 (T âˆ’ t) and Î³Âµ âˆ’ bâˆ’r
Ïƒ
are the same. The signs of Î±0 and Î±1 are determined by the sign of râˆ’b
Ïƒ2 .

5

2

/Î³

Application to COVID-19

We use the same data set and parameters (see Table 1) as in Gatto and Schellhorn (2021), but this time we show the optimal control (result of Theorem 2)
of problem (6). We compare in Figure 2 three types of treatment:
â€¢ no treatment
â€¢ full control, i.e., Î±(t) = 1
â€¢ optimal control, given in Theorem 2
We can see that, for all risk-aversion parameters Î³ considered (between âˆ’1 and
âˆ’5), our control is better.
10

Treatment Parameter
Death rate/no treatment
Death rate
Recovery rate/ no treatment
Recovery rate at time 0
Long run value of recovery rate
Volatility of the measurement of todayâ€™s recovery rate
Volatility of changes in the recovery rate
Speed of mean-reversion of the recovery rate
Transmission rate
Proportion of infected at time 0
Time step

Symbol
Âµ0
Âµ1
K0
K1 (0)
kÌ„1
Ïƒ
Ïƒk
Î»k
Î²
Îµ
âˆ†t

Value
0.0575
0.0575
0.2559
0.2559
0.4612
0.4418
-1.1647
0.7692
0.025
0.01
0.001

Table 1: Parameters

Figure 2: Optimal control of low infection with constant treatment. Weekly US
COVID-19 data from June 7, 2020 to November 1, 2020. Github repository for
generating the plot: https://github.com/yujiading/optimal-control-sir-model.

11

6

Conclusion

We showed that a stochastic optimal control approach enables to fight the
COVID-19 epidemic better. Many interesting problems remain to be solved.
For instance, we could analytic constrained policies in the multiple treatment
case or the Ornstein-Uhlenbeck case. Optimal vaccination is another area where
we believe a similar asymptotic approach can be used. Finally, Bertozzi et al.
(2020) use Hawkes processes to model COVID-19. The control of Hawkes processes remains a largely open problem that deserves attention, in particular for
its application to epidemiology.

Appendix A

Proof of Theorem 1

We follow the proof in Karatzas and Shreve (2014, Prop. 2.13, Sec. 5.2). They
consider the one-dimensional case. Let h : [0, âˆ) â†’ [0, âˆ) be a strictly increasing function with h(0) and
Z
hâˆ’2 (u) = âˆ, âˆ€Îµ > 0
(23)
(0,Îµ)

In our case, we take h(x) = x. Because of (23), there exists a strictly
decreasing
Ra
sequence {an } âŠ‚ (0, 1] with a0 and limnâ†’âˆ an = 0 such that annâˆ’1 hâˆ’2 (u)du =
n. For every n there exists continuous function Ïn on R with support on
(an , anâˆ’1 ) so that
2
, x>0
0 â‰¤ Ïn (x) â‰¤
nh(x)
R an
and anâˆ’1
Ïn (u)du = 1. Then the function
Z

|x|

Z

Î¨n (x) =

y

Ïn (u)dudy
0

0

is even and twice continuously differentiable, with |Î¨0n (x)| â‰¤ 1 and limnâ†’âˆ
Î¨n (x) = |x|. Suppose there are two strong solutions (I (1) , S (1) ) and (I (2) , S (2) ),
d(I (1) âˆ’ I (2) âˆ’ E[I (1) âˆ’ I (2) ]) âˆ’ Î±Ïƒ(I (1) âˆ’ I (2) )dB2

p
p
S (1) I (1) âˆ’ S (2) I (2) dB1
= âˆ’ÏƒS
= âˆ’d(S (1) âˆ’ S (2) âˆ’ E[S (1) âˆ’ S (2) ])
so that
(d(I (1) âˆ’ I (2) ))2 < ÏƒS2 (S (1) I (1) âˆ’ S (2) I (2) )dt + (Î±Ïƒ)2 (I (1) âˆ’ I (2) )2 dt
(d(S (1) âˆ’ S (2) ))2 < ÏƒS2 (S (1) I (1) âˆ’ S (2) I (2) )dt
d((I (1) âˆ’ I (2) )(S (1) âˆ’ S (2) )) < âˆ’ÏƒS2 (S (1) I (1) âˆ’ S (2) I (2) )dt

12

Thus, since |Î¨0n | < 1,
(1)

E[dÎ¨n (It

(2)

(1)

âˆ’ It ) + dÎ¨n (St
(1)

(2)

âˆ’ St )]

(2)

(1)

(2)

= E[Î¨0n (It âˆ’ It )(d(I (1) âˆ’ I (2) )) + Î¨0n (St âˆ’ St )(d(S (1) âˆ’ S (2) ))]
1
(1)
(2)
+ E[Î¨00n (It âˆ’ It )(d(I (1) âˆ’ I (2) ))2 ]
2
1
(1)
(2)
+ E[Î¨00n (St âˆ’ St )(d(S (1) âˆ’ S (2) ))2 ]
2
â‰¤ E[2|Î²||S (1) I (1) âˆ’ S (2) I (2) |dt + |D||I (1) âˆ’ I (2) |dt]
1
(1)
(2)
+ E[Î¨00n (It âˆ’ It )ÏƒS2 (S (1) I (1) âˆ’ S (2) I (2) )dt]
2
1
(1)
(2)
+ E[Î¨00n (St âˆ’ St )ÏƒS2 (S (1) I (1) âˆ’ S (2) I (2) )dt]
2
1
(1)
(2)
+ E[Î¨00n (It âˆ’ It )(Î±Ïƒ)2 (I (1) âˆ’ I (2) )2 ]dt
2
where
D = âˆ’(K0 + Âµ0 ) + Î±(K0 âˆ’ K1 + Âµ0 âˆ’ Âµ1 )
Observe that:
S (1) I (1) âˆ’ S (2) I (2)

= S (1) (I (1) âˆ’ I (2) ) + I (2) (S (1) âˆ’ S (2) )
< |I (1) âˆ’ I (2) | + |S (1) âˆ’ S (2) |

Since Î¨00n < 2/nh and h is positive,



(1)
(2)
(1)
(2)
Î¨00n (It âˆ’ It ) + Î¨00n (St âˆ’ St ) S (1) I (1) âˆ’ S (2) I (2)


2
1
1
<
+
(|I (1) âˆ’ I (2) | + |S (1) âˆ’ S (2) |)
n h(|I (1) âˆ’ I (2) |) h(|S (1) âˆ’ S (2) |)


2
|I (1) âˆ’ I (2) |
|S (1) âˆ’ S (2) |
<
+
n h(|I (1) âˆ’ I (2) |) h(|S (1) âˆ’ S (2) |)
Taking h(x) = x results in
(1)

(2)

(1)

(2)

E[dÎ¨n (It âˆ’ It ) + dÎ¨n (St âˆ’ St )]

< E[(2|Î²| + |D|)|I (1) âˆ’ I (2) |] + E[2|Î²||S (1) âˆ’ S (2) |]

(Î±Ïƒ)2
2Ïƒ 2
E[|I (1) âˆ’ I (2) |] dt
+ S +
n
2
Since limnâ†’âˆ Î¨n (x) = |x|,
(1)

(2)

(1)

âˆ’ It | + |St

E[|It

Z
<

(2)

âˆ’ St |]

t

E[(2|Î²| + |Ds |)|Is(1) âˆ’ Is(2) |] + E[2|Î²||Ss(1) âˆ’ Ss(2) |]

0

+

(Î±s Ïƒ)2
E[|Is(1) âˆ’ Is(2) |]ds
2
13

But,
|Ds |)|Is(1)

p

|)2 ]

q
(1)
(2)
E[|Is âˆ’ Is |2 ]

E[(2|Î²| + |Ds
q
(1)
(2)
(1)
(1)
(2)
(1)
(2) 2
Since |Is âˆ’ Is | < 1, E[(Is âˆ’ Is ) ] < 1 and E[(Is âˆ’ Is )2 ] < E[|Is âˆ’
E[(2|Î²| +

âˆ’

Is(2) |]

<

(2)

Is |] thus
(1)

(2)

(1)

(2)

âˆ’ It | + |St âˆ’ St |]

Z t p
(Î±Ïƒ)2
2
E[(2|Î²| + |Ds |) ] +
E[|Is(1) âˆ’ Is(2) |]
<
2
0

E[|It

+ 2|Î²|E[|Ss(1) âˆ’ Ss(2) |]ds


Z t
p
(Î±Ïƒ)2
2
E[(2|Î²| + |Ds |) ] +
, 2|Î²|
<
max
2
0
Ã— E[|Is(1) âˆ’ Is(2) | + |Ss(1) âˆ’ Ss(2) |]ds
and local uniqueness follows by Gronwallâ€™s inequality.

Appendix B

Proof of Theorem 2

We refer to the problem treated by Gatto and Schellhorn (2021) as the unconstrained problem. Indeed, in that problem Î± was not constrained. We refer
to our problem as the constrained problem. We follow the method of proof
in CvitanicÌ and Karatzas (1992), referred to hereafter as CK. They introduce
auxiliar y problems, which are unconstrained. They show that there exists an
auxiliary problem which solution can be used to construct the solution of the
original constrained problem. We follow the numbering of the sections in CK
in order to ease understanding.
CK Section 2. The Model. To ease the correspondence with the CK paper,
we define b âˆ’ r = K0 + Âµ0 âˆ’ Âµ1 âˆ’ kÌ„1 , Î¸ := (b âˆ’ r)/Ïƒ, and
Z
 Z t
1 t 2 
(0)
H (t) = exp(âˆ’rt) exp âˆ’
Î¸dB2 (s) âˆ’
Î¸ ds
2 0
0
Rt
Observe that E[ 0 Î¸2 ds] < âˆ.
CK Section 3. Portfolio and consumption processes.
Z t
(0)
B2 (t) = B2 (t) +
Î¸ds

Define:

0

Denote by I i,Î± the infected process subject to I(0) = i and control Î±. It is
admissible if
0 â‰¤ I i,Î± (t) â‰¤ 1 âˆ€ 0 â‰¤ t â‰¤ T
14

The set of admissible Î± is denoted A0 (i). Note that (See (3.5) in CK)
H (0) (t)I(t) = i +

t

Z

H (0) (s)I(s)(Î±(s)Ïƒ âˆ’ Î¸)dB2 (s)

0

CK Section 4. Convex sets and their support functions. The difference
between CK and this paper is that our objective is to minimize. This means
that the key relation between our auxiliary infected and infected is reversed
compared to the first equation in CK. Indeed if Î±Î½ solves the auxiliary problem
and Î± the original problem, we must have:
IÎ½i,Î±Î½ (t) â‰¤ I i,Î± (t)
Define


Î´(Î½) =

0
Î½

Î½<0
Î½>0

(24)

It is subadditive:
Î´(Î» + Î½) â‰¤ Î´(Î») + Î´(Î½)

(25)

CK Section 5. Utility functions. The main difference between our utility
functions and the utility functions in financial economics is that our utility
functions are decreasing for positive arguments. Recall indeed that our utility
function is, for Î³ < 0:
i1âˆ’Î³
U (i) = âˆ’
1âˆ’Î³
Since
U 0 (i) = âˆ’iâˆ’Î³
We have limiâ†’âˆ U 0 (i) = âˆ’âˆ and limiâ†’0 U 0 (i) = 0, again for Î³ < 0. This is
unlike CK and Wachter (2002) who consider the case 0 < Î³ < 1 with utility of
1âˆ’Î³
wealth U2 (x) = x1âˆ’Î³ . In their case, limxâ†’âˆ U20 (x) = 0 and limxâ†’0 U20 (x) = âˆ.
We define I2 to be the inverse of U 0 , with I2 (y) on y â‰¤ 0. By straighforward
calculations:
I2 (y) = (âˆ’y)âˆ’1/Î³
We also define the Legendre-Fenchel dual
UÌƒ (y) = max[U (x) âˆ’ xy] = U (I2 (y)) âˆ’ yI2 (y)
x>0

This function satisfies:
UÌƒ 0 (y) = âˆ’I2 (y) y â‰¤ 0

15

CK Section 6. The constrained and unconstrained optimization problems. We define:
A0 (i) = {Î± âˆˆ A0 (i)|0 â‰¤ Î± â‰¤ 1}
The supremum of the unconstrained problem is denoted by V0 , while the supremum of the constrained problem is denoted by V , namely:
V0 (i)

=

sup E[U (I i,Î± (T ))|I(0) = i]
Î±âˆˆA0 (i)

V (i)

=

sup E[U (I i,Î± (T ))|I(0) = i]

Î±âˆˆA0 (i)

CK Section 7. Solution of the unconstrained problem.
the expectation
X0 (y) â‰¡ E[H (0) (T )I2 (yH (0) (T ))]

We note that

is finite for every y âˆˆ (âˆ’âˆ, 0]. We define its inverse Y0 :
Y0 (X0 (y)) = y
The solution of the unconstrained problem is well-known, and equal to:
Î±(s) =

râˆ’b
Î¸
= 2
ÏƒÎ³
Ïƒ |Î³|

CK Section 8. Auxiliary unconstrained optimization problems. Recall Î´(Î½) in (24). It is easily seen that:


Î±Î½
Î½<0
Î±Î½ âˆ’ Î´(Î½) =
â‰¤0
(Î± âˆ’ 1)Î½ Î½ > 0
We introduce a new process I (Î½) by:
dI (Î½) (t)
(0)
= (r + Î±(t)Î½(t) âˆ’ Î´(Î½(t)))dt + Î±(t)ÏƒdB2 (t)
I (Î½) (t)
Likewise we introduce
Î¸(Î½) = Î¸ + Î½/Ïƒ
Z

t

Î¸(Î½) (s)ds
Z t

  Z t

(Î½)
H (t) = exp âˆ’ rt +
Î´(Î½(s))ds E âˆ’
Î¸(Î½) (s)dB2 (s)
0
0
Z
 Z t

 Z t

1 t (Î½)
(Î½)
(Î½)
E âˆ’
Î¸ (s)dB2 (s) â‰¡ exp âˆ’
Î¸ (s)dB2 (s) âˆ’
(Î¸ (s))2 ds
2 0
0
0

B

(Î½)

(t) = B2 (t) +

0

We denote by A0Î½ (i) the class of Î± for which
IÎ½i,Î± (t) â‰¤ 1
16

Since the solution of our dual problem will have Î±(t)Î½(t) âˆ’ Î´(Î½(t)) â‰¤ 0,
clearly A0 (i) âŠ‚ A0Î½ (i). We define:
sup E[U (I i,Î± (T ))]

VÎ½ (i) =

Ï€âˆˆA0Î½ (i)

XÎ½ (y) â‰¡ E[H (Î½) (T )I2 (yH (Î½) (T ))]
We define a class of progressively measurable processes Î½ in R by:
Z
n
D0 = Î½; E

T

Z
Î´(Î½(t))dt â‰¤ âˆ, E

Î½ 2 (t)dt < âˆ, XÎ½ (y) < âˆ, y âˆˆ (âˆ’âˆ, 0]

o

0

Proposition 8.3. in CK shows that, if for some Î» âˆˆ D0 the corresponding
control Î±Î» is optimal for the auxiliary optimization problem and if
âˆ’Î´(Î») + Î±Î» (t)Î»(t) = 0
then Î± âˆˆ A0 (i) and is optimal for the constrained problem.
The solution of the unconstrained problem is:
Î±(s) =

Î¸ + Î½/Ïƒ
râˆ’bâˆ’Î½
Î¸(Î½)
=
=
ÏƒÎ³
ÏƒÎ³
Ïƒ 2 |Î³|

(26)

CK Section 9. Contingent claims attainable by constrained portfolios.
We sketch the proof of theorem 9.1 in CK, as the signs are different, and the
structure of the control is slightly different.
CK 9.1 Theorem. Let B be a positive FT -measurable random variable and
suppose there is a process Î» âˆˆ D0 such that, for all Î½ âˆˆ D0
E[H (Î½) (T )B] â‰¤ E[H (Î») (T )B] := i

(27)

Then there exists a control Î± âˆˆ A0 (i) such that I i,Î± = B.
Sketch of Proof. See CK p.782 for a definition of the stopping time Ï„n . By (27)
and subadditivity of Î´ (25):
0

â‰¤
=

1
lim sup E[(H (Î»)(T ) âˆ’ H (Î»+Îµ(Î½âˆ’Î»)) (T ))B]
Îµâ†“0
Îµ


1 h (Î»)
lim sup E H (T )B 1 âˆ’ exp
Îµâ†“0
Îµ
Z T âˆ§Ï„n
(Î´(Î»(t) + Îµ(Î½(t) âˆ’ Î»(t))) âˆ’ Î´(Î»(t))) dt
0

Z

T âˆ§Ï„n

(Î»)

(âˆ’Î¸(Î») (t) + Î¸(Î»+Îµ(Î½âˆ’Î»)) (t))dB2 (t)
0
h
i
â‰¤ lim sup E H (Î») (T )B(LT + NT )
Ã—E

Îµâ†“0

17

i

where
Î´Ì†

(Î½)


(Î»(t)) =

Î´(Î»(t))
Î½=0
âˆ’Î´(Î½(t) âˆ’ Î»(t)) otherwise

T âˆ§Ï„n

Z

Î´Ì† (Î½) (Î»(t))dt

LT =
0
T âˆ§Ï„n

Z
NT =
0

Î½(t) âˆ’ Î»(t) (Î»)
dB2 (t)
Ïƒ

By Itoâ€™s lemma.
d[H (Î») (t)I(t)(Lt + Nt )] = I(t)H (Î») (t)d(Lt + Nt )
(Î»)

+ (Lt + Nt )H (Î») (t)I(t)Î±(t)ÏƒdB2 (t) + I(t)H (Î») (t)Î±(t)(Î½(t) âˆ’ Î»(t))dt
which implies
H (Î») (T )I(T )(LT + NT )
Z Ï„n

 Î½(t) âˆ’ Î»(t)
(Î»)
+ (Lt + Nt )ÏƒÎ±(t) dB2 (t)
=
I(t)H (Î») (t)
Ïƒ
0
Z Ï„n


+
H (Î») (t)I(t) Î±(t)(Î½(t) âˆ’ Î»(t))dt + dLt
0

Therefore,
hZ
0 â‰¤ E[H (Î») (T )B(LT + NT )] = E

Ï„n


i
H (Î») (t)I(t) Î±(t)(Î½(t) âˆ’ Î»(t))dt + dLt

0

It is easy to see that, for any Ï âˆˆ D0 , take Î½ = Î» + Ï:
âˆ’ Î´(Ï(t)) + Î±(t)Ï(t) â‰¥ 0

(28)

and, taking Î½(t) = 0, we obtain:
âˆ’Î´(Î»(t)) + Î±(t)Î»(t) â‰¤ 0
which together with (28) for Ï = Î» yields:
âˆ’Î´(Î»(t)) + Î±(t)Î»(t) = 0

CK Section 10. Equivalent optimality conditions. The most important
implication to prove is (D)â‡’(B)â‡’(A) in CK. It shows that the solution of the
dual problem solves the auxiliary problem, and that, moreover, it is feasible and
optimal for the original constrained problem. We make it more explicit here.

18

(Part of ) CK 10.1 Theorem. Suppose that for every Î½ âˆˆ D0 ,
E[UÌƒ (YÎ» (i)H (Î») (T ))] â‰¤ E[UÌƒ (YÎ» (i)H (Î½) (T ))]

(29)

then there exists a control Î±Î» âˆˆ [0, 1] that is optimal for the constrained problem
VÎ» (i) = E[U (I i,Î±Î» (T ))] and such that
VÎ» (i) = V (i)
Proof.
E[UÌƒ (YÎ» (i)H (Î») (T ))] â‰¤ E[UÌƒ (YÎ» (i)H (Î»+Îµ(Î½âˆ’Î»)) (T ))]
Since UÌƒ 0 (y) = âˆ’I2 (y),
0

â‰¤
=

1
lim sup E[UÌƒ (YÎ» (i)H (Î»+Îµ(Î½âˆ’Î»)) (T )) âˆ’ UÌƒ (YÎ» (i)H (Î») (T ))]
Îµâ†“0
Îµ
1
YÎ» (i) lim sup E[I2 (YÎ» (i)H (Î») (T ))(H (Î») (T ) âˆ’ H (Î»+Îµ(Î½âˆ’Î»)) (T ))
Îµâ†“0
Îµ

By theorem 9.1 there exists a control Î±Î» âˆˆ A0Î» (i) such that:
I i,Î±Î» (T ) = I2 (YÎ» (i)HÎ» (T ))
Clearly Î±Î» is optimal for the constrained problem, and
âˆ’Î´(Î») + Î±Î» (t)Î»(t) = 0
Thus by proposition 8.3, Î±Î» is optimal for the constrained problem.
CK Section 12. A dual problem. Define:
VÌ‚ (y) = inf 0 E[UÌƒ (yHÎ½ (T ))]
Î½âˆˆD

In our case,
 x1âˆ’Î³

UÌƒ (y) = max âˆ’
âˆ’ xy
x>0
1âˆ’Î³
Thus
y = U 0 (x) = âˆ’xâˆ’Î³ =â‡’ I2 (y) = (âˆ’y)âˆ’1/Î³
Let Ï = (1 âˆ’ Î³)/Î³. Then:
UÌƒ (y) = âˆ’(âˆ’y)âˆ’Ï /Ï
Typically, Î³ = âˆ’1, so that:
UÌƒ (y) = y 2 /2
The main problem in condition (29) is to find the optimal process H (Î»)
(across all H (Î½) ) but it depends on y which depends on Î». Thus the dual must
be fixed for a fixed but arbitrary real number y. The objective has the form
E[UÌƒ (yH (Î½) (T ))] = E[U (I2 (yH (Î½) (T ))) âˆ’ yH (Î½) (T )I2 (yH (Î½) (T ))]
19

The right handside of the equation (see Korn (1997, p.134)) is the maximum
of the function h(B, y) := L(B, y) for all non-negative FT measurable B with
E[H (Î½) (T )B] â‰¤ i. Thus a minimization over all positive numbers y of h(B, y)
would yield the optimal utility of the unconstrained problem. We could thus
first minimize E[UÌƒ (yH (Î½) (T ))] in y, and then minimize over Î½. However, the
main idea is to first minimize over Âµ, and then minimize over y, hoping that the
two can be interchanged.
CK 12.1 Proposition. Suppose that for any y there exists Î»y such that VÌ‚ (y) =
E[UÌƒ (yH (Î»y ) (T ))]. Then there exist an Î± âˆˆ A0 (i) with i = XÎ»y (y) which is optimal
for the primal problem, and we have:
VÌ‚ (y) = sup[V (i) âˆ’ iy]
i

Proof. Write Î» for Î»YÎ» (i) . Then
E[UÌƒ (YÎ» (i)H (Î») (T ))] â‰¤ E[UÌƒ (YÎ» (i)H (Î½) (T ))]
and we conclude by CK Theorem 10.1.
CK Section 15.
Define:

Deterministic coefficients and feedback formulae.
Q(y, t) = E[UÌƒ (yH (Î½) (T ))|yH (Î½) (t) = y]

Recall
dH (Î½)
= (âˆ’r + Î´(Î½))dt âˆ’ (Î¸ + Î½/Ïƒ)dB2
H (Î½)
The HJB equation is:
1
min y 2 (Î¸ + Î½/Ïƒ)2 Qyy + y(âˆ’r + Î´(Î½))Qy + Qt = 0
Î½ 2
(âˆ’y)âˆ’Ï
Q(T, y) = UÌƒ (y) = âˆ’
Ï
Again, with Ï = (1 âˆ’ Î³)/Î³ < 0. We choose
1
Q(y, t) = âˆ’ (âˆ’y)âˆ’Ï v(t)
Ï
Thus
1 2
y (Î¸ + Î½/Ïƒ)2 Qyy + y(âˆ’r + Î´(Î½))Qy
2
1
= âˆ’ (Ï + 1)(âˆ’y)âˆ’Ï v(t)(Î¸ + Î½/Ïƒ)2 + (âˆ’r + Î´(Î½))(âˆ’y)âˆ’Ï v(t)
2
Dividing by (âˆ’y)âˆ’Ï v(t), the problem becomes:
argmin âˆ’
Î½

1+Ï
(Î¸ + Î½/Ïƒ)2 + Î´(Î½)
2
20

(30)

Recall that if Î½ is positive, then Î´(Î½) = Î½ thus we solve (30) and obtain
Î½=

Ïƒ2
+ r âˆ’ b = âˆ’Ïƒ 2 |Î³| + r âˆ’ b
1+Ï

since 1 + Ï = 1/Î³ and Î³ is negative. If Î½ is negative, then Î´(Î½) = 0, thus
Î½ = r âˆ’ b.
From (26), the solution is
Î±(s) =


 r âˆ’ b 
râˆ’bâˆ’Î½
=
min
1,
max
0, 2
Ïƒ 2 |Î³|
Ïƒ |Î³|

Suppose Âµ0 = Âµ1 and treatment is better than no treatment kÌ„1 > K0 . Thus
r âˆ’ b = kÌ„1 âˆ’ K0 is positive. Thus

 kÌ„ âˆ’ K 
1
0
Î±(s) = min 1, max 0,
Ïƒ 2 |Î³|

Appendix C
Z

Ï„



A3 (Ï„, Î³) =
0


Ïƒ2
Ïƒx2
+ Î»x XÌ„ A22 (s, Î³) + x A1 (s, Î³) + (Î³ âˆ’ 1)Âµds
2Î³
2

2Î»x XÌ„b2 (Î³)A2 (Ï„, Î³) 2XÌ„ 2 Î»2x
A1 (Ï„, Î³)
+ 3
âˆ’
2Î³
Î¸3 (Î³)b3 (Î³)
Î¸ (Î³)
b3 (Î³)


2Î¸(Î³)âˆ’(Î¸(Î³)+b2 (Î³))(1âˆ’eâˆ’Î¸(Î³)Ï„ )
p
8b21 (Î³)Ï„ log
2Î¸(Î³)
b2 (Î³)(Î¸(Î³) âˆ’ 2 b1 (Î³)b3 (Î³))
p
+
+
Î¸(Î³)b23 (Î³)
(b2 (Î³) âˆ’ Î¸(Î³)) b1 (Î³)b3 (Î³)
p
p
b2 (Î³) âˆ’ 2 b1 (Î³)b3 (Î³)
2b2 (Î³) + 4 b1 (Î³)b3 (Î³)eâˆ’Î¸(Î³)Ï„ /2

Ã— log
Î¸(Î³)
2Î¸(Î³) âˆ’ (b2 (Î³) + Î¸(Î³)) 1 âˆ’ eâˆ’Î¸(Î³)Ï„
!!

(b2 (Î³) + Î¸(Î³))A1 (Ï„, Î³)
4b21 (Î³)Ï„
âˆ’
+
2b1 (Î³)
(b2 (Î³) + Î¸(Î³))2
!
!
1
2Î¸(Î³)eâˆ’Î¸(Î³)Ï„
2b1 (Î³)Ï„
Ïƒx2
 âˆ’
log
+
2 b3 (Î³)
b2 (Î³) + Î¸(Î³)
2Î¸(Î³) âˆ’ (b2 (Î³) + Î¸(Î³)) 1 âˆ’ eâˆ’Î¸(Î³)Ï„


=

Ïƒx2

Explicit Formula of A3 (Ï„, Î³) in (12)



+ Î»x XÌ„

+(Î³ âˆ’ 1)ÂµÏ„

Appendix D

Proof of Theorem 3

We following the proof of Proposition 2 in Gatto and Schellhorn (2021). Recall
the equations (58) (59) in Gatto and Schellhorn (2021) and following same

21

notations:
âˆ‚

+ L1 f1 = 0
âˆ‚t
âˆ‚

+ L1 f2 = âˆ’L2 f1
âˆ‚t

(31)
(32)

where L1 , L2 are equations (53) (54) in Gatto and Schellhorn (2021).
Solution of (31) We postulate that:
f1 (Z, X, t) = Z 1/Î³ H1 (X, T âˆ’ t)
Substitution in (31) shows that H1 solves:

âˆ‚
+ LÎ³ H1 = 0
âˆ‚t
H1 (X, 0) = 1

(33)

where the operator LÎ³ is defined by:
LÎ³ H

â‰¡


 âˆ‚H
1 2 âˆ‚ 2 H  Î³ âˆ’ 1
Ïƒx
+
Ïƒ
âˆ’
Î»
X
+
Î»
XÌ„
x
x
x
2 âˆ‚X 2
Î³
âˆ‚X
 1 1 1




1
+ X2
âˆ’1 +Âµ 1âˆ’
H
2Î³ Î³
Î³

Using the Ansatz (9), we can rewrite the LHS of (33) into:
(C1 (t)X 2 + C2 (t)X + C3 (t))H1 /Î³ = 0
Clearly all terms C1 , C2 , C3 must be identically zero. Thus:

Ïƒ2
Î³âˆ’1
1âˆ’Î³
dA1 (t, Î³)
= x A21 (t, Î³) + 2
Ïƒx âˆ’ Î»x A1 (t, Î³) +
dt
Î³
Î³
Î³

dA2 (t, Î³)
Ïƒx2 A1 (t, Î³)
Î³âˆ’1
=
A2 (t, Î³) +
Ïƒx âˆ’ Î»x A2 (t, Î³) + Î»x XÌ„A1 (t, Î³)
dt
Î³
Î³
dA3 (t, Î³)
Ïƒ2
A2 (t, Î³) 
= x A1 (t, Î³) + 2
+ Î»x XÌ„A2 (t, Î³) âˆ’ Âµ(1 âˆ’ Î³)
dt
2
Î³
which admit the solutions (10),(11),(12).
Solution of (32) The second equation can be rewritten
âˆ‚

1 Î² 2 2/Î³
+ L1 f2 =
Z SH1 (X, T âˆ’ t)2
âˆ‚t
2 Î³ÏƒS2

(34)

We try the Ansatz:
f2 (Z(t), X(t), t) = Z(t)2/Î³ S(t)g(X(t), t)
22

(35)

Thus
âˆ‚

1 Î²2
+ LÎ³/2 g(X, t) =
H1 (X, T âˆ’ t)2
âˆ‚t
2 ÏƒS2 Î³
g(X, T ) = 0
We use Lemma to obtain the g(X, t) in (15).
The optimal policy is:


âˆ‚F
âˆ‚F
1
XZ âˆ’
Ïƒx = Î±0 + ÎµÎ±1 + O(Îµ2 )
Î±âˆ— =
ÏƒF âˆ‚Z
âˆ‚X
where
Î±0

=
=

Î±1

=
=

âˆ‚f1 XZ
âˆ‚f1 Ïƒx
âˆ’
âˆ‚Z Ïƒf1
âˆ‚X Ïƒf1
X(t)
Ïƒx
âˆ’
(A1 (T âˆ’ t, Î³)X(t) + A2 (T âˆ’ t, Î³))
Î³Ïƒ
Î³Ïƒ



âˆ‚f1 f2
âˆ‚f1 f2
âˆ‚f2
Ïƒx âˆ‚f2
âˆ’
âˆ’
âˆ’
âˆ‚Z
âˆ‚Z f1
Ïƒf1 âˆ‚X
âˆ‚X f1

1/Î³
g(X(t), t)X(t)
âˆ‚g
Z (t)S(t)
âˆ’ Ïƒx
H1 (X, T âˆ’ t)Ïƒ
Î³
âˆ‚X

g(X(t), t)
(A1 (T âˆ’ t, Î³)X(t) + A2 (T âˆ’ t, Î³))
+Ïƒx
Î³
XZ
Ïƒf1



Lemma 5. Let u(x, t) =

2
1 Î²
2 Î³ H1 (x, T
2 ÏƒS

âˆ’ t)2 . The solution to

âˆ‚g(x, t)
+ LÎ³/2 g(x, t) = u(x, t)
âˆ‚t
g(x, T ) = 0

(36)

is in (15).
Sketch of Proof. The solution g(x, t) is the price of a variable-coupon bond in
an affine model. The building block is the solution of a zero-coupon bond in the
similar model. Define m(x) and r(x) to be such that:
âˆ‚f (x, t)
1 âˆ‚ 2 f (x, t)
+ m(x)
âˆ’ r(x)f (x, t)
LÎ³/2 f (x, t) = Ïƒx2
2
âˆ‚x2
âˆ‚x
 Î³/2 âˆ’ 1

m(x) =
Ïƒx âˆ’ Î»x x + Î»x XÌ„
Î³/2
 1 2

2 
r(x) = âˆ’ x2
âˆ’1 +Âµ 1âˆ’
Î³ Î³
Î³
Let f (x, t) be the solution of:
âˆ‚f (x, t) 1 2 âˆ‚ 2 f (x, t)
âˆ‚f (x, t)
+ Ïƒx
+ m(x)
= r(x)f (x, t)
âˆ‚t
2
âˆ‚x2
âˆ‚x
23

(37)

Defining:
dX(t) = m(X)dt + Ïƒx dW (t)

(38)

we see that:
âˆ‚f (x, t) 1 2 âˆ‚ 2 f (x, t)
âˆ‚f (x, t)
+ m(x)
+ Ïƒx
= E[df (X, t)|X(t) = x]/dt
âˆ‚t
2
âˆ‚x2
âˆ‚x

(39)

Thus (37) can be rewritten:
E[df (X(t), t) âˆ’ r(X(t))f (X(t), t)dt|X(t)] = 0
Rt
Using the integrating factor exp(âˆ’ 0 r(X(s)ds), we have:
Z

t

r(X(s))ds)f (X(t), t))|X(t)] = 0

E[d(exp(âˆ’
0

Under the boundary condition f (X(T ), T ) = 1 the only possible solution is:
Z T
f (x, t; T ) = E[exp(âˆ’
r(X(s))ds)|X(t) = x]
t

Define P (t, T ) = f (X(t), t; T ) = H2 (X(t), T âˆ’ t) to be the price of a discount
bond with a maturity of T . Clearly:
dP (t, T )
= r(X(t))dt + v(t, T )dW (t)
P (t, T )
where:

âˆ‚f

v(t, T ) = Ïƒx âˆ‚x
f
By Itoâ€™s lemma, and for the exact same reason as (39):
âˆ‚g(x, t) 1 2 âˆ‚ 2 g(x, t)
âˆ‚g(x, t)
+ Ïƒx
+ m(x)
= E[dg(X, t)|X(t) = x]/dt
2
âˆ‚t
2
âˆ‚x
âˆ‚x
The stochastic equivalent of (36) is:
E[dg(X(t), t) âˆ’ r(X(t))g(x, t)dt|X(t)] = E[u(X(t), t)dt|X(t)]
The solution is:
Z

T

g(X(t), t) =

Q(t, Ï„ )dÏ„
Ï„ =t

where:

Z
Q(t, Ï„ ) = E[exp(âˆ’

Ï„

r(X(s))ds)u(X(Ï„ ), Ï„ )|X(t)]
t

Clearly, for some volatility ÏƒQ (t, Ï„ )
dQ(t, Ï„ )
= r(X(t))dt + ÏƒQ (t, Ï„ )dW (t)
Q(t, Ï„ )
24

We are now ready to define a change of numeraire. Let
dW Ï„ = dW âˆ’ v(t, Ï„ )dt
By Theorem 9.2.2. in Shreve (2004), Q(t, Ï„ )/P (t, Ï„ ) is a PÏ„ -martingale, i.e.,
Q(t, Ï„ ) = P (t, Ï„ )EÏ„t [u(X(Ï„ )]
where
dX(t)

= m(X)dt + Ïƒx dW (t)
= m(X)dt + Ïƒx (dW Ï„ (t) + v(t, Ï„ )dt)

From (9),
u(X(t), t) =

1 Î² 2 Î³2
e
2 ÏƒS 2 Î³



A1 (T âˆ’t,Î³)
X(t)2 +A2 (T âˆ’t,Î³)X(t)+A3 (T âˆ’t,Î³)
2



Let us now take:

 2  A (T âˆ’ t, Î³/2)
1
X 2 (t) + A2 (T âˆ’ t, Î³/2)X(t) + A3 (T âˆ’ t, Î³/2)
P (t, T ) = exp Î³
2
Thus:
v(t, Ï„ ) =

Ïƒx
Î³

(A1 (Ï„ âˆ’ t, Î³/2)X(t) + A2 (Ï„ âˆ’ t, Î³/2))

Î³
2


âˆ’1
Ïƒ2
Ïƒx âˆ’ Î»x + Î³x A1 (Ï„ âˆ’ t, Î³/2) X(t) + Î»x XÌ„
Î³/2
i
Ïƒ2
+ Î³x A2 (Ï„ âˆ’ t, Î³/2) dt + Ïƒx dW Ï„ (t)

h
dX(t) =

(40)

Thus EÏ„t [u(X(Ï„ ))] when (40) holds can be calculated exactly the same way
as E[u(X(Ï„ ))] when (38) holds. The structure is also affine, and there will be a
solution of the form:
 

1 Î² 2 Ï„ Î³2 A1 (T2âˆ’Ï„,Î³) X 2 (Ï„ )+A2 (T âˆ’Ï„,Î³)X(Ï„ )+A3 (T âˆ’Ï„,Î³)
EÏ„t [u(X(Ï„ ), Ï„ )] =
Et e
2 ÏƒS 2 Î³
To summarize, since P (t, T ) = H2 (X(t), T âˆ’ t)
Z

T

g(x, t) =

P (t, Ï„ )EÏ„t [u(X(Ï„ ), Ï„ )]dÏ„

Ï„ =t
Z T

H2 (X, Ï„ âˆ’ t)

=
Ï„ =t

1 Î²2
2 ÏƒS 2 Î³

  A (T âˆ’Ï„,Î³)

2
1
X 2 (Ï„ )+A2 (T âˆ’Ï„,Î³)X(Ï„ )+A3 (T âˆ’Ï„,Î³)
Ï„
Î³
2
dÏ„
Et e

25

(41)

Let MÌƒ (t, Ï„ ) as in (14) and
Y (Ï„ ) = X(Ï„ ) +

A2 (T âˆ’ Ï„, Î³)
A1 (T âˆ’ Ï„, Î³)

Clearly:
Z

Ï„

Ï„

E [X(Ï„ )|X(t) = x] = xMÌƒ (t, Ï„ ) +
MÌƒ (s, Ï„ )(Î»x XÌ„ +
s=t
Z Ï„
MÌƒ 2 (s, Ï„ )ds
VarÏ„ [X(Ï„ )|X(t) = x] = Ïƒx2

Ïƒx2
Î³

A2 (Ï„ âˆ’ s, Î³))ds

t

Thus we can calculate:
mY (Ï„, x) = EÏ„ [Y (Ï„ )|X(t) = x]
A2 (T âˆ’ Ï„, Î³)
A1 (T âˆ’ Ï„, Î³)
Z Ï„
Ï„
2
MÌƒ 2 (s, Ï„ )ds
VY (Ï„, x) = Var [Y (Ï„ )|X(t) = x] = Ïƒx
= EÏ„ [X(Ï„ )|X(t) = x] +

t

We can further develop:
i
h
 2  A (T âˆ’ Ï„, Î³)
1
EÏ„t exp
X 2 (Ï„ ) + A2 (T âˆ’ Ï„, Î³)X(Ï„ ) + A3 (T âˆ’ Ï„, Î³)
Î³
2




A2 (T âˆ’Ï„,Î³)
A2 (T âˆ’Ï„,Î³) 2
2
1
âˆ’ Î³A2 (T âˆ’Ï„,Î³)
Ï„
Î³ A3 (T âˆ’Ï„,Î³)+ Î³ A1 (T âˆ’Ï„,Î³) X(Ï„ )+ A1 (T âˆ’Ï„,Î³)
1
= Et e


 
A2 (T âˆ’Ï„,Î³)
A1 (T âˆ’Ï„,Î³)
A (T âˆ’Ï„,Î³) 2
2
X(Ï„ )+ A2 (T âˆ’Ï„,Î³)
A (T âˆ’Ï„,Î³)âˆ’ Î³A2 (T âˆ’Ï„,Î³)
Î³
1
1
= EÏ„t e Î³ 3
e
Z
A2 (T âˆ’Ï„,Î³)
(yâˆ’m (Ï„,x))2
A1 (T âˆ’Ï„,Î³) 2
2
1
A (T âˆ’Ï„,Î³)âˆ’ Î³A2 (T âˆ’Ï„,Î³)
y âˆ’ 2VYY(Ï„,x)
Î³
1
p
e
dy
= eÎ³ 3
e
2Ï€VY (Ï„, x)
2

= eÎ³

m2
A2 (T âˆ’Ï„,Î³)
Y (Ï„,x)A1 (T âˆ’Ï„,Î³)
+ Î³âˆ’2V
1 (T âˆ’Ï„,Î³)
Y (Ï„,x)A1 (T âˆ’Ï„,Î³)

A3 (T âˆ’Ï„,Î³)âˆ’ Î³A2

1
p
1 âˆ’ 2VY (Ï„, x)A1 (T âˆ’ Ï„, Î³)/Î³

providing Î³ < 2A1 (T âˆ’ Ï„, Î³)VY (Ï„, x). Thus equation (15) follows from equation
(41).

Appendix E

Proof of Theorem 4

When X(t) is a constant, equations (53) and (54) in Gatto and Schellhorn (2021)
become
1 2 b âˆ’ r 2 âˆ‚ 2 F
âˆ‚F
Z
âˆ’ ÂµZ
+ ÂµF
2
2
Ïƒ
âˆ‚Z
âˆ‚Z
1 Î²2
âˆ‚F
L2 F = âˆ’ 2 ZSF
2 ÏƒS
âˆ‚Z
L1 F =

26

Use the Ansatz f1 (Z(t), t) = Z 1/Î³ (t)h1 (T âˆ’ t) and insert in (17) shows that h1
solves:


âˆ‚
+ LÎ³ h1 = 0
h1 (0) = 1
(42)
âˆ‚t
where the operator LÎ³ is defined by:
LÎ³ H

 b âˆ’ r 1 1 1

1 
2
H
âˆ’1 +Âµ 1âˆ’
Ïƒ
2Î³ Î³
Î³

â‰¡

Using the Ansatz (20), we can rewrite (42) into:


C1 (t)


b âˆ’ r 2
+ C2 (t) h1 /Î³ = 0
Ïƒ

Clearly all terms C1 , C2 must be identically zero. Thus
1âˆ’Î³
da1,1 t
=
dt
Î³

da1,2 t
= Âµ(Î³ âˆ’ 1)
dt

which admit the solutions (21), (22) at i = 1.
iâˆ’1
iâˆ’1
Now use fi (Z(t), t) = Z 2 /Î³ (t)S 2 âˆ’1 (t)gi (t). We can rewrite (18) by


i
âˆ‚
1 Î² 2 2iâˆ’1 2
+ LÎ³/2 gi+1 (t) =
g (t)
gi+1 (T ) = 0
(43)
âˆ‚t
2 ÏƒS2 Î³ i
Let u(t) =

2 iâˆ’1
1Î² 2
2
2 Î³ gi (t)
2 ÏƒS

ri =

and

2i  1 b âˆ’ r 2
ai+1,1 + ai+1,2
Î³ 2 Ïƒ

Then

i

LÎ³/2 gi+1 (t) = ri gi+1 (t)
and the stochastic equivalent of (43) is:
âˆ‚gi+1 (t)
+ ri gi+1 (t) = u(t)
âˆ‚t

gi+1 (T ) = 0

which admits
1 Î² 2 2iâˆ’1
1
gi+1 (t) = âˆ’
2
2 ÏƒS Î³ hi+1 (t)

Z

T

gi2 (s)hi+1 (s)ds

(44)

t

We have showed that g1 = h1 (T âˆ’ t). Here we also provide the g2 and g3 in the
following:
g2 (t)

=

Î²2
2ÏƒS2

h2 (T âˆ’ t) âˆ’ h21 (T âˆ’ t)

bâˆ’r 2
(a1,1 âˆ’ a2,1 ) + 2(a1,2 âˆ’ a2,2 )
Ïƒ
27

Î²6
g3 (t) = âˆ’
16ÏƒS6
ï£«
ï£­h22 (T )


bâˆ’r 2
(a1,1 âˆ’ a2,1 )
Ïƒ
h3 (T )
h3 (t)
âˆ’ h2 (t)
h22 (T )
2

a3,1 âˆ’a2,1 bâˆ’r 2
+
a3,2 âˆ’ a2,2
2
Ïƒ

h2 (T )
âˆ’2 2
h1 (T )

h3 (T )h21 (T )
h2 (T )
a3,1 âˆ’

!2

1

a2,1 âˆ’a1,1
2

2

âˆ’

bâˆ’r 2
Ïƒ

+ 2(a1,2 âˆ’ a2,2 )

1
h3 (t)

h3 (T )
(t)
âˆ’ hh43 (t)
h41 (T )
4
1
+h1 (T ) a âˆ’a

3,1
1,1 bâˆ’r 2
+ a3,2
2
Ïƒ

h3 (t)h21 (t)
h2 (t)

+ a3,2 âˆ’

âˆ’ a1,2

ï£¶
a2,2 âˆ’a1,2
2

ï£¸

Suppose we use the first two expansions, the optimal policy is given by:
Î±âˆ— = Î±0 + ÎµÎ±1 + O(Îµ2 )
where
bâˆ’r
âˆ‚f1 bâˆ’r
Ïƒ Z
= Ïƒ
âˆ‚Z Ïƒf1
Î³Ïƒ


bâˆ’r
Z
âˆ‚f1 f2
âˆ‚f
Z 1/Î³ (t)S(t) g2 (t) bâˆ’r
2
Ïƒ
Î±1 = Ïƒ
âˆ’
=
Ïƒf1
âˆ‚Z
âˆ‚Z f1
h1 (T âˆ’ t)Ïƒ
Î³

Î±0 =

References
Andrea L Bertozzi, Elisa Franco, George Mohler, Martin B Short, and Daniel
Sledge. The challenges of modeling and forecasting the spread of covid-19.
Proceedings of the National Academy of Sciences, 117(29):16732â€“16738, 2020.
https://doi.org/10.1073/pnas.2006520117.
JaksÌŒa CvitanicÌ and Ioannis Karatzas. Convex duality in constrained portfolio optimization. The Annals of Applied Probability, 2:767â€“818, 1992.
https://doi.org/10.1214/aoap/1177005576.
Nicole M Gatto and Henry Schellhorn. Optimal control of the SIR model in
the presence of transmission and treatment uncertainty. Mathematical Biosciences, 333:108539, 2021. https://doi.org/10.1016/j.mbs.2021.108539.
Ioannis Karatzas and Steven Shreve. Brownian Motion and Stochastic Calculus.
Springer, 2014. https://doi.org/10.1007/978-1-4612-0949-2.
Ralf Korn.
Optimal Portfolios: Stochastic Models for Optimal Investment and Risk Management in Continuous Time. World Scientific, 1997.
https://doi.org/10.1142/3548.
Steven E Shreve. Stochastic calculus for finance II: Continuous-time models.
Springer-Verlag New York, 2004.
Jessica A Wachter. Portfolio and consumption decisions under mean-reverting
returns: An exact solution for complete markets. Journal of financial and
quantitative analysis, 37:63â€“91, 2002. https://doi.org/10.2307/3594995.
28

