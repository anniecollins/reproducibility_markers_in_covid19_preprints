Adaptive Group Testing on Networks with
Community Structure
Surin Ahn, Wei-Ning Chen, and Ayfer OÌˆzguÌˆr

arXiv:2101.02405v1 [cs.IT] 7 Jan 2021

Department of Electrical Engineering, Stanford University
{surinahn, wnchen, aozgur}@stanford.edu

Abstract
Since the inception of the group testing problem in World War II, the prevailing assumption
in the probabilistic variant of the problem has been that individuals in the population are infected
by a disease independently. However, this assumption rarely holds in practice, as diseases
typically spread through connections between individuals. We introduce an infection model for
networks, inspired by characteristics of COVID-19 and similar diseases, which generalizes the
traditional i.i.d. model from probabilistic group testing. Under this infection model, we ask
whether knowledge of the network structure can be leveraged to perform group testing more
efficiently, focusing specifically on community-structured graphs drawn from the stochastic block
model. Through both theory and simulations, we show that when the network and infection
parameters are conducive to â€œstrong community structure,â€ our proposed adaptive, graph-aware
algorithm outperforms the baseline binary splitting algorithm, and is even order-optimal in
certain parameter regimes. Finally, we derive novel information-theoretic lower bounds which
highlight the fundamental limits of adaptive group testing in our networked setting.

1

Introduction

Identifying individuals who are infected by a disease is crucial for curbing epidemics and ensuring
the well-being of society. However, due to high costs or limited resources, it is often infeasible to
test every member of the population individually. During World War II, when the U.S. military
sought to identify soldiers infected with syphilis, Dorfman made a breakthrough by introducing
the concept of group testing [1]. He showed that by testing groups or pools of samples rather than
individual samples, the infected people in a population of size n can be identified with far fewer
than n tests. The key insight was that if the infected population is sparse, then each pooled test is
likely to produce a negative result, in which case all individuals included in the test can be deemed
â€œnot infectedâ€ even though only a single test was performed. Today, group testing schemes are
actively being used in the COVID-19 pandemic to identify infected individuals in an efficient and
cost-effective manner [2â€“5]. Group testing is also useful to numerous application domains beyond
healthcare, such as wireless communications [6â€“10], machine learning [11â€“13], signal processing [14],
and data streaming [15].
1

Dorfmanâ€™s seminal work, and subsequent works by other authors on the so-called probabilistic
group testing problem [6, 16â€“18], assume that the disease infects individuals in a statistically independent fashion. However, this assumption rarely holds in practice. Diseases typically spread
through connections between individuals (e.g., familial, work-related, or other social connections),
thereby inducing correlated infections. It is therefore natural to ask whether exploiting information
about this connectivity structure can lead to more efficient group testing strategies. This problem
is especially timely given the critical role that group testing is playing in the current COVID-19
pandemic, and that the disease is known to spread from close contact between individuals.
In this work, we study the group testing problem under interaction networks that dictate the
spread of a disease through the population, and investigate whether the graphical structure can
be leveraged to perform pooled testing more efficiently than without knowledge of the graph. We
focus on networks with community structure: those containing clusters of nodes with more dense
connections within a cluster than between clusters. Such networks are pervasive in the real world
â€“ social, biological, and information networks commonly exhibit community structure â€“ and can
often be estimated in practice, thanks to the availability of large datasets and network estimation
techniques. Additionally, we introduce an infection model for arbitrary networks which generalizes
the standard i.i.d. model from the probabilistic group testing literature.
On the algorithmic side, we consider adaptive group testing schemes, where the design of each
test can be informed by the previous test results. We compare two different schemes: the standard
binary splitting [19] algorithm which is oblivious to the underlying network structure, and a simple
graph-aware algorithm that exploits the community structure of the network. We give precise
upper bounds on the expected number of tests performed by each algorithm. Crucially, we show
that when the network and infection parameters yield strong community structure (in which case the
disease is more likely to be transmitted within a community than between communities), the graphaware algorithmâ€™s average complexity is asymptotically strictly better than that of binary splitting.
We corroborate these results with numerical simulations. Finally, we derive novel informationtheoretic lower bounds which asymptotically match the graph aware algorithmâ€™s performance (up
to constants) in certain parameter regimes.
We note that our work may be relevant to other settings where the goal is to identify certain
objects of interest within a â€œclusteredâ€ population. For example, we may wish to identify the
active devices or users in a multiple access network, where devices that are closer together in the
network tend to be active or inactive at the same time. Exploring the potential applications of
network-oriented group testing to these types of problems is of great interest.
Related Works. Our work differs from the graph-constrained group testing problem [20â€“23] in
which the tests must conform to a given network topology. In our case, we allow the tests to be
arbitrary, but ask whether knowledge of the interaction network can help to reduce the number
of required tests. This is similar in spirit to recent work on community-aware group testing [24],
though our work departs from it in several ways. First, [24] assumes the population is partitioned
into disjoint â€œfamilies,â€ whereas our work considers more general network structures which allow for
transmissions between communities. Second, although we focus on community-structured graphs

2

in this paper, our proposed infection model works on top of arbitrary networks and therefore
applies naturally to a broader class of problems. Finally, we give a precise characterization of the
improvement provided by our graph-aware algorithm over the baseline, and in what parameter
regimes our lower bounds are order-optimal.
Paper Organization. The rest of this paper is organized as follows. In Section 2, we describe
the network and infection models, and define our mathematical notation. In Section 3, we provide
background and preliminary ideas. In Section 4, we discuss the main algorithms studied in this
paper: binary splitting and our proposed graph-aware algorithm. Section 5 gives upper and lower
bounds for adaptive group testing on networks consisting of disjoint cliques, and Section 6 generalizes these results to the stochastic block model. Finally, we present the results of our numerical
simulations in Section 7, and conclude in Section 8. All omitted proofs are given in the Appendix.

2

Models and Notation

2.1

Infection Model

We study the following probabilistic infection model with parameters p, q âˆˆ [0, 1], which acts upon
an undirected graph G = (V, E) in two stages (each executed once):
1. Seed Selection: Each vertex is infected i.i.d. with probability p. These initial infected
vertices are called the seeds. They model the introduction of the disease into the population
via some external entity (e.g., a traveler carrying the disease into a country).
2. Neighbor Infection: A seed infects each of its neighbors i.i.d. with probability q. This
models how the disease spreads through the population via interactions between carriers and
nearby individuals.
Remark 1. The above stages can be viewed as the â€œfirst time stepâ€ of a stochastic epidemic model,
i.e., the initial spread of an epidemic. It is inspired by diseases such as COVID-19, which are
initially introduced into a population from an external source and subsequently transmitted between
individuals in close contact. In practice, the specific values of p, q can be tailored to the disease in
question (for example, by using contact tracing to estimate the infectiousness of the disease).
Consider an arbitrary graph with seed selection probability p âˆˆ [0, 1] and neighbor infection
probability q = 0. In this case, our setting reduces to the i.i.d. probabilistic group testing model.
Each node is selected as a seed (and thus infected) with probability p, and since transmissions
between nodes are not possible, no additional nodes are infected during the neighbor infection
phase. It follows that we cannot hope to do any better than classical group testing schemes in this
setting.
Proposition 1. Under an arbitrary graph G = (V, E), identifying infected individuals under our
infection model with seed selection parameter p âˆˆ [0, 1] and zero probability of neighbor infection
(q = 0) is equivalent to the i.i.d. probabilistic group testing problem with infection probability p.

3

Note that the empty graph (a.k.a. null graph), G = (V, E) where E = âˆ…, with arbitrary infection
parameters p, q âˆˆ [0, 1], also yields the i.i.d. group testing model with infection probability p.

2.2

Network Model

For the rest of this paper, we assume that the underlying network is drawn from the stochastic block
model (SBM) [25] â€“ a well-known random graph model with the tendency to produce communitystructured graphs. The standard SBM has the following parameters:
â€¢ n vertices
â€¢ a partition of the vertex set V = {1, 2, . . . , n} into m communities, C1 , . . . , Cm , where
V and Ci âˆ© Cj = âˆ…, âˆ€i 6= j

S

iâˆˆ[m] Ci

=

â€¢ a symmetric matrix P âˆˆ RmÃ—m of edge probabilities.
The random graph G = (V, E) is then generated in the following way. First, initialize E = âˆ…. Then
for each pair of vertices u âˆˆ Ci , v âˆˆ Cj , we add an edge between u and v with probability Pij .
In this paper, we consider a special case of the SBM. We assume the communities are all of size
k, where k is a factor of n (so that the number of communities is m = n/k), and that there is a
constant edge probability p1 within communities, and probability p2 between communities. That
is, P equals p1 along the diagonal entries and p2 on the off-diagonal entries. We further assume that
p1 > p2 , i.e., that edges are more likely to occur within a community than between communities.
Finally, we assume that the communities are known to the group testing algorithms in advance,
but that the graph itself may not be known.
Stochastic Block Infection Model (SBIM): Our infection model acting upon the SBM can
equivalently be studied through a slightly modified infection model which acts upon the complete

graph on n vertices: the graph containing all possible n2 edges. This will reduce the overall number
of parameters we have to consider. Our modified model still begins by selecting each node i.i.d. with
probability p to be a seed. However, in the neighbor infection phase, each seed infects its neighbors
within the same community i.i.d. with probability q1 and infects those outside its community i.i.d.
with probability q2 , where q1 > q2 . The equivalence of this model and the original model can be
seen by setting q1 = p1 Â· q and q2 = p2 Â· q, where q is the neighbor infection probability in the
original model. We call this the Stochastic Block Infection Model, denoted by SBIM(n, k, p, q1 , q2 ).
Note that SBIM(n, k, p, 0, 0), with k an arbitrary factor of n, is equivalent to the i.i.d. group testing
model.
Disjoint k-Cliques Model. Before analyzing the SBIM in full generality in Section 6, we begin
in Section 5 by investigating the special case of SBIM(n, k, p, q, 0), which we refer to as the disjoint
k-cliques model. Here, we have m = n/k communities of size k, each a complete subgraph on
k vertices, with no edges between communities. The transmission rate within a community is q,
and no transmissions are possible between communities. Figure 1 illustrates the SBIM and the
difference between the disjoint k-cliques model (q2 = 0) and the general SBIM with q2 > 0.
4

(a) Seed selection stage

(b) Neighbor infection with q2 = 0
(the disjoint k-cliques model). Nodes
cannot be infected by seeds outside
their own community.

(c) Neighbor infection with q2 > 0.
Any node can be infected by any seed,
even those in external communities.

Figure 1: Illustration of SBIM(n, k, p, q1 , q2 ). In this example, there are m = 4 communities of size
k = 7. Seeds are colored green, and nodes infected by seeds are colored orange.

2.3

Notation

We now define the mathematical notation used in the rest of this paper.
General notation:
â€¢ n: size of the population
â€¢ k: size of each community
â€¢ m , nk : number of communities
â€¢ [n] , {1, 2, . . . , n}
â€¢ X , (X1 , . . . , Xn ) âˆˆ {0, 1}n : infection status vector, where Xv = 1 iff vertex v is infected
â€¢ X ` , (X1 , . . . , X` ), ` âˆˆ [n]
â€¢ XCi âˆˆ {0, 1}, i âˆˆ [m]: infection status of community Ci , where XCi = 1 iff âˆƒv âˆˆ Ci : Xv = 1
â€¢

1A : indicator function for event A

â€¢ H(Â·): entropy of a discrete random variable (in bits) defined as H(X) , âˆ’

P

p(x) log2 p(x)

xâˆˆX

â€¢ hb (Â·): binary entropy function defined as hb (p) , âˆ’p log2 p âˆ’ (1 âˆ’ p) log2 (1 âˆ’ p)
â€¢ We write f (x) â‰º g(x) to denote f (x) = o(g(x)), and f (x)  g(x) to denote f (x) = O(g(x))
Graph notation:
â€¢ G = (V, E): undirected graph with vertex set V, edge set E
5

â€¢ N (v) , {u âˆˆ V : (u, v) âˆˆ E, u 6= v}: set of neighbors of vertex v
â€¢ d(v) , |N (v)|: degree (number of neighbors) of vertex v

3
3.1

Background and Preliminaries
The Group Testing Problem

In the group testing problem, a test corresponds to a subset of individuals S âŠ† [n]. The test
outcome is positive if Xi = 1 for some i âˆˆ S; that is, if at least one member of S is infected.
Otherwise, the test outcome is negative. Equivalently, the outcome is a binary variable Y âˆˆ {0, 1}
given by a boolean OR operation over S:
_
Y =
Xi .
(1)
iâˆˆS

A group testing algorithm or scheme describes how to select subsets S1 , . . . , ST such that the
infection statuses X1 , . . . , Xn can be determined from the corresponding outcomes Y1 , . . . , YT . In
adaptive schemes, the choice of each St is allowed to depend on {St0 : t0 < t}. Moreover, due
to the underlying randomness in the Xi in our probabilistic setting, the total number of tests T
performed by any adaptive scheme is a random variable. In this work, we assume that test outcomes
are noiseless (meaning that we get to observe the Yt as given in (1)), and we require a scheme to
exactly recover X1 , . . . , Xn (i.e., achieve zero error).

3.2

Marginal Infection Probability for General Graphs

Let G = (V, E) be any finite, undirected graph. For the infection model that we study in this paper,
the marginal infection probability of a given vertex v can be characterized in terms of its degree
d(v).
Lemma 1. Let G = (V, E) be a finite, undirected graph. Under G, the infection status of a vertex
v âˆˆ V is Xv âˆ¼ Bernoulli(rv ), where
rv , P(Xv = 1) = 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)d(v) .

(2)

Under a general graph, different nodes may have different degrees and hence different marginal
probabilities of infection. From (2), we see that rv is monotonically non-decreasing with d(v). Note
also that the Xv can be correlated.

3.3

Information-Theoretic Lower Bound

A fundamental result in probabilistic group testing (see [6] or [17, Theorem 1]) is that any adaptive
algorithm which is guaranteed to identify all infected members of the population, assuming noiseless
test results, requires a number of tests T satisfying
E[T ] â‰¥ H(X1 , . . . , Xn ),
6

(3)

where H(X1 , . . . , Xn ) is the Shannon entropy of X = (X1 , . . . , Xn ). This bound highlights the
intimate connection between adaptive group testing and source coding. Indeed, the outcomes of
the adaptive tests can be viewed as a binary, variable-length source code for X; the lower bound
then follows directly from existing results in data compression (see [26, Eqn. 5.38]). Equation (3)
will serve as the point of departure for the lower bounds on E[T ] that we derive in this paper. The
key challenge will be to obtain good approximations to H(X) in the presence of correlated Xv .

4
4.1

Algorithms
Binary Splitting Algorithm

Most adaptive group testing algorithms are based on the idea of recursively splitting the population
until all infected members are found. The most standard such algorithm is known as binary
splitting, which finds one infected member at a time by repeatedly halving the population. This
algorithm identifies all infected members using Î± log2 n + O(Î±) adaptive tests (see [27], [19, p.24],
or [28, Theorem 1.2]), where Î± is the number of infected members. This algorithm works even
when Î± is unknown, and is most effective in the sparse regime, Î± = Î˜(nÎ² ), where Î² âˆˆ [0, 1). We
treat binary splitting as our baseline in this paper, and we will utilize the following performance
guarantee.
Lemma 2. In a population of size n with Î± infected members, where Î± â‰¥ 1, the binary splitting
algorithm is guaranteed to identify all infected members using at most Î±dlog2 ne â‰¤ Î± log2 n + Î±
tests.

4.2

Graph-Aware Algorithm

As an alternative to standard adaptive procedures such as binary splitting, we consider a simple
adaptive scheme which leverages the community structure of the graph. The algorithm works
by mixing samples within each community, employing binary splitting to identify the infected
communities, and finally performing binary splitting again within each infected community to find
the infected members.
Adaptive Graph-Aware Algorithm
1. Mix samples within each community.
2. Run binary splitting on the mixed samples to determine which communities contain at least
one infected member.
3. For each positive test from Step 2, perform binary splitting within the corresponding community to identify infected members.
Under what circumstances should we expect the graph-aware algorithm to outperform binary
splitting? Suppose the underlying interaction network and infection model follow SBIM(n, k, p, q1 , q2 ).
If the seed selection probability p is small, then we expect only a few of the m = n/k communities
7

to contain a seed. This means that after the neighbor infection stage, several of the communities are
likely to contain no infected members at all, especially if q2 is small. In Step 2 of the graph-aware
algorithm, we can efficiently rule out these uninfected communities from consideration. In Step 3,
we need only perform group testing within each of the remaining communities (which contain at
least one infected member). In contrast, the binary splitting algorithm ignores the community
structure (specifically, the fact that entire communities are likely to be uninfected), and is therefore
unlikely to enjoy the same benefits as the graph-aware algorithm under these circumstances. We
will rigorously verify this intuition in the upcoming sections.

5

Disjoint k-Cliques Model

We first consider the graph consisting of disjoint k-cliques (i.e., complete subgraphs of size k, with
no edges between different cliques). That is, we have a graph G = (V, E) with V = [n], where we
assume n is divisible by k. There are m , n/k disjoint cliques with k nodes each, denoted by
C1 , C2 , . . . , Cm where |Ci | = k, âˆ€i âˆˆ [m]. The seed selection probability is p âˆˆ (0, 1], the transmission
rate within a community is q âˆˆ [0, 1], and no transmissions are possible between communities.

5.1

Information-Theoretic Lower Bound

Recall that E[T ] â‰¥ H(X1 , . . . , Xn ) for any adaptive group testing algorithm which exactly identifies
the infected individuals using T tests. Since the infection statuses across the m disjoint cliques are
independent, we have E[T ] â‰¥ m Â· H(X1 , . . . , Xk ), where without loss of generality we assume
C1 = [k]. Thus, obtaining a lower bound on E[T ] reduces to lower bounding H(X1 , . . . , Xk ), i.e.,
the entropy corresponding to a single k-clique. The following lemma lower bounds H(X1 , . . . , Xk )
in terms of a binomial random variable, which then leads to the asymptotic lower bound given in
Theorem 1 below.
Lemma 3. Under the disjoint k-cliques model, the number of tests T required to identify the infected
individuals is lower bounded as


E[T ] â‰¥ m Â· EZ (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q)Z ,
where Z âˆ¼ Binom (k, p) .
Theorem 1. Let Z âˆ¼ Binom (k, p) and assume kp  1 and q 

âˆš

r 1 
.
1
kÂ· log kÂ·p

Then






1
Z
2
EZ (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q)
 k Â· p Â· q Â· log k + log log
.
kÂ·p
Upon combining Lemma 3 with the above theorem, we see that the number of tests T needed
to recover all infected members in the disjoint k-cliques graph (in the specified parameter regime)
is lower bounded as

 
1
2
E[T ]  m Â· k Â· p Â· q Â· log k + log log
.
kp
8

Note that another lower bound is given by


(a)
E[T ] â‰¥ H(X1 , . . . , Xn ) â‰¥ H(XC1 , . . . , XCm ) = m Â· hb 1 âˆ’ (1 âˆ’ p)k

(4)

where (a) uses
 the fact that XC1 , . . . , XCm are a function of X1 , . . . , Xn . Furthermore, since kp  1,
we have hb 1 âˆ’ (1 âˆ’ p)k  k Â· p Â· log2 (1/kp). We summarize the refined lower bound in the following
corollary:
Corollary 1. Assume kp  1 and q 

1
r
 .
1
k log kp

Then under the disjoint k-cliques model, the

number of tests T required to identify the infected individuals is lower bounded as




 1  
1
2
, m Â· k Â· p Â· log
E[T ]  max m Â· k Â· p Â· q Â· log k + log log
,1 .
kÂ·p
kÂ·p

5.2
5.2.1

Algorithm Analysis
Binary Splitting

The following result bounds the expected number of tests used by the binary splitting algorithm
under the disjoint k-cliques model.
Theorem 2. Under the disjoint k-cliques model, the binary splitting algorithm identifies all infected
individuals using T tests, where

 

E[T ] â‰¤ m Â· k Â· log2 m + log2 k + 1 Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1 .
Proof. Let K be the number of infected nodes (which is a random variable in our setting). Then
n
n
hX
i X
E[K] = E
Xi =
P(Xi = 1) = n Â· r
i=1

i=1

where r = 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1 by Lemma 1. Invoking Lemma 2 yields the result.
Asymptotic analysis: Using Theorem 2, we find that the average complexity of binary splitting

is O m Â· k 2 Â· p Â· (q + 1/k) Â· (log2 m + log2 k) since


E[T ]  m Â· k Â· (log m + log k) Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1


(a)
â‰¤ m Â· k Â· (log m + log k) Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ kpq)
= m Â· k Â· (log m + log k) Â· (p + kpq âˆ’ kp2 q)
â‰¤ m Â· k Â· (log m + log k) Â· (p + kpq)

1
= m Â· k 2 Â· p Â· (log m + log k) Â·
+q
k
where in (a) we use the fact that (1 + x)k â‰¥ 1 + kx for x â‰¥ âˆ’1, k â‰¥ 1.

9

(5)

5.2.2

Graph-Aware Algorithm

Next, we provide an upper bound on the expected number of tests performed by the graph-aware
algorithm.
Theorem 3. Under the disjoint k-cliques model, the graph-aware algorithm identifies all infected
individuals using T tests, where

 


 

E[T ] â‰¤ m Â· log2 m + 1 Â· 1 âˆ’ (1 âˆ’ p)k + n Â· log2 k + 1 Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1
Asymptotic analysis: Using Theorem 3 and the fact that (1 + x)k â‰¥ 1 + kx for x â‰¥ âˆ’1, k â‰¥ 1,
we find that the average complexity of the graph-aware algorithm is given by

1
E[T ]  m log m Â· k Â· p + m Â· k 2 log k Â· p Â· q +
.
(6)
k

5.3

Discussion

We summarize the expected number of tests of binary splitting and the graph-aware algorithm, as
well as the information-theoretic lower bound, in Table 1.
Binary splitting
Graph-aware
Lower bound



m log m Â· k 2 Â· p Â· q + k1 + m Â· k 2 log k Â· p Â· q + k1

m log m Â· k Â· p + m Â· k 2 log k Â· p Â· q + k1
 

 
1
1
2
m Â· k Â· p Â· log kp + m Â· k Â· p Â· q Â· log k + log log kp
+1

Table 1: Upper and lower bounds on the expected number of tests in the disjoint k-cliques model.
Next, we discuss different parameter regimes where 1) the lower bound holds, 2) the graphaware algorithm is order-optimal (i.e., the lower bound is tight), and 3) the graph-aware algorithmâ€™s
average complexity is strictly better than binary splittingâ€™s. As stated in Corollary 1, the lower
bound holds when kp  1 and q  r 1   . The next corollary specifies the regime where the
k log

1
kp

graph-aware algorithm is tight:
Corollary 2. If the following conditions hold:
1. kp  mâˆ’Î± for some fixed Î± âˆˆ (0, 1),
2.

1
k

q

1
r
 ,
1
k log kp

then the lower bound is tight, and moreover the graph-aware algorithm is order-optimal.
 
 
1
1
 Î± log m into the lower bound and using the fact that k  log kp
from
Proof. Plugging log kp
the second condition (which implies log k  log log m) yields
E[T ]  m log m Â· k Â· p + m Â· k 2 Â· p Â· q Â· (log k + log log m) + 1
 m log m Â· k Â· p + m Â· k 2 log k Â· p Â· q,
10

and applying q  1/k to the bound for the graph-aware algorithm yields
E [T ]  m log m Â· k Â· p + m Â· k 2 log k Â· p Â· q.

Finally, we specify the regime where the graph-aware algorithm outperforms binary splitting:
Corollary 3. If the following conditions hold:
1. log m  log k,
2. kq  1,
then the graph-aware algorithmâ€™s
average
o complexity is asymptotically strictly better than binary
n
log m
splittingâ€™s by a factor of min kq, log k .
Proof. Under the above conditions, binary splittingâ€™s average complexity is
m log m Â· k 2 Â· p Â· q
whereas the graph aware algorithmâ€™s average complexity is
n
o
max m log m Â· k Â· p, m Â· k 2 log k Â· p Â· q .
{z
} |
{z
}
|
(a)

(b)

Both terms are strictly smaller than the binary splitting bound. We see that (a) saves a factor of
m
kq  1, while (b) saves a factor of log
log k  1.
We summarize the different parameter regimes in Table 2.
kp  1 and q 

Lower boundâ€™s conditions

1
r
k log

Tightness conditions

kp 

mâˆ’Î±



1
kp



r
 
1
and 1  kq  k/ log kp

log m  log k and kq  1

Improvement conditions

Table 2: Parameter regimes of interest for the disjoint k-cliques model.
The main takeaway is that the graph-aware algorithm can potentially improve testing efficiency
compared to standard binary splitting when (i) there are several moderately sized communities
in the network, and (ii) the transmission rate within each clique is â€œintermediate.â€ Additionally,
the graph-aware algorithm is order-optimal when the infected population is sparse. However, note
that when q  1/k, i.e., the intra-clique transmission rate is small, then the bounds for binary
splitting and the graph-aware algorithm are order-wise equivalent. This suggests that knowledge of
the community structure may not help in this regime. Intuitively, this makes sense because when
q is small, the infection statuses of the vertices are â€œmostly independent.â€

11

6

Stochastic Block Infection Model

Having studied the disjoint k-cliques model, we now turn to the fully general SBIM(n, k, p, q1 , q2 ),
where p âˆˆ (0, 1] and q1 , q2 âˆˆ [0, 1].

6.1

Information-Theoretic Lower Bound

Similar to Lemma 3 and Theorem 1, we obtain the following lower bounds for adaptive group
testing over the SBIM.
Lemma 4. Under SBIM(n, k, p, q1 , q2 ), the number of tests T required to identify the infected individuals is lower bounded as
h

i
0
E[T ] â‰¥ m Â· EZ,Z 0 (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z
,
where Z âˆ¼ Binom (k, p) and Z 0 âˆ¼ Binom(n âˆ’ k, p) are independent.
Theorem 4. Let Z âˆ¼ Binom(k, p) and Z 0 âˆ¼ Binom(n âˆ’ k, p) be independent, and assume
1. n Â· p Â· q2  1,
2. n Â· p  1,
3. k Â· p Â· q1  1,
4. q1 â‰¤

r  1   .
1
2k log kp
+1

Then the following lower bound holds:





i
h
0
1
1
 mk 2 pq2 log
EZ,Z 0 (k âˆ’ Z)Â·hb 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z
+ k 2 p Â· q1 log
.
npq2
q1 + npq2
Therefore, the number of tests T needed to recover all infected members over SBIM(n, k, p, q1 , q2 ),
in the parameter regime specified in Theorem 4, is lower bounded as




1
1
2
2
2
E[T ]  m Â· k Â· p Â· q2 Â· log
+ m Â· k Â· p Â· q1 Â· log
.
(7)
n Â· p Â· q2
q1 + n Â· p Â· q2
Remark 2. Recall that in the disjoint k-cliques model, we obtained an additional lower bound in
Equation (4) given by H (XC1 , ..., XCm ), which dominates when kp  mâˆ’Î± . However, under the
general SBIM, the {XC1 , ..., XCm } are no longer mutually independent, rendering the analysis of
H (XC1 , ..., XCm ) intractable. Therefore, we suspect that the lower bound given in Theorem 4 is not
tight when kp is small.

6.2

Algorithm Analysis

To analyze binary splitting and the graph-aware algorithm over the SBIM, we begin by extending
Lemma 1.
Lemma 5. The marginal probability of infection for every vertex v under SBIM(n, k, p, q1 , q2 ) is
given by
P(Xv = 1) = 1 âˆ’ (1 âˆ’ p) Â· (1 âˆ’ p Â· q1 )kâˆ’1 Â· (1 âˆ’ p Â· q2 )nâˆ’k .
12

6.2.1

Binary Splitting

Next, we generalize the bound in Theorem 2 to the SBIM. Notice that in both the Theorem 5
bound and the asymptotic bound derived below, we recover the corresponding bounds from the
disjoint k-cliques setting when we set q1 = q, q2 = 0.
Theorem 5. Under SBIM(n, k, p, q1 , q2 ), the binary splitting algorithm identifies all infected individuals using T tests, where


E[T ] â‰¤ n Â· (log2 n + 1) Â· 1 âˆ’ (1 âˆ’ p) Â· (1 âˆ’ p Â· q1 )kâˆ’1 Â· (1 âˆ’ p Â· q2 )nâˆ’k .
Proof. Let K be the number of infected nodes. Then
n
n
hX
i X
E[K] = E
Xi =
P(Xi = 1) = n Â· r
i=1

i=1

where r = 1 âˆ’ (1 âˆ’ p) Â· (1 âˆ’ p Â· q1 )kâˆ’1 Â· (1 âˆ’ p Â· q2 )nâˆ’k by Lemma 5. Invoking Lemma 2 yields the
result.
Asymptotic Analysis: Using the fact that (1 + x)k â‰¥ 1 + kx for x â‰¥ âˆ’1, k â‰¥ 1, we have


E[T ]  n Â· log n Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ k Â· p Â· q1 ) Â· (1 âˆ’ (n âˆ’ k) Â· p Â· q2 )


â‰¤ n Â· log n Â· (n âˆ’ k) Â· p Â· q2 + k Â· p Â· q1 + p + k Â· (n âˆ’ k) Â· p3 Â· q1 Â· q2

1
â‰¤ m Â· k 2 Â· p Â· (log m + log k) Â·
+ q1 + m Â· q2 + m Â· k Â· p2 Â· q1 Â· q2
k
6.2.2

(8)

Graph-Aware Algorithm

First, we provide a lemma needed to prove the upper bound for the graph-aware algorithm in
Theorem 6. Again, note that by setting q1 = q, q2 = 0 in Theorem 6 and the resulting asymptotic
bound, we recover the corresponding bounds from the disjoint k-cliques setting.
Lemma 6. Let XC1 be the indicator variable which equals 1 if at least one member of community
C1 is infected. Then under SBIM(n, k, p, q1 , q2 ),
!

 nâˆ’k
k
k
P(XC1 = 1) = 1 âˆ’ (1 âˆ’ p) Â· 1 âˆ’ p Â· 1 âˆ’ (1 âˆ’ q2 )
.
Theorem 6. Under SBIM(n, k, p, q1 , q2 ), the graph-aware algorithm identifies all infected individuals using T tests, where
!
!


 nâˆ’k
n 
E[T ] â‰¤ Â· log2 (n/k) + 1 Â· 1 âˆ’ (1 âˆ’ p)k Â· 1 âˆ’ p Â· 1 âˆ’ (1 âˆ’ q2 )k
k

 

+ n Â· log2 k + 1 Â· 1 âˆ’ (1 âˆ’ p) Â· (1 âˆ’ p Â· q1 )kâˆ’1 Â· (1 âˆ’ p Â· q2 )nâˆ’k .
Proof. Same steps as the proof of Theorem 3 (given in the Appendix), except using Lemma 5 and
Lemma 6 wherever P(X1 = 1) and P(XC1 = 1) are needed, respectively.
13

Asymptotic Analysis:
Let T1 and T2 be the first and second terms in the Theorem 6 bound,
respectively. Using the fact that (1 âˆ’ q2 )k â‰¥ 1 âˆ’ kq2 , we have


1 âˆ’ p Â· 1 âˆ’ (1 âˆ’ q2 )k â‰¥ 1 âˆ’ p Â· k Â· q2 ,
so



nâˆ’k 
k
k
E[T1 ]  m log m Â· 1 âˆ’ (1 âˆ’ p) Â· 1 âˆ’ p 1 âˆ’ (1 âˆ’ q2 )


 m log m Â· 1 âˆ’ (1 âˆ’ p)k Â· (1 âˆ’ p Â· k Â· q2 )nâˆ’k
 m log m Â· (1 âˆ’ (1 âˆ’ k Â· p) Â· (1 âˆ’ (n âˆ’ k) Â· p Â· k Â· q2 ))
 m log m Â· (k Â· p + n Â· p Â· k Â· q2 ) .
Following the previous asymptotic analysis for binary splitting,
1

E[T2 ]  m Â· k 2 log k Â· p Â·
+ q1 + m Â· q2 + m Â· k Â· p 2 Â· q1 Â· q2 .
k
Therefore,


1

E[T ]  m log m Â· k Â· p Â· 1 + m Â· k Â· q2 + m Â· k 2 log k Â· p Â·
+ q1 + m Â· q2 + m Â· k Â· p2 Â· q1 Â· q2 . (9)
k

6.3

Discussion

One regime where the graph-aware algorithmâ€™s average complexity is asymptotically strictly better
than that of binary splitting is
1. log m  log k
2. kq1  1
3.

(i) 1  mkq2
or
(ii) mkq2  1 and mkq2 â‰º kq1 

1
.
p2

Suppose conditions 1, 2, and 3(i) hold. Binary splittingâ€™s average complexity (8) becomes
m log m Â· k 2 Â· p Â· q1
whereas the graph-aware algorithmâ€™s average complexity (9) becomes
n
o
max m log m Â· k Â· p, m Â· k 2 log k Â· p Â· q1 .
The first term in the graph-aware bound improves upon binary splittingâ€™s complexity by a factor
m
of kq1  1, and the second term improves by a factor of log
log k  1. These are the same savings
14

(a)

(b)

(c)

(d)

Figure 2: Performance comparison between binary splitting and the graph-aware algorithm under
the SBIM with n = 1000, k = 20, and different values of p, q1 , q2 . Theoretical upper and lower
bounds are also shown.
we obtained in Corollary 3 in the disjoint k-cliques setting; indeed, the bounds themselves match
those in Corollary 3. This is not very surprising because the SBIM asymptotically behaves like the
disjoint k-cliques model under condition 3(i), i.e., when q2 is very small.
However, improvements are still made by the graph-aware algorithm in a more intermediate
regime for q2 . Under condition 3(ii), binary splittingâ€™s average complexity is the same as above,
and the graph-aware algorithmâ€™s complexity becomes
n
o
max m2 log m Â· k 2 Â· p Â· q2 , m Â· k 2 log k Â· p Â· q1 ,
n
o
q1
log m
which represents an improvement over binary splitting by a factor of min mÂ·q
,
 1.
log k
2

7

Numerical Simulations

We implemented the binary splitting and graph-aware algorithms and evaluated their performance
over random instances of the SBIM. The population size was set to n = 1000, and p was varied
15

over the interval [0, 0.1]. We ran 20 trials for each value of p, where a trial consists of generating
an instance from SBIM(n, k, p, q1 , q2 ), then observing the number of tests used by binary splitting
and the graph-aware algorithm to identify the infected nodes. We estimated the lower bound from
Lemma 4 by averaging over many independent samples of Z âˆ¼ Binom(k, p) and Z 0 âˆ¼ Binom(n âˆ’
k, p).
Figure 2 shows some representative plots of the estimated E[T ] as a function of p, with k = 20
and different values of q1 , q2 . The error bars show Â± one standard deviation of the values of T
obtained for a particular value of p. For comparison, we also plot the theoretical upper bounds
from Theorem 5 and Theorem 6; we find that these bounds remain quite faithful to the empirical
results. Additionally, the graph-aware algorithm consistently outperforms binary splitting. For
example, in Figure 2b, at p â‰ˆ 0.07, binary splitting has surpassed the individual testing threshold
with an average of 1271.5 tests, whereas the graph-aware algorithm uses an average of 813.8 tests;
this represents a 36% reduction in testing. The graph-aware algorithm also seems to enjoy lower
variance than binary splitting.
In Figure 3, we fix q1 = 0.01, q2 = 0.001, and vary the community size k âˆˆ {10, 50, 100}. The
graph-aware algorithm seems to perform most favorably for moderate values of k, such as k = 20
(as shown in Figure 2c) or k = 50, i.e., when there are several moderately sized communities in the
network. This is consistent with our earlier theoretical results.
Although the graph-aware algorithm improves significantly upon binary splitting, there is still a
sizable gap between the graph-aware bound and the lower bound shown in the plots. This suggests
that in the non-asymptotic regime, either the lower bound is not tight or better algorithms exist.

8

Conclusion

In this paper, we investigated the group testing problem over networks with community structure.
Motivated by diseases such as COVID-19, we proposed a network infection model to capture how
certain diseases are introduced into a population and subsequently transmitted through close contact between individuals. Our proposed group testing algorithm, which exploits the structure of
the underlying graph, provably outperforms the network-oblivious binary splitting algorithm, and
is even order-optimal in certain parameter regimes.
We conclude with some practical considerations and future directions. First, we note that the
community-structured networks studied in this paper can model populations at different scales:
the â€œcommunitiesâ€ can be schools, families, counties, etc. The insights from our work can also be
extended to more general networks in the real world, where the communities may not be known
in advance. In such instances, one might use the following pipeline to efficiently identify infected
individuals in the population: 1) estimate the network from data (e.g., Facebook social graph); 2)
run a clustering algorithm to identify communities in the network; 3) perform graph-aware group
testing using the previously identified communities. An interesting direction for future work is to
explore the efficacy of such an approach. Other directions of interest include designing non-adaptive
group testing schemes for networks, studying graph-aware group testing under noisy test outcomes,
and extending our infection model to longer time horizons (e.g., SIR or SIS-type infection models).

16

(a)

(b)

(c)

Figure 3: Performance comparison between binary splitting and the graph-aware algorithm under
the SBIM with n = 1000, q1 = 0.01, q2 = 0.001, and different values of p, k. Theoretical upper and
lower bounds are also shown.

Acknowledgement
The authors would like to thank Professor Sennur Ulukus for inspiring discussions on this topic.
This work was supported in part by NSF Grant #1817205, a Cisco Systems Stanford Graduate
Fellowship, and a National Semiconductor Corporation Stanford Graduate Fellowship.

References
[1] R. Dorfman, â€œThe detection of defective members of large populations,â€ The Annals of Mathematical Statistics, vol. 14, no. 4, pp. 436â€“440, 1943.
[2] J. Ellenberg, â€œFive people. One test. This is how you get there.â€ https://www.nytimes.com/
2020/05/07/opinion/coronavirus-group-testing.html. Accessed: July 31, 2020.

17

[3] S. Mallapaty, â€œThe mathematical strategy that could transform coronavirus testing.â€ https:
//www.nature.com/articles/d41586-020-02053-6. Accessed: July 31, 2020.
[4] Centers for Disease Control and Prevention, â€œInterim guidance for use of pooling procedures in SARS-CoV-2 diagnostic, screening, and surveillance testing.â€ https://www.cdc.gov/
coronavirus/2019-ncov/lab/pooling-procedures.html. Accessed: December 21, 2020.
[5] C. A. Hogan, M. K. Sahoo, and B. A. Pinsky, â€œSample pooling as a strategy to detect community transmission of sars-cov-2,â€ JAMA, vol. 323, no. 19, pp. 1967â€“1969, 2020.
[6] J. Wolf, â€œBorn again group testing: Multiaccess communications,â€ IEEE Transactions on
Information Theory, vol. 31, no. 2, pp. 185â€“191, 1985.
[7] T. Berger, N. Mehravari, D. Towsley, and J. Wolf, â€œRandom multiple-access communication
and group testing,â€ IEEE Transactions on Communications, vol. 32, no. 7, pp. 769â€“779, 1984.
[8] H. A. Inan, P. Kairouz, and A. Ozgur, â€œSparse group testing codes for low-energy massive
random access,â€ in Allerton Conference on Communication, Control, and Computing, pp. 658â€“
665, 2017.
[9] H. A. Inan, P. Kairouz, and A. Ozgur, â€œEnergy-limited massive random access via noisy group
testing,â€ in IEEE International Symposium on Information Theory (ISIT), pp. 1101â€“1105,
2018.
[10] H. A. Inan, S. Ahn, P. Kairouz, and A. Ozgur, â€œA group testing approach to random access
for short-packet communication,â€ in IEEE International Symposium on Information Theory
(ISIT), pp. 96â€“100, 2019.
[11] S. Ubaru and A. Mazumdar, â€œMultilabel classification with group testing and codes,â€ in International Conference on Machine Learning, pp. 3492â€“3501, 2017.
[12] Y. Zhou, U. Porwal, C. Zhang, H. Q. Ngo, X. Nguyen, C. ReÌ, and V. Govindaraju, â€œParallel feature selection inspired by group testing,â€ Advances in Neural Information Processing
Systems, vol. 27, pp. 3554â€“3562, 2014.
[13] D. Malioutov and K. Varshney, â€œExact rule learning via boolean compressed sensing,â€ in
International Conference on Machine Learning, pp. 765â€“773, 2013.
[14] A. C. Gilbert, M. A. Iwen, and M. J. Strauss, â€œGroup testing and sparse signal recovery,â€ in
Asilomar Conference on Signals, Systems and Computers, pp. 1059â€“1063, 2008.
[15] A. Emad and O. Milenkovic, â€œPoisson group testing: A probabilistic model for nonadaptive streaming boolean compressed sensing,â€ in IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), pp. 3335â€“3339, 2014.
[16] M. Sobel and P. A. Groll, â€œGroup testing to eliminate efficiently all defectives in a binomial
sample,â€ Bell System Technical Journal, vol. 38, no. 5, pp. 1179â€“1252, 1959.
18

[17] T. Li, C. L. Chan, W. Huang, T. Kaced, and S. Jaggi, â€œGroup testing with prior statistics,â€
in IEEE International Symposium on Information Theory (ISIT), pp. 2346â€“2350, 2014.
[18] T. Kealy, O. Johnson, and R. Piechocki, â€œThe capacity of non-identical adaptive group testing,â€ in Allerton Conference on Communication, Control, and Computing, pp. 101â€“108, 2014.
[19] D. Du, F. K. Hwang, and F. Hwang, Combinatorial Group Testing and Its Applications, vol. 12.
World Scientific, 2000.
[20] N. J. Harvey, M. Patrascu, Y. Wen, S. Yekhanin, and V. W. Chan, â€œNon-adaptive fault diagnosis for all-optical networks via combinatorial group testing on graphs,â€ in IEEE International
Conference on Computer Communications (INFOCOM), pp. 697â€“705, 2007.
[21] M. Cheraghchi, A. Karbasi, S. Mohajer, and V. Saligrama, â€œGraph-constrained group testing,â€
IEEE Transactions on Information Theory, vol. 58, no. 1, pp. 248â€“262, 2012.
[22] A. Karbasi and M. Zadimoghaddam, â€œSequential group testing with graph constraints,â€ in
IEEE Information Theory Workshop (ITW), pp. 292â€“296, 2012.
[23] B. Spang and M. Wootters, â€œUnconstraining graph-constrained group testing,â€ arXiv preprint
arXiv:1809.03589, 2018.
[24] P. Nikolopoulos, T. Guo, C. Fragouli, and S. Diggavi, â€œCommunity aware group testing,â€
arXiv preprint arXiv:2007.08111, 2020.
[25] P. W. Holland, K. B. Laskey, and S. Leinhardt, â€œStochastic blockmodels: First steps,â€ Social
Networks, vol. 5, no. 2, pp. 109â€“137, 1983.
[26] T. M. Cover and J. A. Thomas, Elements of Information Theory, 2nd Edition. Wiley, 2006.
[27] L. Baldassini, O. Johnson, and M. Aldridge, â€œThe capacity of adaptive group testing,â€ in IEEE
International Symposium on Information Theory (ISIT), pp. 2676â€“2680, 2013.
[28] M. Aldridge, O. Johnson, and J. Scarlett, â€œGroup testing: An information theory perspective,â€
arXiv preprint arXiv:1902.06002, 2019.

19

Appendix
A

Proof of Lemma 1

Let Yv be the indicator random variable of whether vertex v is a seed. First, we have
P(Xv = 1) = P(Xv = 1 | Yv = 1) Â· P(Yv = 1) +P(Xv = 1 | Yv = 0) Â· P(Yv = 0)
{z
} | {z }
|
=p

=1

= p + (1 âˆ’ p) Â· P(Xv = 1 | Yv = 0).
Given that v is not a seed, Xv = 1 if and only if v is infected by one of its neighbors. Hence,
P(Xv = 1 | Yv = 0) = P{v is infected by a neighbor}
= 1 âˆ’ P{v isnâ€™t infected by any neighbor}
Y
P{v isnâ€™t infected by u}
=1âˆ’
uâˆˆN (v)

Y 

=1âˆ’


1 âˆ’ P{v is infected by u}

uâˆˆN (v)

Y 

=1âˆ’


1 âˆ’ P{v is infected by u | Yu = 1} Â· P(Yu = 1)

uâˆˆN (v)

Y

=1âˆ’

(1 âˆ’ pq)

uâˆˆN (v)

= 1 âˆ’ (1 âˆ’ pq)d(v) .


B
B.1

Lower Bounds for the Disjoint k-Cliques Model
Proof of Lemma 3

Since H(X1 , ..., Xn ) = m Â· H(X1 , ..., Xk ), it suffices to lower bound H(X1 , ..., Xk ). Notice that




X
k
k
k
k
H (X1 , ..., Xk ) â‰¥ H (X1 , ..., Xk |Y1 , ..., Yk ) =
P Y = yk Â· H X Y = y .
y k âˆˆ{0,1}k

Observe that after conditioning on the locations of the seeds, X1 , ..., Xk are mutually indepen

P
dent. Moreover, by symmetry, both P Y k = y k and H X k Y k = y k depend on i yi , (i.e., the
empirical distribution of y k ). Indeed, the marginal distribution of Xi can be specified as follows:
ï£±

 ï£²1,
if yi = 1,
P
P Xi = 1|Y k = y k =
ï£³1 âˆ’ (1 âˆ’ q)( i yi ) , if y = 0,
i

and the conditional entropy is


k

k

H X Y =y

k



!
=

kâˆ’

X

yi

i

20



P
Â· hb 1 âˆ’ (1 âˆ’ q)( i yi ) ,

P
where hb (Â·) is the binary entropy function. Therefore, by writing Z = i Yi , we have




H X k Y k = EZ (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q)Z ,

(10)

where Z âˆ¼ Binom (k, p) .


B.2

Proof of Theorem 1

Let f (q) =

log(q)
log(1âˆ’q) ,

so that f (q) solves 1 âˆ’ (1 âˆ’ q)Z = 1 âˆ’ q. Then we bound (10) by






EZ (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q)Z â‰¥ EZ (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q)Z Â· 1{1â‰¤Zâ‰¤f (q)}
(a)



â‰¥ hb (q) Â· EZ (k âˆ’ Z) Â· 1{1â‰¤Zâ‰¤f (q)}

â‰¥ hb (q) (EZ [k âˆ’ Z] âˆ’ kP {Z = 0} âˆ’ kP {Z > f (q)})




= k Â· hb (q) (1 âˆ’ p) 1 âˆ’ (1 âˆ’ p)kâˆ’1 âˆ’ P {Z > f (q)}
(b)



â‰¥ k Â· hb (q) (1 âˆ’ p) (k âˆ’ 1)p âˆ’ (k âˆ’ 1)2 p2 âˆ’ P {Z > f (q)}

(c)



k
Â· hb (q) (k Â· p âˆ’ P {Z > f (q)}) ,
2

(11)

where (a) is due to the fact that hb (x) â‰¥ hb (q) for all q â‰¤ x â‰¤ 1 âˆ’ q, (b) holds since (1 âˆ’ p)r â‰¤ eâˆ’pr
and ex â‰¤ 1 + x + x2 for x â‰¤ 1, and (c) is due to the assumption p  1/k.
We then upper bound P {Z > f (q)} by Hoeffdingâ€™s inequality:

 !

 !


f (q) 2 (a)
f (q) 2
f (q)2 (b) 1
 k Â· p,
â‰¤ exp âˆ’2k
â‰¤ exp âˆ’
P {Z > f (q)} â‰¤ exp âˆ’2k p âˆ’
k
2k
2k
2
where (a) holds since by assumption k Â· p Â· q  1, so
 
 
q
1
q
1
k Â· p  log
â‰¤
log
â‰¤ f (q),
2
q
1âˆ’q
q
and (b) holds due to the assumption q 



EZ (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q)

Z



âˆš

r 1 
.
1
kÂ· log kÂ·p

Plugging into (11) yields

 

 
1
1
2
 k Â· p Â· q Â· log
 k Â· p Â· q Â· log k + log log
,
q
kp
2

where in the last inequality we use the assumption q 

âˆš

r 1 

1
kÂ· log kÂ·p

again.


C

Proof of Theorem 3

Let T1 and T2 be the number of tests performed, respectively, in Step 2 and Step 3 of the graphaware algorithm. Specifically, T1 is equal to the number of tests used by binary splitting to identify
21

the infected k-cliques, and T2 is the number of tests to identify infected individuals within each
infected clique. Note that T = T1 + T2 . We will bound E[T1 ] and E[T2 ] separately.
Let Y be the number of infected k-cliques. We have

n
n 
E[Y ] = Â· P(XC1 = 1) = Â· 1 âˆ’ (1 âˆ’ p)k .
k
k
Taking Lemma 2 with n = n/k and Î± = Y gives
T1 â‰¤ (log2 (n/k) + 1) Â· Y
so that

 

n 
Â· log2 (n/k) + 1 Â· 1 âˆ’ (1 âˆ’ p)k .
k
For the second stage of the algorithm, let Zi denote the number of tests used by binary splitting
n/k
P
to identify all infected members of the ith clique. Since T2 =
Zi Â· 1{XC =1} , we have
E[T1 ] â‰¤

i=1

E[T2 ] =

n/k
X

E[Zi Â· 1{XC

i

i

=1} ]

i=1

n
Â· E[Z1 Â· 1{XC1 =1} ]
k
n
= Â· P(XC1 = 1) Â· E[Z1 | XC1 = 1]
k

n 
= Â· 1 âˆ’ (1 âˆ’ p)k Â· E[Z1 | XC1 = 1].
k
Let M denote the number of infected members of C1 . Then by Lemma 2,
=

E[Z1 | XC1 = 1] â‰¤ (log2 k + 1) Â· E[M | XC1 = 1]
and, assuming without loss of generality that C1 = [k],
E[M | XC1 = 1] =

k
X

P(Xj = 1 | XC1 = 1)

j=1

= k Â· P(X1 = 1 | XC1 = 1)
P(X1 = 1, XC1 = 1)
P(XC1 = 1)
P(X1 = 1)
=kÂ·
P(XC1 = 1)
1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1
=kÂ·
1 âˆ’ (1 âˆ’ p)k
=kÂ·

where in the last line we invoke Lemma 1. Putting everything together gives


E[T2 ] â‰¤ n Â· (log2 k + 1) Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1
and therefore
 


 

n 
E[T ] â‰¤ Â· log2 (n/k) + 1 Â· 1 âˆ’ (1 âˆ’ p)k + n Â· log2 k + 1 Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1 .
k

22

D

Lower Bounds for the SBIM

D.1

Proof of Lemma 4

Notice that
H (X1 , ..., Xn ) â‰¥ H (X1 , ..., Xn |Y1 , ..., Yn ) =

X

P (Y n = yn ) Â· H (X n |Y n = y n ) .

y n âˆˆ{0,1}n

Observe that after conditioning on the locations of the seeds, X1 , ..., Xn are mutually independent.
Moreover, for i âˆˆ C` , the marginal distribution of Xi can be specified as follows:
ï£±
ï£²1,
if yi = 1,
P
P
P (Xi = 1|Y n = y n ) =
ï£³1 âˆ’ (1 âˆ’ q1 ) jâˆˆC` yj (1 âˆ’ q2 ) j6âˆˆC` yj , if yi = 0.
Writing z` ,

P

jâˆˆC`

yj , the conditional entropy is
n

H (X |Y

n

n

=y )=

m
X



P
(k âˆ’ z` ) Â· hb 1 âˆ’ (1 âˆ’ q1 )z` (1 âˆ’ q2 ) `0 6=` z`0 ,

`=1
i.i.d.

i.i.d.

where hb (Â·) is the binary entropy function. Since Yi âˆ¼ Ber(p), we have Z` âˆ¼ Binom(k, p) and
hence

i
h
0
,
(12)
H (X n |Y n ) = EZ,Z 0 m Â· (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z
where Z âˆ¼ Binom (k, p) and Z 0 âˆ¼ Binom (n âˆ’ k, p).


D.2

Proof of Theorem 4

First we assume n Â· p Â· q2  1, and let  âˆˆ (0, 1) be a value to be specified. Define
zâˆ— ,

1/2 âˆ’ np(1 + )q2
.
q1

Then as long as Z and Z 0 satisfy the following two conditions
1. {np(1 âˆ’ ) â‰¤ Z 0 â‰¤ np(1 + )},
2. Z â‰¤ z âˆ— ,
we have

0
1
â‰¥ Z Â· q1 + Z 0 Â· q2 â‰¥ 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z .
2

23

(13)



0
0
Since 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z is an increasing function of Z and Z 0 , hb 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z
must increase with Z and Z 0 if they satisfy the above conditions. Therefore, we have
h

i
0
EZ,Z 0 (k âˆ’ Z)hb 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z
h


i
0
â‰¥EZ,Z 0 (k âˆ’ Z)hb 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z Â· 1{0â‰¤Zâ‰¤z âˆ— } Â· 1{np(1âˆ’)â‰¤Z 0 â‰¤np(1+)}
h


i
0
â‰¥ EZ,Z 0 (k âˆ’ Z)hb 1 âˆ’ (1 âˆ’ q2 )Z Â· 1{Z=0} Â· 1{np(1âˆ’)â‰¤Z 0 â‰¤np(1+)} +
{z
}
|
(a)

h


i
0
EZ,Z 0 (k âˆ’ Z)hb 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z Â· 1{1â‰¤Zâ‰¤z âˆ— } Â· 1{np(1âˆ’)â‰¤Z 0 â‰¤np(1+)} .
{z
}
|

(14)

(b)

We will pick  = 21 . Then (a) can be bounded by




n2 p
2
1 âˆ’ 2 Â· exp âˆ’
(a) â‰¥ k Â· hb q2 Â· np(1 âˆ’ ) âˆ’ (q2 Â· np(1 âˆ’ ))
3





2
n p
1
1 âˆ’ 2 Â· exp âˆ’
 k npq2 (1 âˆ’ ) log
npq2 (1 âˆ’ )
3



1
 k npq2 log
npq2
where in the first inequality we use
1. Z 0 â‰¥ np(1 âˆ’ )
0

0

2. (1 âˆ’ q2 )Z â‰¤ eâˆ’q2 Â·Z â‰¤ 1 âˆ’ q2 Â· Z 0 + (q2 Â· Z 0 )2
3. Chernoff bound on Z 0 ,
and in the third inequality we assume np  1. Next, (b) can be bounded by







n2 p
2
(b) â‰¥ hb q1 + npq2 (1 âˆ’ ) âˆ’ (q1 + npq2 (1 âˆ’ )) Â· EZ (k âˆ’ Z)1{1â‰¤Zâ‰¤z âˆ— } Â· 1 âˆ’ 2 Â· exp âˆ’
3




1
 (q1 + npq2 ) log
Â· EZ (k âˆ’ Z)1{1â‰¤Zâ‰¤z âˆ— } .
q1 + npq2


We will now lower bound EZ (k âˆ’ Z)1{1â‰¤Zâ‰¤z âˆ— } as in Theorem 1. Observe that


EZ (k âˆ’ Z)1{1â‰¤Zâ‰¤z âˆ— } â‰¥ EZ [k âˆ’ Z] âˆ’ kP {Z = 0} âˆ’ kP {Z â‰¥ z âˆ— }


â‰¥ k 1 âˆ’ p âˆ’ (1 âˆ’ p)k âˆ’ P {Z â‰¥ z âˆ— }
 k (kp âˆ’ P {Z â‰¥ z âˆ— }) .
Finally, applying Hoeffdingâ€™s inequality to P {Z â‰¥ z âˆ— } yields
ï£«
!2 ï£¶
 !

1
âˆ— 2
âˆ’
npq
(1
+
)
z
2
ï£¸
P {Z â‰¥ z âˆ— } â‰¤ exp âˆ’2k p âˆ’
= exp ï£­âˆ’2k p âˆ’ 2
k
q1 k

2 !

 (2)
(1)
1
kp
1
 exp âˆ’2k
â‰¤
,
= exp âˆ’
2
2q1 k
2
2kq1
24

(15)

where in (1) we use the facts that 1) n Â· p Â· q2  1 and 2) p 

1
q1 k ,

and (2) holds when

1
q1 â‰¤ r
  
.
1
2k Â· log kp + 1
Plugging into (15) yields


EZ (k âˆ’ Z)1{1â‰¤Zâ‰¤z âˆ— }  k 2 p,

(16)

and thus by putting together our bounds on (a) and (b) in (14), we arrive at
h

i
0
EZ,Z 0 (k âˆ’ Z)hb 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z





1
1
2
+ k p Â· (q1 + npq2 ) log
â‰¥k npq2 log
npq2
q1 + npq2




1
1
â‰¥mk 2 pq2 log
+ k 2 p Â· q1 log
.
npq2
q1 + npq2

(17)
(18)
(19)


E
E.1

Proofs of Additional Lemmas
Proof of Lemma 5

Let Yv be the indicator random variable of whether vertex v is a seed, and assume without loss of
generality that v âˆˆ C1 . We have
P(Xv = 1) = P(Xv = 1 | Yv = 1) Â· P(Yv = 1) +P(Xv = 1 | Yv = 0) Â· P(Yv = 0)
{z
} | {z }
|
=p

=1

= p + (1 âˆ’ p) Â· P(Xv = 1 | Yv = 0)
and
P(Xv = 1 | Yv = 0) = P{v is infected by a neighbor}
Y
=1âˆ’
P{v isnâ€™t infected by u}
uâˆˆN (v)

=1âˆ’

Y 


1 âˆ’ P{v is infected by u}

uâˆˆN (v)

=1âˆ’

Y 


1 âˆ’ P{v is infected by u | Yu = 1} Â· P(Yu = 1)

uâˆˆN (v)

!
=1âˆ’

Y

(1 âˆ’ p Â· q1 )

!
Â·

Y

(1 âˆ’ p Â· q2 )

w6âˆˆC1

uâˆˆC1 \{v}

= 1 âˆ’ (1 âˆ’ p Â· q1 )kâˆ’1 Â· (1 âˆ’ p Â· q2 )nâˆ’k .

25

E.2

Proof of Lemma 6

Let A be the event that no member of community C1 is selected as a seed, and let B be the event
that some member of C1 is infected by an individual outside C1 . We further denote by Bu the event
that vertex u infects some member of C1 , where u 6âˆˆ C1 . Note that XC1 = 1 if and only if either Ac
occurs or A âˆ© B occurs. Moreover, A and B are independent events. We have that P(A) = (1 âˆ’ p)k ,
and thus
P(XC1 = 1) = P(Ac ) + P(A) Â· P(B)
= 1 âˆ’ (1 âˆ’ p)k + (1 âˆ’ p)k Â· P(B)
= 1 âˆ’ (1 âˆ’ p)k Â· (1 âˆ’ P(B)).
Finally, we compute P(B) as
Y
P(B) = 1 âˆ’
P(Buc )
u6âˆˆC1

=1âˆ’

Y 
u6âˆˆC1

=1âˆ’

Y 

P(Buc | Yu = 1) Â· P(Yu = 1) + P(Buc | Yu = 0) Â· P(Yu = 0)
| {z } |
{z
} | {z }
=p

=1



=1âˆ’p


1 âˆ’ p + p Â· P(Buc | Yu = 1)

u6âˆˆC1

=1âˆ’

Y 

1 âˆ’ p + p Â· (1 âˆ’ q2 )k



u6âˆˆC1

=1âˆ’



k

1 âˆ’ p Â· 1 âˆ’ (1 âˆ’ q2 )



!nâˆ’k
.


26

