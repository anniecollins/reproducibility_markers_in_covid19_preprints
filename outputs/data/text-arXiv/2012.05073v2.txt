COVID-19 Detection in Chest X-Ray Images using a New Channel Boosted
CNN
Saddam Hussain Khan1,2, Anabia Sohail1,2, and Asifullah Khan*1,2,3
1

Pattern Recognition Lab, Department of Computer & Information Sciences, Pakistan Institute of Engineering &
Applied Sciences, Nilore, Islamabad 45650, Pakistan,
2
PIEAS Artificial Intelligence Center (PAIC), Pakistan Institute of Engineering & Applied Sciences, Nilore,
Islamabad 45650, Pakistan
3
Center for Mathematical Sciences, Pakistan Institute of Engineering & Applied Sciences, Nilore, Islamabad 45650,
Pakistan
asif@pieas.edu.pk

Abstract
COVID-19 is a highly contagious respiratory infection that has affected a large population across
the world and continues with its devastating consequences. It is imperative to detect COVID-19 at
the earliest to limit the span of infection. In this work, a new classification technique ‚ÄúCB-STMRENet‚Äù based on deep Convolutional Neural Network (CNN) and Channel Boosting is proposed
for the screening of COVID-19 in chest X-Rays. In this connection, to learn the COVID-19
specific radiographic patterns, a new convolution block based on split-transform-merge (STM) is
developed. This new block systematically incorporates region and edge-based operations at each
branch to capture the diverse set of features at various levels, especially those related to region
homogeneity, textural variations, and boundaries of the infected region. The learning and
discrimination capability of the proposed CNN architecture is enhanced by exploiting the Channel
Boosting idea that concatenates the auxiliary channels along with the original channels. The
auxiliary channels are generated from the pre-trained CNNs using Transfer Learning. The
effectiveness of the proposed technique ‚ÄúCB-STM-RENet‚Äù is evaluated on three different datasets
of chest X-Rays namely CoV-Healthy-6k, CoV-NonCoV-10k, and CoV-NonCoV-15k. The
performance comparison of the proposed CB-STM-RENet with the existing techniques exhibits
high performance both in discriminating COVID-19 chest infections from Healthy, as well as,
other types of chest infections. CB-STM-RENet provides the highest performance on all these
three datasets; especially on the stringent CoV-NonCoV-15k dataset. The good detection rate
(97%), and high precision (93%) of the proposed technique suggest that it can be adapted for the
diagnosis

of

COVID-19

infected

patients.

The

test

code

is

available

at

https://github.com/PRLAB21/COVID-19-Detection-System-using-Chest-X-Ray-Images.
Keywords: Coronavirus, COVID-19, SARS-CoV-2, Chest X-ray, Channel boosting, Split-transform-Merge,
Convolutional Neural Network, and Transfer Learning.

1

1. Introduction
Coronavirus disease 2019 (COVID-19) is a severe and continuing pandemic, which broke out in
December 2019 and has now affected the whole world. This new pathogenic viral infection is
caused by a new virus from the family of coronavirus (CoV) and named as SARS-CoV-2. COVID19 is highly contagious, which quickly transmits from one individual to another, even before the
onset of clinical symptoms [1], [2]. COVID-19 causes a respiratory illness that can be
asymptomatic, or its clinical manifestation can span across fever, cough, myalgia, respiratory
impairment, pneumonia, acute respiratory distress and even death in severe cases [3], [4].
The lack of a standard vaccine and no approved treatment by the Food and Drug Authority
necessitates the early detection of COVID-19 both for proper care of patients and to control
infection spread. The standard approach approved by World Health Organization for virus antigen
detection is Polymerase Chain Reaction (PCR); however, it suffers from False-negative rate
depending upon viral load and sampling strategy (30‚Äì70% True-positive rate) [5], [6].
Radiological imaging (X-Ray, CT) is used as an assisted screening tool to counter the Falsenegative rate of PCR in symptomatic patients. It acts as a first-line diagnostic measure for patients
suspected with COVID-19 and suffering from a chest infection [7]. In addition to diagnostic
importance, X-Ray and CT images are used for severity assessment and patients‚Äô follow-up [8],
[9]. Chest imaging manifests radiological patterns specific to COVID-19. These patterns
commonly include multifocal and ground-glass opacities and multi-lobular involvement. In
patients with severe COVID-19 pneumonia, lung density increases, and its characteristic marks
become incomprehensible because of consolidation [10], [11]. X-Ray imaging, as compared to CT
imaging, is a quick and easy method that is widely available at low cost. The facility of X-Ray
imaging is commonly available in hospitals, and the availability of its portable devices make it
easy to perform X-Rays imaging in deprived areas, field hospitals and intensive care units [12].
The visual assessments of radiographic images of COVID-19 patients require trained radiologists.
In an ongoing pandemic, the high prevalence of COVID-19 cases in addition to other pulmonary
disorders and a limited number of experts is a considerable burden on radiologists. The inevitable
importance of a timely diagnosis stresses the need for the development of automated assistance
tool that can facilitate radiologists in the initial screening.

2

Deep learning (DL) models are a powerful tool for the analysis of medical images. DL models
have been successfully used for the analysis of thoracic radiologic images for diagnosis of
pneumonia, respiratory distress, tuberculosis, and segmentation of infected regions [13]‚Äì[17].
In this work, a deep Channel Boosted (CB) CNN based new classification technique ‚ÄúCB-STMRENet‚Äù is proposed for the automatic detection of COVID-19 in chest X-Rays. CB-STM-RENet
is a new CNN architecture and is able to discriminate both COVID-19 chest infections from
healthy, as well as other types of chest infections. The proposed technique exploits the systematic
usage of the region and edge-based (RE) feature extraction in our newly proposed convolutional
block. Additionally, to enhance the classification performance, the concept of Channel Boosting
is exploited. In this regard, for the creation of the boosted channels, Transfer Learning (TL) based
fine-tuned pre-trained CNN models are used as auxiliary learners. This combination of the original
and auxiliary channels boosts the chest infection discrimination capability of the proposed CBSTM-RENet. The significant contributions of this research are:
1.

A novel CNN block based on the concept of Split-Transform-Merge (STM) is developed

that systematically exploits the concept of RE-based (RE) feature extraction in each block of the
proposed STM-RENet.
2.

The systematic use of the RE-based operations at each branch of the STM block captures

the diverse set of features at various levels, especially those related to region homogeneity, textural
variations, and boundaries of the infected region.
3.

The idea of Channel Boosting is exploited using TL in addition to the new STM block to

reduce the False negatives and thus achieved a significant improvement in STM-RENet
performance.
4.

The final proposed classification technique ‚ÄúCB-STM-RENet‚Äù thus exploits the

effectiveness of a diverse set of RE-based features, Channel Boosting, and TL.
5.

We have also assembled three different datasets from the publicly available chest X-Ray

images and named them as CoV-Healthy-6k, CoV-NonCoV-10k, and CoV-NonCoV-15k,
respectively.
The remainder of this paper is structured as follows. Related work is presented in section 2. Dataset
description is given in section 3. The detailed framework of the proposed deep CB-CNN for
COVID-19 detection is explained in section 4. Section 5 provides the experimental setup. Section
6 discusses the results and comparative studies. Finally, section 7 concludes the paper.
3

2. Related Work
DL models have shown impressive performance in the medical field. Therefore, DL is primarily
employed in the detection of COVID-19 infection in diverse ways. Several researchers have
employed CNN to speed up the analysis of COVID-19 infected images [18]‚Äì[21]. Initially,
COVID-19 labelled datasets were small in size and generally not suitable for practical
implementation. Therefore, the existing pre-trained CNN architectures such as AlexNet, VGG,
ResNet, Dense Net, Inception etc. have been employed on COVID-19 classification challenge.
These architectures have been fine-tuned on problem-specific COVID dataset using TL and
achieved optimal results. However, because of the non-availability of the consolidated data
repository, these models have been evaluated on various small size datasets gathered from GitHub
and Open-I respiratory, etc.
In one of the early works, a pre-trained ResNet-50 model has been fine-tuned using TL on small
X-ray chest dataset and achieved 98% accuracy [16]. Similarly, a pre-trained ResNet-101 CNN
architecture has been used to detect abnormality in chest X-ray images using different dataset and
reported sensitivity (0.77), and accuracy (71.9%), respectively [22]. Moreover, a pre-trained
inception network has been employed for the prediction of COVID-19 and reported accuracy
(89.5%) [23]. The model has been employed on the multi-class problem like Healthy, COVID-19
non-affected patients, and COVID-19 affected pneumonia patients.
Similarly, nineteen layers of deep CNN architecture has been developed based on the idea of
ResNet, named as COVID-Net and employed on the same dataset [24]. COVID-Net model showed
good accuracy (92%) but at a low detection rate (sensitivity) (87%). Similarly, COVID-CAPS
designed based on the concept of Capsule Net and achieved accuracy (98%), sensitivity (0.80),
and AUC (0.97) [25]. An existing deep CNN Darknet network has been proposed for an accurate
diagnosis of COVID infection on the complex dataset. In this work, darknet performed both binary
(COVID-19 vs. Non-COVID-19) and multi-class (COVID-19, Pneumonia, and Healthy)
discrimination. Darknet achieved a detection accuracy (98%) and (87%) for binary and multi-class,
respectively [26].
In the most recent studies, a framework of four pre-trained existing CNN networks has been
employed for identifying the presence of COVID-19 in X-ray images. These models (ResNet18,
ResNet50, Squeeze Net, and DenseNet121) are fine-tuned on COVID-Xray-5k dataset. On
average, these models obtained approximately a detection rate of (98%) [27]. A pre-trained CNN
4

model like ResNet-50 has also been used for deep feature extraction and ML classification (SVM).
This model is fine-tuned on small COVID-19 dataset using TL and reported an accuracy of 95%
[28]. Similarly, a pre-trained ResNet-152 has been used for deep feature extraction in combination
with Random Forest and XGBoost classifiers, achieving accuracy (97.3%) and (97.7%),
respectively [29].

3. Dataset Details
COVID-19 is a new disease and to the best of our knowledge, up till now, no consolidated data is
available. Consequently, we collected radiologists‚Äô authenticated X-Rays images from different
publically accessible data repositories. The details of the datasets are mentioned in this section.
The examples of X-Rays images from the assembled dataset are illustrated in Figure 1.

A

B

C

Figure 1: Panel (A), (B), and (C) show COVID-19 infected, Non-COVID-19 infected, and Healthy images,
respectively.

3.1.

CoV-Healthy-6k Dataset

For this study, initially COVID-19 vs Healthy individuals‚Äô dataset has been built. The COVID-19
X-Ray images used in this research are collected from [30]. The Healthy individuals‚Äô dataset is
obtained both from [30] and Kaggle repository [31]. The accessed repositories contain images
from multiple publicly accessible sources, and hospitals, and these X-Rays images are verified
from the radiologists. The new dataset consists of 3224 images from both COVID-19 infected and
5

Healthy individuals. The advantage of using an open-source dataset is that it can easily implement
other different DL models to evaluate the effectiveness of the proposed CB-STM-RENet
technique.

3.2.

CoV-NonCoV-10k Dataset

This dataset consisted of COVID-19 infected and non-COVID-19 chest X-Ray images. The nonCOVID-19 X-Rays includes both Healthy and non-COVID-19 infected individuals. These X-Ray
images are collected from [30], whereas the same set of Healthy samples are also used as defined
in CoV-Healthy-6k Dataset. In non-COVID-19 samples, the disease is caused by different viral
and bacterial infections other than COVID-19. This dataset contains total 9538 images, out of
which both the COVID-19 and non-COVID-19 class includes the 4769 images.

3.3.

CoV-NonCoV-15k Dataset

We also build a stringent dataset to evaluate the robustness of the proposed technique. For this,
CoV-NonCoV-10k dataset is augmented by including additional samples from [27]. This new
CoV-NonCoV-15k dataset is imbalanced and consisted of 15127 total images; out of which 5223
and 9904 images are from COVID-19 infected and non-COVID-19 individuals, respectively.

4. Deep Channel Boosting based CNN for COVID-19 Detection
This work proposes a new technique based on CB-CNN for automated detection of COVID-19 in
chest X-Ray images. The proposed technique targets the discrimination of COVID-19 infected
from both non-COVID-19 infected and Healthy individual. In this regard, a new CNN classifier
based on novel split-transform-merge (STM) block [32] is developed that systematically
implements RE-based operations for the learning of COVID-19 specific patterns and terms as
‚ÄúSTM-RENet‚Äù. This architecture is also known as ‚ÄúPIEAS Classification Network-4 (PC Net-4)‚Äù.
The learning capacity of the proposed CNN is enhanced using Channel Boosting to improve the
detection rate while maintaining high precision. The CB-CNN is termed as ‚ÄúCB-STM-RENet‚Äù or
‚ÄúPIEAS Classification Network-5 (PC Net-5)‚Äù. The performance of the proposed technique is
compared with several existing CNNs by implementing them from scratch as well as by adapting
them using TL on X-Ray dataset for COVID-19 detection. The overall workflow is shown in
Figure 2.

6

Training Phase

Proposed CNN Models
ÔÇ∑
ÔÇ∑
80%
Training Dataset

Data
Augmentation

Training

Implementation of
Existing CNN Models

Training Data
80%

ÔÇ∑
ÔÇ∑
ÔÇ∑

Chest X-Ray Images
Healthy
COVID-19
Non-COVID-19
ÔÇ∑
ÔÇ∑
ÔÇ∑

STM-RENet
CB-STM-RENet

Hyperparameter Setting

ÔÇ∑
ÔÇ∑

TL based Fine-tunning
Training from Scratch

20%
Validation Dataset

COVID-19
Dataset
(CoV-Healthy-6k)
(CoV-NonCoV-10k)
(CoV-NonCoV-15k)

Preprocessing

Model Evaluation

Validation
Data

Trained Model

Chest X-ray Images
Test Data
20%

Developed
Model

Classification Output
ÔÇ∑

COVID-19 infected

ÔÇ∑

Non-COVID-19 Infected

ÔÇ∑
ÔÇ∑
ÔÇ∑
ÔÇ∑
ÔÇ∑
ÔÇ∑
ÔÇ∑
ÔÇ∑

Model Evaluation
Accuracy
F-score
MCC
Sensitivity
Specificity
Precision
AUC
PR/ROC Curve

Testing Phase

Figure 2: Overview of the workflow for the proposed COVID-19 detection framework.

4.1.

Proposed STM-RENet

Deep CNNs have been rigorously used in image processing applications because of their strong
pattern mining ability. CNN exploits the structural information of the image using convolution
operation and dynamically extracts feature hierarchies according to the target application. Multiple
innovations in the CNN design have raised their use in medical image classification, detection and
pattern discovery tasks [33], [34].
In this work, a new COVID-19 pneumonia specific CNN architecture has been proposed based on
the novel split-transform-merge block (STM) and RE-based feature extraction proposed in Khan
et al. study [35]. This new architecture is named as STM based RENet (STM-RENet) for COVID19. The architectural design of the new block is illustrated in Figure 3. The proposed block consists
of three sub-branches. The concept of RE-based feature extraction is systematically employed at
each branch using max and average pooling in combination with convolution and ReLU activation
to capture discriminating feature at a high level.
The STM-RENet mine the patterns from X-Ray dataset by splitting the input into three branches
learns the region-specific variations and their characteristic boundaries using RE-based operator
and finally merges the output from multiple paths using concatenation operation. In STM-RENet,
7

two STM blocks with the same topology are stacked one after another to extract a diverse set of
abstract level features. This idea helps the STM-RENet in extracting a diverse set of variations in

Fully Connected Layers

Proposed Split, Transform, Merge-Region and Edge based CNN Network

Chest X-ray Image
3

128,128

256,256

Conv
Block B1

Conv
Block B2

Dropout
50%

768

64,64
224
x
224

Conv
Block C1

Conv
Block A

+

Conv
Block C2

+

Feature
Maps

Dropout
20%

1x1x768

Conv
Block E
Softmax

Conv
Block D1

Image Layer

Conv
Block D2

64

768

Conv Block C 1, 2 Conv Block D 1, 2

Conv Block E

Conv Block A

Conv Block B 1, 2

Conv 3√ó3

Conv 3√ó3

Conv 3√ó3

Conv 3√ó3

Conv 3√ó3

BatchNorm

BatchNorm

BatchNorm

BatchNorm

BatchNorm

RelU

RelU

RelU

RelU

RelU

Conv 3√ó3

Average-Pooling

Average-Pooling

Max-Pooling

Conv 1√ó1

BatchNorm

Conv 3√ó3

BatchNorm

RelU

BatchNorm

RelU

Max-Pooling

RelU

Global Average
Pooling

Healthy, Non_COVID-19

Deep CNN Classification Model (STM-RENet)

COVID-19 Infected

the input feature maps.

Max-Pooling

Figure 3: Architectural details of the proposed STM-RENet.

4.2.

Proposed Channel Boosted STM-RENet (CB-STM-RENet)

Radiographic data exhibits large variations in images and thus, a robust CNN model is required
for good discrimination. The discrimination ability of the proposed STM-RENet is enhanced by
exploiting Channel Boosting. The idea of Channel Boosting is proposed by Khan et al. [36], [37]
for solving complex problems. In the proposed technique, Channel Boosting is performed by
generating auxiliary feature channels from two pre-trained networks via TL to improve the
performance of STM-RENet.
4.2.1. Significance of using Transfer Learning (TL)
TL is a type of machine learning, which allows leveraging the knowledge of existing techniques
for new tasks. TL can be exploited in different ways for multiple tasks, but the most often
employed approaches for knowledge utilization are 1) instance-based TL, 2) feature-space based
TL, 3) parameter exploitation based TL, and 4) Relation-knowledge based TL [38], [39].

8

Feature space-based TL is often used for solving image classification and pattern recognition
related tasks. For this, pre-trained architecture is adapted to the target domain by fine-tuning
network layers or by adding additional layers according to the target domain task. This is also
commonly known as domain adaptation. Supervised domain adaptation-based TL using pretrained deep CNNs has been substantially adopted for solving medical imaging tasks. This can
help in providing a useful set of feature descriptors that are learnt from the source domain to
effectively apply in a target domain by adapting them to target task via fine-tuning. This reduces
the calibration efforts (hyper-parameter selection) that are particularly difficult in deep CNNs
because of the vast number of hyperparameters and considerable training time [40], [41].
4.2.2. Significance of using Auxiliary Channels
CNNs with varied architectural designs have different feature learning capacities. Multiple
channels learnt from different deep CNNs exhibit multi-level information. These channels
represent different patterns, which may help in precisely explaining class-specific characteristics.
Combination of diverse-level abstractions learned from multiple channels may improve both the
global and local representation of the image. The concatenation of auxiliary and original channels
gives the idea of intelligent feature-space based ensemble; whereby the single learner takes the
final decision by analyzing multiple image specific patterns [42].
4.2.3. Proposed Channel Boosted Architectural Design
In this work, we utilized supervised domain adaptation-based TL by exploiting two different pretrained deep CNNs. These deep CNNs vary in architectural design that enables each model to learn
different feature descriptors and encapsulate diverse level of radiological information from chest
X-Ray. These two fine-tuned deep CNNs are termed as auxiliary learner 1 and 2. The purpose of
Channel Boosting is to improve the discriminative capability of the proposed CB-STM-RENet
model. The architectural details of CB-STM-RENet are illustrated in Figure 4.
ùê∂ùëè= ùêΩùëò (ùê∂ùëñ , [ùëÖ1 , ‚Ä¶ , ùëÖùëó ], [ùëâ1 , ‚Ä¶ , ùëâùëó ])

(1)

ùêπùëôùëò = ùêπùëê (ùê∂ùëè , ùëìùëô )

(2)

In Eq. (1), ùê∂ùëñ shows the STM-RENet original channels, whereas ùëÖùëó ùëéùëõùëë ùëâùëó are up to ùëó ùë°‚Ñé number
of auxiliary channels generated by TL-based based fine-tuned auxiliary learner 1 and 2,
respectively. ùêΩùëò (.) concatenates the original STM-RENet channels with the auxiliary channels to
generates the CB input ùê∂ùëè for the classifier. Eq. (2) illustrates the ùëò ùë°‚Ñé resultant feature maps ùêπùëôùëò ,
which is generated by convolving the boosted input ùê∂ùëè with filter of ùëìùëô layer in convolutional block
9

E. At the end of convolutional block E, global average-pooling is used to minimize the connection
intensity. Finally, the fully connected layers are employed to preserve the prominent features, and
dropout layers are used to reduce overfitting.
Deep CNN Classification Model (CB-STM-RENet)
512

128,128

256,256,256

512,512,512

512,512,512

Conv
Block 1

Conv
Block 2

Conv
Block 3

Conv
Block 4

Conv
Block 5

Auxiliary
Learner 1

Feature
Maps

Proposed Split, Transform, Merge-Region and Edge based CNN

Chest X-ray Image
3

128,128

256,256

Conv
Block B1

Conv
Block B2

Conv
Block A

Conv
Block C2

+

+

+

Feature
Maps

Feature
Maps

Softmax

64 (Activation
Function)

1000
512

TL-Based fine-tuned Pre-Trained Model 2

64

64,64

128,128

256,256

512,512,512

Conv
Block

Conv
Block
N,N

Conv
Block
M,N

Conv
Block
M,N

Conv
Block
M,N

Auxiliary
Learner 2

Feature
Maps

Conv Block 1, 2

Conv Block 3, 4, 5

Conv 3√ó3

Conv 3√ó3

Conv Block

RelU

RelU

Conv 7√ó7

Conv 3√ó3

Conv 1√ó1

Conv 3√ó3

Conv 3√ó3

Conv 3√ó3

BatchNorm

BatchNorm

BatchNorm

BatchNorm

RelU

ReLU

ReLU

ReLU

Max-Pooling

Conv 3√ó3

Conv 3√ó3

BatchNorm

BatchNorm

RelU
Max-Pooling

Conv 3√ó3

Dropout
20%

Conv
Block E

Conv
Block D2

Conv
Block D1

Image Layer

Dropout
50%
1792,
1x1x1792

768

Conv
Block C1

Fully Connected Layers

1792

64,64
224
x
224

Boosted Channels

Conv Block M

COVID-19 Infected

64,64

Healthy, Non_COVID-19

TL-Based fine-tuned Pre-Trained Model 1

Conv Block N

A

RelU
+

+

Max-Pooling
ReLU

ReLU

Figure 4: Architectural details of the proposed CB-STM-RENet.

4.3.

Implementation of the Existing CNNs

For a rigorous assessment of the proposed technique, several existing deep CNNs (Alexnet, VGG16, VGG-19, Google Net, Inceptionv3, Resnet-18, Resnet-50, Squeeze Net, DenseNet-201,
ShuffleNet, Xception) have been implemented and compared with [32], [43]‚Äì[49]. These models
are initially trained from scratch on X-Ray images for a fair comparison with the proposed
technique. The implemented deep models are computationally intensive and require a sufficient
amount of training data. Therefore, TL is exploited to train existing deep CNN techniques
optimally and to achieve substantial performance on a small amount of data. TL is a type of
machine learning, in which models already pre-trained for some task are used for new task by finetuning layers of network or by adding some new target specific layers [50], [51]. In this regard,

10

deep CNN models that are pre-trained for ImageNet classification (natural images dataset) are
fine-tuned on chest X-Ray images for binary classification.

5. Experimental Setup
5.1.

Dataset Division

Holdout cross-validation scheme is used for the training and evaluation of the deep CNN models.
Dataset was divided into train and test set with the ratio of 80:20%. From training dataset, 20% is
reserved for model validation and hyperparameter selection. The final evaluation of the model was
made on the test set, which was kept separate from training and validation dataset.

5.2.

Pre-processing

DL models usually overfit on a small size dataset. Therefore, a sufficient amount of data is
required for the effective training and achieving good generalization. Data augmentation is one of
the effective ways to improve the generalization of the learning model by incorporating multiple
variations in the base dataset. The training samples in this study are augmented by applying
different types of transformations, including horizontal and vertical reflections, rotation, and shear.
All the images have been resized to 224x224x3 before assigning to CNN for training.

5.3.

Model Implementation Details

Deep CNN models were trained in an end-to-end method. Stochastic Gradient Descent (SGD) was
employed as an optimizer function to reduce cross-entropy loss. Softmax was used for the
identification of class probabilities. The training was managed using Piecewise learning rate
scheduler by setting an initial value of learning rate as 0.0001 and momentum of 0.95. Some of
the CNN Models were trained with a batch size of 16 while others were trained with 32 a batch
size for 10 epochs. For each of the CNN model, 95% confidence interval (CI) was computed [52],
[53]. The training time for 1 epoch on NVIDIA GeForce GTX Titan X was ~1-2 hours. All the
implemented models were trained for all the three different datasets and evaluated on their unseen
test sets.

11

5.4.

Working Environment

Deep CNN models were built in MATLAB 2019b, and simulations were performed using DL
library. All the experimentations were done on a CUDA enabled NVIDIA GeForce GTX Titan X
computer, having 64 GB RAM.

6. Results
The performance of the proposed technique is evaluated using several performance metrics on an
unseen test set and benchmark against well-known existing techniques. Learning plots of the
proposed CB-STM-RENet, showing accuracy and loss values for training and validation set is
shown in Figure 5. Learning plot suggests that the proposed CB-STM-RENet technique converges
to optimal values quickly.

Figure 5: Training Plot of proposed CB-STM-RENet technique on CoV-NonCoV-15k dataset.

6.1.

Performance Evaluation Metrics

The discrimination ability of the proposed technique is evaluated using accuracy (Acc) and area
under the receiver operative characteristic (AUC-ROC) curve for a balanced dataset, whereas Fscore and AUC of precision and recall (PR) curve are used as a performance metric for imbalanced
dataset. Additionally, Mathew Correlation Coefficient (MCC) is also computed for unbiased
12

estimation as it considers all the examples from COVID-19 positive and negative classes including
both True (TP, TN) and False (FN, FP) predictions. COVID-19 negative class includes both
Healthy and non-COVID-19 infected individuals. The details of the qualitative measure such as
sensitivity (sen), specificity (spe), precision (pre), TP, TN, FN, and FP are also reported. Examples
from COVID-19 positive and negative class that are correctly predicted are known as TP and TN,
respectively. Similarly, positive, and negative class examples that are misclassified are referred to
as FP and FN, respectively. These performance metrics are mathematically expressed in Eq. 3-8.
Accuracy defines the ratio of COVID-19 positive and COVID-19 negative samples that are
correctly classified. COVID-19 negative can be Healthy individuals or patients having other
viral/bacterial infection. F-score is a measure of accuracy for the imbalanced dataset. Sensitivity
and specificity refer to the ratio of COVID-19 positives and negative patients, respectively that are
correctly identified. Precision is the proportion of COVID-19 positive predictions that are made
actually correct.
Acc =

True COVID‚àí19 positives (TP)+True COVID‚àí19 negatives (TN)
Total samples (TP+TN+FP+FN)

√ó 100

True COVID‚àí19 positives (TP)

Sen = Total COVID‚àí19 positive Samples (TP+FN) √ó 100
True COVID‚àí19 negatives (TN)

Spe = Total COVID‚àí19 negative Samples (TN+FP) √ó 100
True COVID‚àí19 positives (TP)

Pre = True COVID‚àí19 positives (TP)+False COVID‚àí19 positives (FP) √ó 100
Pre√óSen

F ‚àí Score = 2 √ó Pre+Sen
MCC =

6.2.

(TN√óTP)‚àí(FN√óFP)
‚àö((FN+FP)(FP+TP)(FN+TN)(FP+TN))

(3)
(4)
(5)
(6)
(7)
(8)

Performance Analysis on CoV-Healthy-6k

Classification results of the proposed STM-RENet with and without Channel Boosting on the test
set of CoV-Healthy-6k are shown in Table 1. The classification ability in terms of accuracy (STMRENet: 97.98%, CB-STM-RENet: 98.53%), F-score (STM-RENet: 0.98, CB-STM-RENet: 0.98)
and MCC (STM-RENet: 0.96, CB-STM-RENet: 0.97) show that both models can effectively
differentiate the COVID-19 infected patients from Healthy individuals.

13

6.3.

Performance Analysis on CoV-NonCoV-10k

The proposed technique is accessed for its effectiveness in discriminating COVID-19 infected
from non-COVID-19 infected. Therefore, STM-RENet with and without Channel Boosting is
trained on CoV-NonCoV-10k with the same set of parameters and evaluated on the test dataset.
Table 1 illustrates the classification results. The performance analysis using various evaluation
metrics (accuracy: 97.48%, F-score: 0.98, and MCC: 0.95) clearly shows that Channel Boosting
improves the discrimination ability of CNN significantly (shown in Table 1).

6.4.

Performance Analysis on the Stringent CoV-NonCoV-15k

Generalization of the proposed technique is accessed by evaluating the performance on stringent
CoV-NonCoV-15k dataset, as shown in Figure 6. This dataset is imbalance and contains a smaller
number of COVD-19 positive patients as compared to non-COVID-19 and Healthy individuals
both in training and test set. Table 1 shows the detection results. F-score and AUC show good
learning potential and strong discrimination ability of our proposed CB-STM-RENet technique as
compared to STM-RENet.

Figure 6: Panel (A), (B), and (C) show COVID-19 infected, Non-COVID-19 infected, and Healthy images,
respectively. The images are tough to classify because of having high illumination, translational, rotational, occlusion
and missing informational effects.

14

Table 1: Performance evaluation of the proposed techniques on the test set of CoV-Healthy-6k, CoV-NonCoV-10k
and CoV-NonCoV-15k. Standard Error (SE) at 95% CI is reported for sensitivity.
CoV-Healthy-6k
Techniques
STM-RE-CBNet
STM-RENet

Accuracy %

STM-RE-CBNet
STM-RENet

97.48
91.82

STM-RE-CBNet
STM-RENet

96.53
92.04

98.53
97.98

MCC

F-score

0.97
0.98
0.96
0.98
CoV-NonCoV-10k
0.95
0.98
0.84
0.92
CoV-NonCoV-15k
0.93
0.95
0.85
0.90

Sensitivity ¬± SE

Precision

Specificity

0.99¬± 0.02
0.97¬± 0.04

0.98
0.99

0.98
0.99

0.99 ¬± 0.02
0.97 ¬± 0.04

0.98
0.88

0.96
0.86

0.97 ¬± 0.04
0.96 ¬± 0.05

0.93
0.84

0.96
0.90

Table 2: Performance analysis of the best performing existing CNN techniques on the test set of CoV-Healthy-6k,
CoV-NonCoV-10k and CoV-NonCoV-15k. SE at 95% CI is reported for sensitivity.
CoV-Healthy-6k

6.5.

Techniques
Resnet18
VGG_16

Accuracy %

ResNet-18
VGG-16

90.36
86.32

ResNet-18
VGG-16

91.20
88.26

96.59
95.74

MCC

F-score

0.93
0.96
0.91
0.95
CoV-NonCoV-10k
0.81
0.90
0.73
0.86
CoV-NonCoV-15k
0.84
0.88
0.77
0.84

Sensitivity ¬± SE

Precision

Specificity

0.98 ¬± 0.03
0.96 ¬± 0.05

0.95
0.95

0.95
0.95

0.90 ¬± 0.12
0.86 ¬± 0.16

0.90
0.86

0.91
0.87

0.95 ¬± 0.06
0.89 ¬± 0.13

0.82
0.80

0.89
0.88

Comparative Analysis with the Existing CNNs

The significance of the proposed architecture and the impact of Channel Boosting is explored by
implementing existing deep CNN techniques. Existing techniques with different CNN
architectural blocks are implemented from scratch as well as well fine-tuned using TL. Figure 7
and Table 2 shows the result of the best performing techniques on a test set of CoV-Healthy-6k,
CoV-NonCoV-10k and CoV-NonCoV-15k. Table 3 shows the results of all of these existing
techniques on CoV-Healthy-6k. The evaluation metrics suggest that TL improves the learning of
discriminating patterns for COVID-19 classification.
The performance comparison based on accuracy, F-score and MCC suggest that the proposed
technique STM-RENet with and without Channel Boosting outperformed the existing techniques
(Table 1-3). The performance gain of the proposed CB-STM-RENet as compared to the highest
performing existing CNN technique (ResNet) is illustrated in Figure 7.

15

Table 3: Performance of existing CNN techniques on the test set of CoV-Healthy-6k. SE at 95% CI is reported for
sensitivity.
Techniques
ShuffleNet
TL_ShuffleNet
Inceptionv3
TL_Inceptionv3
Alexnet
TL_Alexnet
DenseNet201
TL_DenseNet201
Xception
TL_Xception
TL_ VGG_16
Resnet50
TL_Resnet50
TL_Resnet18

Trained from scratch and TL-based fine-tuned CNNs
Accuracy %

84.88
96.59
93.80
96.51
94.50
95.74
95.50
96.51
95.74
96.43
97.05
96.28
97.05
97.13

MCC

0.75
0.93
0.86
0.93
0.89
0.91
0.91
0.93
0.91
0.93
0.94
0.92
0.94
0.94

F-score

Sensitivity ¬± SE

Precision

Specificity

0.86
0.96
0.93
0.96
0.94
0.95
0.95
0.96
0.95
0.96
0.97
0.96
0.97
0.97

0.95 ¬± 0.06
0.96 ¬± 0.05
0.95 ¬± 0.06
0.97 ¬± 0.04
0.92 ¬± 0.09
0.96 ¬± 0.05
0.95 ¬± 0.06
0.96 ¬± 0.05
0.94 ¬± 0.07
0.96 ¬± 0.05
0.97 ¬± 0.04
0.95 ¬± 0.06
0.97 ¬± 0.04
0.97 ¬± 0.04

0.79
0.97
0.92
0.96
0.97
0.95
0.96
0.97
0.97
0.97
0.97
0.98
0.97
0.98

0.75
0.97
0.92
0.96
0.97
0.95
0.96
0.97
0.97
0.97
0.97
0.98
0.98
0.98

Figure 7: Performance gain of the proposed CB-STM-RENet techniques as compared with the ResNet.

6.6.

Feature Space Visualization

Feature space learnt by the proposed CB-STM-RENet technique and ResNet is analyzed to
understand the decision-making behavior better. Figure 8 shows the projection of the first two
principal components of feature space learned by the proposed CB-STM-RENet and ResNet for
16

the test dataset. It is evident from 2D plots that the proposed CB-STM-RENet shows the highest
discriminative capability (segregation of COVID-19 positive from Non-COVID-19) as compared
with ResNet on the test dataset of CoV-Healthy-6k, CoV-NonCoV-10k and CoV-NonCoV-15k,
respectively.

Figure 8: Feature visualization of the proposed CB-STM-RENet and ResNet on test set dataset.

6.7.

Detection Rate Analysis

Significant detection rate is needed in COVID-19 diagnostic system for limiting infection spread
and patient treatment. Therefore, the detection rate (number of correctly identified COVID-19
positive patients) is explored along with the precision of the proposed technique for all three test
sets. The detection rate and precision for the proposed CB-STM-RENet and best performing
existing techniques are reported in Figure 9 and Table 1-2.
17

The quantitative statistics exhibit that the proposed technique with and without Channel Boosting
achieved the highest detection rate (ranging from 96-99%) with the minimum number of False
positives. CB-STM-RENet significantly decreases the number of False negatives and positives,
as shown in Figure 9. The substantial precision suggests that our proposed technique with Channel
Boosting significantly reduced the miss-detection rate (ranging from 1-7%) and is able to screen
the individuals precisely. High precision means very few Healthy individuals or non-COVID-19
patients will be Falsely diagnosed with COVID-19 infection and thus result in lessening the burden
on radiologists.

6.8.

Evaluation of Diagnostic Ability of the Proposed Technique

ROC and PR curve have a significant role in accessing the optimal diagnostic cutoff for the
classifier. These curves graphically illustrate the discrimination ability of the classifier at a whole
range of possible values [54]. Figure 10 shows ROC curves for the proposed and existing
techniques for CoV-Healthy-6k and CoV-NonCoV-10k datasets, whereas both the curves, ROC
and PR are reported for CoV-NonCoV-15k dataset because of its imbalance nature.
It is evident from ROC and PR based quantitative analysis that the proposed technique, both with
and without Channel Boosting at different cutoffs, shows significant diagnostic accuracy. Figure
10 shows that our proposed technique with Channel Boosting achieved an AUC-ROC of 0.99 on
both the datasets (CoV-Healthy-6k and CoV-NonCoV-10k) and 0.98 AUC-PR for CoV-NonCoV15k. The high value of AUC recommends that the proposed technique with Channel Boosting
upholds high sensitivity with low False detection rate and performs well as a whole for COVID19 patients‚Äô screening.

18

Figure 9: Detection rate analysis of the proposed CB-STM-RENet with the existing CNN techniques.

19

(A)

(B)

(C)

(D)

(E)
Figure 10: ROC and PR Curve for the proposed STM-RENet, CB-STM-RENet, and existing CNN techniques. (A) &
(B) are reported for CoV-NonCOV-15k, (C) for CoV-NonCOV-10k, while (D) & (E) for CoV-Healthy-6k. AUC CI
at 95% is shown in square bracket.

20

7. Conclusion
COVID-19 is a contagious viral infectious disease that has affected a broad spectrum of the global
population. The high transmissibility and pathogenic nature make the early detection of infected
individuals vital for commendably fighting COVID-19. Radiographic examination of chest XRays is one of the fastest and key screening approaches. Chest X-Ray images exhibit characteristic
patterns that are associated with COIVD-19 abnormalities. In this work, a new deep Channel
Boosting based CNN is proposed to detect COVID-19 in chest X-Rays by discerning radiographic
patterns. The proposed technique is benchmarked by implementing and comparing with several
existing CNN architectures and techniques reported in the literature. The performance comparison
of the proposed deep CB-STM-RENet with the existing techniques exhibits high classification
performance, both in discriminating COVID-19 chest infections from Healthy, as well as, other
types of chest infections. CB-STM-RENet provides highest performance on all the three datasets,
especially on stringent CoV-NonCOV-15k dataset (Acc:96.53%, F-score:0.95, MCC:0.93, and
AUC:0.98). The good detection rate (97%), high precision (93%), and low False positives of the
proposed technique suggest that it can be adapted for the diagnosis of COVID-19 infection.

Acknowledgements
This work was conducted with the support of PIEAS IT endowment fund and HEC indigenous Scholarship
under the Pakistan Higher Education Commission (HEC). We would like to thank Abdur Rehman, Ayesha
Salar and Aleena Ijaz from Pattern Recognition Lab (PR-Lab), PIEAS for providing helping material.

Conflicts of interest
Authors declared no conflict of interest.

Code availability
The test code is available at https://github.com/PRLAB21/COVID-19-Detection-System-using-ChestX-Ray-Images.

21

References
[1]

M. A. Shereen, S. Khan, A. Kazmi, N. Bashir, and R. Siddique, ‚ÄúCOVID-19 infection:
Origin, transmission, and characteristics of human coronaviruses,‚Äù Journal of Advanced
Research. 2020.

[2]

C. Huang et al., ‚ÄúClinical features of patients infected with 2019 novel coronavirus in
Wuhan, China,‚Äù Lancet, vol. 395, no. 10223, pp. 497‚Äì506, Feb. 2020.

[3]

A. Shoeibi et al., ‚ÄúAutomated Detection and Forecasting of COVID-19 using Deep
Learning Techniques: A Review,‚Äù arXiv. 2020.

[4]

G. Ye et al., ‚ÄúClinical characteristics of severe acute respiratory syndrome coronavirus 2
reactivation,‚Äù J. Infect., 2020.

[5]

W. Wang et al., ‚ÄúDetection of SARS-CoV-2 in Different Types of Clinical Specimens,‚Äù
JAMA - Journal of the American Medical Association. 2020.

[6]

C. P. West, V. M. Montori, and P. Sampathkumar, ‚ÄúCOVID-19 Testing: The Threat of
False-Negative Results,‚Äù Mayo Clinic Proceedings. 2020.

[7]

T. Ai et al., ‚ÄúCorrelation of Chest CT and RT-PCR Testing in Coronavirus Disease 2019
(COVID-19) in China: A Report of 1014 Cases,‚Äù Radiology, p. 200642, Feb. 2020.

[8]

M.-Y. Ng et al., ‚ÄúImaging Profile of the COVID-19 Infection: Radiologic Findings and
Literature Review,‚Äù Radiol. Cardiothorac. Imaging, 2020.

[9]

S. H. Khan, A. Sohail, A. Khan, and Y. S. Lee, ‚ÄúClassification and Region Analysis of
COVID-19 Infection using Lung CT Images and Deep Convolutional Neural Networks,‚Äù
no. Mcc, 2020.

[10] J. Cleverley, J. Piper, and M. M. Jones, ‚ÄúThe role of chest radiography in confirming covid19 pneumonia,‚Äù The BMJ. 2020.
[11] L. A. Rousan, E. Elobeid, M. Karrar, and Y. Khader, ‚ÄúChest x-ray findings and temporal
lung changes in patients with COVID-19 pneumonia,‚Äù BMC Pulm. Med., 2020.
[12] L. Wang and A. Wong, ‚ÄúCOVID-Net: A Tailored Deep Convolutional Neural Network
Design for Detection of COVID-19 Cases from Chest X-Ray Images,‚Äù Mar. 2020.
[13] H. Jung, B. Kim, I. Lee, J. Lee, and J. Kang, ‚ÄúClassification of lung nodules in CT scans
using three-dimensional deep convolutional neural networks with a checkpoint ensemble
method,‚Äù BMC Med. Imaging, 2018.
[14] A. K. Jaiswal, P. Tiwari, S. Kumar, D. Gupta, A. Khanna, and J. J. P. C. Rodrigues,
22

‚ÄúIdentifying pneumonia in chest X-rays: A deep learning approach,‚Äù Meas. J. Int. Meas.
Confed., 2019.
[15] E. J. Hwang et al., ‚ÄúDevelopment and Validation of a Deep Learning-based Automatic
Detection Algorithm for Active Pulmonary Tuberculosis on Chest Radiographs,‚Äù Clin.
Infect. Dis., 2019.
[16] S. Liang et al., ‚ÄúDeep-learning-based detection and segmentation of organs at risk in
nasopharyngeal carcinoma computed tomographic images for radiotherapy planning,‚Äù Eur.
Radiol., 2019.
[17] S. Yeung et al., ‚ÄúA computer vision system for deep learning-based detection of patient
mobilization activities in the ICU,‚Äù npj Digit. Med., 2019.
[18] A. Narin, C. Kaya, and Z. Pamuk, ‚ÄúAutomatic Detection of Coronavirus Disease (COVID19) Using X-ray Images and Deep Convolutional Neural Networks,‚Äù Mar. 2020.
[19] I. D. Apostolopoulos and T. A. Mpesiana, ‚ÄúCovid-19: automatic detection from X-ray
images utilizing transfer learning with convolutional neural networks,‚Äù Phys. Eng. Sci.
Med., no. 0123456789, pp. 1‚Äì6, 2020.
[20] M. E. H. Chowdhury et al., ‚ÄúCan AI help in screening Viral and COVID-19 pneumonia?,‚Äù
vol. XX, Mar. 2020.
[21] E. E.-D. Hemdan, M. A. Shouman, and M. E. Karar, ‚ÄúCOVIDX-Net: A Framework of Deep
Learning Classifiers to Diagnose COVID-19 in X-Ray Images,‚Äù Mar. 2020.
[22] M. Z. Che Azemin, R. Hassan, M. I. Mohd Tamrin, and M. A. Md Ali, ‚ÄúCOVID-19 Deep
Learning Prediction Model Using Publicly Available Radiologist-Adjudicated Chest X-Ray
Images as Training Data: Preliminary Findings,‚Äù Int. J. Biomed. Imaging, 2020.
[23] S. Wang et al., ‚ÄúA deep learning algorithm using CT images to screen for Corona Virus
Disease (COVID-19),‚Äù medRxiv, p. 2020.02.14.20023028, Apr. 2020.
[24] L. Wang, Z. Q. Lin, and A. Wong, ‚ÄúCOVID-Net: a tailored deep convolutional neural
network design for detection of COVID-19 cases from chest X-ray images,‚Äù Sci. Rep., 2020.
[25] P. Afshar, S. Heidarian, F. Naderkhani, A. Oikonomou, K. N. Plataniotis, and A.
Mohammadi, ‚ÄúCOVID-CAPS: A Capsule Network-based Framework for Identification of
COVID-19 cases from X-ray Images,‚Äù pp. 1‚Äì5, 2020.
[26] T. Ozturk, M. Talo, E. A. Yildirim, U. B. Baloglu, O. Yildirim, and U. Rajendra Acharya,
‚ÄúAutomated detection of COVID-19 cases using deep neural networks with X-ray images,‚Äù
23

Comput. Biol. Med., 2020.
[27] S. Minaee, R. Kafieh, M. Sonka, S. Yazdani, and G. Jamalipour Soufi, ‚ÄúDeep-COVID:
Predicting COVID-19 from chest X-ray images using deep transfer learning,‚Äù Med. Image
Anal., 2020.
[28] P. K. Sethy, S. K. Behera, P. K. Ratha, and P. Biswas, ‚ÄúDetection of coronavirus disease
(COVID-19) based on deep features and support vector machine,‚Äù Int. J. Math. Eng. Manag.
Sci., 2020.
[29] R. Kumar, R. Arora, V. Bansal, and V. J. Sahayasheela, ‚ÄúAccurate Prediction of COVID19 using Chest X-Ray Images through Deep Feature Learning model with SMOTE and
Machine Learning Classifiers,‚Äù pp. 1‚Äì10, 2020.
[30] Walid El-Shafai and Fathi Abd El-Samie, ‚ÄúMendeley Data - Extensive COVID-19 X-Ray
and

CT

Chest

Images

Dataset.‚Äù

[Online].

Available:

https://data.mendeley.com/datasets/8h65ywd2jr/3. [Accessed: 26-Nov-2020].
[31] ‚ÄúCOVID-19 Xray Dataset (Train & Test Sets) | Kaggle.‚Äù [Online]. Available:
https://www.kaggle.com/khoongweihao/covid19-xray-dataset-train-test-sets.

[Accessed:

26-Nov-2020].
[32] C. Szegedy et al., ‚ÄúGoing deeper with convolutions,‚Äù in 2015 IEEE Conference on
Computer Vision and Pattern Recognition (CVPR), 2015, vol. 07-12-June, pp. 1‚Äì9.
[33] N. Ahmad, S. Hussain, K. Ahmad, and N. Conci, ‚ÄúComputer vision based room interior
design,‚Äù Eighth Int. Conf. Mach. Vis. (ICMV 2015), vol. 9875, no. January 2019, p. 98751G,
2015.
[34] A. Khan, A. Sohail, U. Zahoora, and A. S. Qureshi, ‚ÄúA survey of the recent architectures of
deep convolutional neural networks,‚Äù Artif. Intell. Rev., pp. 1‚Äì68, Apr. 2020.
[35] S. Hussain and A. Khan, ‚ÄúCoronavirus Disease Analysis using Chest X-ray Images and a
Novel Deep Convolutional Neural Network,‚Äù 10.13140/RG.2.2.35868.64646, no. April, pp.
1‚Äì31, 2020.
[36] A. Khan, A. Sohail, and A. Ali, ‚ÄúA New Channel Boosted Convolutional Neural Network
using Transfer Learning,‚Äù arXiv Prepr. arXiv1804.08528, Apr. 2018.
[37] A. Aziz, A. Sohail, L. Fahad, M. Burhan, N. Wahab, and A. Khan, ‚ÄúChannel Boosted
Convolutional Neural Network for Classification of Mitotic Nuclei using Histopathological
Images,‚Äù in Proceedings of 2020 17th International Bhurban Conference on Applied
24

Sciences and Technology, IBCAST 2020, 2020.
[38] K. Weiss, T. M. Khoshgoftaar, and D. D. Wang, ‚ÄúA survey of transfer learning,‚Äù J. Big
Data, 2016.
[39] Qiang Yang, S. J. Pan, Q. Yang, and Q. Y. Fellow, ‚ÄúA Survey on Transfer Learning,‚Äù IEEE
Trans. Knowl. Data Eng., vol. 1, no. 10, pp. 1‚Äì15, 2008.
[40] N. Wahab and A. Khan, ‚ÄúMultifaceted fused-CNN based scoring of breast cancer wholeslide histopathology images,‚Äù Appl. Soft Comput. J., 2020.
[41] N. Wahab, A. Khan, and Y. S. Lee, ‚ÄúTransfer learning based deep CNN for segmentation
and detection of mitoses in breast cancer histopathological images,‚Äù Microscopy, vol. 68,
no. 3, pp. 216‚Äì233, 2019.
[42] S. Christodoulidis, M. Anthimopoulos, L. Ebner, A. Christe, and S. Mougiakakou,
‚ÄúMultisource Transfer Learning with Convolutional Neural Networks for Lung Pattern
Analysis,‚Äù IEEE J. Biomed. Heal. Informatics, 2017.
[43] F. N. Iandola, M. W. Moskewicz, K. Ashraf, S. Han, W. J. Dally, and K. Keutzer,
‚ÄúSqueezeNet,‚Äù arXiv, 2016.
[44] K. Simonyan and A. Zisserman, ‚ÄúVery Deep Convolutional Networks for Large-Scale
Image Recognition,‚Äù arXiv Prepr. ArXiv 1409.1556, vol. 493, no. 6, pp. 405‚Äì10, Sep. 2014.
[45] K. He, X. Zhang, S. Ren, and J. Sun, ‚ÄúDeep Residual Learning for Image Recognition,‚Äù in
2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, vol.
77, no. 9, pp. 770‚Äì778.
[46] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, ‚ÄúDensely connected
convolutional networks,‚Äù Proc. - 30th IEEE Conf. Comput. Vis. Pattern Recognition, CVPR
2017, vol. 2017-Janua, pp. 2261‚Äì2269, 2017.
[47] X. Zhang, X. Zhou, M. Lin, and J. Sun, ‚ÄúShuffleNet: An Extremely Efficient Convolutional
Neural Network for Mobile Devices,‚Äù in Proceedings of the IEEE Computer Society
Conference on Computer Vision and Pattern Recognition, 2018.
[48] F. Chollet, ‚ÄúXception: Deep learning with depthwise separable convolutions,‚Äù arXiv Prepr.,
pp. 1610‚Äì2357, 2017.
[49] A. Krizhevsky, I. Sutskever, and G. E. Hinton, ‚ÄúImageNet Classification with Deep
Convolutional Neural Networks,‚Äù Adv. Neural Inf. Process. Syst., pp. 1‚Äì9, 2012.
[50] U. Ahmed, A. Khan, S. H. Khan, A. Basit, I. U. Haq, and Y. S. Lee, ‚ÄúTransfer Learning and
25

Meta Classification Based Deep Churn Prediction System for Telecom Industry,‚Äù pp. 1‚Äì10,
2019.
[51] V. Cheplygina, M. de Bruijne, and J. P. W. Pluim, ‚ÄúNot-so-supervised: A survey of semisupervised, multi-instance, and transfer learning in medical image analysis,‚Äù Med. Image
Anal., 2019.
[52] L. D. Brown, T. T. Cai, and A. Das Gupta, ‚ÄúInterval estimation for a binomial proportion,‚Äù
Stat. Sci., 2001.
[53] C. Cortes and M. Mohri, ‚ÄúConfidence intervals for the area under the ROC Curve,‚Äù in
Advances in Neural Information Processing Systems, 2005.
[54] K. Hajian-Tilaki, ‚ÄúReceiver operating characteristic (ROC) curve analysis for medical
diagnostic test evaluation,‚Äù Caspian Journal of Internal Medicine, vol. 4, no. 2. pp. 627‚Äì
635, 2013.

26

