Bio-JOIE: Joint Representation Learning of Biological
Knowledge Bases
Junheng Hao1 , Chelsea J.-T Ju1 , Muhao Chen2 , Yizhou Sun1 , Carlo Zaniolo1 , Wei Wang 1
1 Department

arXiv:2103.04283v1 [q-bio.MN] 7 Mar 2021

2

of Computer Science, University of California Los Angeles, Los Angeles, CA, 90095, USA
Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA 19104, USA
[jhao,chelseaju,yzsun,zaniolo,weiwang]@cs.ucla.edu,muhao@seas.upenn.edu

ABSTRACT
The widespread of Coronavirus has led to a worldwide pandemic
with a high mortality rate. Currently, the knowledge accumulated
from diï¬€erent studies about this virus is very limited. Leveraging
a wide-range of biological knowledge, such as gene ontology and
protein-protein interaction (PPI) networks from other closely related species presents a vital approach to infer the molecular impact of a new species. In this paper, we propose the transferred
multi-relational embedding model Bio-JOIE to capture the knowledge of gene ontology and PPI networks, which demonstrates superb capability in modeling the SARS-CoV-2-human protein interactions. Bio-JOIE jointly trains two model components. The
knowledge model encodes the relational facts from the protein and
GO domains into separated embedding spaces, using a hierarchyaware encoding technique employed for the GO terms. On top of
that, the transfer model learns a non-linear transformation to transfer the knowledge of PPIs and gene ontology annotations across
their embedding spaces. By leveraging only structured knowledge,
Bio-JOIE signiï¬cantly outperforms existing state-of-the-art methods in PPI type prediction on multiple species. Furthermore, we
also demonstrate the potential of leveraging the learned representations on clustering proteins with enzymatic function into enzyme commission families. Finally, we show that Bio-JOIE can
accurately identify PPIs between the SARS-CoV-2 proteins and human proteins, providing valuable insights for advancing research
on this new disease.

on Bioinformatics, Computational Biology and Health Informatics (BCB â€™20),
September 21â€“24, 2020, Virtual Event, USA. ACM, New York, NY, USA, 11 pages.
https://doi.org/10.1145/3388440.3412477

1 INTRODUCTION
The outbreak of COVID-19 (Coronavirus Disease-2019) has infected
over millions of people and caused high death tolls since the end of
2019, as worldwide social and economic disruption. Tremendous
eï¬€orts have been made to discover the infection mechanism of
the causative agent, named SARS-CoV-2. One important and urgent task is to understand the mechanism in which viral proteins
interact with human proteins. The new ï¬ndings will enrich the
annotation of viral genomes [12] in biomedical knowledge bases
(KBs). Constructing and populating such biomedical KBs can signiï¬cantly improve our understanding of the processes by which
SARS-CoV-2 aï¬€ects diï¬€erent cells in human body and will serve
as the foundation for many important downstream applications
such as vaccine development [17], drug repurposing [12, 36] and
drug side eï¬€ect detection [37].
Q5JRX3 O75439

P05026

Q9Y6E2

Q96JC1
(VSP39)

P11310
Q6PML9

P13804

Q9Y312

P38435

Q9H270
(VSP11)

Q9Y673

P38606
Q9UDR5

Q9UH99
P09601

P48556

CCS CONCEPTS
â€¢ Computing methodologies â†’ Learning latent representations; â€¢ Applied computing â†’ Computational proteomics; Biological networks.

KEYWORDS
Biological knowledge bases, representation learning, SARS-CoV-2
ACM Reference Format:
Junheng Hao1 , Chelsea J.-T Ju1 , Muhao Chen2 , Yizhou Sun1 , Carlo Zaniolo1 ,
Wei Wang 1 . 2020. Bio-JOIE: Joint Representation Learning of Biological
Knowledge Bases. In Proceedings of the 11th ACM International Conference
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proï¬t or commercial advantage and that copies bear this notice and the full citation on the ï¬rst page. Copyrights for components of this work owned by others than
the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior speciï¬c
permission and/or a fee. Request permissions from permissions@acm.org.
BCB â€™20, September 21â€“24, 2020, Virtual Event, USA
Â© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-7964-9/20/09. . . $15.00
https://doi.org/10.1145/3388440.3412477

Q9BW92

Q96S66

Q8IWR1
Q4KMQ2

Q96HR9

Q8N6S5

Q00765
O95070

Q9NQC3

HOPS Complex

Endoplasmic Reticulum Morphology

SARS-CoV-2 M Protein
(P0DTC5)

SARS-CoV-2 ORF 3a Protein
(P0DTC3)

Figure 1: Two examples of SARS-CoV-2-human protein interactions: M protein (left) and ORF3a protein (right). The
purple diamonds refers to the viral proteins and the orange
circles refer to the high-conï¬dence human protein target.
Proteins highlighted in blue are involved in certain biological processes, and proteins highlighted in yellow are arranged in a protein complex.
In general, biological KBs, often stored as knowledge graphs
(KGs), consist of various biological entities, their properties and
relations. These KBs can be categorized in diï¬€erent domains, such
as gene annotation, functional proteomic analysis, and transcriptomic proï¬ling. Speciï¬cally, gene ontology (GO) [10, 16] is the
most widely used resource for gene function annotation; STRING

BCB â€™20, September 21â€“24, 2020, Virtual Event, USA

GO: Cellular
Component

GO: Molecular
Function
virion

cellular anatomical
entity

Hao, et al.

structural virion
constituent

GO: Biological
Process

host immune
response mitigation

virus life
cycle

occurs in
extracellular
region

integral component
of membrane

P0DTC3
SARS-CoV-2 ORF3a

virion
membrane

P0DTC5
SARS-CoV-2 M

P59596
SARS-CoV M

Figure 2: Examples of gene ontology annotation enrichment
on three representative SARS-CoV or SARS-CoV-2 proteins,
which possess multiple properties across three biological aspects: biological processes, cellular components and molecular functions.

[29], PDB [2] and neXtProt [19] collect the knowledge accumulated from functional proteomic analysis; Expression Atlas [25] is
a database facilitating the retrieval and analysis of gene expression
studies. While those KBs provide the essential sources of knowledge for in silico research in the corresponding domains, such domainspeciï¬c knowledge is often sparse and costly to apprehend [21, 30].
For example, PPI networks can be far from complete given the information supported by experimental results or suggested by computational inference [14, 21]. Makrodimitris et al. [21] indicate that
the numbers of PPIs in BIOGRID [24] for non-model organisms are
far less than expected, speciï¬cally, there are only 107 interactions
for tomato (Solanum lycopersicum) and 80 interactions for pig (Sus
scrofa). Evidently, relying on the KG from a single domain presents
the risk of learning from limited and scarce information.
The stored knowledge is often interrelated across diï¬€erent perspectives. Hence, the missing knowledge in certain KBs can be
transferred from other KBs, and thus provide a more comprehensive representation of the biological entities. Taking the proteinprotein interaction (PPI) examples of the new SARS-CoV-2 proteins as illustrated in Figure 1, SARS-CoV-2 M protein interacts
with a list of human proteins, and ï¬ve of them are involved in the
endoplasmic reticulum (ER) morphology process as suggested by
the gene ontology annotation (GO:0005783). Similarly, the SARSCoV-2 ORF3a also interacts with a list of human proteins. Among
these proteins, VSP39 and VSP11 are the core subunits of HOPS
complex, presenting a binding action as suggested by the STRING
database. While aligning the gene ontology annotations of the SARSCoV-2 M protein as demonstrated in Figure 2, the SARS-CoV M
protein presents a similar set of gene ontology annotations, such
as â€œhost immune mitigationâ€ and â€œvirion membraneâ€, suggesting
that the side knowledge of gene ontology annotations can facilitate the inference of interactions for related proteins. More generally, the sparse domain information can always beneï¬t from the
supplementary knowledge from other relevant domains, therefore
calling upon a plausible method to support the fusion and transfer
of knowledge across multiple biological domains.

Regardless of the importance and advantages of knowledge fusion across diï¬€erent domains [3, 5], fewer eï¬€orts have been devoted to incorporating knowledge from diï¬€erent domains for a speciï¬c task in computational biology studies. Onto2vec [27] presents
one state-of-the-art learning approach that successfully bridges
gene ontology annotations with the protein representation. However, the known PPI information is neglected and not encoded in
the obtained protein embeddings.
To combine multiple domain-speciï¬c biological knowledge, and
facilitate knowledge transfer across diï¬€erent domains, we purpose
Bio-JOIE, a JoInt Embedding learning framework for multiple domains of Biological KBs. In Bio-JOIE, two model components are
jointly learned, i.e., a knowledge model characterizes diï¬€erent domainspeciï¬c KGs in separate low-dimensional embedding spaces, and
a transfer model captures the cross-domain knowledge association.
More speciï¬cally, the knowledge model encodes the relational facts
of entities in each view into the corresponding embedding space
separately, with a hierarchy-aware technique designated for the
hierarchically-layered domains. Besides, the transfer model seeks
to transfer the knowledge between pairs of domains by employing a weighted non-linear transformation across their embedding
spaces. In evaluation, we apply the Bio-JOIE on several PPI networks with Gene Ontology annotations and the entire gene ontology and evaluate by PPI predictions. We compare Bio-JOIE with
that of the state-of-the-art representation learning approaches on
multiple species, including SARS-CoV-2-Human PPIs, with diï¬€erent model settings. Our best Bio-JOIE outperforms alternative approaches by 7.4% in PPI prediction.
Our contributions are 4-fold. First, we construct a general framework for learning representations across diï¬€erent domain-speciï¬c
KBs, including the dynamically changing SARS-CoV-2 KB. Second,
we emphasize and demonstrate that cross-domain representation
learning by the proposed Bio-JOIE can improve the inference in
one domain by leveraging the complementary knowledge from another domain. Extensive experiments on diï¬€erent species conï¬rm
the eï¬€ectiveness of cross-domain representation learning. Third,
Bio-JOIE also demonstrates cross-species transferability to improve
PPI predictions among multiple species by knowledge population
from gene ontology. Fourth, the protein representations learned
from Bio-JOIE can be leveraged for diï¬€erent tasks. Speciï¬cally,
we show that the protein embeddings trained on PPI network and
gene ontology present the potential to better group enzymes into
diï¬€erent enzyme commission families. Tremendous eï¬€orts have
been made to discover the infection mechanism of the causative
agent, named SARS-CoV-2.

2 MATERIALS AND METHOD
In this section, we present the proposed method to support representation learning and cross-domain knowledge transfer on biological KBs. Without loss of generality and aligned with the evaluation of the proposed Bio-JOIE, we refer two domain-speciï¬c KGs
in the following section to PPI networks and the gene ontology
graph. We begin with the formalized descriptions of the materials
and tasks.

Joint Representation Learning of Biological Knowledge Bases

2.1

Preliminary

Materials. A typical biological KB can be viewed as relational data
that are presented as an edge-labeled directed graph G, which is
formed with a set of entities (e.g. proteins) E and a set of relations
(e.g. interaction types) R. A triple (ğ‘ , ğ‘Ÿ, ğ‘¡) âˆˆ G represents a ğ‘Ÿ âˆˆ R
typed relation between the source and target entities ğ‘ , ğ‘¡ âˆˆ E, As
stated, we continue with the modeling on KGs of two domains,
PPI and gene ontology. For example, in the PPI network, a triple
(FBgn0011606, binding, FBgn0260855) simply states the fact
that two proteins (from ï¬‚y) have binding interaction; and in gene
ontology, a triple (GO:0008152, is a, GO:0008150) similarly
represents that GO:0008152 (a unique identiï¬er of â€œmetabolic processâ€) is one subclass of GO:0008150 (a unique identiï¬er of â€œbiological processâ€). Our model seeks to capture the protein information
in the triples (ğ‘ ğ‘ , ğ‘Ÿ ğ‘ , ğ‘¡ğ‘ ) of PPI graph Gğ‘ in a ğ‘˜ğ‘ -dimensional embedding space, where we use boldfaced notations such as sğ‘ , rğ‘ , tğ‘ âˆˆ
Rğ‘˜ğ‘ to denote the embedding representation. Similarly, gene ontology is another graph Gğ‘œ formed with a set of GO terms Eğ‘œ and
a set of semantic relations Rğ‘œ . The triple (ğ‘ ğ‘œ , ğ‘Ÿğ‘œ , ğ‘¡ğ‘œ ) âˆˆ Gğ‘œ identiï¬es a semantic relation of GO terms, while we also observe hierarchical substructures formed by â€œsubclassâ€ or â€œis_aâ€ relation as
the aforementioned example. The gene ontology is embedded in
another space Rğ‘˜ğ‘œ , such that ğ‘˜ğ‘ and ğ‘˜ğ‘œ may not be equivalent. We
use (ğ‘œ, ğ‘) âˆˆ A to denote a GO term annotation where a GO term
ğ‘œ âˆˆ Eğ‘œ describes a protein ğ‘ âˆˆ Eğ‘ of its corresponding functionality, and A denotes the set of such associations. As introduced in
Section 1, we consider SARS-CoV-2-Human interaction as a similar (but signiï¬cantly smaller) KBs with the same structures as Gğ‘ ,
which serves as an extension of human PPI networks.
Tasks. To validate the learned embedding of biological entities
(proteins and GO terms in this context), we address the following two tasks. (i) PPI type prediction aims at predicting the interaction type between two interacting proteins, including SARS-CoV2 related PPIs; (ii) Protein clustering and family identiï¬cation aims
at clustering the existing proteins and helps identify the clusters
based on Enzyme Commission (EC) numbers.
Methods. The model architecture of Bio-JOIE is shown in Figure
3. The proposed Bio-JOIE jointly learns two types of model components to connect the two views of structured knowledge. Knowledge models are responsible for representing the relational knowledge of PPI and that of GO term into two separate embedding
spaces Rğ‘˜ğ‘ and Rğ‘˜ğ‘œ by using KG embedding and hierarchy-aware
regularization. On top of that, a transfer model learns a transformation to connect between the representations of GO term relation
facts and PPI based on partially provided GO term assignments.
In particular, we investigate weighted transfer techniques to better
capture the knowledge transfer, for which the weights reï¬‚ect the
speciï¬city of the assigned GO term to a protein. The following of
this section describes the model components and the learning objective of Bio-JOIE in detail.

2.2

Knowledge Model

The knowledge models seek to characterize the semantic relations
of GO terms and PPI information into separate embedding spaces.
In each embedding space, the inference of relations or interactions
is modeled as speciï¬c algebraic vector operations. As mentioned,

BCB â€™20, September 21â€“24, 2020, Virtual Event, USA

Gene Ontology Domain
Biological
Process

Molecular
Function

Cellular
Component

Transfer Model
GO:0016020
Membrane

o
fT (o, p)
p
SARS-CoV-2 E

Q6ZVD8

P13861
binding

SARS-CoV-2 E

Binding

O60885

binding
Q14789

P13569

binding

s

NSP13

r

t

reaction
P63167

O60885

binding

activate
P01100

E

fr (s, t)

SARS-CoV-2

Knowledge Model

Human

Protein Interaction Domain

Figure 3: Model architecture of Bio-JOIE. The Knowledge
Model seeks to encode relational facts in each domain respectively (such as proteins and gene ontology). Meanwhile,
the Transfer Model learns to connect both domains and enable knowledge transfer across protein and gene ontology.
the two views of gene ontology and PPI are embedded to separate
embedding spaces.
To capture a triple (ğ‘ , ğ‘Ÿ, ğ‘¡) from either of the two domains, a
cost function ğ‘“ğ‘Ÿ (ğ‘ , ğ‘¡) is provided to measure its plausibility. A lower
score indicates a more plausible triple. We can adopt multiple vector operations in the deï¬ned embedding space with three representative examples deï¬ned as follows, i.e. translations (TransE [4]),
Hadamard product [33] and circular correlation (HolE [23]). The
cost functions are given as follows, where the symbol â—¦ denotes
Hadamard product, and â˜… : Rğ‘‘ Ã— Rğ‘‘ â†’ Rğ‘‘ denotes circular correÃ
lation deï¬ned as [a â˜… b]ğ‘˜ = ğ‘‘ğ‘–=0 ğ‘ğ‘– ğ‘ (ğ‘˜+ğ‘–) mod ğ‘‘ .
ğ‘“ğ‘ŸTrans (s, t) = ||s + r âˆ’ t|| 2
ğ‘“ğ‘ŸMult (s, t) = âˆ’(s â—¦ t) Â· r
ğ‘“ğ‘ŸHolE (s, t) = âˆ’(s â˜… t) Â· r
Since most of the relations in PPI networks are symmetric (such
as binding and catalysis), we apply the Hadamard product based
function. The learning objective of a knowledge model on a graph
ğº is to minimize the following margin ranking loss,
n
o
Ã•
1
Lğ¾G =
max ğ‘“ğ‘Ÿ (ğ‘ , ğ‘¡) + ğ›¾ G âˆ’ ğ‘“ğ‘Ÿ (ğ‘  â€², ğ‘¡ â€² ), 0
|G|
(ğ‘ ,ğ‘Ÿ,ğ‘¡) âˆˆG

where ğ›¾ G

is a positive margin, and a negative sample (ğ‘  â€², ğ‘Ÿ, ğ‘¡ â€² ) âˆ‰ G
is created by randomly substituting either ğ‘  or ğ‘¡ using Bernoulli
negative sampling [32]. With regard to the two domains of relational knowledge (proteins and gene ontology) Gğ‘ and Gğ‘œ , we deG

note the learning objective losses as Lğ¾ ğ‘ and Lğ¾Gğ‘œ .
Hierarchy-aware Encoding Regularization As mentioned in
Section 2.1, it is observed that some ontological knowledge can
form hierarchies [8], which is typically constituted by a relation

BCB â€™20, September 21â€“24, 2020, Virtual Event, USA

with the implicit hierarchical property, such as â€œsubclass_ofâ€, as
substructures. In gene ontology, more than 50% of the triples have
such relations. To better characterize such hierarchies, we model
such substructures diï¬€erently from the aforementioned DistMult
and many others by adding hierarchy regularization. More specifically, given entity pairs (ğ‘’ğ‘™ , ğ‘’â„ ) âˆˆ ğ‘† where ğ‘’ğ‘™ is a subclass of ğ‘’â„ ,
we model such hierarchies by minimizing the distance between
coarser concepts and associated ï¬ner concepts in embedding space.
Hence, the loss is simply deï¬ned as
Ã•
1
L (HA) =
[||ğ‘’ğ‘™ âˆ’ ğ‘’â„ || 2 âˆ’ ğ›¾ HA ] +
|ğ‘† |
(ğ‘’ğ‘™ ,ğ‘’â„ ) âˆˆğ‘†

where [ğ‘¥] + = max{ğ‘¥, 0} and ğ›¾ HA is also a positive margin parameter. This penalizes the case where the embedding of ğ‘’ğ‘™ falls out the
ğ›¾ HA -radius neighborhood centered at the embedding of ğ‘’â„ .
Relation Inference. Given the learned embeddings and a pair of
query proteins ((ğ‘ 1, ğ‘ 2 )), we can predict the most plausible interaction type ğ‘Ÿ by selecting the optimal ğ‘“ğ‘Ÿ (ğ‘ 1, ğ‘ 2 ) score. We can also
provide predictions for possible protein targets given the query of
the subject protein and speciï¬c interaction type (ğ‘, ğ‘Ÿ, ?ğ‘¡) by populating the selection proteins with top score ğ‘“ğ‘Ÿ (ğ‘, ğ‘¡) from the knowledge model. Details about each task are curated in Section 3.3 and
3.5.

2.3

Transfer Model

The transfer model learns to connect between the above two relational embedding spaces via a non-linear transformation. The
transformation is induced based on the GO term assignments, towards the goal to collocate the associated GO terms and proteins
in an embedding space after transformation. Hence, the aï¬ƒnity of
embedding structures of gene ontology and PPIs can be captured.
This allows the relational knowledge to transfer across and complement the learning and inference on both domains.
Given each GO term assignment (ğ‘œ, ğ‘) âˆˆ A, following function
ğ‘“ğ‘‡ (ğ‘œ, ğ‘) measures the plausibility of the transformation that is favored to be minimized.
ğ‘“ğ‘‡ (ğ‘œ, ğ‘) = kğœ (Mğ‘‡ Â· p + bğ‘‡ ) âˆ’ ok 2
Mğ‘‡ âˆˆ Rğ‘˜ğ‘œ Ã—ğ‘˜ğ‘ thereof is a weight matrix and bğ‘‡ âˆˆ Rğ‘˜ğ‘ is a bias
vector. ğœ is either the identify function, or a non-linear function as
tanh, the latter thereof aim at smoothing the transformation with
additional non-linearity.
2.3.1 Basic Transfer Model. The basic strategy to learn the transfer model is to treat each GO term assignment evenly, and thereby
minimizing the following learning objective loss.
n
Ã•
 o
1
Lğ‘‡1 =
max ğ‘“ğ‘‡1 (ğ‘œ, ğ‘) + ğ›¾ A âˆ’ ğ‘“ğ‘‡1 ğ‘œ â€², ğ‘ â€² , 0
|A|
(ğ‘œ,ğ‘) âˆˆA

Hao, et al.

terms and proteins, in contract to general GO terms, more speciï¬ed GO terms necessarily carry more precise descriptions to the
proteins. Hence, an improved transfer model weights among GO
term associations to a protein for the purpose of more attentively
capturing those with more speciï¬c GO terms. Let ğœ” (ğ‘œ) be a weight
is speciï¬cally assigned to ğ‘œ, the objective of the weighted transfer
model is to minimize the following loss,


Ã•
i
1
ğœ” (ğ‘œ) h
Lğ‘‡2 =
max
ğ‘“ğ‘‡2 (ğ‘œ, ğ‘) + ğ›¾ A âˆ’ ğ‘“ğ‘‡2 ğ‘œ â€², ğ‘ â€² , 0
|A|
ğ¶
(ğ‘œ,ğ‘) âˆˆA

where ğ¶ is a normalizing constant to constrain that
Ë†
1 for a speciï¬c protein ğ‘.
biological
process

h0

symbolic
process

h1

viral
process

h2

host immune
response mitigation

h3

Ã

Ë†
(ğ‘œ,ğ‘)

ğœ” (ğ‘œ)
ğ¶

=

w(h0 )
w(h1 )
w(h2 )
w(h3 )

evasion of host natural
killer cell activity h4

P0DTC5
SARS-CoV-2 M
Known GO Annotation

w(h4 ) = 0

Figure 4: Explanation of weighted transfer model for modeling hierarchical gene ontology.
Exemplarily, there could be several ways to calculate the association weight.
Level-based weight. The level of the node in one hierarchical
taxonomy is a natural indicator of its speciï¬city. Accordingly, the
weight can be deï¬ned as,
ğ‘™
ğœ” (ğ‘œ) =
ğ‘™ max
where ğ‘™ is the termâ€™s current depth and ğ‘™ max is the maximum length
of the associated branch in the gene ontology DAG.
Degree centrality weight. A small nodeâ€™s degree centrality in the
graph roughly reï¬‚ects its specialty and we apply
1
ğœ” (ğ‘œ) =
ğ‘‘ (ğ‘œ)
as the balance factor for diï¬€erent GO term specialty.
In practice, incorporating a speciï¬city-based weight to the transfer model essentially enhances the inference in the protein domain,
as we have observed in the evaluation in Section 3. However, the
above weight options generally yield similar performance gain,
and we ï¬x the weight option as the level-based weight in our experimental setting.

(ğ‘ â€², ğ‘œ â€² )

2.4 Joint Learning Objectives

ğ‘ â€²,

Bio-JOIE jointly learns two knowledge models respectively for
GO term relations and PPIs, and a transfer model to support knowledge transfer between these two. Therefore, the joint learning objective minimizes the following loss,

âˆ‰ A thereof is a negative sample by randomly substituting
and ğ›¾ A is a positive margin.

2.3.2 Weighed Transfer Model. Since some ontological knowledge,
such as gene ontology, may form hierarchical structures, where GO
terms in lower levels typically describe more speciï¬ed gene functionality. During the characterization of associations between GO

Gğ‘

L = ğœ†ğ‘¡ Lğ‘‡ + ğœ†ğ‘ Lğ¾ + Lğ¾Gğ‘œ

Joint Representation Learning of Biological Knowledge Bases

ğœ†ğ‘ and ğœ†ğ‘¡ are two positive hyperparameters. We use Adam [18]
to optimize the learning objective loss. The learning process uses
orthogonal initialization [26] to initialize the weight matrix, and
Xavier normal initialization [11] for vector parameters. A normalization constraint is enforced to keep all embedding vectors of GO
terms and proteins on unit hyper-spherical surfaces, which is to
prevent the non-convex optimization process from collapsing to a
trivial solution where all vectors shrink to zero [4, 13, 20, 33].
Note that Bio-JOIE is suitable for joint representation learning
on proteomic knowledge of diï¬€erent species. In this protein-GO
example, the proteins of these species are signiï¬cantly diï¬€erent
from each other. However, they share the same set of annotations
in the GO domain. Therefore, More speciï¬cally, if we have multiple PPI networks Gğ‘– , ğ‘– = 1, 2, . . . , ğ‘š where ğ‘š denotes the number of
independent species, ğ‘› knowledge models are trained respectively.
Consequently, one unique transfer model is also trained to facilitate the protein-GO knowledge transfer regarding each species.
The learning objective on the multi-species setting is changed accordingly as,

L=

ğ‘š
Ã•
ğ‘–=1

ğœ†ğ‘–ğ‘¡ Lğ‘‡ +

ğ‘š
Ã•
ğ‘ G
ğœ†ğ‘– Lğ¾ ğ‘ + Lğ¾Gğ‘œ
ğ‘–=1

with the assumption that the knowledge model for gene ontology
remains unchanged.
In addition to joint learning on multiple species, Bio-JOIE can
also be re-trained from new observations of PPIs. For example,
suppose newly discovered SARS-CoV-2-Human PPI knowledge extends the original human PPI networks, we can ï¬ne-tune the Bio-JOIE
from the saved model and obtained embeddings, by only optimizing the Bio-JOIE on the new triples and hence fast obtain representations for all new proteins, without a long time for retraining
the Bio-JOIE from scratch.

3

RESULTS

In this section, we evaluate the embeddings learned from Bio-JOIE
with two groups of tasks: PPI type prediction (Section 3.3) and protein clustering based on enzymatic functions (Section 3.4). Furthermore, we provide an extensive case study in Section 3.5 on SARSCoV-2 related PPI prediction and classiï¬cation.

3.1

Dataset

The protein-protein interactions for yeast (Saccharomyces cerevisiae),
ï¬‚y (Drosophila melanogaster), and human (Homo sapiens) are collected from the STRING [29] database. There are seven types of
interactions annotated in the STRING database. To preserve a balanced and suï¬ƒcient number of cases in each class, we randomly
choose the protein pairs from four types of interaction: activation,
binding, catalysis, and reaction. In total, there are 21704, 10000,
36400 pairs of proteins for yeast, ï¬‚y, and human, respectively; each
type contains roughly the same number of interactions. Table 1
summarizes the PPI information for each species. Note that, the
human PPI dataset does not contain the virus-generated proteins,
but the set partially overlaps with the virus-human pan-PPI networks.

BCB â€™20, September 21â€“24, 2020, Virtual Event, USA

The gene ontology annotations for each protein are extracted
from gene ontology Consortium [10], including all three biological aspects: biological process (BP), cellular components (CC), and
molecular function (MF). Table 2 summarizes the number of relations between proteins and GO terms. The relations between GO
terms include is-a, part-of, has-part, regulates, positively-regulates,
and negatively-regulates.
Table 1: Statistics of PPI networks and associated GO annotations from diï¬€erent species.
Species
Yeast
Fly
Human

# Proteins
3,736
3,826
8,204

# PPI Triples
21,704
10,000
36,400

# GO Annotations
191,801
87,807
102,759

Table 2: Statistics of three aspects in the gene ontology: biological processes (BP), cellular components (CC) and molecular functions (MF).
Aspects
# GO entities
# GO triples
# Protein-GO annotations (yeast)
# Protein-GO annotations (ï¬‚y)
# Protein-GO annotations (human)

BP
5744
19,021
72,956
44,605
42,899

CC
1,147
2,116
58,729
24,550
32,929

MF
1,764
2,190
60,116
18,652
26,931

For the SARS-CoV-2 dataset, we collect the latest virus-protein
interaction from BioGrid1 and the limited GO annotations for SARSCoV-2 from Gene Ontology Consortium2 , as last updated on early
April. In summary, there are 26 SARS-CoV-2 generated proteins
and 332 human proteins presenting the evidence of viral-human
protein interactions as suggested by Gordon et al. [12]. The selection is based on a high MIST score and a low SAINTexpress BFDR
from Aï¬ƒnity Capture-MS. Out of the same experiment, we select
1131 viral-human protein pairs with MIST scores lower than 0.01
as our negative samples. The 26 SARS-CoV-2 generated proteins
are annotated with 282 GO terms. In addition to SARS-CoV-2, BioGrid also includes 30 viral proteins from SARS-CoV and MERSCoV, which are two similar contagious viruses causing respiratory
infection. These 30 viral proteins are annotated with 630 GO terms,
and display 326 interactions with human proteins. All processed
datasets are available at https://www.haojunheng.com/project/goterm.

3.2 Baselines
We compare Bio-JOIE with the most applicable state-of-the-art
approach, Onto2Vec [27], on learning the representation of proteins. Onto2Vec considered the annotation from gene ontology for
representation learning. In addition, we compare Bio-JOIE with
a simpler setting, Bio-JOIE-NonGO, where we only consider the
single-domain knowledge of PPI.
Onto2Vec, Onto2Vec-Parent, Onto2Vec-Ancestor. Onto2Vec utilizes the annotation information from gene ontology to create pairwise context and apply Word2Vec [22] to generate protein and GO
1 Data
2 Data

source: https://wiki.thebiogrid.org/doku.php/covid
source: http://geneontology.org/covid-19.html

BCB â€™20, September 21â€“24, 2020, Virtual Event, USA

Hao, et al.

DistMult for the knowledge model in Section 2.2, with hierarchyterm embeddings. Its schema allows the model to learn the repreaware regularization and the level-weighted transfer model (Secsentation of proteins and GO terms simultaneously. The proposed
tion 2.3) deployed. For simplicity, the reported Bio-JOIE adopt the
setting of Onto2Vec only includes the direct relationship between
same settings if not speciï¬cally explained. The number of epochs
a protein and a GO term. In this experiment, we explicitly include
in training on all settings is limited to 150. For evaluation, we aim
the relationship between a protein and the parents of the annoat predicting the correct interaction type, given pairs of proteins
tated GO terms, named Onto2Vec-Parent, and the ancestors of the
in the test set. We conduct a 5-fold cross validation for Bio-JOIE
annotated GO terms, named Onto2Vec-Ancestor.
Onto2Vec-Sum, Onto2Vec-Mean. To examine the eï¬€ect of Onto2Vec and all baselines, and report the average and standard deviation
of accuracy. The best-performing classiï¬er is RF for OPA2Vec and
on learning the protein representation from a single domain, i.e.
most of the Onto2Vec variants. The only exception is to apply MLP
gene ontology, we remove the relations between proteins and GO
for Onto2Vec-Ancestor on ï¬‚y.
terms during the learning process. The representation of a protein
is then computed by either summing up the embeddings of all the
Table 3: PPI type prediction accuracy (%) evaluated on yeast,
associated GO terms (Onto2Vec-Sum), or taking the average of the
ï¬‚y and human species.
embeddings of those GO terms (Onto2Vec-Mean).
OPA2Vec Based on Onto2Vec, OPA2Vec further learns the proModel
Yeast
Fly
Human
tein and GO term embeddings by leveraging meta-data (labels, synOnto2Vec
76.41 Â± 0.73
70.85 Â± 0.85
77.97 Â± 0.46
onyms, etc), which better characterize GO terms.
80.79 Â± 0.66
75.46 Â± 1.11
74.90 Â± 0.46
Onto2Vec-Parent
Bio-JOIE (NonGO). As opposed to considering the knowledge
86.31 Â± 0.42
80.31 Â± 0.92
78.73 Â± 0.46
Onto2Vec-Ancestor
from a single domain of gene ontology, we adopt Bio-JOIE to conOnto2Vec-Sum
76.38 Â± 0.83
72.84 Â± 1.13
72.53 Â± 0.73
sider only the knowledge from Protein-Protein Interaction. In this
77.95 Â± 0.81
74.38 Â± 1.13
73.47 Â± 0.80
Onto2Vec-Mean
79.88 Â± 0.74
74.45 Â± 0.97
72.04 Â± 0.58
OPA2Vec
approach, all the gene ontology annotations and the gene ontology
Bio-JOIE-NonGO
83.65 Â± 0.92
77.58 Â± 1.07
76.10 Â± 0.87
graph are neglected, and thus is reduced to a knowledge model. We
Bio-JOIE
87.15 Â± 1.15
84.56 Â± 0.81
81.42 Â± 0.62
only use the knowledge model in Section 2.2, where the protein
Bio-JOIE-Weighted
90.12
Â±
1.21
85.55
Â±
1.57
83.89
Â± 0.92
embeddings are solely learned from PPI networks by the original
KG embedding technique, DistMult. We refer to this approach as
Results. The results for PPI type prediction are shown in Table 3.
â€œNon-GOâ€.
We
observe that our best Bio-JOIE variant outperforms Bio-JOIEIt is worth mentioning that the goal of Onto2Vec and OPA2Vec
NonGO
by 7.4% on average for all three species. This observation
is to learn the protein representation; therefore, to adapt for the
directly shows that gene ontology KG provides complementary
task of PPI prediction, we concatenate the embeddings of each
knowledge for proteins. Subsequently, Gene Ontology annotations
pair of proteins and train a multi-class classiï¬er to predict the PPI
beneï¬t the learning of protein representations and better predict
type for a given pair of query proteins. We examine the perforthe interaction types between proteins. Compared to other basemance with four diï¬€erent classiï¬ers: logistic regression (LR), suplines, it is observed that Bio-JOIE notably outperforms Onto2Vecport vector machine (SVM), random forest (RF), and neural networks (MLP). The evaluation is conducted with ï¬ve-fold cross-validation. Ancestor with an average increase of 7.4% on the prediction accuracy, and a relative gain of 9.0% on average of all three species. This
Similar settings apply to all Onto2Vec variants and OPA2Vec. On
observation is due to the advantage that Bio-JOIE better leverthe contrary, our proposed model equips with relational modeling
ages the complementary knowledge from PPI to enhance the PPI
and outputs PPI predictions by selecting the most plausible relaprediction. As mentioned in Section 3.2, Onto2Vec does not utition type. As a result, we do not need an additional classiï¬er for
lize the PPI information into protein embedding learning. Instead,
Bio-JOIE and Bio-JOIE-NonGO.
it obtains embeddings based on the aggregated semantic representations of GO terms. It requires additional classiï¬ers for PPI
type prediction given pre-trained protein embeddings. In contrast,
3.3 PPI Type Prediction on Multiple Species
Bio-JOIE jointly learns protein representations from both the knowlWe examine how eï¬€ectively Bio-JOIE leverages gene ontology to
edge model that captures the structured information of known
predict protein-protein interaction types. To do so, we ï¬rst evaluPPIs, and the transfer model that delivers the annotations of GO
ate the performance on three organisms separately: human, yeast,
terms. Also, we observe that Bio-JOIE-Weighted achieves better
and ï¬‚y. Then we study the contribution of the three aspects in gene
results than Bio-JOIE, with a relative performance gain of 2.5%.
ontology, i.e. biological process (BP), cellular component (CC), and
We hypothesize that such gain is attributed to speciï¬city modelmolecular function (MF), on predicting the type of PPI. Speciï¬cally,
ing in the transfer model which distinguishes more speciï¬c and
we provide an analysis on how the knowledge from Gene Ontology
informative GO terms from other general GO terms and assigns
contributes to PPIs in diï¬€erent species.
a higher weight, which selectively learns the alignments between
Experimental setting. We ï¬rst separate the PPI triples into aptwo domains. In terms of diï¬€erent species, we also observe that
proximately 70% for training, 10% for validation and 20% for testBio-JOIE achieves a higher PPI prediction accuracy on yeast coming. For hyperparameters with the best performance from the valpared to human and ï¬‚y. The possible reason is that the yeast inidation set, we select dimension ğ‘‘ ğ‘ = ğ‘‘ğ‘œ = 300 and margin paramteraction network is denser, such that 0.30% of the protein pairs
eters ğ›¾ G = 0.25, ğ›¾ A = 1.0 and ğ›¾ HA = 1.0. Two weight factors in
are known to interact, compared to human (0.13%) and ï¬‚y (0.11%),
the joint learning objective are set as ğœ†ğ‘ = 1.0, ğœ†ğ‘¡ = 1.0. We use
which indicates that yeast is possibly well studied. OPA2Vec claims

Joint Representation Learning of Biological Knowledge Bases

to be an improved version of Onto2Vec. Similar to Onto2Vec, it
only considers the direct relationship between a protein and a GO
term, without parents and ancestors. We ï¬nd that OPA2Vec performs slightly better than Onto2Vec on Yeast and Fly, but worse on
Human. In addition, OPA2Vec falls short when compared to any of
the Bio-JOIE variants, indicating that incorporating the metadata
of GO terms is insuï¬ƒcient for protein representation learning.
It is noteworthy that unlike Onto2Vec, which achieves its best
performance with the help of full gene ontology (i.e. Onto2VecAncestor), our Bio-JOIE model can utilize only the GO terms that
are directly annotated with the proteins to accomplish the highest accuracy score. This also makes Bio-JOIE training processes
more time eï¬ƒcient. We hypothesize that for Bio-JOIE in the PPI
type prediction task, GO terms that are directly related to associated proteins with high speciï¬city are suï¬ƒcient for the transfer model to model the protein-GO association in the embedding
spaces. In contrast, Onto2Vec needs entire structured information
of GO terms for its word2vec module to construct an exhaustive
context of protein features.
Table 4: Comparison of PPI prediction accuracy of Bio-JOIE
on three diï¬€erent aspects of gene ontology.
#
1

2
3

Aspects
BP
CC
MF
BP+CC
BP+MF
CC+MF
AllGO

Yeast
0.8794
0.8499
0.8539
0.8717
0.8673
0.8569
0.9012

Fly
0.8402
0.8272
0.8386
0.8473
0.8471
0.8466
0.8555

Human
0.8153
0.8054
0.8165
0.8271
0.8163
0.8170
0.8389

We further explore the eï¬€ects of three diï¬€erent aspects of gene
ontology in predicting the types of PPIs. To achieve this, we train
Bio-JOIE in settings where only speciï¬c aspects of gene ontology
annotations are used. Results are shown in Table 4, in which BP, CC
and MF respectively refer to the cases where GO terms of biological
processes, cellular components and molecular functions are used. â€œBP
+ CCâ€ denotes that the GO terms from both biological processes
and cellular components are included in training. We observe that
Bio-JOIE performs the best with GO terms from all aspects (full
gene ontology). This phenomenon is consistent among all three
species, indicating that the protein representations are more robust when learning from a more enhanced knowledge graph. It is
also interesting to see that the accuracy of the task is generally
higher when we include the GO terms from biological processes.
This leads to 2.61% improvement in accuracy over CC, and at least
2.13% of improvement over MF when evaluating individually. In
the two-aspect evaluation, â€œBP+CCâ€ is in average leads to 0.7% better accuracy than â€œCC+MFâ€. This is attributed to the fact that BP
is the largest group in the gene ontology, containing more entities
and relational facts. Consequently, Bio-JOIE achieves the best performance with all three aspects of gene ontology annotations incorporated. This indicates that the characterization of PPIs beneï¬ts
from more comprehensive gene ontology annotations.
In addition to joint learning from two diï¬€erent domains (i.e. GO
terms and PPIs), as mentioned in Section 2.4, Bio-JOIE can be

BCB â€™20, September 21â€“24, 2020, Virtual Event, USA

Table 5: PPI type prediction accuracy on diï¬€erent conï¬gurations of multi-species joint learning.
Model
Bio-JOIE (single)
Bio-JOIE (concat)
Bio-JOIE (multi-way)

Yeast
0.9012
0.8795
0.9062

Fly
0.8555
0.8282
0.8638

Human
0.8389
0.8028
0.8426

trained to capture PPIs for multiple species with several speciesspeciï¬c knowledge models, along with transfer models that bridge
the universal gene ontology. To validate the beneï¬t of joint learning on multiple species together, we consider three following conï¬gurations of Bio-JOIE: (i) the â€œmulti-wayâ€ setting uses one unique
knowledge model and one transfer model to the universal gene
ontology for each species; (ii) the â€œconcatâ€ setting uses one uniï¬ed knowledge model to capture all species of PPIs, together with
one transfer model to learn protein-GO alignments, that is, simply concatenate all PPI triples and all gene ontology annotations
of proteins in multiple species; (iii) the â€œsingleâ€ setting trains separately on each species, which is exactly the same as in the setting
in Table 3. We summarize the results in Table 5. It is observed that
the â€œmulti-wayâ€ setting can slightly improve PPI performance in
comparison to the â€œ singleâ€ setting that trains separately on each
species. Also in the â€œconcatâ€ setting with one shared transfer model
and knowledge model, the performance signiï¬cantly drops with a
2.8% decrease of accuracy on average compared to the â€œsingleâ€ setting. Such results suggest that each species has unique patterns
of PPIs, such diï¬€erences are better diï¬€erentiated in separate embedding spaces. Hence, the multi-way setting better encodes the
species-speciï¬c knowledge and model, which helps the type prediction of PPIs for each species by Bio-JOIE that are jointly trained
on multiple species.

3.4 Identifying Protein Families And Enzyme
Commission Based Clustering
Besides inferring PPI types, the embedding representations of proteins can also be used to identify potential protein families based
on their functions. This can be achieved by performing clustering
algorithms on the learned protein embeddings.
The Enzyme Commission number (EC number) deï¬nes a hierarchical classiï¬cation scheme that provides the enzyme nomenclature based on enzyme-catalyzed reactions. The top-level EC numbers contain seven classes: oxidoreductases, transferases, hydrolases, lyases, isomerases, ligases, and translocases. In this experiment, we select 1340 yeast proteins in total with enzymatic functions. We learn the protein representations using all the triples of
PPI networks and the annotation from gene ontology and evaluate the learned representations of these proteins by performing
the k-means clustering algorithm to group them into seven nonoverlapping clusters. These clusters are compared with the toplevel of enzyme commission classiï¬cation. Purity score is reported
as evaluation metrics.
The evaluation of the clustering results is shown in Table 6.
Bio-JOIE achieves the best clustering performance on yeast by
a relative increase of 9.7%, which demonstrates that Bio-JOIE has

BCB â€™20, September 21â€“24, 2020, Virtual Event, USA

the good model capability to representation learning and empirically show the validity of the learned embeddings to measure the
similarity. We hypothesize that Bio-JOIE better incorporates protein annotation resource and utilizes the complementary knowledge in the gene ontology domain, while Bio-JOIE also captures
PPI information and encode it into protein embeddings. This in
the end results in comprehensive representations for proteins and
helps to identify protein EC classes by clustering.
Table 6: Results of top-level EC clustering by K-means on
learning selected yeast protein embeddings.
Model
Onto2Vec
Onto2Vec-Parent
Onto2Vec-Ancestor
Onto2Vec-Sum
Onto2Vec-Mean
Bio-JOIE (KM only)
Bio-JOIE

3.5

Purity Score
0.2339
0.2452
0.3224
0.3022
0.2616
0.2514
0.3306

Case Study: SARS-CoV-2-Human Protein
Target Prediction

The COVID-19 pandemic requires many eï¬€orts and attentions from
scientists of diï¬€erent ï¬elds. However, there is very limited knowledge of the molecular details of SARS-CoV-2. In this subsection,
we apply Bio-JOIE to gain more insights of the PPI network between SARS-CoV-2 and human proteins. Speciï¬cally, we explore
the potential of Bio-JOIE on predicting whether a pair of human
and SARS-CoV-2 proteins interact or not. This is modeled as a binary prediction task. Correspondingly, results from the binary predictions can serve as a guide to identify the targeted proteins by
SARS-CoV-2. We ï¬rst use the known interactions between these
two species to validate the eï¬€ectiveness of Bio-JOIE. These interactions are experimentally veriï¬ed as described in Section 3.1. In
this setting, we particularly study the contribution of the knowledge of other closely related viruses (SARS-CoV and MERS) on
supporting PPI prediction. We also show the high-conï¬dence candidates of targeted human proteins predicted by Bio-JOIE for four
selected SARS-CoV-2 proteins.
Experimental setting. In this experiment, we randomly split the
known positive human-virus PPIs into train and test sets with a
ratio of 80% and 20%. We train Bio-JOIE on this train set along
with human PPIs. For evaluation, positive test samples and selected
negative samples, mentioned in Section 3.1 are used to perform
binary
prediction.
We adopt
F1-score
as the evaluation
Results.
As in Section
3.3, we
ï¬rst evaluate
Bio-JOIEmetric.
on SARSCoV-2 PPI prediction. From the observation in Section 3.3, two important factors are considered: three aspects in the gene ontology
domain and the scope of input SARS-CoV-2-Human PPIs. More
speciï¬cally, we deï¬ne increasingly four scopes of input PPIs, as
shown in Figure 5, i.e. (1) S1: Only using the train folds of SARSCoV-2-Human PPIs; (2) S2: Using SARS-CoV-2-Human PPIs with
the 2-hop neighbor proteins from SARS-CoV-2 viral proteins, i.e.
including the ones which also interact with any proteins that the
SARS-CoV-2 interacts; (3) S3: SARS-CoV-2-Human PPIs with all
other protein interactions on human; (4) S4: SARS-CoV-2-Human

Hao, et al.

S1: SARS-CoV2
PPIs

SARS-CoV PPIs

S2: SARS-CoV2 PPIs + 2-hop
Protein Neighbor Subnet

MERS PPIs

S3: SARS-CoV2 PPIs + All Human PPIs
S4: S3 + SARS-CoV/MERS PPIs

Figure 5: Diï¬€erent scopes of input to train Bio-JOIE for
SARS-CoV-2 PPI prediction.
Table 7: F-1 score on SARS-CoV-2-Human PPI interaction
classiï¬cation.
Input
NonGO
BP
CC
MF
BP+CC
BP+MF
CC+MF
AllGO

S1
0.6737
0.7103
0.7188
0.6737
0.7257
0.7252
0.7317
0.7307

S2
0.7004
0.7353
0.7383
0.7016
0.7570
0.7479
0.7622
0.7537

S3
0.6918
0.7348
0.7380
0.7022
0.7499
0.7486
0.7692
0.7500

S4
0.6997
0.7492
0.7675
0.7365
0.7813
0.7713
0.7917
0.7885

PPIs with all protein interactions in S3 plus all SARS-CoV and
MERS PPIs. As for the aspects of the gene ontology domain, similar
to Table 4 in Section 3.3, we adopt eight options, i.e. one without
gene ontology information (NonGO), three using a single aspect
of GO terms (BF, CC, MF), three options using two of the aspects
(BF+CC, etc) and one using all three aspects (AllGO).
The results are summarized in Table 7. In terms of gene ontology aspects, we observe that CC contributes the most compared
to other aspects of gene ontology annotations, and the best performance is achieved by adopting CC+MF in Bio-JOIE learning. One
explanation is that most of the SARS-CoV-2 proteins have CC annotations and these annotations make up over 70% of all currently
available annotations on average. However, less than 5 proteins
(such as NSP and ORF 1a) have BF and MF annotations, possibly
due to insuï¬ƒcient knowledge on understanding SARS-CoV-2 biological mechanism. As for the input ï¬elds, we ï¬nd that the performance drastically increases with the expansion of input from S1
to S2, which indicates that interactions of 2-hop neighbor proteins
can beneï¬t SARS-CoV-2 PPI prediction. However, such a trend is
not clearly observed when expanding the input ï¬eld from S2 to S3.
We hypothesize that proteins that are not within 2-hop neighbors
may not be very related to SARS-CoV-2 or provide beneï¬cial insights. Interestingly, when adding interactions of two related coronaviruses (SARS-CoV/MERS-CoV) that cause respiratory infection,
the performance continues to improve with a relative gain of 3.4%.
As shown in Figure. 2, viruses that are closely related to SARS-CoV2 tend to share important properties. This strongly suggests that

Joint Representation Learning of Biological Knowledge Bases

BCB â€™20, September 21â€“24, 2020, Virtual Event, USA

it is crucial to leverage their interactions and gene ontology annotations as augmented knowledge for drastically emerging SARSCoV-2.

SARS-CoV-2
ORF8
NSP13
M
NSP7

Targeted proteins in human
P05556, P61019, Q9Y4L1, P17858, Q92769,
Q9BQE3, Q9NQC3, Q9NXK8, P33527, P61106
Q99996, P67870, P35241, O60885, P26358,
Q9UHD2, Q12923, Q86YT6, Q04726, P61106
P26358, Q9NR30, O75439, Q15056, P61962,
P49593, P33993, O60885, Q9Y312, P78527
P62834, P51148, P62070, P67870, O14578,
Q8WTV0, P53618, Q9BS26, O94973, Q7Z7A1

Besides providing PPI prediction, the proposed model can help
by identifying high-conï¬dence candidates for potential human protein targets; this is considered as a link prediction task. When a
viral protein (such as SARS-CoV-2 M protein) is given as the query,
along with a speciï¬c relation (such as â€œbindingâ€ under the experiment system type of â€œAï¬ƒnity Capture-MSâ€), Bio-JOIE can output
a list of most likely protein targets by enumerating the triples with
top ğ‘“ğ‘Ÿ (â„, ğ‘¡) scores. The predictions are listed in Table 8. It is our observation, Bio-JOIE can successfully predict the high-conï¬dence
human protein targets in the test set from by [12] among its top
predictions (marked as boldfaced entities). Other than the proteins
in the test set, Bio-JOIE can also provide a list of reasonable candidates that possess a relatively high MIST score. For example,
P62834 is one of the top-ranked protein targets of SARS-CoV-2
NSP7 by our Bio-JOIE, which has a MIST score of 0.658. Diving
deep into the facts for P62834, though P62834 is not considered
as a high-conï¬dence target by [12], we observe that both P62834
(RAB1A_HUMAN) and SARS-CoV-2 NSP7 interacts with protein
P62820 (RAB1A_HUMAN). Besides, they are both annotated with
the cellular component GO:0016020 (membrane) and enables molecular function GO:0000166 (nucleotide binding), which are possibly
the reasons for Bio-JOIE making such prediction with a high rank.
Furthermore, Bio-JOIEâ€™s predictions include proteins that are not
covered by [12], which inspires further scientiï¬c research to verify.
We further investigate how the information suï¬ƒciency of SARSCoV-2 related PPIs in training set aï¬€ect the performance. We deï¬ne
the train-set ratio parameter as means the proportions of the SARSCoV-2-Human PPIs that are used for training Bio-JOIE and follow
the aforementioned evaluation protocol on â€œNonGO/S3â€, â€œCC/S3â€,
â€œCC+MF/S3â€ and â€œCC+MF/S4â€ as input other than the control of
SARS-CoV-2-Human PPIs part. We plot the PPI results in Figure
6. As expected, when the proportion of SARS-CoV-2-Human PPIs
used for training increases from 20% to 80%, the F1 score improves
from 0.2-0.3 to around 0.8, which strongly conï¬rms that the known
SARS-CoV-2-Human PPIs serve as one signiï¬cant factor to the PPI
prediction. Moreover, the more knowledge we know about existing SARS-CoV-2 interaction, the more powerful the model is to
predict SARS-CoV-2. We also observe that the performance is not
saturated when the training ratio is approaching 100%, which possibly results from the fact that as a novel coronavirus, the current

0.7
0.6
F-1 Score

Table 8: Top target proteins predicted by Bio-JOIE. Known
interactions from training set are excluded. Proteins that are
considered as high-conï¬dence targets are boldfaced.

0.8

0.5
0.4
0.3

NonGO/L3
CC/L3

0.2

CC+MF/L3
CC+MF/L4

0.2

0.3

0.4

0.5
0.6
0.7
0.8
SARS-CoV-2 PPI train set ratio

0.9

1.0

Figure 6: Bio-JOIE performance on diï¬€erent train-set ratios
of SARS-CoV-2-Human PPIs.

known interactions are still very limited. This encourages the scientiï¬c communities to unearth more knowledge on SARS-CoV-2;
moreover, Bio-JOIE has the potential of bringing about signiï¬cant
advances based on new discoveries.

4 RELATED WORK
In the past decade, much attention has been paid to representation
learning of KBs. Methods along this line of research typically encode entities into low dimensional embedding spaces, where the
relational inference [32], proximity measures and alignment [9]
of those entities can be supported in the form of vector algebras.
Therefore, they provide eï¬ƒcient and versatile methods to incorporate the symbolic knowledge of KGs into statistical learning and
inference. Some existing approaches focus speciï¬cally on computational biology studies [1, 6, 15, 27, 34], which similarly embed
features of biological entities within low-dimensional representations. One representative work related to ours is Onto2Vec [27],
in which protein representations are learned by incorporating the
full semantic content of gene ontology in the feature learning using
Word2Vec [22]. However, Onto2Vec replies on the ontology information, while falls short of capturing the multi-relational semantic
facts that are important to characterize the proximity of biological
entities. For example, regarding the protein and GO terms, the PPI
knowledge and the non-hierarchical relationships between gene
ontology entities (such as â€œregulatesâ€) are not considered.
Another thread of related work is joint representation learning
for multiple KGs, where embedding models are learned to bridge
multiple relational structures for tasks such as entity alignment
and type inference. MTransE [9] jointly learns a transformation
across two separate translational embedding spaces based on oneto-one seed alignment of entities. Later extensions of this model
family, such as KDCoE [7], MultiKE [35] and JAPE [28], require
additional information of literal descriptions [7] and numerical attributes of entities [28, 31, 35] that are generally not available for
biological KB. Our recent development on this line of research, i.e.
JOIE [13] learns a many-to-one mapping between entity embeddings and ontological concept embeddings, and aims at resolving

BCB â€™20, September 21â€“24, 2020, Virtual Event, USA

the entity type inference task using the latent space of the type ontology. One of the caveats is that JOIE does not speciï¬cally incorporate the speciï¬city of concepts in the ontology in the transfer process, for which we ï¬nd to be particularly beneï¬cial in this problem
setting. Besides, the aforementioned methods are mostly for general encyclopedia KBs (such as Wikidata, DBpedia) and have not
been adapted for the purpose the modeling biological KBs. More
speciï¬cally, in contrast to these methods, our method features the
characterization of more complicated many-to-many associations
between proteins and GO terms. Besides, instead of predicting the
alignment of entities, we focus on transferring relational knowledge from one domain to enhance the prediction on the other.

5

CONCLUSION

In this paper, we present a novel model Bio-JOIE, that enables endto-end representation learning for cross-domain biological knowledge bases. Our approach utilizes the knowledge model to capture
structural and relational facts within each domain and motivates
the knowledge transfer by alignments among domains. Extensive
experiments on the tasks of PPI type prediction and clustering
demonstrate that Bio-JOIE can successfully leverage complementary knowledge from one domain to another and therefore enable
learning entity representation in multiple interrelated and transferable domains in biology. More importantly, Bio-JOIE also provides
interaction type predictions on SARS-CoV-2 with human protein
targets, which potentially brings reliable computational methods
seeking new directions on drug design and disease mitigation.
In our main directions of future research, we plan to enhance
and extend entity representations by systematically incorporating
important multimodal features and annotations. For example, primary sequence information and secondary geometric folding features can be modeled simultaneously in protein networks and their
combined representation can lead to a comprehensive understanding that will greatly beneï¬t many downstream applications.

Hao, et al.

[7]
[8]
[9]
[10]
[11]
[12]

[13]

[14]
[15]

[16]

[17]
[18]
[19]

[20]
[21]
[22]

ACKNOWLEDGMENTS
The authors would like to thank the anonymous reviewers for their
supportive, insightful and constructive comments. This work was
partially supported by NSF DBI-1565137, NSF III-1705169, NSF CAREER Award 1741634, NSF DGE-1829071, NSF #1937599, DARPA
HR00112090027, NIH R35-HL135772, Okawa Foundation Grant, Amazon Research Award, NEC Research Gift, and Verizon Media Faculty Research and Engagement Program.

[23]
[24]

[25]

[26]

REFERENCES
[1] Mona Alshahrani, Mohammad Asif Khan, Omar Maddouri, Akira R Kinjo, NÃºria
Queralt-Rosinach, and Robert Hoehndorf. 2017. Neuro-symbolic representation
learning on biological knowledge graphs. Bioinformatics 33, 17 (2017), 2723â€“
2730.
[2] Helen Berman, Kim Henrick, Haruki Nakamura, and John L Markley. 2007. The
worldwide Protein Data Bank (wwPDB): ensuring a single, uniform archive of
PDB data. Nucleic acids research 35, suppl_1 (2007), D301â€“D303.
[3] Jens Bleiholder and Felix Naumann. 2009. Data fusion. CSUR 41, 1 (2009), 1â€“41.
[4] Antoine Bordes, Nicolas Usunier, et al. 2013. Translating embeddings for modeling multi-relational data. In NIPS.
[5] Volha Bryl and Christian Bizer. 2014. Learning conï¬‚ict resolution strategies for
cross-language wikipedia data fusion. In WWW. 1129â€“1134.
[6] Muhao Chen, Chelsea J-T Ju, Guangyu Zhou, Xuelu Chen, Tianran Zhang, KaiWei Chang, Carlo Zaniolo, and Wei Wang. 2019. Multifaceted proteinâ€“protein

[27]
[28]
[29]

[30]

[31]

interaction prediction based on Siamese residual RCNN. Bioinformatics 35, 14
(2019), i305â€“i314.
Muhao Chen, Yingtao Tian, Kai-Wei Chang, Steven Skiena, and Carlo Zaniolo.
2018. Co-training Embeddings of Knowledge Graphs and Entity Descriptions
for Cross-lingual Entity Alignment. In IJCAI.
Muhao Chen, Yingtao Tian, Xuelu Chen, Zijun Xue, and Carlo Zaniolo. 2018.
On2Vec: Embedding-based Relation Prediction for Ontology Population. In
SDM.
Muhao Chen, Yingtao Tian, Mohan Yang, and Carlo Zaniolo. 2017. Multilingual
knowledge graph embeddings for cross-lingual knowledge alignment. In IJCAI.
Gene Ontology Consortium. 2018. The Gene Ontology Resource: 20 years and
still GOing strong. Nucleic acids research 47, D1 (2018), D330â€“D338.
Xavier Glorot and Yoshua Bengio. 2010. Understanding the diï¬ƒculty of training
deep feedforward neural networks. In Proceedings of the thirteenth international
conference on artiï¬cial intelligence and statistics. 249â€“256.
David E Gordon, Gwendolyn M Jang, Mehdi Bouhaddou, Jiewei Xu, Kirsten
Obernier, Kris M White, Matthew J Oâ€™Meara, Veronica V Rezelj, Jeï¬€rey Z Guo,
Danielle L Swaney, et al. 2020. A SARS-CoV-2 protein interaction map reveals
targets for drug repurposing. Nature (2020), 1â€“13.
Junheng Hao, Muhao Chen, Wenchao Yu, Yizhou Sun, and Wei Wang. 2019. Universal Representation Learning of Knowledge Bases by Jointly Embedding Instances and Ontological Concepts. In Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery and data mining. ACM.
Lei Huang, Li Liao, and Cathy H Wu. 2018. Completing sparse and disconnected
protein-protein network by deep learning. BMC bioinformatics 19, 1 (2018), 103.
Yu-An Huang, Zhu-Hong You, Xin Gao, Leon Wong, and Lirong Wang. 2015. Using weighted sparse representation model combined with discrete cosine transformation to predict protein-protein interactions from protein sequence. BioMed
research international 2015 (2015).
Rachael P Huntley, Tony Sawford, Prudence Mutowo-Meullenet, Aleksandra
Shypitsyna, Carlos Bonilla, Maria J Martin, and Claire Oâ€™Donovan. 2015. The
GOA database: gene ontology annotation updates for 2015. Nucleic acids research 43, D1 (2015), D1057â€“D1063.
Tjerko Kamminga, Simen-Jan Slagman, Vitor AP Martins dos Santos, Jetta JE Bijlsma, and Peter J Schaap. 2019. Risk-based bioengineering strategies for reliable
bacterial vaccine production. Trends in biotechnology (2019).
Diederik P Kingma and Jimmy Ba. 2015. Adam: A method for stochastic optimization. ICLR (2015).
Lydie Lane, Ghislaine Argoud-Puy, Aurore Britan, Isabelle Cusin, Paula D Duek,
Olivier Evalet, Alain Gateau, Pascale Gaudet, Anne Gleizes, Alexandre Masselot,
et al. 2012. neXtProt: a knowledge platform for human proteins. Nucleic acids
research 40, D1 (2012), D76â€“D83.
Jianxin Ma, Peng Cui, Xiao Wang, and Wenwu Zhu. 2018. Hierarchical taxonomy
aware network embedding. In Proceedings of the 24th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining. ACM, 1920â€“1929.
Stavros Makrodimitris, Roeland van Ham, and Marcel Reinders. 2019. Sparsity
of Protein-Protein Interaction Networks Hinders Function Prediction in NonModel Species. bioRxiv (2019), 832253.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeï¬€ Dean. 2013.
Distributed representations of words and phrases and their compositionality. In
Advances in neural information processing systems. 3111â€“3119.
Maximilian Nickel, Lorenzo Rosasco, et al. 2016. Holographic Embeddings of
Knowledge Graphs. In AAAI.
Rose Oughtred, Chris Stark, Bobby-Joe Breitkreutz, Jennifer Rust, Lorrie
Boucher, Christie Chang, Nadine Kolas, Lara Oâ€™Donnell, Genie Leung, Rochelle
McAdam, et al. 2019. The BioGRID interaction database: 2019 update. Nucleic
acids research 47, D1 (2019), D529â€“D541.
Irene Papatheodorou, Pablo Moreno, Jonathan Manning, Alfonso MuÃ±oz-Pomer
Fuentes, Nancy George, Silvie Fexova, Nuno A Fonseca, Anja FÃ¼llgrabe,
Matthew Green, Ni Huang, et al. 2020. Expression Atlas update: from tissues
to single cells. Nucleic acids research 48, D1 (2020), D77â€“D83.
Andrew M Saxe, James L McClelland, et al. 2014. Exact solutions to the nonlinear
dynamics of learning in deep linear neural networks. ICLR (2014).
Fatima Zohra Smaili, Xin Gao, and Robert Hoehndorf. 2018. Onto2vec: joint
vector-based representation of biological entities and their ontology-based annotations. Bioinformatics 34, 13 (2018), i52â€“i60.
Zequn Sun, Wei Hu, and Chengkai Li. 2017. Cross-lingual entity alignment via
joint attribute-preserving embedding. In ISWC.
Damian Szklarczyk, John H Morris, Helen Cook, Michael Kuhn, Stefan Wyder,
Milan Simonovic, Alberto Santos, Nadezhda T Doncheva, Alexander Roth, Peer
Bork, et al. 2016. The STRING database in 2017: quality-controlled proteinâ€“
protein association networks, made broadly accessible. NAR (2016).
Paul D Thomas, Valerie Wood, Christopher J Mungall, Suzanna E Lewis, Judith A
Blake, Gene Ontology Consortium, et al. 2012. On the use of gene ontology annotations to assess functional similarity among orthologs and paralogs: a short
report. PLoS computational biology 8, 2 (2012).
Bayu Distiawan Trsedya, Jianzhong Qi, and Rui Zhang. 2019. Entity Alignment
between Knowledge Graphs Using Attribute Embeddings. In AAAI.

Joint Representation Learning of Biological Knowledge Bases

[32] Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge
Graph Embedding by Translating on Hyperplanes.. In AAAI.
[33] Bishan Yang, Wen-tau Yih, Xiaodong He, et al. 2015. Embedding entities and
relations for learning and inference in knowledge bases. In ICLR.
[34] Zhu-Hong You, Keith CC Chan, and Pengwei Hu. 2015. Predicting proteinprotein interactions from primary protein sequences using a novel multi-scale
local feature representation scheme and the random forest. PloS one 10, 5 (2015).
[35] Qingheng Zhang, Zequn Sun, Wei Hu, Muhao Chen, Lingbing Guo, and Yuzhong
Qu. 2019. Multi-view Knowledge Graph Embedding for Entity Alignment. In

BCB â€™20, September 21â€“24, 2020, Virtual Event, USA

IJCAI.
[36] Yadi Zhou, Yuan Hou, Jiayu Shen, Yin Huang, William Martin, and Feixiong
Cheng. 2020. Network-based drug repurposing for novel coronavirus 2019nCoV/SARS-CoV-2. Cell discovery 6, 1 (2020), 1â€“18.
[37] Marinka Zitnik, Monica Agrawal, and Jure Leskovec. 2018. Modeling polypharmacy side eï¬€ects with graph convolutional networks. Bioinformatics 34, 13
(2018), i457â€“i466.

