Inference in mixed causal and noncausal models with
generalized Studentâ€™s t-distributions

arXiv:2012.01888v1 [econ.EM] 3 Dec 2020

Francesco Giancateriniâˆ— and Alain Hecq
Department of Quantitative Economics
School of Business and Economics
Maastricht University
December, 2020

Abstract

This paper analyzes the properties of the Maximum Likelihood Estimator for mixed
causal and noncausal models when the error term follows a Studentâ€™s tâˆ’distribution. In
particular, we compare several existing methods to compute the expected Fisher information matrix and show that they cannot be applied in the heavy-tail framework. For
this purpose, we propose a new approach to make inference on causal and noncausal
parameters in finite sample sizes. It is based on the empirical variance computed on the
generalized Studentâ€™s t, even when the population variance is not finite. Monte Carlo
simulations show the good performances of our new estimator for fat tail series. We
illustrate how the different approaches lead to different standard errors in four time series: annual debt to GDP for Canada, the variation of daily Covid-19 deaths in Belgium,
the monthly wheat prices and the monthly inflation rate in Brazil.
Keywords: MLE, noncausal models, generalized Studentâ€™s t-distribution, inference.
JEL: C22

1

Introduction

Mixed causal and noncausal models (MAR) are time series processes with both leads and lags
components. Such specifications allow to capture nonlinear features such as bubbles, namely processes that experience a rapid increase followed by a sudden crash. Linear autoregressive models
(e.g. ARMA models) cannot exhibit these bubble patterns. MAR models have successfully been
implemented on several time series, for instance: commodity prices, inflation rate, bitcoin and
âˆ— Corresponding author: Francesco Giancaterini, Maastricht University, School of Business and Economics, Department of Quantitative Economics, P.O.box 616, 6200 MD, Maastricht, The Netherlands.
Email: f.giancaterini@maastrichtuniversity.nl.
The authors would like to thank Sean Telg, Elisa Voisin and Ines Wilms for their various suggestions. All errors are
ours.

1

2

other equity prices. Furthermore, forecasts from mixed causal and noncausal models often beat
those from linear ones. They also have an economic flavor. They are interpreted as situations in
which economic agents have more information then econometricians, linking MAR models with the
existence of non-fundamentalness in structural econometric models (see Alessi et al. (2011) and
Lanne and Saikkonen (2013)). Still their estimation and in particular making inference on MAR
parameters is far from trivial.
This paper analyzes the behaviour of the Maximum Likelihood Estimator (MLE) for mixed
causal and noncausal models with an error term following Studentâ€™s tâˆ’distributions. Although
most theoretical results for MARs are derived under the assumption of finite variance of the error
term (see i.a. Breidt, Davis, Li & Rosenblatt (1991); Lanne & Saikkonen (2011)), we emphasize
that working with the generalized version of the Studentâ€™s t allows to also cover infinite variance
cases (when the degree of freedom 1 < Î½ â‰¤ 2). Many studies on commodity prices (see Fries
and Zakoian (2019); Hecq and Voisin (2019, 2020) ; Hecq, Issler and Telg (2020)) reveal that the
estimated degrees of freedom of the Studentâ€™s t lie between 1.5 and 2. The alternative methods to
make inference in the infinite variance cases would be either to work with a different asymptotic
theory (Davis and Resnick (1985)), or to use different distributions (see the work on alpha stable
distributions by Fries and Zakoian (2019)), or, in case of purely noncausal models, to rely on bootstrap estimators (Cavaliere, Nielsen and Rahbek, (2020)).
The rest of the paper is organized as follows. Section 2 introduces mixed causal and noncausal
models. Section 3 presents the different ways of obtaining the expected Fisher information matrix
for MARs. The existing strategies are briefly reviewed. Section 4 proposes a new approach to compute the standard errors of causal and noncausal parameters, based on a robust estimator of the
residuals. We show its validity in finite samples. Section 5 studies, using Monte Carlo simulations,
the performances of the current methodologies and of the new approach. Section 6 is dedicated to
the empirical applications on four different time series. Section 7 concludes.

2

Mixed causal and noncausal models

Breidt et al. (1991) introduce a maximum likelihood procedure for estimating the parameters of
noncausal processes. Their starting point is the autoregressive model
a(L)yt = Îµt ,

(1)

where L is the backshift operator, Îµt is an independent and identically (i.i.d.) non-Gaussian1 sequence of random variables with mean zero and finite variance. It is assumed that the autoregressive
polynomial a(z) = 1 âˆ’ Ï†1 z âˆ’ Â· Â· Â· âˆ’ Ï†z z p has no roots on the unit circle, so that Ï†(z) 6= 0 for |z| = 1.
Breidt et al. (1991) further assume that the polynomial a(z) has respectively s roots inside and r
outside the unit circle. Equation (1) can be factored in
a(z) = Ï•(z)âˆ— Ï†(z),

(2)

where Ï•(z)âˆ— is called the noncausal polynomial since its roots are inside the unit circle such that
1âˆ’Ï•âˆ—1 z âˆ’...âˆ’Ï•âˆ—s z s 6= 0 for |z| â‰¥ 1. Breidt et al. (1991) derive the covariance matrix of the estimated
parameters only for probability density functions of Îµt that satisfy a certain set of assumptions listed
in Section 3. The generalized Studentâ€™s tâˆ’distribution with degrees of freedom equal or less than
1 The

non-Gaussianity of Îµt is required to identify noncausal from causal models.

3

2, does not satisfy one of these assumptions and, as a consequence, this approach cannot be used
in the heavy-tail framework. Lanne and Saikkonen (2011) directly start with a mixed causal and
noncausal model expressed as the product of the backward and forward looking polynomials
Ï†(L)Ï•(Lâˆ’1 )yt = t ,

(3)

where Lâˆ’1 produces leads such that Lâˆ’1 yt = yt+1 . We denote such a model a MAR(r,s) with Ï†(L)
the causal/autoregressive polynomial of order r and Ï•(Lâˆ’1 ) the noncausal/lead polynomial of order
s. With this representation it is assumed that both Ï†(z) and Ï•(z) have their roots outside the unit
circle:
Ï†(z) 6= 0 and Ï•(z) 6= 0 f or |z| < 1.
(4)
Note that purely causal or purely noncausal models are respectively obtained when Ï•(Lâˆ’1 ) = 1
or Ï†(L) = 1. In (3) the parameter vectors Ï† = (Ï†1 , ..., Ï†r ) and Ï• = (Ï•1 , ..., Ï•s ) turn out to be
orthogonal to the parameters that describe the distribution of the error term t (see Lemma 1
of Lanne and Saikkonen (2011)). They can be estimated by an AMLE approach. AMLE refers
to as the approximate maximum likelihood estimators because we lose the r first and the last s
observations when estimating MAR(r, s). An important and useful feature of mixed causal and
noncausal models, is that we can set:
ut = Ï•(Lâˆ’1 )yt â†” ut = Ï†1 utâˆ’1 + Â· Â· Â· + Ï†r utâˆ’r + t ,

(5)

vt = Ï†(L)yt â†” vt = Ï•1 vt+1 + Â· Â· Â· + Ï•s vt+s + t .

(6)

In order to obtain the standard errors of the estimated parameters, Lanne and Saikkonen work
with a density function which satisfies similar assumptions presented in Breidt et al. (1991) and,
in particular, that it must have a finite variance.
Hecq, Lieb and Telg (2016) propose a new approach to more easily compute the standard errors
for MAR(r, s) using the generalized tâˆ’distribution and relying on the results developed for the
linear regression model by Fonseca et al. (2008). Their approach, also implemented in the R
package MARX, works if and only if E(|t |2 ) < âˆ and hence if the degrees of freedom is larger
than 2. We show however that this approach can be misleading as it imposes strong restrictions
that can lead to incorrect estimates of the standard errors.

3

Asymptotic standard errors for maximum likelihood estimation

Let us consider a general density function f and denote the likelihood function of Î¸ by
L(Î¸) =

T
Y

f (t |Î¸).

t=1

We indicate with Î¸0 = (Î¸1 , ..., Î¸p ) the vector of the true values of the causal and noncausal coefficients (p = r + s). The other parameters of the general density function (degrees of freedom and
scale parameter), are, for the moment, assumed to be known and equal to their true population

4

values; we will show next that they are independent from the estimation of Î¸. Furthermore, we assume that t has a finite variance, equal to Ïƒ 2 . Taking the logs of L(Î¸), we obtain the log-likelihood
function
T
X
l(Î¸) = ln L(Î¸) =
ln(f (t |Î¸)).
(7)
t=1
Î´l(Î¸)
Î´Î¸

the score vector of the log-likelihood, the MLE of Î¸ is given by the solution
Defining b(Î¸) =
b to the p = r + s equations b(Î¸)
b = 0. If the sample size is sufficiently large, it turns out that the
Î¸
b can be well approximated by 2
distribution of the maximum likelihood estimation Î¸
b â‰ˆ N (Î¸ 0 , I(Î¸0 )âˆ’1 ),
Î¸

(8)

where I is the expected Fisher information matrix
I(Î¸0 ) = âˆ’E

 Î´ 2 l(Î¸0 ) 
.
Î´Î¸0 Î´Î¸0 0

(9)

Since it is not always trivial to evaluate analytically the expected value of the Hessian matrix, we
can also compute the observed Fisher information matrix:
I(Î¸0 ) = âˆ’

 Î´ 2 l(Î¸0 ) 
Î´Î¸0 Î´Î¸0 0

.

(10)

For the law of large numbers I(Î¸0 ) converges in probability to I(Î¸0 ). In practice, since the true
value of Î¸ is not known, these two matrices are obtained by replacing the population parameters
b and I(Î¸).
b
by their ML estimates to get I(Î¸)
Let us start with I(Î¸0 ), the observed information matrix of a MAR(r, s) as described in (3).
We consider t i.i.d. and distributed according to a generalized Studentâ€™s t distribution, such that
its density function at time t is:
"
 2 #
Î“( Î½02+1 )
1 t
fÏƒ0 (t , Î½0 , Î·0 ) =
1+
,
(11)
âˆš
Î“( Î½20 ) Ï€Î½0 Î·0
Î½0 Î·0
with the corresponding approximate log-likelihood function, conditional on y = [y1 , . . . , yT ], equal
to:
"  

q

  #
Î½0 + 1
Î½0
l(Ï†, Ï•, Î½0 , Î·0 |y) = (T âˆ’ p) ln Î“
âˆ’ ln
Î½0 Ï€Î·02 âˆ’ ln Î“
+
2
2


2 
T âˆ’s
Î½0 + 1 X
1 Ï†(L)Ï•(Lâˆ’1 )yt
âˆ’
ln 1 +
. (12)
2 t=r+1
Î½0
Î·0
We indicate with Î½0 and Î·0 respectively the true values of the degrees of freedom and of the
scale parameter. Instead, Ïƒ02 denotes the true value of the variance of the error term which, in a
generalized Studentâ€™s tâˆ’distribution, is equal to
Ïƒ02 = Î·02
2 We

use the notation of Hamilton (1984, p.143).

Î½0
,
Î½0 âˆ’ 2

âˆ€Î½0 > 2.

5

In this case, we have that I(Î¸0 ) is given by
" Î´2 l(Î¸
I(Î¸0 ) = âˆ’

0)

Î´Ï†0 Ï†0 0
Î´ 2 l(Î¸0 )
Î´Ï•0 Ï†0 0

Î´ 2 l(Î¸0 )
Î´Ï†0 Ï•0 0
Î´ 2 l(Î¸0 )
Î´Ï•0 Ï•0 0

#
,

(13)

knowing that, in the general case:
 T âˆ’s

 T âˆ’s

P
P
Î´l((Î¸)
âˆ’4
2 âˆ’2
0
2
âˆ’2
2 âˆ’1
0
)
U
U
=
2(Î½
+
1)Î·
(Î½
+
z
)
U
U
[z
Î·]
âˆ’
(Î½
+
1)Î·
(Î½
+
z
tâˆ’1 tâˆ’1 t
tâˆ’1 tâˆ’1 ;
t
t
Î´Ï†Ï†0
t=r+1
t=r+1
 T âˆ’s

 T âˆ’s

P
P
Î´l((Î¸)
âˆ’4
2 âˆ’2
0
2
âˆ’2
2 âˆ’1
0
=
2(Î½
+
1)Î·
(Î½
+
z
)
V
V
[z
Î·]
âˆ’
(Î½
+
1)Î·
(Î½
+
z
)
V
V
t+1 t+1 t
t+1 t+1 ;
t
t
Î´Ï•Ï•0
t=r+1
t=r+1
 T âˆ’s

 T âˆ’s

P
P
Î´l((Î¸)
âˆ’4
2 âˆ’2
0
2
âˆ’2
2 âˆ’1
0
=
2(Î½
+1)Î·
(Î½
+z
)
U
V
[z
Î·]
âˆ’(Î½
+1)Î·
(Î½
+z
)
(U
V
+Y
)
;
tâˆ’1 t+1 t
tâˆ’1 t+1
t
t
t
Î´Ï†Ï•0
t=r+1

âˆ’1

t=r+1

âˆ’1

)yt
t
= Ï•(L Î· )vt = Ï†(L)Ï•(L
, Utâˆ’1 = (utâˆ’1 , . . . , utâˆ’r ), Vt+1 = (vt+1 , . . . , vt+s )
with zt = Ï†(L)u
Î·
Î·
and Yt is a matrix r Ã— s with elements ytâˆ’i+j (i = 1, . . . , r and j = 1, . . . , s).
Section 3.1 shows that in mixed causal and noncausal models, the expected Fisher information
matrix (unlike I(Î¸Ì‚)) cannot be computed when the population variance is not finite. In Section 5
we will evaluate, by means of Monte Carlo simulations, whether the observed Fisher information
matrix still allows to respect Equation (8) in this context.

3.1

Lanne and Saikkonenâ€™s methodology

Lanne and Saikkonen (2011) propose to calculate the asymptotic covariance matrix using a general
(Lebesgue) density function, which depends on parameters vector Î», where all the distributional
parameters are collected (scale parameter and degrees of freedom which, exactly as the previous
section, are respectively indicated with Î· and Î½). Furthermore, it is characterized by an i.i.d
innovation term with finite and constant variance, equal to Ïƒ 2 . Similar conditions as of Andrews
et al. (2006) must be satisfied. In details these are:
(A1) For all x âˆˆ R and all Î» âˆˆ Î›, f (x, Î») > 0 and f (x, Î») is twice continuously differentiable with
respect to (x, Î»).
R
(A2) For all Î» âˆˆ Î› , xf 0 (x, Î»)dx = âˆ’1.
R
(A3) f 00 (x; Î»)dx = 0.
R
(A4) x2 f 00 (x, Î»)dx = 2.
R
(A5) J = (f 0 (x, Î»))2 /f (x, Î»)dx > 1.
(A6) The matrix â„¦ is positive definite.3
(A7) For j, k = 1, ..., d and all Î» âˆˆ Î›0 ,
3 Matrix

defined in Equation (11) in Lanne and Saikkonen (2011).

6

â€¢ f (x, Î») is dominated by a function f1 (x, Î») such that

R

x2 f1 (x)dx < âˆ, and

|Î´2 f (x,Î»)/Î´j Î´k |
are dominated
f (x;Î»)
R c1
c1
by a1 + a2 |x| , where a1 , a2 , and c1 are nonnegative constants and |x| f1 (x)dx < âˆ.
0

2

2
â€¢ x2 (ff(x,Î»))
(x,Î») , x

f 00 (x,Î»)
f (x;Î»)

, |x|

Î´f 0 (x;Î»)/Î»j
f (x;Î»)

,

(Î´f 0 (x;Î»)/(Î´Î»j ))2
,
f 2 (x;Î»)

and

In this Section we relax the assumption that the distributional parameters of density f are known.
Also, we need to introduce some notation used in their paper. Let Î¶t âˆ¼ i.i.d (0, 1) and define the
AR(r) stationary process uâˆ—t by Ï†0 (L)uâˆ—t = Î¶t and the AR(s) stationary process vtâˆ— by Ï•0 (L)vtâˆ— = Î¶t .
âˆ—
âˆ—
âˆ—
âˆ—
Let also define Utâˆ’1
= (uâˆ—tâˆ’1 , . . . , uâˆ—tâˆ’r ), Vtâˆ’1
= (vtâˆ’1
, . . . , vtâˆ’s
) and the associated covariance maâˆ—
âˆ—
âˆ—
âˆ—
trices Î“U âˆ— = Cov(Utâˆ’1 ), Î“V âˆ— = Cov(Vtâˆ’1 ) and Î“U âˆ— V âˆ— = Cov(Utâˆ’1
, Vtâˆ’1
) = Î“0V âˆ— U âˆ— .
Theorem 1 (by Lanne et al., 2011) Given conditions (A1)-(A7), there exists a sequence of
b = (Ï†,
b Ï•
b , Î·b, vb) of lt (Î¸) in (7) such that
local maximizers Î¸
d
b âˆ’ Î¸0 ) âˆ’
(T âˆ’ p)1/2 (Î¸
â†’ N (0, diag(Î£âˆ’1 , â„¦âˆ’1 )),

where Î£âˆ’1 is the asymptotic variance-covariance matrix of the AML estimators (Ï†, Ï•), such that


  2
J Î“U âˆ— Î“U âˆ— V âˆ—
Ïƒ JËœÎ“U âˆ—
Î“U âˆ— V âˆ—
(14)
Î£=
=
Î“V âˆ— U âˆ— J Î“V âˆ—
Î“V âˆ— U âˆ—
Ïƒ 2 JËœÎ“V âˆ—
and â„¦âˆ’1 is the asymptotic variance-covariance matrix of the distributional parameters.
Lanne and Saikkonen (2008) show in detail how to obtain the Î£ matrix. Furthermore, they
show that we have a block diagonality because the representation (3) and the conditions (A2)(A4). Due to the block diagonality of the covariance matrix of the limiting distribution, the AML
b Ï•
b ) and (b
estimators of (Ï†,
Î½ , Î·b) are asymptotically independent. The matrix Î£ is positive definite
if condition (A5) is true (J > 1). To see for which type of distribution (A5) holds, we need to
take into consideration Remark 2 of Andrews et al. (2006). They show that, using (A2) and the
Cauchy-Schwarz inequality
2  Z
Z  0
2

Z
fÏƒ (x, Î»)
fÏƒ0 (x, Î»)
2
fÏƒ (x, Î»)dx â‰¤
x fÏƒ (x, Î»)dx
fÏƒ (x, Î»)dx = Ïƒ 2 JËœ, (15)
1=
x
fÏƒ (x, Î»)
fÏƒ (x, Î»)
with an equality if and only if f is gaussian. Hence, (A5) is true for non-gaussian f since JËœ can be
rewritten as
Z
(f 0 (x, Î»))2
âˆ’2
Ëœ
J =Ïƒ
dx = Ïƒ âˆ’2 J ,
(16)
f (x, Î»)
where the density function inside the integral, refers to a rescaled density function (that is with
unit variance). In other words, we have that Î£ is positive definite if Ïƒ 2 JËœ > 1 or if (A5) is true.4
In our case, we have t i.i.d. according to a generalized Studentâ€™s t distribution and:



Z 0
fÏƒ (t , Î½, Î·)2
Î½(Î½ + 1)
2 Ëœ
2
2 Î½
âˆ’2 Î½ + 1
Ïƒ J =Ïƒ
dt = Î·
Î·
=
> 1 (âˆ€Î½ > 2),
fÏƒ (t , Î½, Î·)
Î½âˆ’2
Î½+3
(Î½ âˆ’ 2)(Î½ + 3)
with fÏƒ (t , Î½, Î·) defined in (11). It is easy to see that this approach works if and only if t has
4 The condition Ïƒ 2 JËœ > 1 is stated in Breidt et al. (1991). Instead, the condition J > 1 is stated in Lanne and
Saikkonen (2011). They are exactly equivalent.

7

finite variance. This is the reason why most authors (e.g. Lanne and Saikkonen (2011)) use a
standardized Studentâ€™s tâˆ’distribution (such that Ïƒ = Î·) in their empirical application. When we
consider this type of standardized distribution, the log-likelihood function is:
"
Î“( Î½+1
1
2 )
q
1+
l (Ï†, Ï•, Î½0 , Î·0 |y) = ln
Î½
Î½ âˆš
Î½âˆ’2
Î“( 2 ) Ï€Î½Î·
Î½
(

0

Ï†(L)Ï•(Lâˆ’1 )yt
q
Î· Î½âˆ’2
Î½

!2 #âˆ’ Î½+1
)
2
,

such that, unlike (12), its structure ensures convergence for Î½ > 2 (hence finite variance). This is the
shortcoming of this approach: we cannot take into consideration series with degrees of freedom less
than 2. This is restrictive for series such as stock prices, commodity prices, bitcoin, etc. where heavy
tails are observed with a degree of freedom that ranges between, 1.3 and 1.9 (without reaching the
Cauchy for Î½ = 1 though). We also observe that the heavier the tails are, the faster the estimator
seems to converge (see Hecq et al. (2016)).

3.2

Diagonality of the conditional expected Fisher information matrix

Hecq et al. (2016) take their inspiration from the conclusions of Fonseca et al. (2008) who consider
the linear regression model
0
yi = Xi Î² + i (i = 1, ..., T ),
(17)
where Xi and Î² are both vectors pÃ—1 and i are i.i.d. following a generalized Studentâ€™s t-distribution
with Î½ degrees of freedom and a scale parameter Î·, such that
c(Î½, Î· 2 ) =

Î½/2
Î“( Î½+1
2 )Î½
p
,
Î“( Î½2 ) Ï€Î· 2

(18)

the log-likelihood function being
T

l(Î², Î·, Î½|y, X) = T ln[c(Î½, Î· 2 )] âˆ’

Î½+1X
ln(Î½ + zi2 ),
2 i=1

(19)

0

where zi =

yi âˆ’Xi Î²
.
Î·

The first derivative of the log-likelihood function with respect to Î² is given by


0
T
X
Î´l(Î², Î·, Î½|y, X)
Xi (yi âˆ’ Xi Î²)
2 âˆ’1
= (Î½ + 1)
(Î½ + zi ) (Î½ + 1)
,
Î´Î²
Î·2
i=1
whereas the second derivative with respect to Î², applying the product and chain rule is


T 
T 
X
X
0
0
Î´ 2 l(Î², Î·, Î½|y, X)
âˆ’4
2 âˆ’2
2
âˆ’2
âˆ’1
0
=
2(Î½+1)Î·
(Î½+z
)
(X
X
)(y
âˆ’X
Î²)
âˆ’(Î½+1)Î·
(Î½+z
)
(X
X
)
i
i
i
i
i
i
i
i .
Î´Î² 0 Î´Î²
i=1
i=1
(20)

8

In order to obtain the expected Fisher information I(Â·) with respect to Î², we have to take the
expectation of this expression and multiply it by -1. Fonseca et al. (2008) show that:

I(Î²) = âˆ’E


T
X
0
Î´ 2 l(Î², Î·, Î½|y, X)
âˆ’2 Î½ + 1
=
Î·
Xi Xi .
Î½ + 3 i=1
Î´Î² 0 Î´Î²|Î²

(21)

Hecq et al. (2016) adapt the results obtained by Fonseca et al. (2008) in the context of the
noncausal model setup. That is, they consider a general MAR(r, s) model
Ï†(L)Ï•(Lâˆ’1 )yt = t ,

(22)

where t âˆ¼ t(Î½, Î·). To ensure a similar model setup, Hecq et al. (2016) use representations (5) and
(6). They replace the aforementioned alternative representations of noncausal model to the original
linear representation (17), so that they can compute the standard errors of the causal/noncausal
coefficients using the results of Fonseca et al. (2008). In other words, they obtain the standard
errors of the causal coefficient using (5) and assuming the noncausal parameters as known. Instead,
for the standard errors of the noncausal parameters, they use representation (6) supposing that the
causal coefficients are known. This is of course an approximation which leads to a block diagonal
and conditional expected Fisher information matrix (14). For instance, in a MAR(1,1) they obtain
the following conditional expected Fisher information matrices for the causal and the noncausal
parts
 2

Î´ l(Ï†, Î·, Î½|Ï•)
I(Ï†|Ï•) = âˆ’E
,
Î´Ï†2
 2

Î´ l(Ï•, Î·, Î½|Ï†)
I(Ï•|Ï†) = âˆ’E
Î´Ï•2
implying both

Î´ 2 l(Â·)
Î´Ï†Î´Ï•

= 0 and

Î´ 2 l(Â·)
Î´Ï•Î´Ï†

= 0; hence
" Î´2 l(Ï†,Î·,Î½|Ï•)

I(Ï†, Ï•) = âˆ’E

Î´Ï†2

0

0
Î´ 2 l(Ï•,Î·,Î½|Ï†)
Î´Ï•2

#
.

(23)

Obviously, when we invert I(Ï†, Ï•), we have different results from those that we obtain if we would
have inverted the complete Fisher information matrix. Hecq et al. (2016) illustrate that this approximation gives mildly satisfactory results.
Furthermore, exactly as Lanne and Saikkonen (2011), Hecq et al. (2016) state that this methodology can be applied only if the error term has a finite variance (hence if Î½ > 2). A closed form
solution for these limiting distributions does not exist (see Davis et al. (1992) and Andrews et
al. (2013)) and this problem could be overcome by means of bootstrapping and simulation-based
models.

3.3

Simulation study

In this section, we investigate the conclusions obtained by Hecq et al. (2016) in the finite variance
case of the error term. In particular, we want to evaluate to what extent the assumption of the
block diagonality of the conditional expected Fisher information matrix yields misspecified standard

9

errors. Indeed their approach is implemented in the R package MARX and has been applied in
several researches. For this purpose, we compute the empirical density functions of the percentage
difference of the standard errors obtained through the two aforementioned approaches. In particular,
we analyze the empirical density functions of ZÏ†,i and ZÏ•,j , where:
ZÏ†,i =

S.E.L.Ï•,j âˆ’ S.E.H.Ï•,i
S.E.L.Ï†,i âˆ’ S.E.H.Ï†,i
Ã— 100 ; ZÏ•,j =
Ã— 100.
S.E.H.Ï†,i
S.E.H.Ï•,j

S.E.L.Ï†,i indicates the standard error of the i-th causal coefficient obtained through the expected
Fisher information matrix (Î£), with i âˆˆ [1, r]. Instead, S.E.H.Ï†,i represents the standard error of
the i-th causal coefficient derived from Hecq et al.â€™s approach. The same is true for true for S.E.L.Ï•,j
and S.E.H.Ï•,j . The only difference is that the latters refer to the j-th noncausal coefficient, with
j âˆˆ [1, s].
The data generating process is a MAR(1,1) with a scale parameter Î· = 5, T=1000 observations
and 10000 replications. In addition, we consider different values of degrees of freedom (Î½0 =3, Î½0 =4
and Î½0 =5) and different combinations of values for the causal/noncausal coefficients, that is:
â€¢ Ï†0 =0.65, Ï•0 =0.35;
â€¢ Ï†0 =0.5, Ï•0 =0.5;
â€¢ Ï†0 =0.35, Ï•0 =0.65.
Figures 1-3 show the empirical density functions of ZÏ† and of ZÏ• obtained through Monte Carlo
experiments.
We conclude that the standard errors proposed by Lanne and Saikkonen (2011) should be used
for non-heavy tailed models. The approximation developed in Hecq et al. (2016) on the other hand,
underestimates the standard errors and consequently provides a too narrow confidence interval.
Furthermore, such underestimation decreases with decreasing degrees of freedom. Hence, although
the approach proposed by Hecq et al (2016) is easy to implement, it should be applied in cases
of heavy tail disturbances, or where the Lanne and Saikkonen (2011)â€™s method already show some
convergence problems. This happens, due to estimation uncertainty, when the degrees of freedom
is small even though the population variance is finite.

4

A new approach based on the robust estimate of residuals
in finite samples

In this section we propose a new methodology to compute the standard errors of MAR parameters.
It is valid for mixed causal and noncausal models whenever the error term is distributed according
to a generalized Studentâ€™s tâˆ’distribution and the sample size is finite. Although in the heavytail framework it is not possible to derive the theoretical limiting distributions of these parameters,
Monte Carlo simulations in the next section show how our new estimator empirically satisfies Equation (8) for Î½ âˆˆ (1, D], with D < âˆ.
In Section 3.1, it is stated that the variance of the error term (Ïƒ 2 ) multiplies the block diagonal matrices of the Expected Fisher information matrix defined in (13). Since the Studentâ€™s
tâˆ’distribution with heavy-tailed innovations is characterized by an undefined variance, the expected Fisher information matrix cannot be computed in this context. Our alternative strategy

10

MAR(1,1): Ï†0 = 0.65, Ï•0 = 0.35, Î½0 = 5
ZÏ†

ZÏ•

MAR(1,1): Ï†0 = 0.5, Ï•0 = 0.5, Î½0 = 5
ZÏ†

ZÏ•

MAR(1,1): Ï†0 = 0.35, Ï•0 = 0.65, Î½0 = 5
ZÏ†

ZÏ•

Figure 1: Density plots of the variables ZÏ† and ZÏ• , based on 5 degrees of freedom and T=1000
observations

11

MAR(1,1): Ï†0 = 0.65, Ï•0 = 0.35, Î½0 = 4
ZÏ•

ZÏ†

MAR(1,1): Ï†0 = 0.5, Ï•0 = 0.5, Î½0 = 4
ZÏ†

ZÏ•

2

MAR(1,1): Ï†0 = 0.35, Ï•0 = 0.65, Î½0 = 4
ZÏ†

ZÏ•

Figure 2: Density plots of the variables ZÏ† and ZÏ• , based on 4 degrees of freedom and T=1000
observations

12

MAR(1,1): Ï†0 = 0.65, Ï•0 = 0.35, Î½0 = 3
ZÏ†

ZÏ•

MAR(1,1): Ï†0 = 0.5, Ï•0 = 0.5, Î½0 = 3
ZÏ†

ZÏ•

MAR(1,1): Ï†0 = 0.35, Ï•0 = 0.65, Î½0 = 3
ZÏ†

ZÏ•

Figure 3: Density plots of the variables ZÏ† and ZÏ• , based on 3 degrees of freedom and T=1000
observations

13

consists in replacing the variance of the error term with the variance of residuals (Ïƒb2 ) in (13).
Furthermore, especially in those cases where the population variance is not finite (Î½ âˆˆ (1, 2]), we
expect the residuals having a wide range of values. In order to decrease the effect of huge outliers, we estimate the variance of the residuals using the Median Absolute Deviation (MAD) robust
estimator:
M ADb = median(|b
i âˆ’ median(b
i )|)
(24)
and a consistent estimation of the standard deviation is given by:
Ïƒb = k Ã— M ADb .

(25)

Rousseeuw et al. (1993) show that, if we set k to 1.48, Equation (25) ensures convergence to the
standard deviation under the assumption of normality. Let us now find the value of k that provides
a robust estimation of the standard deviation of the residuals if multiplied by the MAD estimator,
under the assumption of Studentâ€™s tâˆ’distribution, for Î½ âˆˆ (1, D]. The standard deviation of the
residuals depends on two different parameters: the degrees of freedom (Î½) and the sample size (T ).
This implies that also k is a function of Î½ and T :
k(Î½, T ) =

Ïƒ
bb (Î½, T )
.
M ADb

(26)

In other words, k is a random variable with different density functions depending on the different
values of Î½ and T . Supposing Î½ = 1.8 and T = 500, to obtain the empirical density function of
k(1.8, 500) we apply a Monte Carlo experiment where the error term is simulated setting Î½ = 1.8
and T = 500.5 In each replication we compute the value of k using Equation (26). In this way, the
Monte Carlo experiment yields as many values of k as the number of replications. To identify from
these values the empirical density function of k, we use the kernel density estimation. The extreme
values of k can affect the non-parametric estimation and to avoid this, we extract all values of k
within the range:


Q1 âˆ’ 3 Ã— IQR, Q3 + 3 Ã— IQR ,
where Q1 and Q3 are respectively the first and the third quartile of k and IQR is its interquartile
range. With the following values, we obtain an empirical density function as shown in Figure 4.
In addition to choosing Î½ = 1.8 and T = 500, we also consider N=700.000 replications. A large
number of replications is important to obtain an empirical density function as accurate as possible.
Finally, in order to obtain a robust estimate of standard deviation of residuals, we take the mode
of k, indicating this value as k âˆ— . Appendix A provides values of k âˆ— for other Î½ and T .
In conclusion, this approach gives us a Fisher information matrix:
 2

Ïƒ JËœÎ“U âˆ—
Î“U âˆ— V âˆ—
Î£Ì„ = b
,
(27)
Î“V âˆ— U âˆ—
Ïƒb2 JËœÎ“V âˆ—
where, using Equation (25), we have:

2
Î½+1
Ïƒb2 JËœ = k âˆ— (Î½, T ) Ã— M ADb Î· âˆ’2
.
Î½+3
5 For now we are not interested in the scale parameter of the error term since, in Equation (26), it is shown that
Î· does not affect k.

14

Figure 4: Empirical density function of k(Î½ = 1.8, T = 500), obtained using 700.000 replications.

5

Monte Carlo simulations

So far we have seen that, for mixed causal and noncausal models with an innovation term distributed
according to a generalized Studentâ€™s tâˆ’distribution, it is not possible to derive the theoretical
limiting distribution in the heavy-tail framework. This section focuses on identifying, through
Monte Carlo experiments, which of the aforementioned estimators of the standard errors satisfies
Equation (8) in finite samples. As previously stated, we will also include in the analysis the standard
b Ï•
b )).
errors obtained by the observed Fisher information matrix (I(Ï†,
For this purpose, we run several Monte Carlo simulations characterized by N=10000 replications
each. The data generating process is a MAR(1,1) with a scale parameter Î·0 = 3 and sample sizes
T =(100, 200, 500, 1000). We also consider several degrees of freedom Î½0 = (3, 1.8, 1.5, 1.2) and
different combinations of causal and noncausal coefficients, that is:
â€¢ Ï†0 =0, Ï•0 =0;
â€¢ Ï†0 =0.65, Ï•0 =0.35;
â€¢ Ï†0 =0.5, Ï•0 =0.5;
â€¢ Ï†0 =0.35, Ï•0 =0.65.
For each replication we test whether the estimated causal and noncausal coefficients are equal to
their respective true values. In particular, we compute two different tâˆ’tests: H0 : Ï† = Ï†0 and H0 :
Ï• = Ï•0 against the two sided alternatives, respectively Ï† 6= Ï†0 and Ï• 6= Ï•0 . Tables 1-14 show
the empirical rejection frequencies (at nominal significance level 5%) obtained using the different
Ë† and I(Ï†,
b Ï•)
methodologies to compute the standard errors. In particular, the columns Î£Ì„
b indicate
the empirical rejection frequencies whenever the standard errors are obtained by the matrices (27)
and (23) respectively.
We observe that for Î½ > 2 (Tables 1-4), Hecq et al. (2016) method provides an empirical
tâˆ’distribution characterized by tails fatter than a standard normal distribution. The reason is that
in the denominator of the tâˆ’test we have underestimated standard errors (see Section 3.3). We also

15

observe that our new approach and the observed Fisher information matrix have less distortions
for small sample sizes (T=100, T=200) than the expected Fisher information matrix. The latter
only gets closer the 5% nominal rejection frequency for T=1000. For Î½ â‰¤ 2 (Tables 5-14) the
expected Fisher information matrix of the causal and noncausal parameters (Î£Ì‚) cannot be derived.
On the other hand, we loose the normality of these parameters whenever the standard errors are
computed through the observed Fisher information matrix. The diagonal conditional expected
b Ï•))
b Ï•),
b performs better than I(Ï†,
b but the results are still far from
Fisher information matrix (I(Ï†,
Ë†)
those that we would have obtained in case of standard normal distribution. Our new approach (Î£Ì„
is the only one that allows us to empirically satisfy Equation (8). Also, this new method provides
empirical rejection frequencies slightly smaller for high values of causal and noncausal coefficients.
This is not a issue of great relevance in terms of inference, as high values are likely significantly
different from zero.

6

Empirical investigations

We illustrate the differences and the similarities in the computed standard errors of MAR models on
four time series. These are: (a) the annual debt to GDP ratio for Canada from 1870 to 2015 (source:
IMF), (b) the variation of daily Covid-19 deaths in Belgium from 10/March/2020 to 17/July/2020
(source: WHO), (c) the monthly wheat prices from January 1990 until September 2020 (source:
IMF) and (d) the monthly inflation rate in Brazil (obtained from year to year difference on IPCA
index6 ) observed from January 1997 to June 2020 (source: Central Bank of Brazil). Figure 5
presents the data. With this panel of applications we want to show that MAR models are also
interesting for modeling other series than the usual commodity prices.
The way to estimate MAR models imply a series of steps. We first estimate a conventional
causal autoregressive model by OLS in order to obtain the lag order p using information criteria
(see Lanne and Saikkonen (2011)). We find p = 2 for three out of the four series, namely for
inflation, debt to GDP ratio and wheat prices whereas p = 4 is chosen for Belgianâ€™s Covid series.
Using an AML approach and searching for the r and s with p = r + s that maximize the generalized
Studentâ€™s t likelihood function, Canadian debt/GDP, wheat prices as well as Brazilian inflation
follow a MAR(1,1) and the variation of Covid-19 deaths a MAR(2,2). We detail next the value
of estimated parameters and their standard errors obtained using methods reviewed and newly
introduced in this paper.
From our simulation results, we can expect some differences and similarities given the degrees
of freedom estimated for the four variables: for the Canadian series Î½Ì‚ = 2.37, for â€˜Covid-19 data
Î½Ì‚ = 1.17, on wheat prices Î½Ì‚ = 2.21 and Î½Ì‚ = 3.22 for Brazilian inflation. Although we observe
fat tails in each series, it is only on daily Belgian data that the the degree of freedom is below 2.
However, none of them is significantly different from two. To check this, we use the standard errors
given by âˆ’(T âˆ’ p)âˆ’1 Î´ 2 lT (Ï†Ì‚, Ï•Ì‚, Î¸2 )/Î´Î¸2 Î´Î¸2 0 with Î¸Ë†2 = (Î½Ì‚, Î·Ì‚), being a consistent estimator of the
expected Fisher information matrix of the distributional parameters â„¦ (see Lanne and Saikkonen
(2011)). This matrix, unlike Î£, has no restrictions and can be computed also when the population
6 The

IPCA targets population families with household income ranging from 1 to 40 minimum wages. This
income range guarantees a 90% coverage of families living in 13 geographic zones: metropolitan areas of BeleÌm,
Fortaleza, Recife, Salvador, Belo Horizonte, VitoÌria, Rio de Janeiro, SaÌƒo Paulo, Curitiba, Porto Alegre, as well as the
Federal District and the cities of GoiaÌ‚nia and Campo Grande. Basket items include Food and Beverages, Housing,
Household Articles, Wearing Apparel, Transportation, Health and Personal Care, Personal Expenses, Education and
Communication.

16

Empirical rejection frequencies - MAR(1,1): Ï†0 = 0, Ï•0 = 0, Î½0 = 3
Sample size

Î£Ì‚
Ï†

T=100
T=200
T=500
T=1000

Ï•

24.26%
14.93%
8.98%
7.17%

23.64%
15.43%
9.35%
7.28%

Ï†

Ï•

12.08%
8.43%
5.82%
5.50%

Ë†
Î£Ì„

b Ï•)
I(Ï†,
b

b Ï•)
I(Ï†,
b
11.70%
8.77%
6.65%
5.48%

Ï†

Ï•

18.36%
14.61%
12.14%
10.50%

18.45%
15.33%
12.25%
10.73%

Ï†

Ï•

9.52%
7.21%
5.26%
4.74%

9.44%
7.53%
5.76%
4.56%

Table 1: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.
Empirical rejection frequencies - MAR(1,1): Ï†0 = 0.65, Ï•0 = 0.35, Î½0 = 3
Sample size
Ï†
T=100
T=200
T=500
T=1000

Ï•

22.37%
13.91%
8.22%
7.38%

22.36%
13.90%
8.42%
6.95%

Ï†

Ï•

10.52%
6.96%
5.47%
5.65%

Ë†
Î£Ì„

b Ï•)
I(Ï†,
b

b Ï•)
I(Ï†,
b

Î£Ì‚

10.83%
7.77%
5.89%
5.37%

Ï†

Ï•

16.85%
12.55%
10.26%
9.66%

16.53%
13.31%
10.27%
9.37%

Ï†

Ï•

8.21%
4.47%
4.76%
4.82%

8.20%
4.80%
5.16%
4.27%

Table 2: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.
Empirical rejection frequencies - MAR(1,1): Ï†0 = 0.5, Ï•0 = 0.5, Î½0 = 3
Sample size

Î£Ì‚
Ï†

T=100
T=200
T=500
T=1000

Ï•

23.50%
14.60%
8.82%
7.30%

23.80%
14.97%
8.95%
7.04%

Ï†

Ï•

11.33%
7.65%
5.85%
5.35%

Ë†
Î£Ì„

b Ï•)
I(Ï†,
b

b Ï•)
I(Ï†,
b
11.16%
8.20%
6.25%
5.32%

Ï†

Ï•

17.44%
14.26%
11.55%
10.64%

17.35%
14.65%
11.91%
10.25%

Ï†

Ï•

8.53%
5.19%
5.08%
4.54%

8.58%
5.21%
5.36%
4.44%

Table 3: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.
Empirical rejection frequencies - MAR(1,1): Ï†0 = 0.35, Ï•0 = 0.65, Î½0 = 3
Sample size

Î£Ì‚
Ï†

T=100
T=200
T=500
T=1000

23.12%
13.47%
8.68%
7.07%

Ï•
22.34%
13.76%
8.66%
6.52%

Ï†
10.80%
7.40%
5.80%
5.37%

Ë†
Î£Ì„

b Ï•)
I(Ï†,
b

b Ï•)
I(Ï†,
b
Ï•
10.47%
6.80%
9.97%
5.21%

Ï†
16.34%
12.44%
10.47%
9.30%

Ï•
16.75%
13.06%
10.48%
9.07%

Ï†
8.33%
6.30%
5.12%
4.41%

Ï•
8.17%
6.41%
5.08%
4.10%

Table 4: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.

17

Empirical rejection frequencies - MAR(1,1): Ï†0 = 0, Ï•0 = 0, Î½0 = 1.8
Ë†
b Ï•)
b Ï•)
Sample size
I(Ï†,
b
I(Ï†,
b
Î£Ì‚
Î£Ì„
T=100
T=200
T=500
T=1000

Ï†

Ï•

/
/
/
/

/
/
/
/

Ï†
13.32%
10.50%
9.55%
8.87%

Ï•
13.56%
11.08%
9.81%
9.58%

Ï†
12.20%
9.62%
8.73%
7.88%

Ï•
12.63%
10.21%
8.67%
8.68%

Ï†
6.18%
5.18%
4.71%
4.18%

Ï•
6.41%
5.73%
4.74%
4.89%

Table 5: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.
Empirical rejection frequencies - MAR(1,1): Ï†0 = 0.65, Ï•0 = 0.35, Î½0 = 1.8
Ë†
b Ï•)
b Ï•)
Sample size
Î£Ì‚
I(Ï†,
b
I(Ï†,
b
Î£Ì„
T=100
T=200
T=500
T=1000

Ï†

Ï•

/
/
/
/

/
/
/
/

Ï†
10.06%
7.38%
6.72%
6.53%

Ï•
11.82%
9.64%
8.36%
8.83%

Ï†
10.93%
7.82%
7.18%
6.81%

Ï•
11.41%
9.28%
8.10%
8.32%

Ï†
5.54%
4.36%
3.74%
3.77%

Ï•
5.73%
5.04%
4.56%
4.45%

Table 6: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.
Empirical rejection frequencies - MAR(1,1): Ï†0 = 0.5, Ï•0 = 0.5, Î½0 = 1.8
Ë†
b Ï•)
b Ï•)
Î£Ì‚
Sample size
I(Ï†,
b
I(Ï†,
b
Î£Ì„
T=100
T=200
T=500
T=1000

Ï†

Ï•

/
/
/
/

/
/
/
/

Ï†
11.24%
8.59%
7.33%
7.29%

Ï•
11.18%
8.87%
7.45%
8.37%

Ï†
11.72%
8.81%
7.63%
7.34%

Ï•
11.54%
9.14%
7.67%
7.96%

Ï†
5.58%
4.58%
3.99%
4.04%

Ï•
6.08%
4.74%
4.08%
4.41%

Table 7: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.
Empirical rejection frequencies - MAR(1,1): Ï†0 = 0.35, Ï•0 = 0.65, Î½0 = 1.8
Ë†
b Ï•)
b Ï•)
Sample size
Î£Ì‚
I(Ï†,
b
I(Ï†,
b
Î£Ì„
T=100
T=200
T=500
T=1000

Ï†

Ï•

/
/
/
/

/
/
/
/

Ï†
12.29%
9.45%
8.29%
7.92%

Ï•
9.95%
7.77%
6.74%
7.19%

Ï†
11.32%
9.10%
7.77%
7.72%

Ï•
11.11%
8.04%
7.17%
7.43%

Ï†
5.86%
4.71%
4.18%
4.33%

Ï•
5.64%
4.44%
3.90%
4.13%

Table 8: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.

18

Empirical rejection frequencies - MAR(1,1): Ï†0 = 0, Ï•0 = 0, Î½0 = 1.5
Ë†
b Ï•)
b Ï•)
Î£Ì„
Sample size
Î£Ì‚
I(Ï†,
b
I(Ï†,
b
T=100
T=200
T=500
T=1000

Ï†

Ï•

/
/
/
/

/
/
/
/

Ï†
16.72%
13.93%
12.65%
11.92%

Ï•
16.19%
14.63%
12.84%
11.99%

Ï†
12.63%
11.06%
10.32%
9.62%

Ï•
12.90%
11.31%
10.10%
9.46%

Ï†
5.81%
5.35%
5.41%
4.97%

Ï•
5.82%
5.37%
4.84%
5.42%

Table 9: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.
Empirical rejection frequencies - MAR(1,1): Ï†0 = 0.65, Ï•0 = 0.35, Î½0 = 1.5
Ë†
b Ï•)
b Ï•)
Sample size
Î£Ì‚
I(Ï†,
b
I(Ï†,
b
Î£Ì„
T=100
T=200
T=500
T=1000

Ï†

Ï•

/
/
/
/

/
/
/
/

Ï†
11.28%
9.50%
7.70%
7.63%

Ï•
14.71%
12.47%
11.20%
10.76%

Ï†
10.90%
9.00%
8.06%
7.15%

Ï•
12.08%
10.33%
9.67%
8.79%

Ï†
4.75%
4.19%
3.94%
3.61%

Ï•
5.13%
5.01%
4.56%
4.81%

Table 10: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.
Empirical rejection frequencies - MAR(1,1): Ï†0 = 0.5, Ï•0 = 0.5, Î½0 = 1.5
Ë†
b Ï•)
b Ï•)
Î£Ì„
Sample size
Î£Ì‚
I(Ï†,
b
I(Ï†,
b
T=100
T=200
T=500
T=1000

Ï†

Ï•

/
/
/
/

/
/
/
/

Ï†
13.09%
11.20%
9.39%
9.04%

Ï•
13.13%
10.76%
9.95%
9.03%

Ï†
11.52%
9.67%
8.79%
7.61%

Ï•
11.87%
9.63%
8.91%
8.23%

Ï†
4.98%
4.35%
4.19%
3.93%

Ï•
5.18%
4.80%
4.15%
4.34%

Table 11: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.
Empirical rejection frequencies - MAR(1,1): Ï†0 = 0.35, Ï•0 = 0.65, Î½0 = 1.5
Ë†
b Ï•)
b Ï•)
Sample size
Î£Ì‚
I(Ï†,
b
I(Ï†,
b
Î£Ì„
T=100
T=200
T=500
T=1000

Ï†

Ï•

/
/
/
/

/
/
/
/

Ï†
14.27%
12.51%
10.71%
9.96%

Ï•
11.48%
9.09%
8.39%
7.84%

Ï†
12.00%
10.16%
9.32%
8.23%

Ï•
10.98%
8.54%
8.47%
7.46%

Ï†
5.10%
4.67%
4.49%
4.23%

Ï•
4.70%
4.27%
3.96%
3.94%

Table 12: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.

19

Empirical rejection frequencies - MAR(1,1): Ï†0 = 0, Ï•0 = 0, Î½0 = 1.2
Ë†
b Ï•)
b Ï•)
Sample size
I(Ï†,
b
I(Ï†,
b
Î£Ì„
Î£Ì‚
T=100
T=200
T=500
T=1000

Ï†

Ï•

/
/
/
/

/
/
/
/

Ï†
21.30%
20.15%
19.00%
18.18%

Ï•
21.22%
19.66%
18.45%
18.64%

Ï†
14.91%
13.85%
13.34%
12.95%

Ï•
14.34%
14.08%
12.93%
12.89%

Ï†
6.11%
5.91%
6.03%
5.62%

Ï•
6.16%
6.24%
5.28%
5.56%

Table 13: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.
Empirical rejection frequencies - MAR(1,1): Ï†0 = 0.65, Ï•0 = 0.35, Î½0 = 1.2
Ë†
b Ï•)
b Ï•)
Î£Ì„
Sample size
I(Ï†,
b
I(Ï†,
b
Î£Ì‚
T=100
T=200
T=500
T=1000

Ï†

Ï•

/
/
/
/

/
/
/
/

Ï†
13.70%
11.85%
10.22%
9.69%

Ï•
18.38%
16.86%
15.17%
5.35%

Ï†
12.30%
10.69%
9.22%
8.61%

Ï•
13.39%
13.02%
11.57%
11.38%

Ï†
4.62%
4.51%
4.04%
3.53%

Ï•
5.69%
5.59%
4.26%
4.81%

Table 14: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.
Empirical rejection frequencies - MAR(1,1): Ï†0 = 0.5, Ï•0 = 0.5, Î½0 = 1.2
Ë†
b Ï•)
b Ï•)
Sample size
Î£Ì‚
I(Ï†,
b
I(Ï†,
b
Î£Ì„
T=100
T=200
T=500
T=1000

Ï†

Ï•

/
/
/
/

/
/
/
/

Ï†
16.54%
14.97%
13.21%
12.02%

Ï•
16.12%
13.93%
12.87%
11.29%

Ï†
13.26%
12.12%
10.67%
9.82%

Ï•
12.65%
12.00%
10.72%
10.35%

Ï†
5.31%
4.90%
4.51%
3.86%

Ï•
5.09%
4.91%
3.98%
4.12%

Table 15: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.
Empirical rejection frequencies - MAR(1,1): Ï†0 = 0.35, Ï•0 = 0.65, Î½0 = 1.2
Ë†
b Ï•)
b Ï•)
Sample size
Î£Ì‚
I(Ï†,
b
I(Ï†,
b
Î£Ì„
T=100
T=200
T=500
T=1000

Ï†

Ï•

/
/
/
/

/
/
/
/

Ï†
19.05%
17.39%
15.54%
14.67%

Ï•
13.43%
11.42%
9.96%
9.88%

Ï†
14.26%
12.92%
11.59%
11.37%

Ï•
12.09%
9.67%
9.24%
9.22%

Ï†
5.79%
5.27%
5.05%
4.73%

Ï•
4.72%
4.34%
3.48%
3.63%

Table 16: Percentage of observations outside the interval [-1.96, +1.96]. This value is equal to 5% in a standard
normal distribution.

20

variance does not exist.
For the causal and noncausal parameters different confidence intervals are observed according
Canadian government debt as % of GDP (1870 âˆ’2015)

Covidâˆ’19 Belgium: variation of daily deaths (10/03/2020 âˆ’ 17/07/2020)

160

40

120

0
80

âˆ’40
40

1900

1940

1980

2020

2020.2

2020.3

Time

2020.4

2020.5

Time

(a) Annual data for the Canadian debt expressed as percentage of the GDP.

(b) Daily data for the variation of deaths
for covid-19 in Belgium.

Wheat prices (1990:01âˆ’2020:09)

Brazilian inflation (1997:01âˆ’2020:06)

400

15

300

10

200

5

100

1990

2000

2010

2020

Time

(c) Monthly data for the wheat prices.

2000

2005

2010

2015

2020

Time

(d) Monthly data for the inflation rate in
Brazil.

Figure 5: Charts of the 4 time series covered by the empirical investigation.
to the approach used to compute the standard errors. In the empirical application concerning
the Canadian debt (Table 17), we have too narrow confidence intervals whenever we compute the
standard errors using Hecq et al. (2016) or Lanne and Saikkonen (2011) methodology. Instead, in
the table associated to the Brazilian inflation rate (Table 20), we notice that the standard errors
obtained through the robust estimator of residuals, are larger (and consequently also the confidence
intervals) than those obtained by the â€traditionalâ€ methodologies described in Section 3. The same
is true for the causal coefficient in the wheat prices (Table 19). For the noncausal coefficient of
the same empirical application, we obtain too narrow confidence intervals when the standard error
b Ï•)
b and by Î£Ì‚. Finally, the time series related to the variation of deaths for
is computed by I(Ï†,
Covid-19 in Belgium (Table 18), is characterized by an error term with an undefined variance. Our
method allows to have narrower confidence intervals than those obtained using Hecq et al. (2016)
and the observed Fisher information matrix.

21

Canadian debt expressed as % of GDP
Estimated
coefficients
c1 =0.6504
Ï†

Standard errors
Î£Ì‚

Ë†
Î£Ì„

0.072153

0.031742

0.031260

0.048623

Ï•
c1 =0.8860

0.029278

0.012380

0.019083

0.029682

Î·b = 2.9058

0.332407

0.332407

0.332407

0.332407

Î½b = 2.3442

0.555568

0.555568

0.555568

0.555568

b Ï•)
I(Ï†,
b

b Ï•)
I(Ï†,
b

Table 17: Estimated coefficients and standard errors for Canadian debt ratio.
Covid 19 in Belgium: variation of daily deaths
Estimated
coefficients
c1 =-0.4660
Ï†

Standard errors
Î£Ì‚

Ë†
Î£Ì„

0.056116

0.028793

/

0.024285

c2 =-0.5853
Ï†

0.033870

0.028793

/

0.024277

Ï•
c1 =0.0803

0.045516

0.025620

/

0.023881

Ï•
c2 =0.6037

0.033870

0.025619

/

0.023881

Î·b = 4.2279

0.639214

0.639214

0.639214

0.639214

Î½b = 1.1785

0.209340

0.209340

0.209340

0.209340

b Ï•
b)
I(Ï†,

b Ï•
b)
I(Ï†,

Table 18: Estimated coefficients and standard errors for the variation of daily Covid-19 deaths in Belgium.
Wheat prices
Estimated
coefficients
c1 =0.9241
Ï†

b Ï•)
I(Ï†,
b

b Ï•)
I(Ï†,
b

Standard errors
0.007701

0.003549

0.007851

0.013969

Ï•
c1 =0.2866

0.051349

0.023949

0.019681

0.035019

Î·b = 6.9191

0.515185

0.515185

0.515185

0.515185

Î½b = 2.2096

0.324037

0.324037

0.324037

0.324037

Î£Ì‚

Ë†
Î£Ì„

Table 19: Estimated coefficients and standard errors for wheat prices.
Brazilian inflation rate
Estimated
coefficients
c1 =0.5842
Ï†

Standard errors
0.036605

Ï•
c1 =0.9385

0.009304

Î·b = 0.2654
Î½b = 3.2217

Î£Ì‚

Ë†
Î£Ì„

0.028383

0.038656

0.046492

0.006895

0.016444

0.019777

0.021556

0.021556

0.021556

0.021556

0.719318

0.719318

0.719318

0.719318

b Ï•)
I(Ï†,
b

b Ï•)
I(Ï†,
b

Table 20: Estimated coefficients and standard errors for inflation rate in Brazil.

22

7

Conclusions

In this paper we first review the behaviour of the ML estimator for mixed causal and noncausal
models. In particular we focused on those having an error term distributed according to a generalized Studentâ€™s tâˆ’distribution. We have seen that the expected Fisher information matrix (derived
by Lanne and Saikkonen (2011)) of the causal and noncausal parameters, can be computed if and
only if the probability density function satisfies a certain set of assumptions. The generalized Studentâ€™s tâˆ’distribution with an infinite variance (Î½ âˆˆ (1, 2]), does not meet one of these and hence
this methodology is not applicable in this context. This is a strong limitation, since time series such
as commodity prices, bitcoin, etc. feature heavy tails with degrees of freedom less than 2. Hecq et
al. (2016) proposes a new and easier way to compute the standard errors of these parameters that
is valid only when the population has a finite variance. It is also implemented in the R package
MARX and applied in several researches. However, through a simulation study, we show that this
approach leads to the underestimation of the standard errors due to the strong restrictions imposed
on the expected Fisher information matrix.
To overcome these problems, we propose an alternative way to compute the standard errors
from the expected Fisher information matrix, based on a simple non parametric estimator of the
variance of the residuals. Monte Carlo simulations show the good performances of this new estimator, even when the variance of the population is not finite. We estimate MAR models on four
macroeconomic and financial time series and we illustrate the differences in the estimated standard
errors using the different approaches.

23

8

Appendix A

The following table shows the different values of k that maximize their own empirical density
functions according to the different values of T and Î½ selected for the Monte Carlo simulations,
presented in Section 5.

kâˆ—
T=100
T=200
T=500
T=1000

Î½ = 1.2

Î½ = 1.4

Î½ = 1.5

Î½ = 1.6

Î½ = 1.8

Î½=3

4.186322
5.311298
7.266156
9.022733

3.317155
3.901011
4.941986
5.839081

3.049654
3.557615
4.297126
4.971029

2.866044
3.2330488
3.849296
4.330869

2.57295
2.85024
3.233094
3.491673

1.937395
2.02271
2.082257
2.116381

24

References
Alessi, L., Barigozzi, M., and Capasso, M. Non-fundamentalness in structural econometric
models: A review. International Statistical Review 79, 1 (2011), 16â€“47.
Andrews, B., and Davis, R. A. Model identification for infinite variance autoregressive processes.
Journal of Econometrics 172, 2 (2013), 222â€“234.
Andrews, B., Davis, R. A., and Breidt, F. J. Maximum likelihood estimation for all-pass
time series models. Journal of Multivariate Analysis 97, 7 (2006), 1638â€“1659.
Breidt, F. J., Davis, R. A., Lh, K.-S., and Rosenblatt, M. Maximum likelihood estimation
for noncausal autoregressive processes. Journal of Multivariate Analysis 36, 2 (1991), 175â€“198.
Cavaliere, G., Nielsen, H. B., and Rahbek, A. Bootstrapping noncausal autoregressions:
with applications to explosive bubble modeling. Journal of Business & Economic Statistics 38, 1
(2020), 55â€“67.
Davis, R., and Resnick, S. Limit theory for moving averages of random variables with regularly
varying tail probabilities. The Annals of Probability (1985), 179â€“195.
Davis, R. A., Knight, K., and Liu, J. M-estimation for autoregressions with infinite variance.
Stochastic Processes and Their Applications 40, 1 (1992), 145â€“180.
Fries, S., and Zakoian, J.-M. Mixed causal-noncausal ar processes and the modelling of explosive bubbles (2017).
Hamilton, J. Time series analysis, (1994).
Hecq, A., Issler, J. V., and Telg, S. Mixed causalâ€“noncausal autoregressions with exogenous
regressors. Journal of Applied Econometrics 35, 3 (2020), 328â€“343.
Hecq, A., Lieb, L., and Telg, S. Identification of mixed causal-noncausal models in finite
samples. Annals of Economics and Statistics/Annales dâ€™EÌconomie et de Statistique, 123/124 (2016),
307â€“331.
Hecq, A., and Voisin, E. Predicting bubble bursts in oil prices using mixed causal-noncausal
models. arXiv preprint arXiv:1911.10916 (2019).
Hecq, A., and Voisin, E. Forecasting bubbles with mixed causal-noncausal autoregressive models. Econometrics and Statistics (2020).
Lanne, M., and Saikkonen, P. Modeling expectations with noncausal autoregressions. Available
at SSRN 1210122 (2008).
Lanne, M., and Saikkonen, P. Noncausal autoregressions for economic time series. Journal of
Time Series Econometrics 3, 3 (2011).
Lanne, M., and Saikkonen, P. Noncausal vector autoregression. Econometric Theory (2013),
447â€“481.
Rousseeuw, P. J., and Croux, C. Alternatives to the median absolute deviation. Journal of
the American Statistical association 88, 424 (1993), 1273â€“1283.

