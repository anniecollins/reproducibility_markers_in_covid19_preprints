JOURNAL, VOL. XX, NO. XX, XXXX 2020

1

COVID-DA: Deep Domain Adaptation from
Typical Pneumonia to COVID-19

arXiv:2005.01577v1 [eess.IV] 30 Apr 2020

Yifan Zhang, Shuaicheng Niu, Zhen Qiu, Ying Wei, Peilin Zhao, Jianhua Yao,
Junzhou Huang, Qingyao Wu, and Mingkui Tan

Abstract‚ÄîThe outbreak of novel coronavirus disease 2019
(COVID-19) has already infected millions of people and is still
rapidly spreading all over the globe. Most COVID-19 patients
suffer from lung infection, so one important diagnostic method
is to screen chest radiography images, e.g., X-Ray or CT images.
However, such examinations are time-consuming and laborintensive, leading to limited diagnostic efficiency. To solve this
issue, AI-based technologies, such as deep learning, have been
used recently as effective computer-aided means to improve
diagnostic efficiency. However, one practical and critical difficulty
is the limited availability of annotated COVID-19 data, due to
the prohibitive annotation costs and urgent work of doctors to
fight against the pandemic. This makes the learning of deep
diagnosis models very challenging. To address this, motivated by
that typical pneumonia has similar characteristics with COVID19 and many pneumonia datasets are publicly available, we
propose to conduct domain knowledge adaptation from typical
pneumonia to COVID-19. There are two main challenges: 1)
the discrepancy of data distributions between domains; 2) the
task difference between the diagnosis of typical pneumonia and
COVID-19. To address them, we propose a new deep domain
adaptation method for COVID-19 diagnosis, namely COVIDDA. Specifically, we alleviate the domain discrepancy via feature
adversarial adaptation and handle the task difference issue via
a novel classifier separation scheme. In this way, COVID-DA
is able to diagnose COVID-19 effectively with only a small
number of COVID-19 annotations. Extensive experiments verify
the effectiveness of COVID-DA and its great potential for realworld applications.
Index Terms‚ÄîCOVID-19, domain adaptation, deep learning,
typical pneumonia

I. I NTRODUCTION

T

HE outbreak of novel coronavirus disease 2019 (COVID19) has rapidly spread worldwide [1], [2]. To date (April
28, 2020) there have been 2,954,222 confirmed cases of
This work was partially supported by Key-Area Research and Development Program of Guangdong Province (2018B010107001, 2018B010108002,
2019B010155002, 2019B010155001), National Natural Science Foundation of
China (NSFC) 61836003 (key project), 61876208, 2017ZT07X183, Tencent
AI Lab Rhino-Bird Focused Research Program (No.JR201902), Fundamental
Research Funds for the Central Universities D2191240, Pearl River S&T Nova
Program of Guangzhou 201806010081.
Y. Zhang, S. Niu, Z. Qiu, Q. Wu and M. Tan are with South China University of Technology, Guangzhou 510641, China, and also with Guangzhou
Laboratory, Guangzhou 510335, China (e-mail: {sezyifan, sensc, seqiuzhen}@mail.scut.edu.cn; {qyw, mingkuitan}@scut.edu.cn).
Y. Wei, P. Zhao, J. Yao and J. Huang are with Tencent AI Lab,
Shenzhen 518000, China (email: {judywei, jianhuayao, masonzhao, joehhuang}@tencent.com).
Corresponding to Mingkui Tan.
This work is finished when Yifan Zhang and Shuaicheng Niu work as
interns in Tencent AI Lab.

COVID-19 (including 202,597 deaths, with a fatal rate of
6.9%) [3], leading to great threats for global public health.
Due to COVID-19, many countries have been forced into
emergencies [4] and suffered from devastating effects on
population health [5] and social economy [6], [7]. To fight
against COVID-19, one key step is to diagnose patients
and provide immediate medical treatment, thereby preventing
further spread of COVID-19.
Currently, the main diagnosis method for COVID-19 is the
real-time Reverse-Transcriptase Polymerase Chain Reaction
(RT-PCR) [8] test, which is regarded as the gold standard
for COVID-19 detection. However, RT-PCR has a lower
diagnostic sensitivity and generally requires repeated tests for
the final confirmation of infection [9]. As a result, the RT-PCR
test is very time-consuming and laborious [10]. Meanwhile, it
is extremely difficult for hospitals in hyper-endemic regions to
provide sufficient RT-PCR tests for tons of suspected patients.
To conquer this issue, an alternative diagnostic method is
based on the screening of chest radiography images (CRIs),
e.g., X-ray or computed tomography (CT) images [11], since
COVID-19 patients often present abnormal characteristics of
lung infection on CRIs [12], [13]. Compared with RT-PCR,
CRI-based diagnosis method is more efficient and has been
widely used in clinical diagnosis in practice [14], [27]. Nevertheless, when dealing with tons of patients, medical specialists
still need to screen CRIs one by one, which, however, is
highly stressful and time-consuming. Hence, there is an urgent
need to develop computer-aided methods for the diagnosis of
COVID-19, which help to improve the diagnostic efficiency
of medical specialists.
Recently, deep learning (DL) has achieved remarkable success in medical image analysis [15]‚Äì[21]. It is a natural idea to
develop DL-based methods for COVID-19 diagnosis. One of
the key factors behind the success of DL is the large amount
of labeled data [22]. However, in the diagnosis of COVID19, such extensive annotations are unavailable now due to
prohibitive annotation costs and urgent work of doctors to fight
against the pandemic. Hence, there is a strong motivation to
develop domain adaptation [23] to improve DL-based diagnostic models for COVID-19. Specifically, domain adaptation
leverages a source domain with rich labeled data to help the
model learning on the target domain. Considering that typical
pneumonia has some similar characteristics with COVID-19
and many open-source pneumonia datasets are accessible, we
seek to conduct domain adaptation from typical pneumonia to
COVID-19 in this paper.

JOURNAL, VOL. XX, NO. XX, XXXX 2020

In this task, there are two major challenges. The first one is
the domain discrepancy of data distributions, which mainly
derived from different medical imaging devices or techniques.
In this regard, directly applying a deep model trained on the
typical pneumonia domain to the COVID-19 domain tends to
perform poorly and be impractical. The second challenge lies
in the diagnostic task difference between typical pneumonia
and COVID-19. The two tasks are similar but not completely
the same, which may result in poor generalization of the
source-trained classifier to the target domain. However, most
existing domain adaptation methods [24]‚Äì[26] neglect the task
difference issue and adopt only one domain-shared classifier.
As a result, they may perform poorly in COVID-19 diagnosis.
To solve the above challenges, we propose a novel deep
domain adaptation method for the diagnosis of COVID-19
(namely COVID-DA), which relies on domain adversarial
learning and a new classifier separation scheme. To be specific, we alleviate the domain discrepancy by aligning the
feature distributions of two domains via feature adversarial
adaptation. In this way, COVID-DA is able to learn domaininvariant features for classification. Based on such features,
we handle the task difference issue based on a novel classifier
separation scheme, which disentangles the classifier into a
domain-shared classifier and two domain-specific classifiers
(for two domains). Specifically, the domain-shared classifier
aims to learn task-shared classification knowledge between
typical pneumonia and COVID-19, while the domain-specific
classifiers seek to learn task-specific classification knowledge.
To this end, we train the domain-shared classifier to learn taskshared semantic information by aligning the joint distributions
of two domains over features and predictions. Meanwhile,
we maximize the diversity between the domain-shared and
domain-specific classifiers to make the latter ones focus on
task-specific classification information. Based on the above,
COVID-DA is able to diagnose COVID-19 effectively with
only a limited amount of labeled data, and thus is more
applicable in real-world applications.
Our main contributions are summarized as follows:
‚Ä¢

‚Ä¢

‚Ä¢

We propose a novel deep domain adaptation method for
the diagnosis of COVID-19. To the best of our knowledge, this is the first attempt to study domain adaptation
from typical pneumonia to COVID-19.
Based on a novel classifier separation scheme and a
new domain adversarial adaptation method, the proposed
method is able to overcome the task difference and
domain discrepancy simultaneously.
We conduct extensive experiments to evaluate the proposed method. Promising results demonstrate its effectiveness and superiority, e.g., the proposed method improves the diagnostic performacne for COVID-19 from
0.6875 to 0.9298 in terms of the F1 metric.

The rest of this paper is organized as follows. We first
present related work in Section II. Following that, we detail
the problem definition and the proposed method in Section III.
Next, we empirically evaluate the proposed method in Section IV, and conclude the paper in Section V.

2

II. R ELATED W ORK
A. Computer-aided Diagnosis for COVID-19
To control the transmission of COVID-19, one of the most
important steps is to screen out the infected patients, and
then provide proper treatments for them. Due to the relatively
low time and labour costs, chest radiography imaging (CRI),
e.g., X-ray or computed tomography (CT) imaging, has been
widely adopted to provide diagnostic evidences for radiologists. However, when facing tons of suspected patients, it is
still time-consuming for radiologists to screen medical images
one by one, leading to inferior diagnostic efficiency. To address
this, based on deep learning techniques, many computer-aided
diagnosis methods have been developed [14], and some of
them have been deployed in hospitals [27]. For example, Xu
et al. proposed a deep learning (DL) method for the early
detection of COVID-19 from Influenza-A viral pneumonia and
normal cases [28]. Chen et al. proposed a UNet++ based deep
model for segmenting the infected regions of COVID-19 [29].
Nevertheless, since deep models are notoriously data-hungry,
these DL-based methods require plenty of annotated data to
achieve satisfactory performance. However, in the diagnosis
of COVID-19, such rich supervision is unavailable in most
practical scenarios due to prohibitive annotation costs and
urgent work of doctors to fight the pandemic.
To solve this issue, recent studies [10], [11] directly
combined publicly available typical pneumonia datasets and
COVID-19 dataset together to train a multi-class classification
model. However, these methods ignore the domain discrepancy
between typical pneumonia and COVID-19, thereby resulting
in limited diagnostic performance for COVID-19. Therefore,
there is an urgent need to develop task-specific domain adaptation methods for COVID-19 to improve the performance of
DL-based diagnosis models.
B. Domain Adaptation
Most existing domain adaptation methods for natural images
seek to alleviate the domain discrepancy either by adding
adaptation layers to match high-order moments of distributions, e.g., DDC [26], or by devising a domain discriminator
to learn domain-invariant features in an adversarial manner,
e.g., DANN [30] and MCD [31]. Following the latter manner,
CLAN [32] proposed to conduct category-aware domain adaptation instead of only global alignment of domain distributions.
In medical image analysis, by taking the characteristics of
medical imaging into account, Kamnitsas et al. attempted
to introduce a multi-connected domain discriminator for improved adversarial training [33]. Ren et al. proposed a Siamese
architecture on the target domain to add a regularization for the
whole-slide images [34]. However, all these methods ignore
the task difference between domains, and thus may perform
poorly on the adaptation from typical pneumonia to COVID19. To handle these, we propose a new deep domain adaptation
method for COVID-19, which aims to alleviate the domain
discrepancy and overcome task difference simultaneously. In
this way, the proposed method is able to diagnose COVID-19
more effectively in real-world applications.

JOURNAL, VOL. XX, NO. XX, XXXX 2020

3

Source Domain
Source-specific

ùë™ùíî

Normal

Diversity Loss
ùìõùêùùê¢ùêØ

Domain Loss

Pneumonia

Shared Feature
Extractor ùëÆùíá

ùë´ùüè

ùìõùêùùüè ùìõùêùùüê

ùë´ùüê

Classification
Loss ùìõf

Domain-shared

ùë™ùíÖ

Target Domain

Diversity Loss
ùìõùêùùê¢ùêØ
Target-specific

ùë™ùíï
Normal

COVID-19

Feature Extractor

Domain Discriminator

Domain-shared Classifier

Domain-specific Classifier

Fig. 1. The scheme of COVID-DA. Based on the domain discriminator D1 , we conduct feature distribution adaptation to learn domain-invariant feature
extractor Gf for two domains. Meanwhile, based on the discriminator D2 , we perform joint distribution adaptation for the classifier Cd to learn domain-shared
classification knowledge. We maximize the diversity between domain-shared and domain-specific classifiers to encourage the later ones to learn domain private
knowledge. Moreover, we take the average ensemble (denoted by ‚äï) of the domain-shared and domain-specific classifiers as the final prediction.

III. M ETHOD
Problem Definition. This paper studies the problem of
domain adaptation from typical Pneumonia (source domain)
to COVID-19 (target domain), where the model has access to
only limited labeled data from the target domain. Formally,
s
ntl
let Ds ={xi , yi }ni=1 be labeled source data, Dlt ={xj , yj }j=1
nt

u
be limited labeled target data and Dut ={xk }k=1
be unlabeled
t
s
t
target data. Here, n , nl , nu denote the number of source data,
labeled target data and unlabeled target data, where ntl ntu
and ntl ns . Moreover, let Dt =Dlt ‚à™Dut be the complete target
domain with nt =ntl +ntu as the sample number.
The goal is to learn a well-performed deep model for the
target domain, using both source samples (labeled) and target
samples (partially labeled). This task, however, is very difficult
due to (1) only limited labeled samples in the target domain
and (2) apparent discrepancy between typical Pneumonia
and COVID-19 in terms of domain distributions and tasks.
However, existing domain adaptation methods for medical
images only focus on alleviating the discrepancy in terms
of domain distributions, while ignoring the task difference
between domains. As a result, directly applying them to
the task tends to perform poorly in practice. To solve this,
we propose a new deep domain adaptation method for the
diagnosis of COVID-19, namely COVID-DA.

A. Overall Scheme of COVID-DA
To enforce effective domain knowledge adaptation, we seek
to alleviate the domain discrepancy with domain adversarial
adaptation and handle the task difference via a novel classifier
separation scheme. To this end, as shown in Fig. 1, COVIDDA consists of three main parts: (1) a domain-shared feature
extractor Gf for extracting domain-invariant features; (2)
two domain discriminators {D1 , D2 } for feature adaptation
and classifier adaptation, respectively; (3) a domain-shared
classifier Cd and two domain-specific classifiers {Ct , Cs }
for the diagnosis of COVID-19. Note that the separation of

domain-shared and domain-specific classifiers helps to disentangle task-shared and task-specific pathological information
regarding typical pneumonia and COVID-19.
Overall, COVID-DA conducts three main strategies as follows. (a) feature adversarial adaptation: we impose a domain loss Ld1 to align the feature distributions of two domains,
so that the domain discrepancy is minimized in an adversarial
learning manner [24], [25]; (b) classifier adversarial adaptation: we exploit a domain loss Ld2 to conduct joint distribution
alignment for the domain-shared classifier Cd , making it able
to learn domain-shared pathological information in an adversarial learning manner; (c) classifier diversity maximization:
we maximize the diversity between the domain-shared and
domain-specific classifiers via a diversity loss Ldiv , so that the
domain-specific classifiers can learn task-specific information
in two domains. Note that the strategies (b) and (c) help
COVID-DA to handle the task difference effectively. Lastly,
we train the feature extractor and all classifiers via a focal
classification loss Lf [35], which makes the model class
imbalance-aware and discriminative. In this way, COVID-DA
is able to adapt the source domain knowledge to the target
domain and diagnose COVID-19 effectively.
The overall training procedure of COVID-DA is to solve
the following minimax problem [36]:
min max ‚àíŒ± [Ld1 (Œ∏f , Œ∏d1 ) + Ld2 (Œ∏cd , Œ∏d2 )]
Œò1 Œò2
{z
}
|
domain loss

‚àí Œ≤ Ldiv (Œ∏cd , Œ∏ct , Œ∏cs ) + Lf (Œò1 ),
|
{z
} | {z }
diversity loss

(1)

focal loss

where Œò1 ={Œ∏f , Œ∏cd , Œ∏ct , Œ∏cs } denotes the parameters of the
feature extractor Gf and all classifiers {Cd , Ct , Cs }, while
Œò2 ={Œ∏d1 , Œ∏d2 } denotes the parameters of two discriminators
{D1 , D2 }. Here, Œ± and Œ≤ are trade-off parameters.
We next detail two domain losses Ld1 and Ld2 in Section III-B and Section III-C, respectively. Following that, we
detail the classifier diversity loss Ldiv in Section III-D and
then the focal loss Lf in Section III-E.

JOURNAL, VOL. XX, NO. XX, XXXX 2020

4

B. Feature Adversarial Adaptation
Diverse imaging devices and preprocessing techniques intrinsically result in huge domain discrepancy in terms of data
distribution. To resolve the discrepancy, we resort to domain
adversarial learning for aligning feature distributions of domains. Specifically, on the one hand, a domain discriminator
D1 is trained to adequately distinguish feature representations
between two domains by minimizing a domain loss Ld1 . On
the other hand, the feature extractor Gf is trained to confuse
the discriminator by maximizing the domain loss Ld1 . As a
result, the learned feature extractor is able to extract domaininvariant features that confuse the discriminator well. Based
on the least square distance [37], we define the domain loss
for feature adversarial adaptation as:
1 X
1 X
d1 (x)2 + t
(1 ‚àí d1 (x))2 , (2)
Ld1 (Œ∏f , Œ∏d1 ) = s
n
n
s
t
D

On the one hand, a discriminator D2 is trained to adequately differentiate the joint distributions between domains
by minimizing a domain loss Ld2 . Specifically, the input of
the discriminator D2 consists of both features and predictions.
On the other hand, the domain-shared classifier Cd is trained
to confuse the discriminator by maximizing the domain loss.
As Section III-B, we define the domain loss for classifier
adversarial adaptation based on the least square distance:
1 X
1 X
d2 (x)2 + t
(1‚àíd2 (x))2 , (3)
Ld2 (Œ∏cd , Œ∏d2 ) = s
n
n
Ds
Dt

where d2 (x) = D2 Gf (x), Cd (Gf (x)) denotes the prediction of the domain discriminator regarding the joint distribution over the feature and the prediction w.r.t. x. Moreover, we
denote the label of the target domain as 1 and that of the
source as 0.

D

where d1 (x) = D1 (Gf (x)) denotes the prediction of the
domain discriminator w.r.t. x. We set the label of the target
domain to 1 and that of the source domain to 0.
C. Classifier Adversarial Adaptation
Most existing adversarial domain adaptation methods [24],
[30], [38] assume that the source domain deals with the same
classification task as the target domain. Hence, they usually
focus on feature distribution alignment as Section III-B and
use a classifier trained on the source domain to classify the
target data. However, they may fail to handle the problem in
this paper, since pneumonia diagnosis and COVID-19 diagnosis are similar but not completely the same, originated from
different pathological mechanisms. Specifically, let P(f s ) and
P(f t ) denote the feature distributions of the source and target
domains, while let P(ys |f s ) and P(yt |f t ) be the prediction
conditional distributions of two domains. Even though the
feature distributions have been matched (i.e., P(f s )=P(f t )),
the task difference potentially results in different prediction
conditional distributions (i.e., P(ys |f s )6=P(yt |f t )) [39], [40].
As a result, only using the source-trained classifier P(ys |f s )
may not be able to diagnose COVID-19 well.
To solve this issue, as shown in Fig. 1, we propose
a novel classifier separation scheme by disentangling the
domain-shared classifier Cd and the domain-specific classifiers
{Cs , Ct }. To be specific, the domain-shared classifier seeks
to acquire task-shared classification knowledge, while the
domain-specific classifiers aim to learn task-specific knowledge. By taking the average ensemble of two classifiers as the
final prediction [41], COVID-DA is able to handle the task
difference and diagnose COVID-19 well.
In this scheme, one key issue is how to learn the domainshared classifier. In fact, when the feature distributions match
well (i.e., P(f s )=P(f t )), if we train the classifier to align the
joint distributions (i.e., P(ys , f s )=P(yt , f t )), then the domainshared classifier is able to learn task-shared classification
knowledge since P(y, f )=P(f )P(y|f ) [42]. Motivated by this,
we propose to train the domain-shared classifier by aligning
the joint distributions via domain adversarial learning [25].

D. Classifier Diversity Maximization
In COVID-DA, we handle the issue of task difference by
disentangling the domain-shared and domain-specific classifiers. In Section III-C, we have enforced the domain-shared
classifier to acquire domain-invariant classification knowledge.
In this section, we further enforce the domain-specific classifiers to acquire domain private classification knowledge. To
this end, we maximize the diversity between the domainspecific classifier and the domain-shared classifier. Specifically, given any sample x, let yÃÇd denote the prediction of
domain-shared classifiers (i.e., Cd ), and let yÃÇt and yÃÇs denote
the prediction of the domain-specific classifier (i.e., Ct and
Cs ). Based on the cosine distance, we maximize the classifier
diversity based on the following diversity loss:
 1 X

1 X
cos yÃÇd , yÃÇs ‚àí t
cos yÃÇd , yÃÇt .
Ldiv (Œ∏cd , Œ∏ct , Œ∏cs )= ‚àí s
n
n
Ds
Dt
(4)
In this way, the two domain-specific classifiers are different
with the domain-shared classifier as large as possible, and
thus able to learn domain-specific classification information.
Moreover, since the final prediction of COVID-DA is the average ensemble of two classifiers, maximizing classifier diversity
also enhance the performance of ensemble learning [43].
E. Focal Loss for COVID-19 Diagnosis
For the diagnosis of COVID-19, one can adopt any classification losses to train our COVID-DA, e.g., cross-entropy.
Nevertheless, considering the class imbalance issue in medical
diagnosis, we use the focal loss [35] as follows:
X

1
Lf (Œò1 ) = ‚àí t s
y> (1‚àíyÃÇ)Œ≥ log(yÃÇ) , (5)
nl +n t s
Dl ‚à™D

where yÃÇ is the final prediction of COVID-DA w.r.t. a given
sample x. Here, yÃÇ is the average prediction of both domainshared (Cd ) and domain-specific (Ct or Cs ) classifiers. Note
that, the focal loss is a widely-used loss for class imbalance
issue [24]. Moreover, denotes the element-wise product and
Œ≥ is a hyper-parameter in focal loss.

JOURNAL, VOL. XX, NO. XX, XXXX 2020

5

We summarize the training and inference details of COVIDDA in Algorithms 1 and 2, respectively. Moreover, we implement the adversarial learning via a gradient reversal layer
(GRL) [30], [38], which reverses the gradient of the domain
loss when backpropagating to the feature extractor or domainshared classifier. In this way, we are able to train COVID-DA
through standard backpropagation in an end-to-end manner.

TABLE I
S TATISTICS OF THE DATASET, WHERE PNEUMONIA SERVES AS THE
SOURCE DOMAIN AND COVID-19 SERVES AS THE TARGET DOMAIN .

Set

Categories

Domain

#Total

#Normal #Pneumonia #COVID-19
Training Pneumonia
COVID-19
Test

COVID-19

5613
2541

2306
0

0
258

7919
2799

885

0

60

945

Algorithm 1 Training of COVID-DA
s

Require: Labeled source data Ds ={xi , yi }n
i=1 , labeled target data
ntl
ntu
Dlt ={xj , yj }j=1
; Trainand unlabeled target data Dut ={xk }k=1
ing epoch M ; Trade-off hyper-parameters Œ± and Œ≤.
Initialize: Parameters of COVID-DA: Feature extractor Gf ; classifiers {Cd , Ct , Cs }; domain discriminators {D1 , D2 }.
1: for m = 1 ‚Üí M do
2:
Extract feature vector f based on Gf ;
3:
Obtain the predictions {yÃÇd , yÃÇt , yÃÇs } of {Cd , Ct , Cs } based on
f , respectively;
4:
Compute the domain adversarial losses Ld1 and Ld2 based on
f and {Cd , D1 , D2 }; // Eqn. (2) and Eqn. (3)
5:
Compute the classifier diversity loss Ldiv based on
{yÃÇd , yÃÇt , yÃÇs }; // Eqn. (4)
6:
if labeled data then
7:
Compute the classification loss Lf based on {yÃÇd , yÃÇt } and
{yÃÇd , yÃÇs }. // Eqn. (5)
8:
end if
9:
Compute the total loss; // Eqn. (1)
10:
loss.backward(). // standard backward propagation
11: end for
12: Output: Gf , Cd and Ct .

Algorithm 2 Inference of COVID-DA
Require: Target COVID-19 data x; Parameters of feature extractor
Gf ; Two classifiers for the target domain {Cd , Ct }.
1: Extract feature f regrading x using Gf ;
2: Compute the predictions {yÃÇd , yÃÇt } using {Cd , C
t } based on f ;
3: Compute the ensemble prediction yÃÇ = yÃÇd +yÃÇt /2.
4: Output: yÃÇ.

IV. E XPERIMENTAL R ESULTS
To verify the proposed method1 , we evaluate COVID-DA
on two main aspects: (1) the performance in the diagnosis of
COVID-19; (2) the algorithm characteristics of COVID-DA.
A. Experimental Settings
1) Dataset: The dataset2 used in this experiment is collected from three open-source datasets, i.e., the COVID chest
X-ray dataset [44], the COVID-19 Radiography Database3
and the dataset of RSNA Pneumonia Detection Challenge on
Kaggle4 . Based on these collected data, we randomly choose
part of normal cases and all typical pneumonia cases to make
up the source domain, and use the rest of normal cases and all
COVID-19 cases as the target domain. The statistics of two
domains are summarized in Table I.
1 We

will make the source code publicly available.
dataset is available at https://github.com/qiuzhen8484/COVID-DA.git.
3 https://www.kaggle.com/tawsifurrahman/covid19-radiography-database.
4 https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data.
2 The

Note that only 30% of the training COVID-19 samples
are labeled in the training process, which would be more
practical in real-world scenarios. Moreover, the three datasets
are acquired from different countries with various imaging
devices, while the tasks of two domains are similar but not
completely the same. Therefore, this domain adaptation task
suffers from severe domain discrepancy and task difference.
In addition, as shown in Table I, the class imbalance is also
severe. Considering the above issues, such a diagnosis task of
COVID-19 is very challenging.
2) Compared methods: We compare COVID-DA with four
categories of methods. (1) Baselines: Source-only (training
the model on the well-labeled source domain), Target-only
(training the model on the target domain with limited labels)
and Fine-tuning (training the model on the well-labeled source
domain and then fine-tuning it on the target domain with
limited labels); (2) deep diagnostic models for COVID19: DLAD [11] and COVID-Net [10] (training on the labeled target domain); (3) Unsupervised domain adaptation:
MCD [31], DSN [45], DANN [30], DMAN [24], which train
deep models on both the labeled source domain and unlabeled
target domain; (4) Semi-supervised domain adaptation:
SDT [46] and semi-DMAN (extended from DMAN [24]).
Note that, the semi-supervised domain adaptation methods
train deep models using both labeled source data and partiallylabeled target data.
3) Implementation details: We implement our method
based on PyTorch [47]. For a fair comparison, we adopt a
Resnet-18 [48] model, pretrained on ImageNet [49], as the
backbone of all methods. For all compared methods, we keep
the same hyper-parameters as the original paper. For COVIDDA, the details consist of two parts. (1) network architectures: We implement the feature extractor based on Resnet18, while we implement the two domain discriminators based
on two-layer fully-connected networks [24], and implement
all classifiers by one fully-connected layer; (2) parameter
settings: In the training process, we use an SGD optimizer
with the learning rate of 0.001 to train the whole network. The
batch size for each domain is set to 16. As for the trade-off
parameters in Eqn. (1), we set Œ±=0.1 and Œ≤=0.1 via crossvalidation. Following [35], we set Œ≥=2.0 for the focal loss.
4) Evaluation metrics: We evaluate the diagnostic performance of all considered methods for COVID-19 in terms of
six metrics: F1 score (%), Recall (%), Precision (%), AUC,
Sum (%) and Cost. Specifically, the first three metrics are
calculated based on previous studies [24], [41], the AUC metric
is based on the work [50], and the Sum and Cost metrics are
based on [51], [52]. We recommend readers to these papers
for detailed implementations of these metrics.

JOURNAL, VOL. XX, NO. XX, XXXX 2020

6

TABLE II
C OMPARISONS ON COVID-19 DIAGNOSIS IN TERMS OF F1 SCORE (%), R ECALL (%), P RECISION (%), AUC, S UM (%) AND C OST.

Method

F1 (‚Üë)

Recall (‚Üë)

Precision (‚Üë)

AUC (‚Üë)

Sum (‚Üë)

Cost (‚Üì)

Source-only
Target-only
Fine-tuning
DLAD [11]
COVID-Net [10]
MCD [31]
DANN [30]
DSN [45]
DMAN [24]
Semi-DMAN
SDT [46]

65.04
68.75
64.29
67.18
71.94
61.54
66.15
73.02
75.63
77.27
79.69

66.67
55.00
75.00
73.33
83.33
60.00
71.67
76.67
75.00
85.00
85.00

63.49
91.67
56.25
61.97
63.29
63.16
61.43
69.70
76.27
70.83
75.00

0.899
0.971
0.946
0.961
0.977
0.904
0.904
0.884
0.915
0.978
0.962

82.03
77.33
85.52
85.14
90.03
78.81
84.31
87.20
86.71
91.31
91.54

20.3
24.6
17.0
17.1
11.9
23.7
18.0
14.6
14.9
10.2
9.8

COVID-DA

92.98

88.33

98.15

0.985

94.11

6.4

TABLE III
A BLATION STUDIES ON COVID-DA IN TERMS OF SIX METRICS . B OTH CROSS ENTROPY LOSS Lce AND FOCAL LOSS Lf ARE USED FOR CLASSIFICATION ;
D OMAIN LOSSES Ld1 AND Ld2 ARE USED FOR DOMAIN ADAPTATION REGARDING DISCRIMINATORS D1 AND D2 ; D IVERSITY LOSS Ldiv IS EMPLOYED
TO MAXIMIZE THE CLASSIFIER DIVERSITY.

Backbone
‚àö
‚àö
‚àö
‚àö
‚àö

Lce
‚àö

Ld2

Lf

Ld1

‚àö
‚àö
‚àö

‚àö
‚àö

‚àö

‚àö

‚àö

‚àö

Ldiv

‚àö

F1 (‚Üë)

Recall (‚Üë)

Precision (‚Üë)

AUC (‚Üë)

Sum (‚Üë)

Cost (‚Üì)

70.71
72.92
84.62
91.07

58.33
58.33
73.33
85.00

89.74
97.22
100.00
98.08

0.986
0.985
0.974
0.996

78.94
79.11
86.67
92.44

22.9
22.6
14.4
8.2

92.98

88.33

98.15

0.985

94.11

6.4

B. Evaluation on COVID-19 Diagnosis
1) Results: We evaluate all methods in terms of six metrics
and report the results in Table II. Overall, the proposed
method performs the best, which confirms its effectiveness and
superiority in COVID-19 diagnosis. Since there is an urgent
need for computer-aided diagnosis for COVID-19, COVIDDA makes great medical sense in practice.
According to Table II, we draw the following observations.
(1) Both Target-only and Fine-tuning do not certainly outperform the Source-only on all considered evaluation metrics.
One possible reason is that the deep model may overfit to the
limited labeled data of the target domain, and thus perform
limitedly on the test set. (2) deep diagnostic models (DLAD
and COVID-Net) outperform Target-only, which demonstrates
the contribution of particularly devised architectures. (3) most
unsupervised domain adaptation (DA) methods (e.g., DANN,
DSN and DMAN) outperform Source-only, which confirms
the effectiveness of DA. (4) The semi-supervised DA methods (i.e., SDT and semi-DMAN) further improve the model
performance on the target domain. This result verifies the
contribution of limited target annotations in DA. (5) COVIDDA outperforms all compared methods, which demonstrates
the superiority of the proposed method to leverage both welllabeled source data and partially-labeled target data.
2) Visualization of Grad-CAMs: In this section, we use
the Gradient-weighted Class Activation Mapping [53] (GradCAM) method to visualize the important regions that the
devised classifiers focus on for predictions. We present the
visualization results of three COVID-19 patients in Fig. 2. As
expected, the domain-shared classifier focuses more on the
surrounding regions to capture the task-shared classification

1.00

(a) Input

0.00

1.00

(b) Domain-shared (c) Target-specific (d) Final Prediction
Classifier
Classifier

Fig. 2. Visualization of three COVID-19 confirmed patients‚Äô chest X-ray
images and the corresponding Grad-CAMs obtained by our method. (a) the
original input image; (b) the Grad-CAMs obtained by our domain-shared
classifier; (c) the Grad-CAMs obtained by our target-specific classifier; (d)
the Grad-CAMs obtained by the ensemble of both domain-shared and targetspecific classifiers. Specifically, the red-coloured area is the region where
the classifiers focus on. The probabilities on the rightest column denote the
confidence of the final prediction.

information, while the target-specific classifier focuses more
on pathological regions of COVID-19 itself. By combining the
above two classifiers, COVID-DA is able to make predictions
based on both task-shared and target-specific classification
information. In addition, the visualized Grad-CAMs are also
an interpretation for the prediction of COVID-DA, which helps
doctors to judge the prediction reliability in practice.

JOURNAL, VOL. XX, NO. XX, XXXX 2020

7

TABLE IV
I NFLUENCE OF THE TRADE - OFF PARAMETERS Œ± AND Œ≤ IN COVID-DA. H ERE , Œ± AND Œ≤ CONTROL THE DOMAIN LOSSES (Ld1 AND Ld2 ) AND
CLASSIFIER DIVERSITY LOSS (Ldiv ), RESPECTIVELY.

Parameter

Œ±

Œ≤

Value

F1 (‚Üë)

Recall (‚Üë)

Precision (‚Üë)

AUC (‚Üë)

Sum (‚Üë)

Cost (‚Üì)

10‚àí3
10‚àí2
10‚àí1
1

90.09
91.89
92.98
87.27

83.33
85.00
88.33
80.00

98.04
100.00
98.15
96.00

0.961
0.990
0.985
0.980

91.61
92.50
94.11
89.89

9.1
8.1
6.4
11

10‚àí3
10‚àí2
10‚àí1
1

89.47
90.09
92.98
90.43

85.00
83.33
88.33
86.67

94.44
98.04
98.15
94.55

0.984
0.985
0.985
0.976

92.33
91.61
94.11
93.16

8.4
9.1
6.4
7.5

TABLE V
C OMPARISONS OF DIFFERENT MEASUREMENTS FOR COMPUTING DOMAIN ADVERSARIAL LOSSES (Ld1 AND Ld2 ) AND THE CLASSIFIER DIVERSITY LOSS
(Ldiv ) IN COVID-DA.

Objective

Measurement

F1 (‚Üë)

Recall (‚Üë)

Precision (‚Üë)

AUC (‚Üë)

Sum (‚Üë)

Cost (‚Üì)

Domain Losses
(Ld1 and Ld2 )

Focal Loss
GAN Loss
Least Square Loss

87.85
89.91
92.98

78.33
81.67
88.33

100.00
100.00
98.15

0.984
0.988
0.985

89.17
90.83
94.11

11.7
9.9
6.4

Diversity Loss
(Ldiv )

L1 Distance
L2 Distance
KL Divergence
JS Divergence
Cosine Distance

91.38
90.09
85.71
90.27
92.98

88.33
83.33
85.00
85.00
88.33

94.64
98.04
86.44
96.23
98.15

0.963
0.963
0.950
0.977
0.985

94.00
91.61
92.05
92.39
94.11

6.6
9.1
8.9
8.3
6.4

3) Ablation studies: We conduct ablation studies to evaluate the effectiveness of different components in COVIDDA. As shown in Table III, all components in our methods (i.e., feature adversarial adaptation, classifier adversarial
adaptation, classifier diversity maximization, and focal loss)
make empirical contributions and play important roles in our
method. Particularly, domain adversarial losses (Ld1 and Ld2 )
are relatively important. Moreover, the classifier diversity loss
(Ldiv ) is able to further improve diagnostic performance.
These results demonstrate the necessity to reduce the domain
discrepancy and overcome the task difference in the task of
domain adaptation for COVID-19.
C. More Discussions
1) Parameter sensitivities: As mentioned in Section IV-A3,
we set trade-off parameters Œ± = 0.1 and Œ≤ = 0.1 in all
experiments, where Œ± adjusts the domain adversarial losses
(Ld1 and Ld2 ) and Œ≤ controls the classifier diversity loss
(Ldiv ). In this section, we evaluate the sensitivities of these
two parameters, where we only evaluate one parameter each
time, fixing all other parameters. From Table IV, our proposed
method achieves the best or relatively good performance with
the setting Œ± = 0.1 and Œ≤ = 0.1.
2) Domain adversarial loss: In our method, we define the
domain adversarial losses (in Eqns. (2) and (3)) relying on the
least square loss, since it helps to improve domain confusion
and stabilize training, by preserving the domain distance
information [37]. In this section, we empirically compare it
with the focal loss and original GAN loss [36]. As shown in
Table V, the least-square loss outperforms another two losses,
which demonstrates the superiority of the adopted domain loss.

3) Classifier diversity loss: In our method, we define the
classifier diversity loss (in Eqn. (4)) relying on the cosine
distance. In fact, one can also use other distance metrics,
e.g., L1 distance, L2 distance, KL divergence and JS divergence, according to the tasks at hand. To find the most suitable
one, we conduct many preliminary experiments and report the
results in Table V. To be specific, the cosine distance performs
the best over all considered distances in the domain adaptation
task for COVID-19.
V. C ONCLUSION
In this paper, we have proposed a deep domain adaptation
method for the diagnosis of COVID-19 (namely COVIDDA), which aims to transfer the domain knowledge from
the well-labeled source domain (i.e., typical pneumonia) to
the partially-labeled target domain (i.e., COVID-19). To be
specific, we minimize the domain discrepancy by aligning the
feature distributions of two domains via domain adversarial
learning. Meanwhile, we develop a novel classifier separation
scheme to overcome the issue of task difference between
domains. In this way, the proposed method is able to learn
a well-performed deep model with very limited annotations of
COVID-19. Extensive experiments demonstrate the effectiveness and superiority of COVID-DA.
It is worth mentioning that our proposed method is of great
clinical importance, since extensive annotations of COVID-19
are inaccessible now, while there is an urgent demand to develop deep learning based diagnosis methods for COVID-19.
In the future, one can apply COVID-DA to CT imaging-based
diagnosis of COVID-19 and extend it to the segmentation task
for fine-grained diagnosis of COVID-19.

JOURNAL, VOL. XX, NO. XX, XXXX 2020

R EFERENCES
[1] J. T. Wu, K. Leung, and G. M. Leung, ‚ÄúNowcasting and forecasting the
potential domestic and international spread of the 2019-ncov outbreak
originating in wuhan, china: a modelling study,‚Äù The Lancet, vol. 395,
no. 10225, pp. 689‚Äì697, 2020.
[2] C. Wang, P. W. Horby, F. G. Hayden, and G. F. Gao, ‚ÄúA novel
coronavirus outbreak of global health concern,‚Äù The Lancet, vol. 395,
no. 10223, pp. 470‚Äì473, 2020.
[3] WHO, ‚ÄúCoronavirus disease 2019 situation report - 99,‚Äù April
28, 2020. [Online]. Available: https://www.who.int/docs/default-source/
coronaviruse/situation-report/.
[4] C. Sohrabi et al., ‚ÄúWorld health organization declares global emergency:
A review of the 2019 novel coronavirus (covid-19),‚Äù International
Journal of Surgery, 2020.
[5] L. Pan, M. Mu, H. G. Ren, P. Yang, Y. Sun, R. Wang et al., ‚ÄúClinical
characteristics of covid-19 patients with digestive symptoms in hubei,
china: a descriptive, cross-sectional, multicenter study,‚Äù American Journal of Gastroenterology, vol. 20, 2020.
[6] N. Fernandes, ‚ÄúEconomic effects of coronavirus outbreak (covid-19) on
the world economy,‚Äù SSRN, 2020.
[7] R. Baldwin and E. Tomiura, ‚ÄúThinking ahead about the trade impact of
covid-19,‚Äù Economics in the Time of COVID-19, p. 59, 2020.
[8] J. F.-W. Chan et al., ‚ÄúA familial cluster of pneumonia associated with
the 2019 novel coronavirus indicating person-to-person transmission: a
study of a family cluster,‚Äù The Lancet, vol. 395, pp. 514‚Äì523, 2020.
[9] Y. Fang, H. Zhang, J. Xie, M. Lin, L. Ying, P. Pang, and W. Ji,
‚ÄúSensitivity of chest ct for covid-19: comparison to rt-pcr,‚Äù Radiology,
p. 200432, 2020.
[10] L. Wang and A. Wong, ‚ÄúCovid-net: A tailored deep convolutional neural
network design for detection of covid-19 cases from chest radiography
images,‚Äù arXiv, 2020.
[11] J. Zhang, Y. Xie, Y. Li, C. Shen, and Y. Xia, ‚ÄúCovid-19 screening on
chest x-ray images using deep learning based anomaly detection,‚Äù arXiv,
2020.
[12] C. Huang et al., ‚ÄúClinical features of patients infected with 2019 novel
coronavirus in wuhan, china,‚Äù The Lancet, vol. 395, no. 10223, pp. 497‚Äì
506, 2020.
[13] M.-Y. Ng et al., ‚ÄúImaging profile of the covid-19 infection: radiologic
findings and literature review,‚Äù Radiology: Cardiothoracic Imaging,
vol. 2, no. 1, p. e200034, 2020.
[14] S. Feng et al., ‚ÄúReview of artificial intelligence techniques in imaging
data acquisition, segmentation and diagnosis for covid-19,‚Äù arXiv, 2020.
[15] E. GoÃÅmez-de Mariscal et al., ‚ÄúDeep-learning-based segmentation of
small extracellular vesicles in transmission electron microscopy images,‚Äù
Scientific Reports, vol. 9, no. 1, pp. 1‚Äì10, 2019.
[16] S. Wang, K. He, D. Nie, S. Zhou, Y. Gao, and D. Shen, ‚ÄúCt male pelvic
organ segmentation using fully convolutional networks with boundary
sensitive representation,‚Äù Medical Image Analysis, 2019.
[17] M. Ariz et al., ‚ÄúDynamic atlas-based segmentation and quantification
of neuromelanin-rich brainstem structures in parkinson disease,‚Äù IEEE
Transactions on Medical Imaging, vol. 38, no. 3, pp. 813‚Äì823, 2018.
[18] M. Anthimopoulos et al., ‚ÄúLung pattern classification for interstitial lung
diseases using a deep convolutional neural network,‚Äù IEEE Transactions
on Medical Imaging, vol. 35, no. 5, pp. 1207‚Äì1216, 2016.
[19] N. Tajbakhsh et al., ‚ÄúConvolutional neural networks for medical image
analysis: Full training or fine tuning?‚Äù IEEE Transactions on Medical
Imaging, vol. 35, no. 5, pp. 1299‚Äì1312, 2016.
[20] H. Gupta, K. H. Jin, H. Q. Nguyen, M. T. McCann, and M. Unser, ‚ÄúCnnbased projected gradient descent for consistent ct image reconstruction,‚Äù
IEEE Transactions on Medical Imaging, vol. 37, pp. 1440‚Äì1453, 2018.
[21] S. Niu, J. Wu, Y. Zhang, Y. Guo, P. Zhao et al., ‚ÄúDisturbance-immune
weight sharing for neural architecture search,‚Äù arXiv, 2020.
[22] Z. Cao, K. You, M. Long, J. Wang, and Q. Yang, ‚ÄúLearning to transfer
examples for partial domain adaptation,‚Äù in CVPR, 2019.
[23] S. J. Pan and Q. Yang, ‚ÄúA survey on transfer learning,‚Äù IEEE Transactions on Knowledge and Data Engineering, vol. 22, no. 10, pp. 1345‚Äì
1359, 2009.
[24] Y. Zhang, H. Chen, Y. Wei, P. Zhao et al., ‚ÄúFrom whole slide imaging
to microscopy: Deep microscopy adaptation network for histopathology
cancer image classification,‚Äù in MICCAI, 2019, pp. 360‚Äì368.
[25] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell, ‚ÄúAdversarial discriminative domain adaptation,‚Äù in CVPR, 2017, pp. 7167‚Äì7176.

8

[26] E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Darrell, ‚ÄúDeep
domain confusion: Maximizing for domain invariance,‚Äù arXiv, 2014.
[27] F. Shi, L. Xia, F. Shan, D. Wu, Y. Wei, H. Yuan, H. Jiang, Y. Gao, H. Sui,
and D. Shen, ‚ÄúLarge-scale screening of covid-19 from community
acquired pneumonia using infection size-aware classification,‚Äù arXiv,
2020.
[28] X. Xu et al., ‚ÄúDeep learning system to screen coronavirus disease 2019
pneumonia,‚Äù arXiv, 2020.
[29] J. Chen et al., ‚ÄúDeep learning-based model for detecting 2019 novel
coronavirus pneumonia on high-resolution computed tomography: a
prospective study,‚Äù medRxiv, 2020.
[30] Y. Ganin and V. Lempitsky, ‚ÄúUnsupervised domain adaptation by
backpropagation,‚Äù arXiv, 2014.
[31] K. Saito, K. Watanabe, Y. Ushiku, and T. Harada, ‚ÄúMaximum classifier
discrepancy for unsupervised domain adaptation,‚Äù in CVPR, 2018, pp.
3723‚Äì3732.
[32] Y. Luo, L. Zheng, T. Guan, J. Yu, and Y. Yang, ‚ÄúTaking a closer look at
domain shift: Category-level adversaries for semantics consistent domain
adaptation,‚Äù in CVPR, 2019, pp. 2507‚Äì2516.
[33] K. Kamnitsas, C. Baumgartner, C. Ledig, V. Newcombe, J. Simpson,
A. Kane, D. Menon, A. Nori, A. Criminisi, D. Rueckert et al., ‚ÄúUnsupervised domain adaptation in brain lesion segmentation with adversarial
networks,‚Äù in IPMI. Springer, 2017, pp. 597‚Äì609.
[34] J. Ren, I. Hacihaliloglu, E. A. Singer, D. J. Foran, and X. Qi, ‚ÄúAdversarial domain adaptation for classification of prostate histopathology
whole-slide images,‚Äù in MICCAI. Springer, 2018, pp. 201‚Äì209.
[35] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. DollaÃÅr, ‚ÄúFocal loss for
dense object detection,‚Äù in ICCV, 2017, pp. 2980‚Äì2988.
[36] I. Goodfellow et al., ‚ÄúGenerative adversarial nets,‚Äù in NeurIPS, 2014,
pp. 2672‚Äì2680.
[37] X. Mao, Q. Li, H. Xie, R. Y. Lau, Z. Wang, and S. Paul Smolley, ‚ÄúLeast
squares generative adversarial networks,‚Äù in ICCV, 2017, pp. 2794‚Äì2802.
[38] M. W. Lafarge et al., ‚ÄúDomain-adversarial neural networks to address the
appearance variability of histopathology images,‚Äù in Deep Learning in
Medical Image Analysis and Multimodal Learning for Clinical Decision
Support. Springer, 2017, pp. 83‚Äì91.
[39] S. Motiian, M. Piccirilli, D. A. Adjeroh, and G. Doretto, ‚ÄúUnified deep
supervised domain adaptation and generalization,‚Äù in ICCV, 2017, pp.
5715‚Äì5725.
[40] Z. Luo, Y. Zou, J. Hoffman, and L. Fei-Fei, ‚ÄúLabel efficient learning
of transferable representations acrosss domains and tasks,‚Äù in NeurIPS,
2017, pp. 165‚Äì177.
[41] Y. Zhang, Y. Wei, P. Zhao, S. Niu et al., ‚ÄúCollaborative unsupervised
domain adaptation for medical image diagnosis,‚Äù in Medical Imaging
meets NeurIPS, 2019.
[42] M. Long, H. Zhu, J. Wang, and M. I. Jordan, ‚ÄúDeep transfer learning
with joint adaptation networks,‚Äù in ICML, 2017, pp. 2208‚Äì2217.
[43] Z.-H. Zhou, Ensemble methods: foundations and algorithms. CRC
press, 2012.
[44] J. P. Cohen, P. Morrison, and L. Dao, ‚ÄúCovid-19 image data
collection,‚Äù arXiv, 2020. [Online]. Available: https://github.com/
ieee8023/covid-chestxray-dataset.
[45] K. Bousmalis, G. Trigeorgis, N. Silberman, D. Krishnan, and D. Erhan,
‚ÄúDomain separation networks,‚Äù in NeurIPS, 2016, pp. 343‚Äì351.
[46] E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko, ‚ÄúSimultaneous deep
transfer across domains and tasks,‚Äù in ICCV, 2015, pp. 4068‚Äì4076.
[47] A. Paszke et al., ‚ÄúPytorch: An imperative style, high-performance deep
learning library,‚Äù in NeurIPS, 2019, pp. 8024‚Äì8035.
[48] K. He, X. Zhang, S. Ren, and J. Sun, ‚ÄúDeep residual learning for image
recognition,‚Äù in CVPR, 2016, pp. 770‚Äì778.
[49] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, ‚ÄúImagenet:
A large-scale hierarchical image database,‚Äù in CVPR, 2009, pp. 248‚Äì255.
[50] Y. Ding, C. Liu, P. Zhao, and S. C. Hoi, ‚ÄúLarge scale kernel methods
for online auc maximization,‚Äù in ICDM, 2017, pp. 91‚Äì100.
[51] Y. Zhang, P. Zhao, J. Cao, W. Ma, J. Huang, Q. Wu, and M. Tan, ‚ÄúOnline
adaptive asymmetric active learning for budgeted imbalanced data,‚Äù in
SIGKDD, 2018, pp. 2768‚Äì2777.
[52] Y. Zhang, P. Zhao, S. Niu, Q. Wu, J. Cao, J. Huang, and M. Tan,
‚ÄúOnline adaptive asymmetric active learning with limited budgets,‚Äù IEEE
Transactions on Knowledge and Data Engineering, 2019.
[53] R. R. Selvaraju et al., ‚ÄúGrad-cam: Visual explanations from deep
networks via gradient-based localization,‚Äù in ICCV, 2017, pp. 618‚Äì626.

