arXiv:2011.11507v1 [cs.LG] 23 Nov 2020

COND LSTM-Q: A NOVEL DEEP LEARNING MODEL FOR
PREDICTING C OVID -19 MORTALITY IN FINE GEOGRAPHICAL
S CALE

HyeongChan Jo1,â€  , Juhyun Kim2,â€  , Tzu-Chen Huang3 , and Yu-Li Ni, M.D.1,*
1

2

Division of Biology and Biological Engineering, Caltech
The Division of Physics, Mathematics and Astronomy, Caltech
3
Walter Burke Institute for Theoretical Physics, Caltech
*
Corresponding author: ynni@caltech.edu
â€ 
These authors contributed equally to this work.

November 24, 2020

A BSTRACT
Predictive models with a focus on different spatial-temporal scales benefit governments and healthcare
systems to combat the COVID-19 pandemic. Here we present the conditional Long Short-Term
Memory networks with Quantile output (condLSTM-Q), a well-performing model for making quantile
predictions on COVID-19 death tolls at the county level with a two-week forecast window. This fine
geographical scale is a rare but useful feature in publicly available predictive models, which would
especially benefit state-level officials to coordinate resources within the state. The quantile predictions
from condLSTM-Q inform people about the distribution of the predicted death tolls, allowing better
evaluation of possible trajectories of the severity. Given the scalability and generalizability of neural
network models, this model could incorporate additional data sources with ease, and could be further
developed to generate other useful predictions such as new cases or hospitalizations intuitively.

1

Introduction

The coronavirus disease 2019 (COVID-19) pandemic has taken more than 1.1 million lives worldwide and more than
224,000 lives in the United States as of October 2020. Predicting the trend of the pandemic in terms of deaths and
positive cases precisely has been crucial, as it allows the governments and healthcare systems to effectively distribute
and prioritize resource allocations [1].
Here we present the conditional Long Short-Term Memory networks with Quantile output (condLSTM-Q) model, a
novel deep learning model predicting the spatial and temporal distribution of COVID-19 outbreak. The condLSTM-Q
was developed during the Caltech COVID-19 Initiative [2], a campaign aimed to develop and explore novel models to
complement the classic epidemiological models. The optimization goal for participating models was to predict daily
death tolls attributed to COVID-19 in each county across the United States with a two-week future prediction window. In
addition, the models were required to provide estimations of 10-quantiles (0.1 to 0.9 quantile with intervals of 0.1) as the
outputs, as quantile prediction is useful when forecasting the extremes. [3, 4]. The county-level spatial resolution was
selected to inform state officials and local governments so that they can make timely decisions on resource allocations
and strengthen their pandemic preparedness. The condLSTM-Q was among one of the best performers by the end of
the campaign in early June. To test the robustness of this model, the model was then deposited without architectural
modifications since mid-June, 2020, and has continued to be trained and output predictions using updated data. Since
its deposit, the modelâ€™s predictions were comparable to the well-known, publicly available predictions by the Institute
for Health Metrics and Evaluation (IHME) [5] throughout May-October when this manuscript was written, showcasing
the robustness of condLSTM-Q.

A PREPRINT - N OVEMBER 24, 2020

The foundation of the condLSTM-Q was based on the Long Short-Term Memory networks (LSTM), a common
neural network model well-suited for time series predictions [6]. There are previous works of using LSTM and
other neural networks for COVID-19 forecasting, such as risk assessment of countries [7], and predicting national
COVID-19 mortality rates [8]. Nevertheless, to our knowledge no county-level, quantile prediction model existed when
our prototype was developed. Lack of county-based predictions could hugely impact the prevention and control of
COVID-19 pandemic at local governments, which plays pivotal roles in the pandemic preparedness in the United States.
Making quantile predictions rather than single-point predictions also gives a sense of the distribution of the predicted
values, which can help governments to understand the situation better. Thus we decided to explore if the LSTM-based
model could provide good quantile predictions at the county level. We improved the classical LSTM model by adapting
and building on a "conditional" LSTM architecture which takes in static data more naturally along with time series
data [9, 10]. In addition, we utilized the flexibility of neural networks to output a distribution of 10-quantiles that was
required by the initiative.
Given the robust performance of condLSTM-Q and the fact that we have not exploited all possible variations of the
model, this architecture from our pilot experiment is worthy of further exploration. Interdisciplinary collaboration
between experts in machine learning and epidemiology would greatly facilitate building better variants that will provide
both longer prediction windows and clearer interpretability.

2
2.1

Methods
Data Sources and Data Preprocessing

Our model includes a variety of data that is expected to have correlations with the death toll. The original source
of each data is given in Section 5. The data used in our model fall into one of the following seven categories: (1)
COVID-19 mortality and confirmed cases provided by New York Times; (2) demographics and local health resources
such as age composition, mortality rate by diseases, and the number of hospitals, provided by the Yu group at University
of California, Berkeley; (3) county-wise gross domestic product (GDP) from the Bureau of Economic Analysis; (4)
population density and geographical data from 2010 Census; (5) mobility changes in response to COVID-19 provided
by Descartes Labs; (6) policy actions in response to COVID-19 such as state of emergency declaration, safe-at-home
order, and business closure, from Covidvis team at University of California, Berkeley [11] and the U.S. Department of
Health and Human Services; (7) and the U.S. pneumonia and influenza mortality report from the National Center for
Health Statistics Mortality Surveillance System in Centers for Disease Control and Prevention (CDC). All the data were
county-level, and the latest start date of the time series data was March 1, 2020.
Preprocessing specifics for each dataset are listed in the following:
â€¢ Mobility data from the Descartes Labs was provided for 2,721 counties out of 3,114 counties in total. The missing
393 countiesâ€™ mobility data were filled in with their corresponding state-level data. Missing dates in mobility
data of Descartes Labs were interpolated with the data on the closest existing date of the same day in a week to
reflect the weekly pattern inherent in the data. As of November 8, 2020, 14,049 values were missing, out of total
688,413 data points (about 2%). They were filled in using either the aforementioned same-day interpolation or
spline interpolation, and the data from the first and the last day of recording was repeated to fill the missing data
before and after the existing data, if necessary. Spline interpolation has an advantage over the same-day interpolation
in handling a large number of missing data over a long period of time, whereas the latter can capture the weekly
pattern that cannot be maintained in the former method.
â€¢ Seasonality feature was extracted from the U.S. pneumonia and influenza data, under the premise that the COVID-19
will follow a seasonality of virus that becomes more dormant during the summer and severe in the winter. More
specifically, the multiplicative seasonality was extracted from the state-wide pneumonia and influenza mortality rate
during flu seasons from 2013 to 2020 provided by CDC [12].
â€¢ Among 64 features of the demographics and local health data, 43 features including the population estimate and the
mortality rate of various underlying diseases were selected as the static features.
â€¢ For the policy actions features, declaration of the state of emergency, safe-at-home action, and the closure of
inessential business were selected as the static features.
All numerical values were standardized before the model training step.
2

A PREPRINT - N OVEMBER 24, 2020

2.2

Implementation of condLSTM-Q

The classical LSTM which the condLSTM-Qâ€™s backbone was based on is shown in Fig 1A. LSTM is a type of Recurrent
Neural Network (RNN) that can be trained to learn the mapping from the time series features to the time series of
interest. Compared to previous architectures of RNN, LSTM has the advantage of remembering long-term dependencies
by passing the information through its cell state and hidden states recurrently. However, the classical LSTM architecture
cannot take into account non-time series data (hereinafter referred to as categorical data) in a natural way; such features
have to be stacked into the same dimension of the time series data during data processing as shown in Fig 1 A, in order
to take both types of data into the input stream. This way of data processing undermines the optimal performance of
LSTM.
One approach to overcome this limitation is to initialize the initial states of the LSTM units in response to the categorical
data. Intuitively, the categorical data should provide a priori information to the prediction, rather than real-time
information. Thus, a "conditional" module can be added to get these categorical data and feed in "priors" as the hidden
states, as implemented in [9], in contrast to the usual LSTM where the hidden states are initialized to zeros or random
noise [13].
This is the way we treat the categorical data in our model, conditional LSTM with Quantile output model (condLSTM-Q;
Fig 1 B). In this model, categorical inputs are passed through a fully connected layer into the model as the hidden states
to the initial step of the LSTM layer. Through this design, we could input 50 categorical data such as Income, Age and
Gender Distribution, Medicare coverage, and Population in their original forms of one scalar per feature into our model.
After the initialization step, the cell states and hidden states in LSTM were then updated as in the classical LSTM,
based on 8 time series features including mobility of the population, new cases per day, and new deaths per day.
Another feature of condLSTM-Q is that it generates predictions on 10-quantiles (â€œQ"). To get the sense of the
distribution of the predicted values, which help us understand the situation and the quality of the prediction better (a
forecast with higher variance results in huge uncertainty in whatever derivatives from the forecast), our model forecasts
the death counts in each quantile from 0.1 to 0.9 with 0.1 increments by a variant of the multi-output LSTM. In this
model, the outputs from the LSTM layer are fed into 9 parallel dense layers to generate a vector of dimension 9 for each
day in the prediction, where each component of the output vector is a forecast of each quantile. A standard measure for
the accuracy of such a quantile forecasting is the pinball loss defined as
loss = max(q Â· , (q âˆ’ 1) Â· ),

(1)

where 0 < q < 1 is the quantile and  = y âˆ’ yÌ‚ is the difference between the true target value y and the predicted target
value yÌ‚. As such, our model is trained to minimize the average pinball loss
9

1X
max(qi Â· i , (qi âˆ’ 1) Â· i ),
9 i=1

(2)

where qi = i/10, 1 â‰¤ i â‰¤ 9 and i = y âˆ’ yË†i is the difference between the true target vector and the predicted target
vector for quantile qi .
2.3

Hyperparameters and the Training

The time series data after preprocessing is an array of shape (#counties, #dates, #features), and the categorical data is
an array of shape (#counties, #features). For each date in the time series data, the data is further split into a history
window of size 7 and a target window of size 14, so that condLSTM-Q can learn to predict the mortality rate for the
next 14 days based on the history of prior 7 days.
For hyperparameter tuning, we held out the last 21 daysâ€™ worth of data for validation. As of August 4, 2020, we used
136 daysâ€™ worth of data until July 14, 2020, for the training set, and the remaining 21 daysâ€™ worth of data for the
validation set. Since the data was from 3,114 counties, and the input and the target for the model should be 7 and 14
days long, this led to 316,224 samples for training and 3,114 samples for validation.
The optimal hyperparameters selected were 128 units in LSTM, a learning rate of 0.001, and a dropout rate of 0.2. In
this setting, overfitting was observed after 30 epochs, so the model was trained with the ADAM optimizer [14] for 20
epochs to avoid overfitting.
3

A PREPRINT - N OVEMBER 24, 2020

3
3.1

Result
Predictions and Performance

The condLSTM-Q provides a 14-day, county-level prediction with 10-quantiles. To illustrate this, we show predictions
for several representative counties, identified by their Federal Information Processing Standards- or FIPS-based county
code, including Cook County, Los Angeles, New York, Wayne, Philadelphia, Hennepin, Maricopa and Montgomery
from June 12 to June 25, 2020 (See Fig 3). This prediction interval was immediately after we finalized and froze the
model architecture. The model was trained with data up to June 11, 2020, and was agnostic to the data afterward (i.e.
post-June 12). The condLSTM-Q was able to predict the death trends in different phases in the pandemic with different
dynamic ranges. For example, the number of daily deaths in Los Angeles fluctuated between 20 and 60 per day whereas
the counts in Philadelphia were roughly a third of that.
To validate the performance of the condLSTM-Q, we aggregated the sum of reported mortality cases of the counties
and plotted the national trend with New York Timesâ€™ statistics (Fig 2). At first, the precision of predictive values was
subjected to limited data for model training. The predictions gradually improved around mid-April, and successfully
predicted the descending trend of COVID-19 mortality from May to July 2020 and the â€œsecond waveâ€ of COVID-19
since late July 2020. To observe the changes in prediction accuracy from day 1 to day 14 of the prediction (i.e. across
the two-week prediction window), we aligned the day 1, 3, 7, 10, and 14 of each of the prediction windows to their
corresponding dates. The overall prediction accuracy was improved with more available training data. Before mid-April
2020, distal prediction (e.g. day 14) was much more varied compared to proximal predictions; however, after the model
became stable with enough training data, the performance of both distal and proximal prediction converged with a
smaller spread, and the precision of distal prediction was not inferior to proximal predictions.
Visualization of the nationwide, county-based prediction from August 6 to August 19, 2020, is shown in Fig 4. This
interval approximately covered periods of the COVID-19 â€œsecond waveâ€ with the highest number of daily death
attributed to COVID-19 in the United States, which impacted the Southwest and Southeast regions the most. With
county-level resolution, condLSTM-Q demonstrated its ability to pick up inhomogeneous hot spots within specific
states, whereas other coarser geographical models could only observe an average trend of the whole state. In addition,
at this resolution, one can observe state-state interactions of spread in the state border. For instance, quite a few counties
in Arizona and Nevada had trends more similar to their neighboring California hot spots than to other counties within
the states.
3.2

Comparison with other models

To evaluate the performance of condLSTM-Q, we compared its predictions with the IHME model [5]. As condLSTM-Q
provides county-wise predictions while the IHME model generates state-wise predictions, we aggregated predictions
of condLSTM-Q over each county into corresponding states and measured root mean square error (RMSE) of the
state-wise forecasts on two-week intervals. We also averaged across the 9 quantile predictions from condLSTM-Q to
estimate the mean of the distribution, in order to allow direct comparison against single value predictions from IHME.
Note also that due to the format of the IHME model available, predictions from the two models are matched on a
bimonthly basis.
As shown in Fig 5, the state-wise predictions of condLSTM-Q were consistently comparable to the IHME model. The
condLSTM-Q initially had higher RMSE in early May 2020, but showed better performance over most intervals since
then after training data became ample. Despite the fact that condLSTM-Q model was trained using county-level data
with the pinball loss function, it demonstrated a robust performance on a different geographical scale under a different
metric (i.e. RMSE). We also measured the RMSE by setting zeros as control(i.e. placing zeros on the full 14-days
interval across all 50 states in the United States). Our results revealed that both IHME and our condLSTM-Q model
presented a similar pattern with the control, indicating that there could be an uncaptured variance in both models. We
also noticed that there was an abrupt peak of the epidemic curve (approximately 20,000 deaths) on June 24, 2020, when
New York Times made bulk adjustments in its data due to changes in tallying criteria.
3.3

Usefulness of conditional layer for categorical data

With a classical LSTM network which does not have a conditional layer for initializing the hidden states based on
categorical data as in condLSTM-Q, the categorical data should be stacked to the same dimension of the time series
data to be fed into the model. As mentioned in the Introduction, this may lead to suboptimal performance of the model
because it introduces constant values in time series features which actually is not sequential data. To test this, we
compared the prediction accuracy of two models: the model with the aforementioned stacking method, which we refer
to as the "pseudo-categorical" LSTM model, and condLSTM-Q. The pseudo-categorical LSTM model had a pinball
4

A PREPRINT - N OVEMBER 24, 2020

loss of 0.115 during the prediction period of May 22 - June 4, 2020, and 0.0994 during June 5 - June 18, 2020. The
pinball loss of condLSTM-Q, on the other hand, was 0.0959 and 0.0744, respectively, over the same prediction periods.
To investigate whether such a decrease in pinball loss was observed in every county, we looked at the difference in
pinball loss between condLSTM-Q and pseudo-categorical LSTM model in each county. Fig 6 A shows a distribution
of such differences in counties with a high number of deaths (> 50). The difference was obtained by subtracting the
pinball loss of a pseudo-categorical model from condLSTM-Qâ€™s loss, so its bias to the left means condLSTM-Qâ€™s loss
is significantly lower than the pseudo-categorical model (p < 0.0005, one-sided Wilcoxon signed-rank test)
The difference between these two models is well-demonstrated in Fig 6 B and C, which shows example predictions of
May 22 - June 4 and June 5 - June 18, 2020, in New York - the county with the largest difference in pinball loss between
the models. When the condLSTM-Q was already capturing a down-turned trend, the pseudo-categorical LSTM was
still predicting an upward trend. We also found that the condLSTM-Q had a much tighter spread of prediction, allowing
planning based on the predictions much more possible.
3.4

Explainability of the model

To quantify the relative importance of individual features and see which has the most information for the prediction,
permutation feature importance was measured for each time series and categorical feature. As suggested in previous
studies [15, 16], we measured the feature importance based on how the modelâ€™s validation loss has increased after
permuting each feature in a validation set. Increased validation loss after shuffling a feature shows that the model is
relying on the feature for the prediction, whereas an unchanged validation loss means the model is largely ignoring the
feature during prediction.
For categorical data, each feature was shuffled across counties, as it does not have a temporal component. Time series
features, on the other hand, were shuffled across counties first, and then permuted across time. As each county can
have drastically different values in time series features, shuffling across counties and time separately ensures more
realistic input data for LSTM, compared to the features shuffled across counties and time altogether. Such permutation
was done 10 times for each feature, and the resulting 10 input data sets were given to the trained model to generate
predictions. The validation loss was calculated from each prediction and compared to the original validation loss to see
how the shuffled features affected the modelâ€™s performance. As the importance of each feature can change over time,
permutation feature importance was measured at three different time frames (May 15-28, July 15-28, and October 8-21,
2020) with the same procedure.
The result is shown in Fig 7 and Fig 8. For categorical data (Fig 7), its importance to the prediction was generally
higher during the earlier phase, when there were insufficient time series data for the model to be trained on. The top
three features with the greatest importance during the earlier phase in May were GDP in 2015, GDP in 2016, and heart
disease mortality. GDP was also one of the most important features in the later phase in July, but it was not as important
as the population estimate (2018) and estimated mortality (2015-2017). These two features were the most important
categorical features in October as well, followed by the number of eligible people for Medicare (2018).
In contrast, the ranking of the importance of the time series features (see Fig 8) was relatively stable compared to
categorical features. The number of deaths and cases were the two most important features in all three time frames. In
the beginning, the number of cases was more important, but was surpassed by the number of deaths later on. Seasonality
also had high importance, especially during the earlier phase in May and July 2020 when there were fewer data for the
model to be trained on.

4
4.1

Discussion
Contribution and Novelty

This is the first use of conditional RNN in the prediction of COVID-19 trend that we know of. The model has the merit
of providing fine-scale, county-level predictions of daily deaths with a two-week window. The performance of the
model was robust and comparable to, if not slightly better than, the well-known IHME predictions. Given that the
application of this model type is very new in the field, and that we are far from testing all possible architectures with
different input features, one could foresee that the modelâ€™s performance in terms of stability, precision, and length of
the forecast window could still be enhanced with further optimization. We also see that this type of model could be
generalized to trend forecasting of other infectious diseases in the future and is not limited to COVID-19 itself.
County-level spatial resolution is a feature not available in other famous and publicly available forecasts such as
IHME, DELPHI, and Los Alamos National Laboratory [17, 18] which provide state-wise predictions. This provides
unique opportunities for investigating trends within the states, and interactions between counties along state borders. In
5

A PREPRINT - N OVEMBER 24, 2020

addition, through the analysis of the importance of the categorical data which will be discussed below, one could learn
which features are risk factors that affect the death trend and provide handles for officials to ameliorate the risks.
4.2

Effect of categorical features on predictions

One advantage of using conditional LSTM is that it provides insight into the effect of each categorical and time series
feature on the predictions. Fig 9 shows the total number of deaths predicted by each model after altering categorical
features with the highest permutation feature importance. As mentioned in the Result, GDP in 2015 and 2016 and heart
disease mortality were the most important features in the beginning, but later on, the dominant factors shifted to the
population estimate, estimated mortality, and the number of eligible people for Medicare; an increase in any of these
features led to an increase in predicted counts and vice versa.
Such a pattern in the earlier phase shows the possible vulnerability of people with heart disease to COVID-19, which is
consistent with previous studies reporting elevated risk of poorer outcomes with COVID-19 in people with congenital
heart disease [19] and coronary heart disease [20, 21, 22]. The positive correlation between GDP and the predicted
number of deaths in the earlier phase is also consistent with a study claiming a positive correlation between GDP and
the number of confirmed cases of COVID-19 in China [23] - nevertheless, the GDP estimates the value of goods and
services produced by each county [24], which inevitably correlates with its population and other variables. Therefore, it
would require further investigation to remove the dependencies of each factor.
In the later phase, on the other hand, the important features have shifted to population estimates, mortality rate, and the
number of eligible people for Medicare. This may indicate that the number of deaths due to COVID-19 in the later
phase is more related to the overall healthcare resources and general health condition of the population in each county.
4.3

Additional Benefits

The LSTM-based structure is scalable and flexible. We were limited to a few available data sources during the initiative
and have not expanded actively to other data sources that possibly provide additional information for predictions, as
testing the robustness of this architecture was the original goal of this pilot study. Once there are additional data sources,
the condLSTM-Q could adapt and be retrained to extract information from the new data source without adjusting the
architecture. For instance, if one hypothesizes that the temperature affects the death trend, the model can be easily
retrained and tested with an additional time series feature of temperature added to the input data stream. One could
also foresee that, when the vaccine is eventually distributed, the immunization rate in regions could be one additional
important feature.

5

Material Availability

Code and Model for our study are available in:
https://github.com/cjackal/COVID-SKTW
Demographics and Health Resource dataset from the Yu Group at UC Berkeley:
https://raw.githubusercontent.com/Yu-Group/covid19-severity-prediction/data/county_data_
abridged.csv
COVID-19 mortality dataset from New York Times:
https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv
Local area GDP dataset from U.S. Bureau of Economic Analysis (BEA):
https://www.bea.gov/news/2019/local-area-gross-domestic-product-2018
Land area and Population density dataset from 2010 Census:
https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?src=bkmk
Mobility dataset from DescartesLabs:
https://raw.githubusercontent.com/descarteslabs/DL-COVID-19/master/
DL-us-mobility-daterow.csv
COVID-19 related policies dataset from HHS:
https://healthdata.gov/dataset/covid-19-state-and-county-policy-orders
6

A PREPRINT - N OVEMBER 24, 2020

6

Acknowledgement

The authors thank Prof Yaser Abu-Mostafa, and the Teaching Assistants of CS156 in Caltech for organizing the
COVID19 prediction initiative and for providing the data pipeline for parsing data sources. We thank Isaac Yen-Hao
Chu M.D. for reading the manuscript. Y.L.Ni was supported by Taipei Veterans General Hospital-National Yang-Ming
University Excellent Physician Scientists Cultivation Program, No.103-Y-A-003.

References
[1] IHME COVID-19 health service utilization forecasting team and Christopher JL Murray. Forecasting covid-19
impact on hospital bed-days, icu-days, ventilator-days and deaths by us state in the next 4 months. medRxiv, 2020.
[2] Yaser S. Abu-Mostafa. Caltech cs156 covid-19 model. https://cs156.caltech.edu/, September 2020.
[3] Najeebullah Khan, Shamsuddin Shahid, Liew Juneng, Kamal Ahmed, Tarmizi Ismail, and Nadeem Nawaz.
Prediction of heat waves in pakistan using quantile regression forests. Atmospheric Research, 221:1 â€“ 11, 2019.
[4] Angela Brennan, Paul C. Cross, and Scott Creel. Managing more than the mean: using quantile regression to
identify factors related to large elk groups. Journal of Applied Ecology, 52(6):1656â€“1664, 2015.
[5] IHME. Institute for health metrics and evaluation covid-19 estimate. http://www.healthdata.org/covid/
data-downloads, October 2020.
[6] Hochreiter and Schmidhuber. Long Short-Term Memory. Neural Computation, 9(8):1735â€“1780, November 1997.
Publisher: MIT Press.
[7] Ratnabali Pal, Arif Ahmed Sekh, Samarjit Kar, and Dilip K. Prasad. Neural network based country wise risk
prediction of COVID-19. Applied Sciences, 10(18):6448, September 2020. arXiv: 2004.00959.
[8] Patricia Melin, Julio Cesar Monica, Daniela Sanchez, and Oscar Castillo. Multiple Ensemble Neural Network
Models with Fuzzy Response Aggregation for Predicting COVID-19 Time Series: The Case of Mexico. Healthcare,
8(2):181, June 2020. Number: 2 Publisher: Multidisciplinary Digital Publishing Institute.
[9] Philippe RÃ©my. Conditional rnns made easy with tensorflow and keras. https://github.com/philipperemy/
cond_rnn, March 2020.
[10] Andrej Karpathy and Fei-Fei Li. Deep visual-semantic alignments for generating image descriptions. CoRR,
abs/1412.2306, 2014.
[11] The Covidvis team. Covidvis. https://covidvis.berkeley.edu/, May 2020.
[12] CDC. Pneumonia and influenza mortality surveillance from the national center for health statistics mortality
surveillance system. https://gis.cdc.gov/grasp/fluview/mortality.html, October 2020.
[13] Hans-Georg Zimmermann, Christoph Tietz, and Ralph Grothmann. Forecasting with recurrent neural networks:
12 tricks. In Neural Networks: Tricks of the Trade, pages 687â€“707. Springer, 2012.
[14] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017.
[15] Leo Breiman. Random forests. Machine learning, 45(1):5â€“32, 2001.
[16] Aaron Fisher, Cynthia Rudin, and Francesca Dominici. All models are wrong, but many are useful: Learning a
variableâ€™s importance by studying an entire class of prediction models simultaneously, 2019.
[17] COVID Analytics. Delphi model. https://www.covidanalytics.io/projections/, October 2020.
[18] Los Alamos National Laboratory. Lanl model. https://covid-19.bsvgateway.org/, October 2020.
[19] Weiyi Tan and Jamil Aboulhosn. The cardiovascular burden of coronavirus disease 2019 (covid-19) with a focus
on congenital heart disease. International Journal of Cardiology, 309:70 â€“ 77, 2020.
[20] Ruchong Chen, Wenhua Liang, Mei Jiang, Weijie Guan, Chen Zhan, Tao Wang, Chunli Tang, Ling Sang, Jiaxing
Liu, Zhengyi Ni, Yu Hu, Lei Liu, Hong Shan, Chunliang Lei, Yixiang Peng, Li Wei, Yong Liu, Yahua Hu, Peng
Peng, Jianming Wang, Jiyang Liu, Zhong Chen, Gang Li, Zhijian Zheng, Shaoqin Qiu, Jie Luo, Changjiang Ye,
Shaoyong Zhu, Xiaoqing Liu, Linling Cheng, Feng Ye, Jinping Zheng, Nuofu Zhang, Yimin Li, Jianxing He,
Shiyue Li, and Nanshan Zhong. Risk factors of fatal outcome in hospitalized subjects with coronavirus disease
2019 from a nationwide analysis in china. Chest, 158(1):97 â€“ 105, 2020.
[21] Yingyu Chen, Xiao Gong, Lexun Wang, and Jiao Guo. Effects of hypertension, diabetes and coronary heart
disease on covid-19 diseases severity: a systematic review and meta-analysis. medRxiv, 2020.
7

A PREPRINT - N OVEMBER 24, 2020

[22] C Chen, C Chen, JT Yan, N Zhou, JP Zhao, and DW Wang. Analysis of myocardial injury in patients with
covid-19 and association between concomitant cardiovascular diseases and severity of covid-19. Zhonghua xin
xue guan bing za zhi, 48(7):567â€”571, July 2020.
[23] Yi Zhang, Hanwen Tian, Yinglong Zhang, and Yiping Chen. Is the epidemic spread related to gdp? visualizing
the distribution of covid-19 in chinese mainland, 2020.
[24] U.S. Bureau of Economic Analysis (BEA). Local area gross domestic product, 2018. https://www.bea.gov/
system/files/2019-12/lagdp1219.pdf, October 2020.

8

A PREPRINT - N OVEMBER 24, 2020

Figure 1: Classical LSTM vs condLSTM-Q Architecture. Classical LSTM architecture (Top). The classical LSTM
can predict time series better than traditional RNN by remembering and passing cell states and hidden states over the
timesteps. The hidden states are usually initialized to zero or random values. Categorical features have to be stacked
and replicated to the same dimension to match the time series features. The classical structure outputs one time series.
The condLSTM-Q architecture (Bottom). In condLSTM-Q, categorical inputs are passed through a fully connected
layer as hidden states to the initial step ("Conditional" based on the static information) of the LSTM layer. A dropout
layer is also applied to the dense layer to prevent overfitting to the categorical inputs. The output from the LSTM layer
is fed into 9 parallel dense layers to provide 9 outputs for 10-quantiles ("Q"). Each of the 9 parallel outputs is given to
the pinball loss function during training, thus the parallel dense layer gets updated to match the corresponding quantiles
by minimizing the summed loss.

9

A PREPRINT - N OVEMBER 24, 2020

Figure 2: Nationwide prediction on the total number of deaths, aggregated from counties. At each time point, the
actual data from that day is shown in blue, and the predicted values returned from models trained until 1, 3, 7, 10, and
14 days ago are shown in different colors. The modelâ€™s overall accuracy is relatively low in the beginning when there
was not enough data for the model to be trained on, but the prediction started to follow the trend well since late April

10

A PREPRINT - N OVEMBER 24, 2020

Figure 3: Predictions in representative locations Representative counties including Cook, Los Angeles, New York,
Wayne, Philadelphia, Hennepin, Maricopa, and Montgomery. The condLSTM-Q was able to keep track of the death
trends in different phases in the pandemic with different dynamic ranges. For instance, Los Angeles had daily deaths
fluctuating between 20 - 60 per day whereas Philadelphia counts were roughly a third of that.

11

A PREPRINT - N OVEMBER 24, 2020

Figure 4: County-wise prediction by condLSTM-Q. County-wise absolute death counts (Top) and the differences
with the ground truth (Bottom), summed from August 6 to August 19, 2020. This interval was roughly the peak of the
â€œsecond wave" of deaths in the United States. Note that the top and the bottom figures have different color scales.

12

A PREPRINT - N OVEMBER 24, 2020

Dates
2020-05-04
2020-05-19
2020-06-03
2020-06-24
2020-07-04
2020-07-18
2020-08-06
2020-08-21
2020-09-02
2020-09-18

condLSTM-Q
54.814
18.396
13.709
74.154
16.291
48.690
32.927
14.276
16.325
13.123

14-day prediction RMSE
IHME
38.189
20.812
14.152
74.295
14.790
47.098
33.749
21.912
18.915
14.421

control
67.881
38.046
27.152
77.597
28.945
64.760
55.354
37.628
34.328
28.974

Figure 5: Performance analysis. State-level prediction (Top). State-wise, two-week prediction RMSE of condLSTM-Q
and IHME model. We matched the starting dates of our predictions to the dates when the IHME model was updated,
where each model would have access to the training data up to the day before the onset of the two-week prediction. We
also tried placing zeros in all the predictions and calculated RMSE as a control. Both IHME and condLSTM-Q showed
a similar pattern with the control, indicating that there is an uncaptured variance for both models. County(FIPS)-level
performance measured by pinball loss and RMSE (Bottom). The error for both metrics showed a steady decline since
April with several jumps from June to August, which is from the abnormality in New York Timesâ€™ data due to their bulk
adjustments following the changes in tallying criteria.

Figure 6: Effectiveness of conditional architecture. (A) A histogram of differences in pinball loss between
condLSTM-Q and the pseudo-categorical model, in counties with a high number of total death (>50). The loss
from the pseudo-categorical model was subtracted from condLSTM-Qâ€™s loss, so negative values mean condLSTM-Q
has lower pinball loss. (B, C) Representative case study of New York, in two different time frames. The condLSTM-Q
not only captures the trend better, but also has a tighter distribution when compared to the pseudo-categorical model
trained on the same training data with categorical data stacked to match the time series.

13

A PREPRINT - N OVEMBER 24, 2020

Figure 7: Importance of each categorical feature. The permutation feature importance of the 10 most important
categorical features in three prediction windows (May 15-28, July 15-28, and October 8-21, 2020) is shown. The
categorical features were more important during the earlier phase rather than in the later phase. The list of important
features also changed over time: GDP and heart disease mortality for the earlier phase; population, mortality, and
the number of eligible people for medicare for the later phase. Asterisks indicate statistical significance based on
one-sample sign test to original validation loss (*p<0.05, **p<0.01)

Figure 8: Importance of each time series feature. The permutation feature importance of the time series features in
three prediction windows (May 15-28, July 15-28, and October 8-21, 2020) is shown. The number of cases, deaths, and
flu seasonality are the three most important time series features in the model. The importance of seasonality, however,
went down nearly to zero in the later phase. Asterisks indicate statistical significance from one-sample sign test to
original validation loss (*p<0.05, **p<0.01)

14

A PREPRINT - N OVEMBER 24, 2020

Figure 9: Changes in nationwide prediction after modifying categorical features. For each model making predictions over 2 weeks from May 15th (top), July 15th (middle), and October 8th, 2020 (bottom), new predictions after
increasing and decreasing a categorical feature are shown in blue and orange, along with the original prediction in green.
Each altered feature has been selected based on permutation feature importance from each of the models, and features
were either increased or decreased by 3 standard deviations. The values shown in this figure are the predicted numbers
of deaths in the United States.

15

