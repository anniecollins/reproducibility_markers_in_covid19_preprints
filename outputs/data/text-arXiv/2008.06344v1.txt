SPATIOTEMPORAL PREDICTION OF COVID‚Äì19
MORTALITY AND RISK ASSESSMENT

arXiv:2008.06344v1 [stat.ML] 7 Aug 2020

A. Torres‚ÄìSignes, M. P. Frƒ±ÃÅas and M. D. Ruiz‚ÄìMedina

Abstract
This paper presents a multivariate functional data statistical approach, for spatiotemporal prediction of COVID‚Äì19 mortality counts.
Specifically, spatial heterogeneous nonlinear parametric functional regression trend model fitting is first implemented. Classical and Bayesian
infinite‚Äìdimensional log‚ÄìGaussian linear residual correlation analysis
is then applied. The nonlinear regression predictor of the mortality
risk is combined with the plug‚Äìin predictor of the multiplicative error
term. An empirical model ranking, based on random K‚Äìfold validation, is established for COVID‚Äì19 mortality risk forecasting and assessment, involving Machine Learning (ML) models, and the adopted
Classical and Bayesian semilinear estimation approach. This empirical analysis also determines the ML models favored by the spatial
multivariate Functional Data Analysis (FDA) framework. The results
could be extrapolated to other countries.
Keywords Bayesian and Classical Functional Prediction, COVID‚Äì19
Mortality Risk, Machine Learning Forecasting, Nonlinear Parametric
Regression.
MSC code 60G25; 60G60; 62J05; 62J10

1

Introduction

Coronavirus disease 2019 (COVID‚Äì19) rapidly spreads around many other
countries, since December 2019 when arises in China (see [44]; [51]). It has
supposed a substantial damage in terms of both human lives and economic
cost. There is no vaccine specifically designed for this virus. Thus, the absence of reliable data regarding this infectious disease transmission makes
necessary cautious responses. A crucial problem is geo-localization of outbreaks, since it allows a more effective allocation of medical resources (see,
e.g., [11]; [25]; [34]; [36], just to mention a few). Some mathematical models

1

have been introduced in the literature, trying to describe the spatiotemporal dynamics of COVID-19. To generate and assess short-term forecasts
of the cumulative number of reported cases, three models are presented in
[37], which were validated with outbreaks of other diseases different from
COVID‚Äì19. Alternative SEIR type models with little variations are formulated, involving, for instance, stochastic components (see [26]). In [19], a
Œ∏‚ÄìSEIHRD model is introduced, well adapted to COVID‚Äì19, based on the
Be-CoDiS model (see [20]). This model is able to estimate the number of
cases, deaths, and needs of beds in hospitals. The most remarkable feature
of the presented approach in [19] is the balance between complexity and
indentifiability of model parameters.
Mathematics contributes in an essential way to the derivation of epidemiological models, and the subsequent analysis of the causes, dynamics,
and spread of an epidemic/pandemic (see, e.g, [17] and [23] for an overview
on mathematical models in Epidemiology). Particularly, ordinary differential equations have been extensively applied in the characterization of the
time evolution of an infectious disease over uniform population distributions
within a habitat. Most of those models are compartment epidemic models,
such as the SIR (susceptible-infectious-recovered) model. The SIR model
was first proposed in [24] to explain plague and cholera epidemics. It was
later extended to the SIR-susceptible (SIRS) model to allow imperfect immunity (see, e.g., [12]). Indeed, there exists an extensive literature on SIR
models, based on ordinary differential equations (see, e.g. [13]; [21]; [27];
[35]; [41]; [45]; [49]). Delay differential equations have also been applied in
the SIR modeling context (see [5]; [31]; [40], among others). These models
are limited, since any structure due to the spatial position is not reflected.
Reaction-diffusion models provide a framework for their spatial extension,
reflecting the infectious disease spread over a spatial region. Thus, they provide a simplest modeling alternative in Ecology and Epidemiology involving
space and time. A diffusive predator-prey model is analyzed in [15]. A one
dimensional SIR model, including constant diffusive movement of all individuals is derived in [47] with no-flux boundary conditions. SIR modeling based
on hyperbolic partial differential equations is studied in [32], and, based on
parabolic partial differential equation systems with no-flux boundary conditions in [28]. See also [39] and [38] on SEIRD (susceptible, exposed, infected,
recovered, deceased) model, that incorporates the spatial spread of the disease with inhomogeneous diffusion terms.
The stochastic version of SIR‚Äìtype models intends to cover several limitations detected regarding uncertainly, in the observations, and the hidden
dynamical epidemic process. Specifically, the counts compartments are observed with error, and several factors introduce uncertainly in the hidden
2

epidemic process, such as the presence of heterogeneous populations. The
transmission, recovery and loss of immunity rate parameters, for example, are
uncertain themselves. In a first stage, a probabilistic mechanism is adopted
involving a Markov chain of SIR states (see [4]; [48]). Some more recent
stochastic models involve complex networks (see [50]; [43]) or drug‚Äìresistant
influenza (see [10]). As pointed out in [52] (see references therein), these
models do not take into account the observation error in the counts, and
obtain mass balance equation from the observed counts. The uncertainty in
the parameter space is neither accounted for. The approach presented in [52]
covers these gaps, adopting a Bayesian hierarchical statistical SIRS model
framework. Specifically, the stochastic SIR‚Äìlike model fitting is performed,
assuming that the counts are observed with error and the dynamical evolution of the SIR process is stochastic. Parameter uncertainty is also modelled
under this Bayesian statistical framework (see also [2]).
Many alternative models have been proposed to address the problem of
uncertainly in the counts and the parameters, in the spatiotemporal statistical and Cox process context (see, e.g., [1]; [4]; [14], among others). Some
of them go beyond the SIR modeling framework (see, e.g., [7] or [22], where
the problem of correlation of rates of change between neighbouring sites or
individuals is addressed). Survival Dynamical System are proposed in [46],
paying attention to survival functions instead of population counts. We particularly refer to the approach presented in [33], where a spatially descriptive,
temporally dynamic hierarchical model is formulated, to handle inference
from small‚Äìarea counts on the number of infected during successive, regular
time intervals. The realizations of an underlying multivariate autoregressive
process are involved in the infection relative risk modeling, incorporating the
space-time dynamics, and providing an epidemic‚Äìfield‚Äìbased view. Markov
chain Monte Carlo (MCMC) in a Bayesian statistical framework is applied
to compute the posterior estimates of all parameters of interest.
Our paper extends some of the tools applied in [33] to the nonlinear trend
model fitting, and infinite‚Äìdimensional statistical frameworks. The prediction approach presented involves nonlinear parametric functional regression,
and spatial multivariate functional linear residual correlation analysis. It is
well‚Äìknown that Functional Data Analysis (FDA) techniques allow to make
inference on the small-scale and large‚Äìscale sample properties, in our case, of
the hidden stochastic mortality risk process generating the spatiotemporal
counts (see, e.g., [42]). Note that the classical stochastic diffusion models
offer a particle view rather than a field view (see, e.g., [30]). Thus, we incorporate large‚Äì and small‚Äìscale sample information in our statistical analysis
framework. The first stage involves nonlinear parametric curve regression,
from the observed realizations of the COVID‚Äì19 mortality log‚Äìrisk process,
3

at each one of the Spanish Communities. The second step performs a spatial multivariate functional linear residual correlation analysis. Thus, the
resulting semi‚Äìlinear additive plug‚Äìin predictor approximates the behavior
of the COVID‚Äì19 mortality log‚Äìrisk process in space and time. Bayesian and
Classical approaches are adopted in the implementation of the second step.
Hence, our approach includes uncertainly in the observed counts, parameters
and hidden COVID‚Äì19 mortality log‚Äìrisk process. The presented estimation
methodology is validated from the observed number of deaths registered at
the Spanish Communities, during the period analyzed, since March, 8, 2020
until May, 13, 2020. Our results show a remarkable qualitative agreement
with the reported epidemiological data.
Nowadays Machine learning models have established themselves as serious
contenders to classical statistical models in the area of forecasting. Research
started in the eighties with the development of the neural network model.
Subsequently, research extended the concept to alternative models, such as
support vector machines, decision trees, and others, that are collectively
called machine learning models ([3]; [16]). This paper also aims to establish
an empirical comparative study of these models and our approach. Applying
random K‚Äìfold validation, the forecasting ability of ML models are tested
into two categories, respectively corresponding to the original and projected
functional data. A model ranking is established in both cases. In the second category, they are compared with our multivariate infinite‚Äìdimensional
Bayesian and Classical semilinear approaches. From the COVID‚Äì19 mortality data set analyzed, the outperformance of Radial Basis Function Neural
Network (RBF), and Gaussian Processes (GP) against the remaining forecasting models tested: Support Vector Regression (SVR), Bayesian Neural
Networks (BNN), Classical and Bayesian multivariate infinite‚Äìdimensional
semilinear estimation, Multilayer Perceptron (MLP), Generalized Regression
Neural Network (GRNN) is observed. Note that, the best K‚Äìfold running for
these superior RBF and GP methods is obtained under an FDA preprocessing of the data. Our approach presents a more stable and robust behavior
against the possible random splitting of the functional sample into training,
and validation or testing samples.
The outline of the paper is the following. The adopted modeling approach is introduced in Section 2. Section 3 derives the estimation methodology. This methodology is applied to the spatiotemporal statistical analysis
of COVID‚Äì19 mortality in Spain in Section 4. The empirical comparative
study with ML models is addressed in Section 5. An empirical model ranking
is provided in Section 6 leading to some concluding remarks. In the Appendix
additional outputs, obtained in our spatiotemporal estimation of COVID‚Äì19
mortality and risk assessment in Spain, are displayed. Finally, this Appendix
4

also provides a brief introduction to our implementation of ML models in an
FDA framework.

2

The Model

Let (‚Ñ¶, A, P) be the basic probability space. Consider H to be a real separable Hilbert space, with H ? denoting its dual. Let Œõ = {Œõt,z , z ‚àà D ‚äÇ
Rd , t ‚àà R+ , } be a spatiotemporal risk process on (‚Ñ¶, A, P) such that
Z

Z
exp
ln (Œªt,z ) h(z)dz dt < ‚àû, ‚àÄh ‚àà H, T ‚àà B, a.s.,(1)
IT (h) =
T

D

where T is a bounded Borel set in R+ , and B denotes the Borel œÉ‚Äìalgebra.
Process Œõ is assumed to satisfy E [k ln (Œõt (¬∑)) k2H ] < ‚àû, with Œõt (z) = Œõt,z ,
for every z ‚àà D and t ‚àà R+ . Here,


Z

ln (Œªt,z ) h(z)dz , t ‚àà R+ = {Rt (h), t ‚àà R+ }
exp
D

defines a temporal realization of the generalized risk process evaluated at the
test function h ‚àà H. Note that, the weighted integration of the realizations
of the log‚Äìrisk process, in terms of test function h ‚àà H, keeps the spatial
information on this process. For certain families of compactly supported test
functions, the local mean defined by this integral allows the localization of
the values of the spatiotemporal risk process over a specific spatial region.
For any bounded Borel set T , let N (T ) : (‚Ñ¶, A, P) ‚àí‚Üí N be a measurable mapping, with values in the natural numbers N. Given the observation
of IT (h), the conditional probability distribution of the number of random
events N (T ), that occur in the bounded interval T ‚àà B, is a Poisson probability distribution with functional mean IT (h), h ‚àà H. Thus, its conditional
characteristic function is given by
fN (T )/IT (h) (Œæ) = E [exp (iŒæN (T )) /IT (h)]
= exp (IT (h) (exp(iŒæ) ‚àí 1)) ,

2.1

‚àÄŒæ,

h ‚àà H.

(2)

Data Model

Let us consider the following observation model for the generalized log‚Äìrisk
process: For t = 1, . . . , T,
ln (Œõt ) (œàp,$p ) = gt (œàp,$p , Œ∏(p)) + Œµt (œàp,$p )
= gt (¬∑, Œ∏(p)), œàp,$p (¬∑) H + Œµt (¬∑), œàp,$p (¬∑)
5

H

, p = 1, . . . , P,

(3)

where {œàp,$p , p = 1, . . . , P } ‚äÇ H denotes a function family in H, whose
elements have compact support defining the small‚Äìareas, where the counts
are aggregated. Here, $p , p = 1, . . . , P, are the localization hyperparameters
(in the next section, the center and bandwidth parameters), associated with
those small‚Äìareas. For each p ‚àà {1, . . . , P }, Œ∏(p) = (Œ∏1 (p), . . . , Œ∏q (p)) ‚àà Œò
denotes the unknown parameter vector to be estimated at the pth region, and
Œò is the open set defining the parameter space, whose closure Œòc is compact
in Rq . The parametric regression function gt is continuous over Œ∏(¬∑) ‚àà Œò, and
t ‚àà R+ , with respect to H‚Äìnorm. Furthermore, we assume that gt is of the
form
gt (Œ∏(¬∑)) =

N
X

(Ak (¬∑) cos(œïk (¬∑)t) + Bk (¬∑) sin(œïk (¬∑)t)) ,

t ‚àà R+ ,

(4)

k=1

with
Œ∏(¬∑) = (Œ∏1 (¬∑), Œ∏2 (¬∑), Œ∏3 (¬∑), . . . , Œ∏3N ‚àí2 (¬∑), Œ∏3N ‚àí1 (¬∑), Œ∏3N (¬∑))
= (A1 (¬∑), B1 (¬∑), œï1 (¬∑), . . . , AN (¬∑), BN (¬∑), œïN (¬∑)) ‚àà H 3N ,
Ck2 (¬∑) = A2k (¬∑) + Bk2 (¬∑) > 0, k = 1, . . . , N,
0 ‚â§ œï(¬∑) < œï1 (¬∑) < ¬∑ ¬∑ ¬∑ < œïN (¬∑) < œï < ‚àû.

(5)

In equation (3), for any T ‚â• 2, Œµt is assumed to be a temporal dynamical
zero‚Äìmean process that satisfies the state equation
Œµt = œÅ(Œµt‚àí1 ) + ŒΩt ,

t = 1, . . . , T,

(6)

where {ŒΩt , t = 1, . . . , T } are independent H‚Äìvalued zero‚Äìmean Gaussian
random variables, with E [kŒΩt k2H ] = E [kŒΩ0 k2H ] < ‚àû, and P [ŒΩt ‚àà H] = 1,
t = 1, . . . , T. The autocorrelation operator œÅ is bounded linear operator.
Thus, the observation noise Œµt obeys an Autoregressive Hilbertian equation
of order one (ARH(1) equation), which admits an unique stationary solution
0
under the condition kœÅkkL(H)
< 1, for certain k0 ‚àà N (see, e.g., [8]). Here,
k ¬∑ kL(H) denotes the bounded linear operator norm in H.

3

Trend Model Fitting and Residual Correlation Analysis

Let L1 , . . . , LP be the small-areas, where the counts are aggregated. Consider
{œàp,œÅp , p = 1, . . . , P } ‚äÇ H to be a family of compactly supported radial
functions in H, whose centers cp , p = 1, . . . , P, are allocated at the regions
6

L1 , . . . , LP , respectively. The bandwidth parameters œÅ1 , . . . , œÅP provide their
associated windows with suitable size.
bT (p), in
From (3), we first compute the least-squares estimator (LSE) Œ∏
the Walker sense, of the parameter vector Œ∏(p), for p = 1, . . . , P (see (4)‚Äì
bT (p) is obtained as the solution to
(5)). Thus, for p = 1, . . . , P, the LSE Œ∏
the following optimization problem:
T
1X
2
b
LT (Œ∏ T (p)) = inf c LT (œÑ p ) = inf c
ln (Œõt ) (œàp,œÅp ) ‚àí gt (œÑ p ) .
œÑ p ‚ààŒò
œÑ p ‚ààŒò T
t=1

(7)

Hence,
\
bT (p))
ln
(Œõt )(œàp,œÅp ) = gt (Œ∏

(8)

defines the parametric nonlinear regression predictor of the log‚Äìrisk process
at region p, for any time t ‚àà R+ , and for p = 1, . . . , P.

3.1

Classical and Bayesian componentwise estimation
of the mortality residual log‚Äìrisk process

n
o
bT (¬∑)), t = 1, . . . , T be the functional residLet Y = Yt = ln (Œõt (¬∑)) ‚àí gt (Œ∏
uals from the nonlinear parametric regression model fitting. The empirical autocovariance and
operators, based on the residuals

 cross‚Äìcovariance
Yt (¬∑) = ln (Œõt (¬∑)) ‚àí gt Œ∏cT (¬∑) , t = 1, . . . , T, are respectively given by
T
1X
Y
b
R0,T (h)(g) =
Yt (h)Yt (g),
T t=1

T ‚àí1

Y
b1,T
R
(h)(g) =

1 X
Yt (h)Yt+1 (g), (9)
T ‚àí 1 t=1

b Y and R
bY are also nuclear operators. In
for every h, g ‚àà H. Operators R
0,T
1,T
particular, we will consider the spectral decomposition
bY =
R
0,T

T
X

bY )[œÜk,T ‚äó œÜk,T ],
Œªk,T (R
0,T

(10)

k=1

bY ), k = 1, . . . , T } and {œÜk,T , k ‚â• 1} denote the empirical
where {Œªk,T (R
0,T
bY , respectively.
eigenvalues and eigenvectors of R
0,T
The following classical componentwise estimator of the autocorrelation
operator is considered (see [8]): For every h, g ‚àà H,
K(T )

œÅbT (h)(g) =

1
bY (œÜk,T )(œÜl,T ) hg, œÜl,T i ,
hh, œÜk,T iH R
1,T
H
Y
b
k,l=1 Œªk,T (R0,T )
X

7

(11)

where K(T ) denotes the truncation parameter, that depends on the functional sample size T. An optimal choice is given by K(T ) = ln(T ). Under the
conditions derived in Corollary 4.1, Theorem 4.8 and Theorem 8.7 in [8], œÅbT
is a strong‚Äìconsistent componentwise estimator of the autocorrelation operator of the residuals, with respect to the norm in the space L(H) of bounded
linear operators. Under the assumptions made in Theorem 1 in [18], the
corresponding plug‚Äìin predictor
Ybt = œÅbT (Yt‚àí1 ),

t ‚â• 1,

(12)

is a weak‚Äìconsistent estimator of Œµt in equation (6), with respect to H‚Äìnorm.
We refer to (12), as the classical plug‚Äìin predictor of the mortality residual
log‚Äìrisk process.
In the Bayesian componentwise estimation of œÅ in (6), we assume that œÅ
is compact self‚Äìadjoint operator. An a‚Äìpriori beta probability distribution
with parameters ak > 0 and bk > 0 is considered to represent the uncertainly
in the eigenvalue Œ≥k (œÅ) of œÅ, for every k ‚â• 1. From the sample Œµt , t = 1, . . . , T,
of size T, since Œ≥k (œÅ) ‚àº B(ak , bk ), the likelihood function is computed as
T
1 X
1
e
(Œµt (œàk ) ‚àí Œ≥k (œÅ)Œµt‚àí1 (œàk ))2
Lk (Œµ1k , . . . , ŒµT k , Œ≥k (œÅ)) =
‚àö T exp ‚àí 2
2œÉ
k t=1
œÉk 2œÄ
I{0<Œ≥k (œÅ)<1}
√ó[Œ≥k (œÅ)]ak ‚àí1 (1 ‚àí Œ≥k (œÅ))bk ‚àí1
B(ak , bk )
!
T
X
1
1
[ŒΩt (œàk )]2
=
‚àö T exp ‚àí 2
2œÉk t=1
œÉk 2œÄ

√ó[Œ≥k (œÅ)]ak ‚àí1 (1 ‚àí Œ≥k (œÅ))bk ‚àí1

I{0<Œ≥k (œÅ)<1}
,
B(ak , bk )

k ‚â• 1,

(13)

p
where Œµtk = Œµt (œàk ) = hŒµt , œàk iH , and œÉk = E[Œµt (œàk )]2 , t = 1, . . . , T, with
œàk being the k‚Äìth eigenvector of œÅ, for each k ‚â• 1. Here, I is the indicator function on the interval (0, 1), and B(ak , bk ) denotes the beta function
k )Œì(bk )
. From (13), the Bayesian estimator Œ≥[
B(ak , bk ) = Œì(a
k (œÅ) of Œ≥k (œÅ) is
Œì(ak +bk )
given by
Œ≥[
k (œÅ) =


q
1
2
2
=
(Œæk (T ) + Œ∂k (T ) ¬± (Œæk (T ) ‚àí Œ∂k (T )) ‚àí 4Œ∂k (T )œÉk (2 ‚àí (ak + bk )) ,
2Œ∂k (T )
(14)
PT
PT
where, for each k ‚â• 1, Œæk (T ) = t=1 Œµt‚àí1 (œàk )Œµt (œàk ), Œ∂k (T ) = t=1 [Œµt‚àí1 (œàk )]2 ,
and œÉk2 = E[Œµt (œàk )]2 , for t = 1, . . . , T.
8

!

The Bayesian componentwise estimator œÅeT of the autocorrelation operator
œÅ is then computed as
K(T )

œÅeT =

X

Œ≥[
k (œÅ)[œàk ‚äó œàk ],

(15)

k=1

where K(T ) is the truncation parameter, usually selected as K(T ) = ln(T ).
The resulting Bayesian componentwise plug‚Äìin predictor is given by
Œµet = œÅeT (Œµt‚àí1 ),

t ‚â• 1.

In practice, in the computation of the Bayesian componentwise estimator
bT (¬∑)), for each
œÅeT , we replace in (13)‚Äì(14), Œµt by Œµbt = Yt = ln (Œõt (¬∑)) ‚àí gt (Œ∏
t = 1, . . . , T. The eigenvectors {œàk , k ‚â• 1} can also be replaced by their
empirical counterpart. Hence,
Yet = œÅeT (Yt‚àí1 ),

t ‚â• 1.

(16)

We refer to (16) as the Bayesian plug‚Äìin predictor of the residual log‚Äìrisk
process Yt . From equations (12) and (16), the corresponding Classical and
Bayesian plug‚Äìin predictors implemented for spatiotemporal forecasting of
COVID‚Äì19 mortality risk are given, for any t, by


b
b
b
Rt (œàp,œÅp ) = exp gt (Œ∏ T (p)) + Yt (œàp,œÅp ) , p = 1, . . . , P


bT (p)) + Yet (œàp,œÅp ) , p = 1, . . . , P.
e t (œàp,œÅp ) = exp gt (Œ∏
R
(17)
Classical and Bayesian estimation of the autocovariance operator of the
innovation process ŒΩt in (6) is provided in Appendix.

4

Statistical Analysis of COVID‚Äì19 Mortality in Spain

The COVID‚Äì19 mortality analysis performed here is based on the daily
records reported by the Spanish Statistical National Institute, since March, 8
to May, 13, 2020, at the 17 Spanish Communities. Interpolation at 265 temporal nodes, and cubic B-spline smoothing is applied to obtain our functional
data set, in the implementation of the spatial heterogeneous nonlinear parametric curve regression model (3)‚Äì(4) (see Figures 9 and 10 in Appendix).
The spatiotemporal correlation structure of COVID‚Äì19 mortality residual
log‚Äìrisk process is estimated from equations (11) and (15). Thus, from (17),
with P = 17,
9

\
b
b
ln(Œõ
t )(œàp,œÅp ) = gt (Œ∏ T (p)) + Yt (œàp,œÅp ), t ‚àà R+ , p = 1, . . . , 17
^
e
e
ln(Œõ
t )(œàp,œÅp ) = gt (Œ∏ T (p)) + Yt (œàp,œÅp ), t ‚àà R+ , p = 1, . . . , 17.

(18)

bk (¬∑) and B
bk (¬∑),
Tables 9‚Äì10, in Appendix, display the parameter estimates A
k = 1, . . . , N, in the nonlinear parametric trend model fitting. Here, we have
,
considered N = 6. Thus, 12 parameters must be estimated, since œïk = 2œÄ
66
for k = 1, . . . , N = 6, is assumed to be constant. In Tables below, the
following Spanish Community codes have been considered: C1 for Andalucƒ±ÃÅa;
C2 for AragoÃÅn; C3 for Asturias; C4 for Islas Baleares; C5 for Canarias; C6
for Cantabria; C7 for Castilla La Mancha; C8 for Castilla y LeoÃÅn; C9 for
CatalunÃÉa; C10 for Comunidad Valenciana; C11 for Extremadura; C12 for
Galicia; C13 for Comunidad de Madrid; C14 for Murcia; C15 for Navarra;
C16 for Pas Vasco, and C17 for La Rioja.
In equation (14), for the computation of the Bayesian estimator (15) of
the autocorrelation operator œÅ, the prior Œ≥k (œÅ) ‚àº Œ≤(4, 5) has been tested,
for every k ‚â• 1. Note that, although, K(T ) = [ln(T )]‚àí = [ln(265)]‚àí =
[5.57973]‚àí = 5 is usually considered, we have also tested the truncation
parameter values N = 8 and N = 9. Table 1 displays the discrete approximation of k ¬∑ kL2 ([0,66]) ‚Äìnorm, multiplied by the scale factor S = 102 , of
the empirical functional quadratic errors associated with these three truncation parameter values. We find that the sample size T = 265 leads to the
threshold dimension K(265) = 9, providing the allowed model complexity, in
our finite‚Äìdimensional implementation of the COVID‚Äì19 mortality log‚Äìrisk
predictor, under both, Bayesian and Classical approaches.
Figures 1 and 2 respectively show the maps reflecting the original and estimated spatiotemporal evolution of COVID‚Äì19 mortality risk, and accumulated mortality counts, under the presented Bayesian and Classical semilinear
estimation approaches, over the 17 Spanish Communities analyzed.

5

An Empirical Comparative Study

This section provides an empirical model ranking for spatiotemporal
COVID‚Äì19 mortality risk assessment, based on random K‚Äìfold validation,
involving the ML models introduced in Appendix, and the forecasting approach presented in this paper. The random K‚Äìfold (K = 5, 10) has been
10

Table 1: k ¬∑ kL2 ([0,66]) ‚Äìnorm, multiplied by the scale factor S = 102 , of
the empirical functional quadratic errors at the 17 Spanish Communities, after applying nonlinear trend model fitting, and Classical and Bayesian residual correlation analysis, for the truncation parameter values K(T ) = 5, 9, 8
from the left to the right
SC/TP
C1
C2
C3
C4
C5
C6
C7
C8
C9
C10
C11
C12
C13
C14
C15
C16
C17

B.5
0.0069
0.0388
0.0048
0.0002
0.0007
0.0001
0.0126
0.0018
0.0858
0.0016
0.0011
0.0405
0.0253
0.0002
0.0408
0.0033
0.0004

C.5
0.0027
0.0186
0.0023
0.0002
0.0003
0.0001
0.0067
0.0015
0.0409
0.0010
0.0009
0.0152
0.0162
0.0001
0.0174
0.0018
0.0003

B.9
0.0067
0.0388
0.0042
0.0001
0.0007
0.0000
0.0118
0.0008
0.0856
0.0011
0.0008
0.0408
0.0252
0.0002
0.0407
0.0029
0.0003

C.9
0.0026
0.0185
0.0018
0.0001
0.0003
0.0000
0.0060
0.0005
0.0405
0.0005
0.0006
0.0155
0.0161
0.0001
0.0174
0.0013
0.0002

B.8
0.0066
0.0388
0.0044
0.0001
0.0007
0.0000
0.0118
0.0008
0.0857
0.0011
0.0008
0.0408
0.0252
0.0002
0.0407
0.0029
0.0003

C.8
0.0026
0.0185
0.0019
0.0001
0.0003
0.0000
0.0060
0.0005
0.0405
0.0005
0.0006
0.0154
0.0161
0.0001
0.0173
0.0013
0.0002

implemented from the records reported by the Spanish Statistical National
Institute, since March, 8 to May, 13, 2020. The empirical ranking is referred
to two categories, where we respectively perform forecasts from the observed
pointwise, and from the generalized (projected) COVID‚Äì19 mortality log‚Äì
risk process realizations. In the first category the ML models: Multilayer
Perceptron (MLP), Radial Basis Function Neural Network (RBF), Bayesian
Neural Network (BNN), Generalized Regression Neural Network (GRNN),
Support Vector Regression (SVR), and Gaussian Processes (GP) are compared. In the second category, the performance of the presented approach is
compared with these ML methodologies.
A brief introduction to the ML methodologies, here implemented in a
classical and FDA frameworks, is provided in Appendix.

11

day 10

day 13

day 16

day 19

day 22

295

day 10

day 13

day 16

day 19

day 22

80

80

40

day 25

day 28

day 31

day 34

40

day 37

day 25

day 28

day 31

day 34

day 37

20

day 40

day 43

day 46

day 49

day 55

day 58

day 61

day 64

day 52

20

10

day 40

day 43

day 46

day 49

day 55

day 58

day 61

day 64

day 52

5

day 13

day 16

day 19

day 22

0

295

day 10

day 13

day 16

day 19

day 22

80

day 28

day 31

day 34

40

day 37

day 25

day 28

day 31

day 34

day 37

20

day 40

day 43

day 46

day 49

day 55

day 58

day 61

day 64

day 52

295
80

40

day 25

10

5

0

day 10

295

20

10

day 40

day 43

day 46

day 49

day 55

day 58

day 61

day 64

5

day 52

10

5

0

0

Figure 1: COVID‚Äì19 mortality risk maps, since March, 8 to May, 13, 2020.
Original (left) and estimated (right) maps, computed from the Bayesian (first
line) and classical (second line) COVID‚Äì19 mortality predictors, for the truncation parameter value K(T ) = 8

5.1

Results from the Empirical Comparative Study

We start from the functional data set obtained after the FDA preprocessing
procedure has been applied, as described in the previous section. Specifically, data have been interpolated and cubic B-spline smoothed. The logarithmic transform and linear scaling are also applied. We held out the first
ten points and the last three, for each log‚Äìrisk curve, as an out of sample
set. In the first category, ML models are implemented from this data set,
establishing a first model ranking based on the obtained validation results.
In the second category, COVID‚Äì19 mortality log‚Äìrisk curves are projected
onto the empirical eigenvectors of the autocovariance operator, considering
the truncation parameter value K(T ) = 8. Our choice of the truncation parameter K(T ) = K(265) = 8 fits the threshold providing a balance between
K(T ) = [ln(T )]‚àí = [ln(265)]‚àí = 5, signing an agreement with the separation and velocity decay of the empirical eigenvalues of the autocovariance
operator, and the parameter value K(T ) = K(265) = 9, controlling model
complexity according to the sample size T = 265. Based on the validation
results obtained in this category, a second model ranking is established involving the ML models tested and the approach presented. The derived
12

day 1

day 4

day 7

day 10

day 13

day 16

8000

day 1

day 4

day 7

day 10

day 13

day 16

2000

2000

1200

day 19

day 22

day 25

day 28

day 31

day 34

1200

500

day 19

day 22

day 25

day 28

day 31

day 34

day 37

day 40

day 43

day 46

day 49

day 52

250

day 37

day 40

day 43

day 46

day 49

day 58

day 61

day 64

day 67

125

day 55

25

day 58

day 61

day 64

day 67

25

0

day 1

day 4

day 7

day 10

day 13

day 16

0

8000

day 1

day 4

day 7

day 10

day 13

day 16

2000

day 22

day 25

day 28

day 31

day 34

1200

500

day 19

day 22

day 25

day 28

day 31

day 34

day 37

day 40

day 43

day 46

day 49

day 52

250

day 37

day 40

day 43

day 46

day 49

day 58

day 61

day 64

day 67

500

250

day 52
125

day 55

8000
2000

1200

day 19

500

250

day 52
125

day 55

8000

125

day 55

25

day 58

day 61

day 64

day 67

0

25

0

Figure 2: COVID‚Äì19 mortality cumulative cases maps, since March, 8 to
May, 13, 2020. Original (left) and estimated (right) maps, from the Bayesian
(first line) and classical (second line) COVID‚Äì19 mortality count predictors,
for the truncation parameter value K(T ) = 8
empirical model ranking is not affected by these two categories. However, it
can be observed how each ML model performance is favored by one of the
two categories (see Section 6). For instance, linear SVR is the best option for
the first category, while better forecasting results are obtained when nonlinear SVR is implemented from the projected data. As we will see in Section
6, the particular features of the data at each one of the 17 Spanish Communities analyzed also affect the performance of the implemented prediction
methodologies.
One-step-ahead forecasting is selected in the implementation of the ML
methodologies, and the proposed Classical and Bayesian semilinear approaches.
Model fitting is evaluated in terms of the Symmetric Mean Absolute Percentage Errors (SMAPEs), given by, for P = 17, and T = 265,
\
T
ln(Œõ
t )(œàp,œÅp ) ‚àí ln(Œõt )(œàp,œÅp )
1X

 ,
T t=1 ln(Œõ )(œà ) + ln(Œõ
\
)(œà
)
/2
t
p,œÅp
t
p,œÅp

p = 1, . . . , P.

(19)

The most widely used methodology for model selection in ML is K‚Äìfold
validation approach. In our case, we have applied random K‚Äìfold validation.
We have computed the mean of the SMAPEs obtained at each one of the
13

K iterations of the random K‚Äìfold cross validation procedure implemented.
This validation technique consists of random splitting the functional sample
into a training and validation sample at each one of the K iterations. Model
fitting is performed from the training sample, and the target outputs are
defined from the validation or testing sample. In particular, we have selected
K = 5, 10, in the K‚Äìfold validation implemented. By running each model
ten times and averaging SMAPEs, we remove the fluctuations due to the
random initial weights (for MLP and BNN models), and the differences in
the parameter estimation in all methods, due to the random specification of
the sample splitting in the implementation of the random K‚Äìfold validation
procedure.
The ten‚Äìrunning based random K‚Äìfold validation SMAPEs are displayed
in Tables 2 (K = 5) and Table 3 (K = 10), for the six ML techniques tested,
GRNN, MLP, SVR, BNN, RBF, and GP, from data in the first category. The
ML model estimation results, based on the complete functional sample, are
also displayed in Table 11 in Appendix (see also Figures 3 and 4). In Table 12
in Appendix, one can also find the corresponding estimation results from the
projected data. (Note that, the same Spanish Community codes, as before,
are used in all the tables referred in this section, that is, C1 for Andalucƒ±ÃÅa;
C2 for AragoÃÅn; C3 for Asturias; C4 for Islas Baleares; C5 for Canarias; C6
for Cantabria; C7 for Castilla La Mancha; C8 for Castilla y LeoÃÅn; C9 for
CatalunÃÉa; C10 for Comunidad Valenciana; C11 for Extremadura; C12 for
Galicia; C13 for Comunidad de Madrid; C14 for Murcia; C15 for Navarra;
C16 for Pas Vasco, and C17 for La Rioja).
Tables 4 (K = 5) and Table 5 (K = 10) provide the ten‚Äìrunning based
random K‚Äìfold validation results, from the projected data category. The random K‚Äìfold validation results obtained after implementation of the Bayesian
and Classical semilinear approaches, as well as the estimation results based
on the global sample are displayed in Table 6. See also Figures 5 and 6,
where original and estimated COVID‚Äì19 mortality log‚Äìrisk and cumulative
cases curves are respectively shown.
In the previous selection of ML model hyperparameters, we have also applied random K‚Äìfold validation (K = 5, 10). Our selection has been made
from a suitable set of candidates. Specifically, the optimal numbers of hidden (NH) nodes in the implementation of MLP and BNN have been selected
from the candidate sets = [0, 1, 3, 5, 7, 9] and [1, 3, 5, 7, 9], respectively. The
cross‚Äìvalidation results in both cases, K = 5, 10, lead to the same choice
of the NH optimal value. Namely, NH= 1 for MLP, and NH= 5 for BNN.
The last one displays slight differences with respect to the values NH= 3, 7,
in the 10‚Äìfold cross‚Äìvalidation implementation. In the same way, we have
selected the spread and bandwidth parameters in the RBF and GRNN pro14

cedures. Thus, after applying random K‚Äìfold validation, with K = 5, 10,
the optimal values Œ≤ = 2.5, and h = 0.05 are obtained, from the candidate sets [2.5, 5, 7.5, 10, 12.5, 15, 17.5, 20] and [0.05, 0.1, 0.2, 0.3, 0.5, 0.6, 0.7],
respectively. As commented, in the first category, the best SVR performance
corresponds to the linear case, finding the hyperparameters that minimize
the five‚Äìfold cross‚Äìvalidation loss (by using automatic hyperparameter optimization from fitrsvm MatLab function). While, from the projected data
category, the best option corresponds to the Gaussian kernel based nonlinear
SVR model fitting (applying the same option of automatic hyperparameter
optimization, in the argument of fitrsvm MatLab function). In the implementation of GP we follow the same tuning procedure for model selection. In this
case, for both categories, we have opted by Bayesian cross-validation optimization (in the hyperparameter optimization argument of the fitrgp MatLab
function).
In all the results displayed, the SMAPE‚ÄìMEAN (M.) and SMAPE‚Äì
TOTAL (T.) have been computed as rank-based performance measures, for
comparing the ML models tested, and the presented Classical and Bayesian
semilinear estimation approaches.
Andaluc√≠a

Arag√≥n

Asturias

Islas Baleares
3.2

3.6

3.15

3.2

3.6

3.4

3.4

3.2

Cantabria

3.25

3.25

3.3

4
3.8

Canarias

3.25

3.8

3.1
3.1

3.2

3.2

3.15

3.15
3.1

3.1

3.05

3.05

3.05
20

40

60

20

Castilla La Mancha

40

60

20

Castilla y Le√≥n

40

60

Catalu√±a

20

40

60

60

3.8
3.6

3.4

3.4
3.2

3.6
3.2

3.5

40

Galicia

3.6

3.8

4

20

Extremadura

4

4.5

4

3.5

60

4.2
5

4

40

C. Valenciana

4.5

4.5

20

3

3.4
3.5

20

40

60

20

C. Madrid

40

60

20

Murcia

40

60

20

Navarra

60

20

Pa√≠s Vasco

3.6

5.5

40

40

60

5

3.2

3.6

3.1
4.5

3.3
3.2
3.1

3.4

3
20

40

60

60

Log-int. obs.
GRNN est.
MLP est.
SVR est.
BNN est.
RBF est.
GP est.

3.2
3.8

40

La Rioja
3.4

4

3.4

20

20

40

60

20

40

60

20

40

60

20

40

60

Figure 3: FIRST DATA CATEGORY. Observed and estimated COVID‚Äì19
mortality log‚Äìrisk curves, from the implementation of Generalized Regression Neural Network (GRNN), Multilayer Perceptron (MLP), Support Vector
Regression (SVR), Bayesian Neural Network (BNN), Radial Basis Function
Neural Network (RBF), and Gaussian Processes (GP)
15

Table 2: FIRST DATA CATEGORY. Average SMAPEs multiplied
by the factor 102 (10 running of random K‚Äìfold validation, K = 5)
SC GRNN
C1
0.1962
C2
0.6150
C3
0.1541
C4
0.0984
C5
0.2065
C6
0.1585
C7
0.4957
C8
0.0804
C9
0.7280
C10 0.2208
C11 0.1273
C12 0.5237
C13 0.3637
C14 0.1359
C15 0.6105
C16 0.2479
C17 0.0667
M.
0.2958
T.
5.0293

6

MLP
0.0845
0.1531
0.0479
0.0388
0.0555
0.0423
0.0786
0.0352
0.2170
0.0724
0.0618
0.1706
0.0717
0.0388
0.1705
0.0931
0.0414
0.0867
1.4731

SVR
0.0890
0.0711
0.0438
0.0190
0.0378
0.0227
0.0771
0.0226
0.1061
0.0751
0.0373
0.1441
0.0701
0.0307
0.1592
0.0926
0.0195
0.0657
1.1177

BNN
0.0709
0.0805
0.0338
0.0226
0.0414
0.0257
0.0707
0.0215
0.0866
0.0577
0.0460
0.1449
0.0671
0.0235
0.1228
0.0753
0.0255
0.0598
1.0166

RBF
0.0635
0.0782
0.0371
0.0214
0.0429
0.0266
0.0712
0.0247
0.0421
0.0541
0.0451
0.1126
0.0605
0.0220
0.1101
0.0665
0.0241
0.0531
0.9026

GP
0.0592
0.0710
0.0325
0.0226
0.0397
0.0263
0.0587
0.0189
0.0475
0.0494
0.0385
0.1065
0.0480
0.0213
0.1121
0.0632
0.0246
0.0494
0.8400

Concluding Remarks

Model empirical selection results hold in a broad‚Äìbased sense, as displayed
in Section 5.1. Specifically, these results have been tested for K = 5 and
K = 10 in the random K‚Äìfold validation, leading to almost the same model
ranking in the two categories. See Table 7 and Figure 7 for the first category, and Table 8 and Figure 8 for the second category. (In Table 8 and
Figure 8, C‚ÄìARH(1) and B‚ÄìARH(1) respectively denote the Classical and
Bayesian semilinear estimation). The random K‚Äìfold validation results displayed for the presented Classical and Bayesian semilinear approaches locate
these methodologies after SVR model. Thus, the fifth and sixth positions
are respectively occupied in that empirical ranking. In the first category,
RBF and GP are almost equal, while in the second category slightly larger
differences can be observed. On the other hand, the projected data category
favors the GRNN, RBF and GP performance, while better results are ob16

Andaluc√≠a

Arag√≥n

Asturias

1000

Islas Baleares

300

800
600

100
100

100

500

50

100
200
0
20

40

60

0

Castilla La Mancha

20

40

60

0
0

Castilla y Le√≥n

20

40

60

40

60

Extremadura

0

20

40

60

Galicia

600

800

300

600

200

400

200

400

1000

100

200

0
60

60

400

2000

40

40

1000

500

20

20

3000

1000

0

0
0

1200

4000
1000

20

C. Valenciana

5000
2000

0
0

Catalu√±a

1500

0

50

50

0
0

Cantabria
200
150

150

200

400

Canarias
150

200

0
0

C. Madrid

20

40

60

0

Murcia

20

40

60

0

Navarra

20

40

60

0
0

Pa√≠s Vasco

20

40

60

0

20

40

60

La Rioja

1400

8000
6000

300

1200

400
100

Cum. obs.
GRNN est.
MLP est.
SVR est.
BNN est.
RBF est.
GP est.

1000
200

800
4000

600

200

50

100

400

2000

200
0
0

20

40

60

0
0

20

40

60

0
0

20

40

60

0

20

40

60

0

20

40

60

Figure 4: FIRST DATA CATEGORY. Observed and estimated COVID‚Äì19
mortality cumulative cases curves from the implementation of Generalized
Regression Neural Network (GRNN), Multilayer Perceptron (MLP), Support
Vector Regression (SVR), Bayesian Neural Network (BNN), Radial Basis
Function Neural Network (RBF), and Gaussian Processes (GP)

17

Table 3: FIRST DATA CATEGORY. Average SMAPEs multiplied
by the factor 102 (10 running of random K‚Äìfold validation, K = 10)
SC GRNN
C1
0.1957
C2
0.6132
C3
0.1556
C4
0.0971
C5
0.2049
C6
0.1572
C7
0.4898
C8
0.0804
C9
0.7258
C10 0.2191
C11 0.1262
C12 0.5228
C13 0.3594
C14 0.1345
C15 0.6080
C16 0.2464
C17 0.0660
M.
0.2942
T.
5.0022

MLP
0.0777
0.1490
0.0473
0.0342
0.0457
0.0368
0.0698
0.0340
0.1976
0.0704
0.0530
0.1578
0.0647
0.0366
0.1523
0.0889
0.0370
0.0796
1.3528

SVR
0.0700
0.0663
0.0350
0.0135
0.0318
0.0177
0.0644
0.0171
0.0979
0.0556
0.0310
0.1341
0.0576
0.0209
0.1411
0.0709
0.0148
0.0553
0.9397

BNN
0.0594
0.0738
0.0303
0.0200
0.0370
0.0234
0.0590
0.0191
0.0812
0.0482
0.0395
0.1282
0.0579
0.0204
0.1141
0.0622
0.0222
0.0527
0.8959

RBF
0.0543
0.0680
0.0331
0.0182
0.0369
0.0233
0.0616
0.0211
0.0326
0.0471
0.0375
0.0940
0.0533
0.0194
0.0982
0.0568
0.0203
0.0456
0.7757

GP
0.0554
0.0654
0.0304
0.0211
0.0372
0.0247
0.0588
0.0177
0.0437
0.0463
0.0355
0.0993
0.0458
0.0207
0.1039
0.0594
0.0227
0.0463
0.7879

tained from the original data in the implementation of MLP, SVR and BNN.
Note that, the best models in the above rankings, RBF and GP, display a
better performance in the second category. Thus, we can conclude that the
FDA preprocessing produces a remarkable improvement, even in the communities, like, Navarra and Galicia, where the worst results are obtained with all
the ML models tested. Particularly, this improvement is more significative
at Murcia Community. In that sense, one can also observe that the spatial
component of the data also affects the performance of the ML models tested
through the two categories distinguished (e.g., the best performance overall
ML models tested is obtained at Islas Baleares, Castilla‚ÄìLeoÃÅn and La Rioja,
and the worst at Navarra and Galicia). Remark also the outperformance of
the Classical and Bayesian semilinear approaches at the Islas Baleares and
Murcia Communities.
Note also that, the rank-based performance measure applied only refers to
estimation accuracy, and other features of the probability distribution of the
18

Table 4: SECOND DATA CATEGORY. Average SMAPEs multiplied by the factor 102 (10 running of random K‚Äìfold, K = 5)
SC GRNN
C1
0.1569
C2
0.1836
C3
0.1029
C4
0.0433
C5
0.0609
C6
0.0259
C7
0.3783
C8
0.0774
C9
0.4968
C10 0.1710
C11 0.1556
C12 0.3759
C13 0.2894
C14 0.0375
C15 0.3646
C16 0.1792
C17 0.0900
M.
0.1876
T.
3.1893

MLP
0.0958
0.1835
0.1309
0.0299
0.0524
0.0239
0.2136
0.0467
0.2926
0.0935
0.0914
0.2235
0.1599
0.0250
0.2410
0.0828
0.0724
0.1211
2.0589

SVR
0.0695
0.0697
0.0474
0.0171
0.0282
0.0133
0.1018
0.0315
0.1458
0.0541
0.0456
0.1509
0.0903
0.0124
0.1378
0.0677
0.0216
0.0650
1.1047

BNN
0.0604
0.0880
0.0491
0.0181
0.0264
0.0148
0.0963
0.0320
0.1329
0.0489
0.0441
0.1396
0.0775
0.0153
0.1297
0.0578
0.0256
0.0622
1.0567

RBF
0.0240
0.0286
0.0273
0.0133
0.0153
0.0130
0.0309
0.0292
0.0254
0.0277
0.0221
0.0402
0.0259
0.0114
0.0334
0.0292
0.0129
0.0241
0.4100

GP
0.0337
0.0329
0.0284
0.0130
0.0159
0.0129
0.0439
0.0207
0.0417
0.0316
0.0247
0.0560
0.0368
0.0109
0.0573
0.0344
0.0144
0.0299
0.5090

estimators have not been investigated yet. Indeed, the presented approach
offers more stable, and robust estimations against the random selection of the
training and validation samples. Thus, an improved model ranking position
could be occupied by our approach if variability in that sense is penalized.
Another subject to be addressed in a near future is the optimal selection of
the test functions {œàp,œÅp , p = 1, . . . , P } involved in the formulation of the
generalized least-squares loss function (7), and in the COVID‚Äì19 mortality
risk assessment from equation (17). Our final goal would be to obtain an
optimal design, from a set of candidates, of the test function family, providing the spatial sample information required, for spatiotemporal ML, and
Classical and Bayesian semilinear forecasting, in a multivariate functional
data framework (see, e.g., [6] regarding optimal selection of time intervals,
or, instants, in the implementation of SVR from a multivariate functional
data set).

19

Table 5: SECOND DATA CATEGORY. Average SMAPEs multiplied by the factor 102 (from 10 running of random K‚Äìfold, K = 10)
SC GRNN
C1
0.1545
C2
0.1844
C3
0.1029
C4
0.0432
C5
0.0610
C6
0.0260
C7
0.3750
C8
0.0764
C9
0.4894
C10 0.1680
C11 0.1537
C12 0.3689
C13 0.2848
C14 0.0367
C15 0.3618
C16 0.1773
C17 0.0884
M.
0.1854
T.
3.1524

MLP
0.0983
0.1730
0.1192
0.0286
0.0476
0.0217
0.2026
0.0482
0.3198
0.0815
0.0839
0.2558
0.1582
0.0226
0.2264
0.0835
0.0623
0.1196
2.0333

SVR
0.0666
0.0660
0.0481
0.0165
0.0258
0.0133
0.1095
0.0305
0.1753
0.0521
0.0436
0.1505
0.0968
0.0120
0.1201
0.0651
0.0210
0.0655
1.1129

BNN
0.0573
0.0749
0.0452
0.0158
0.0248
0.0140
0.0924
0.0300
0.1212
0.0462
0.0397
0.1249
0.0792
0.0143
0.1227
0.0545
0.0231
0.0577
0.9801

RBF
0.0234
0.0277
0.0273
0.0124
0.0144
0.0124
0.0307
0.0262
0.0229
0.0252
0.0199
0.0401
0.0240
0.0106
0.0317
0.0264
0.0125
0.0228
0.3877

GP
0.0312
0.0301
0.0274
0.0123
0.0149
0.0125
0.0399
0.0187
0.0372
0.0290
0.0219
0.0490
0.0320
0.0104
0.0522
0.0318
0.0136
0.0273
0.4642

Acknowledgements
This work has been supported in part by project PGC2018-099549-B-I00 of
the Ministerio de Ciencia, InnovacioÃÅn y Universidades, Spain (co-funded with
FEDER funds).
We also thank Unidad de Transferencia del IMUS, and the organizer,
Professor Emilio Carrizosa, by the seminar MatemaÃÅticas y la COVID, that
constitutes the germinating seed in the development of the present work.

20

Table 6: SECOND DATA CATEGORY. Average SMAPEs multiplied by the factor 102 (10 running of random K‚Äìfold, K = 5, 10)
SC
C1
C2
C3
C4
C5
C6
C7
C8
C9
C10
C11
C12
C13
C14
C15
C16
C17
M.
T.

B. k5
0.0781
0.1227
0.0797
0.0221
0.0302
0.0146
0.1966
0.0524
0.3947
0.0512
0.0637
0.2389
0.1591
0.0155
0.1624
0.0666
0.0323
0.1047
1.7807

C. k5 B. k10
0.0645 0.0750
0.0952 0.1188
0.0598 0.0767
0.0145 0.0209
0.0243 0.0291
0.0125 0.0142
0.1089 0.1850
0.0349 0.0494
0.2228 0.3709
0.0364 0.0490
0.0346 0.0600
0.1883 0.2317
0.0938 0.1488
0.0133 0.0150
0.1279 0.1555
0.0482 0.0638
0.0203 0.0304
0.0706 0.0997
1.2002 1.6942

C. k10
0.0623
0.0944
0.0595
0.0145
0.0234
0.0123
0.1075
0.0346
0.2236
0.0348
0.0337
0.1866
0.0896
0.0131
0.1232
0.0460
0.0202
0.0694
1.1792

B. est. C. est.
0.0726 0.0611
0.1152 0.0940
0.0736 0.0591
0.0197 0.0144
0.0282 0.0227
0.0138 0.0120
0.1736 0.1065
0.0465 0.0347
0.3479 0.2257
0.0470 0.0335
0.0565 0.0330
0.2231 0.1866
0.1388 0.0840
0.0146 0.0127
0.1504 0.1204
0.0612 0.0441
0.0287 0.0201
0.0948 0.0685
1.6115 1.1647

Table 7: MODEL RANKING FOR THE FIRST CATEGORY (10FOLD CV)

O.D.C. T.‚Äì10‚Äìfold‚ÄìSMAPE
RBF
0.7757(10‚àí2 )
GP
0.7879(10‚àí2 )
BNN
0.8959(10‚àí2 )
SVR
0.9397(10‚àí2 )
MLP
1.3528(10‚àí2 )
GRNN
5.0022(10‚àí2 )

Appendix
Bayesian and Classical estimation of the autocovariance operator of 21
the innovations defining
the mortality residual log‚Äìrisk process
In the Bayesian componentwise estimation of the autocovariance operator
of the residual log‚Äìrisk innovation process, ŒΩt , we can apply the approach

Andaluc√≠a

Arag√≥n

Asturias

Islas Baleares

3.3
3.6

3.8

3.2
3.6

3.4

3.4

3.2

Canarias
3.25

3.2

3.2

3.2

3.15

3.15

3.15

3.1
3.1

Cantabria

3.25

3.25

3.8
4

3.1

3.1

3.05

3.05

3.05
20

40

60

20

Castilla La Mancha

40

60

20

Castilla y Le√≥n

40

60

40

60

20

C. Valenciana

4.5

4.5

20

Catalu√±a

40

60

4.2

4

3.8

4

3.6

3.5

3.4

3.4

3.2
3.2

3.5

60

3.6

4
4.5

40

Galicia

3.6

5
4

20

Extremadura

3

3.4
3.5

20

40

60

20

C. Madrid

40

60

20

Murcia

40

60

20

Navarra
3.6

5.5

40

60

20

Pa√≠s Vasco

40

60

3.4

4

5

3.8

3.2

3.6

3.3
3.2

3.1
4.5

3.1
3.4

3
20

40

60

20

40

60

20

40

60

20

40

40

60

Log-int. obs.
GRNN est.
MLP est.
SVR est.
BNN est.
RBF est.
GP est.
B. est.
C. est.

3.2
3.4

20

La Rioja

60

20

40

60

Figure 5: SECOND DATA CATEGORY. Observed and estimated COVID‚Äì
19 mortality log‚Äìrisk curves, from the implementation of Generalized Regression Neural Network (GRNN), Multilayer Perceptron (MLP), Support
Vector Regression (SVR), Bayesian Neural Network (BNN), Radial Basis
Function Neural Network (RBF), Gaussian Processes (GP), and Classical
and Bayesian semilinear estimation
Table 8: MODEL RANKING FOR THE SECOND CATEGORY
(10-FOLD CV)

P.D.C.
RBF
GP
BNN
SVR
C‚ÄìARH(1)
B‚ÄìARH(1)
MLP
GRNN

T.‚Äì10‚Äìfold‚ÄìSMAPE
0.3877(10‚àí2 )
0.4642(10‚àí2 )
0.9801(10‚àí2 )
1.1129(10‚àí2 )
1.1792(10‚àí2 )
1.6942(10‚àí2 )
2.0333(10‚àí2 )
3.1524(10‚àí2 )

22

Andaluc√≠a

Arag√≥n

Asturias

1000

Islas Baleares

300

800
600
400

100
100

100

500

50

100
200
0
20

40

60

0

Castilla La Mancha

20

40

60

0
0

Castilla y Le√≥n

20

40

60

20

40

60

Extremadura

0

20

40

60

Galicia

600

800

300

600

200

400

200

400

1000

100

200

0
60

60

1000

2000

40

40

400

500

20

20

3000

1000

0

0
0

1200

4000
1000

0

C. Valenciana

5000
2000

0

Catalu√±a

1500

0

50

50

0
0

Cantabria
200
150

150

200

Canarias
150

200

0
0

C. Madrid

20

40

60

0

Murcia

20

40

60

0

Navarra

20

40

60

0
0

20

Pa√≠s Vasco

40

60

0

20

40

60

La Rioja

1400

8000
100

6000

300

1200

400

Cum. obs.
GRNN est.
MLP est.
SVR est.
BNN est.
RBF est.
GP est.
B. est.
C. est.

1000
200

800
4000

600

200

50

100

400

2000

200
0
0

20

40

60

0
0

20

40

60

0
0

20

40

60

0

20

40

60

0

20

40

60

Figure 6: SECOND DATA CATEGORY. Observed and estimated COVID‚Äì
19 mortality cumulative cases curves, from the implementation of Generalized
Regression Neural Network (GRNN), Multilayer Perceptron (MLP), Support
Vector Regression (SVR), Bayesian Neural Network (BNN), Radial Basis
Function Neural Network (RBF), Gaussian Processes (GP), and Classical
and Bayesian semilinear estimation
1
presented in [9]. Specifically, for each k ‚â• 1, consider œÑk = 2Œªk (R
ŒΩ , with
0)
ŒΩ
ŒΩ
Œªk (R0 ) being the kth eigenvalue of R0 = E[ŒΩt ‚äó ŒΩt ] = E[ŒΩ0 ‚äó ŒΩ0 ], for every
t = 1, . . . , T, T ‚â• 2. When the eigenvectors {œÜk,ŒΩ , k ‚â• 1} of R0ŒΩ are known,
we define the loss function, given by the likelihood, as
!
T
X
T /2
L(Œµ1k , . . . , ŒµT k , œÑk ) = CœÑk exp ‚àíœÑk
[Œµt (œÜk,ŒΩ ) ‚àí œÅ(Œµt‚àí1 )(œÜk,ŒΩ )]2

=

T /2
CœÑk

exp ‚àíœÑk

i=1
T
X

!
2

[ŒΩt (œÜk,ŒΩ )]

, k ‚â• 1,

(20)

i=1

where {ŒΩt (œÜk,ŒΩ ), t = 1, . . . , T } are independent and identically distributed
zero‚Äìmean Gaussian random variables with variance 2œÑ1k , and Œµtk = Œµt (œÜk,ŒΩ ) =
hŒµt , œÜk,ŒΩ iH , for each k ‚â• 1.
1
In equation (20), as conjugate prior for parameter œÑk = 2Œªk (R
ŒΩ , let us
0)
consider œÑk ‚àº Œì (ghk , Œ≤
i k ) (with Œ≤k denoting the rate parameter), for gk > 2,
k
. For k ‚â• 1, the posterior density of œÑk , given
k ‚â• 1. Hence, E œÑ1k = gkŒ≤‚àí1
23

0.05

5-fold original data
10-fold original data
5-fold projected data
10-fold projected data

0.045
0.04
0.035
0.03
0.025
0.02
0.015
0.01
0.005
0
RBF

GP

BNN

SVR

MLP

GRNN

Figure 7: ML MODEL RANKING. T.‚Äì10‚Äìfold‚ÄìSMAPE in green line for
the first category (O.D.C. category), and red line for the second category
(P.D.C category), and T.‚Äì5‚Äìfold‚ÄìSMAPE in black line for the first category
(O.D.C category), and blue line for the second category (P.D.C category)

5-fold projected data
10-fold projected data

0.03

0.025

0.02

0.015

0.01

0.005

0
RBF

GP

BNN

SVR

C.ARH B.ARH

MLP

GRNN

Figure 8: JOINT MODEL RANKING. T.‚Äì10‚Äìfold‚ÄìSMAPE (red line)
and T.‚Äì5‚Äìfold‚ÄìSMAPE (blue line) in the second category (P.D.C category)

24

xik = ŒΩi (œÜk,ŒΩ ), i = 1, . . . , T, is
!
T
X
T /2+gk ‚àí1
C
x2ik œÑk
exp ‚àíœÑk
i=1

Œ≤k +

T
X

!!
x2ik

.

i=1

That is, the posterior
is a Gamma probability distribution with parameters

PT 2 
T /2 + gk and Œ≤k + i=1 xik .
For the loss function defined in terms of the squared error, the Bayes
ŒΩ
estimator
k (R0 ) = 1/œÑk is the posterior expectation of 1/œÑk , given by
PT of 2Œª
(Œ≤k + i=1 x2ik )/(T /2 + gk ‚àí 1), for each k ‚â• 1. Thus, the Bayes estimator
ekT (RŒΩ ) of Œªk (RŒΩ ) = 1/2œÑk is
Œª
0
0
PT 2
Œ≤
+
k
ŒΩ
i=1 xik
ekT (R ) =
Œª
, k‚â•1
(21)
0
T + 2gk ‚àí 2
(see [29], p.236). Hence, from (21), the Bayesian componentwise estimator
of R0ŒΩ is computed as follows:
ŒΩ
g
R
0,T =

‚àû
X

ekT (RŒΩ )[œÜk,ŒΩ ‚äó œÜk,ŒΩ ].
Œª
0

(22)

k=1

In the classical approach, an unbiased estimator of Œªk (R0ŒΩ ) is obtained
from the identity
ŒªkT (R0ŒΩ ) =

T
T
1X 2
1X
xik =
[ŒΩi (œÜk,ŒΩ )]2 ,
T i=1
T i=1

k ‚â• 1.

(23)

Thus, the classical componentwise estimator of R0ŒΩ is defined as
ŒΩ
R0,T

=

‚àû
X

ŒªkT (R0ŒΩ ) [œÜk,ŒΩ ‚äó œÜk,ŒΩ ].

(24)

k=1

In practice, in the computation of equations (22) and (24), when the
eigenvectors {œÜk,ŒΩ , k ‚â• 1} are unknown, one can consider their consistent
approximation in terms of the empirical eigenvectors {œÜk,T,ŒΩ , k ‚â• 1}, under the conditions assumed in Corollary 4.1, Lemma 4.3, and Theorem 4.8
in [8]. Indeed, under the conditions in Theorem 1 of [18], and the referred setting of conditions in [8], for each k ‚â• 1, Yt (œÜk,ŒΩ ) ‚àí œÅb(Yt‚àí1 )(œÜk,ŒΩ )
and Yt (œÜk,T,ŒΩ ) ‚àí œÅb(Yt‚àí1 )(œÜk,T,ŒΩ ), consistently approximate xtk = ŒΩt (œÜk,ŒΩ ), for
t = 1, . . . , T, in the computation of equations (21) and (23), for the cases
where the eigenvectors {œÜk,ŒΩ , k ‚â• 1} are known and unknown, respectively.
25

Note also that, under the conditions assumed in [9], in particular, when,
k
‚â§ Œªk (R0ŒΩ ), we obtain the following equivalent
for every k ‚â• 1, 2(gk Œ≤‚àí1)+1
asymptotic behavior in the Hilbert‚ÄìSchmidt operator norm k ¬∑ kS(H) , for both
estimation approaches:
ŒΩ
ŒΩ
g
lim T E R
0,T ‚àí R0

T ‚Üí‚àû

2

ŒΩ

S(H)

= lim T EkR0,T ‚àí R0ŒΩ k2S(H) = 2
T ‚Üí‚àû

‚àû
X

[Œªk (R0ŒΩ )]2 .

k=1

In the practical implementation of the Bayesian componentwise estimator
(22) in Sections 4‚Äì5, we have considered the prior probability

 distribution
ŒΩ
b
œÑk ‚àº Œì (gk , Œ≤k ) with gk = 6, and Œ≤k = (2gk ‚àí 1)ŒªK(T ),T R0,T /10 for each


ŒΩ
b
k ‚â• 1, where ŒªK(T ),T R0,T denotes the K(T )th empirical eigenvalue of
the autocovariance operator of the innovation process defining the residual
log‚Äìrisk process, and K(T ) represents the truncation parameter value (see
[9]).

Additional Outputs in the Spatiotemporal Log‚ÄìGaussian
Analysis of COVID‚Äì19 Mortality Risk
The original COVID‚Äì19 mortality cumulative cases curves, and its interpolation and B‚Äìspline smoothing are shown in Figure 9. The corresponding
COVID‚Äì19 mortality risk curves are also displayed in Figure 10.
Andaluc√≠a

1500

Arag√≥n

1000

200

500

0
0

20

40

60

Castilla La Mancha

20

40

60

Castilla y Le√≥n

2000
1500

4000

1000

2000

500

20

40

60

C. Madrid

10000

0
-5000
0

20

40

60

60

20

40

60

Murcia

400
200

0

0

-50

-200
0

20

40

60

40

60

C. Valenciana

1500

-100
0

20

40

60

Extremadura

600

60

40

60

Galicia

0

0
40

Navarra

20

500

200

20

0
1000

400

500

600

50

0

-100
20

1000

0

100

100

0

-2000
0

150

5000

40

0

0
0

20

Catalu√±a

6000

1000

-1000

200

0

-100
0

Cantabria

300

100

0

-200
0

2000

0

Canarias

200

100
0

0
-500

Islas Baleares

300

200

500

3000

Asturias

400

1000

0

-200
0

20

40

60

Pa√≠s Vasco

1500

0

20

40

60

400

20

40

60

Obs.
S. B-sp

300

1000

0

La Rioja

200
500

100
0

0
0

20

40

60

0

20

40

60

0

20

40

60

Figure 9: Observed, and Interpolated and cubic B‚Äìspline smoothed COVID‚Äì
19 mortality cumulative cases curves at the 17 Spanish Autonomous Communities, since March, 8 to May, 13, 2020

26

60

Andaluc√≠a

Arag√≥n

30

40

20

20

10

Asturias

10

8

5

0

80

40

60

Castilla La Mancha

80

40

60

Castilla y Le√≥n

60

150

40

40

100

20

20

50

0

0
20

40

60

C. Madrid

300

100
0
20

40

60

60

4

60

40

60

Murcia

15

4

10

2

5

0

0
20

40

60

60

C. Valenciana

60

Navarra

60

Extremadura

40

15

20

10

10

60

Pa√≠s Vasco

20

40

60

Galicia

30

0

0
20

60

40

5

0
40

0
20

20

20

20

6

40

40

20

2

0
20

0
20

8

200

40

Catalu√±a

200

60

6

2

0
20

Cantabria

8

4

4

0
20

Canarias

6

2

0
20

Islas Baleares

6

-10
20

40

60

20

40

60

La Rioja

15

S. B-sp

40

10

20

5

0
20

40

60

0
20

40

60

20

40

60

Figure 10: Observed COVID‚Äì19 mortality risk curves at the 17 Spanish
Autonomous Communities, since March, 8 to May, 13, 2020

The least‚Äìsquares parameter estimates computed in the spatial heterogeneous nonlinear parametric trend model fitting are shown in Tables 9‚Äì10.
Finally, the COVID‚Äì19 mortality log‚Äìrisk estimations, based on spatial
heterogeneous linear and nonlinear trend model fitting, are compared in Figure 11, under a Classical (C) and Bayesina (B) approximation of the functional residuals, considering the truncation parameter value K(265) = 9.

A Brief Introduction to our FDA Implementation of ML models
The implemented ML models are introduced here. Their reformulation in
the multivariate FDA framework adopted is also provided.
Multilayer Perceptron (MLP)
MLP shares the philosophy of nonlinear regression, in terms of a link function g, the hidden node output, defining the following approximation of the
response:
NH
X
b = Œ∑0 +
y
(25)
Œ∑k g(Œ≤kT x),
k=1

27

Table 9: NONLINEAR TREND MODEL FITTING. Parameter estimates
bk (¬∑), k = 1, . . . , 6, at the 17 Spanish Communities
A
SC/AE
C1
C2
C3
C4
C5
C6
C7
C8
C9
C10
C11
C12
C13
C14
C15
C16
C17

b1 (¬∑)
A
3.6343
3.4345
3.2031
3.1445
3.1015
3.1347
4.0591
3.8032
4.5095
3.6321
3.2967
3.3454
4.8419
3.0941
3.2877
3.6870
3.2197

b2 (¬∑)
A
-0.4814
-0.3923
-0.1364
-0.1118
-0.0693
-0.1397
-0.5487
-0.5500
-0.7435
-0.4685
-0.2274
-0.2122
-0.6790
-0.1037
-0.2598
-0.4302
-0.2071

b3 (¬∑)
b4 (¬∑)
b5 (¬∑)
b6 (¬∑)
A
A
A
A
-0.0075 -0.0258 0.0189 0.0193
0.0416 0.0265 -0.0709 -0.0572
-0.0088 0.0221 0.0430 0.0289
0.0041 0.0337 0.0062 0.0072
-0.0345 0.0352 -0.0112 0.0003
0.0020 0.0300 -0.0061 -0.0002
-0.0907 0.0951 0.0992 0.0842
-0.1007 0.0633 0.0139 0.0277
-0.1134 0.1809 0.2231 0.2026
-0.0540 0.0384 -0.0152 0.0011
-0.0083 0.0553 0.0250 0.0240
-0.0927 -0.0330 0.0724 0.0679
-0.2455 0.0311 0.0554 0.0667
0.0210 0.0141 -0.0016 0.0041
-0.0524 0.0842 -0.0423 -0.0348
-0.0086 0.0078 -0.0027 -0.0017
0.0162 0.0079 0.0206 0.0110

from the input vector xT = (1, x) augmented with 1, and the weight vector Œ≤k associated with the kth hidden node, k = 1, . . . , N H, defining Œ≤ =
(Œ≤1 , . . . , Œ≤N H )T . The hidden node outputs are also weighted by the compob is usually referred as the network
nents of (Œ∑0 , . . . , Œ∑N H ). In this context, y
output. MLP allows the approximation of any given continuous function
on a compact set as close as arbitrarily, from a given network with a finite
number of hidden nodes. Optimization algorithms are applied to obtain the
weights from the least‚Äìsquares loss function. In our implementation of MLP,
in an FDA framework, the input vector is defined by

xT = 1D (¬∑), ln (Œªt ) (œÜ1 ), . . . , ln (Œªt ) (œÜK(T ) ), . . . , ln (Œªt‚àíp ) (œÜK(T ) ) ,
with 1D (¬∑) denoting the indicator function of the domain D ‚äÇ R2 , the
spatial support of the functions in H. Here, ln(Œªt‚àíj )(œÜl ), l = 1, . . . , K(T ),
j = 0, . . . , p, denote the observed projected log‚Äìrisk values, onto the autocovariance operator eigenvectors œÜ1 , . . . , œÜK(T ) , at times t, . . . , t ‚àí p. Parameter K(T ) denotes the truncation achieved in our finite‚Äìdimensional approximation, and T the number of temporal nodes, or training data points. In
28

Table 10: NONLINEAR TREND MODEL FITTING. Parameter estimates
bk (¬∑), k = 1, . . . , 6, at the 17 Spanish Communities
B
SC/BE B1
C1
0
C2
0
C3
0
C4
0
C5
0
C6
0
C7
0
C8
0
C9
0
C10
0
C11
0
C12
0
C13
0
C14
0
C15
0
C16
0
C17
0

B2
-0.0052
-0.0367
-0.0531
-0.0074
0.0433
0.0018
-0.0365
0.0953
-0.1587
0.1118
0.0754
-0.1104
0.4654
0.0355
-0.0187
0.0025
0.0389

B3
-0.1330
-0.0998
-0.0074
-0.0284
-0.0438
-0.0174
-0.2451
-0.2389
-0.4054
-0.1579
-0.1138
-0.1338
-0.1302
-0.0560
-0.0021
-0.0707
-0.0270

B4
-0.0123
-0.0462
-0.0142
-0.0151
-0.0116
-0.0068
-0.1791
-0.0431
-0.2269
-0.0458
-0.0166
0.1330
-0.1602
0.0119
-0.0897
-0.0638
-0.0174

B5
0.0064
-0.0343
-0.0003
-0.0092
-0.0118
-0.0089
-0.0820
-0.0313
-0.1010
-0.0418
-0.0048
0.0761
-0.1061
0.0025
-0.0562
-0.0439
-0.0006

B6
-0.0195
-0.0107
0.0020
0.0012
0.0046
0.0000
0.0026
-0.0045
0.0047
-0.0220
0.0072
-0.0017
-0.0038
-0.0044
0.0134
-0.0267
0.0019

practice, the theoretical eigenvectors are usually replaced by the empirical
eigenvectors. Parameter p + 1 provides the number of temporal lags incorporated in the prediction. In our case, since we have considered one-step-ahead
forecasting, p = 1, the response

yt+1 = ln (Œªt+1 ) (œÜ1 ), . . . , ln (Œªt+1 ) (œÜK(T ) )
(26)
at time t + 1, is approximated from the input vector

ln (Œªt ) (œÜ1 ), . . . , ln (Œªt ) (œÜK(T ) ) .

(27)

Hence, equation (25) can be rewritten as
bt+1 = Œ∑0 +
y

NH
X

Œ∑k g (hŒ≤k , xiH ) , Œ≤k , x ‚àà H, k = 1, . . . , N H.

k=1

Usually, the logistic function g(u) =

1
1+exp(‚àíu)

29

is considered.

(28)

4.5

Andaluc√≠a

Arag√≥n

4

3.3

3.3

4
3.5

3.1

3

3
20

40

60

Castilla La Mancha

5
4.5

4

4

3.5

3.5

3

40

60

Castilla y Le√≥n

40

60

C. Madrid

6

3.1

3.1

60

3
20

4.5

40

60

C. Valenciana

3
20

3.8

40

60

Extremadura

20

40

60

Galicia

4

3.6

4

4

3.5

3
20

40

60

3.5

Murcia

5

3.1

3.4

3

3.2

2.9

60

Navarra

3.8

4.5

40

40

60

40

60

Pa√≠s Vasco

3.4

3.5

3.2

40

60

40

60

20

40

60

La Rioja

3.6

3
20

2.5
20

4

3
20

3
20

4.5

3

3.2

3
20

3.6

60

40

Catalu√±a

6

3.2

40

3.1

3
20

5.5

20

3.2

3.4

3.3

4

Cantabria

3.3

3.2

5

3
20

Canarias

3.3

3.2

3
20

4.5

Islas Baleares

3.2

3.5

5

Asturias

3.4

Log-int. obs.
B. NL. est.
C. NL. est.
B. L. est.
C. L. est.

3
20

40

60

20

40

60

Figure 11: Observed and estimated COVID‚Äì19 mortality log‚Äìrisk curves, at
the 17 Spanish Communities, since March, 8 to May, 13, 2020, under a spatial
heterogeneous linear and nonlinear trend model fitting, applying a classical
(C) and Bayesian (B) componentwise estimation of the residual correlation,
under the truncation parameter value K(T ) = 9
Radial Basis Function Neural Network (RBF)
RBF works with node functions, depending on a center and scale parameters,
fitting the local smoothness of the response. Specifically, from an initial
blank network, the nodes are sequentially added, around the training pattern,
until an acceptable error is reached. All the output layer weights are then
recomputed using the least squares formula. Gaussian functions have been
widely selected as node functions. Equation (27) defines the input vector in
our implementation of RFB in an infinite‚Äìdimensional setting given by the
formula


NH
X
kx ‚àí cj k2H
,
(29)
y=
Œ∑j exp
œÅ2
j=1
where, as usual, the weight parameters Œ∑j , j = 1, . . . , N H, define the linear
combination of radial basis functions. Here, the scale parameter œÅ, and the
functional location parameters cj ‚àà H, j = 1, . . . , N H, respectively provide
the width, and the functional center of the node functions. In practice,
a K(T )‚Äìdimensional implementation is considered based on the truncation
parameter K(T ), as given in (27).
30

Support Vector Regression (SVR)
SVR implementation involves a loss function leading to a balance between
model complexity and precision (accurate prediction). A bias parameter b is
also considered in its formulation as reflected in the following equation:
y = f (x) = Œ≤ T x + b,

(30)

M
X
1
2
L = kŒ≤k + C
|ym ‚àí f (xm )| ,
2
m=1

(31)

where the loss function

is considered. Here, xm and ym respectively denote the mth training input
vector and the target output, for m = 1, . . . , M, and
|ym ‚àí f (xm )| = max {0, |ym ‚àí f (xm )| ‚àí } .
Thus, the errors below  are not penalized. The solution to the optimization
problem associated with the loss function (31) is given by
?
f (x) = (Œ±m
‚àí Œ±m )xT x + b,

(32)

?
where Œ±m
and Œ±m are Lagrange multipliers. The support vectors are the
training vectors giving nonzero Lagrange multipliers. A nonlinear version is
obtained when the inner product xT x in (32) is replaced by K(xT x), with K
being a kernel. A usual kernel choice is the Gaussian kernel.
In our implementation of this methodology in an FDA framework from
equations (26)‚Äì(27), we will consider

f (x) = hŒ≤, xiH + b,
T

Œ≤, b, x ‚àà H,
K(T )

XX
1
|ln (Œªt+1 ) (œÜl ) ‚àí f (ln (Œªt ) (œÜl ))|l ,
L = kŒ≤k2H + C
2
t=1 l=1

(33)

where T denotes, as before, the number of temporal nodes, and for l ‚â• 1,
|ln (Œªt+1 ) (œÜl ) ‚àí f (ln (Œªt ) (œÜl ))|l
= max {0, |ln (Œªt+1 ) (œÜl ) ‚àí f (ln (Œªt ) (œÜl ))| ‚àí l } .

(34)

Bayesian Neural Network (BNN)
The design of BNN involves Bayesian estimation, and the concept of regularization. The network parameters or weights are considered random variables,
31

following a prior probability distribution. Smooth fits are usually favored in
the selection of the prior probability of the weights to reduce model complexity. The posterior probability distribution of the weights is obtained after
data are observed. The network prediction is then computed. Specifically,
the optimal prediction is obtained by minimizing the following expression:
J = ŒΩEO + (1 ‚àí ŒΩ)EW ,

(35)

where EO is the sum of the square errors in the network output, based
on the posterior distribution of the parameters, EW represents the sum of
the squares of the weights or the network parameters, and ŒΩ ‚àà (0, 1) denotes the regularization parameter. Let L be the number of parameters. An
L‚Äìdimensional Gaussian prior probability distribution is usually assumed
for the network parameters with zero‚Äìmean and variance‚Äìcovariance matrix
1
I
, with IL√óL denoting the L √ó L identity matrix. Thus,
2(1‚àíŒΩ) L√óL


1‚àíŒΩ
p(w) =
œÄ

L/2
exp (‚àí(1 ‚àí ŒΩ)EW (w)) .

(36)

This prior puts more weight onto small network parameter values close to
zero. The posterior probability density, given the observed data O = o, and
the value ŒΩ of the regularization parameter, is defined as
p(w/o, ŒΩ) =

p(o/w, ŒΩ)p(w/ŒΩ)
.
p(o/ŒΩ)

(37)

Considering that the errors are also Gaussian distributed the conditional
probability of the data O given the parameters ŒΩ and w, is obtained as
 ŒΩ M/2
p(o/w, ŒΩ) =
exp (‚àíŒΩEO (o)) ,
(38)
œÄ
where M denotes the number of training data points. From equations (36)‚Äì
(38),
p(w/o, ŒΩ) = c exp (‚àíJ(w, o, ŒΩ)) ,
(39)
where c denotes the normalizing constant. The conditional probability of
the parameter ŒΩ given de observed data O = o is also computed under a
Bayesian framework as
p(ŒΩ/o) =

P (o/ŒΩ)p(ŒΩ)
.
p(o)

(40)

Equations (39) and (40) are maximized to obtain the optimal weights and
the regularization parameter ŒΩ, respectively.
32

In our FDA implementation from (26)‚Äì(27), the corresponding optimization problem is formulated by conditioning to the projected data. Note that,
in the selected Gaussian prior probability framework, the error projections
are also Gaussian, and our choice of the function basis, diagonalizing the
empirical autocovariance operator of the errors, leads to a projected error
vector with independent Gaussian components, which is also normalized, in
terms of the empirical eigenvalues as described in the preprocessing procedure in Section 5.1. Hence, optimization from equations (39) and (40) can
be implemented in a similar way.
Generalized Regression Neural Network (GRNN)
GRNN is based on kernel regression. The kernel estimator is computed from
the weighted sum of the observed responses, or target outputs associated
with the training data points in a neighborhood of the objective data point x,
where prediction must be computed. The training data points are selected in
the vicinity of the given objective point x. Specifically, the following formula
is applied in the approximation of the response value at the point x :


kx‚àíxj k
M
K
X
h

 yj ,
(41)
yb(x) =
PM
kx‚àíxj k
K
j=1
l=1
h
where yj is the target output for training data point xj , for j = 1, . . . , M, and
K is the kernel function. Usually an isotropic rapidly decreasing kernel
func‚àö
2
tion is considered, e.g., the Gaussian kernel K(u) = exp (‚àíu /2) / 2œÄ constitutes a common choice. The bandwidth parameter h defines the smoothness
of the fit. Thus, h controls the size of the smoothing region. Hence, large values of h correspond to a stronger smoothing than the smallest values allowing
a larger degree of local variation. Our FDA formulation, from (26)‚Äì(27), follows straightforward by considering the H‚Äìnorm k ¬∑ kH in (41), instead of the
Euclidean norm k ¬∑ k.
Gaussian Processes (GP)
A good performance is usually observed in the implementation of GP regression, based on the multivariate normal probability distribution assumption,
characterizing the observed responses at the different training data points.
Specifically, we consider the observation model
Y = Z + ,

33

(42)

where the additive noise vector  has independent components. A multivariate normal distribution of the random vector Z ‚àº N (0, Œ£), with covariance
matrix Œ£Z is assumed. This matrix provides the variances and covariances
between the output vector components in the training set. Applying Bayes
rule we obtain the solution to the inverse problem (42). Thus, the estimation
of Z, for a given input vector x? , is obtained as


b x? = E [Z/Y = x? ] = Œ£Y,Z Œ£Z + œÉ 2 I ‚àí1 Y.
Z
(43)

Here, we consider an alternative multivariate FDA interpretation, in
terms of a training test function set (instead of a training data point set,
based on temporal nodes). Hence, Œ£Z is replaced by the matrix autocovariance operator RZ of the output, and Œ£Y,Z is replaced by the matrix
cross-covariance operator RY,Z , both evaluated at the training test function
set. In this case, œÉ2 denotes the functional variance or trace of the autocovariance operator, characterizing the Gaussian infinite‚Äìdimensional distribution
of the H‚Äìvalued independent components of the zero‚Äìmean observation noise
vector . Hence, the identity matrix I is replaced by the identity operator
IHP on HP , with P denoting the number of training test functions. That is,
h
i


b? = E Z
b ? /Y = x? = RY,Z RZ + œÉ 2 IHP ‚àí1 Y.
Z
(44)


ML Estimation Results in the Two Categories
The estimation results obtained from the implementation of the above ML
models in the first category are displayed in Table 11. The SMAPEs from
the projected data are shown in Table 12.

References
[1] O. O. Aalen, O. Borgan and H. K. Gjessing (2008). Survival and event
history analysis: a process point of view. Springer Science & Business
Media, New‚ÄìYork.
[2] C. Abboud, O. Bonnefon, E. Parent and S. Soubeyrand (2019). Dating and localizing an invasion from post-introduction data and a coupled reaction‚Äìdiffusion‚Äìabsorption model. Journal of Mathematical Biology 79, 765‚Äì789.
[3] E. Alpaydin (2004). Introduction to Machine Learning. MIT Press, Cambridge, MA.
34

Table 11: FIRST CATEGORY. SMAPEs multiplied by factor 102 .
AC GRNN
C1
0.1964
C2
0.6117
C3
0.1565
C4
0.0969
C5
0.2044
C6
0.1571
C7
0.4889
C8
0.0808
C9
0.7231
C10 0.2185
C11 0.1255
C12 0.5216
C13 0.3584
C14 0.1342
C15 0.6064
C16 0.2456
C17 0.0655
M.
0.2936
T.
4.9916

MLP
0.0611
0.1172
0.0375
0.0314
0.0427
0.0319
0.0545
0.0273
0.1976
0.0526
0.0487
0.1666
0.0592
0.0286
0.1470
0.0681
0.0356
0.0710
1.2078

SVR
0.0665
0.0588
0.0328
0.0129
0.0290
0.0161
0.0619
0.0161
0.0850
0.0532
0.0298
0.1210
0.0548
0.0201
0.1307
0.0674
0.0147
0.0512
0.8707

BNN
0.0535
0.0678
0.0284
0.0191
0.0356
0.0230
0.0583
0.0180
0.1102
0.0446
0.0350
0.1022
0.0613
0.0202
0.0931
0.0573
0.0207
0.0499
0.8480

RBF
0.0483
0.0609
0.0300
0.0167
0.0334
0.0217
0.0569
0.0189
0.0318
0.0428
0.0338
0.0870
0.0490
0.0182
0.0864
0.0514
0.0181
0.0415
0.7053

GP
0.0490
0.0567
0.0273
0.0185
0.0328
0.0218
0.0503
0.0153
0.0352
0.0415
0.0316
0.0887
0.0412
0.0180
0.0927
0.0532
0.0200
0.0408
0.6936

[4] H. Anderson and T. Britton (2000.). Stochastic epidemic models and their
statistical analysis. Springer‚ÄìVerlag, New‚ÄìYork.
[5] E. E. Beretta, T. Hara, W. Ma and Y. Takeuchi (2001). Global asymptotically stability of an SIR epidemic model with distributed time delay.
Nonlinear Anal Theory Methods Appl 47, 4107‚Äì4115.
[6] R. Blanquero, E. Carrizosa, A. JimeÃÅnez‚ÄìCordero and B. Martƒ±ÃÅn‚Äì
BarragaÃÅn (2020). Selection of time instants and intervals with
support vector regression for multivariate functional data
https://www.researchgate.net/publication/327552293.
[7] B. M. Bolker and B. Grenfell (1996). Impact of vaccination on the spatial correlation and persistence of measles dynamics. Proceedings of the
National Academy of Sciences 93, 12648-12653.

35

Table 12: SECOND CATEGORY. SMAPEs multiplied by factor
102 .
CA GRNN
C1
0.1526
C2
0.1831
C3
0.1024
C4
0.0431
C5
0.0610
C6
0.0260
C7
0.3734
C8
0.0762
C9
0.4850
C10 0.1663
C11 0.1533
C12 0.3641
C13 0.2827
C14 0.0361
C15 0.3590
C16 0.1759
C17 0.0878
N.
0.1840
T.
3.1282

MLP
0.0857
0.1393
0.0804
0.0212
0.0362
0.0167
0.1301
0.0435
0.2467
0.0607
0.0540
0.2325
0.1350
0.0197
0.1843
0.0754
0.0352
0.0939
1.5966

SVR
0.0592
0.0619
0.0457
0.0157
0.0242
0.0125
0.0914
0.0290
0.1470
0.0460
0.0394
0.1320
0.0707
0.0117
0.1226
0.0566
0.0190
0.0579
0.9845

BNN
0.0501
0.0606
0.0374
0.0154
0.0240
0.0135
0.0737
0.0238
0.0818
0.0421
0.0383
0.0887
0.0699
0.0121
0.1049
0.0489
0.0219
0.0475
0.8070

RBF
0.0223
0.0248
0.0268
0.0117
0.0133
0.0118
0.0298
0.0244
0.0199
0.0236
0.0180
0.0369
0.0215
0.0102
0.0290
0.0243
0.0122
0.0212
0.3605

GP
0.0305
0.0285
0.0278
0.0120
0.0138
0.0121
0.0398
0.0180
0.0360
0.0276
0.0209
0.0480
0.0304
0.0104
0.0506
0.0302
0.0134
0.0265
0.4497

[8] D. Bosq (2000). Linear processes in function spaces. Lecture notes in
statistics 149. Springer, New‚ÄìYork.
[9] D. Bosq and M. D. Ruiz‚ÄìMedina (2014). Bayesian estimation in a high
dimensional parameter framework. Electron J Statist 8, 1604‚Äì1640.
[10] D. L. Chao, J. D. Bloom, B. F. Kochin, R. Antia and Jr, I. M. Longini
(2012). The global spread of drug-resistant influenza. Journal of the Royal
Society Interface 9, 648-656.
[11] Z. Du, X. Xu, Y. Wu, L. Wang, L. A. Cowling and B. J. Meyers (2020).
Serial interval of COVID-19 among publicly reported confirmed cases.
Emerg. Infect. Dis. 26(6).
[12] J. Dushoff, J. Plotkin, S. Levin and D. Earn (2004). Dynamical resonance can account for seasonality of influenza epidemics. Proceedings of
36

the National Academy of Sciences of the United States of America 101,
16915‚Äì16916.
[13] M. Elhia, A. Laaroussi, M. Rachik, Z. Rachik and E. Labriji (2014).
Global stability of a susceptible‚Äìinfected‚Äìrecovered (SIR) epidemic model
with two infectious stages and treatment. Int J Sci Res 3, 114‚Äì121.
[14] T. R. Fleming and D. P. Harrington (1991). Counting processes and
survival analysis. Wiley Series in Probability and Mathematical Statistics:
Applied Probability and Statistics. John Wiley & Sons, Inc., New‚ÄìYork.
[15] L. N. Guin and P. K. Mandal (2014). Spatiotemporal dynamics of
reaction‚Äìdiffusion models of interacting populations. Appl Math Model
38, 4417‚Äì4427.
[16] T. Hastie, R. Tibshirani and J. Friedman (2001). The elements of statistical learning. Springer Series in Statistics. Springer‚ÄìVerlag, New‚ÄìYork.
[17] A. Huppert and G. Katriel (2013). Mathematical modelling and prediction in infectious disease epidemiology. Clin Microbiol Infect 19, 999‚Äì
1005.
[18] A.V. Ivanov, N.N. Leonenko, M.D. Ruiz Medina, and B.M. Zhurakovsky
(2015). Estimation of harmonic component in regression with cyclically
dependent errors. Stastics: A Journal of Theoretical and Applied Statistics 49, 156‚Äì186.
[19] B. Ivorra, M. R. FerraÃÅndez, M. Vela-PeÃÅrez and A. M. Ramos (2020).
Mathematical modeling of the spread of the coronavirus disease 2019
(COVID-19) taking into account the undetected infections. The case of
China. Commun Nonlinear Sci Numer Simulat 88, 105‚Äì303.
[20] B. Ivorra, A. M. Ramos and D. Ngom (2015). Be-CoDiS: A mathematical
model to predict the risk of human diseases spread between countries.
Validation and application to the 2014 ebola virus disease epidemic. Bull
Math Biol 77, 1668-1704.
[21] C. Ji, D. Jiang and N. Shi (2012). The behavior of an SIR epidemic
model with stochastic perturbation. Stoch Anal Appl. 30, 755‚Äì773.
[22] M. J. Keeling, D. A. Rand and A. J. Morris (1997). Correlation models
for childhood epidemics. Proceedings of the Royal Society of London 264,
1149-1156.

37

[23] M. J. Keeling and P. Rohani (2008). Modeling infectious diseases in
humans and animals. Princeton University Press, Princeton.
[24] W. Kermack and A. McKendrick (1927). Contributions to the mathematical theory of epidemics - I. Proceedings of the Royal Society of Edinburgh A 115, 700‚Äì721.
[25] M. A. Khan and A. Atangana (2020). Modeling the dynamics of
novel coronavirus (2019-nCov) with fractional derivative. Alex. Eng. J..
doi.org/10.1016/j.aej.2020.02.033.
[26] A. J. Kucharski, T. W. Russell, C. Diamond, Y. Liu, J. Edmunds
and S. Funk et al. (2020). Early dynamics of transmission and control of COVID-19: a mathematical modelling study. Lancet Infect Dis.
doi.org/10.1016/S1473-3099(20)30144-4.
[27] Y. A. Kuznetsov and C. Piccardi (1994). Bifurcation analysis of periodic
SEIR and SIR epidemic models. J Math Biol 32, 109‚Äì121.
[28] A. E. Laaroussi, M. Rachik and M. Elhia (2018). An optimal control
problem for a spatiotemporal SIR model Int. J. Dynam. Control 6, 384397.
[29] E. L. Lehmann and G. Casella (1998). Theory of point estimation.
Springer (2th Rdition), New York.
[30] C. Malesios, N. Demiris, P. Kostoulas, K. Dadousis, T. Koutroumanidis
and Z. Abas (2016). Spatio-temporal modelling of foot-and-mouth disease
outbreaks. Epidemiol. Infect. 144, 2485‚Äì2493.
[31] C. C. McCluskey (2010). Complete global stability for an SIR epidemic
model with delay distributed or discrete. Nonlinear Anal Real World Appl
11, 55-59.
[32] F. A. Milner and R. Zhao (2008). SIR model with directed spatial diffusion. Math Popul Stud 15, 160‚Äì181.
[33] A. S. Mugglin, N. Cressie and I. Gemmell (2002). Hierarchical statistical
modelling of influenza epidemic dynamics in space and time. Statist. Med.
21, 2703-2721.
[34] H. Nishiura, N. M. Linton and A. R. Akhmetzhanov (2020). Serial interval of novel coronavirus (COVID-19) infections. Int. J. Infect. Dis. 93,
284‚Äì286.
38

[35] S. Pathak, A. Maiti and G. Samanta (2010). Rich dynamics of an SIR
epidemic model. Nonlinear Anal Model Control 15, 71‚Äì81.
[36] A. Remuzzi and G. Remuzzi (2020). COVID-19 and Italy: what next?
The Lancet. doi.org/10.1016/S0140-6736(20)30690-5
[37] K. Roosa, Y. Lee, R. Luo, A. Kirpich, R. Rothenberg, J. Hyman et
al. (2020). Real‚Äìtime forecasts of the COVID-19 epidemic in China from
February 5th to February 24th. Infect Dis Modell 5, 256-263.
[38] L. Roques and O. Bonnefon (2016). Modelling population dynamics
in realistic landscapes with linear elements: A mechanistic-statistical
reaction-diffusion approach. PloS One 11(3):e0151217.
[39] L. Roques, S. Soubeyrand and J. Rousselet (2011). A statistical-reactiondiffusion approach for analyzing expansion processes. J Theor Biol. 274,
43‚Äì51.
[40] M. Sekiguchi and E. Ishiwata (2010). Global dynamics of a discretized
SIRS epidemic model with time delay. J Math Anal Appl 371, 195‚Äì202.
[41] E. Tornatore, S. M. Buccellato and P. Vetro (2005). Stability of a
stochastic SIR system. Phys A Stat Mech Its Appl 354, 111‚Äì126.
[42] A. Torres, M. P. Frƒ±ÃÅas and M. D. Ruiz-Medina (2016). Log‚ÄìGaussian
Cox processes in infinite-dimensional spaces. Theor Prob Math Stat 95,
157‚Äì177.
[43] E. Volz (2008). SIR dynamics in random networks with heterogeneous
connectivity. Journal of Mathematical Biology 56, 293‚Äì310.
[44] C. Wang, P. W. Horby, F. Hayden and G. F. Gao (2020). A novel coronavirus outbreak of global health concern. Lancet 395, 470-473.
[45] J. Yu, D. Jiang and N. Shi (2009). Global stability of two-group SIR
model with random perturbation. J Math Anal Appl. 360 235‚Äì244.
[46] R. K. Wasiur, B. Choiy, E. Kenahz and G. A. Rempa (2019). Survival dynamical systems for the population-level analysis of epidemics.
arXiv.1901.00405.
[47] G. Webb (1981). A reaction-diffusion model for a deterministic diffusive
epidemic. J Math Anal Appl 84, 150-161.

39

[48] Y. Xu, L. Allena and A. Perelson (2007). Stochastic model of an influenza epidemic with drug resistance. Journal of Theoretical Biology
248, 179‚Äì193.
[49] F. Zhang, Z. Li and F. Zhang (2008). Global stability of an SIR epidemic
model with constant infectious period. Appl Math Comput. 199, 285-291.
[50] T. Zhou, Z. Fu and B. Wang (2006). Epidemic dynamics on complex
networks. Progress in Natural Science 16, 452-457.
[51] F. Zhou, T. Yu, R. Du, G. Fan, Y. Liu, Z. Liu, J. Xiang, Y. Wang, B.
Song, X. Gu, et al (2020). Clinical course and risk factors for mortality
of adult inpatients with COVID‚Äì19 in Wuhan, China: a retrospective
cohort study. The Lancet. doi.org/10.1016/S0140-6736(20)30566-3.
[52] L. Zhuang and N. Cressie (2014). Bayesian hierarchical statistical SIRS
models. Statistical Methods & Applications 23, 601-646.

40

