Spatio-Temporal Neural Network for Fitting and Forecasting COVID-19

Yi-Shuai Niu 1 2 Wentao Ding 3 Junpeng Hu 1 Wenxu Xu 1 Stephane Canu 4

arXiv:2103.11860v1 [cs.LG] 22 Mar 2021

Abstract
We established a Spatio-Temporal Neural Network, namely STNN, to forecast the spread of
the coronavirus COVID-19 outbreak worldwide
in 2020. The basic structure of STNN is similar to the Recurrent Neural Network (RNN) incorporating with not only temporal data but also
spatial features. Two improved STNN architectures, namely the STNN with Augmented Spatial
States (STNN-A) and the STNN with Input Gate
(STNN-I), are proposed, which ensure more predictability and flexibility. STNN and its variants
can be trained using Stochastic Gradient Descent
(SGD) algorithm and its improved variants (e.g.,
Adam, AdaGrad and RMSProp). Our STNN models are compared with several classical epidemic
prediction models, including the fully-connected
neural network (BPNN), and the recurrent neural
network (RNN), the classical curve fitting models,
as well as the SEIR dynamical system model. Numerical simulations demonstrate that STNN models outperform many others by providing more
accurate fitting and prediction, and by handling
both spatial and temporal data.

1. Introduction
The novel coronavirus COVID-19 was firstly reported in
Wuhan since December 2019. The Chinese government reacted very quickly and made great effort to limit the spread
of the disease. Numerous effective control measures have
been implemented, including traffic control, travel limitation, mask wearing, social distancing, party cancellation,
targeted isolation, environmental disinfection, work resumption delaying, and online working etc. As a result, the
epidemic situation was effectively controlled in China. By
1

School of Mathematical Sciences, Shanghai Jiao Tong University, Shanghai, China 2 SJTU-Paristech Elite Institute of Technology, Shanghai Jiao Tong University, Shanghai, China 3 Institute
for Data and Decision Analytics, Chinese University of Hong
Kong, Shenzhen, China 4 Normandie University, INSA Rouen,
UNIROUEN, UNIHAVRE, LITIS, France. Correspondence to:
Yi-Shuai Niu <niuyishuai@sjtu.edu.cn>.

mid-February, the peak of the daily active cases appeared
and dropped rapidly, and the spread of the disease in China
area was almost stopped by mid-April. Meanwhile, it was
just the beginning of the worldwide situation. WHO reported in April 4 that over 1 million cases of COVID-19 had
been confirmed worldwide, a more than tenfold increase in
less than a month. Until January 2021, there are 95 millions
cumulative cases and 2 million deaths worldwide. Several
variants of COVID-19 appeared and some of them have
stronger transmission capacity, e.g., SARS-CoV-2 outbreak
in UK was estimated up to 70% more transmissible than the
previously circulating forms (Kirby, 2021).
Scientists rush to understand the new illness COVID-19.
Hundreds of preprints are shared every day on the study of
all aspects including biomedicine, epidemiology, economics,
sociology, mathematics and computer sciences etc. Several
reports, e.g., (Organization et al., 2019; Wu et al., 2020; Leung et al., 2020; Xu et al., 2020; Li et al., 2020a), show that
COVID-19 has a higher basic reproductive number R0 and
a lower death rate comparing to the other well-known two
coronaviruses SARS-CoV and MERS-CoV (SARS-CoV
outbreak in 2002 caused more than 8000 infections and 800
deaths, and MERS-CoV outbreak in 2012 caused 2494 individuals and 858 deaths). Zhongâ€™s team analyzed in first the
symptoms, latency and mortality of COVID-19 and emphasized the significance of early isolation (Guan et al., 2020).
Later, the impact of different factors has been studied, such
as the temperature, human mobility and control measures
etc., see e.g., (Lin et al., 2020; Chinazzi et al., 2020; Xie &
Zhu, 2020; Kraemer et al., 2020). With the spread of the
pandemic to the whole world, the transmission dynamical
models for different countries have been investigated, see
e.g., (Phan et al., 2020; Mizumoto & Chowell, 2020; Fanelli
& Piazza, 2020; Rockett et al., 2020; Giordano et al., 2020;
Sarkar et al., 2020).
Our work is focused on establishing a spatio-temporal deep
neural network model to predict the spread of disease over
time and space. There exist many works on machine learning approaches to forecast the trend of COVID-19. The
study of traditional models such as linear regression, SVM
for regression, fast decision tree learner and so on are reported in (James Fong et al., 2020; Chinazzi et al., 2020;
Ayyoubzadeh et al., 2020), which showed that the traditional
methods performed well enough with small-scale dataset.

Spatio-Temporal Neural Network for Fitting and Forecasting COVID-19

The use of deep learning models such as LSTM and GRU
to predict COVID-19 are reported in (Yang et al., 2020;
Chimmula & Zhang, 2020; Shahid et al., 2020; Li et al.,
2020b), which performed well in some tasks using time
series dataset. However, an advanced model taking both
temporal and spatial data into account to predict the spread
of infectious disease is rarely appeared in literature.
In this manuscript, we establish in Section 2 a spatiotemporal deep neural network (namely, STNN) to fit spatial and temporal pandemic data and predict the trend of
the decease over time and space. Its training algorithm
based on SGD is also proposed. Two improved variants
of STNN, namely STNN with Augmented Spatial States
(STNN-A) and STNN with Input Gate (STNN-I), are developed which could provide more flexibility and improve
prediction accuracy. Some classical prediction models to
compare with are briefly introduced in Section 3 including:
the fully-connected neural network model (BPNN), the recurrent neural network models (LSTM and GRU), the curve
fitting (Gaussian, exponential and polynomial) models, and
the SEIR dynamical system model. Our proposed STNN
model and its variants are implemented in Python, and the
compared classical prediction models are developed in MATLAB. These codes are tested on a set of COVID-19 dataset
(a collection of various spatial and temporal data in China,
United-States and Italy). Numerical results are reported in
Section 4 which demonstrate that our STNN models perform well enough by providing accurate predictions and
exhibit the ability to handle both spatial and temporal data.

2. Spatio-Temporal Neural Network (STNN)
Spatio-Temporal Neural Network, namely STNN, is a neural
network architecture to predict phenomena evolving in time
and in space. Thus, it is suitable for epidemic predictions.
2.1. Classical STNN Model
The classical STNN model is based on the Recurrent Neural
Network (RNN) with additional spatial data. The idea to
feed the neural network with spatial data comes from (Ziat
et al., 2017). The spatial and temporal data required in
STNN are described as follows:
Model Data: Suppose that we observe a time series data
of size m. Temporal data at time t âˆˆ [m]1 is denoted by
xt âˆˆ RnÃ—d where n is the number of observing locations
(e.g., cities, countries) and d is the number of observing
targets (e.g., infections, deaths). The spatial data, denoted by
Wi âˆˆ RnÃ—n , i âˆˆ [p], is a collection of p matrices of spatial
features (e.g., the distance between cities, the transport flow
between cities).
1

The notation [m] with m âˆˆ N stands for {1, 2, . . . , m}.

Model Architecture: The architecture of the classical
STNN is illustrated in Figure 1:

Figure 1. Structure of the classical STNN model.

STNN consists of three parts: the hidden states st âˆˆ
RnÃ—l , t âˆˆ [m] (where l denotes the dimension of hidden
states for each observing position), the observation network
a and the state network b. Both of the networks a and b are
traditional fully-connected neural networks as in Figure 2.

Figure 2. Common structure of the observation and state networks.

The hidden state can be understood as the high-dimensional
representation of the observation, and the observation is the
projection of the hidden state on the low-dimensional space
through the observation network. The state network is used
to achieve the hidden state transition, that is, the hidden
state st+1 is the output of the state network b with input
hidden state st coupling with spatial data Wi , âˆ€i âˆˆ [p]. Due
to the functionality of the observation network and the state
network, we use either tanh or sigmoid as activation
functions for all hidden layers and the output layer.
Unlike the traditional RNN model, the hidden states in
STNN are also parameters to be trained, so that the loss
function of STNN model is defined as:
m

L(Î¸) =

1 X
ka(st ) âˆ’ xt k2F
m t=1
p
mâˆ’1
X
1 X
+
b st +
Wi st
m âˆ’ 1 t=1
i=1

2

!
âˆ’ st+1

,
F

where k.kF stands for the matrix Frobenius norm 2 , and the
training parameters Î¸ = (Î¸a , Î¸b , s1 , . . . , sm ) in which Î¸a
2
Let A be an m Ã—
pn real matrix, the Frobenius norm of A is
defined by kAkF = tr(A> A).

Spatio-Temporal Neural Network for Fitting and Forecasting COVID-19

and Î¸b are parameters of the neural networks a and b. The
first summand of L measures the quality of the observation
network and the hidden states, and the second summand
measures the quality of the state network and the hidden
states. Training STNN amounts to find an observation network a, a state network b and all hidden states st , t âˆˆ [m]
to minimize the loss function L, which is the following
unconstrained optimization problem:
min L(Î¸).

augmented output dimension (p + 1 times larger than the
input one). This particular structure could be useful to
include more rich spatial features, thereby improving the
capacity of STNN to handle spatial data in a more flexible
way. The improved STNN with Augmented Spatial States,
namely STNN-A model, is described in Figure 3.

(P)

Î¸

Once an â€œoptimalâ€ network is obtained, the prediction is
made by updating the last hidden state from sm to sm+1
through the state network as
!
p
X
sm+1 = b sm +
Wi sm ,
i=1

Figure 3. Structure of the STNN-A model.

The loss function LA for STNN-A model is defined by:
m

LA (Î¸) =

and the predicted output xm+1 is obtained through the observation network as a(sm+1 ).

1 X
2
ka(st ) âˆ’ xt kF
m t=1
+

2.2. Improved STNN models
There are several drawbacks of the classical STNN model.
Firstly, the spatial data Wi , i âˆˆ [p] are introduced by the
linear mapping
U : st 7â†’ st +

p
X

Wi st .

(1)

i=1

Such a simple superposition is hard to reflect the
real contribution (probably nonlinear) of each element
st , W1 st , . . . , Wp st , thus eventually limits the modelâ€™s prediction accuracy and flexibility.
Secondly, there are no input data in STNN. Introducing
input data xt at time t may help to correct the hidden states,
thus enhance the prediction accuracy.
To overcome these drawbacks, we propose two improved
architectures, namely STNN with Augmented Spatial States
(STNN-A) and STNN with Input Gate (STNN-I).

mâˆ’1
1 X
2
kb (W(st )) âˆ’ st+1 kF .
m âˆ’ 1 t=1

Note that both L and LA have a similar structure thus can
be minimized in a similar way. The prediction of STNN-A
is proceed accordingly as described in STNN.
STNN with Inputs Gate In STNN and STNN-A structures, the prediction of the next time t + 1 depends on the
observation network, the state network and the current hidden state st . So if they are not accurate, the error will be
propagated and accumulated through the network, and yield
worse predictions over time. Therefore, we propose to introduce input data xtâˆ’1 at time t to adjust the accuracy of the
hidden state st .
To this end, the input observation xtâˆ’1 is introduced through
a fully-connected neural network, namely input network c,
whose output c(xtâˆ’1 ) will be coupled with the hidden state
st at each time t. Then, the next hidden state st+1 is justified
by c(xtâˆ’1 ) as:
st+1 = b(c(xtâˆ’1 ), W(st )).

STNN with Augmented Spatial States By introducing
augmented spatial states, using a separate spatial state for
each spatial feature as
W : st 7â†’ (st , W1 st , . . . , Wp st ),

The improved STNN with Input Gate, namely STNN-I
model, is described in Figure 4. Similar to STNN and
STNN-A models, the loss function of STNN-I model is:

(2)

the output of W is used as input of the state network b which
helps to provide more flexibility for improving the accuracy
of the state transition.
From an algebraic point of view, both of the mappings U
and W are linear. However, the mapping U has the same
input and output dimension; while the mapping W has an

m

LI (Î¸) =

1 X
ka(st ) âˆ’ xt k2F
m t=1
+

mâˆ’1
1 X
2
kb (c(xtâˆ’1 ), W(st )) âˆ’ st+1 kF .
m âˆ’ 2 t=2

Once the optimal network is obtained, we predict future
hidden states sm+t as:

Spatio-Temporal Neural Network for Fitting and Forecasting COVID-19
ğ’™ğ’•âˆ’ğŸ

ğ’‚(ğ’”ğ’• )

ğ’‚(ğ’”ğ’•âˆ’ğŸ )
ğ’”ğ’•âˆ’ğŸ

ğ’™ğ’•+ğŸ

ğ’™ğ’•

ğ’ƒ(ğ’„(ğ’™ğ’•âˆ’ğŸ ),ğ“¦(ğ’”ğ’•âˆ’ğŸ ))

ğ’„(ğ’™ğ’•âˆ’ğŸ )

ğ’”ğ’•

ğ’„(ğ’™ğ’•âˆ’ğŸ )

ğ’™ğ’•âˆ’ğŸ

ğ’™ğ’•âˆ’ğŸ

The classical SGD algorithm for problem (P) is described
as follows:

ğ’‚(ğ’”ğ’•+ğŸ )
ğ’ƒ(ğ’„(ğ’™ğ’•âˆ’ğŸ ),ğ“¦(ğ’”ğ’• ))

ğ’”ğ’•+ğŸ

ğ’„(ğ’™ğ’• )
ğ’™ğ’•

Figure 4. Structure of the STNN-I model.

sm+t

ï£±
ï£´
, if t = 1;
ï£²b(c(xmâˆ’1 ), W(sm ))
= b(c(xm ), W(sm+1 ))
, if t = 2;
ï£´
ï£³
b (c(a(sm+tâˆ’2 )), W(sm+tâˆ’1 )) , if t â‰¥ 3.

Note that for t â‰¥ 3, there is no observation data yet, thus
we have to use the predicted result at time m + t âˆ’ 2, i.e.,
a(sm+tâˆ’2 ) as input data.
2.3. SGD and Its Variants for Training STNN Models
Training STNN models amounts to solving a large-scale
nonlinear and nonconvex optimization problem of type (P),
which is obviously a challenging problem and NP-hard in
general. The most popular methods in deep learning is to use
the Stochastic Gradient Descent (SGD) algorithm and its improved variants (based on the Nesterov acceleration, Polyak
momentum, adaptive learning rate, sampling techniques and
noise reduction etc., see e.g. (Ruder, 2016; Bottou, 1998;
Bottou & Bousquet, 2008; Goodfellow et al., 2016) for excellent presentations and theoretical analysis). Note that
due to the lack of necessary and sufficient optimality conditions for nonconvex optimization, and the introduction of
stochastics, SGD and its variants can be only expected to
find an Îµ-stationary point, i.e., a random vector Î¸âˆ— for which
E[kâˆ‡L(Î¸âˆ— )k] â‰¤ Îµ.
The term â€œstochasticâ€ in SGD is typically performed as sampling one or a minibatch of samples to compute the gradient
of the loss function defined on them, namely gradient estimator gÌ‚ of the true gradient g. The gradient estimator gÌ‚ is
supposed to be unbiased, i.e., E[gÌ‚] = g.
Next, we will present SGD for training the classical STNN
model. The variant STNN models can be trained in a similar
way. Suppose that we have totally m samples {x1 , . . . , xm },
let us choose a subset of mÌ‚ samples {xi }iâˆˆS where S is the
index set of samples with S âŠ‚ [m âˆ’ 1] and |S| = mÌ‚. The
loss function defined on S is:
1 X
L(Î¸; S) =
ka(st ) âˆ’ xt k2F
mÌ‚
tâˆˆS
!
2
p
X
1 X
Wi st âˆ’ st+1 .
+
b st +
mÌ‚
i=1
tâˆˆS

F

Algorithm 1 SGD for training STNN model
Input: Learning rates {Î·k }; Initial Î¸ of STNN.
Output: Optimal Î¸ of STNN.
Initialize k â† 1;
while Stopping criterion not met do
Take a minibatch of mÌ‚ samples with indices in S;
Compute gradient estimator: gÌ‚ â† âˆ‡Î¸ L(Î¸; S);
Update parameter: Î¸ â† Î¸ âˆ’ Î·k gÌ‚;
k â† k + 1;
end while
The hyper-parameter Î·k in SGD is called learning rate. It is
necessary to gradually decrease the learning rate over time
since the SGD gradient estimator introduces a source of
noise (the random sampling) that does not become 0 even
at a local minimum. To guarantee the convergence of SGD,
one may choose {Î·k } as:
+âˆ
X
k=1

Î·k = +âˆ and

+âˆ
X

Î·k2 < +âˆ.

k=1

In practice, we often use the following formulation to generate a sequence {Î·k } as
(
(1 âˆ’ Î±k )Î·0 + Î±k Î·Ï„ , if 0 â‰¤ k < Ï„ ;
Î·k =
Î·Ï„
, if k â‰¥ Ï„,
i.e., linearly decay Î·k from Î·0 until iteration Ï„ with Î±k = Ï„k ,
and fix Î·k = Î·Ï„ when k â‰¥ Ï„ . Concerning the choice of
parameters Ï„ , Î·0 and Î·Ï„ , we usually set Ï„ to the number of
iterations required to make a few hundred passes through
the training set; the final learning rate Î·Ï„ should be set to
roughly 1% of the initial learning rate Î·0 . However, the
set of Î·0 is a sensitive question, which should be neither
too large nor too small. If it is too large, then the learning
curve will show violent oscillations and cause severe instability; if it is too small, learning proceeds slowly and may
become stuck with a high loss value. Typically, we set Î·0
slightly greater than the learning rate that yields the best
performance after the first 100 iterations.
Concerning the convergence rate of SGD, it depends on the
optimization problem we are going to solve. The convergence rate is often measured by the excess error defined as
L(Î¸(k) ) âˆ’ minÎ¸ L(Î¸) where Î¸(k) denotes the parameter Î¸ at
iteration k. As a result, the convergence rate of SGD is of
order O( âˆš1k ) for convex optimization problem, and O( k1 )
for strongly convex optimization problem. These bounds
cannot be improved unless extra conditions are assumed.
However, training an STNN model is highly nonconvex, and
the study of the convergence rate of SGD for a nonconvex

Spatio-Temporal Neural Network for Fitting and Forecasting COVID-19

optimization problem is still far from mutual. Some recent
works (Khaled & RichtaÌrik, 2020; Lei et al., 2019; Gower
et al., 2019) show that the optimal convergence rate for SGD
to find Îµ-stationary points of nonconvex optimization problems under the expected smoothness assumption is O(Îµâˆ’4 ),
and recover the optimal O(Îµâˆ’1 ) if the Polyak-Åojasiewicz
condition is satisfied. Note that a training algorithm with
super-linear convergence rate for machine learning is in general not expected, as (Bottou & Bousquet, 2008) argue that
too fast convergence presumably corresponds to overfitting.
We have also tried some improved SGD for training STNN
models, including Adam (Kingma & Ba, 2014), AdaGrad
(Duchi et al., 2011) and RMSProp (Tieleman & Hinton,
2012), among which Adam seems to outperform the others.
Adam is a variant of SGD based on adaptive estimates of
lower-order moments and adaptive learning rate. It includes
bias corrections to the estimates of both the first and second
order moments. The method is claimed to be straightforward to implement, computationally efficient, little memory
requirements, well suited for problems that are large in terms
of data and parameters, and appropriate for non-stationary
objectives and problems with very noisy sparse gradients.
The Adam algorithm for training STNN model is described
in Algorithm 2 where â—¦ denotes the Hadamard product (i.e.,
element-wise product). The convergence analysis of Adam
can be found in (Reddi et al., 2019).
Algorithm 2 Adam for training STNN model
Input: Learning rate Î· (= 0.001), exponential decay
rates for moment estimates, Ï1 (= 0.9), Ï2 (= 0.999), Î´
(= 10âˆ’8 ), and initial Î¸ of STNN.
Output: Optimal Î¸ of STNN.
Initialize k â† 1;
Initialize 1st and 2nd moments u = 0, v = 0;
while Stopping criterion not met do
Take a minibatch of mÌ‚ samples with indices in S;
Compute gradient estimator: gÌ‚ â† âˆ‡Î¸ L(Î¸; S);
Update biased 1st moment: u â† Ï1 u + (1 âˆ’ Ï1 )gÌ‚;
Update biased 2nd moment: v â† Ï2 v + (1 âˆ’ Ï2 )gÌ‚ â—¦ gÌ‚;
Correct bias in 1st moment: uÌ„ â† u/(1 âˆ’ Ïk1 );
Correct bias in 2nd moment: vÌ„ â†âˆšv/(1 âˆ’ Ïk2 );
Update parameter: Î¸ â† Î¸ âˆ’ Î·uÌ„/( vÌ„ + Î´);
k â† k + 1;
end while

3.1. Fully-Connected Neural Network
Fully-connected Neural Network, also called Back Propagation Neural Network (BPNN), is a popular supervised
learning model, which is widely used due to its simple
structure and strong fitting ability. BPNN often plays an important part of other complex neural network architectures
such as CNN, ResNet, GAN as well as our STNN.
A classical BPNN contains three parts: input layer, hidden
layers and hidden layer. Every layer consists of some neurons associated with weights, bias and activation functions.
The structure of the classical BPNN is previously illustrated
in Figure 2.
We can use SGD and its variants to train BPNN model for
epidemic prediction. The training data is a set of temporal
input-output pairs {(xt , yt )}t where xt is a vector of inputs
at time t (e.g., the time step t) and yt is a vector of outputs
at time t (e.g., number of infections, deaths and recoveries
at t). A well trained BPNN will receive a future input xt
and output a prediction yt .
3.2. Recurrent Neural Networks
There are two commonly used Recurrent Neural Network
(RNN) architectures, namely LSTM and GRU.
LSTM (Long Short-Term Memory) LSTM proposed in
(Hochreiter & Schmidhuber, 1997) is suitable for processing
and predicting events with long interval and delay in time
series. The network can choose whether to memorize or
delete relevant information through a structure called â€gateâ€
(including 3 gates: forget gate, input gate, output gate). The
spread of an epidemic is strongly related to the situation in a
certain period, while the relation with other periods is much
weaker, so that LSTM should be appropriate to predict the
spread of COVID-19.
GRU (Gated Recurrent Unit) GRU is a variant of LSTM
proposed in (Cho et al., 2014). It is a simplified LSTM with
only two gates (called update gate and reset gate) whose
structure is shown in Figure 5, thus it is claimed to be easier
to train than LSTM, and can also achieve the same function
as LSTM. For these reasons, GRU is now a very popular
and widely used RNN.

ğ’‰ğ’•

ğ’‰ğ’•

3. Other Prediction Models
We are going to compare STNN models with several classical prediction models, including: fully-connected neural
network, recurrent neural network, curve fitting models and
dynamical system SEIR model. Note that these models take
temporal data only. We will briefly introduce these models
and explain how to use them for epidemic prediction.

ğ’“ğ’•
Reset Gate

ğ’–ğ’•

Linear

Update Gate

ğ’‰ğ’•âˆ’ğŸ

ğ’™ğ’•

ğ’šğ’•

Figure 5. Structure of GRU Cell.

Spatio-Temporal Neural Network for Fitting and Forecasting COVID-19

Using RNN to predict COVID-19 We select a sequence of
data from past k time steps as input of RNN, whose output
is also a sequence of the same length. Then, passing output
sequence into a two layers fully-connected network (with
only input and output layers) to get the prediction of the
next time step. This procedure is shown in Figure 6. Both
LSTM and GRU can be trained using SGD and its variants.

useful to predict in the periods where the number of infections is increasing or decreasing unilaterally.
Gaussian Model The Gaussian model is often used to fit
peaks defined as the sum of Gaussian functions as

y=

k
X

ai e

 
 
xâˆ’bi 2
âˆ’
c
i

,

i=1

where ai is the amplitude, bi is the centroid, ci is related to
the peak width, and k is the number of peaks to fit. Gaussian
fitting is particularly useful to predict peaks of the infections.
Polynomial Model Polynomial model for curve fitting is
given by
Figure 6. Prediction procedure by RNN (LSTM/GRU).

y=

n
X

ai xi ,

i=0

3.3. Curve Fitting Models
Curve fitting techniques are classical prediction approaches,
which aim at constructing curves, or mathematical functions,
that have best fits to a series of data points. Curve fitting
can involve either interpolation, where an exact fit to the
data is required, or smoothing, in which a smooth function
is constructed to approximate the data. Fitted curves can be
used for data visualization, and to infer values of a function
where no data are available, i.e., extrapolation. Therefore,
we can use the fitted curves based on the observed data for
epidemic prediction.
Strictly speaking, the supervised deep learning models
BPNN and RNN are also curve fittings which use neural
network structures (as parametric composite functions) to
fit observation data. In this section, we will focus on some
other type of classical curve fitting models for epidemic
prediction, which can be found in many textbooks of numerical analysis (e.g., (Arlinghaus, 1994)) and curve fitting
packages (e.g., MATLAB Curve Fitting Toolbox).
Exponential Model
is described by

The multi-terms exponential model

y=

k
X

ai ebi x ,

i=1

where ai , bi âˆˆ R are model parameters, x âˆˆ R is input, and
y âˆˆ R is output.
Exponential model is often used when the rate of change
of a quantity is proportional to the initial amount of the
quantity. If the coefficient associated with bi is negative, y
represents exponential decay; otherwise, y represents exponential growth. Thus, the exponential model is particularly

where n is the degree of the polynomial. Polynomial model
is often used when a simple empirical model is required.
You can use the polynomial model for interpolation or extrapolation, or to characterize data using a global fit. In the
pandemic prediction, polynomial model can be used at any
period of the epidemic. The main advantages of polynomial
fits include reasonable flexibility for data that is not too
complicated, which means the fitting process is simple. The
main disadvantage is that high-degree fits can become unstable. Additionally, polynomials of any degree can provide a
good fit within the data range, but can diverge wildly outside
that range. Therefore, exercise caution when extrapolating
with polynomials.
3.4. Dynamical System : SEIR Model
Differential equations are classical approaches to study epidemic dynamics involving over time. R. Ross seems to be
the first to establish a mathematical differential equation to
research the dynamical transmission of disease (Ross, 1911);
then Kermack and Mckendrick established the warehouse
SIR and SIS models (Kermack & McKendrick, 1927; 1932),
based on which various improved dynamical transmission
models of infectious diseases have been developed such as
the SIRS model, the SEIR model and the SEIRS model, see
e.g., (Bartlett, 1949; Bailey et al., 1975; Anderson & May,
1979; Beretta et al., 2001).
According to the transmission characteristics of COVID-19,
patients have an incubation period, and acquire antibodies
during a period after recovery. Therefore, among these dynamical transmission models, the SEIR model seems to be
the most suitable one for COVID-19 prediction. The SEIR
model divides persons into four categories: susceptible (S),
exposed (E), infectious (I) and removed (R). The dynamics

Spatio-Temporal Neural Network for Fitting and Forecasting COVID-19

between them can be simply described as follows:
ï£±
Î²SI
ï£´
,
ï£´S 0 = âˆ’
ï£´
ï£´
N
ï£´
ï£² 0
Î²SI
E =
âˆ’ Î´E,
N
ï£´
ï£´
0
ï£´
I = Î´E âˆ’ Î³I,
ï£´
ï£´
ï£³ 0
R = Î³I,
where S(t), E(t), I(t), R(t) are functions of the number of
susceptible, exposed, infectious and removed persons over
time t; N is the total population of the area; the parameter
Î² is the effective contact rate, Î´ is the exit rate from the
vulnerable to confirmed infections, and Î³ is the removal
rate of infected persons. These parameters can be estimated
using least square method, and updated for different period
to improve the fitting accuracy and get better estimations.

4. Numerical Experiment
In this section, we will report our numerical results for
forecasting the trend of COVID-19 in several countries,
including China, USA and Italy.
Our STNN models are implemented in Python, the compared RNN (typically the GRU model is chosen instead of
the LSTM model) comes from Keras, and the codes for
other compared prediction models (curve fitting models,
BPNN, and SEIR) are all developed in MATLAB. Numerical simulations are performed on a supercomputer Ï€ 2.0,
at HPC center of Shanghai Jiao Tong University, equipped
with 4 GPUs (Tesla V100-SXM3) and 20 CPUs (Intel Xeon
Gold 6248 CPU@2.50GHz) for neural network training.
Data Sources3 We collect the Chinese provincial data from
National Health Commission of the Peopleâ€™s Republic of
China, the USA data from Johns Hopkins University, and
Italian data from the Health Ministry. These data are all
in time series, consist of the cumulative confirmed cases,
deaths and recoveries.
In addition to the number of patients reported, we collect
some temporal and spatial data related to the spread of the
decease. The daily migration data between provinces of
China are collected from Baidu Map. Some hospital information (e.g., the number of hospitals and the fever clinics)
is obtained from CSMAR (short for China Stock Market &
Accounting Research Database). The population of each
province is obtained from National Bureau of Statistics.
Some meteorological data include temperature, humidity
and air quality index (AQI) are obtained from a data service
platform Nowapi.
A correlation analysis using provincial data (except Hubei)
from January to March 2020 is reported in Table 1. It was
3
All data are shared on GitHub at https://github.com/
niuyishuai/covid-19-data.

Table 1. The correlation coefficient of different factors to the epidemic data (C: confirmed; R: recovered; D: deaths; S: sum of
absolute values of CRD).

IMMIGRATION
EMIGRATION
TEMPERATURE
HUMIDITY
AQI
HOSPITALS
POPULATION

C

R

D

S

0.162
0.065
-0.094
0.136
0.009
0.174
0.380

0.038
-0.070
0.033
0.144
-0.085
0.192
0.407

0.015
0.002
-0.024
0.049
0.026
0.087
0.153

0.215
0.137
0.150
0.329
0.120
0.454
0.940

found that the population had the greatest impact on the
epidemic situation, followed by: the number of hospitals,
humidity, immigration scale index, temperature, emigration
scale index and then air quality index. The main factors
with major impact will be considered in STNN models.
Fitting and predicting active cases for COVID-19 Firstly,
we report fitting and prediction results of daily active cases
in China because it consists of a complete period from the
early outbreak to the rapid control. The provincial data from
January to March 2020 are used to test different models. The
reason to choose this period is that the pandemic situation
is very different, broke out in January, peaked in February,
and reduced quickly in March. The spatial data for STNN
model include the adjacency matrix of geographic locations,
the average population migrations, and the distance matrix
among 33 provinces. Temporal data is divided into 2 categories: training set (90%) and validation set (10%). The
compared BPNN, GRU, curve fitting and SEIR models are
fed with temporal data only. The STNN and GRU models are trained up to 10,000 epochs using Adam algorithm,
where the observation, state and input networks have 1-3
layers with 10-30 neurons in each. The `2 regularization
could be involved to avoid overfitting. The BPNN model
is a 3 layered network with 5 neurons in the hidden layer
and tanh as activation function, which is trained up to 1000
epochs 10 times using SGD with random initialization and
the one with best performance is used. We apply the root
mean square error (namely, RMSE) to measure the training and prediction errors for all tested models. The fitting
and prediction results using COVID-19 data in China are
summarized in Table 2 and illustrated in Figure 7.
Table 2. Training and testing RMSE (base on 103 ) of daily active
cases in China, boldface/underline for best/worst records.
JAN .
T RAIN
T EST
STNN
STNN-A
STNN-I
BPNN
GRU
GAUSS
EXP
POLY
SEIR

0.27
0.00
0.02
0.32
0.22
0.31
0.51
0.32
0.41

2.56
0.87
2.51
8.73
6.08
9.20
9.21
2.06
3.39

F EB .
T RAIN
T EST
0.46
0.23
1.56
0.36
1.95
1.16
5.18
2.65
1.86

2.47
0.83
1.10
2.65
3.19
4.06
50.25
1.23
1.49

M AR .
T RAIN
T EST
0.68
0.09
0.13
0.08
0.36
0.14
0.27
0.23
0.15

0.75
0.34
0.11
0.36
0.29
0.37
0.45
0.12
0.27

P EAK .
T RAIN
T EST
3.09
3.15
3.26
1.24
2.12
2.62
3.79
2.32
2.91

6.43
5.40
7.93
0.85
0.90
1.98
29.13
11.42
6.38

Spatio-Temporal Neural Network for Fitting and Forecasting COVID-19
STNN
STNN-A

1e4

STNN-I
BPNN

GRU
GAUSS

Jan

EXP
POLY

SEIR
Ground Truth

Feb

1e4

6
4
4
3
2
0
2
âˆ’2
1
âˆ’4
0
0 2 4 6 8 10 12 14 âˆ’60 5 10 15 20 25 30
Days
Days

Mar
1e4
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0.0
0 5 10 15 20 25 30 35
Days

Peak
1e5
1.0
0.8
0.6
0.4
0.2
0.0
0 5 10 15 20 25
Days

Figure 7. Fitting and prediction results of daily active cases in
China using STNN, STNN-A, STNN-I, GRU, BPNN, curve fitting,
and SEIR models.

Concerning global outbreaks outside of China, we choose
two typical countries: USA and Italy. The fitting and prediction results are reported in Figure 8; the training and testing
errors are summarized in Table 3. The first 300 days of
spatial and temporal data from 22 January to 31 December
of 2020 are used to predict the peak of the next 15 days in
Italy and the trend of continued growth over the next 30
days in USA.
Table 3. Training and testing RMSE (base on 104 ) of daily active
cases in USA and Italy, boldface/underline for best/worst records.
USA
T RAIN
T EST
STNN
STNN-A
STNN-I
BPNN
GRU
GAUSS
EXP
POLY
SEIR

14.00
4.84
6.75
1.48
1.05
12.22
38.08
15.14
7.83

20.79
19.93
23.59
42.36
27.08
16.35
76.27
56.30
86.92

I TALY
T RAIN
T EST
0.83
0.33
0.19
0.19
0.60
0.53
4.49
3.08
1.58

2.26
3.52
1.92
2.59
5.87
8.44
57.99
17.79
12.92

Comments on numerical results Numerical results demonstrate that the STNN-A, STNN-I and BPNN models often
provide best fitting and prediction results (as shown in Figures 7 and 8 and in Tables 2 and 3 with boldface for smallest RMSE and underline for largest RMSE). The classical
STNN, GRU, SEIR and polynomial models often perform
well for both fitting and prediction of data in China and
other countries, only slightly weaker in RMSE than the im-

STNN
STNN-A

STNN-I
BPNN

USA

1.2 1e7
1.0
0.8
0.6
0.4
0.2
0.0
180 210 240 270 300 330
Days

GRU
GAUSS

1.75
1.50
1.25
1.00
0.75
0.50
0.25
0.00

EXP
POLY

1e6

SEIR
Ground Truth

ITALY

240 260 280 300 320
Days

Figure 8. Fitting and prediction results of daily active cases in USA
and Italy using STNN, STNN-A, STNN-I, GRU, BPNN, curve
fitting, and SEIR models.

proved STNN models and BPNN model. The exponential
model seems to perform bad for both fitting and prediction,
even for unilateral cases, and not suitable to fit peaks; while
BPNN, GRU, STNN and Gaussian models perform quite
well to predict peaks. The major drawback of the SEIR
model is the high dependence on the estimation of model
parameters; the Gaussian model performs well for unilateral
fitting and short period unilateral prediction, but not very
satisfactory for long period unilateral prediction; the polynomial model works well for fitting within the data range,
but diverges wildly for prediction beyond that range. As for
our STNN models, the main advantage is the compatibility
and the flexibility of using both temporal and spatial data to
increase the accuracy (with small RMSE) of fitting and prediction; while its main drawback is also the requirement of
many types (temporal and spatial) of data whose collection
could be difficult and cumbersome. As plus, the training of
deep neural networks (e.g., STNN and RNN) is very time
and computing resource consuming comparing to the other
models. Nevertheless, there is a need of large amounts of
training data in many deep learning models, whose collection, in the current era of big data, is not too difficult. The
increasing GPU computing power also makes it possible
to train deep neural networks. Therefore, we believe that
STNN should be a promising deep learning model in many
potential applications involving spatial and temporal data.

Acknowledgments
This project is partially supported by the special grand
for Science and Technology Innovation at Shanghai Jiao
Tong University â€œSpatio-Temporal Deep Neural Network
for Trend Prediction of the New Coronavirus COVID-19 and
Countermeasures Researchesâ€ (Grant 2020RK10), 2020,
and by the National Natural Science Foundation of China
(Grant 11601327).

Spatio-Temporal Neural Network for Fitting and Forecasting COVID-19

References
Anderson, R. M. and May, R. M. Population biology of
infectious diseases: Part i. Nature, 280(5721):361â€“367,
1979.

Giordano, G., Blanchini, F., Bruno, R., Colaneri, P., Di Filippo, A., Di Matteo, A., and Colaneri, M. Modelling
the covid-19 epidemic and implementation of populationwide interventions in italy. Nature Medicine, pp. 1â€“6,
2020.

Arlinghaus, S. L. Practical handbook of curve fitting. CRC
Press, 1994.

Goodfellow, I., Bengio, Y., and Courville, A. Deep Learning.
MIT Press, 2016.

Ayyoubzadeh, S. M., Ayyoubzadeh, S. M., Zahedi, H., Ahmadi, M., and Kalhori, S. R. N. Predicting covid-19
incidence through analysis of google trends data in iran:
data mining and deep learning pilot study. JMIR Public
Health and Surveillance, 6(2):e18828, 2020.

Gower, R. M., Loizou, N., Qian, X., Sailanbayev, A.,
Shulgin, E., and RichtaÌrik, P. Sgd: General analysis and
improved rates. In International Conference on Machine
Learning, pp. 5200â€“5209. PMLR, 2019.

Bailey, N. T. et al. The mathematical theory of infectious
diseases and its applications. Charles Griffin & Company
Ltd, 5a Crendon Street, High Wycombe, Bucks HP13
6LE., 1975.
Bartlett, M. Some evolutionary stochastic processes. Journal of the Royal Statistical Society. Series B (Methodological), 11(2):211â€“229, 1949.
Beretta, E., Hara, T., Ma, W., and Takeuchi, Y. Global
asymptotic stability of an sir epidemic model with distributed time delay. Nonlinear Analysis: Theory, Methods
& Applications, 47(6):4107â€“4115, 2001.
Bottou, L. Online algorithms and stochastic approximations.
Online learning and neural networks, 1998.
Bottou, L. and Bousquet, O. The tradeoffs of large scale
learning. In Advances in neural information processing
systems, pp. 161â€“168, 2008.
Chimmula, V. K. R. and Zhang, L. Time series forecasting
of covid-19 transmission in canada using lstm networks.
Chaos, Solitons & Fractals, pp. 109864, 2020.
Chinazzi, M., Davis, J. T., Ajelli, M., Gioannini, C., Litvinova, M., Merler, S., y Piontti, A. P., Mu, K., Rossi, L.,
Sun, K., et al. The effect of travel restrictions on the
spread of the 2019 novel coronavirus (covid-19) outbreak.
Science, 368(6489):395â€“400, 2020.
Cho, K., Van Merrienboer, B., Gulcehre, C., Bahdanau,
D., Bougares, F., Schwenk, H., and Bengio, Y. Learning phrase representations using rnn encoder-decoder for
statistical machine translation. Computer Science, 2014.
Duchi, J., Hazan, E., and Singer, Y. Adaptive subgradient
methods for online learning and stochastic optimization.
Journal of machine learning research, 12(7), 2011.
Fanelli, D. and Piazza, F. Analysis and forecast of covid-19
spreading in china, italy and france. Chaos, Solitons &
Fractals, 134:109761, 2020.

Guan, W., Ni, Z., Hu, Y., Liang, W., Ou, C., He, J., Liu, L.,
Shan, H., Lei, C., Hui, D. S., et al. Clinical characteristics of coronavirus disease 2019 in china. New England
journal of medicine, 382(18):1708â€“1720, 2020.
Hochreiter, S. and Schmidhuber, J. Long short-term memory.
Neural computation, 9(8):1735â€“1780, 1997.
James Fong, S., Herrera Viedma, E., et al. Finding an
accurate early forecasting model from small dataset: A
case of 2019-ncov novel coronavirus outbreak. 2020.
Kermack, W. O. and McKendrick, A. G. A contribution to
the mathematical theory of epidemics. Proceedings of the
royal society of london. Series A, Containing papers of a
mathematical and physical character, 115(772):700â€“721,
1927.
Kermack, W. O. and McKendrick, A. G. Contributions to
the mathematical theory of epidemics. ii.â€”the problem
of endemicity. Proceedings of the Royal Society of London. Series A, containing papers of a mathematical and
physical character, 138(834):55â€“83, 1932.
Khaled, A. and RichtaÌrik, P. Better theory for sgd in the
nonconvex world, 2020.
Kingma, D. P. and Ba, J. Adam: A method for stochastic
optimization. arXiv preprint arXiv:1412.6980, 2014.
Kirby, T. New variant of sars-cov-2 in uk causes surge of
covid-19. The Lancet Respiratory Medicine, 2021. ISSN
2213-2600. doi: https://doi.org/10.1016/S2213-2600(21)
00005-9.
Kraemer, M. U., Yang, C.-H., Gutierrez, B., Wu, C.-H.,
Klein, B., Pigott, D. M., Du Plessis, L., Faria, N. R., Li,
R., Hanage, W. P., et al. The effect of human mobility
and control measures on the covid-19 epidemic in china.
Science, 368(6490):493â€“497, 2020.
Lei, Y., Hu, T., Li, G., and Tang, K. Stochastic gradient
descent for nonconvex learning without bounded gradient
assumptions. IEEE Transactions on Neural Networks and
Learning Systems, pp. 1â€“7, 2019.

Spatio-Temporal Neural Network for Fitting and Forecasting COVID-19

Leung, K., Wu, J., and Leung, G. Nowcasting and forecasting the wuhan 2019-ncov outbreak. Preprint published
by the School of Public Health of the University of Hong
Kong, 2020.
Li, Q., Guan, X., Wu, P., Wang, X., Zhou, L., Tong, Y.,
Ren, R., Leung, K. S., Lau, E. H., Wong, J. Y., et al.
Early transmission dynamics in wuhan, china, of novel
coronavirusâ€“infected pneumonia. New England Journal
of Medicine, 2020a.
Li, Z., Zheng, Y., Xin, J., and Zhou, G. A recurrent neural
network and differential equation based spatiotemporal
infectious disease model with application to covid-19.
arXiv preprint arXiv:2007.10929, 2020b.
Lin, Q., Zhao, S., Gao, D., Lou, Y., Yang, S., Musa, S. S.,
Wang, M. H., Cai, Y., Wang, W., Yang, L., et al. A conceptual model for the outbreak of coronavirus disease 2019
(covid-19) in wuhan, china with individual reaction and
governmental action. International journal of infectious
diseases, 2020.
Mizumoto, K. and Chowell, G. Transmission potential of
the novel coronavirus (covid-19) onboard the diamond
princess cruises ship, 2020. Infectious Disease Modelling,
2020.
Organization, W. H. et al. Who mers global summary and
assessment of risk, july 2019. Technical report, World
Health Organization, 2019.
Phan, L. T., Nguyen, T. V., Luong, Q. C., Nguyen, T. V.,
Nguyen, H. T., Le, H. Q., Nguyen, T. T., Cao, T. M., and
Pham, Q. D. Importation and human-to-human transmission of a novel coronavirus in vietnam. New England
Journal of Medicine, 382(9):872â€“874, 2020.
Reddi, S. J., Kale, S., and Kumar, S. On the convergence
of adam and beyond. arXiv preprint arXiv:1904.09237,
2019.
Rockett, R. J., Arnott, A., Lam, C., Sadsad, R., Timms, V.,
Gray, K.-A., Eden, J.-S., Chang, S., Gall, M., Draper,
J., et al. Revealing covid-19 transmission in australia by
sars-cov-2 genome sequencing and agent-based modeling.
Nature medicine, pp. 1â€“7, 2020.
Ross, R. The prevention of malaria. John Murray, 1911.
Ruder, S. An overview of gradient descent optimization
algorithms. arXiv preprint arXiv:1609.04747, 2016.
Sarkar, K., Khajanchi, S., and Nieto, J. J. Modeling and forecasting the covid-19 pandemic in india. Chaos, Solitons
& Fractals, 139:110049, 2020.

Shahid, F., Zameer, A., and Muneeb, M. Predictions for
covid-19 with deep learning models of lstm, gru and bilstm. Chaos, Solitons & Fractals, pp. 110212, 2020.
Tieleman, T. and Hinton, G. Lecture 6.5-rmsprop: Divide
the gradient by a running average of its recent magnitude.
COURSERA: Neural networks for machine learning, 4
(2):26â€“31, 2012.
Wu, J. T., Leung, K., and Leung, G. M. Nowcasting and forecasting the potential domestic and international spread of
the 2019-ncov outbreak originating in wuhan, china: a
modelling study. The Lancet, 395(10225):689â€“697, 2020.
Xie, J. and Zhu, Y. Association between ambient temperature and covid-19 infection in 122 cities from china.
Science of the Total Environment, 724:138201, 2020.
Xu, X., Chen, P., Wang, J., Feng, J., Zhou, H., Li, X., Zhong,
W., and Hao, P. Evolution of the novel coronavirus from
the ongoing wuhan outbreak and modeling of its spike
protein for risk of human transmission. Science China
Life Sciences, 63(3):457â€“460, 2020.
Yang, Z., Zeng, Z., Wang, K., Wong, S.-S., Liang, W., Zanin,
M., Liu, P., Cao, X., Gao, Z., Mai, Z., et al. Modified
seir and ai prediction of the epidemics trend of covid-19
in china under public health interventions. Journal of
Thoracic Disease, 12(3):165, 2020.
Ziat, A., Delasalles, E., Denoyer, L., and Gallinari, P. Spatiotemporal neural networks for space-time series forecasting and relations discovery. In 2017 IEEE International
Conference on Data Mining (ICDM), pp. 705â€“714. IEEE,
2017.

