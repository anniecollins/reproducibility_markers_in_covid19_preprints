Coronavirus (COVID-19) Classification using CT Images by Machine Learning Methods
Mucahid Barstugan1, Umut Ozkaya1, Saban Ozturk2
Electrical and Electronics Engineering, Konya Technical University1, Konya, Turkey
Electrical and Electronics Engineering, Amasya University1, Amasya, Turkey
Corresponding Author: mbarstugan@ktun.edu.tr
Abstract: This study presents early phase detection of Coronavirus (COVID-19), which is named by World Health
Organization (WHO), by machine learning methods. The detection process was implemented on abdominal
Computed Tomography (CT) images. The expert radiologists detected from CT images that COVID-19 shows
different behaviours from other viral pneumonia. Therefore, the clinical experts specify that COVÄ°D-19 virus needs
to be diagnosed in early phase. For detection of the COVID-19, four different datasets were formed by taking
patches sized as 16x16, 32x32, 48x48, 64x64 from 150 CT images. The feature extraction process was applied to
patches to increase the classification performance. Grey Level Co-occurrence Matrix (GLCM), Local Directional
Pattern (LDP), Grey Level Run Length Matrix (GLRLM), Grey-Level Size Zone Matrix (GLSZM), and Discrete
Wavelet Transform (DWT) algorithms were used as feature extraction methods. Support Vector Machines (SVM)
classified the extracted features. 2-fold, 5-fold and 10-fold cross-validations were implemented during the
classification process. Sensitivity, specificity, accuracy, precision, and F-score metrics were used to evaluate the
classification performance. The best classification accuracy was obtained as 99.68% with 10-fold cross-validation
and GLSZM feature extraction method.
Keywords: Classification, Coronavirus, COVID-19, CT images, Feature Extraction.

1. INTRODUCTION
COVID-19 disease was occurred in the end of 2019 at Wuhan region of China. COVID-19 disease showed fever,
cough, fatigue, and myalgias in human body during early phases (1). The patients had abnormal situations in their
CT chest images. The respiratory problems, heart damages, and secondary infection situations were observed as
complications of the disease. The findings showed that COVID-19 virus spreads from person to person. The infected
person needs to be treated in intensive care unit. The infected people have serious respiratory problems. The CT
images of the infected people shows that COVID-19 disease has own characteristics. Therefore, the clinical experts
need lung CT images to diagnose the COVID-19 in early phase.
The development of computer vision systems supports the medical applications such as increasing the
image quality, organ segmentation, and organ texture classification. The analysis of time series and tumor
characteristics (2), the segmentation and detection (3) of tumor modules are some of the machine learning
application in biomedical image processing field.
In the literature, there is not a detailed study on coronavirus disease. Xu et al. (4) classified CT images of
COVID-19 into three class as COVID-19, Influenza-A viral pneumonia, and healthy cases. They obtained the
images from the hospitals in Zhejiang region of China. The dataset consisted of total 618 images, which includes
219 images from 110 patients with COVID-19, 224 images of 224 patients with Influenza-A viral pneumonia, and
175 images of 175 healthy people. They classified the images with 3D-dimensional deep learning model and
achieved an 87.6% overall classification accuracy. Shan et al. (5) developed a deep learning based system for
segmenting and quantification the infected regions as well as the entire lung on chest CT images. They used 249
COVID-19 patients and 300 new COVID-19 patients for validation in their study. They obtained Dice similarity

1

coefficient as 91.6%. The normal delineation system often takes 1 to 5 hours; however, their proposed system
reduced the delineation time to four minutes.
This study used 150 CT images for COVID-19 classification. Before classification process, the four
different datasets were created from 150 CT images and the samples of datasets were labelled as coronavirus / noncoronavirus (infected / non-infected). Feature extraction methods and SVM are used during the classification of the
coronavirus images. The findings showed that the proposed method could be used to diagnose the COVID-19
disease as an assistant system.
This paper is organized as follows. Section 2 analyses the images statistically and visually. Section 3
briefly explains the feature extraction classification techniques. Section 4 presents the classification results. Section
5 discusses and concludes the results.

2. MATERIAL
2.1. Statistical Features of Dataset Used
The data consist of 150 CT abdominal images, which belong the 53 infected cases, from the Societa Italiana di
Radiologia Medica e Interventistica (6). The patch regions were cropped on 150 CT images. The patches were
extracted from the regions selected. Four different patch subsets were created and presented in Table 1.

Subset
Subset 1
Subset 2
Subset 3
Subset 4

Table 1. Four different subsets created from patch regions
Patch
Number of
Number of
Dimension
Non-Coronavirus Patches
Coronavirus Patches
16x16
5912
6940
32x32
942
1122
48x48
255
306
64x64
76
107

2.2. Visual Features of Dataset
The images in the dataset have acquired from different CT tools. This situation makes the classification process
difficult. Because, some grey-levels in one CT image represent the coronavirus infected areas. And the same greylevels in another CT image represent the non-infected areas. Figure 1 shows the infected areas in images that were
acquired from different CT tools.

Figure 1. The labelled infected areas on CT images

2

As seen in Figure 1, the grey levels are different in different CT tools. This situation is a disadvantage for
classification. Figure 2 shows the patch regions and patch samples from four different subsets.

Figure 2. Sample images for infected and non-infected situations for all subsets
3.

METHOD

This study performs a coronavirus classification in two stages. In the first stage, the classification process was
implemented on four different subsets without feature extraction process. The subsets were transformed into vector
and classified by SVM. In the second stage, five different feature extraction methods such as Grey Level Cooccurrence Matrix (GLCM) (7-9), Local Directional Patterns (LDP) (10), Grey Level Run Length Matrix (GLRLM)
(11), Grey Level Size Zone Matrix (GLSZM) (12), and Discrete Wavelet Transform (DWT) (13) extracted the
features and the features were classified by SVM (14). During the classification process, 2-fold, 5-fold, and 10-fold
cross-validation methods were used. The mean classification results after cross-validations were obtained. Figure 3
shows the two stages of classification process.

Figure 3. The classification process for Stage 1 and Stage 2

3

3.1. The Feature Extraction Techniques
The feature sets formed by using GLCM, LDP, GLRLM, GLSZM and DWT were used for classification of
coronavirus. The SVM classifier was used to classify the extracted features, because the SVM is a strong binary
classifier. The feature extraction methods used in this study are as follows:
ïƒ˜ Grey Level Co-occurrence Matrix
ïƒ˜ Local Directional Pattern
ïƒ˜ Grey Level Run Length Matrix
ïƒ˜ Grey Level Size Zone Matrix
ïƒ˜ Discrete Wavelet Transform

3.1.1. Grey Level Co-occurrence Matrix
GLCM is used to obtain the second-degree statistical features on the images. GLCM consists of the relationships of
different angles between the pixels of an image. Let a co-occurrence matrix that is obtained from an I image be
represented as P=[p(i, j | d, ÆŸ)]. At this point, the co-occurrence matrix is used to evaluate the ith pixel frequency
features with the jth neighbor pixel frequency features by considering the ÆŸ direction and d length. This study
selected d=1. And so the ÆŸ angle is taken as 0Â°. GLCM method extracted the angular secondary moment, contrast,
correlation, sum of squares: variance, inverse difference moment, sum average, sum variance, sum entropy, entropy,
difference entropy, difference variance, information measures of correlation 1, information measures of correlation
2, autocorrelation, dissimilarity, cluster shade, cluster prominence, maximum probability, and the inverse difference
features from all subsets (7-9). GLCM method produces 1x19 feature vector for classifier input.
3.1.2. Local Directional Pattern
LDP method uses Kirsch compass kernels to combine the directional elements (30). Let ic be density of an I image
on (xc, yc). Let in be the pixel density when the center pixel ic is outside of 3x3 neighbourhood of (xc, yc). LDP value
of (xc, yc) is computed as follows (10):

ğ‘Œğ‘Œğ‘Œğ‘ŒÅ(ğ‘¥ğ‘¥ğ‘ğ‘ , ğ‘¦ğ‘¦ğ‘ğ‘ ) = âˆ‘7ğ‘›ğ‘›=0 ğ‘ ğ‘ (ğ‘–ğ‘–ğ‘›ğ‘› âˆ’ ğ‘–ğ‘–ğ‘ğ‘ ) . 2ğ‘›ğ‘›
ğ‘ ğ‘ (ğ‘¥ğ‘¥) = ï¿½

1
0

(1)

ğ‘¤ğ‘¤â„ğ‘’ğ‘’ğ‘’ğ‘’ ğ‘¥ğ‘¥ â‰¥ 0
ğ‘œğ‘œğ‘œğ‘œâ„ğ‘’ğ‘’ğ‘’ğ‘’

(2)

LDP method produces output matrix sized as input image. This matrix is transformed into a vector for
classifier input.

3.1.3. Grey Level Run Length Matrix
GLRLM extracts texture features on a high level. Let L be the number of grey-levels, R is the longest run, and P is
the number of pixels in the image. A GLRLM matrix is LÃ—R, and each p(i,j | Î¸) element gives the number of
occurrences in the Î¸ direction with i grey level and j run length. GLRLM extracts the short-run emphasis, long-run
emphasis, grey-level non-uniformity, run-length non-uniformity, run percentage, low grey-level run emphasis, and

4

high grey-level run emphasis features from all subsets (11). GLRLM method produces 1x7 feature vector for
classifier input.

3.1.4 Grey Level Size Zone Matrix
GLSZM is a feature extraction method, which is developed version of GLRLM algorithm. GLSZM extracts the
small zone emphasis, long zone emphasis, grey-level non-uniformity, size zone non-uniformity, zone percentage, low
grey-level zone emphasis, high grey-level zone emphasis, small zone low grey-level emphasis, small zone high greylevel emphasis, large zone low grey-level emphasis, large zone high grey-level emphasis, grey-level variance, and
size zone variance features from all subsets (12). GLSZM method produces 1x13 feature vector for classifier input.

3.1.5 Discrete Wavelet Transform
DWT separates the image into frequency sub-bands by using an h low-pass filter and g high-pass filter.
Approximation coefficients (LL), horizontal details (LH), vertical details (HL), and diagonal details (HH) represent
the lowest frequency, horizontal high frequencies, vertical high frequencies, and high frequencies in both directions,
respectively (13). The feature set was created by LL coefficients, which has dimension of the half of input size, after
DWT. The LL coefficients were obtained by db1 wavelet, and the coefficient matrix were transformed into a feature
vector.
3.2. Support Vector Machines (SVMs)
SVM gives high classification accuracy in many applications. An SVM is based on two ideas. The first idea is to
map feature vectors to a high dimensional space with a nonlinear method and to use linear classifiers in this new
space. The second idea is to separate the data with a high margin hyperplane. This plane is the best plane, which can
separate the data as well as possible (14). The cost (C) parameter of SVM algorithm was taken as 1, which is default
value of the SVM algorithm for all classification processes.
4.

EXPERIMENTAL RESULTS

This study presents a coronavirus classification in two stages. Stage 1 classified subsets without feature extraction.
Stage 2 implemented feature extraction process on all subsets and classified the features extracted. Five different
evaluation metrics (Equations 3-7) were used to assess the proposed method. These metrics are sensitivity (SEN),
specificity (SPE), accuracy (ACC), precision (PRE), and F-score.
Sensitivity = TP / (TP+FN)
Specificity = TN / (TN+FP)
Accuracy = (TP + TN) / (TP + TN + FN+FP)
Precision = TP / (TP+FP)
F-score = (2*TP)/(2*TP+FP+FN)

(3)
(4)
(5)
(6)
(7)

TP, TN, FP, and FN values are the number of true positives, true negatives, false positives, and false negatives,
respectively (15).

5

4.1. Classification Results of Subset 1
Subset 1 has 5912 non-infected and 6940 infected patches. These patches were classified by Stage 1 and Stage 2.
Table 2 presents the obtained classification results.
Table 2. The classification results for Subset 1
Stage
Stage 1

Stage 2

Feature Number of
Extraction Features
x
256
x
256
x
256
GLCM
19
GLCM
19
GLCM
19
LDP
256
LDP
256
LDP
256
GLRLM
7
GLRLM
7
GLRLM
7
GLSZM
13
GLSZM
13
GLSZM
13
DWT
64
DWT
64
DWT
64

Crossvalidation
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold

Evaluation Metrics (mean (%) Â± std)
SEN
SPE
ACC
PRE
F-score
83.97Â±2.1 76.99Â±1 80.2Â±0.4 75.67Â±0.4 79.6Â±0.7
84.28Â±1.1 77.2Â±1.6 80.5Â±0.8 75.93Â±1.2 79.88Â±0.7
84.23Â±1.6 77.25Â±1.5 80.46Â±1 75.94Â±1.2 79.86Â±1
97.56Â±0.4 98.82Â±0.3 98.19Â±0.2 98.48Â±0.3 98.02Â±0.2
98.41Â±0.3 99.12Â±0.3 98.79Â±0.3 98.96Â±0.4 98.69Â±0.4
98.52Â±0.3 99.23Â±0.4 98.91Â±0.2 99.1Â±0.4 98.81Â±0.2
43.72Â±0.1 57.09Â±0.7 50.94Â±0.3 46.47Â±0.4 45.05Â±0.1
41.58Â±2.7 58.49Â±2.3 50.71Â±0.9 46.03Â±1.1 43.66Â±1.8
42.47Â±2.5 57.71Â±1.6 50.7Â±1.5 46.09Â±1.8 44.19Â±2.1
98.6Â±0.1 93.67Â±0.2 95.93Â±0.1 92.99Â±0.2 95.71Â±0.1
98.75Â±0.5 94.29Â±0.5 96.34Â±0.1 93.65Â±0.5 96.1Â±0.1
98.78Â±0.5 94.38Â±1 96.41Â±0.6 93.75Â±1.1 96.2Â±0.6
97.34Â±0.4 99.57Â±0.1 98.54Â±0.2 99.48Â±0.1 98.4Â±0.3
97.56Â±0.7 99.68Â±0.4 98.71Â±0.3 99.62Â±0.1 98.58Â±0.4
97.72Â±0.5 99.67Â±0.1 98.77Â±0.2 99.6Â±0.2 98.65Â±0.2
96.21Â±0.1 98.6Â±0.3 97.5Â±0.1 98.33Â±0.3 97.26Â±0.1
96.62Â±0.7 98.62Â±0.2 97.7Â±0.3 98.35Â±0.2 97.47Â±0.4
96.8Â±0.6 98.66Â±0.4 97.81Â±0.3 98.4Â±0.5 97.6Â±0.4

As seen in Table 2, the best classification result was obtained as 99.68% in Stage 2 with 10-fold crossvalidation and GLSZM feature extraction method.
4.2. Classification Results of Subset 2
Subset 2 has 942 non-infected and 1122 infected patches. These patches were classified by Stage 1 and Stage 2.
Table 3 presents the obtained classification results.

6

Table 3. The classification results for Subset 2
Stage
Stage 1

Stage 2

Feature Number of
Extraction Features
x
1024
x
1024
x
1024
GLCM
19
GLCM
19
GLCM
19
LDP
1024
LDP
1024
LDP
1024
GLRLM
7
GLRLM
7
GLRLM
7
GLSZM
13
GLSZM
13
GLSZM
13
DWT
256
DWT
256
DWT
256

Crossvalidation
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold

Evaluation Metrics (mean (%) Â± std)
SEN
SPE
ACC
PRE
F-score
82.6Â±0.6 77.99Â±0.6 80.09Â±0.1 75.9Â±0.4 79.1Â±0.1
83.23Â±2.5 80.31Â±3.1 81.64Â±2.2 78.07Â±2.8 80.54Â±2.3
83.65Â±2.6 79.94Â±3.2 81.64Â±1.9 77.87Â±2.67 80.62Â±1.9
97.55Â±0.5
99.11
98.4Â±0.2
98.92
98.2Â±0.2
97.77Â±0.7 99.38Â±0.2 98.64Â±0.4 99.24Â±0.3 98.5Â±0.5
97.77Â±1.6 99.47Â±0.5 98.69Â±0.8 99.35Â±0.6 98.55Â±0.9
43.82Â±1.1 54.55Â±2.3 49.66Â±1.7 44.76Â±1.8 44.3Â±1.4
43.1Â±4.4 51.4Â±2.3 47.6Â±3.8 42.7Â±4.1 42.88Â±4.2
42.03Â±4.9 52.49Â±3.9 47.72Â±1.9 42.56Â±2.4 42.22Â±3.4
54.77Â±1.2 78.7Â±2.1 67.78Â±0.6 68.38Â±1.7 60.81Â±0.1
58.69Â±4.9 78.25Â±1.1 69.33Â±2.1 69.32Â±1.8 63.5Â±3.6
60.29Â±5.4 77.99Â±2.5 69.91Â±2.8 69.65Â±3
64.57Â±4
90.23Â±0.9 94.47Â±0.3 92.54Â±0.3 93.2Â±0.2 91.7Â±0.4
90.77Â±2.6 94.48Â±1.8 92.78Â±1.1 93.29Â±1.9 91.98Â±1.3
91.5Â±1.9 95.01Â±1.5 93.41Â±1.1 93.93Â±1.8 92.69Â±1.2
98.72Â±0.3 99.55Â±0.1 99.18Â±0.2 99.47Â±0.2 99.09Â±0.7
98.94Â±0.5 99.64Â±0.4 99.32Â±0.3 99.57Â±0.4 99.25Â±0.3
99.15Â±1.1 99.55Â±0.8 99.37Â±0.6 99.47Â±0.9 99.31Â±0.7

Table 3 shows that the best classification result was obtained as 99.37% in Stage 2 with 10-fold crossvalidation and DWT feature extraction method.
4.3. Classification Results of Subset 3
Subset 3 has 255 non-infected and 306 infected patches. These patches were classified by Stage 1 and Stage 2. Table
4 presents the obtained classification results.
Table 4. The classification results for Subset 3
Stage
Stage 1

Stage 2

Feature Number of
Extraction Features
x
2304
x
2304
x
2304
GLCM
19
GLCM
19
GLCM
19
LDP
2304
LDP
2304
LDP
2304
GLRLM
7
GLRLM
7
GLRLM
7
GLSZM
13
GLSZM
13
GLSZM
13
DWT
576
DWT
576
DWT
576

Crossvalidation
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold

Evaluation Metrics (mean (%) Â± std)
SEN
SPE
ACC
PRE
71.37Â±0.4 70.26Â±0.5 70.77Â±0.1 66.67Â±0.3
72.94Â±8.9
74.2Â±4
73.62Â±3.5 70.2Â±3.1
74.54Â±10.5 73.55Â±9.9 73.99Â±7.1 70.62Â±8.9
96.07Â±2.2 99.67Â±0.5 98.04Â±0.8 99.6Â±0.6
96.47Â±3.7 99.67Â±0.7 98.22Â±1.7 99.61Â±0.9
96.52Â±4.9 99.67Â±1.1 98.22Â±2.2 99.63Â±1.2
40.78Â±0.2 55.23Â±1.4 48.66Â±0.9 43.16Â±0.8
41.57Â±9.6 56.19Â±5.3 49.55Â±5.4 43.86Â±6.9
39.66Â±7.6 56.6Â±8.6 48.8Â±4.8 43.37Â±5.9
53.3Â±8.6 79.74Â±1.8 67.73Â±2.9 68.57Â±1.6
56.47Â±6.9 80.08Â±5.2 69.34Â±3.2 70.54Â±5.6
57.63Â±9.6 80.12Â±5.9 69.89Â±5.5 70.72Â±7.6
94.5Â±3.4 97.06Â±2.3 95.9Â±0.3 96.49Â±2.6
95.29Â±4.9 98.37Â±1.6 96.97Â±1.5 98.08Â±1.9
95.26Â±5.3 98.67Â±2.3 97.15Â±2.3 98.52Â±2.6
98.43Â±1.1 99.67Â±0.5 99.11Â±0.3 99.61Â±0.6
98.82Â±1.1
100
99.47Â±0.5
100
99.23Â±2.4
100
99.64Â±1.1
100

7

F-score
68.99
71.35Â±5
72.19Â±7.8
97.8Â±0.9
97.97Â±1.9
97.98Â±2.6
41.94Â±0.5
42.57Â±8.1
41.14Â±5.9
59.85Â±6.1
62.48Â±4.8
63.22Â±8
95.43Â±0.4
96.57Â±1.8
96.76Â±2.7
99.01Â±0.3
99.41Â±0.5
99.6Â±1.3

Table 4 shows that the best classification result was obtained as 99.64% in Stage 2 with 10-fold crossvalidation and DWT feature extraction method.
4.4. Classification Results of Subset 4
Subset 3 has 76 non-infected and 107 infected patches. These patches were classified by Stage 1 and Stage 2. Table
5 presents the obtained classification results.
Table 5. The classification results for Subset 4
Stage
Stage 1

Stage 2

Feature Number of
Extraction Features
x
4096
x
4096
x
4096
GLCM
19
GLCM
19
GLCM
19
LDP
4096
LDP
4096
LDP
4096
GLRLM
7
GLRLM
7
GLRLM
7
GLSZM
13
GLSZM
13
GLSZM
13
DWT
1024
DWT
1024
DWT
1024

Crossvalidation
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold
2-fold
5-fold
10-fold

SEN
86.84Â±7.4
78.92Â±14.5
72.68Â±16.8
86.84Â±3.7
86.83Â±14.1
86.79Â±8.9
31.58Â±11.2
38.08Â±10.5
33.04Â±19.6
50Â±3.7
48.58Â±11.4
47.86Â±18.6
90.79Â±1.9
89.58Â±7.2
87.14Â±14.8
93.42Â±1.9
93.42Â±4.7
93.39Â±7

Evaluation Metrics (mean (%) Â± std)
SPE
ACC
PRE
74.74Â±4.3 79.78Â±0.6 71.05Â±1.5
73.94Â±7.3 75.96Â±3.5 68.51Â±4.1
76.6Â±15.2 74.88Â±9.4 70.97Â±12.7
97.18Â±1.4 92.9Â±0.7 95.71Â±1.8
98.18Â±2.5 93.47Â±6.2 96.93Â±4.3
98.1Â±4
93.45Â±3.5 97.64Â±4.9
68.23Â±2.2 52.99Â±3.5 40.7Â±6.7
66.28Â±10.3 54.67Â±6
45Â±6.7
64.6Â±11.6 51.32Â±12.5 38.85Â±19
80.33Â±6.9 67.75Â±2.6 64.92Â±6.1
80.52Â±7.1 67.28Â±8.5 63.64Â±14.6
79.36Â±8.6 66.17Â±11.1 61.75Â±15.6
84.05Â±9.5 86.87Â±4.7 80.82Â±8.9
92.47Â±7.9 91.29Â±5.8 90.44Â±9.9
94.45Â±8.8 91.22Â±10.1 91.9Â±12.4
94.41Â±2.6 93.99Â±3.5 92.24Â±3.5
98.18Â±2.5 96.17Â±1.6 97.41Â±3.5
100
97.28Â±2.9
100

F-score
78.04Â±2.1
72.74Â±6.1
70.51Â±10.8
91.02Â±1.2
91.18Â±8.9
91.53Â±4.8
35.41Â±9.7
40.74Â±9.7
35.09Â±18.9
56.29Â±0.1
55.08Â±12.7
53.25Â±16.4
85.33Â±4.2
89.71Â±6.2
89.05Â±12.6
92.82Â±2.7
95.26Â±1.9
96.46Â±3.7

Table 5 shows that the best classification result was obtained as 97.28% in Stage 2 with 10-fold crossvalidation and DWT feature extraction method.
Table 2, Table 3, Table 4 and Table 5 show that the best performance was obtained by extracting features on
patches. GLCM, GLSZM and DWT methods always had classification accuracy over 90% during 10-fold cross
validation. The best classification performance was achieved by using GLSZM method with 5-fold cross-validation.
The scheme of the best method is presented in Figure 4.

Figure 4. The optimum classifier structure for detection of the infected patches
As seen in Figure 4, the CT image was divided into 32x32 sized patches. GLSZM method extracts the features
of the patches and form feature vector. The vector is classified by five different SVM structures, which were
obtained during training phase. The mean classification performance is obtained by SVM classification.

8

5.

DISCUSSION and CONCLUSION

COVID-19 was firstly encountered at Wuhan region in China and have been threatening the public health, trade and
world economy. The virus shows the partially similar behaviours with other viral pneumonia. Therefore, the
spreading rate of the virus made the situation difficult to be under control. CT imaging results of COVID-19 show
that different findings according to other clinical studies. Some situations such as the bronchiectasis, lesion swelling
symptoms, and different shadowiness in CT images provide to diagnose COVID-19, easily.
In this study, the coronavirus image set has different type of images, which were acquired with different CT
tools. Therefore, five feature extraction methods were utilized to find the feature set that separates the infected
patches with a high accuracy. The dataset in this study was formed manually and achieved 99.68% classification
accuracy. The proposed method should be tested on another coronavirus CT image dataset.
The literature studies are mostly medical studies. The classification, segmentation studies may increase on
COVID-19 in the literature. This study examined COVID-19 images in the classification field. There should be done
more classification and segmentation studies on COVID-19. For this aim, the dataset diversion needs to be
increased. The machine learning methods should be implemented more on CT abdominal images, X-ray chest
images, blood test results when these data were shared to literature.
REFERENCES
1.
Huang C, Wang Y, Li X, Ren L, Zhao J, Hu Y, et al. Clinical features of patients infected with 2019 novel
coronavirus in Wuhan, China. The Lancet. 2020;395(10223):497-506.
2.
Huang P, Park S, Yan R, Lee J, Chu LC, Lin CT, et al. Added value of computer-aided CT image features
for early lung cancer diagnosis with small pulmonary nodules: a matched case-control study. Radiology.
2018;286(1):286-95.
3.
Esteva A, Kuprel B, Novoa RA, Ko J, Swetter SM, Blau HM, et al. Dermatologist-level classification of
skin cancer with deep neural networks. Nature. 2017;542(7639):115-8.
4.
Xu X, Jiang X, Ma C, Du P, Li X, Lv S, et al. Deep Learning System to Screen Coronavirus Disease 2019
Pneumonia. arXiv preprint arXiv:200209334. 2020.
5.
Shan+ F, Gao+ Y, Wang J, Shi W, Shi N, Han M, et al. Lung Infection Quantification of COVID-19 in CT
Images with Deep Learning. arXiv preprint arXiv:200304655. 2020.
6.
: Societa Italiana di Radiologia Medica e Interventistica; 2020 [Available from: https://www.sirm.org/.
7.
Clausi DA. An analysis of co-occurrence texture statistics as a function of grey level quantization.
Canadian Journal of remote sensing. 2002;28(1):45-62.
8.
Haralick RM, Shanmugam K, Dinstein IH. Textural features for image classification. IEEE Transactions on
systems, man, and cybernetics. 1973(6):610-21.
9.
Soh L-K, Tsatsoulis C. Texture analysis of SAR sea ice imagery using gray level co-occurrence matrices.
IEEE Transactions on geoscience and remote sensing. 1999;37(2):780-95.
10.
Chakraborti T, McCane B, Mills S, Pal U. Loop descriptor: Local optimal-oriented pattern. IEEE Signal
Processing Letters. 2018;25(5):635-9.
11.
Sohail ASM, Bhattacharya P, Mudur SP, Krishnamurthy S, editors. Local relative GLRLM-based texture
feature extraction for classifying ultrasound medical images. 2011 24th Canadian Conference on Electrical and
Computer Engineering (CCECE); 2011: IEEE.
12.
Thibault G, Angulo J, Meyer F. Advanced statistical matrices for texture characterization: application to
cell classification. IEEE Transactions on Biomedical Engineering. 2013;61(3):630-7.
13.
Shensa MJ. The discrete wavelet transform: wedding the a trous and Mallat algorithms. IEEE Transactions
on signal processing. 1992;40(10):2464-82.
14.
Kulkarni SR, Harman G. Statistical learning theory: a tutorial. Wiley Interdisciplinary Reviews:
Computational Statistics. 2011;3(6):543-56.

9

15.
Ruuska S, HÃ¤mÃ¤lÃ¤inen W, Kajava S, Mughal M, Matilainen P, Mononen J. Evaluation of the confusion
matrix method in the validation of an automated system for measuring feeding behaviour of cattle. Behavioural
processes. 2018;148:56-62.

10

