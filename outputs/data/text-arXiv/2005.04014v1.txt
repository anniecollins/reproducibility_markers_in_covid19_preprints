1

Convolutional Sparse Support Estimator Based
Covid-19 Recognition from X-ray Images
Mehmet YamacÃß1,3 , Mete Ahishali1 , Aysen Degerli1 , Serkan Kiranyaz2 , Muhammad E. H. Chowdhury2 , and
Moncef Gabbouj1

arXiv:2005.04014v1 [eess.IV] 8 May 2020

1

Tampere University, Faculty of Information Technology and Communication Sciences, Tampere, Finland
2
Department of Electrical Engineering, Qatar University, Qatar
3
Huawei Technologies Oy (Finland) Co. Ltd, Tampere, Finland

Abstract‚ÄîCoronavirus disease (Covid-19) has been the main
agenda of the whole world since it came in sight in December,
2019. It has already caused thousands of causalities and infected
several millions worldwide. Any technological tool that can be
provided to healthcare practitioners to save time, effort, and possibly lives has crucial importance. The main tools practitioners
currently use to diagnose Covid-19 are Reverse transcriptionpolymerase chain reaction (RT-PCR) and Computed Tomography
(CT), which require significant time, resources and acknowledged
experts. X-ray imaging is a common and easily accessible tool
that has great potential for Covid-19 diagnosis. In this study, we
propose a novel approach for Covid-19 recognition from chest Xray images. Despite the importance of the problem recent studies
in this domain produced not so satisfactory results due to the
limited datasets available for training. Recall that Deep Learning
techniques can generally provide state-of-the-art performance
in many classification tasks when trained properly over large
datasets, such data scarcity can be a crucial obstacle when
using them for Covid-19 detection. Alternative approaches such
as representation-based classification (collaborative or sparse
representation) might provide satisfactory performance with
limited size datasets, but they generally fall short in performance
or speed compared to Machine Learning methods. To address
this deficiency, Convolution Support Estimation Network (CSEN)
has recently been proposed as a bridge between model-based and
Deep Learning approaches by providing a non-iterative real-time
mapping from query sample to ideally sparse representation coefficient‚Äô support, which is critical information for class decision
in representation based techniques.
Main premises of this study can be summarized as follows:
(i) a benchmark X-ray dataset, namely QaTa-Cov19, containing
over 6200 X-ray images is created. Up to date, this is the largest
dataset covering 462 X-ray images from Covid-19 patients along
with three other classes; bacterial pneumonia, viral pneumonia,
and normal. (ii) In such a scarce and imbalanced dataset
the proposed CSEN based classification scheme equipped with
feature extraction from a state-of-the-art deep neural network
solution for X-ray images, CheXNet, achieves over 98% sensitivity
and over 95% specificity for Covid-19 recognition directly from
raw X-ray images without any pre- or post-processing. (iii)
Having such an elegant Covid-19 assistive diagnosis performance,
this study further provides solid evidence that Covid-19 induces
a unique pattern in X-rays that can be discriminated with a high
accuracy.
Index Terms‚ÄîCovid-19 Recognition, SARS-CoV-2 virus,
Transfer Learning, Representation based Classification.

I. I NTRODUCTION

C

ORONAVIRUS disease 2019 (Covid-19) has been declared as a pandemic by the World Health Organization

(WHO) two months after its first appearance in December,
2019 in Wuhan, China. It has infected more than 3 million people, caused thousands of causalities and has so far paralyzed
the mobility all around the World. The spreading rate of Covid19 is so high that the number of cases is expected to be doubled
every three days if the social distancing is not strictly observed
to slow this accretion [1]. Roughly around half of Covid19 positive patients exhibit also a comorbidity [2], making
difficult to differentiate Covid-19 from other lung diseases.
Automated and accurate Covid-19 diagnosis is critical for both
saving lives and preventing its rapid spread in the community.
Currently, RT-PCR (Reverse transcription polymerase chain
reaction) and CT (computed tomography) are the common
diagnosis techniques used today. RT-PCR results are ready
at the earliest 24 hours for critical cases and generally take
several days to conclude a decision [3]. CT may be an
alternative at initial presentation; however, it is expensive and
not easily accessible [4]. The most common tool that medical
experts use for both diagnostic and monitoring the course of
the disease is X-ray imaging. Compared to RT-PCR or CT
test, having an X-ray image is an extremely low cost and a
fast process, usually taking only few seconds. Recently, WHO
reported that even RT-PCR may give false results in Covid-19
cases due to several reasons such as poor quality specimen
from the patient, inappropriate processing of the specimen,
taking the specimen at an early or late stage of the disease [5].
For this reason, X-ray imaging has a great potential to be an
alternative technological tool to be used along with the other
tests for an accurate diagnosis.
Accordingly, there are several recent works [6], [7], [8], [9]
that have been proposed for Covid-19 detection/ classification
from X-ray images. However, they use a rather small dataset
(the largest containing only a few hundreds of X-ray images),
with only a few Covid-19 samples. This makes it difficult to
generalize their results in practice. To address this deficiency
and provide reliable results, in this study the researchers of
Qatar University and Tampere University have compiled the
largest Covid-19 dataset, called QaTa-Cov19. Compared to
the earlier benchmark dataset created in this domain, such
as COVID Chestxray Dataset [10] or Covid-19 DATASET
[11], QaTa-Cov19 has the followƒ±ng unique benchmarking
properties. First, it is the largest dataset, not only in terms of
the number of images (more than 6200 images) but its versa-

2

tility i.e., QaTa-Cov-19 contains additional major pneumonia
categories, such as Viral and Bacterial, along with the control
(normal) class. Moreover, this is the most diverse dataset
encapsulating X-ray images from several countries (e.g. Italy,
Spain, China, etc.) produced by different X-ray machines.
Finally, the images are in different quality, resolution and SNR
levels as shown in Fig. 1.

(a)

(b)

Fig. 2: Sample QaTa-Cov19 X-ray images: (a) X-ray images
from different classes. (b) X-ray images from the Covid-19
patients who are in the different stages.

Fig. 1: Sample Covid-19 X-ray images from QaTa-Cov19.
QaTa-Cov19 contains many X-ray images from the Covid19 patients who are in the early stages; therefore, their Xray images show mild or no-sign of Covid-19 infestation by
the naked eye. Some sample images are shown in Fig. 2-(b).
Another fact which makes the diagnosis far more challenging
is that inter-class similarity can be very high for many X-ray
images as some samples shown in Fig. 2-(a). Against such high
inter-class similarities and intra-class variations, in this study
we aim for a high robustness level. Our primary objective is
to achieve the highest sensitivity possible in the diagnosis of
Covid-19 induced pneumonia with an acceptable false-alarm
rate (e.g. specificity > 95%). In particular, the misdiagnosis of
a Covid-19 X-ray image as a normal case should be minimized
whilst a small number of false negatives is tolerable.
In numerous classification tasks, Deep Learning techniques
have been shown to achieve state-of-the-art performance in
term of both recognition accuracy and their parallelizable
computing structures which play an important role especially
in real-time applications. Despite their advantages, in order to
achieve a desired performance level in a deep model, a proper
training over a massive training dataset is usually needed.
Nevertheless, this is unfortunately not an option yet for this
problem since the available data is still rather limited.
An alternative supervised approach, which requires a limited
number of training samples to achieve satisfactory classification accuracy is representation-based classification [12],
[13], [14]. In representation-based classification systems, a
dictionary, whose columns consist of the training samples that
are stacked in such a way that a subset of them corresponding

to a class, is pre-defined. A test sample is expected to be a
linear combination of all points from the same class as the
test sample. Therefore, given a predefined dictionary matrix,
D and a test sample y, we expect the solution xÃÇ from y = Dx,
carry enough information about the class of y. The two
well-known representation based classification methodologies
are sparse representation-based classification (SRC) [13] and
collaborative representation based classification (CRC) [12].
Out of these two, SRC provides slightly improved accuracy
by solving a sparse representation problem, i.e., producing a
sparse solution xÃÇ from y = Dx. Then, the location of the
non-zero elements of xÃÇ, which is also known as support set,
provides us with the class of the query y. Despite improved
recognition accuracy, SRC solutions are iterative solutions
and can be computational demanding compared to CRC. In
a recent work [15], a compact neural network design that
can be considered as a bridge between learning-based and
representation-based methodologies was proposed. The socalled Convolutional Support Estimation Network (CSEN)
uses a pre-defined dictionary and learns a direct mapping using
moderate/low size training set, which maps query samples, y,
directly to the support set of representation coefficients, x (as
it should be purely sparse in the ideal case).
In this study, to address the aforementioned limitations in
Covid-19 diagnosis from X-ray images we propose a CSENbased approach. Since the largest set of Covid-19 X-ray
images ever compiled is used in this study, the proposed
approach can be evaluated rigorously against a high-level of
diversity to obtain a reliable analysis. The general pipeline of
the proposed CSEN based recognition scheme is illustrated
in Fig. 3. In order to obtain highly discriminative features,
we use the recently proposed CheXNet [16], which is the

3

fine-tuned version of 121 layer Dense Convolutional Network
(DenseNet-121) [17] by using over 100000 frontal view Xray images form 14 classes. Having the pre-trained CheXNet
for feature extraction, we develop two different strategies to
obtain the classes of query X-ray images: (i) using collaborative representation-based classification with a proper preprocessing; (ii) a slightly modified version of our recently
proposed convolution support estimator (CSEN) models. The
proposed CSEN scheme outperforms the competing methods
and achieves over 98% of sensitivity and over 95% for
specificity in this challenging dataset.
The rest of the paper is organized as follows. In Section II, notations and mathematical preliminaries are given
with emphasis on sparse representation and sparse support
estimation. Then in Section III, a literature review on deep
learning models over X-ray images and representation based
classification is presented. The proposed CSEN-based Covid19 recognition system is introduced in Section IV along
with two recent alternative approaches that are used as the
competing methods. The data collection is also explained
in this section. Experimental setup and the main results are
provided in Section V. Finally, Section VI concludes the paper
and suggests topics for future research.
II. P RELIMINARIES AND M ATHEMATICAL N OTATIONS
A. Notations
In this study, the `p -norm of a vector x ‚àà Rn is defined
Pn
p 1/p
as kxk`np = ( i=1 |xi | )
for p ‚â• 1. On the other hand,
the `0 -norm of the vector x ‚àà Rn is defined as kxk`n =
0
Pn
p
limp‚Üí0 i=1 |xi | = #{j : xj 6= 0} and the `‚àû -norm is
defined as kxk`n = maxi=1,...,n (|xi |). A signal s is called
‚àû
strictly k-sparse if kxk0 ‚â§ k. Sparse support set or simply
support set, Œõ ‚äÇ {1, 2, 3, ..., n} of sparse signal x can be
defined as the set of non-zero coefficients‚Äô location, i.e., Œõ :=
{i : xi = 0}.
B. Sparse Signal Representation
Sparse representation (SR) of a signal s ‚àà Rd in a predefined set of waveforms, Œ¶ ‚àà Rd√ón , can be defined as
representing s as a linear combination of only a small subset of
atoms of in the dictionary Œ¶, i.e, s = Œ¶x. Defining these sets,
which dates back to Fourier‚Äôs pioneering work [18], has been
excessively studied in the literature. In the early approaches,
these sets of waveforms have been selected as a collection
of linearly independent and generally orthogonal waveforms
(which are called a complete dictionary or basis i.e, d = n)
such as Fourier Transform, DCT and Wavelet Transform, until
the pioneering work of Mallat [19] on overcomplete dictionaries (n >> d). In the last decade, interest in SR research
increased tremendously and their wide range of applications
includes denoising [20], classification [21], anomaly detection
[22], [23], Deep Learning [24] and Compressive Sensing (CS)
[25], [26].
With a possible dimensional reduction that can be satisfied
via a compression matrix A ‚àà Rm√ód (m << d), sample can
be obtained from s,
y = As = AŒ¶x = Dx,

(1)

where D ‚àà Rm√ón can be called the equivalent dictionary.
Because Eq. (1) describes an under-determined system of
linear equations, finding the representation coefficient vector x
requires at least one more constraint to have a unique solution.
Using the prior information about sparsity, the following
representation
min kxk0 subject to Dx = y
x

(2)

which is also a sparse representation of x has a unique
solution provided that D satisfies some required properties
[27]. However, the optimization problem in Eq. (2) is a NPhard. Fortunately, the following relaxation
min kxk1 subject to Dx = y
x

(3)

produces exactly the same solution as that of Eq. (2) provided
that D obeys some criteria [28] and m > k(log(n/k)). In
addition, real world applications generally exhibit not exact
sparsity but approximate sparsity. Furthermore, the query
sample y can be corrupted with an additive noise pattern.
In this case, the equality constraint in Eq. (3) can be further
relaxed such as in the Basis Pursuit Denoising (BPDN) [29]:
minx kxk s.t. ky ‚àí Dxk ‚â§ , where  is a small constant that
depends on the noise level.
We may refer to the Sparse Support Estimation (SE) problem as finding the indices a set, Œõ, of non-zero elements of
x [30], [31]. Indeed, in many applications, SE can be more
important than finding the magnitude and sign of x as well
as Œõ, which refers to the sparse Signal Recovery (SSR) via a
recovery technique, such as Eq. (3). For example, in a sparse
representation based classification system, a query sample y
can be represented with sparse coefficient vector, x, in the
dictionary, D in such a way that when we recover this representation coefficient from y = Dx, the solution vector xÃÇ is
expected to have a significant number of non-zero coefficients
coming from the particular locations corresponding to the class
of y.
Readers are referred to [15] for more detailed literature
review on SE and its applications. In the sequel, we briefly
summarize the building blocks of the proposed approach.

III. BACKGROUND AND P RIOR A RT
A. CheXNet
In the proposed approach, we first use the pre-trained deep
network, CheXNet, to extract discriminative features from
raw X-ray images. CheXNet was developed for pneumonia
detection from the chest X-ray images [16]. In [16], it was
claimed that their CheXNet can perform even better than
expert radiologist in the pneumonia detection problem. This
deep neural network design is based on previously proposed
DenseNet [17] that consists of 121 layers. It is first pre-trained
over ImageNet dataset [32] and performed transfer learning
over 112120 frontal-view chest X-ray images in the ChestXray14 dataset [33].

4

Fig. 3: The proposed approach for Covid recognition from X-ray images. The proposed convolution support estimator network
(CSEN) which can be trained from a moderate size training set. The pipeline employs the pre-trained deep neural network
for feature extraction. A is the dimensional reduction (PCA) matrix, the coarse
‚àí1 Testimation of representation coefficient (sparse
in ideal case), xÃÇ is obtained via the denoiser matrix, B = DT D + ŒªI
D , where D = AŒ¶ and Œ¶ is the pre-defined
dictionary matrix of training samples (before dimensional reduction).

B. Representation Based Classification
Given a test sample y, which represents either the extracted features, s, or their dimensionally reduced version,
i.e., y = As. In developing the dictionary, training samples
are stacked in D with particular locations in such a way that
the optimal support for a given query y should be the set
of all points coming from the same class as y. Therefore, a
solution vector, xÃÇ of y = Dx is supposed to have enough
information, i.e., the sparse support should be the set of
location indices of the training sample from the same class
as y. This strategy is generally known as representation-based
classification. However, a typical solution xÃÇ of y = Dx is
not necessarily a sparse one especially when its size grows
with more training samples, which results in a highly underdetermined system of linear equations. Fortunately, if one
estimates the representation coefficient vector with a sparse
recovery design such as `1 -minimization as in Eq. (3), we
can expect that the important non-zero entries of the solution,
xÃÇ, are grouped in the particular locations that correspond to
the locations of the training samples from the same class as
y. This can be a typical example of scenarios where support
estimation can be more valuable than the magnitudes and sign
recovery as explained in Section II-B.
For instance, [14] proposed a systematic way of determining
the identity of face images using `1 -minimization. The authors
develop a three-step classification technique that includes: (i)
normalization of all the atoms in D and y to have unit
`2 -norm; (ii) estimating the representation coefficient vector
via sparse recovery, i.e., xÃÇ = arg minx kxk1 s.t ky ‚àí Dxk2 ;
and (iii) finding the residuals corresponding to each class via
ei = ky ‚àí Di xÃÇi k2 , where xÃÇi is the group of the estimated
coefficients, xÃÇ, that correspond to class i.
This technique, which is known as Sparse Representation
based Classification (SRC), and its variants have been applied
to a wide range of applications in literature [34], [35], e.g.,
human action recognition [36], and hyperspecral image classification [37], to name a few. Despite the good recognition
accuracy performance of SRC systems, their main drawbacks
is the fact that their sparse recovery algorithms (e.g., `1 -

minimization) is iterative methods and computationally costly,
rendering them infeasible in real time applications. Later,
the authors of [12] introduced Collaborative Representation
based Classification (CRC), which is similar to SRC except
for the use of traditional
`2 -minimizationo in the second step;
n
2
2
xÃÇ = arg minx ky ‚àí Dxk2 + Œª kxk2 . Thus, CRC does
not require an iterative solution to obtain representation coefficient thanks to that `2 -minimization
has a closed form solution,
‚àí1 T
xÃÇ = DT D + ŒªIn√ón
D y. Although, the sparsity in xÃÇ
cannot be guaranteed, it has often been reported to achieve
a comparable classification performance, especially in smallsize training datasets.
IV. P ROPOSED A PPROACH
A. The Benchmark Dataset: QaTa-Cov19
Covid-19 chest X-ray images were gathered from different publicly available but scattered image sources. However,
the major sources of Covid-19 images are Italian Society
of Medical and Interventional Radiology (SIRM) COVID-19
Database [11], Radiopaedia [38], Chest Imaging (Spain) at
thread reader [39] and online articles and news-portals. The
authors have carried out the task of collecting and indexing
the X-ray images for Covid-19 positive cases reported in the
published and preprint articles from China, South Korea, USA,
Taiwan, Spain, and Italy, as well as online news-portals (up
to 20th April 2020). Therefore, these X-ray images represent
different age groups, gender, ethnicity and country. Negative
Covid19 cases were normal, viral and bacterial pneumonia
chest X-ray images and collected from the Kaggle chest Xray database. Kaggle chest X-ray database contains 5863
chest X-ray images of normal, viral and bacterial pneumonia
with varying resolutions [40]. Out of these 5863 chest X-ray
images, 1583 images are normal images and the remaining are
bacterial and viral pneumonia images. Sample X-ray images
from QaTa-Cov19 dataset are shown in Fig. 6.
B. Feature Extraction
With their outstanding performance in image classification
along with other inference tasks, deep neural networks became

5

Fig. 4: Baseline Approach I: collaborative representation based classification is fed by deep learning based extracted features
that are pre-processed.

Fig. 5: Baseline Approach II: A 5-layer MLP layer is used over the features of CheXNet.

Section III-A. With the pre-trained model, we extract 1024long vectors, right after the last average pooling layer. After
data normalization (zero mean and unit variance), we obtain
a feature vector s ‚àà Rd=1024 .
A dimensionality reduction PCA is applied to s in order to
get the query sample, y = As ‚àà Rm , where A ‚àà Rm√ód is
PCA matrix (m < d).
C. The proposed CSEN-based Classification

Fig. 6: Samples from the benchmark QU-Chest dataset.

a dominant paradigm. However, these techniques usually necessitates a large number of training samples (e.g., several
hundred-thousand to millions depending on the network size)
to achieve an adequate generalization capability. That is to
say, the aforementioned problem of the data scarcity with
the Covid-19 case prevents us from training a deep learning
technique from scratch. Albeit, we can still leverage their
power by finding properly pre-trained models for similar
problems. To this end, we use a-state-of-the art pneumonia
detection network, CheXNet, whose details are summarized in

Considering the limited number of training data in our
Covid-19 dataset, a representation-based classification can be
applied hereafter to obtain the class of y using the dictionary
Œ¶ (in the form of D = AŒ¶), whose columns are stacked
training samples with class-specific locations.
As discussed earlier, sparse representation-based classification is a support estimation problem which is expected to be an
easier task than a sparse signal recovery problem. On the other
hand, even if the exact signal recovery is not possible in noisy
cases or in cases where xÃÇ is not exactly but approximately
sparse (which is the case in almost all the time in dictionarybased classification problems), it is still possible to recover the
support set exactly [9], [30], [41], [42] or partially [42], [43],
[44]. However, many works in the literature dealing with SE
problems tend to first apply a sparse recovery technique on y
to first get xÃÇ, then use simple thresholding over xÃÇ to obtain
a sparse support estimation, ŒõÃÇ. Nevertheless, SSR techniques
such as `1 -minimization are rather slow and their performance
varies from one SRR tool to another [15]. In our previous work
[15], we proposed an alternative solution for this handcrafted
sparse recovery approach which aims to learn a direct map
from test sample y to the support set ŒõÃÇ. Along with the speed
and stability compared to conventional SSR based techniques,
and recent deep learning based solutions to SRR problem,

6

CSEN has a crucial advantage of having a compact design
that can achieve a good performance level even over scarce
training data.
Mathematically speaking, an ideal CSEN is supposed to
n
yield a binary mask v ‚àà {0, 1} :

where xGi is the group of coefficients from the it h class.
In this manner, one possible cost function for a SE network
would be,
E(x) =

X

(PŒò (xÃÉ)p ‚àí vp )2 + Œª

p

vi = 1

if i ‚àà Œõ

(4)

which indicates the true support i.e., Œõ
=
{i ‚àà {1, 2, .., n} : vi = 1}. In order to approximate this
ideal case, a CSEN network, P (y, D) produces a probability
vector p which returns a measure about the probability
of each index being in Œõ such that pi ‚àà [0, 1]. Having
the estimated probability map, estimating the support can
easily be done via ŒõÃÇ = { i ‚àà { 1, 2, .., n} : pi > œÑ }, by
thresholding p with œÑ where œÑ is a fixed threshold.
A CSEN is composed of fully convolutional layers, and
as input it takes a proxy, xÃÉ, of sparse coefficient
‚àí1vector,
which is a coarse estimation of x i.e., DT D + ŒªI
DT y
T
or simply xÃÉ = D y. Using such a proxy of x, instead of
making inference directly on y has also studied in a few more
recent studies. For instance, In [45], [46], the authors proposed
reconstruction-free image classification from compressively
sensed images.
The input vector xÃÉ is reshaped to a 2-D plane in order to
use is with 2-D convolutional layers. This transformation is
performed via re-ordering the indices of the atoms in such a
way that the non-zero elements of the representation vector
x for a specific class come together in the 2-D plane. A
representative illustration of the proposed dictionary design
with compared to the traditional one is shown in Fig. 7.
Hereafter the proxy xÃÉ is convolved with the weight kernels,
connecting the input with the next layer with N filters to yield
the inputs of the next layer, with the biases b1 as follows:
f1 = {S(ReLu(bi1 + w1i ‚àó xÃÉ))}N
i=1 ,

(5)

where b1 is the weight bias, S(.) is the down- or up-sampling
operation and ReLu(x) = max(0, x). In more general form,
the k th feature map of layer l is defined as,
Nl‚àí1

flk

=

S(R E L U(bkl

+

X

ik

CONV 2D(wl

i
, fl‚àí1
,0 Z ERO PAD0 ))).

i=1

(6)
Therefore, the
trainable
parameters
of
CSEN
will
be:

i i N2
i
i NL
1
ŒòCSEN = {w1i , bi1 }N
i=1 , {w2 , b2 }i=1 , ...{wL , bL }i=1 for a
L layer CSEN design.
In developing the dictionary that is to be used in the sparse
representation based classification, the training samples are
stacked-in by grouping of them according to their classes.
Thus, instead of using traditional `1 -minimization formulation
as in Eq. (3), the following group `1 -minimization formulation
may result in increased classification accuracy,
(
min kDx ‚àí
x

2
yk2

+Œª

c
X
i=1

)
kxGi k2

(7)

c
X

kPŒò (xÃÉ)Gi k2 .

(8)

i=1

where PŒò (xÃÉ)p is network output at location p and vp is the
ground truth binary mask of the sparse code x. Due to its high
computational complexity, we approximate the cost function
in (8) with a simpler average pooling layer after convolutional
layer, which can produce directly the estimated class in our
CSEN design. An illustration of proposed CSEN-based Covid19 recognition is shown in Fig. 3.

Fig. 7: The illustration of proposed dictionary design vs.
conventional design in representation based classifiers.

D. Competing Methods
This section summarizes the competing methods that are
selected among numerous alternatives due to their superior
performance levels obtained in similar problems. For a fair
comparative evaluations, all classification methods have the
same input feature vectors fed to the proposed CSENs.
1) Collaborative representation-based classification: As a
possible competing technique to the proposed CSEN based
technique which is a hybrid method, CRC [12] is a direct
and representation-based classification method. It is a noniterative support estimation technique, that satisfies faster and
comparable classification performance with SRC while it is
more stable compared to existing iterative sparse recovery
tools as it is shown in [15]. In the first step of CRC, the
trade-off parameter of regularized least square solution is set
as Œª = 2 ‚àó 10‚àí12 .
2) Multi-layer Perceptron (MLP) classification: As one
of the most-common classifiers, a 4-hidden layer MLP is
used for this problem. For training we used Back-Propagation
(BP) with Adam optimization technique [47]. The network
and training hyper-parameters are as follows: learning rate,
Œ± = 10‚àí4 , and moment updates Œ≤1 = 0.9, Œ≤2 = 0.999, and 50
as the number of epochs. Fig. 8 illustrates the network configuration in detail. This network configuration has achieved the
best performance among others (deeper and shallower) where
deep configurations have suffered from over-fitting while the
shallow ones exhibit an inferior learning performance.
3) Support Vector Machines (SVMs): For a multi-class
problem, the first objective is to select the SVM topology for
ensemble learning: one-vs-one or one-vs-all. In order to find
the optimal topology and the hyper-parameters (e.g. kernel
type and its parameters) we first performed a grid-search with

7

with only 15 Back-Propagation epochs. Neither grid-search
nor any other parameter or configuration optimization was
performed for CSEN.
B. Experimental Results

Fig. 8: The MLP configuration.
the following variations and setting: kernel function {linear,
radial basis function (RBF)}, box constraint (C parameter) in
the range [1, 103 ] with log scale, and kernel scale (Œ≥ for the
RBF kernel) in the range [10‚àí4 , 10‚àí2 ] with log scale.
4) k-Nearest-Neighbor (k-NN): Finally, we use a traditional approach, k-Nearest Neighbor (k-NN) is used with
PCA dimensionality reduction. In a similar fashion, the distance metric and the k-value are optimized by a prior gridsearch. The following distance metrics are evaluated: Cityblock, Chebyshev, correlation, cosine, Euclidean, Hamming,
Jaccard, Mahalanobis, Minkowski, standardized Euclidean,
and Spearman metrics. The k-value is varied within the range
of [1, 4416] with log scale.
V. E XPERIMENTAL R ESULTS
A. Experimental Setup
We have performed our experiments over the QaTa-Cov19
dataset, which consists of normal and three pneumonia classes:
bacterial, viral, and Covid-19. The proposed approach is evaluated using a stratified 5-fold cross-validation (CV) scheme
with a ratio of 80% for training and 20% for the test (unseen
folds) splits, respectively.
Table II shows the number of X-ray images per class in
the QaTa-Cov19 dataset. Since the dataset is unbalanced, we
have applied data augmentation to the training set in order to
balance the size of each class in the train set. Therefore, the
X-ray images in viral and Covid-19 pneumonia, and normal
classes are augmented up to the same number as the bacterial
pneumonia class in the train set. We use Image Data Generator
by Keras to perform data augmentation by applying ZCA
whitening with epsilon of 10‚àí6 , randomly rotating the X-ray
images in a range of 10 degrees, randomly shifting images both
horizontally and vertically within the interval of [‚àí0.1, +0.1].
In each CV fold, we use a total of 8832 and 1257 images in
the train and test (unseen in the fold) sets, respectively.
The experimental evaluations of SVM, k-NN and CRC are
performed using MATLAB version 2019a, running on PC with
Intel R i7-8650U CPU and 32 GB system memory. On the
other hand, MLP and CSEN methods are implemented using
Tensorflow library [48] with Python on NVidia R TITAN-X
GPU card. For the CSEN training, ADAM optimizer [47] is
used with the proposed default learning parameters: learning
rate, Œ± = 10‚àí3 , and moment updates Œ≤1 = 0.9, Œ≤2 = 0.999

The same network configurations are used for CSEN as
in [15]. Accordingly, we use two compact CSEN designs:
CSEN1 and CSEN2, respectively. The first CSEN network
consists of only two hidden convolutional layers, the first
layer has 48 neurons and the second has 24. ReLu activation
function is used in the hidden layers and the filter size was
3√ó3. On the other hand CSEN2 uses max-pooling and has one
additional hidden layer with 24 neurons to perform transposedconvolution. CSEN1 and CSEN2 are compared against the 6
competing methods under the same experimental setup.
For the dictionary construction in Œ¶ each CSEN design, 625
images for each class (from the augmented training samples
per fold) are stacked in a such way that the representation coefficient in the 2-D plane, X has 50 √ó 50 size as
shown in Fig. 7. The rest of the images in the training set
are used to train each CSEN i.e., 1583 samples from each
class. We use PCA dimensional reduction matrix, A with
the compression ratio, CR = m
d = 0.5. Therefore, we have
512 √ó 2500 equivalent
dictionary,
D, and 2500 √ó 512 denoiser
‚àí1 T
B = DT D + ŒªI
D to obtain a coarse estimation of the
representation (sparse in ideal case) coefficients, xÃÉ ‚àà Rn=2500 .
Hereafter, the CSEN networks are trained to have class of y
from input xÃÉ as illustrated in Fig., 3.
Due to the lack of other learning-based SE studies in the
literature, we chose a deeper network compared to CSEN designs to investigate the role of network depth in this problem.
ReconNet [49] was proposed as a non-iterative deep learning
solution to compressive sensing problem i.e., sÃÇ ‚Üê P (y) and
it is one of the state-of-the-art in compressively sensed image
recognition task. It consists of 6 fully convolutional layers and
one dense layer in front of the convolutional ones, which act as
the learned denoiser for the mapping from y ‚àà Rm to sÃÉ ‚àà Rd .
Then, the convolutional layers are responsible for producing
the reconstructed signal, sÃÇ from sÃÉ. Therefore, by replacing this
dense layer with the denoiser matrix B, this network can be
used as a competing method.
Both CSEN and the modified ReconNet use xÃÉ as a input,
which is produced using an equivalent dictionary D and its
pseudo-inverse matrix B.
In designing the dictionary of CRC system, all training
samples are stacked in the dictionary, Œ¶, i.e., 2208 samples
from each class. The same PCA matrix used in CSEN based
recognition, A is applied to features, s ‚àà Rd=1024 . Therefore,
a dictionary D of size 512 √ó 8832 and the corresponding
denoiser matrix B of size 8832 √ó 512 are used in the CRC
framework.
The classification performance of the proposed CSEN-based
approach and the competing methods is presented in Table I.
As can be easily observed from the Table I, the proposed
approaches surpass all competing methods in Covid-19 recognition performance by achieving 98.5% sensitivity, and over
95% specificity. As shown in Table III, compared to MLP and

8

TABLE I: Classification Performances of the proposed CSEN and competing methods. The best Covid-19 recognition
(sensitivity) rates are highlighted.
Bacterial
NN
SVM
MLP
CRC
ReconNET
CSEN1
CSEN2

0.777
0.771
0.761
0.820
0.765
0.793
0.794

Viral
Normal
Accuracy
0.801
0.903
0.788
0.928
0.765
0.923
0.827
0.928
0.785
0.918
0.805
0.926
0.803
0.927

Covid-19

Bacterial

0.950
0.928
0.947
0.955
0.936
0.955
0.959

0.623
0.586
0.620
0.758
0.590
0.656
0.659

Viral
Normal
Sensitivity
0.612
0.899
0.632
0.911
0.561
0.885
0.550
0.922
0.625
0.891
0.642
0.906
0.646
0.904

Covid-19

Bacterial

0.965
0.981
0.965
0.968
0.970
0.985
0.985

0.898
0.916
0.872
0.869
0.902
0.901
0.900

Viral
Normal
Specificity
0.859
0.904
0.837
0.933
0.828
0.936
0.913
0.930
0.834
0.927
0.856
0.932
0.852
0.934

Covid-19
0.949
0.924
0.946
0.954
0.933
0.953
0.957

Fig. 9: False Negatives of proposed Covid-19 recognition scheme.
TABLE II: Number of images per class and per-fold before
and after data augmentation.
Class

# of Samples

Training
Samples

Augmented
Training Samples

Test
Samples

2760

2208

2208

552

1485

1188

2208

297

1579
462
6286

1263
370
5029

2208
2208
8832

316
92
1257

Bacterial
Pneumonia
Viral
Pneumonia
Normal
Covid-19
Total

vector multiplications. Furthermore, saving the trainable parameters (‚àº 16k) and a light dictionary matrix coefficients
(‚àº 1280k) in the test device is more memory efficient compared to saving coefficients (‚àº 4521k) of larger size dictionary
used in CRC.
TABLE V: Performance of CRC algorithm when the dictionary (size of 625 per class) that is used in CSEN is used.

Bacterial
Viral
Normal
Covid-19

TABLE III: The number of network parameters of each
method.

# of trainable
parameters

MLP

CSEN1

CSEN2

ReconNet

672,836

11,089

16,297

22,914

TABLE IV: Computation times (sec) of each method over
1257 test images.
CRC
(light)
Computation
Time (in sec.)

13.4176

CRC

CSEN1

CSEN2

ReconNet

MLP

40.7878

0.2196

0.2272

0.2993

0.2935

ReconNet, the proposed CSEN designs are very compact, and
computationally efficient. This is evident in Table IV where
the computational complexity (measured as total computation,
time over the 1257 test images) is reported.
When compared against CRC in particular, CSEN-based
classification has two advantages; computational efficiency
and, a superior Covid-19 recognition performance. The computational efficiency comes from the fact that a larger size
dictionary matrix (of size of 512 √ó 8832) is used in CRC and
hence, this requires more computations in terms of matrix-

Accuracy
0.8129
0.8163
0.9267
0.9564

CRC (Light)
Sensitivity
0.7464
0.5461
0.9170
0.9394

Specificity
0.8650
0.8998
0.9299
0.9578

For further analysis, we also tested the CRC framework
by using the light dictionary (of size 512 √ó 2500) used in
CSEN based recognition. We called it CRC (light), and as
it can be seen in Table V, the performance of CRC further
reduced, and there was no significant improvement concerning
the computational cost. When it comes to creating deeper
convolutional layers instead of using CSEN designs, such
as the modified ReconNet, the results presented in Table I
shows us that compact CSEN structures are indeed preferable
to achieve superior classification performances compared to
deeper networks.
TABLE VI: The overall (cumulative) confusion matrix of the
proposed recognition scheme.
CSEN2

Real

Bacterial
Viral
Normal
Covid-19

Bacterial
1818
338
15
0

Predicted
Viral
636
959
71
3

Normal
180
127
1428
4

Covid-19
126
61
65
455

Finally, Table VI presents the overall (cumulative) confusion

9

matrix of the proposed CSEN-based Covid-19 recognition
approach over the new QaTa-Cov19 Dataset. The most critical
mis-classifications are the false-positives, that is, the misclassified Covid-19 X-ray images. The confusion matrix shows
that the proposed approach has mis-classified 7 Covid-19
images (out of 462). The 3 out of 7 misclassifications are
still in ‚ÄúViral Pneumonia‚Äù category, which can be an expected
confusion due to the viral nature of Covid-19. However, the
other four cases are mis-classified as ‚ÄúNormal‚Äù which is indeed
a severe clinical misdiagnosis. A close look to these falsenegatives in Fig. 9 reveals the fact that they are indeed very
similar to normal images where typical Covid-19 patterns are
hardly visible even by an expert‚Äôs naked eye. It is possible
that these images come from the patients who were in the
very early stages of Covid-19.
VI. C ONCLUSIONS
The commonly used methods in Covid-19 diagnosis, namely
Reverse Transcription-Polymerase Chain Reaction and Computed Tomogrophy have certain limitations and drawbacks
such as long processing times and unacceptably high misdiagnosis rates. These drawbacks are also shared by most
of the recent works in the literature based on deep learning
due to the data scarcity from the Covid-19 cases. Although
Deep Learning based recognition techniques are dominant in
Computer Vision where they achieved state-of-the-art performance, their performance degrades fast due to data scarcity,
which is the reality in this problem at hand. This study
aims to address such limitations by proposing a robust and
highly accurate Covid-19 recognition approach directly from
raw X-ray images without any pre- or post-processing. The
proposed approach is based on the CSEN that can be seen as
a bridge between Deep Learning models and representationbased methods. CSEN uses both a dictionary and a set of
training samples to train direct map from the query samples to
the sparse support set of representation coefficients. With this
unique ability and having the advantage of a compact network,
the proposed CSEN-based Covid-19 recognition systems surpass the competing methods and achieve over 98% sensitivity and over 95% specificity. Furthermore, they yield the
most computationally efficient scheme in terms of speed and
memory. Finally, the largest dataset of X-ray images, QaTaCov19 will be released along with this study as a benchmark
dataset in this domain. This will, henceforth, accelerate the
research efforts globally and support the fight against Covid19 worldwide.
R EFERENCES
[1] L. Pellis, F. Scarabel, H. B. Stage, C. E. Overton, L. H. Chappell,
K. A. Lythgoe, E. Fearon, E. Bennett, J. Curran-Sebastian, R. Das et al.,
‚ÄúChallenges in control of covid-19: short doubling time and long delay
to effect of interventions,‚Äù arXiv preprint arXiv:2004.00117, 2020.
[2] F. Zhou, T. Yu, R. Du, G. Fan, Y. Liu, Z. Liu, J. Xiang, Y. Wang,
B. Song, X. Gu et al., ‚ÄúClinical course and risk factors for mortality of
adult inpatients with covid-19 in wuhan, china: a retrospective cohort
study,‚Äù The Lancet, 2020.
[3] Y. Fang, H. Zhang, J. Xie, M. Lin, L. Ying, P. Pang, and W. Ji,
‚ÄúSensitivity of chest ct for covid-19: comparison to rt-pcr,‚Äù Radiology,
p. 200432, 2020.

[4] K. A. Erickson, K. Mackenzie, and A. Marshall, ‚ÄúAdvanced but expensive technology. balancing affordability with access in rural areas.‚Äù
Canadian family physician Medecin de famille canadien, vol. 39, pp.
28‚Äì30, 1993.
[5] W. H. Organization et al., ‚ÄúLaboratory testing for coronavirus disease
2019 (covid-19) in suspected human cases: interim guidance, 2 march
2020,‚Äù World Health Organization, Tech. Rep., 2020.
[6] M. E. Chowdhury, T. Rahman, A. Khandakar, R. Mazhar, M. A. Kadir,
Z. B. Mahbub, K. R. Islam, M. S. Khan, A. Iqbal, N. Al-Emadi et al.,
‚ÄúCan ai help in screening viral and covid-19 pneumonia?‚Äù arXiv preprint
arXiv:2003.13145, 2020.
[7] I. D. Apostolopoulos and T. A. Mpesiana, ‚ÄúCovid-19: automatic detection from x-ray images utilizing transfer learning with convolutional
neural networks,‚Äù Physical and Engineering Sciences in Medicine, p. 1,
2020.
[8] L. O. Hall, R. Paul, D. B. Goldgof, and G. M. Goldgof, ‚ÄúFinding covid19 from chest x-rays using deep learning on a small dataset,‚Äù arXiv
preprint arXiv:2004.02060, 2020.
[9] M. Wainwright, ‚ÄúInformation-theoretic bounds on sparsity recovery in
the high-dimensional and noisy setting,‚Äù in 2007 IEEE International
Symposium on Information Theory. IEEE, 2007, pp. 961‚Äì965.
[10] J. P. Cohen, P. Morrison, and L. Dao, ‚ÄúCovid-19 image data collection,‚Äù
arXiv preprint arXiv:2003.11597, 2020.
[11] ‚ÄúCovid-19 database,‚Äù 2020. [Online]. Available: https://www.sirm.org/
category/senza-categoria/covid-19/
[12] L. Zhang, M. Yang, and X. Feng, ‚ÄúSparse representation or collaborative
representation: Which helps face recognition?‚Äù in 2011 International
conference on computer vision. IEEE, 2011, pp. 471‚Äì478.
[13] J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and Y. Ma, ‚ÄúRobust
face recognition via sparse representation,‚Äù IEEE transactions on pattern
analysis and machine intelligence, vol. 31, no. 2, pp. 210‚Äì227, 2008.
[14] J. Wright, Y. Ma, J. Mairal, G. Sapiro, T. S. Huang, and S. Yan, ‚ÄúSparse
representation for computer vision and pattern recognition,‚Äù Proceedings
of the IEEE, vol. 98, no. 6, pp. 1031‚Äì1044, 2010.
[15] M. Yamac, M. Ahishali, S. Kiranyaz, and M. Gabbouj, ‚ÄúConvolutional
sparse support estimator network (csen) from energy efficient support estimation to learning-aided compressive sensing,‚Äù arXiv preprint
arXiv:2003.00768, 2020.
[16] P. Rajpurkar, J. Irvin, K. Zhu, B. Yang, H. Mehta, T. Duan, D. Ding,
A. Bagul, C. Langlotz, K. Shpanskaya et al., ‚ÄúChexnet: Radiologistlevel pneumonia detection on chest x-rays with deep learning,‚Äù arXiv
preprint arXiv:1711.05225, 2017.
[17] G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, ‚ÄúDensely
connected convolutional networks,‚Äù in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 4700‚Äì4708.
[18] O. D. Escoda, L. Granai, and P. Vandergheynst, ‚ÄúMeÃÅmoire sur la
propagation de la chaleur dans les corps solides,‚Äù Nouveau Bulletin des
Sciences de la SocieÃÅteÃÅ Philomathique de Paris 6, pp. 112‚Äì116, 1808.
[19] S. G. Mallat and Z. Zhang, ‚ÄúMatching pursuits with time-frequency
dictionaries,‚Äù IEEE Transactions on signal processing, vol. 41, no. 12,
pp. 3397‚Äì3415, 1993.
[20] J.-L. Starck, E. J. CandeÃÄs, and D. L. Donoho, ‚ÄúThe curvelet transform
for image denoising,‚Äù IEEE Transactions on image processing, vol. 11,
no. 6, pp. 670‚Äì684, 2002.
[21] J. Yang, K. Yu, Y. Gong, T. S. Huang et al., ‚ÄúLinear spatial pyramid
matching using sparse coding for image classification.‚Äù in CVPR, vol. 1,
no. 2, 2009, p. 6.
[22] A. Adler, M. Elad, Y. Hel-Or, and E. Rivlin, ‚ÄúSparse coding with
anomaly detection,‚Äù Journal of Signal Processing Systems, vol. 79, no. 2,
pp. 179‚Äì188, 2015.
[23] D. Carrera, G. Boracchi, A. Foi, and B. Wohlberg, ‚ÄúDetecting anomalous
structures by convolutional sparse models,‚Äù in 2015 International Joint
Conference on Neural Networks (IJCNN). IEEE, 2015, pp. 1‚Äì8.
[24] W. Wen, C. Wu, Y. Wang, Y. Chen, and H. Li, ‚ÄúLearning structured
sparsity in deep neural networks,‚Äù in Advances in neural information
processing systems, 2016, pp. 2074‚Äì2082.
[25] D. L. Donoho et al., ‚ÄúCompressed sensing,‚Äù IEEE Transactions on
information theory, vol. 52, no. 4, pp. 1289‚Äì1306, 2006.
[26] E. J. CandeÃÄs et al., ‚ÄúCompressive sampling,‚Äù in Proceedings of the
International Congress of Mathematicians, vol. 3, 2006, pp. 1433‚Äì1452.
[27] D. L. Donoho and M. Elad, ‚ÄúOptimally sparse representation in general
(nonorthogonal) dictionaries via ell1 minimization,‚Äù Proceedings of the
National Academy of Sciences, vol. 100, no. 5, pp. 2197‚Äì2202, 2003.
[28] E. J. Candes, ‚ÄúThe restricted isometry property and its implications for
compressed sensing,‚Äù Comptes rendus mathematique, vol. 346, no. 9-10,
pp. 589‚Äì592, 2008.

10

[29] S. S. Chen, D. L. Donoho, and M. A. Saunders, ‚ÄúAtomic decomposition
by basis pursuit,‚Äù SIAM review, vol. 43, no. 1, pp. 129‚Äì159, 2001.
[30] W. Wang, M. J. Wainwright, and K. Ramchandran, ‚ÄúInformationtheoretic limits on sparse support recovery: Dense versus sparse measurements,‚Äù in 2008 IEEE International Symposium on Information
Theory. IEEE, 2008, pp. 2197‚Äì2201.
[31] J. Haupt and R. Baraniuk, ‚ÄúRobust support recovery using sparse
compressive sensing matrices,‚Äù in 2011 45th Annual Conference on
Information Sciences and Systems. IEEE, 2011, pp. 1‚Äì6.
[32] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, ‚ÄúImagenet:
A large-scale hierarchical image database,‚Äù in 2009 IEEE conference on
computer vision and pattern recognition. Ieee, 2009, pp. 248‚Äì255.
[33] X. Wang, Y. Peng, L. Lu, Z. Lu, M. Bagheri, and R. M. Summers,
‚ÄúChestx-ray8: Hospital-scale chest x-ray database and benchmarks on
weakly-supervised classification and localization of common thorax
diseases,‚Äù in Proceedings of the IEEE conference on computer vision
and pattern recognition, 2017, pp. 2097‚Äì2106.
[34] S. Shekhar, V. M. Patel, N. M. Nasrabadi, and R. Chellappa, ‚ÄúJoint
sparse representation for robust multimodal biometrics recognition,‚Äù
IEEE Transactions on Pattern Analysis and Machine Intelligence,
vol. 36, no. 1, pp. 113‚Äì126, 2013.
[35] X. Mei and H. Ling, ‚ÄúRobust visual tracking and vehicle classification
via sparse representation,‚Äù IEEE transactions on pattern analysis and
machine intelligence, vol. 33, no. 11, pp. 2259‚Äì2272, 2011.
[36] T. Guha and R. K. Ward, ‚ÄúLearning sparse representations for human
action recognition,‚Äù IEEE Transactions on Pattern Analysis and Machine
Intelligence, vol. 34, no. 8, pp. 1576‚Äì1588, 2011.
[37] W. Li and Q. Du, ‚ÄúA survey on representation-based classification and
detection in hyperspectral remote sensing imagery,‚Äù Pattern Recognition
Letters, vol. 83, pp. 115‚Äì123, 2016.
[38] 2020. [Online]. Available: https://radiopaedia.org/playlists/25975?lang=
us
[39] 2020.
[Online].
Available:
https://threadreaderapp.com/thread/
1243928581983670272.html
[40] P. Mooney, ‚ÄúChest x-ray images (pneumonia),‚Äù kaggle, Marzo,
2018. [Online]. Available: https://www.kaggle.com/paultimothymooney/
chest-xray-pneumonia
[41] K. R. Rad, ‚ÄúNearly sharp sufficient conditions on exact sparsity pattern
recovery,‚Äù IEEE Transactions on Information Theory, vol. 57, no. 7, pp.
4672‚Äì4679, 2011.
[42] J. Scarlett and V. Cevher, ‚ÄúLimits on support recovery with probabilistic
models: An information-theoretic framework,‚Äù IEEE Transactions on
Information Theory, vol. 63, no. 1, pp. 593‚Äì620, 2016.
[43] G. Reeves and M. Gastpar, ‚ÄúSampling bounds for sparse support recovery in the presence of noise,‚Äù in 2008 IEEE International Symposium
on Information Theory. IEEE, 2008, pp. 2187‚Äì2191.
[44] G. Reeves and M. C. Gastpar, ‚ÄúApproximate sparsity pattern recovery:
Information-theoretic lower bounds,‚Äù IEEE Transactions on Information
Theory, vol. 59, no. 6, pp. 3451‚Äì3465, 2013.
[45] A. DegÃÜerli, S. Aslan, M. Yamac, B. Sankur, and M. Gabbouj, ‚ÄúCompressively sensed image recognition,‚Äù in 2018 7th European Workshop
on Visual Information Processing (EUVIP). IEEE, 2018, pp. 1‚Äì6.
[46] S. Lohit, K. Kulkarni, and P. Turaga, ‚ÄúDirect inference on compressive
measurements using convolutional neural networks,‚Äù in 2016 IEEE
International Conference on Image Processing (ICIP), Sep. 2016, pp.
1913‚Äì1917.
[47] D. P. Kingma and J. Ba, ‚ÄúAdam: A method for stochastic optimization,‚Äù
arXiv preprint arXiv:1412.6980, 2014.
[48] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S.
Corrado, A. Davis, J. Dean, M. Devin et al., ‚ÄúTensorflow: Large-scale
machine learning on heterogeneous distributed systems,‚Äù arXiv preprint
arXiv:1603.04467, 2016.
[49] K. Kulkarni, S. Lohit, P. Turaga, R. Kerviche, and A. Ashok, ‚ÄúReconnet: Non-iterative reconstruction of images from compressively sensed
measurements,‚Äù in Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, 2016, pp. 449‚Äì458.

