Exploring the Effect of Image Enhancement Techniques on COVIDâ€19
Detection using Chest Xâ€rays Images
Tawsifur Rahman1, Amith Khandakar2, Yazan Qiblawey2, Anas Tahir2, Serkan Kiranyaz2, Saad
Bin Abul Kashem3, Mohammad Tariqul Islam4, Somaya Al Maadeed5, Susu M Zughaier6,
Muhammad Salman Khan7, Muhammad E. H. Chowdhury*2
Department of Biomedical Physics & Technology, University of Dhaka Dhakaâ€1000, Bangladesh;
tawsifurrahman@bmpt.du.ac.bd,

1

Department of Electrical Engineering, Qatar University, Dohaâ€2713, Qatar; mchowdhury@qu.edu.qa (MEHC),
amitk@qu.edu.qa (AK), yazan.qiblawey@qu.edu.qa (YQ), a.tahir@qu.edu.qa (AT), mkiranyaz@qu.edu.qa (SK)

2

Faculty of Robotics and Advanced Computing, Qatar Armed Forcesâ€Academic Bridge Program, Qatar Foundation, Dohaâ€
24404, Qatar; Skashem@qf.org.qa (SBAK)

3

4

Dept. of Electrical, Electronics and Systems Engineering, Universiti Kebangsaan Malaysia, Bangi, Selangor 43600,
Malaysia; tariqul@ukm.edu.my (MTI)

Department of Computer Science and Engineering, Qatar University, Dohaâ€2713, Qatar; s_alali@qu.edu.qa (SAM)

5

Department of Basic Medical Sciences, College of Medicine, Biomedical and Pharmaceutical Research Unit, QU Health,
Qatar University, Dohaâ€2713, Qatar; szughaier@qu.edu.qa (SMZ)

6

Department of Electrical Engineering (JC), University of Engineering and Technology, Peshawar, Pakistan;

7

salmankhan@uetpeshawar.edu.pk (MSK)

Abstract
The use of computer-aided diagnosis in the reliable and fast detection of corona virus disease (COVID-19)
has become a necessity to prevent the spread of the virus during the pandemic to ease the burden on the
medical infrastructure. Chest X-ray (CXR) imaging has several advantages over other imaging techniques
as it is cheap, easily accessible, fast and portable. CXR images are sometimes of poor quality and so image
enhancement techniques can help the machine learning models to extract valuable discriminating features
from the image. Numerous works have been reported on COVID-19 detection from smaller set of original
X-ray images. However, the effect of image enhancement in COVID-19 detection was not reported in the
literature. This paper explores the effect of various popular image enhancement techniques and states the

*

Correspondence: mchowdhury@qu.edu.qa; Tel.: +974 3101 0775

effect of each of them on the detection performance. We have compiled the largest X-ray dataset called
COVQU-20, consisting of 18,479 normal, non-COVID lung opacity and COVID-19 CXR images. To the
best of our knowledge, this is the largest public COVID positive database. Ground glass opacity is the
common symptom reported in COVID-19 pneumonia patients and so a mixture of 3616 COVID-19, 6012
non-COVID lung opacity, and 8851 normal chest X-ray images were used to create this dataset. Five
different image enhancement techniques: histogram equalization (HE), contrast limited adaptive histogram
equalization (CLAHE), image complement, gamma correction, and Balance Contrast Enhancement
Technique (BCET) were used to improve COVID-19 detection accuracy. Six different Convolutional
Neural Networks (CNNs) (ResNet18, ResNet50, ResNet101, InceptionV3, DenseNet201, and ChexNet)
were investigated in this study. Gamma correction technique outperforms other enhancement techniques
in detecting COVID-19 from standard and segmented lung CXR images. The accuracy, precision,
sensitivity, f1-score, and specificity in the detection of COVID-19 with gamma correction on CXR images
were 96.29%, 96.28%, 96.29%, 96.28% and 96.27% respectively. Classification performance using
segmented lungs X-ray images slightly decreased however, the reliability of network performance
significantly improved, which was observed using visualization technique. The accuracy, precision,
sensitivity, F1-score, and specificity were 95.11 %, 94.55 %, 94.56 %, 94.53 % and 95.59 % respectively
for segmented lung images. The enhancement techniques were also compared in terms of the time taken
by the network while using each of these techniques. The proposed approach with very high and
comparable performance will boost the fast and robust COVID-19 detection using chest X-ray images.

1. Introduction
Coronavirus Disease 2019 (COVIDâ€19) pandemic with the exponential infection rate has
overloaded worldwide healthcare systems [1]. Currently, there are more than sixteen million active
Preprint submitted to Elsevier

November 25, 2020

cases and more than one million deaths in the world, as of November 2020 [2]. COVIDâ€19 diagnosis
is carried out by Reverse Transcription Polymerase Chain Reaction (RTâ€PCR), which suffers from low
accuracy, delay and low sensitivity [1, 3, 4]. Early diagnosis of a disease increases the chances for
successful treatment of infected patients and also reduces the chances of spreading in the community
for a contagious disease like COVIDâ€19. Radiography images such as chest Xâ€ray (CXR) or Computed
tomography (CT) are routine technique for diagnosing lung related diseases such as pneumonia [5],
Tuberculosis[6] and can be useful in COVIDâ€19 detection as well [7, 8]. One of the advantages of CXR
is the ability to perform them easily using portable Xâ€ray machines providing faster, accurate COVIDâ€
19 diagnosis [7, 9â€11]. CXRs are found to be potential for detecting COVIDâ€19 with the help of
artificial intelligence (AI), and are also less harmful for human body compared to CT [7, 9â€11].

Recently, a large number of works have been carried out to detect COVIDâ€19 using Xâ€ray images
with the help of AI models. Ioannis et al. [12] reported 96.78 % accuracy for COVIDâ€19 from Bacterial
Pneumonia and Normal Xâ€rays in a dataset of 1427 Xâ€ray. Similarly, Abbas et al. [13] reported an
accuracy of 95.12 % for COVIDâ€19 classification from COVIDâ€19, Normal and SARS CXRâ€™s using their
preâ€trained CNN model (DeTraC Decompose, Transfer and Compose) with a small database of 196
Xâ€ray images. Minaee et al. [14] reported a specificity and sensitivity of 90% and 97 % respectively
using ChexPert dataset [15]. These results showed the potential of using CNN to distinguish COVIDâ€
19 from other lung diseases using CXR images. Khan et al. [16] explored limited number of machine
learning algorithms for a four class classification problem (COVIDâ€19, Bacterial Pneumonia, Viral
Pneumonia and Normal) with a very small dataset. Ashfar et al. [17] reported an accuracy of 95.7 %
using a Capsule Networks, called COVIDâ€CAPS rather than a conventional CNN to deal with a
smaller dataset. Some researchers have created a small dataset of COVIDâ€19 CXR images to train
machine learning models for automatic COVIDâ€19 detection [11, 18]. The datasets consist of COVIDâ€
Preprint submitted to Elsevier

November 25, 2020

19 Xâ€ray and CT images taken from the published articles. Goldstein et al. [19] built a classifier to
detect COVIDâ€19 using preâ€trained deep learning model (ReNet50) and enhanced by data
augmentation and lung segmentation with the help of 2362 frontal CXR images collected from four
hospitals in Israel and achieved 89.7 %, 87.1 % accuracy and sensitivity respectively. Wang and Wong
[20] on the other hand used around 14k CXRs but reported only 83.5 % accuracy using a deep CNN,
called COVIDâ€Net. Motamed et al. [21] proposed a randomized generative adversarial network
(RANDGAN) that detects images of an unknown class (COVIDâ€19) from known and labelled classes
(Normal and Viral Pneumonia) without the need for labels and training data from the unknown class
of images (COVIDâ€19) using 14,100 CXR and attaining an AUC of 0.77. Angelica et al. [22] introduced
a graph based deep semiâ€supervised framework for classifying COVIDâ€19 from CXR images using
around 15,254 images and achieved an accuracy of 96.4 %. Degerli et al. in [23] proposed a novel
method for the joint localization, severity grading, and detection of COVIDâ€19 from 15495 CXR
images by generating the soâ€called infection maps that can accurately localize and grade the severity
of COVIDâ€19 infection with 98.69 % accuracy. Chowdhury et al. [24] proposed an ensemble of deep
CNN models named as Efficient Convolutional Network (ECOVNet) to detect and classify COVIDâ€
19, normal and pneumonia using 16,493 CXR and achieved an accuracy of 97 %. Yamac et al. [25]
introduced a compact CNN architecture, Convolution Support Estimation Network (CSEN) that
utilizes CheXNet as a feature extractor to classify the target CXR images as COVIDâ€19, Bacterial
pneumonia, Viral Pneumonia or Normal. The network produced 98% COVIDâ€19 detection sensitivity
using a dataset of 462 COVIDâ€19 CXR images. Same group of researchers have proposed a reliable
advance warning system to diagnose earlyâ€stage COVIDâ€19 cases using compact CSEN network [26].
Serval deep and compact classifiers were evaluated with 155 earlyâ€stage COVIDâ€19, and 1,579
Normal CXR images. It was reported that CheXNet and CSEN have achieved a COVIDâ€19 detection
sensitivity of 97.1% and 98.5% respectively. Ahmed et al. in [27] proposed a novel CNN architecture,
Preprint submitted to Elsevier

November 25, 2020

ReCoNet (residual imageâ€based COVIDâ€19 detection network) for COVIDâ€19 detection using
preprocessing steps, which was reported to be very useful for enhancing unique COVIDâ€19 signature.
The proposed modular architecture trained on 15,134 CXR images and achieving 97.48 %, 96.39 %
and 97.53 % accuracy, sensitivity and specificity respectively. The machine learning model consists
of a CNNâ€based multiâ€level preprocessing filter block in cascade with a multiâ€layer CNNâ€based
feature extractor and a classification block.

There is a demand for medical image enhancement to help clinicians make accurate/proper
diagnosis of disease [5, 7, 11, 28]. Image enhancement process consists of a collection of techniques
that are used to improve the visual appearance of an image such as removing blur and noise of the
image, which in turn increase contrast, and gives more details of an image. The photographs taken
using cellular phones and smartphones are generally of poor contrast. Therefore, this type of images
needs enhancement algorithms to improve its contrast. It is required to improve the overall quality
of the image, which improves the spatial features of the image. The main purpose of image
enhancement is to improve the interpretability or perception of information contained in the image
for human viewers or feature extraction and creates an image that is subjectively better than the
original image by changing the pixelâ€™s intensity of the input image. A major concern is not to alter
the information during the image enhancement process. Image enhancement plays a crucial role in
many fields such as medical image processing, remote sensing, high definition television (HDTV),
hyperspectral image processing, microscopic imaging etc. [29]. Various image enhancement
techniques such as deâ€noising algorithms, filtering, interpolation, wavelets etc. [30â€32] are applied for
this purpose. Many functions are available to enhance the geometric features such as edges, corners
and ridges of the medical images. These techniques and approaches can enhance the classification
performance of the machine learning models for the medical images. Several local image
Preprint submitted to Elsevier

November 25, 2020

enhancement algorithms have been introduced in the last two decades to improve the image quality
to boost machine learning modelsâ€™ performance [33, 34]. Arun et al. [35] proposed the adaptive
histogram equalization technique, which can help in image enhancement however not free from
fuzzy appearance of the image. This approach was further improved by Hasikin et al. [36], where
they proposed the use of fuzzy set theory. It not only produced better quality images but also
required minimum processing time. Selvi et at. [37] proposed a method for enhancing the fingerprint
images. A fourâ€step image enhancement technique, i.e. preprocessing, fuzzy based filtering, adaptive
thresholding and morphological operation, was utilized for producing noise free fingerprint images.
This technique produced better peak signalâ€toâ€noise (PSNR) values than many previous techniques.
Mohammad et al. [38] presented Biâ€and Multiâ€histogram methods to enhance the contrast while
preserving the brightness and natural appearance of the images. This technique has been useful in
many applications that require image enhancement [39]. Several other popular histogram techniques
can be explored for CXR images to investigate whether they can help AI in various image
classification techniques or not [7, 20, 40â€47]. In our previous study [7], we have discussed four
different preâ€processing schemes which were tested for detecting COVIDâ€19 from other coronavirus
family diseases (Severe Acute Respiratory Syndrome (SARS) and Middle East Respiratory Syndrome
(MERS)) using CXR images. It was observed that 3â€channel approach (combination of original,
Contrast Limited Adaptive Histogram Equalization (CLAHE) and image complementation)
outperforms other enhancement techniques and achieves sensitivities of 99.5%, 93.1%, and 97% for
classifying COVIDâ€19, MERS, and SARS images. Yujin et al. [45] used Histogram Equalization (HE)
and gamma correction enhancement techniques for detecting COVIDâ€19 from CXR. They proposed
a patchâ€based convolutional neural network approach with a relatively small number of trainable
parameters for COVIDâ€19 diagnosis and it showed 92.5% sensitivity for COVIDâ€19. Heidari et al. [27]
proposed a VGGâ€19 preâ€trained network using histogram equalization and a new three channel
Preprint submitted to Elsevier

November 25, 2020

approach using 8474 CXR images consisting of COVIDâ€19, community acquired pneumonia and
normal cases. The three channel approach used the two sets of filtered images from the enhanced
CXR and the original images, which achieved 94.5% accuracy in classifying COVIDâ€19 images. Most
of these groups notably used a very small dataset containing only a few COVIDâ€19 samples. This
makes it difficult to generalize their findings, and cannot guarantee to reproduce the results when
these models are evaluated on a larger dataset. It can be summarized that the above stated studies
along with many other are relying on a limited dataset for developing and validating machine
learning models. Therefore, image enhancement techniques can be investigated on a large dataset
and can be compared to the original Xâ€ray image based performance. The contributions of this paper
can be explicitly stated as

1. To the best of the authorâ€™s knowledge, no study has extensively studied the effect of various
common chest Xâ€ray enhancement techniques on COVIDâ€19 CXR classification,

2. In this article, COVIDâ€19 detection results were reported from the largest lung segmented
images and compared with the plain Xâ€ray images,

3. The outcome of this study were verified by image visualization technique to confirm the
findings of the deep networks.

The remaining part of the paper is divided into the following sections: Section 2 provide the details
of the various preâ€trained classification models, lung segmentation models, different image
enhancement and visualization techniques. Section 3 describes the methodology followed in this
study, and the results of the classification performance using the original and segmented CXR images
enhanced using techniques along with visualization heat map in Section 4. The paper is then
concluded in Section 5.
Preprint submitted to Elsevier

November 25, 2020

2. Background
2.1 Deep Convolutional Neural Networks
Deep CNNs have been popularly used in image classification due to their superior performance
compared to other machine learning paradigm. The networks structure automatically extract the
spatial and temporal features of an image. The approach of transfer learning has been successfully
incorporated in many applications. [48â€50], especially where large dataset can be hard to find.

Thus

it opens the opportunity of utilizing smaller dataset and also reduces the time required to develop a
deep learning algorithm from scratch [51, 52]. For COVIDâ€19 detection, nine preâ€trained deep
learning CNNs such as ResNet18, ResNet50, ResNet101 [53], DenseNet201 [54], ChexNet [55], and
InceptionV3 [56] were preâ€dominantly used in the literature. ChexNet is the only network that is
trained on CXRâ€™s unlike the other networks that are initially trained on ImageNet database. Residual
Network (in short ResNet) with several variants, solve vanishing gradient and degradation problem
[53] and learn from residuals instead of features [57]. Dense Convolutional Network (in brief
DenseNet) needs a smaller number of parameters than a conventional CNN, as it does not learn
redundant feature maps. The DenseNet has layers with direct access to original input image and loss
function gradients. Another variant of DenseNet, ChexNet is trained and validated using a large
number of CXR images [55].Inceptionâ€v3 is a CNN architecture from the inception family that makes
several improvements including using label smoothing, factorized 7x7 convolutions, and the use of
an auxiliary classifier to propagate label information lower down the network (along with the use of
batch normalization for layers in the side head). This network scales in ways that strive to use the
added computation as effectively as possible through correctly factorized convolutions and
aggressive regularization [56].

Preprint submitted to Elsevier

November 25, 2020

Figure 1: Uâ€Net model architecture for lung segmentation.

2.2 Segmentation
Recently UNet architecture has gained increasing popularity in different biomedical image
segmentation applications [58] . In this study, a Uâ€net model with small variation in decoding part is
utilized [59]. The Uâ€net model consists of a contracting path with 4 encoding blocks, followed by an
expanding path with 4 decoding blocks. Each encoding block consists of two consecutive 3x3
convolutional layers followed by a max pooling layer with a stride of 2 for down sampling. While the
decoding blocks consists of a transposed convolutional layer for up sampling, a concatenation with
the corresponding feature map from contracting path, and two 3x3 convolutional layer. All
convolutional layers are followed by Batch normalization and ReLU activation. At the final layer 1x1
convolution is utilized to map the output from last decoding block to 2 channel feature maps, where
a pixelâ€wise SoftMax is applied to map each pixel into a binary class of background or lung.

Preprint submitted to Elsevier

November 25, 2020

2.3 Image Enhancement Techniques
Image enhancement is an important imageâ€processing technique, which highlights key information
in an image and reduces or removes certain secondary information to improve the identification
quality in the process. The aim is to make the objective images more suitable for specific application
than the original images. We employ five different enhancement strategies in this research. In the
following section, these image enhancement techniques will be briefly introduced:

2.3.1 Histogram Equalization (HE)
Histogram equalization (HE) technique aims to distribute the gray levels within an image. Each
gray level is therefore equally likely to occur. HE changes the brightness and contrast of the dark and
low contrast images to enhance image quality [60]. The histogram would be skewed towards the
lower end of the grayscale for a dark image, and the image information would be squeezed into the
dark end of the histogram. In order to create a more evenly distributed histogram, the grey levels can
be reâ€distributed at the dark end, which can make the picture clear. The histogram of a digital image
with intensity levels in the range [0, Lâ€1] is a discrete function represented as follows:
ğ’‰ ğ’“ğ’Œ

ğ’ğ’Œ

Where, ğ’“ğ’Œ is kth intensity value,

ğŸ
ğ’ğ’Œ is the number of pixels in the image with intensity, ğ’“ğ’Œ .

Histograms are frequently normalized by the total number of pixels in the image. Assuming an M x
N image, a normalized histogram is related to the probability of occurrence of ğ’“ğ’Œ in the image as
shown in equation 2.

ğ’‘ ğ’“ğ’Œ

ğ’ğ’Œ
ğ‘´âˆ—ğ‘µ

ğŸ

2.3.2 Contrast limited adaptive histogram equalization (CLAHE)
Preprint submitted to Elsevier

November 25, 2020

An improved HE variant is called Adaptive Histogram Equalization (AHE). AHE performs
histogram equalization over small regions (i.e., patches) in the image, and thus, AHE enhances the
contrast of each region individually. Therefore, it improves local contrast and edges adaptively in
each region of the image to the local distribution of pixel intensities instead of the global information
of the image. However, AHE could over amplify the noise component in the image [61]. However,
images enhanced with Contrastâ€Limited Adaptive Histogram Equalization (CLAHE) are more
natural in appearance than those produced by HE. When the HE technique was applied to the Xâ€ray
images, it was observed that it might saturate certain regions. To address this difficulty, CLAHE uses
the same approach as AHE but the amount of contrast enhancement that can be produced within the
selected region is limited by a threshold parameter. Firstly, the original image is converted from RGB
(red, green and blue) color space to HSV (hue, saturation and value) color space as human sense color
similar to HSV version. Secondly, value component of HSV is processed by CLAHE without affecting
the hue and saturation. The initial histogram is cropped and each grayâ€level is redistributed to the
cropped pixels. The value of each pixel is reduced to a userâ€selectable limit. Finally, the HSV
processed image is reâ€transformed to RGB color space.

2.3.3 Image Invert/ Complement
The image inversion or complement is a technique where the zeros become ones and ones become
zeros so black and white are reversed in a binary image. For an 8â€bit gray scale image, the original
pixel is subtracted from the highest intensity value, 255, the difference is considered as pixel values
for the new image. For xâ€ray images, the dark spots turn into lighter and light spots become darker.
The mathematical expression is simply:
ğ’š

Preprint submitted to Elsevier

ğŸğŸ“ğŸ“

ğ’™

ğŸ‘

November 25, 2020

Where, ğ‘¥ and y are the intensity values of the original and the transformed (new) images. This
technique shows the lungs area (i.e., the region of interest) lighter and the bones are darker. As this
is a standard procedure, which was used widely by radiologists, it may equally help deep networks
for a better classification. It can be noted that the histogram for the complemented image is a flipped
copy of the original image.

2.3.4 Gamma correction
Typically, linear operations are performed on individual pixels in image normalization, such as
scalar multiplication, addition and subtraction. Gamma correction performs a nonâ€linear operation
on source image pixels Gamma correction alternates the pixel value to improve the image using the
projection relationship between the value of the pixel and the value of the gamma according to the
internal map. If P represents the pixel value inside the [0,255] range, Î© represents the angle value, Ò
is the symbol of the gamma value set, x is the gray scale value of the pixel (x Ïµ P). Let ğ’™ğ’ be range
midpoint [0, 255]. The linear map from group P to group Î© is defined as:

ğ‹: ğ‘· â†’ ğœ´, ğœ´

ğ|ğ

ğ‹ ğ’™ ,ğ‹ ğ’™

ğ…ğ’™
ğŸğ’™ğ’

ğŸ’

The mapping from Î© to Ò is defined as:
ğ’‰: ğœ´ â†’ Ò , Ò

ğœ¸|ğœ¸

ğ’‰ ğ’™
ğ’‰ ğ’™
ğ’‡ğŸ ğ’™

ğŸ“
ğŸ ğ’‡ğŸ ğ’™
ğšğœğ¨ğ¬ ğ‹ ğ’™

ğŸ”
ğŸ•

where a Ïµ [0, 1] denotes a weighted factor.

Preprint submitted to Elsevier

November 25, 2020

Based on this map, group P can be related to Ò group pixel values. The arbitrary pixel value is
calculated in relation to a given Gamma number. Let ğœ¸ (x) = h(x), and the Gamma correction function
is as follows

ğ’ˆ ğ’™

ğŸğŸ“ğŸ“

ğ’™
ğŸğŸ“ğŸ“

ğŸ/ğœ¸ ğ’™

ğŸ–

where g(x) represents the output pixel correction value in gray scale.

2.3.5 Balance Contrast Enhancement Technique (BCET)
BCET represents a strategy for improving balance contrast by stretching or compressing the
contrast of the image without altering the histogram pattern of the image data. The solution is based
on the parabolic function acquired from the image data. The general parabolic functional form is
defined as
ğ’€

ğ’‚ ğ’™

ğ’ƒ

ğŸ

ğ’„

ğŸ—

The three coefficients a, b and c are determined from the following equations using the minimum,
the maximum and the mean of the input and output image values.

ğ’ƒ

ğ’‚

ğ’„

ğ’‰ğŸ ğ‘¬ ğ‘³
ğŸğ’‰ ğ‘¬ ğ‘³

ğ’‰
ğ‘³

ğ‘¯ ğ‘³
ğ’ ğ’‰ ğ’
ğ’‚ ğ’

ğ’ƒ

ğŸ

ğ’” ğ‘¯ ğ‘³
ğ’† ğ‘¯ ğ‘³

ğŸğ’ƒ

ğ’ğŸ ğ‘¯
ğ’ ğ‘¯

ğ‘¬
ğ‘¬

ğŸğŸ

ğŸğŸ

ğŸğŸ

Where Ê¹lÊ¹ represents the minimum value of the input image, Ê¹hÊ¹ denotes the maximum value of the
input image, Ê¹eÊ¹ denotes the mean value of the input image, Ê¹LÊ¹ the minimum value of the output

Preprint submitted to Elsevier

November 25, 2020

image, Ê¹HÊ¹ denotes the maximum value of the output image and Ê¹EÊ¹ denotes the mean value of the
output image.

Figure 2 shows the difference between the different image enhancement techniques.

Figure 2: Histogram for original Xâ€ray image and images undergo different enhancement techniques.

Preprint submitted to Elsevier

November 25, 2020

2.4 Visualisation Techniques
The emergence of visualization tools has led to growing interest in how CNN works and the logic
behind the making of particular decisions by a network. In order to view the decisionâ€making process
of CNNs, visualization methods lead to better visual representation. These also improve the
transparency of the model by visualizing the reasoning behind the inference that can be interpreted
in a way that can be easily understood by humans, thereby increasing trust in the results of the CNNs.
There are many popular visualization techniques such as SmoothGrad [62], Gradâ€CAM [63], Gradâ€
CAM++ [64], Scoreâ€CAM [65]. But in this study Scoreâ€CAM was due to its promising performance
[6]. Figure 3 provides a sample Scoreâ€CAM visualization, where it highlights the regions used by
CNN in making decisions. These visualization helps in increasing the confidence of the reliability of
the deep layer networks, by confirming the decision making from relevant region of the images.

Figure 2: Scoreâ€CAM visualization of A) COVIDâ€19 CXR, B) Normal CXR, C) Nonâ€COVID Lung Opacity CXR, to
show where the CNN model is mainly taking the decision.

3. Methodology
The detailed methodology adopted in the study is shown in Figure 4. The study used two different
databases: 1) lung segmentation and 2) classification of CXR images into COVIDâ€19, Nonâ€COVID
lung opacity and Normal. The major experiments that are carried out in the study: 1) Training and
Preprint submitted to Elsevier

November 25, 2020

testing of Uâ€Net model to segment lungs from CXR images, 2) Training and testing original and five
different enhanced plain CXR images for classification using six different preâ€trained networks 3)
Training and testing segmented lungs of CXR images (original and enhanced) for classification using
same networks. The reliability of the last two experiments were verified using Scoreâ€CAM technique.

Figure 4: Block diagram of the system methodology.

The details of the study, i.e. dataset details, preâ€processing and augmentation adopted in the study,
performance matrices utilized in the study are discussed below.
3.1 Datasets Description
In this study, authors have used a large dataset compiled by the team and referred to as COVQU
dataset, which is comprised of 18,479 CXR images across 15,000 patient cases
3.1.1 Lung Segmentation

Preprint submitted to Elsevier

November 25, 2020

To investigate lung segmentation models, authors have created ground truth lung masks for 18,479
CXR images which are verified by expert radiologists as a part of separate study (which is not
reported in this study). Sample CXR images and masks are shown in Figure 5. The modified Uâ€Net
network was trained and tested with CXR images and their respective ground truth masks.

3.1.2 Image Classification
The dataset used to train and evaluate the proposed study, which is referred to as COVQU, is
comprised of 18,479 CXR images across 15,000 patient cases. This COVQU dataset is the largest public
COVID positive cases dataset, according to the best of the authorsâ€™ knowledge. To generate this
dataset, authors used and modified different open access database for three different types (COVID,
Normal, and nonâ€COVID). COVQU dataset combined RSNA CXR dataset [66] and COVIDâ€19
dataset, details below.

The COVQU dataset compiled as a part of this study is the largest public COVIDâ€19 positive cases
dataset, according to the best of the authorsâ€™ knowledge. To compile this dataset, COVIDâ€19, Normal,
and nonâ€COVID images from different open access databases and online resources were used.
Normal and Nonâ€COVID images in COVQU dataset were taken from Radiological Society of North
America (RSNA) CXR dataset [66]. In the following section, details of the RSNA and COVIDâ€19
datasets are discussed:

3.1.3 Image Classification
The COVQU dataset compiled as a part of this study is the largest public COVIDâ€19 positive cases
dataset, according to the best of the authorsâ€™ knowledge. To compile this dataset, COVIDâ€19, Normal,
and nonâ€COVID images from different open access databases and online resources were used.
Normal and Nonâ€COVID images in COVQU dataset were taken from Radiological Society of North
Preprint submitted to Elsevier

November 25, 2020

America (RSNA) CXR dataset [66]. In the following section, details of the RSNA and COVIDâ€19
datasets are discussed:

3.1.4 RSNA CXR dataset
RSNA pneumonia detection challenge dataset [66], consists of about 26,684 CXR DICOM (Digital
Imaging and Communications in Medicine) images, where 8,851 images are normal, 11,821 images
are with different lung abnormalities and 6,012 are nonâ€COVID ground grass lung opacity Xâ€ray
images. In this study, we have used 8,851 normal and 6,012 nonâ€COVID lung opacity Xâ€ray images.
Sample of the Xâ€ray images used in the study are shown in Figure 6.

Figure 5: Samples of CXR and their ground truth masks of the dataset.

3.1.5 COVIDâ€19 dataset
COVIDâ€19 dataset is comprised of 3,616 positive COVIDâ€19 CXR images, which are collected from
different publicly available dataset, online source and published articles. Out of 3,616 Xâ€ray images,
2,473 images are collected from BIMCVâ€COVID19+ dataset [67], 183 images from a Germany medical
school [68], 559 Xâ€ray image from Italian Society of Medical Radiology (SIRM), GitHub, Kaggle &
Twitter [69â€72], and 400 Xâ€ray images from another COVIDâ€19 CXR repository[73]. BIMCVâ€
Preprint submitted to Elsevier

November 25, 2020

COVID19+ dataset is the single largest public dataset with 2,473 CXR images of COVIDâ€19 patients
acquired from digital Xâ€ray (DX) and computerized Xâ€ray (CX) machines.

Figure 6: CXR image samples from different datasets: (A) COVIDâ€19, (B) nonâ€COVID Lung Opacity, (C) and Normal.

3.2 Preprocessing And Data Augmentation
The datasets were preprocessed to resize the Xâ€Ray images to fit the input imageâ€size requirements
of different CNN models such as 256Ã—256 pixels for Uâ€Net model, 299Ã—299 pixels for InceptionV3 and
224Ã—224 pixels for all other networks. Using the mean and standard deviation of the images, Zâ€score
normalization was carried out.

3.2.1 Data Augmentation
It is reported that the data augmentation can improve the classification accuracy of the deep
learning algorithms by augmenting the existing data rather than collecting new data [74]. Data
augmentation can significantly increase the diversity of data available for the training models. Image
Preprint submitted to Elsevier

November 25, 2020

augmentation is crucial when the dataset is imbalance. In this study, the number of normal images
was 8,851, which is more than twice the size of COVIDâ€19 positive CXR images. Therefore, it was
important to augment COVIDâ€19 positive CXR images twoâ€times to make the database balance. Some
of the deep learning frameworks have builtâ€in data augmentation facility within the algorithms,
however, in this study, image rotation based augmentation technique was utilized to generate
training images of COVIDâ€19 before applying to the CNN models for training.

3.2 Experiments
Fiveâ€fold cross validation was used and therefore, 80 % data were used for training and 20 % for
testing. Out of training dataset subset, 20 % were utilized for validation to avoiding overfitting issue
[75]. Finally, the results were a weighted average of the five folds. Table 1 shows the details of the
number of training, validation and test CXR images used in the two experiments of plain and
segmented lung Xâ€ray images using five different enhancement techniques.
Table 1. Details of the dataset used for training, validation and testing.

Database
COVID19 dataset
RSNA
CXR
dataset

Types

Training Dataset
Count.
of Training Augmented Validation
CXRâ€™s/ class
image
train
image
/fold
image/fold
/fold

Test image/
fold

COVID-19

3616

2314

4628

578

724

Normal
NonCOVID

8851

5664

5664

1416

1771

6012

3847

3847

962

1203

As mentioned earlier, three different experiments were conducted in this study on PyTorch library
with Python 3.7 on IntelÂ® XeonÂ® CPU E5â€2697 v4 @ 2,30GHz and 64 GB RAM, with a 16 GB NVIDIA
GeForce GTX 1080 GPU. In the following section, each of them will be discussed separately:

3.2.1 Lung Augmentation
Preprint submitted to Elsevier

November 25, 2020

Modified Uâ€Net model was trained and validated to create lung segmentation using fiveâ€fold cross
validation. Out of 18,479 CXR images and ground truth lung masks, 80% images and corresponding
masks were used for training and 20% images for testing. The images were trained using batch size
of 4, learning rate of 0.001, for maximum of 20 epochs using Adam optimizer. The learning rate
decreased if no improvement was observed for consecutive 3 epochs and stopped if there was no
improvement for consecutive 6 epochs.

3.2.2 COVID Classification

Six different CNN models were compared separately using nonâ€segmented (plain) and segmented
(lung) Xâ€ray images with using five different image enhancement techniques for the classification of
COVIDâ€19, Nonâ€COVID lung opacity, and normal images to investigate the effect of image
enhancement and lung segmentation on COVIDâ€19 detection. Five deep networks (Inceptionv3,
ResNet50, ResNet101, ChexNet and DenseNet201) and one comparatively shallow networks
(ResNet18) were evaluated. The images were trained using batch size of 32, learning rate of 0.001, for
maximum of 20 epochs using Adam optimizer. As mentioned earlier, the learning rate was decreased
with no improvement for consecutive 3 epochs and stopped with no improvement for consecutive 6
epochs.

3.3 Performance Matrix

3.3.1 Lung Segmentation

The performance of different networks in image segmentation for the testing dataset was evaluated
after the completion of training and validation phase and was compared using three performance
metrics: loss, accuracy, IoU, Dice. The equations used to calculate accuracy, Intersectionâ€Overâ€Union
(IoU) or Jaccard Index and Dice coefficient (or F1â€score) are shown in equation (13â€15).
Preprint submitted to Elsevier

November 25, 2020

ğ‘¨ğ’„ğ’„ğ’–ğ’“ğ’‚ğ’„ğ’š

ğ‘¨

ğ‘»ğ‘·

ğ‘»ğ‘·
ğ‘­ğ‘µ

ğ‘°ğ’ğ‘¼ ğ‘±ğ’‚ğ’„ğ’„ğ’‚ğ’“ğ’… ğ’Šğ’ğ’…ğ’†ğ’™

ğ‘«ğ’Šğ’„ğ’† ğ‘ªğ’ğ’†ğ’‡ğ’‡ğ’Šğ’„ğ’Šğ’†ğ’ğ’•

ğ‘»ğ‘·

ğ‘­ğŸ

ğ‘»ğ‘µ
ğ‘­ğ‘·
ğ‘»ğ‘·
ğ‘­ğ‘µ

ğ’”ğ’„ğ’ğ’“ğ’†

ğŸğŸ‘

ğ‘»ğ‘µ

ğŸğŸ’

ğ‘­ğ‘·
ğŸ âˆ— ğ‘»ğ‘·
ğŸ âˆ— ğ‘»ğ‘· ğ‘­ğ‘µ

ğŸğŸ“

ğ‘­ğ‘·

3.3.2 COVID Classification

The different CNNsâ€™ performance in classification was evaluated using six performance metrics:
Overall accuracy, weighted sensitivity or recall, weighted specificity, weighted precision, weighted
F1 score using equations (16â€20). Since different classes had different number of images, per class
weighted performance metric and overall accuracy was used to compare the networks. The
performance was also evaluated using area under curve (AUC):

ğ‘¨ğ’„ğ’„ğ’–ğ’“ğ’‚ğ’„ğ’š

ğ‘¨

ğ‘»ğ‘·

ğ‘»ğ‘·
ğ‘­ğ‘µ

ğ‘»ğ‘µ
ğ‘­ğ‘·

ğ‘»ğ‘µ

ğŸğŸ”

ğ‘ºğ’†ğ’ğ’”ğ’Šğ’•ğ’Šğ’—ğ’Šğ’•ğ’š

ğ‘¹

ğ‘»ğ‘·
ğ‘»ğ‘· ğ‘­ğ‘µ

ğŸğŸ•

ğ‘ºğ’‘ğ’†ğ’„ğ’Šğ’‡ğ’Šğ’„ğ’Šğ’•ğ’š

ğ‘º

ğ‘»ğ‘µ
ğ‘­ğ‘· ğ‘»ğ‘µ

ğŸğŸ–

ğ‘·ğ’“ğ’†ğ’„ğ’Šğ’”ğ’Šğ’ğ’

ğ‘­ğŸ ğ‘ºğ’„ğ’ğ’“ğ’†

ğ‘·

ğ‘­

ğ‘»ğ‘·
ğ‘»ğ‘· ğ‘­ğ‘·
ğŸ âˆ— ğ‘»ğ‘·
ğŸ âˆ— ğ‘»ğ‘· ğ‘­ğ‘µ

ğŸğŸ—

ğ‘­ğ‘·

ğŸğŸ

Here, true positive (TP), true negative (TN), false positive (FP) and false negative (FN) were used
to denote the number of COVIDâ€19 CXR images were identified as COVIDâ€19, the number of normal
and nonâ€COVID lung opacity CXRs were identified as normal and nonâ€COVID CXRs, the number of
Preprint submitted to Elsevier

November 25, 2020

normal and nonâ€COVID CXRs incorrectly identified as COVIDâ€19 CXRs and the number of COVIDâ€
19 CXRs incorrectly identified as normal and nonâ€COVID, respectively.

In addition to the metrics stated above, the various classification networks were also compared in
terms of the elapsed time per image, i.e. time taken by each network to classify an input image,
represented in equation 21.
ğœ¹ğ’•

ğ’•ğŸ

ğ’•ğŸ

ğŸğŸ

Where ğ’•ğŸ is the starting time for a network to classify an image, I and ğ’•ğŸ is the end time when the
network has classified the same image, I.

4. Results And Discussions
This section describes the performance of the lung segmentation model and classification networksâ€™
performance on plain Xâ€ray images and segmented lung Xâ€ray images.

4.1 Lung Segmentation

Table 2 shows the performance matrix of the trained, validated and tested modified Uâ€Net model
for lung segmentation.
Table 2. Performance of segmentation network

Network
Modified U-Net

Test loss
0.0376

Accuracy (A)
98.63

IoU
94.3

Dice
96.94

The modified Uâ€Net model was used to segment the classification database (8851 normal, 6012 lung
opacity and 3416 COVID images), which was used for classification of COVID, lung opacity and
normal cases. It is important to see on a completely unseen imageâ€set with lung infection and normal
images how well the trained segmentation model works. It can be seen from Figure 7 that the
modified Uâ€net model trained on the segmented CXR dataset can segment the lung areas of the Xâ€
Preprint submitted to Elsevier

November 25, 2020

ray images of the classification database very reliably. However, there is quantitative evaluation on
the classification dataset is not possible as there is no ground truth masks available for this database
and therefore, qualitative evaluation were done to confirm that each Xâ€ray image was segmented
correctly.

Figure 7. CXR sample images (left), generated masks by the network (middle) and resulting segmented lung (right).
4.2 COVIDâ€19 Classification

As mentioned earlier, there are two different experiments (on plain and segmented lungs Xâ€ray
images) were conducted for classification of COVIDâ€19, Nonâ€COVID Lung opacity and Normal. The
comparative performance of the best performing model for different enhancement techniques for
classification between the three classes of plain images is shown in Table 3, & Table 4 shows the
comparative performance of the different CNN models in classifying COVIDâ€19 using original and
Gamma corrected Xâ€ray images.

Preprint submitted to Elsevier

November 25, 2020

Table 3. Comparison of the best network for the COVIDâ€19 classification using CXR images for
different enhancement techniques
Different

Model

Overall

Enhancement

Original
Complement
Histeq
CLAHE
Gamma
BCET

InceptionV3
DenseNet201
ChexNet
DenseNet201
ChexNet
DenseNet201

Weighted

A

P

R

F

S

ğœ¹ğ’•

93.46
94.19
94.34
94.08
96.29
94.5

93.49
94.21
94.17
94.09
96.28
94.5

93.47
94.19
94.14
94.08
96.29
94.5

93.47
94.19
94.14
94.07
96.28
94.49

95.48
95.78
95.98
95.77
97.27
96.25

0.98
0.72
0.62
0.75
0.6
0.8

Table 4. Comparison of different models for Covidâ€19 classification
using Original and Gamma corrected CXR images
Technique

Original

Gamma

Model

Resnet18
Resnet50
Resnet101
ChexNet
DenseNet201
InceptionV3
Resnet18
Resnet50
Resnet101
ChexNet
DenseNet201
InceptionV3

Overall

Weighted

A

P

R

F

S

93.43
93.01
93.01
93.21
92.7
93.46
94.63
94.56
94.93
96.29
95.05
94.95

93.43
93.12
93.04
93.28
92.78
93.49
94.64
94.58
94.94
96.28
95.06
94.95

93.43
93.02
93.01
93.21
92.7
93.47
94.62
94.56
94.93
96.29
95.05
94.95

93.42
93.04
93
93.2
92.72
93.47
94.6
94.53
94.92
96.28
95.05
94.93

95.49
95.5
95.11
95.54
95.35
95.48
95.92
95.81
96.2
97.27
96.55
96.24

In Table 3, the best performing network has been reported for the different enhancement
techniques. It is evident that Gamma enhancement technique was the best performing enhancement
technique not only in terms of classification but also in terms of elapsed time as shown in Table 3. It
was further verified in Table 4, where this enhancement technique had consistently improved the
performance for different network using the original Xâ€ray images. Finally, it was seen that the
combination of gamma enhancement and ChexNet was the best performing networking for the
COVIDâ€19 classification with about 96.29 % and 96.28 %, accuracy and F1â€Score respectively. The
superior performance of CheXNet in comparison to DenseNet201 is exhibiting that deeper layer does
not always perform better and it is important to adjust hyper parameters for a specific application. It
Preprint submitted to Elsevier

November 25, 2020

can also be noted that CheXNet is the only DenseNet variant which was initially trained on chest Xâ€
ray images. Similar performance was observed by the authors in their other COVIDâ€19 classification
problem [11]. However, ResNet18, 50 and 101 showed increasingly better performance for the
classification of images without segmentation. Figure 8(A) clearly shows that the ROC curves for the
best performing networks for the different enhancement techniques and it is evident that the gamma
enhancement is helping the network in discriminating the different classes better. The comparative
performance of the different image enhancement techniques for the different CNNs were shown in
Table 5. Table 6 shows the comparative performance of the different CNN models for the
classification of the threeâ€class problem using original and Gamma corrected lung segmented Xâ€ray
images.

Figure 8. ROC curves for the best performing network in each image enhancement technique for plain CXR images (A) and for
segmented lung CXR images (B).
Table 5. Comparison of the best network for the COVIDâ€19 classification using segmented CXR images for
different enhancement techniques
Enhancement

Model

techniques

Original
Complement
Histeq
CLAHE
Gamma
BCET
Preprint submitted to Elsevier

ChexNet
InceptionV3
DenseNet201
ChexNet
DenseNet201
DenseNet201

Overall

Weighted

A

P

93.22
93.46
93.44
93.9
95.11
94.12

93.22
93.49
93.43
93.91
94.55
94.17

R

93.22
93.47
93.44
93.9
94.56
94.14

F

93.22
93.47
93.42
93.89
94.53
94.14

S

95.51
95.48
95.55
95.77
95.59
95.98

ğœ¹ğ’•

0.65
1.2
0.78
0.7
0.72
0.85
November 25, 2020

Table 6. . Comparison of different models for Covidâ€19 classification
using Original and Gamma Corrected CXR images

Weighted
Technique

Original

Gamma

Model
Resnet18
Resnet50
Resnet101
ChexNet
DenseNet201
InceptionV3
Resnet18
Resnet50
Resnet101
ChexNet
DenseNet201
InceptionV3

Overall
A
92.23
92.51
93.14
93.22
92.79
92.43
93.31
93.24
93.13
93.63
95.11
93.92

P
92.23
92.5
93.14
93.22
92.87
92.44
93.3
93.24
92.92
93.67
94.55
93.92

R
92.22
92.51
93.15
93.22
92.79
92.43
93.31
93.24
92.94
93.63
94.56
93.92

F
92.21
92.5
93.12
93.22
92.77
92.4
93.3
93.22
92.92
93.59
94.53
93.9

S
94.66
95.38
95.41
95.51
94.62
94.81
95.82
95.23
95.25
95.34
95.59
95.7

Table 5 shows that Gamma enhancement technique was the best performing enhancement
technique using the segmented lung Xâ€ray images. Figure 8(B) shows the ROC curves for the different
image enhancement techniques for best performing network where the enhancement technique had
consistently improved the performance for different networks in comparison to the original Xâ€ray
images. It can also be seen that Gamma enhancement technique is the best performing with
comparable elapsed time per image ( ğœ¹ğ’•

as shown in Figure 9. Finally, it was seen that the

combination of gamma enhancement and DenseNet201 was the best performing networking for the
COVIDâ€19 classification with about 95.11 % and 94.56 %, accuracy and F1â€Score respectively.
4.3 Visualization Using Scoreâ€Cam

As mentioned earlier, it is important to see where network is learning from the CXR images. It can
be learning from relevant and nonâ€relevant areas of the CXR images for classification which were
verified using Scoreâ€CAM based heat maps generated for original (nonâ€segmented) and segmented
CXR images.

Preprint submitted to Elsevier

November 25, 2020

Figure 9. Comparison of F1 Score versus the elapsed time per image for the best performing network in each image enhancement
technique for plain X-ray images (A) and segmented lung X-ray images (B).

Figure 10. Score-CAM visualization of correctly classified COVID-19 X-ray images using the different enhancement techniques:
CXR (top row), Score-CAM heat map on original CXR (middle row) and on segmented lungs CXR (bottom row).

It is clearly visible from the heat map visualization of both the original and segmented lungs using
Scoreâ€CAM technique is that the decision making in original CXR is not always from the lungs areas
(Figure 10). The areas which are mostly contributing to take decision by CNN models are not a part
of the lungs always or in most of the cases. It is noticeable that there was no increase in performance
with the segmented lungs in comparison to the plain Xâ€rays however it can be seen, that the

Preprint submitted to Elsevier

November 25, 2020

segmented lungs helped the CNN to take decision from the main region of interest compared to the
plain Xâ€rays, which is also criticized

in recent papers [28, 76].

It is also interesting to see how the Gamma enhancement technique is outperforming other
enhancement techniques for a sample case where almost all the techniques have misclassified a
COVIDâ€19 Xâ€rays to either class: Normal or Lung Opacity but Gamma enhancement technique have
correctly classified it. It can also be seen from Figure 11 that Gamma enhancement technique on the
segmented lungs is taking decisions from the region of interest, i.e. lungs, and correctly classifies the
images otherwise which was missâ€classified by the network.

Figure 11. Gamma Enhancement on segmented lungs correctly classify COVID-19 x-ray while others miss classify the sample X-ray
images.

5. Conclusion
This work explores the effect of different image enhancement techniques in the automatic detection
of COVIDâ€19 from the CXR images using deep Convolutional Neural Networks. The performance of
six different CNN models for five different enhancement techniques were evaluated for the
classification of COVIDâ€19, Nonâ€COVID lung opacity and normal CXR images. ChexNet model with
gamma enhancement technique provided the best performance without image segmentation
whereas DenseNet201 with gamma enhancement technique outperforms for the segmented lungs.
Preprint submitted to Elsevier

November 25, 2020

The classification accuracy, precision and recall for the detection of COVIDâ€19 were found to be
96.29%, 96.28%, and 96.28% without segmentation and 95.11%, 94.55% and 94.56% with segmentation
respectively. Scoreâ€CAM visualization technique confirms the reliability of the trained models as the
decision was made from the lung regions in the segmented CXR images. Thus the results reaffirms
the importance of accurate segmentation of lungs from the CXR images, which can assist machine
learning models in diagnostic decisions. This deep AI based system can be helpful as a fast screening
tool, especially during the pandemic period, and can save the casualties due to delay or not accurate
diagnosis.

Author Contribution

Experiments were designed by TR and MEHC. Experiments were performed by TR, AK, AT, YQ and
SBAK. Results were analyzed by MEHC, SK, MSK, MTI, SAM, and SMZ. The project is supervised
by MEHC and SAM. All the authors were involved in the interpretation of data and paper writing
and revision of the article.
Funding
Qatar University COVID19 Emergency Response Grant (QUERGâ€CENGâ€2020â€1) provided the
support for the work and the claims made herein are solely the responsibility of the authors.
Acknowledgments
The publication of this article was funded by the Qatar National Library.
References

[1]

S. A. Harmon, T. H. Sanford, S. Xu, E. B. Turkbey, H. Roth, Z. Xu, et al., ÊºArtificial intelligence for the detection of COVIDâ€19
pneumonia on chest CT using multinational datasets,Êº Nature Communications, vol. 11 (1), p. 4080(2020/08/14 2020)

[2]

COVIDâ€19 CORONAVIRUS PANDEMIC [Online]. Available: https://www.worldometers.info/coronavirus/. [Accessed on 20â€11â€
2020]
Preprint submitted to Elsevier

November 25, 2020

[3]

Y. Yang, M. Yang, C. Shen, F. Wang, J. Yuan, J. Li, et al., ÊºEvaluating the accuracy of different respiratory specimens in the laboratory
diagnosis and monitoring the viral shedding of 2019â€nCoV infections. medRxiv 2020.02. 11.20021493 [Preprint]. 17 February 2020,Êº
Preprint] doi: 0.1101/2020.02, vol. 11)

[4]

M. Yu, D. Xu, L. Lan, M. Tu, R. Liao, S. Cai, et al., ÊºThinâ€section Chest CT Imaging of Coronavirus Disease 2019 Pneumonia:
Comparison Between Patients with Mild and Severe Disease,Êº Radiology: Cardiothoracic Imaging, vol. 2 (2), p. e200126(2020)

[5]

T. Rahman, M. E. Chowdhury, A. Khandakar, K. R. Islam, K. F. Islam, Z. B. Mahbub, et al., ÊºTransfer Learning with Deep
Convolutional Neural Network (CNN) for Pneumonia Detection using Chest Xâ€ray,Êº Applied Sciences, vol. 10 (9), p. 3233(2020)

[6]

T. Rahman, A. Khandakar, M. A. Kadir, K. R. Islam, K. F. Islam, R. Mazhar, et al., ÊºReliable Tuberculosis Detection using Chest Xâ€
ray with Deep Learning, Segmentation and Visualization,Êº IEEE Access, vol. 8 pp. 191586â€191601(2020)

[7]

A. Tahir, Y. Qiblawey, A. Khandakar, T. Rahman, U. Khurshid, F. Musharavati, et al., ÊºCoronavirus: Comparing COVIDâ€19, SARS
and MERS in the eyes of AI,Êº arXiv preprint arXiv:2005.11524, 2020)

[8]

M. E. Chowdhury, T. Rahman, A. Khandakar, R. Mazhar, M. A. Kadir, Z. B. Mahbub, et al., ÊºCan AI help in screening viral and
COVIDâ€19 pneumonia?,Êº IEEE Access, vol. 8 pp. 132665â€132676(2020)

[9]

T. Ai, Z. Yang, H. Hou, C. Zhan, C. Chen, W. Lv, et al., ÊºCorrelation of chest CT and RTâ€PCR testing in coronavirus disease 2019
(COVIDâ€19) in China: a report of 1014 cases,Êº Radiology, p. 200642(2020)

[10]

Y. Fang, H. Zhang, J. Xie, M. Lin, L. Ying, P. Pang, et al., ÊºSensitivity of chest CT for COVIDâ€19: comparison to RTâ€PCR,Êº Radiology,

[11]

M. E. Chowdhury, T. Rahman, A. Khandakar, R. Mazhar, M. A. Kadir, Z. B. Mahbub, et al., ÊºCan AI help in screening viral and

p. 200432(2020)

COVIDâ€19 pneumonia?,Êº arXiv preprint arXiv:2003.13145, 2020)
[12]

I. D. Apostolopoulos and T. A. Mpesiana, ÊºCovidâ€19: automatic detection from xâ€ray images utilizing transfer learning with
convolutional neural networks,Êº Physical and Engineering Sciences in Medicine, p. 1(2020)

[13]

A. Abbas, M. M. Abdelsamea, and M. M. Gaber, ÊºClassification of COVIDâ€19 in chest Xâ€ray images using DeTraC deep

[14]

S. Minaee, R. Kafieh, M. Sonka, S. Yazdani, and G. J. Soufi, ÊºDeepâ€covid: Predicting covidâ€19 from chest xâ€ray images using deep

convolutional neural network,Êº arXiv preprint arXiv:2003.13815, 2020)

transfer learning,Êº arXiv preprint arXiv:2004.09363, 2020)
[15]

J. Irvin, P. Rajpurkar, M. Ko, Y. Yu, S. Ciureaâ€Ilcus, C. Chute, et al., ÊºChexpert: A large chest radiograph dataset with uncertainty
labels and expert comparison,Êº in Proceedings of the AAAI Conference on Artificial Intelligence, 2019, pp. 590â€597.

[16]

A. I. Khan, J. L. Shah, and M. M. Bhat, ÊºCoronet: A deep neural network for detection and diagnosis of COVIDâ€19 from chest xâ€ray
images,Êº Computer Methods and Programs in Biomedicine, p. 105581(2020)

[17]

P. Afshar, S. Heidarian, F. Naderkhani, A. Oikonomou, K. N. Plataniotis, and A. Mohammadi, ÊºCovidâ€caps: A capsule networkâ€
based framework for identification of covidâ€19 cases from xâ€ray images,Êº arXiv preprint arXiv:2004.02696, 2020)

[18]

J. P. Cohen, P. Morrison, and L. Dao, ÊºCOVIDâ€19 image data collection,Êº arXiv preprint arXiv:2003.11597, 2020)

[19]

E. Goldstein, D. Keidar, D. Yaron, Y. Shachar, A. Blass, L. Charbinsky, et al., ÊºCOVIDâ€19 Classification of Xâ€ray Images Using Deep
Neural Networks,Êº arXiv preprint arXiv:2010.01362, 2020)

[20]

L. Wang and A. Wong, ÊºCOVIDâ€Net: A Tailored Deep Convolutional Neural Network Design for Detection of COVIDâ€19 Cases
from Chest Xâ€Ray Images,Êº arXiv preprint arXiv:2003.09871, 2020)

[21]

S. Motamed, P. Rogalla, and F. Khalvati, ÊºRANDGAN: Randomized Generative Adversarial Network for Detection of COVIDâ€19
in Chest Xâ€ray,Êº arXiv preprint arXiv:2010.06418, 2020)

[22]

A. I. Avilesâ€Rivero, P. Sellars, C.â€B. SchÃ¶nlieb, and N. Papadakis, ÊºGraphXCOVID: Explainable Deep Graph Diffusion Pseudoâ€
Labelling for Identifying COVIDâ€19 on Chest Xâ€rays,Êº arXiv preprint arXiv:2010.00378, 2020)

[23]

A. Degerli, M. Ahishali, M. Yamac, S. Kiranyaz, M. E. Chowdhury, K. Hameed, et al., ÊºCOVIDâ€19 Infection Map Generation and
Detection from Chest Xâ€Ray Images,Êº arXiv preprint arXiv:2009.12698, 2020)

[24]

N. K. Chowdhury, M. Rahman, N. Rezoana, and M. A. Kabir, ÊºECOVNet: An Ensemble of Deep Convolutional Neural Networks
Based on EfficientNet to Detect COVIDâ€19 From Chest Xâ€rays,Êº arXiv preprint arXiv:2009.11850, 2020)

[25]

M. Yamac, M. Ahishali, A. Degerli, S. Kiranyaz, M. E. Chowdhury, and M. Gabbouj, ÊºConvolutional Sparse Support Estimator
Based Covidâ€19 Recognition from Xâ€ray Images,Êº arXiv preprint arXiv:2005.04014, 2020)
Preprint submitted to Elsevier

November 25, 2020

[26]

M. Ahishali, A. Degerli, M. Yamac, S. Kiranyaz, M. E. Chowdhury, K. Hameed, et al., ÊºA Comparative Study on Early Detection of
COVIDâ€19 from Chest Xâ€Ray Images,Êº arXiv preprint arXiv:2006.05332, 2020)

[27]

S. Ahmed, M. H. Yap, M. Tan, and M. K. Hasan, ÊºReconet: Multiâ€level preprocessing of chest xâ€rays for covidâ€19 detection using
convolutional neural networks,Êº medRxiv, 2020)

[28]

T. Rahman, A. Khandakar, M. A. Kadir, K. R. Islam, K. F. Islam, R. Mazhar, et al., ÊºReliable Tuberculosis Detection using Chest Xâ€
ray with Deep Learning, Segmentation and Visualization,Êº arXiv preprint arXiv:2007.14895, 2020)

[29]

Y. A. Hamad, K. Simonov, and M. B. Naeem, ÊºBrainÊ¹s tumor edge detection on low contrast medical images,Êº in 2018 1st Annual
International Conference on Information and Sciences (AiCIS), 2018, pp. 45â€50.

[30]

R. Kaur and S. Kaur, ÊºComparison of contrast enhancement techniques for medical image,Êº in 2016 conference on emerging devices
and smart systems (ICEDSS), 2016, pp. 155â€159.

[31]

H. Ackar, A. Abd Almisreb, and M. A. Saleh, ÊºA Review on Image Enhancement Techniques,Êº Southeast Europe Journal of Soft
Computing, vol. 8 (1), 2019)

[32]

S. B. Rana and S. Rana, ÊºA review of medical image enhancement techniques for image processing,Êº International Journal of Current
Engineering and Technology, vol. 5 (2), pp. 1282â€1286(2015)

[33]

H. Vidyasaraswathi and M. Hanumantharaju, ÊºReview of various histogram based medical image enhancement techniques,Êº in
Proceedings of the 2015 International Conference on Advanced Research in Computer Science Engineering & Technology (ICARCSET 2015),
2015, pp. 1â€6.

[34]

V. A. Kotkar and S. S. Gharde, ÊºReview of various image contrast enhancement techniques,Êº International journal of innovative research
in Science, Engineering and Technology, vol. 2 (7), 2013)

[35]

R. Arun, M. S. Nair, R. Vrinthavani, and R. Tatavarti, ÊºAn alpha rooting based hybrid technique for image enhancement,Êº image,
vol. 9 (10), pp. 1â€10(2011)

[36]

K. Hasikin and N. A. M. Isa, ÊºEnhancement of the low contrast image using fuzzy set theory,Êº in 2012 UKSim 14th International

[37]

M. Selvi and A. George, ÊºFBFET: Fuzzy based fingerprint enhancement technique based on adaptive thresholding,Êº in 2013 Fourth

Conference on Computer Modelling and Simulation, 2012, pp. 371â€376.

International Conference on Computing, Communications and Networking Technologies (ICCCNT), 2013, pp. 1â€5.
[38]

M. F. Khan, E. Khan, and Z. Abbasi, ÊºSegment dependent dynamic multiâ€histogram equalization for image contrast enhancement,Êº
Digital Signal Processing, vol. 25 pp. 198â€223(2014)

[39]

W. Wang and X. Yuan, ÊºRecent advances in image dehazing,Êº 2017)

[40]

M. Farooq and A. Hafeez, ÊºCovidâ€resnet: A deep learning framework for screening of covid19 from radiographs,Êº arXiv preprint
arXiv:2003.14395, 2020)

[41]

U. Ozkaya, S. Ozturk, and M. Barstugan, ÊºCoronavirus (COVIDâ€19) Classification using Deep Features Fusion and Ranking
Technique,Êº arXiv preprint arXiv:2004.03698, 2020)

[42]

D. Ezzat and H. A. Ella, ÊºGSAâ€DenseNet121â€COVIDâ€19: a hybrid deep learning architecture for the diagnosis of COVIDâ€19 disease
based on gravitational search optimization algorithm,Êº arXiv preprint arXiv:2004.05084, 2020)

[43]

X. Li, C. Li, and D. Zhu, ÊºCOVIDâ€MobileXpert: Onâ€Device COVIDâ€19 Screening using Snapshots of Chest Xâ€Ray,Êº arXiv preprint
arXiv:2004.03042, 2020)

[44]

E. J. d. S. Luz, P. L. Silva, R. Silva, L. Silva, G. Moreira, and D. Menotti, ÊºTowards an Effective and Efficient Deep Learning Model
for COVIDâ€19 Patterns Detection in Xâ€ray Images,Êº CoRR, 2020)

[45]

Y. Oh, S. Park, and J. C. Ye, ÊºDeep learning covidâ€19 features on cxr using limited training data sets,Êº IEEE Transactions on Medical
Imaging, 2020)

[46]

B. D. Goodwin, C. Jaskolski, C. Zhong, and H. Asmani, ÊºIntraâ€model Variability in COVIDâ€19 Classification Using Chest Xâ€ray
Images,Êº arXiv preprint arXiv:2005.02167, 2020)

[47]

C. Zheng, X. Deng, Q. Fu, Q. Zhou, J. Feng, H. Ma, et al., ÊºDeep learningâ€based detection for COVIDâ€19 from chest CT using weak
label,Êº medRxiv, 2020)

[48]

S. Christodoulidis, M. Anthimopoulos, L. Ebner, A. Christe, and S. Mougiakakou, ÊºMultisource transfer learning with convolutional
neural networks for lung pattern analysis,Êº IEEE journal of biomedical and health informatics, vol. 21 (1), pp. 76â€84(2016)
Preprint submitted to Elsevier

November 25, 2020

[49]

H. Yang, S. Mei, K. Song, B. Tao, and Z. Yin, ÊºTransferâ€learningâ€based online Mura defect classification,Êº IEEE Transactions on
Semiconductor Manufacturing, vol. 31 (1), pp. 116â€123(2017)

[50]

S. AkÃ§ay, M. E. Kundegorski, M. Devereux, and T. P. Breckon, ÊºTransfer learning using convolutional neural networks for object
classification within xâ€ray baggage security imagery,Êº in 2016 IEEE International Conference on Image Processing (ICIP), 2016, pp. 1057â€
1061.

[51]

N. Tajbakhsh, J. Y. Shin, S. R. Gurudu, R. T. Hurst, C. B. Kendall, M. B. Gotway, et al., ÊºConvolutional neural networks for medical
image analysis: Full training or fine tuning?,Êº IEEE transactions on medical imaging, vol. 35 (5), pp. 1299â€1312(2016)

[52]

S. J. Pan and Q. Yang, ÊºA survey on transfer learning,Êº IEEE Transactions on knowledge and data engineering, vol. 22 (10), pp. 1345â€
1359(2009)

[53]

ResNet, AlexNet, VGGNet, Inception: Understanding various architectures of Convolutional Networks. Available: https://cvâ€

[54]

G. Huang, Z. Liu, L. Van Der Maaten, and K. Q. Weinberger, ÊºDensely connected convolutional networks,Êº in Proceedings of the

tricks.com/cnn/understandâ€resnetâ€alexnetâ€vggâ€inception/. [Accessed: 5â€Julyâ€2020]

IEEE conference on computer vision and pattern recognition, 2017, pp. 4700â€4708.
[55]

P. Rajpurkar, J. Irvin, K. Zhu, B. Yang, H. Mehta, T. Duan, et al., ÊºChexnet: Radiologistâ€level pneumonia detection on chest xâ€rays
with deep learning,Êº arXiv preprint arXiv:1711.05225, 2017)

[56]

C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna, ÊºRethinking the inception architecture for computer vision,Êº in

[57]

Y. LeCun, K. Kavukcuoglu, and C. Farabet, ÊºConvolutional networks and applications in vision,Êº in Proceedings of 2010 IEEE

Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 2818â€2826.

international symposium on circuits and systems, 2010, pp. 253â€256.
[58]

O. Ronneberger, P. Fischer, and T. Brox, ÊºUâ€net: Convolutional networks for biomedical image segmentation,Êº in International
Conference on Medical image computing and computerâ€assisted intervention, 2015, pp. 234â€241.

[59]

lungâ€segmentationâ€2d [Online]. Available: https://github.com/imlabâ€uiip/lungâ€segmentationâ€2d#readme. [Accessed on: 01 August
2020]

[60]

M. Veluchamy and B. Subramani, ÊºImage contrast and color enhancement using adaptive gamma correction and histogram
equalization,Êº Optik, vol. 183 pp. 329â€337(2019)

[61]

J. B. Zimmerman, S. M. Pizer, E. V. Staab, J. R. Perry, W. McCartney, and B. C. Brenton, ÊºAn evaluation of the effectiveness of
adaptive histogram equalization for contrast enhancement,Êº IEEE Transactions on Medical Imaging, vol. 7 (4), pp. 304â€312(1988)

[62]

D. Smilkov, N. Thorat, B. Kim, F. ViÃ©gas, and M. Wattenberg, ÊºSmoothgrad: removing noise by adding noise,Êº arXiv preprint
arXiv:1706.03825, 2017)

[63]

R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and D. Batra, ÊºVisual explanations from deep networks via gradientâ€
based localization,Êº in Proceedings of the IEEE International Conference on Computer Vision, pp. 618â€626.

[64]

A. Chattopadhay, A. Sarkar, P. Howlader, and V. N. Balasubramanian, ÊºGradâ€cam++: Generalized gradientâ€based visual
explanations for deep convolutional networks,Êº in 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), 2018, pp.
839â€847.

[65]

H. Wang, Z. Wang, M. Du, F. Yang, Z. Zhang, S. Ding, et al., ÊºScoreâ€CAM: Scoreâ€Weighted Visual Explanations for Convolutional
Neural Networks,Êº in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, 2020, pp. 24â€25.

[66]

kaggle. RSNA Pneumonia Detection Challenge

[Online]. Available: https://www.kaggle.com/c/rsnaâ€pneumoniaâ€detectionâ€

challenge/data. [Accessed on 09â€Juneâ€2020]
[67]

(2020). BIMCVâ€COVID19, Datasets related to COVID19â€™s pathology course

[Online]. Available: https://bimcv.cipf.es/bimcvâ€

projects/bimcvâ€covid19/#1590858128006â€9e640421â€6711. [Accessed on: 06 August 2020]
[68]

(2020).

covidâ€19â€imageâ€repository

[Online].

Available:

https://github.com/mlâ€workgroup/covidâ€19â€imageâ€

repository/tree/master/png. [Accessed on: 06 August 2020]
[69]

(2020). COVIDâ€19 DATABASE [Online]. Available: https://www.sirm.org/category/senzaâ€categoria/covidâ€19/. [Accessed on: 06
August 2020]

[70]

(2020). Chest Imaging [Online]. Available: https://www.eurorad.org/. [Accessed on: 06 August 2020]

[71]

(2020). covidâ€chestxrayâ€dataset [Online]. Available: https://github.com/ieee8023/covidâ€chestxrayâ€dataset. [Accessed on: 06 August
2020]
Preprint submitted to Elsevier

November 25, 2020

[72]

(2020). COVIDâ€19 Radiography Database

[Online]. Available: https://www.kaggle.com/tawsifurrahman/covid19â€radiographyâ€

database. [Accessed on: 06 August 2020]
[73]

(2020). COVIDâ€CXNet [Online]. Available: https://github.com/armiro/COVIDâ€CXNet. [Accessed on: 06 August 2020]

[74]

A. MikoÅ‚ajczyk and M. Grochowski, ÊºData augmentation for improving deep learning in image classification problem,Êº in 2018

[75]

E.

international interdisciplinary PhD workshop (IIPhDW), 2018, pp. 117â€122.
D.

SCIENCE.

Overfitting

in

Machine

Learning:

What

It

Is

and

How

to

Prevent

It

[Online].

Available:

https://elitedatascience.com/overfittingâ€inâ€machineâ€learning. [Accessed: 07 July 2020]
[76]

J. Schlemper, O. Oktay, M. Schaap, M. Heinrich, B. Kainz, B. Glocker, et al., ÊºAttention gated networks: Learning to leverage salient
regions in medical images,Êº Medical image analysis, vol. 53 pp. 197â€207(2019)

Preprint submitted to Elsevier

November 25, 2020

