Does Non-COVID19 Lung Lesion Help? Investigating Transferability
in COVID-19 CT Image Segmentation
Yixin Wanga,b , Yao Zhanga,b , Yang Liua,b , Jiang Tianb , Cheng Zhongb , Zhongchao Shib ,
Yang Zhanga,c,âˆ— and Zhiqiang Hea,c,âˆ—
a Institute

of Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China
Lab, Lenovo Research, Beijing, China
c Lenovo Corporate Research & Development, Lenovo Ltd., Beijing, China

arXiv:2006.13877v2 [eess.IV] 4 Jan 2021

b AI

ARTICLE INFO

ABSTRACT

Keywords:
COVID-19
CT image
Segmentation
Transfer learning

Background and Objective: Coronavirus disease 2019 (COVID-19) is a highly contagious virus
spreading all around the world. Deep learning has been adopted as an effective technique to aid
COVID-19 detection and segmentation from computed tomography (CT) images. The major challenge lies in the inadequate public COVID-19 datasets. Recently, transfer learning has become a
widely used technique that leverages the knowledge gained while solving one problem and applying
it to a different but related problem. However, it remains unclear whether various non-COVID19
lung lesions could contribute to segmenting COVID-19 infection areas and how to better conduct this
transfer procedure. This paper provides a way to understand the transferability of non-COVID19 lung
lesions and a better strategy to train a robust deep learning model for COVID-19 infection segmentation.
Methods: Based on a publicly available COVID-19 CT dataset and three public non-COVID19
datasets, we evaluate four transfer learning methods using 3D U-Net as a standard encoder-decoder
method. i) We introduce the multi-task learning method to get a multi-lesion pre-trained model for
COVID-19 infection. ii) We propose and compare four transfer learning strategies with various performance gains and training time costs. Our proposed Hybrid-encoder Learning strategy introduces a
Dedicated-encoder and an Adapted-encoder to extract COVID-19 infection features and general lung
lesion features, respectively. An attention-based Selective Fusion unit is designed for dynamic feature
selection and aggregation.
Results: Experiments show that trained with limited data, proposed Hybrid-encoder strategy based
on multi-lesion pre-trained model achieves a mean DSC, NSD, Sensitivity, F1-score and Accuracy of
0.704, 0.735, 0.682, 0.707 and 0.994, respectively, with better genetalization and lower over-fitting
risks for segmenting COVID-19 infection.
Conclusions: The results reveal the benefits of transferring knowledge from non-COVID19 lung lesions, and learning from multiple lung lesion datasets can extract more general features, leading to
accurate and robust pre-trained models. We further show the capability of the encoder to learn feature
representations of lung lesions, which improves segmentation accuracy and facilitates training convergence. In addition, our proposed Hybrid-encoder learning method incorporates transferred lung
lesion features from non-COVID19 datasets effectively and achieves significant improvement. These
findings promote new insights into transfer learning for COVID-19 CT image segmentation, which
can also be further generalized to other medical tasks.

1. Introduction
In December 2019, the coronavirus disease 2019 (COVID19) broke out and has become a global challenge since then.
This new virus was spreading rapidly, affecting countries
worldwide. Up to 30 July 2020, 16,341,920 identified cases
of COVID-19 have been reported in over 216 countries and
territories, resulting in 650,805 deaths. This severe disease
has been declared as a Public Health Emergency of International Concern by the World Health Organization (WHO).
A gold standard method to screen the COVID-19 patients is the real-time reverse transcription-polymerase chain
reaction(rRT-PCR)[1], which reports the results within few
hours to 2 days and requires repeated tests[2, 3]. Researchers
found that chest computed tomography (CT) images show
E-mail addresses: wangyixin19@mails.ucas.ac.cn (Yixin Wang),
zhangyang20@lenovo.com (Yang Zhang), hezq@lenovo.com (Zhiqiang
He)
âˆ— Corresponding author
ORCID (s): 0000-0002-8062-0765 (Y. Wang)

Yixin Wang et al.: Preprint submitted to Elsevier

strong ability to capture ground glass and bilateral patchy
shadows which are typical CT features in affected patients[4].
Thus, chest CT can help identify distinguishing patterns and
features in patients. Given that traditional CT imaging analysis methods are time-consuming and laborious, it is of great
importance to develop artificial intelligence (AI) systems to
aid COVID-19 diagnosis[5].
Segmentation in CT slices is a key component of the diagnostic work-up for patients with COVID-19 infection in
clinical practice[6]. Recently, deep learning with CNNs has
showed significant performance improvements on the automatic detection and automatic extraction of essential features
from CT images, related to the diagnosis of the Covid-19.
Though deep learning has made great progress in medical
image segmentation, it remains a challenging task in the field
of COVID-19 lung infection, as existing public datasets on
COVID-19 are relatively small and weakly labelled. Thus,
training deep networks from scratch with inadequate data
and task-specific nature such as COVID-19 infection may
Page 1 of 11

Does Non-COVID19 Lung Lesion Help? Investigating Transferability in COVID-19 CT Image Segmentation

lead to over-fitting and poor generalization.
Transfer learning is an effective method to solve this problem, which helps to leverage knowledge and latent features
from other datasets and avoids over-parameterization. In
transfer learning, successful deep learning models such as
ResNet, DenseNet and GoogLeNet have been trained on large
datasets such as ImageNet. These pre-trained models have
proven impressive performance on natural image downstream
tasks. However, there exists no large-scale annotated medical image datasets as data acquisition is difficult, and highquality annotations are expensive. Recent research[7] shows
that transfer learning from natural image datasets to medical
tasks produces very limited performance gain. In particular,
though with large medical datasets for pre-training, transfer
learning in the task of COVID-19 infection segmentation is
still much more difficult: 1) The shape, texture and position
of COVID-19 infections are in high variation. 2) Existing
large medical CT datasets differ in domains with COVID-19
datasets. Thus, similar in domain, a pre-trained model from
lung lesions may share more knowledge with COVID-19 infection and learn some general-purpose visual representations for lung lesions.
Evidence shows that larger datasets are necessarily better for pre-training and the diversity of datasets is extremely
important[8]. In medical domain, pre-training from medical datasets, especially chest CT datasets tends to be more
homogeneous compared to non-medical and other medical
areasâ€™ data. Thus, non-COVID19 lung lesion CT imaging
manifestations may serve as potential profit for COVID-19
segmentation. Existing works have proven that multi-task
training through simply fusing different lesions with COVID19 affects modelâ€™s representation ability for COVID-19 infection segmentation[9]. Therefore, with limited COVID-19
datasets, 1) whether these non-COVID19 lesions help and
to what extent they can contribute to COVID-19 infection
segmentation? 2) How to train a better pre-trained model
using these non-COVID19 datasets for transfer learning? 3)
In what manners can the pre-trained models fitted on nonCOVID19 lesions be effectively transferred to COVID-19?
In this paper, we aim to answer the above questions which
are significant for COVID-19 segmentation. To our best
knowledge, this is the first study to explore the transferability of non-COVID19 datasets for COVID-19 CT images segmentation.
Our contributions are as follows.
â€¢ We experimentally assess the extent of contributions
from non-COVID19 to COVID-19 infection segmentation. We found that despite the disparity between
non-COVID19 lung lesion images and COVID-19 infection images, pre-training on the large scale wellannotated lung lesions may still be transferred to benefit COVID-19 recognition and segmentation.
â€¢ We conduct extensive experiments using various nonCOVID19 lung lesion datasets. Although pre-training
on a single non-COVID19 dataset is unstable among
different transfer strategies, learning from different nonYixin Wang et al.: Preprint submitted to Elsevier

COVID19 lesions demonstrates promising performance
since such a multi-task learning process can share knowledge from different related tasks and discover common and general representations of lung lesions.
â€¢ We design four different transfer learning strategies
with various performance gains and training time costs:
Continual Learning, Body Fine-tuning, Pre-trained Lesion Representations and Hybrid-encoder Learning.
The Hybrid-encoder strategy effectively combines both
non-COVID19 and COVID-19 features and shows the
best performance. We further conclude that it is possible to freeze the encoder and train only the decoder on
COVID-19 tasks during fine-tuning, which provides
significant performance gains and fast convergence speed.

2. Background
In this section, we review the recent related research on
COVID-19 CT images, COVID-19 segmentation and transfer learning for COVID-19.

2.1. Research on COVID-19 CT Images
CT is widely used in the screening and diagnosis of COVID19 since ground-glass opacities and bilateral patchy shadows
are the most relative imaging features in pneumonia associated with infections. Recent research on CT-based diagnosis for COVID-19 has indicated great performance. Compared with traditional CT images processing, artificial intelligence (AI) serves as a core technology, enabling a more
accurate and efficient solution. The machine learning-based
CT radiomics models such as random forest, logistic regression showed feasibility and accuracy for predicting hospital stay in patients affected in the work of [10]. Machine
learning method was also adopted by Tang et al.[11] to realize automatic severity assessment (non-severe or severe)
of COVID-19 based on chest CT images, and to explore
the severity-related features from the resulting assessment
model. Gozes et al.[12] presented a system that utilized robust 2D and 3D deep learning models, modifying and adapting existing AI models and combining them with clinical
understanding. Huang et al.[13] monitored the disease progression and understood the temporal evolution of COVID19 quantitatively using serial CT scan by an automated deep
learning method.

2.2. Research on COVID-19 Segmentation
Segmentation is an essential step in AI-based image processing and analysis[6]. In particular, segmenting the regions of interests (ROIs) of COVID-19 infections is crucial
and helpful for doctors to make further assessment and quantification. However, manual contouring of these infections
is time-consuming and tedious. Although plenty of methods have been explored on COVID-19 diagnosis and classification, there are very few works on the segmentation of
COVID-19 infection due to its great annotation challenges.
Shan et al.[14] developed a DL-based system for automatic segmentation and quantification of infection regions
Page 2 of 11

Does Non-COVID19 Lung Lesion Help? Investigating Transferability in COVID-19 CT Image Segmentation

and adopted a human-in-the-loop (HITL) strategy to accelerate the manual delineation of CT training. Zheng et al.[15]
designed a weakly-supervised deep learning algorithm to investigate the potential of a deep learning-based model for automatic COVID-19 detection on chest CT volumes using the
weak patient-level label. Based on semi-supervised learning, Fan et al.[16] presented a COVID-19 Lung Infection
Segmentation Deep Network (Inf-Net) for CT slices based
on randomly selected propagation. Yan et al.[17] introduced
a feature variation block which adaptively adjusted the global
properties of the features for segmenting COVID-19 infection.

2.3. Research on COVID-19 Transfer Learning
In transfer learning, deep models are first trained on large
datasets such as ImageNet, then these pre-trained models are
fine-tuned on different downstream tasks. Several studies
[8], [18], [19] have investigated transfer learning methodologies on deep neural networks applied to medical image
analysis tasks. Plenty of works used networks pre-trained
on natural images to extract features and followed by another
classifier[20],[21]. Carneiro et al.[21] replaced the fully connected layers of a pre-trained model with a new logistic layer
and only trained the appended layer, yielding promising results for classification of unregistered multi-view mammograms. Other studies performed layer fine-tuning on the pretrained networks for adapting the learned features to the target domain. In [22], CNNs were pre-trained as a feature generator for chest pathology identification. Gao et al.[23] finetuned all the layers of a pre-trained CNN to classify interstitial lung diseases. Ghafoorian et al.[24] trained a CNN on
legacy MR images of brain and evaluated the performance of
the domain-adapted network on the same task with images
from a different domain.
Due to the limited labeled COVID-19 data, several transfer learning methods have been applied to address this problem. Chouhan et al.[25] proposed an ensemble approach of
transfer learning using pre-trained models trained on ImageNet. Researchers used five different pre-trained models
and analyzed their performance in chest X-ray images. In
the work of [26], several deep CNNs were employed for automatic COVID-19 infection detection from X-ray images
through tuning parameters. Majeed et al.[27] presented a
critical analysis for 12 off-the-shelf CNN models and proposed a simple CNN architecture with a small number of
parameters that performed well on distinguishing COVID19 from normal X-rays. By combining three different models which were fine-tuned on 3 datasets, Misra et al.[28] designed a multi-channel ensemble TL method based on ResNet18 in such a way that the model could extract more relevant
features for each class and identify COVID-19 features more
accurately from the X-ray images.
Even though the above studies on transfer learning present
inspiring achievement for COVID-19 research, there are several limitations: 1) They only focus on the ensemble of existing CNNs, but ignore the contribution of various datasets for
pre-training. 2) Their studies are limited to X-ray dataset and
Yixin Wang et al.: Preprint submitted to Elsevier

only dedicate to COVID-19 detection and classification. 3)
They lack an in-depth study on the transferability of different transfer manners related to COVID-19 infections. Our
work contributes to a much more difficult task of semantic segmentation in COVID-19 CT images. We explore the
transferability from the perspective of transferring knowledge from various non-COVID19 lung lesions. Moreover,
we investigate better transfer methods to assist COVID-19
segmentation.

3. Methodology
In this section, we briefly describe our backbone network
in 3.1, then introduce the multi-task learning method to get
a multi-lesion pre-trained model in 3.2. We further give detailed illustration on four transfer strategies employed in our
work in 3.3-3.5.

3.1. Encoder-Decoder Network
The U-Net is a commonly used network for medical semantic segmentation. As an advanced architecture, it has
a U-shape like structure with an encoding and a decoding
signal path. The encoder serves as a contraction to capture semantically image contextual features. The decoder
is a symmetric expanding path recovering spatial information. The two paths are connected using skip connections
on each same level, which recombine with essential highresolution features from the encoding path. In this work, we
make some minor changes following nnU-Net[29]. Original
batch normalization and ReLU are replaced by instance normalization and leaky ReLU. Whatâ€™s more, deep supervision
loss[30] is aggregated to obtain multi-level deep supervision
and facilitate the training process.

3.2. Pre-trained Multi-lesion Learning
Multi-task learning is an effective method to share knowledge among different related tasks. As for segmentation tasks,
the performance of each task highly depends on the similarity among these tasks. Due to the large domain distance
among those existing non-COVID19 lung lesion datasets,
fusing these lesions to train a multi-task segmentation model
tends to underperform on each single task. However, this
multi-task training can exploit the shared knowledge which
is essential for learning some general-purpose visual representations about lung lesions. Therefore, in our work, besides separately training segmentation models on each nonCOVID19 dataset as pre-trained models for transfer learning, we provide a multi-lesion model learning from multiple lung lesions. Compared with learning from separate
tasks, this multi-task strategy leads to a more robust pretrained model across all lesion tasks and empowers downstream COVID-19 task.

3.3. Continual Learning
Continual Learning aims to learn from an endless stream
of tasks[31]. This paradigm is capable of learning consecutive tasks without forgetting how to perform previously trained
tasks. This is challenging that the training process tends
Page 3 of 11

Does Non-COVID19 Lung Lesion Help? Investigating Transferability in COVID-19 CT Image Segmentation

to lose knowledge from the previous tasks due to the information relevant to current tasks. To avoid this, we adopt
a training schedule to pre-train the model. The value of
the initial learning rate is set as 0.01 and decays throughout the training process following the â€˜polyâ€™ learning rate
policy (1 âˆ’ epoch âˆ• epoch max )0.9 . In this way, the learning
rate is decreasing continuously so that the weight parameters after training non-COVID19 lesion tasks tend to follow
its training process while slightly being updated by the current COVID-19 infection task.

3.4. Fine-tuning
Fine-tuning is the most standard strategy to transfer knowledge from domains where data are abundant. In general,
it is conducted by copying the weights from a pre-trained
network and tuning them on the downstream task. Recent
work[32] shows that fine-tuning can enjoy better performance
on small datasets. It is of additional interest to assess the
contribution of the encoder and decoder relative to learning COVID-19 knowledge. While the progressive reinitializatons demonstrate the incremental effect of each layers, it
is unnecessary to prob the extent of localized reinitialization because our encoder-decoder network is not very deep.
Therefore, we adopt two strategies for tuning a non-COVID19
lesion model on the COVID-19 downstream task.

3.4.1. Body Fine-tuning
Due to the large domain difference between pre-trained
tasks and downstream tasks, the most secured fine-tuning
method is Body Fine-tuning, which means all parameters
of the pre-trained models are used as the initial values to
complete the training process of the model. When we train
COVID-19 infection networks, all of the parameters are assigned initially from the pre-trained models on non-COVID19
lesions. In this fine-tuning strategy, the update of parameters
largely depends on COVID-19 infection training process itself. Thus, it is a conservative fine-tuning approach that the
training task of COVID-19 infection is not affected by the
upstream pre-trained non-COVID19 models too much.
3.4.2. Pre-trained Lesion Representations
Our segmentation model is an encoder-decoder architecture and the encoder serves as a series of convolution
operations to encode image features into context representations. These representations are trained on large relative
datasets from upstream tasks, and fed as features to downstream ones. In natural language processing tasks, features
extracted from internal representations of sequence language
models are encoded as pre-trained text representations[31],
[32]. In this fine-tuning strategy, we aim to learn general
lung lesion features, which we call Pre-trained Lesion Representations. We first train models on non-COVID19 lung
lesion datasets. The encoders of these models are capable of
encoding lesion features. In other words, the encodersâ€™ parameters can exhibit some transferability. Thus, in the following fine-tuning process on COVID-19 dataset, we preYixin Wang et al.: Preprint submitted to Elsevier

Decoder

Selective Fusion
Dedicated-encoder

Adapted-encoder

COVID-19

Multi-lesion pre-trained model

MSD tumor

StructSeg

NSCLC

Non-COVID19 Lung Lesion
HÃ—WÃ—C

ğ— ğğ

HÃ—WÃ—C
a
ğ—ğŸ

s
1Ã—1Ã—C

z
1Ã—1Ã—C/r

softmax

ğ— ğ’”ğ’‡

b
HÃ—WÃ—C

ğ— ğšğ

Selective Fusion

HÃ—WÃ—C

Figure 1: An overview of Hybrid-encoder transfer learning
strategy. The U-Net network consists of a parallel encoder
and a shared decoder. Features from Dedicated-encoder and
Adapted-encoder are aggregated via a Selective Fusion unit.
For simplicity the figure shows 2D images.

serve and freeze them while only fine-tuning and re-training
the decoding parts.

3.5. Hybrid-encoder Learning
During performing the above fine-tuning strategies, we
face two challenges: 1) Body Fine-tuning easily falls into
over-fitting because the downstream COVID-19 infection dataset
is much smaller. 2) Utilizing the encoder of pre-trained models to capture feature representation is unstable, because the
label spaces and losses for the upstream and downstream
tasks differ inevitably. For example, though they are all lung
lesions, they differ in appearance and shape. Therefore, we
present a new transfer learning strategy for COVID-19, which
incorporates three key properties:
â€¢ It leverages the transferred knowledge from non-COVID19
lung lesions.
â€¢ It gains stable performance improvement in both training from scratch and transfer learning methods.
â€¢ It shows no obvious training time increase.
To achieve these properties, we propose a Hybrid-encoder
architecture. As shown in Fig.1, we enhance the standard UNet network by equipping with two encoders with the same
architecture: Dedicated-encoder and Adapted-encoder. Furthermore, an attention-based Selective Fusion unit is developed to aggregate information from both of the encoders by
determining two sets of learnable weights.

Page 4 of 11

Does Non-COVID19 Lung Lesion Help? Investigating Transferability in COVID-19 CT Image Segmentation

3.5.1. Dedicated-encoder
The Dedicated-encoder is a task-specific feature extractor, focusing on segmenting COVID-19 infection through
reinitializing all the parameters. These parameters Î˜ğ‘‘ğ‘’ are
all COVID19-specific which enable continuing update to the
network.
3.5.2. Adapted-encoder
The Adapted-encoder is an auxiliary feature extractor,
aiming to learn general lung lesion features. Based on Pretrained Multi-lesion learning in 3.2, we pre-train our 3D UNet networkâ€™s encoder to obtain dense representations of general lung lesions. When being transferred to target COVID19 task, this pre-trained encoder serves as an adapted-encoder
by totally freezing its pre-trained parameters as Î˜ğ‘ğ‘‘ .
Given a COVID-19 input volume as the ğ‘ ğ‘¡â„ sample Xs âˆˆ
ğ»Ã—ğ‘Š
Ã—ğ· , it is passed through the above paralleled encoders.
â„
Each encoder follows the same 3D U-Net, which consists of
a number of stacked convolution layers and pooling layers.
ğ‘ğ‘‘
ğ‘¡â„
More specifically, let ğ‘¥ğ‘‘ğ‘’
ğ‘– , ğ‘¥ğ‘– be the output of ğ‘– layer of
Dedicated-encoder and Adapted-encoder, respectively. These
vectors can be obtained from the output of the previous layer
ğ‘¥ğ‘‘ğ‘’
and ğ‘¥ğ‘ğ‘‘
by a mapping îˆ´(â‹…):
ğ‘–âˆ’1
ğ‘–âˆ’1
ğ‘¥ğ‘‘ğ‘’
ğ‘–
ğ‘¥ğ‘ğ‘‘
ğ‘–

))
)
( (
(
, ğ‘– âˆˆ {0, â€¦ , ğ‘™},
= ğœ îˆµ ğ–ğğ âˆ— ğ‘¥ğ‘‘ğ‘’
= îˆ´ ğ‘¥ğ‘‘ğ‘’
ğ‘–âˆ’1
ğ‘–âˆ’1
(1)
))
( ( ğšğ
( ğ‘ğ‘‘ )
ğ‘ğ‘‘
= îˆ´ ğ‘¥ğ‘–âˆ’1 = ğœ îˆµ ğ– âˆ— ğ‘¥ğ‘–âˆ’1 , ğ‘– âˆˆ {0, â€¦ , ğ‘™},

where ğ‘Š represents the weight matrix, âˆ— denotes convoluton
operation, îˆµ(â‹…) and ğœ(â‹…) represent instance normalization and
leaky ReLU, respectively.
At the end of the encoding phase, both Dedicated-encoder
and Adapted-encoder representations with ğ¶ channels containing rich semantic information are learned separately from
de
COVID-19
and
(datasets,)denoted as X =
) non-COVID19
(
ad
ğ‘“ğ‘‘ğ‘’ Xğ‘  ; Î˜ğ‘‘ğ‘’ and X = ğ‘“ğ‘ğ‘‘ Xğ‘  ; Î˜ğ‘ğ‘‘ , and the two encoders are parameterized by Î˜ğ‘‘ğ‘’ and Î˜ğ‘ğ‘‘ , respectively.

3.5.3. Selective Fusion
Inspired by [33], we design a Selective Fusion operation to combine and aggregate the information from both encoders to obtain a global and comprehensive representation
for decoding phase. To achieve this, we first fuse Xde and
Xad using element-wise summation operation âŠ• as follows:
Xf = Xde âŠ• Xad .

(2)

We then apply global average pooling to shrink Xf through
its 3D spatial dimensions ğ» Ã— ğ‘Š Ã— ğ·. The ğ‘ ğ‘¡â„ element of
channel-wise statistics ğ¬ âˆˆ â„ğ¶ is calculated by:
( )
ğ‘ ğ‘ = îˆ²ğ‘”ğ‘ Xf =

ğ» âˆ‘
ğ‘Š âˆ‘
ğ·
âˆ‘
1
Xf (ğ‘–, ğ‘—, ğ‘™). (3)
ğ» Ã— ğ‘Š Ã— ğ· ğ‘–=1 ğ‘—=1 ğ‘™=1

The output ğ‘ ğ‘ can be interpreted as integrated local descriptors to provide selection guidance. In order to exploit channelwise dependencies, we conduct fully connection (fc) via ğ– âˆˆ
Yixin Wang et al.: Preprint submitted to Elsevier

ğ¶

ğ¶

â„ ğ‘Ÿ Ã—ğ¶ to reduce the dimension to ğ³ âˆˆ â„ ğ‘Ÿ Ã—1 with a reduction
ratio ğ‘Ÿ:
ğ³ = îˆ²ğ‘“ ğ‘ (ğ¬) = ğœ(îˆµ(ğ– âˆ— ğ¬)).

(4)

To adaptively select different information from two encoders,
we utilize softmax operation to obtain soft-attention across
channels by:
ğš=

ğ‘’ğğ³
ğ‘’ğ€ğ³
, ğ› = ğ€ğ³
,
ğğ³
+ğ‘’
ğ‘’ + ğ‘’ğğ³

ğ‘’ğ€ğ³

(5)

ğ¶

where ğ€, ğ âˆˆ â„ ğ‘Ÿ Ã—ğ¶ and ğš, ğ› represent the soft attention
vectors for Xde and Xad , respectively. Through applying these
soft-attentions using Eqn. 6, features from these two paralleled encoders are dynamic selected as incorporated COVID19 feature representations ğ—ğ¬ğŸ and then fed into the decoding
part.
(
)
(6)
ğ—ğ¬ğŸ = îˆ´ ğš â‹… Xde âŠ• ğ› â‹… Xad

4. Experiments
In this section, we will describe in detail the datasets,
experimental setup and results of our investigation.

4.1. Dataset Introduction
4.1.1. COVID-19 Dataset
This dataset is released by Coronacases Initiative and
Radiopaedia1 . It is a publicly available COVID-19 volume
dataset which contains 20 COVID-19 CT scans. In the work
of [9], [34], left lung, right lung, and infections are welllabelled by two radiologists and verified by an experienced
radiologist. Thus, with over 1800 annotated slices, this dataset
serves as a downstream COVID-19 infection segmentation
dataset for transfer learning in our work.

4.1.2. Non-COVID19 Lung Lesion Datasets
In order to better explore the transferability from various non-COVID19 lung lesions to COVID-19 infections,
the following relationships need to be satisfied among these
datasets: 1) The size of different lesion datasets are similar.
2) The shape, size and location of different lesion areas are
relatively distinguishing. Therefore, in this paper, we introduce three public datasets.
MSD Lung Tumor This dataset was used in a crowdsourced challenge of generalized semantic segmentation algorithms called the Medical Segmentation Decathlon (MSD)
held in MICCAI 20182 . This dataset includes patients with
non-small cell lung cancer from Stanford University (Palo
Alto, CA, USA) publicly available through TCIA and previously utilized to create a radiogenomic signature[35], [36],
[37]. The tumor regions are denoted by an expert thoracic radiologist on a representative CT cross section using OsiriX[38].
63 3D CT scans with corresponding tumor segmentation masks
are utilized in our paper.
1 https://github.com/ieee8023/covid-chestxray-dataset
2 http://medicaldecathlon.com/

Page 5 of 11

Does Non-COVID19 Lung Lesion Help? Investigating Transferability in COVID-19 CT Image Segmentation

StructSeg Lung Cancer StructSeg organ dataset is a
collection of 3D organ CT scans along with their segmentation ground-truth from 2019 MICCAI challenge3 . This
dataset contains two types of cancers, nasopharyngeal cancer and lung cancer. We adopt the gross target volume segmentation of lung cancer from 50 patients. Each CT scan
is annotated by an experienced oncologist and verified by
another one.
NSCLC Pleural Effusion This dataset is developed from
a Non-Small Cell Lung Cancer (NSCLC) cohort of 211 subjects4 . 78 cases with pleural effusion are selected with their
segmentation masks.

by:
|
|
(ğœ) |
(ğœ) |
|ğœ•ğ´ âˆ© ğ‘…ğœ•ğµ | + |ğœ•ğµ âˆ© ğ‘…ğœ•ğ´ |
|
|
|
|,
ğ‘ğ‘†ğ·(ğ´, ğµ) =
|ğœ•ğ´| + |ğœ•ğµ|

(8)

(ğœ)
where ğ‘…(ğœ)
and ğ‘…ğœ•ğµ
represent the borders of ground-truth
ğœ•ğ´
and segmentation masks which use a threshold ğœ to tolerate
the inter-rater variability of the annotators. We set ğœ = 3ğ‘šğ‘š
for COVID-19 infection. In contrast to the DSC, which measures the overlap of volumes, the NSD measures the overlap
of two surfaces.
We also consider three other evaluation metrics. Accuracy denotes the correct rate for both positive and nega4.2. Experimental Settings
tive predictions. Sensitivity shows the percentage of posAll the experiments are implemented in Pytorch and trained itive instances correctly identified positive. F1-score is the
on NVIDIA Tesla V100 32GB GPU. For fair comparison,
weighted harmonic average of Precision and Sensitivity which
we follow the settings on COVID-19 dataset benchmarks in
is an effective and comprehensive evaluation.
[9].
4.4. Analysis of Different Non-COVID19
For the COVID-19 dataset, we use 5-fold cross validation based on a pre-defined dataset split file. Each fold conPre-trained Models
tains 4 scans (20%) for training and 16 (80%) for testing.
All of the four pre-trained models (MSD, StructSeg, NSCLC,
Training fewer data is more suitable for exploring the conMulti-lesion) are utilized to investigate the ability of transfer
tribution of transfer learning.
learning to COVID-19 datasets. With extensive experiments
For non-COVID19 lung lesion datasets, we all randomly
in Table 1, we observe that different pre-trained models show
select 80% of the data for training and the rest of 20% for validifferent transferability. The best scores of models corredation. Pre-trained models based on these non-COVID19 lesponding to each transfer learning strategies are highlighted
sions are all trained from scratch with random initial paramalong with the detailed comparative analysis of 5 validation
eters using 3D U-Net network. Due to the limited number of
folds.
different lesion cases, we do data pre-processing following
4.4.1. Single-lesion Pre-trained Model
nnU-Net[29]. The input patch size is set as 50Ã—160Ã—192 and
Among pre-trained models on each single lesion (MSD,
batch size as 2. Stochastic gradient descent optimizer with
StructSeg, NSCLC), compared with training COVID-19 datasets
an initial learning rate of 0.01 and a nesterov momentum of
from scratch, MSD tumor pre-trained model improves the
0.99 are used for non-COVID19 pre-training. Reduction rasegmentation by 3.0% DSC and 3.2% NSD at most. Meantio ğ‘Ÿ is set as 16, following [33]. We adopt a summation of
while, StructSeg and NSCLC lung lesion pre-trained modDice loss and Cross entropy loss as loss function.
els show instability under different transfer strategies. As
shown in Table 1, with Continual Learning and Body Fine4.3. Evaluation Metrics
tuning strategies, StructSeg and NSCLC pre-trained models
Diagnostic evaluation is often used in clinical practice
can achieve promising improvement in most folds, but infor disease diagnosis, patient follow-up or efficacy monitorstead, they obtain lower performance with the strategy of
ing. Whether the results of a certain diagnostic evaluation
Pre-trained Lesion Representations. The rationale is that
are true, reliable and practical, will largely determine a reathere exists a large domain distance between these two lesonable medical decision. In this work, we introduce five
sions and COVID-19 infection. The strategy of Pre-trained
evaluation metrics for the exploration of transferability.
Lesion Representations totally uses encoded non-COVID19
Dice similarity coefficient (DSC) measures volumetric
lesion features. Thus, the transferability of a single-lesion
overlap between segmentation results and annotations. It is
dataset model largely depends on their domain difference.
computed by:

2|ğ´ âˆ© ğµ|
,
|ğ´| + |ğµ|

4.4.2. Multi-lesion Pre-trained Model
As shown in Table 1, we further notice that among all
transfer learning strategies, multi-lesion pre-trained model
where A is the sets of foreground voxels in the annotation
not only achieves a high percentage for DSC and NSD valand B is the corresponding sets of foreground voxels in the
ues, but also performs the most stably among all pre-trained
segmentation result, respectively.
models, with the average DSC value of 0.696, 0.696, 0.693,
Normalized surface distance (NSD)[39] serves as a distance- 0.704, respectively. This shows the robustness of a multibased measurement to assess performance. It is computed
lesion pre-trained model used for transfer learning to COVID3 https://structseg2019.grand-challenge.org
19 infection. Table 2 further verifies this demonstration us4 https://wiki.cancerimagingarchive.net/display/Public/NSCLCing Sensitivity, F1-score and Accuracy concerned with difRadiomics
ferent transfer strategies. It is observed that transferring from
ğ·ğ‘†ğ¶(ğ´, ğµ) =

Yixin Wang et al.: Preprint submitted to Elsevier

(7)

Page 6 of 11

Does Non-COVID19 Lung Lesion Help? Investigating Transferability in COVID-19 CT Image Segmentation

(a)

(b)

(c)

(d)

(e)
CT Image

Ground-truth Train from scratch

MSD

StructSeg

NSCLC

Multi-lesion

Figure 2: Visual comparison of COVID-19 infection segmentation results. Training from scratch means using no pre-trained
models. MSD, StructSeg, NSCLC and Multi-lesion mean using pre-trained models from corresponding non-COVID19 lesion
datasets.
Table 1
Results of 5-fold cross validation of different transfer learning strategies under different non-COVID19 lung lesion pre-trained
models. The best results are shown in red font.
Transfer Strategy
Train from
scratch

Pre-trained

fold 0

fold 1

fold 2

fold 3

fold 4

AVG

model

DSC

NSD

DSC

NSD

DSC

NSD

DSC

NSD

DSC

NSD

DSC

NSD

None

0.681Â±0.205

0.709Â±0.213

0.713Â±0.205

0.718Â±0.230

0.662Â±0.217

0.717Â±0.242

0.681Â±0.231

0.708Â±0.271

0.627Â±0.269

0.649Â±0.282

0.673Â±0.223

0.700Â±0.224
0.732Â±0.219

MSD

0.696Â±0.211

0.725Â±0.219

0.731Â±0.206

0.734Â±0.238

0.724Â±0.166

0.782Â±0.180

0.720Â±0.205

0.745Â±0.224

0.646Â±0.235

0.672Â±0.242

0.703Â±0.203

Continual

StructSeg

0.672Â±0.234

0.704Â±0.231

0.712Â±0.206

0.716Â±0.234

0.704Â±0.163

0.762Â±0.183

0.717Â±0.192

0.745Â±0.208

0.600Â±0.264

0.616Â±0.276

0.681Â±0.214

0.709Â±0.228

Learning

NSCLC

0.673Â±0.215

0.702Â±0.219

0.712Â±0.209

0.720Â±0.244

0.722Â±0.145

0.775Â±0.169

0.720Â±0.209

0.745Â±0.235

0.581Â±0.283

0.605Â±0.292

0.681Â±0.218

0.709Â±0.237

Multi-lesion

0.709Â±0.209

0.726Â±0.220

0.740Â±0.209

0.735Â±0.232

0.692Â±0.191

0.745Â±0.198

0.721Â±0.208

0.749Â±0.219

0.618Â±0.251

0.638Â±0.260

0.696Â±0.213

0.718Â±0.225

MSD

0.679Â±0.214

0.706Â±0.224

0.706Â±0.210

0.708Â±0.250

0.724Â±0.157

0.785Â±0.167

0.708Â±0.178

0.724Â±0.228

0.623Â±0.247

0.642Â±0.253

0.688Â±0.201

0.713Â±0.225

Body

StructSeg

0.689Â±0.203

0.710Â±0.222

0.719Â±0.207

0.721Â±0.238

0.713Â±0.161

0.770Â±0.173

0.724Â±0.209

0.743Â±0.231

0.603Â±0.265

0.617Â±0.271

0.689Â±0.211

0.712Â±0.229

Fine-tuning

NSCLC

0.696Â±0.197

0.714Â±0.213

0.716Â±0.206

0.720Â±0.239

0.673Â±0.208

0.734Â±0.219

0.690Â±0.229

0.707Â±0.266

0.579Â±0.288

0.590Â±0.298

0.671Â±0.228

0.693Â±0.248

Multi-lesion

0.702Â±0.209

0.715Â±0.221

0.736Â±0.209

0.730Â±0.235

0.703Â±0.182

0.755Â±0.188

0.725Â±0.211

0.754Â±0.225

0.612Â±0.254

0.628Â±0.263

0.696Â±0.213

0.717Â±0.227

Pre-trained
Lesion
Representations
Hybrid-encoder

MSD

0.709Â±0.210

0.735Â±0.225

0.741Â±0.207

0.751Â±0.233

0.713Â±0.159

0.763Â±0.173

0.693Â±0.217

0.689Â±0.262

0.618Â±0.249

0.637Â±0.258

0.695Â±0.209

0.715Â±0.232

StructSeg

0.657Â±0.231

0.670Â±0.243

0.696Â±0.215

0.687Â±0.249

0.657Â±0.233

0.701Â±0.246

0.682Â±0.231

0.701Â±0.237

0.536Â±0.271

0.535Â±0.276

0.645Â±0.238

0.659Â±0.252

NSCLC

0.663Â±0.214

0.668Â±0.224

0.695Â±0.209

0.683Â±0.241

0.626Â±0.240

0.664Â±0.251

0.658Â±0.229

0.670Â±0.254

0.544Â±0.285

0.543Â±0.294

0.637Â±0.237

0.646Â±0.253

Multi-lesion

0.704Â±0.210

0.728Â±0.220

0.731Â±0.208

0.737Â±0.235

0.705Â±0.193

0.748Â±0.213

0.725Â±0.209

0.751Â±0.221

0.602Â±0.265

0.618Â±0.271

0.693Â±0.218

0.716Â±0.232

Multi-lesion

0.712Â±0.207

0.737Â±0.225

0.731Â±0.205

0.745Â±0.237

0.726Â±0.132

0.783Â±0.163

0.736Â±0.131

0.778Â±0.143

0.615Â±0.254

0.634Â±0.269

0.704Â±0.206

0.735Â±0.224

multi-lesion pre-trained model outperforms training from scratch 19 but shows dissatisfying instability. However, pre-training
on all these evaluation metrics among all strategies. Signififrom multi-lesion model shows high precision and smooth
cantly, when it comes to Pre-trained Lesion Representations,
boundary like manually annotated.
where the encoder of pre-trained models is totally frozen
4.5. Analysis of Different Transfer Learning
and serves as a non-COVID19 lesion features extractor, the
multi-lesion pre-trained model can still perform well. This
Strategies
confirms the effectiveness of multi-task training for multiBased on the above conclusion that multi-lesion pre-trained
ple lung lesions, which generates more robust and generalmodel brings consistently higher accuracy and robustness,
purpose representations to help COVID-19 infection tasks.
we further analyze the performance of different transfer strateFig.2(a)-(e) show some examples of segmentation results of
gies adopted in this paper.
the above pre-trained models. It is clear that compared with
Table 3 shows the results of COVID-19 infection segtraining from scratch, pre-training from single non-COVID19 mentation using the same multi-lesion pre-trained model unmodels can obtain more accurate massive structures of COVID- der different transfer strategies. These results suggest that
Yixin Wang et al.: Preprint submitted to Elsevier

Page 7 of 11

Does Non-COVID19 Lung Lesion Help? Investigating Transferability in COVID-19 CT Image Segmentation
Table 2
Results of Average Sensitivity, F1-score and Accuracy of different transfer learning strategies under different non-COVID19
lung lesion pre-trianed models. The best results are shown in
red font.
Train from scratch

Sensitivity

F1-score

Accuracy

0.6204Â±0.2369

0.6728Â±0.2227

0.9939Â±0.0086

0.6592Â±0.2148
0.6317Â±0.2224
0.6371Â±0.2249
0.6545Â±0.2244

0.7033Â±0.2029
0.6809Â±0.2139
0.6814Â±0.2180
0.6962Â±0.2134

0.9942Â±0.0083
0.9941Â±0.0081
0.9939Â±0.0086
0.9941Â±0.0083

0.6482Â±0.2186
0.6392Â±0.2312
0.6270Â±0.2041
0.6528Â±0.2252

0.6877Â±0.2170
0.6894Â±0.2112
0.6709Â±0.2277
0.6956Â±0.1328

0.9934Â±0.0100
0.9940Â±0.0083
0.9941Â±0.0086
0.9941Â±0.0083

0.6809Â±0.2055
0.6218Â±0.2362
0.6200Â±0.2376
0.6622Â±0.2117

0.6949Â±0.2093
0.6455Â±0.2382
0.6371Â±0.2368
0.6934Â±0.2185

0.9940Â±0.0083
0.9926Â±0.0118
0.9929Â±0.0096
0.9940Â±0.0082

0.6818Â±0.2147

0.7069Â±0.1870

0.9943Â±0.0081

Continual Learning
MSD
StructSeg
NSCLC
Multi-lesion
Body Fine-tuning
MSD
StructSeg
NSCLC
Multi-lesion

Pre-trained Lesion Representations
MSD
StructSeg
NSCLC
Multi-lesion
Hybrid-encoder
Multi-lesion

all the transfer strategies improve the performance of training from scratch on average DSC, NSD and Sensitivity. In
particular, in fold 2, they improve the segmentation by more
than 6.4% DSC and 6.6% NSD on maximum. The strategies of Continual Learning and Body Fine-tuning get similar
promising results, which both improve the segmentation by
2.3% DSC, 1.8% NSD and 3.4% Sensitivity on average.
An interesting observation is that, compared with Continual Learning and Body Fine-tuning, where all the parameters are updated on COVID-19 dataset, the strategy of Pretrained Lesion Representations still achieves a competitive
performance with an entirely frozen encoder and inherited
weights of pre-trained non-COVID19 models. It is observed
to improve the DSC from 0.673 to 0.693, NSD from 0.700 to
0.716 and Sensitivity from 0.643 to 0.662. In particular, in
terms of training cost, Table 3 shows the training time (per
epoch) for each transfer strategy. It can be clearly seen that
the strategy of Pre-trained Lesion Representations spends
just 148s per epoch on average, much less than training from
scratch and other transfer strategies. Due to the frozen encoder, the strategy of Pre-trained Lesion Representations cuts
down nearly a half of parameters that need to be updated.
Thus, it is promising to adopt this strategy for COVID-19
transfer learning to save training costs and gain fast convergence.
It is also observed in Table 3 that our proposed Hybridencoder transfer learning strategy exhibits significantly better segmentation performance than other strategies using multilesion pre-trained model. It improves the average DSC from
0.673 to 0.704 and NSD from 0.700 to 0.735, which also
performs best among all the pre-trained models in Table 1.
In terms of Sensitivity, F1-score and Accuracy in Table 2,
proposed Hybrid-encoder learning outperforms other strateYixin Wang et al.: Preprint submitted to Elsevier

gies and enhances the values to 0.6818, 0.7069 and 0.9943,
respectively. The transfer ability of Hybrid-encoder is also
confirmed by Fig.3. Compared with training from scratch,
Hybrid-encoder learning yields segmentation results with more
accurate boundaries in Fig.3 (b)(c)(e) and identifies some
minor COVID-19 infection areas in Fig.3 (a)(d)(f). The success of proposed Hybrid-encoder learning strategy is owed
to the designed parallel encoders, where the COVID-19 and
non-COVID19 lesions are both employed for encoding feature representations, leading to better generalization and lower
over-fitting risks.

5. Discussion
A valuable demonstration is that a multi-lesion pre-trained
model can make the best of multiple lesion representations,
and advance the generalization and robustness of pre-trained
models. There is value in recognizing that the CT appearance of these different lung lesions share some similarity.
Thus, with more kinds of lung lesion datasets incorporated
to pre-train a model, we could achieve better performance.
This exploration is an important contribution, enabling more
research on transfer learning to COVID-19 infection from
the perspective of utilizing non-COVID19 lung lesions.
Moreover, this paper examines a series of different transfer learning strategies, including Continual Learning, Body
Fine-tuning, Pre-trained Lesion Representations and the proposed Hybrid-encoder Learning. We observe segmentation
improvement in all performance metrics. It is also noted
that the strategy of Pre-trained Lesion Representations with
a frozen encoder enhances performance as well. This gains
more insight into the significant transferability exhibited by
the encoding parameters. Though the encoding layers do not
contain any explicit knowledge of the COVID-19 infection,
their parameters still enable the optimizer to reach a higher
performance while fine-tuning. The rationale is that the encoded multi-lesion representations contain more high-level
and abundant encoding information of the medically relevant lung lesion observed in CT images. Through combining the multi-lesion representations and COVID-19 infection features, the proposed Hybrid-encoder achieves significant improvement. These observation and exploration are
important not only in COVID-19 transfer learning but also in
the general medical domain, because feature reuse from pretraining out-of-domain datasets shows significant improvement for task performance and training convergence.

6. Conclusion
In this paper, we investigate the transferability in COVID19 CT segmentation. We present a set of experiments to better understand how different non-COVID19 lung lesions influence the performance of COVID-19 infection segmentation and their different transfer ability under different transfer
learning strategies. Our results reveal clear benefits of pretraining on non-COVID19 lung lesion datasets when public
labelled COVID-19 datasets are inadequate to train a robust
deep learning model. Among all the strategies, our proposed
Page 8 of 11

Does Non-COVID19 Lung Lesion Help? Investigating Transferability in COVID-19 CT Image Segmentation

CT Image

Ground-truth

Train from scratch

Hybrid-encoder

(a)

(b)

(c)

(d)

(e)

(f)

Figure 3: Visual comparison of COVID-19 infection segmentation results between training from scratch and proposed Hybridencoder transfer learning strategy based on multi-lesion pre-trained model.

Table 3
Results of 5-fold cross validation of different transfer learning strategies based on Multi-lesion pre-trained model.
Time represents the training time for an epoch. The best results are shown in red font.
Train from scratch

fold 0
fold 1
fold 2
fold 3
fold 4
AVG

Continual Learning

Body Fine-tuning

Lesion Representations

Hybrid-encoder

DSCâ†‘

NSDâ†‘

Sen.â†‘

Timeâ†“

DSCâ†‘

NSDâ†‘

Sen.â†‘

Timeâ†“

DSCâ†‘

NSDâ†‘

Sen.â†‘

Timeâ†“

DSCâ†‘

NSDâ†‘

Sen.â†‘

Timeâ†“

DSCâ†‘

NSDâ†‘

Sen.â†‘

Timeâ†“

avg

0.681

0.709

0.639

224s

0.709

0.726

0.683

194s

0.702

0.715

0.668

196s

0.704

0.728

0.682

145s

0.712

0.737

0.696

212s

std

0.205

0.213

0.162

â€“

0.209

0.220

0.161

â€“

0.209

0.221

0.160

â€“

0.210

0.220

0.156

â€“

0.207

0.225

0.153

â€“

avg

0.713

0.718

0.707

194s

0.740

0.735

0.752

193s

0.736

0.730

0.754

196s

0.731

0.737

0.762

145s

0.731

0.745

0.773

210s

std

0.205

0.230

0.189

â€“

0.209

0.232

0.204

â€“

0.209

0.235

0.172

â€“

0.208

0.235

0.126

â€“

0.205

0.237

0.132

â€“

avg

0.662

0.717

0.621

224s

0.692

0.745

0.667

193s

0.703

0.755

0.688

194s

0.705

0.748

0.676

146s

0.726

0.783

0.701

212s

std

0.217

0.242

0.295

â€“

0.191

0.198

0.272

â€“

0.182

0.188

0.262

â€“

0.193

0.213

0.260

â€“

0.123

0.163

0.240

â€“

avg

0.681

0.708

0.604

194s

0.721

0.749

0.657

193s

0.725

0.754

0.648

196s

0.725

0.751

0.696

148s

0.736

0.778

0.705

215s

std

0.231

0.271

0.241

â€“

0.208

0.219

0.164

â€“

0.211

0.225

0.203

â€“

0.209

0.221

0.143

â€“

0.131

0.143

0.147

â€“

avg

0.627

0.649

0.531

194s

0.618

0.638

0.514

223s

0.612

0.628

0.506

194s

0.602

0.618

0.495

157s

0.615

0.634

0.534

218s

std

0.269

0.282

0.267

â€“

0.251

0.260

0.254

â€“

0.254

0.263

0.258

196s

0.265

0.271

0.255

â€“

0.254

0.269

0.263

â€“

avg

0.673

0.700

0.620

206s

0.696

0.718

0.655

199s

0.696

0.717

0.653

195s

0.693

0.716

0.662

148s

0.704

0.735

0.682

213s

std

0.223

0.224

0.237

16s

0.213

0.225

0.224

13s

0.213

0.227

0.225

1s

0.218

0.232

0.212

5s

0.206

0.224

0.200

3s

Hybrid-encoder Learning method based on multi-lesion pretrained model effectively utilizes tranferred non-COVID19
lung lesion knowledge and gains significant improvement.
Future research directions include utilizing more various
non-COVID19 lung lesion datasets and investigating better
transfer learning methods, so that non-COVID19 lung lesions can be effectively used to improve the quality of COVID19 infection segmentation in the absence of sufficient highquality COVID-19 datasets.

Declaration of Competing Interest
The authors have no conflict of interest to disclose.

[2]

[3]

[4]

References
[1] J. F.-W. Chan, C. C.-Y. Yip, K. K.-W. To, T. H.-C. Tang, S. C.-Y.
Wong, K.-H. Leung, A. Y.-F. Fung, A. C.-K. Ng, Z. Zou, H.-W. Tsoi,
G. K.-Y. Choi, A. R. Tam, V. C.-C. Cheng, K.-H. Chan, O. T.-Y.
Tsang, and K.-Y. Yuen, â€œImproved molecular diagnosis of covid-19
by the novel, highly sensitive and specific covid-19-rdrp/hel real-time

Yixin Wang et al.: Preprint submitted to Elsevier

[5]

reverse transcription-pcr assay validated in vitro and with clinical
specimens,â€ Journal of Clinical Microbiology, vol. 58, no. 5, 2020.
[Online]. Available: https://jcm.asm.org/content/58/5/e00310-20
A. I. Khan, J. L. Shah, and M. M. Bhat, â€œCoronet: A deep neural
network for detection and diagnosis of covid-19 from chest x-ray
images,â€ Computer Methods and Programs in Biomedicine, vol. 196,
p. 105581, 2020. [Online]. Available: http://www.sciencedirect.com/
science/article/pii/S0169260720314140
R. M. Pereira, D. Bertolini, L. O. Teixeira, C. N. Silla, and Y. M.
Costa, â€œCovid-19 identification in chest x-ray images on flat and hierarchical classification scenarios,â€ Computer Methods and Programs
in Biomedicine, vol. 194, p. 105532, 2020. [Online]. Available: http:
//www.sciencedirect.com/science/article/pii/S0169260720309664
M. Chung, A. Bernheim, X. Mei, N. Zhang, M. Huang, X. Zeng,
J. Cui, W. Xu, Y. Yang, Z. A. Fayad, A. Jacobi, K. Li, S. Li,
and H. Shan, â€œCt imaging features of 2019 novel coronavirus
(2019-ncov),â€ Radiology, vol. 295, no. 1, pp. 202â€“207, 2020,
pMID: 32017661. [Online]. Available: https://doi.org/10.1148/
radiol.2020200230
S. Jin, B. Wang, H. Xu, C. Luo, L. Wei, W. Zhao, X. Hou,
W. Ma, Z. Xu, Z. Zheng, W. Sun, L. Lan, W. Zhang, X. Mu,
C. Shi, Z. Wang, J. Lee, Z. Jin, M. Lin, H. Jin, L. Zhang,
J. Guo, B. Zhao, Z. Ren, S. Wang, Z. You, J. Dong, X. Wang,

Page 9 of 11

Does Non-COVID19 Lung Lesion Help? Investigating Transferability in COVID-19 CT Image Segmentation

[6]

[7]
[8]

[9]

[10]

[11]
[12]

[13]

[14]
[15]

[16]
[17]

[18]

[19]

[20]

[21]

J. Wang, and W. Xu, â€œAi-assisted ct imaging analysis for covid19 screening: Building and deploying a medical ai system
in four weeks,â€ medRxiv, 2020. [Online]. Available: https:
//www.medrxiv.org/content/early/2020/03/23/2020.03.19.20039354
F. Shi, J. Wang, J. Shi, Z. Wu, Q. Wang, Z. Tang, K. He, Y. Shi, and
D. Shen, â€œReview of artificial intelligence techniques in imaging data
acquisition, segmentation and diagnosis for covid-19,â€ IEEE Reviews
in Biomedical Engineering, pp. 1â€“1, 2020.
M. Raghu, C. Zhang, J. Kleinberg, and S. Bengio, â€œTransfusion: Understanding transfer learning for medical imaging,â€ 2019.
V. Cheplygina, M. [de Bruijne], and J. P. Pluim, â€œNot-sosupervised: A survey of semi-supervised, multi-instance, and
transfer learning in medical image analysis,â€ Medical Image
Analysis, vol. 54, pp. 280 â€“ 296, 2019. [Online]. Available: http:
//www.sciencedirect.com/science/article/pii/S1361841518307588
J. Ma, Y. Wang, X. An, C. Ge, Z. Yu, J. Chen, Q. Zhu, G. Dong,
J. He, Z. He, T. Cao, Y. Zhu, Z. Nie, and X. Yang, â€œTowards dataefficient learning: A benchmark for covid-19 ct lung and infection
segmentation,â€ Medical Physics, vol. n/a, no. n/a. [Online]. Available:
https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.14676
X. Qi, Z. Jiang, Q. YU, C. Shao, H. Zhang, H. Yue, B. Ma,
Y. Wang, C. Liu, X. Meng, S. Huang, J. Wang, D. Xu, J. Lei,
G. Xie, H. Huang, J. Yang, J. Ji, H. Pan, S. Zou, and S. Ju,
â€œMachine learning-based ct radiomics model for predicting hospital
stay in patients with pneumonia associated with sars-cov-2 infection:
A multicenter study,â€ medRxiv, 2020. [Online]. Available: https:
//www.medrxiv.org/content/early/2020/03/03/2020.02.29.20029603
Z. Tang, W. Zhao, X. Xie, Z. Zhong, F. Shi, J. Liu, and D. Shen,
â€œSeverity assessment of coronavirus disease 2019 (covid-19) using
quantitative features from chest ct images,â€ 2020.
O. Gozes, M. Frid-Adar, H. Greenspan, P. D. Browning, H. Zhang,
W. Ji, A. Bernheim, and E. Siegel, â€œRapid ai development cycle for
the coronavirus (covid-19) pandemic: Initial results for automated detection & patient monitoring using deep learning ct image analysis,â€
2020.
L. Huang, R. Han, T. Ai, P. Yu, H. Kang, Q. Tao, and
L. Xia, â€œSerial quantitative chest ct assessment of covid-19:
Deep-learning approach,â€ Radiology: Cardiothoracic Imaging,
vol. 2, no. 2, p. e200075, 2020. [Online]. Available: https:
//doi.org/10.1148/ryct.2020200075
F. Shan, Y. Gao, J. Wang, W. Shi, N. Shi, M. Han, Z. Xue, D. Shen,
and Y. Shi, â€œLung infection quantification of covid-19 in ct images
with deep learning,â€ 2020.
C. Zheng, X. Deng, Q. Fu, Q. Zhou, J. Feng, H. Ma, W. Liu, and
X. Wang, â€œDeep learning-based detection for covid-19 from chest
ct using weak label,â€ medRxiv, 2020. [Online]. Available: https:
//www.medrxiv.org/content/early/2020/03/26/2020.03.12.20027185
D.-P. Fan, T. Zhou, G.-P. Ji, Y. Zhou, G. Chen, H. Fu, J. Shen, and
L. Shao, â€œInf-net: Automatic covid-19 lung infection segmentation
from ct images,â€ 2020.
Q. Yan, B. Wang, D. Gong, C. Luo, W. Zhao, J. Shen, Q. Shi, S. Jin,
L. Zhang, and Z. You, â€œCOVID-19 Chest CT Image Segmentation â€“
A Deep Convolutional Neural Network Solution,â€ arXiv e-prints, p.
arXiv:2004.10987, Apr. 2020.
N. Tajbakhsh, J. Y. Shin, S. R. Gurudu, R. T. Hurst, C. B. Kendall,
M. B. Gotway, and J. Liang, â€œConvolutional neural networks for medical image analysis: Full training or fine tuning?â€ IEEE Transactions
on Medical Imaging, vol. 35, no. 5, pp. 1299â€“1312, 2016.
H.-C. Shin, H. R. Roth, M. Gao, L. Lu, Z. Xu, I. Nogues, J. Yao,
D. Mollura, and R. M. Summers, â€œDeep convolutional neural networks for computer-aided detection: Cnn architectures, dataset characteristics and transfer learning,â€ 2016.
V. Cheplygina, I. P. Pena, J. H. Pedersen, D. A. Lynch, L. Sorensen,
and M. de Bruijne, â€œTransfer learning for multicenter classification of
chronic obstructive pulmonary disease,â€ IEEE Journal of Biomedical
and Health Informatics, vol. 22, no. 5, p. 1486â€“1496, Sep 2018.
[Online]. Available: http://dx.doi.org/10.1109/JBHI.2017.2769800
G. Carneiro, J. C. Nascimento, and A. P. Bradley, â€œUnregistered mul-

Yixin Wang et al.: Preprint submitted to Elsevier

[22]

[23]

[24]

[25]

[26]

[27]

[28]
[29]

[30]
[31]
[32]
[33]
[34]

[35]
[36]

[37]

tiview mammogram analysis with pre-trained deep learning models,â€
in MICCAI, 2015.
Y. Bar, I. Diamant, L. Wolf, S. Lieberman, E. Konen, and
H. Greenspan, â€œChest pathology identification using deep feature selection with non-medical training,â€ Computer Methods in
Biomechanics and Biomedical Engineering: Imaging & Visualization, vol. 6, no. 3, pp. 259â€“263, 2018. [Online]. Available:
https://doi.org/10.1080/21681163.2016.1138324
M. Gao, U. Bagci, L. Lu, A. Wu, M. Buty, H.-C. Shin, H. Roth, G. Z.
Papadakis, A. Depeursinge, R. M. Summers, Z. Xu, and D. J. Mollura,
â€œHolistic classification of ct attenuation patterns for interstitial
lung diseases via deep convolutional neural networks,â€ Computer
Methods in Biomechanics and Biomedical Engineering: Imaging &
Visualization, vol. 6, no. 1, pp. 1â€“6, 2018, pMID: 29623248. [Online].
Available: https://doi.org/10.1080/21681163.2015.1124249
M. Ghafoorian, A. Mehrtash, T. Kapur, N. Karssemeijer, E. Marchiori, M. Pesteie, C. R. G. Guttmann, F.-E. de Leeuw, C. M. Tempany, B. van Ginneken, and et al., â€œTransfer learning for domain
adaptation in mri: Application in brain lesion segmentation,â€ Lecture
Notes in Computer Science, p. 516â€“524, 2017.
V. Chouhan, S. K. Singh, A. Khamparia, D. Gupta, P. Tiwari,
C. Moreira, R. DamaÅ¡eviÄius, and V. H. C. de Albuquerque, â€œA novel
transfer learning based approach for pneumonia detection in chest
x-ray images,â€ Applied Sciences, vol. 10, no. 2, p. 559, Jan 2020.
[Online]. Available: http://dx.doi.org/10.3390/app10020559
I. D. Apostolopoulos and T. A. Mpesiana, â€œCovid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks,â€ Physical and Engineering Sciences in Medicine, Apr 2020. [Online]. Available:
http://dx.doi.org/10.1007/s13246-020-00865-4
T. Majeed, R. Rashid, D. Ali, and A. Asaad, â€œCovid-19 detection
using cnn transfer learning from x-ray images,â€ medRxiv, 2020.
[Online]. Available: https://www.medrxiv.org/content/early/2020/
05/19/2020.05.12.20098954
S. Misra, S. Jeon, S. Lee, R. Managuli, and C. Kim, â€œMulti-Channel
Transfer Learning of Chest X-ray Images for Screening of COVID19,â€ arXiv e-prints, p. arXiv:2005.05576, May 2020.
F. Isensee, J. Petersen, S. A. A. Kohl, P. F. JÃ¤ger, and K. H.
Maier-Hein, â€œnnu-net: Breaking the spell on successful medical
image segmentation,â€ CoRR, vol. abs/1904.08128, 2019. [Online].
Available: http://arxiv.org/abs/1904.08128
Q. Dou, H. Chen, Y. Jin, L. Yu, J. Qin, and P.-A. Heng, â€œ3d deeply supervised network for automatic liver segmentation from ct volumes,â€
2016.
N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. de Laroussilhe, A. Gesmundo, M. Attariyan, and S. Gelly, â€œParameter-efficient
transfer learning for nlp,â€ 2019.
C. Sun, X. Qiu, Y. Xu, and X. Huang, â€œHow to fine-tune bert for text
classification?â€ 2019.
X. Li, W. Wang, X. Hu, and J. Yang, â€œSelective kernel networks,â€ in
Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR), June 2019.
M. Jun, G. Cheng, W. Yixin, A. Xingle, G. Jiantao, Y. Ziqi,
Z. Minqing, L. Xin, D. Xueyuan, C. Shucheng, W. Hao, M. Sen,
Y. Xiaoyu, N. Ziwei, L. Chen, T. Lu, Z. Yuntao, Z. Qiongjie,
D. Guoqiang, and H. Jian, â€œCOVID-19 CT Lung and Infection
Segmentation Dataset,â€ Apr. 2020. [Online]. Available: https:
//doi.org/10.5281/zenodo.3757476
S. Napel and S. K. Plevritis, â€œNsclc radiogenomics: Initial
stanford study of 26 cases,â€ 2014. [Online]. Available: https:
//wiki.cancerimagingarchive.net/x/Gglp
S. Bakr, O. Gevaert, S. Echegaray, K. Ayers, M. Zhou, M. Shafiq,
H. Zheng, J. Benson, W. Zhang, A. Leung, M. Kadoch, C. D Hoang,
J. Shrager, A. Quon, D. Rubin, S. Plevritis, and S. Napel, â€œA radiogenomic dataset of non-small cell lung cancer,â€ Scientific data, vol. 5,
Oct. 2018.
O. Gevaert, J. Xu, C. D. Hoang, A. N. Leung, Y. Xu, A. Quon,
D. L. Rubin, S. Napel, and S. K. Plevritis, â€œNon-small cell lung

Page 10 of 11

Does Non-COVID19 Lung Lesion Help? Investigating Transferability in COVID-19 CT Image Segmentation
cancer: identifying prognostic imaging biomarkers by leveraging
public gene expression microarray dataâ€“methods and preliminary
results,â€ Radiology, vol. 264, no. 2, p. 387â€”396, August 2012.
[Online]. Available: https://europepmc.org/articles/PMC3401348
[38] A. Rosset, L. Spadola, and O. Ratib, â€œOsirix: an open-source
software for navigating in multidimensional dicom images,â€ Journal
of digital imaging, vol. 17, no. 3, p. 205â€”216, September 2004.
[Online]. Available: https://europepmc.org/articles/PMC3046608
[39] S. Nikolov, S. Blackwell, R. Mendes, J. D. Fauw, C. Meyer,
C. Hughes, H. Askham, B. Romera-Paredes, A. Karthikesalingam,
C. Chu, D. Carnell, C. Boon, D. Dâ€™Souza, S. A. Moinuddin, K. Sullivan, D. R. Consortium, H. Montgomery, G. Rees, R. Sharma, M. Suleyman, T. Back, J. R. Ledsam, and O. Ronneberger, â€œDeep learning to achieve clinically applicable segmentation of head and neck
anatomy for radiotherapy,â€ 2018.

Yixin Wang et al.: Preprint submitted to Elsevier

Page 11 of 11

