A Measurement of Transportation Ban inside
Wuhan on the COVID-19 Epidemic by Vehicle
Detection in Remote Sensing Imagery
Chen Wu1, Jingwen Yuan2, Lixiang Ru3, Hongruixuan Chen1, Bo Du3, Liangpei
Zhang1
1. State Key Laboratory of Information Engineering in Surveying, Mapping and
Remote Sensing, Wuhan University
2. School of Remote Sensing and Information Engineering, Wuhan University
3. School of Computer Science, Wuhan University

Abstract
Wuhan, the biggest city in Chinaâ€™s central region with a population of more than 11
million, was shut down to control the COVID-19 epidemic on 23 January, 2020. Even
though many researches have studied the travel restriction between cities and provinces,
few studies focus on the transportation control inside the city, which may be due to the
lack of the measurement of the transportation ban. Therefore, we evaluate the
implementation of transportation ban policy inside the city by extracting motor vehicles
on the road from two high-resolution remote sensing image sets before and after Wuhan
lockdown. In order to detect vehicles from the remote sensing image datasets with the
resolution of 0.8m accurately, we proposed a novel method combining anomaly
detection, region grow and deep learning. The vehicle numbers in Wuhan dropped with
1

a percentage of at least 63.31% caused by COVID-19. Considering fewer interferences,
the dropping percentages of ring road and high-level road should be more representative
with the value of 84.81% and 80.22%. The districts located in city center were more
intensively affected by the transportation ban. Since the public transportations have
been shut down, the significant reduction of motor vehicles indicates that the lockdown
policy in Wuhan show effectiveness in controlling human transmission inside the city.
Keywords: COVID-19, Wuhan lockdown, transportation ban, remote sensing,
vehicle.

1. Introduction
The novel coronavirus disease 2019 (COVID-19) caused by SARS-CoV-2 quickly
spread in the city of Wuhan, China, in January 2020. China faced the risk of COVID19 outbreak due to chunyun (the massive human migration during the Spring Festival
holiday including typically 3 billion trips) (Chen et al. 2020). Since there is no specific
drug treatment and vaccine, the government implemented the travel ban in Wuhan city
to control the epidemic (Tian et al. 2020). Wuhan shut down all the inbound and
outbound transportations, as well as the public transports inside the city, on 23 January,
2020 (Wuhan municipal headquarters for the COVID-19 epidemic prevention and
control 2020a). Even though 5 million people left in the beginning of chunyun, there
were still more than 9 million people in Wuhan before city lockdown (China News
2020). It appears to be the largest quarantine in human history considering the

2

population covered (Tian et al. 2020).
Lots of researches have indicated that the transmission control measures limited the
growth of the COVID-19 epidemic in China (Chen et al. 2020; Chinazzi et al. 2020;
Commission 2020; Jia et al. 2020; Kraemer et al. 2020; Tian et al. 2020). However,
most publications focus on the study of the travel ban from Wuhan to other cities and
provinces, which may be because it is hard to quantitatively evaluate the transportation
restriction inside the city. As the main component of urban transportation, most motor
vehicles were banned on 26 January, expect the allowed anti-epidemic cars (Wuhan
municipal headquarters for the COVID-19 epidemic prevention and control 2020b).
Therefore, considering the public transportations have been shut down, the statistics of
motor vehicles on the road before and after Wuhan lockdown is a good approach to
evaluate the implementation of transportation ban policy.
Remote sensing provides an appropriate data source for large-scale study (Reichstein
et al. 2019), such as environment study (Gray et al. 2020; Liu et al. 2020), landuse/land-cover study (Gao and Oâ€™Neill 2020; Jin et al. 2013; Yang et al. 2018),
vegetation monitoring (Erb et al. 2018; RÃ¶dig et al. 2019; Taubert et al. 2018).
Nowadays, the high-resolution remote sensing images show significant potentials to
distinguish cars from the road, and make an objective statistic for counting the vehicle
number on the road throughout the whole city (Eikvil et al. 2009; Tanveer et al. 2020).
There are numerous studies focusing on vehicle detection on remote sensing imagery
(Ji et al. 2020; Leitloff et al. 2010). However, most of the existing studies are based on
3

the aerial images, since their resolutions are smaller than 0.3m and have enough spatial
details to identify cars (Audebert et al. 2017; Chen et al. 2016; Li et al. 2019; Tang et
al. 2017a; Tang et al. 2017b; Tao et al. 2019). The problem is, only a few satellite
sensors can reach the resolution of 0.3m, and they are not just in the right pathway to
acquire the necessary images. Hence, it is hard to obtain an ideal performance of vehicle
detection with existing methods when dealing with remote sensing images with a lower
resolution and lacking of enough information of vehicle shape.
In order to implement a measurement of transportation ban inside Wuhan caused by
COVID-19, we collected two sets of high-resolution images acquired before and after
Wuhan lockdown, by a Chinese high-resolution remote sensing satellite GF-2 with the
resolution of 0.8m. These images covered an area of 2204ğ‘˜ğ‘š , and almost half of the
central region of Wuhan city. Since the vehicles are nearly a clustering of pixels without
any details in such a resolution, we proposed a novel method combining anomaly
detection, region grow and deep learning to detect vehicles on the road. The road lines
from open street map were used to exclude the non-road distributions. The dropping
percentages of vehicle numbers after Wuhan lockdown were calculated to measure the
implementation of the transportation ban policy in the whole city and different districts,
even specific into ring roads and high-level roads. This work builds a new capacity for
studying the effect of lockdown policy inside the city during COVID-19 epidemic.
The manuscript was organized as follows. Section 2 introduces the study site, remote
sensing data collected and data pre-processing. In the section 3, we describe the novel
4

vehicle detection method, including vehicle candidate extraction and deep learning
identification. Then, in section 4 and 5, we present detailed analysis about vehicle
dropping caused by transportation ban. Finally, we draw a conclusion in section 6.

2. Study Site

.

.

Open Street Map
Study Site
District Boundary

Study Site
District Boundary

0 4.5 9

18

27

36
KM

0 4.5 9

(a)

(b)

.

Study Site
District Boundary
Ring Road
High-Level Road

0 4.5 9

(c)

5

18

27

36
KM

18

27

36
KM

.

.

012 4 6 8
K

012 4 6 8
K

(d)

(e)

Figure 1. Experimental data before and after Wuhan lockdown. (a) Study site covering Wuhan city. (b)
Open street map used for extracting roads. (c) Ring roads and high-level roads for car statistics. (d) GF2 high-resolution pan image acquired on 19 October, 2019. (e) GF-2 high-resolution pan image
acquired on 30 January, 2020.

In order to quantitatively evaluate the strictness of transport restriction, we collect
two sets of GF-2 high-resolution remote sensing images. These two sets are acquired
on 19 October, 2019, and 30 January, 2020, separately, as shown in Figure 1 (d) and (e).
The first image set was acquired on Weekend, and the second image set was acquired
on Weekday. Normally, there will be an increase of motor vehicle between these two
image sets. These two image sets are all acquired at about 11:00 a.m., when there are
always heavy traffics at that time.
Each image set contains 6 GF-2 high-resolution images, and was mosaic into a large
image after carefully co-registration. GF-2 high-resolution image data provide 4
multispectral bands with the resolution of 3.2m, and 1 pan band with the resolution of
0.8m. For extracting vehicles on the road, we selected pan images as the base image,
and NDVI (Normalized Difference Vegetation Index) images after GS pan-sharpening
6

were extracted to mask false alarms. In order to confirm the consistency of vehicle
detection model, radiometric normalization was implemented with 23 pseudo-invariant
features (PIFs), which were manually selected from the stable roads throughout the
image. ğ‘… of the regression is 0.9223 in radiometric normalization. The image on 30
January, 2020 was normalized to the image on 19 October, 2019.
The common region of these two multi-temporal images was extracted for
comparison, as shown in Figure 1 (a). It covers two main parts of Wuhan city (Hankou
and Hanyang), and unfortunately, there was no GF-2 image data covering the rest one
(Wuchang). The study site has the area of 2885.19ğ‘˜ğ‘š , which covering 25.61% area
of Wuhan city (2204.41ğ‘˜ğ‘š /8608.91ğ‘˜ğ‘š ). Even though it only covers 1/4 of the whole
city, the study site covers 41.43% area of city center, which is inside the third ring road
(217.19 ğ‘˜ğ‘š /524.29 ğ‘˜ğ‘š ), as shown in Figure 1 (c). Therefore, the study site is
representative to evaluate the transportation ban during Wuhan lockdown.
Besides the remote sensing image, we also selected open street map (OSM) of the
whole Wuhan city to extract roads. The two pan images were both registered to OSM
to reduce mis-registration error. Buffer with 20m on both sides of OSM road lines were
implemented to extract roads from pan images.
Since some roads in city center will be obstructed by high buildings resulting in false
alarms, ring roads and high-level roads were also used for a better estimation of
transportation restrictions, as shown in Figure 1 (c). A buffer with 40m on both sides of
ring roads and high-level roads were generated for statistics.
7

3. Methodology for Vehicle Detection

Figure 2. Example of vehicles in GF-2 image with the resolution of 0.8m.

As shown in Figure 2, the vehicles on GF-2 image with the resolution of 0.8m do not
show enough shape information for identification. They are very easy to be
misclassified into other landscapes. Fortunately, the vehicles on the road have two
characteristics: firstly, they are anomalous from the road; secondly, they still contain
some characteristics considering their road backgrounds. Therefore, we proposed a
vehicle detection method combing candidate extraction by local anomaly detection and
identification by deep learning.

3.1.

Vehicle Candidate Extraction

3.1.1. Local Anomaly Detection

Considering that vehicles on the remote sensing image with the resolution of 0.8m
do not contain detailed shape features, it is difficult to detect vehicle objects directly.

8

We decided to utilize the unsupervised method as preprocessing to find vehicle
candidates and reduce the interference factors on the road, such as road dividers,
pedestrian crossings, highway lane markers, and so on.
We assume that, the vehicles must be significantly different from the roads visually,
which are the background centering the targets. Therefore, we regard vehicles as
anomaly targets and roads as background. We choose local RX (Reed-Xiaoli) algorithm,
which is a variation of a standard anomaly detection algorithm called RX, to separate
the anomalous target information from the background (Reed and Yu 1990).
Assuming that background objects and anomalous targets in the image follow
Gaussian normal distribution. The pixel under test (PUT) can be detected by analyzing
the statistics (mean and variance) in a local sliding window. The sliding window is
shown in Figure 3, including a guard window and a background window. The pixels
inside the background window and outside the guard window are used as the
background pixels.
In the local sliding window, the two hypotheses must be distinguished as the formula:
ğ» :ğ‘¥
ğ» :ğ‘¥

ğ‘›
ğ‘ 

(1)
ğ‘›

(2)

where ğ‘¥ is the vector of point to be tested, ğ‘› is the background plus noise spectral
vector, and ğ‘  is the target spectral vector.

9

Figure 3. Sliding window used in local RX algorithm with a background window (dotted line) and an
inner guard window (solid line).

The RX anomaly detector is the following:
ğ»
ğ‘…ğ‘‹ ğ‘Ÿ

ğ‘Ÿ

ğœ‡

ğ¶

ğ‘Ÿ

ğœ‡

ğœ‚

(3)

ğ»
where ğ‘Ÿ is the gray value of the pixel to be detected, ğœ‡
background pixels, ğ¶

âˆ‘

ğ‘¥

ğœ‡

ğ‘¥

ğœ‡

âˆ‘

ğ‘¥ is the mean of

is the covariance matrix of the

background pixels, ğœ‚ is the decision threshold.
In this paper, the Open Street Map dataset covering Wuhan city was used to extract
roads with a buffer of 20m. Local anomaly detection algorithm is then implemented
only in the road regions. Afterwards, we adjusted the setting of the threshold ğœ‚ to
transform the anomaly detection results into a binary map to show the vehicle candidate
pixels. In this experiment, we set the outer background window size to 21 21, the inner
guard window size to 9 9, and the threshold ğœ‚ to 3.

3.1.2. NDVI Mask and Shape Filter

Although the local RX anomaly detection algorithm can separate anomalies from the
road, the detection results also include some background objects (such as tree shadows,
pedestrian crossing, isolation belts, dashed road lines, etc.) and noise interference.
In order to reduce false alarms in the preprocessing step, we firstly remove the
10

vegetation pixels and their corresponding shadows by NDVI mask. NDVI (Normalized
Difference Vegetation Index) is a well-known index to extract vegetation distributions.
So, in this paper, we utilized a threshold to identify vegetation regions, and filter out
the anomalous pixels inside these regions. In the image on 19 October, 2019, the
threshold is assigned as 0; while in the image on 30 January, 2020, the threshold is
changed to -0.16, since the later image was acquired in winter.
Then, a connection region clustering with 8-neighbor searching was implemented to
identify vehicle candidates from pixels, which were represented as rectangles. Shape
filter was used to remove obvious false alarms. There are two indicators in shape filter:
area indicates the area of detected pixel cluster; aspect ratio indicates the ratio of width
and height of the minimum bounding rectangle.
The filter rules are set as follows:
1) Area rule: If the area of rectangle is higher than 100 or lower than 4, it will be
removed. Whereas, if the area is lower than 4 but the max anomaly value is higher
than 5, the candidate will be remained to avoid deleting quite small vehicles.
2) Aspect ratio rule: The maximum height should not be larger than 22. The aspect
ratio should not be larger than 5.8 and smaller than 0.15.

3.1.3. Seeded Region Growing and Shape Filter

Since the candidate clustering was firstly implemented based on anomaly detection,
it may not represent the real shape of the vehicles. Moreover, some false alarms will be
better removed according to the original image. Therefore, we will further eliminate the
11

confusing background features through the method of seed region growing.
Seeded region growing (SRG) is a robust region growing method based on the
similarity of pixels in the region. It starts with the assigned seed and then grows the
area by merging pixels to its nearest neighboring seed area (Adams and Bischof 1994).
The initial seeds are selected from the vehicle candidate pixels. Then, the seed pixels
start to grow to their adjacent areas in the original pan image. In the 8 neighborhoods
of the seed point, if the absolute difference value between the pixel under test and the
mean of initial seed pixels is smaller than a given threshold ğœ† (ğœ† was assigned as 6),
the test pixel will be included in the area where the seed pixel located. The iteration will
be terminated when there are no more pixels meeting the growth criteria or reaching
the regions outside the road buffer.
Finally, the shape filter with area rule and aspect ratio rule was implemented again
to remove false alarms after seeded region growing. The whole process is shown as
Figure 4.

(a)

(b)

(c)

(d)

Figure 4. The results of region growing and shape filter. (a) The original gray image. (b) The vehicle
detection results based on local RX. (c) The candidates after seed region growing. (d) The false alarm
removed by shape filter.
12

3.2.

Deep Learning Identification

3.2.1. Training Samples Selection

After the vehicle candidates are extracted by local anomaly detection and shape filter,
we utilize a CNN model to perform binary classification for refining vehicle detection.
Since sufficient samples are necessary for training a robust CNN model, we randomly
select a large number of samples from the preliminary anomaly detection results. In
addition, since the vehicle doesnâ€™t contain enough shape information and must be
identified considering road background, image patches with a fixed size centered on
detected objects are needed. According to the statistics, most bounding box sizes of
vehicles are smaller than 22
of 32

22. We consequently extract image patches with a size

32 for each vehicle. 22181 samples from the two multi-temporal images are

finally selected from the extracted patches. These selected image patches are then
manually labeled as positive (with vehicles) and negative samples (without vehicles),
respectively. Some typical positive and negative samples are presented as Figure 5.

(a)

(b)

Figure 5. Typical (a) positive and (b) negative samples. Positive samples mainly include vehicles of
different colors and sizes. Negative samples include lane line, roof and other noise.

We further randomly split 90% of the whole labeled dataset as training set to training
the network and 10% as validation set to tune the hyper-parameters. The numbers of
positive and negative samples for training set are 4409/15554, and for validation set are
490/1728.
13

3.2.2. Network Architecture

The architecture of our built classification network is summarized in Figure 6. It
mainly contains 3 convolutional layers and 2 fully connected layers. As depicted in
Figure 6, the first convolutional layer filters the input images with a size of
32

32

1 with 16 kernels with spatial size of 3

3 . The second and third

convolutional layers have 32 and 64 kernels with a size of 3

3, respectively. Each

convolutional layer has a consequent max-pooling layer with kernel size of 2

2. The

fully connected layers have 64 neuron units each.

Figure 6. The network architecture for binary classification.

Assuming that the output of the last fully connected layer is ğ‘‹ âˆˆ ğ‘…

, where ğ‘› is

the batch size and ğ‘‘ is the number of feature dimension, a fully connected layer with
ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘ activation is utilized to mapping ğ‘‹ into probabilistic space:
ğ‘¦
where ğ‘¦ âˆˆ ğ‘…

ğ‘“ ğ‘‹ğ‘Š

ğ‘ .

(4)

is the predicted probability and ğ‘“ â‹… is the ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘ activation

function. ğ‘Š denote the weight matrix and ğ‘ is the bias vector in this layer. The
binary cross entropy loss (Janocha and Czarnecki 2017) is used to minimize the
14

difference between the predicted label and ground truth label. Let the ground truth label
be ğ‘¦ âˆˆ ğ‘…

, the loss function is computed as
ğ¿

1
ğ‘›

ğ‘¦ log ğ‘¦

1

ğ‘¦ log 1

ğ‘¦

(5)

After the classification model is trained, the testing images could be fed into the
network. For training set, we only extracted patches with a size of 32

32 for each

object. However, some large vehicles, such as bus and trucks, have larger size and
influence the reliability of predictions. Considering the maximum size of all detected
anomalous objects is 22, we extract patches with a size of 24
32

24 , 28

32 for each testing object. The extracted patches are all resized to 32

28 and
32 to

fit the size of inputs of network. Then, they are fed into the trained network to obtain
the probability of containing vehicles, respectively. The average value of probabilities
of different scale patches is computed as the final stable predictions.

3.2.3. Training Details

To alleviate the impact of overfitting, data augmentation methods are used to enlarge
the training set. Specifically, only spatial transformation methods for images, including
random flipping vertically and horizontally, random 90-, 180- and 270-degree rotation,
are adopted. In the training procedure, an Adam optimizer (Kingma and Ba 2014) with
initial learning rate of 1ğ‘’

is used. The batch size and number of epochs are set as

64 and 100, respectively. We use a warmup learning rate scheduler strategy (Gotmare
et al. 2019). Specifically, the learning rate firstly goes up from 1ğ‘’
15

to 1ğ‘’

linearly

in the first 20 epochs and decays by 0.8 every epoch in consequent. In order to evaluate
the robustness of the proposed method, we train the DL model with a random selection
of training and validation sets for 5 times. The loss and accuracy curves in training
process, and their corresponding standard deviations are presented in Figure 7.

(a)

(b)

Figure 7. The loss and accuracy curves of (a) training set and (b) validation set.

After the training process, the threshold of 0.5 was used in vehicle detection in the
whole region to distinguish vehicles and non-vehicles.

4. Experimental Results and Accuracy Assessment
4.1.

Accuracy Assessment

In order to quantitatively evaluate the performance of the proposed vehicle detection
algorithm, we selected 10 regions with the total area of 7.0ğ‘˜ğ‘š , where 402 vehicles
and 42 vehicles are separately labelled in multi-temporal images before and after
Wuhan lockdown. As shown in Figure 8 and Figure 9, the green rectangles indicate
correction detection, the yellow rectangles indicate omission error, and the red
rectangles indicate false alarm.
16

Figure 8. Vehicle detection results with accuracy assessment in 10 regions before Wuhan lockdown.
17

Figure 9. Vehicle detection results with accuracy assessment in 10 regions after Wuhan lockdown.
18

Figure 8 and Figure 9 show the visual evaluation of the proposed method with the
best model in training process. Most vehicles were correctly detected visually, and not
many false alarms were remained in the images. It can be observed that large vehicles
and dark vehicles are easier to be miss-detected. In visual comparison, the detection
result before lockdown shows better performance than that after lockdown. This is
because there are much fewer vehicles on the road after lockdown, whereas most
disturbances still exist. It leads to a lower detection rate after lockdown.
Table 1 Quantitative assessment of vehicle detection
Correction False
Omission
Precision
Detection
Alarm Error
Rate
Faster RCNN
213
388
189
35.4
2730
39
11.7
2019 Vehicle Candidate 363
DL Identification
303.6 3.4 238 8.3 98.4 3.4
56.1 1.0
Faster RCNN
2020 Vehicle Candidate
DL Identification

Recall
Rate
53.0
92.3
75.5 0.8

F1
42.4
20.8
64.4 0.8

21

208

21

9.2

50.0

15.5

33

2019

9

1.6

78.6

3.2

23.8 0.4

71.0 2.2 18.4 0.4

25.1 0.6

56.7 1.1 35.6 1.6

The quantitative assessment of vehicle detection is shown in Table 1. In order to
make comparison with the state-of-the-art object detection based on deep learning, we
select faster RCNN algorithm trained with the same training samples. DL indicates deep
learning identification. Precision rate, recall rate and F1 score are used for assessment.
Since the DL identification was trained with random initialization, the mean accuracy
and the corresponding standard deviation are shown in Table 1. It can be observed that
vehicle candidate extraction firstly extracts most vehicles on the road with a high recall
rate, whereas there are many false alarms with a low precision rate. After DL
identification, most false alarms can be removed with the obviously increased precision
rate and slightly reduced recall rate. As a comprehensive indicator, the rising of F1 score
19

indicates the effectiveness of our proposed algorithm.
The proposed method can obtain a precision rate of 56.1Â±1.0%, a recall rate of
75.5Â±0.8% before lockdown, and a precision rate of 25.1Â±0.6%, a recall rate of
56.7Â±1.1% after lockdown. Comparatively, a state-of-the-art object detection, faster
RCNN, can only obtain a precision rate of 35.4%, a recall rate of 53.0% before
lockdown, and a precision rate of 9.2%, a recall rate of 50.0% after lockdown. The
validation indicates that the proposed method can obtain a satisfactory performance on
these remote sensing images, and general object detection method is inapplicable. It
can be observed that the precision rate of vehicle detection after lockdown is obviously
less than that before lockdown, this is because there were much fewer vehicles after
lockdown while most interferences still existed.
In order to evaluate the algorithm in detail, we make a ablation study as shown in
Figure 10. It illustrates that after anomaly detection and NDVI mask, there are still lots
of false alarms in the image (Figure 10 (a)). After shape filter (Figure 10 (b)), some
obvious false alarms have been removed. The seeded region growing also makes many
false alarms highlighted (Figure 10 (c)), and then the 2nd implementation of shape filter
remove these errors (Figure 10 (d)). Finally, most of the false alarms are removed by
deep learning identification (Figure 10 (e)).

20

(a)

(b)

(c)

Correct Detection
Omission Error
False Alarm

(d)

(e)

Figure 10. The ablation study of the proposed algorithm. (a) Anomaly detection and NDVI mask. (b)
Shape filter. (c) Seeded region growing. (d) Shape filter. (e) Deep learning identification.

Table 2 indicates the quantitative assessment of ablation study. It indicates that with
the steps of vehicle candidate extraction, the precision rate is increasing with a slightly
reduced recall rate. After DL identification, the accuracy increases significantly.
Table 2 Ablation study of the proposed algorithm
(a)
(b)
(c)
(d)
(e)
Precision Rate 4.7
10.9 11.3 11.7 56.1 1.0
Recall Rate
96.8 90.3 90.5 90.3 75.5 0.8
F1
8.9
19.5 20.1 20.8 64.4 0.8

21

4.2.

Experimental Results

..

0 25 50

.

..

0 25 50

100
M

100
M

(a)

..

0 25 50

0 25 50

100
M

(b)

(c)

.

..

0 25 50

100
M

(d)

100
M

0 25 50

(e)

100
M

(f)

Figure 11. Vehicle detection results of (a) 2nd ring road before lockdown; (b) Hangkong Road flyover
before lockdown; (c) Wuhan Yangtze River Bridge before lockdown; (d) 2nd ring road after lockdown.
(e) Hangkong Road flyover after lockdown. (f) Wuhan Yangtze River Bridge after lockdown.

In the experiment, we implemented the proposed vehicle detection algorithm with
the best model on the whole study site. The vehicles detected are labeled with red
rectangles. In Figure 11, we show three typical regions in these two multi-temporal
remote sensing images. Figure 11 (a) and (d) shows a cross between 2nd ring road and
Gusaoshu overpass, where there is always a traffic jam in normal days. Figure 11 (b)
and (e) shows Hangkong Road flyover near Wushang Plaza, which is one of the most
popular shopping centers in Wuhan. Figure 11 (c) and (f) shows Wuhan Yangtze River
Bridge, which is a core transportation road across Yangtze River. It illustrates that after
Wuhan lockdown, the number of vehicles on these transportation roads takes a rapid
22

decrease. Furthermore, most detected objects in the image after lockdown belong to
false alarms visually.

(a)

(b)

23

(c)
Figure 12. Statistics of vehicles in 500ğ‘š

500ğ‘š blocks. (a) Vehicle distribution before lockdown

(b) Vehicle distribution after lockdown. (c) Difference before and after lockdown.

In order to make a global evaluation, we make a statistics of vehicles in
500ğ‘š

500ğ‘š blocks throughout the whole study site. For reducing the interferences,

we only selected the buffers of OSM data under the following categories for statistics:
â€œmotorwayâ€,

â€œmotorway_linkâ€,

â€œprimaryâ€,

â€œprimary_linkâ€,

â€œsecondaryâ€,

â€œsecondary_linkâ€, â€œtertiaryâ€, â€œtertiary_linkâ€, â€œtrunkâ€, â€œtrunk_linkâ€, and â€œunclassifiedâ€
(Wiki 2020). The figures for the statistics before and after Wuhan lockdown, and their
difference (2020-2019) are shown in Figure 12. The corresponding histograms are
shown beside the figures. In the histograms, blocks with zero vehicles in both images
are removed. Figure 12 illustrates that, after Wuhan lockdown, the vehicle numbers on
the road rapidly decrease throughout the whole city. The areas with heavy traffics will
show more significant decrease, especially in the city center inside the ring road. From
the aspect of histogram, the histogram after Wuhan lockdown move left compared with
24

that before lockdown, which means that vehicle number reduction happens in most
areas. This is also proved by the histogram of difference number, which shows most
values lower than 0.

.

.

0

50

100

0

200
M

50

100

(a)

200
M

0

50

100

200
M

(d)

50

100

(b)

200
M

(c)

.

.

0

.

0

50

100

200
M

.

0

50

(e)

100

200
M

(f)

Figure 13. Examples of blocks with an increased vehicle number. (a) Road beside Huoshenshan before
lockdown. (b) Road near Huoshenshan before lockdown. (c) Road beside a community before
lockdown. (d) Road beside Huoshenshan after lockdown. (e) Road near Huoshenshan after lockdown.
(f) Road beside a community after lockdown.

Even with such a strict transportation ban, there were still some blocks with an
increase vehicle number. When we looked into the blocks with an increase larger than
10, 3 of 20 blocks were caused by the construction of Huoshenshan Hospital (Figure
13 (a), (b), (d), (e)), 10 of 20 blocks were caused by vehicle parking after lockdown
(Figure 13 (c), (f)), and the others were caused by false alarms.
25

4.3.

Dropping Perecentage

Table 3 Vehicle numbers before and after Wuhan lockdown. The first block indicates the
statistics of different districts. The second block indicates the statistics of the whole city, and
Region
Jianghan
Qiaokou
Hanyang
Dongxihu
Wuchang
Jiangan
Huangpi
Hongshan
Caidian
Hannan
Jiangxia
Wuhan
Ring Road (RD)
High-Level Road

along ring roads and high-level roads.
Before
After
Dropping
Image
Lockdown Lockdown Percentage
Area
5540
1763
68.18%
28.63
3961
1278
67.74%
41.37
5185
1712
66.98%
111.26
5639
1979
64.91%
494.84
549
201
63.39%
12.93
5771
2218
61.57%
48.01
2077
877
57.78%
404.90
736
312
57.61%
71.00
5707
2458
56.93%
878.85
50
25
50.00%
13.70
717
360
49.79%
98.90
35932
13183
63.31%
2204.41
5081
772
84.81%
13172
2605
80.22%

Total
Area
28.64
41.37
111.26
494.84
97.10
80.27
2257.20
510.89
1097.70
283.53
2018.01
8608.91

Area
Percentage
99.99%
100.00%
100.00%
100.00%
13.32%
59.81%
17.94%
13.90%
80.06%
4.83%
4.90%
25.61%

The vehicle numbers in different regions detected by the best model are summarized
in Table 3. It can be seen that in most districts, the vehicle numbers decreases more than
50%, and approximately 65% when the covering areas are large enough. As a statistic
in the covering Wuhan city, the vehicle number after lockdown dropped 63.31%, which
even has a very high probability to be under-estimated. As shown in the accuracy
assessment, although there are fewer vehicle objects after lockdown, the interferences
causing false alarms still exist, which is also proved with a lower precision rate after
lockdown. Considering the stable false alarms involved in the vehicle detection results,
the dropping percentage before and after lockdown will be under-estimated. When we
focus on the ring roads and high-level roads, where there are fewer building
obstructions and other interferences, the dropping rate became as high as 84.81% and
26

80.22%. The dropping percentages on the ring roads and high-level roads would be
more representative during Wuhan lockdown. Most of the top dropping percentages in
different districts locates inside the 3rd ring road, such as Jianghan, Qiaokou and
Hanyang, as also shown in Figure 14.

Figure 14. Dropping percentages of vehicle numbers in different district.

5. Discussion
5.1.

Effect Factors on Accuracy

Even though we have tried our best to detect vehicles accurately, considering the
resolution of remote sensing image, there are still many factors leading to false alarms
and omission errors. The main effect factors are summarized as follows:
(1) The resolution of remote sensing image is the main factor affecting accuracy.
With the resolution of 0.8m, there is not enough shape information to identify vehicles.
The feasible way is to detect vehicles as anomalies from the road. However, some
27

interferences, such as road marks, building edges, show quite similar shapes with
vehicles, so it is difficult to distinguish in such a resolution.
(2) The omission errors mainly include dark vehicles, large vehicles, and jammed
vehicles near crossroad. Dark vehicles are blended in the road surface in the view of
remote sensing image. For jammed vehicles, they have similar objects nearby, thus
cannot be distinguished as anomalies.
(3) Since the observation view of these two images are different, more obstructions
of high buildings will be observed in the image after lockdown, which will result in
more false alarms.
(4) The image set before lockdown was acquired on Saturday, and the image set after
lockdown was acquired on Thursday. Normally, there will be an increase of motor
vehicle between these two images. However, according to our research, there was a
significant reduction, which is more evident that the transportation ban had an obvious
influence on the traffic situation.

5.2.

Analysis on the Estimation of Dropping Percentage

For the estimation of dropping percentage, there are two influence factors: firstly,
even though the vehicle numbers on the road decreased, the interferences, such as road
marks and building edges, still exist and are easily to be detected as false alarms. Then,
because of transportation ban, many vehicles are parked at the roadside, which are
forbidden in normal days. They will be detected in the image after lockdown. Therefore,

28

due to the existing interferences and parking vehicles at the roadsides, the dropping
percentage of vehicle number caused by Wuhan lockdown is quite likely to be underestimated. Since there were fewer interferences and building obstructions around the
ring roads and high-level roads, their estimated dropping percentage with 84.81% and
80.22% are more reasonable.

5.3.

Contributions

The significance of our study mainly lies in two aspects. First, the lockdown policy
has been implemented by numerous cities throughout the world. The travel control
between cities and provinces have been intensively studied, whereas the effects of
transportation ban inside the city are rarely quantitatively evaluated (Kraemer et al.
2020; Maier and Brockmann 2020; Tian et al. 2020). To our best knowledge, for the
first time our study provides a quantitative insight into the transportation ban policy
inside Wuhan city after strict lockdown. Considering the public transportations have
been shut down, the significant reduction of motor vehicles indicates that the lockdown
policy in Wuhan show effectiveness in controlling human transmission inside the city.
Second, the existing vehicle detection methods mainly focus on the image with the
resolution higher than 0.3m, whereas these kinds of spaceborne remote sensing data are
not always available (Chen et al. 2016; Ji et al. 2020; Tang et al. 2017a). Our method
can accurately detect vehicles on the road with the resolution of about 1m, which is
more applicable in practice. With our method, it is feasible to study the traffic situation

29

over a large area at a certain time.

6. Conclusion
In order to reduce the spread of COVID-19, government enacted a strict lockdown
policy in Wuhan from 23 January, 2020, including a transmission control for all inbound
/outbound transportation, and a transport ban policy inside the city (Chinazzi et al. 2020;
Kraemer et al. 2020; Tian et al. 2020). Lots of researches have indicated that human
mobility control between cities and provinces have slowed the epidemic progression
obviously (Jia et al. 2020). Whereas, few studies focus on the transportation ban inside
the city, which may be because that the measurement of transportation ban is hard to
implemented. Therefore, we collected two high-resolution remote sensing image
datasets acquired before and after Wuhan lockdown by a Chinese satellite GF-2, to
analyze the vehicle number dropping caused by the transportation ban inside the city.
Due to the resolution of 0.8m, the traditional object detection methods are unable
to detect vehicles without detailed shape information. We proposed a novel vehicle
detection method combining candidate extraction by local anomaly detection, and
vehicle identification by multi-scale CNN model considering their road background.
The experiment and accuracy evaluation shows that our method obtained satisfactory
performances in these two images, and outperformed the state-of-the-art object
detection methods.
We find that the vehicle numbers in Wuhan dropped with a percentage of at least

30

63.31%. Considering the interferences, the dropping percentage of ring road and highlevel road should be more reasonable with the value of 84.81% and 80.22%. Since the
public transportations have been shut down, the significant reduction of motor vehicles
indicates that the lockdown policy in Wuhan show effectiveness in controlling human
transmission inside the city.

Acknowledgements
We acknowledge Hubei Data and Application Center of High-Resolution Earth
Observation System for providing remote sensing images.

Reference
Adams, R., & Bischof, L. 1994. Seeded region growing. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 16, 641-647.
Audebert, N., Saux, B.L., & Lefevre, S. 2017. Segment-before-Detect: Vehicle Detection and
Classification through Semantic Segmentation of Aerial Images. Remote Sensing, 9, 368.
Chen, S., Yang, J., Yang, W., Wang, C., & BÃ¤rnighausen, T. 2020. COVID-19 control in China
during mass population movements at New Year. The Lancet, 395, 764-766.
Chen, Z., Wang, C., Wen, C., Teng, X., Chen, Y., Guan, H., Luo, H., Cao, L., & Li, J. 2016. Vehicle
Detection in High-Resolution Aerial Images via Sparse Representation and Superpixels. IEEE
Transactions on Geoscience and Remote Sensing, 54, 103-116.
Chinazzi, M., Davis, J.T., Ajelli, M., Gioannini, C., Litvinova, M., Merler, S., Pastore y Piontti, A.,
Rossi, L., Sun, K., Viboud, C., Xiong, X., Yu, H., Halloran, M.E., Longini, I.M., & Vespignani,
A. 2020. The effect of travel restrictions on the spread of the 2019 novel coronavirus (201931

nCoV) outbreak. Science, 2020.2002.2009.20021261.
Hubei Health Commission. 2020, COVID-19 report in Hubei province on 8 April 2020.
http://wjw.hubei.gov.cn/fbjd/dtyw/202004/t20200409_2210515.shtml.
Wuhan municipal headquarters for the COVID-19 epidemic prevention and control. 2020a,
Announcement No. 1. http://www.gov.cn/xinwen/2020-01/23/content_5471751.htm.
Wuhan municipal headquarters for the COVID-19 epidemic prevention and control. 2020b,
Announcement No. 9. http://www.gov.cn/xinwen/2020-01/25/content_5472165.htm.
Eikvil, L., Aurdal, L., & Koren, H. 2009. Classification-based vehicle detection in high-resolution
satellite images. ISPRS Journal of Photogrammetry and Remote Sensing, 64, 65-72.
Erb, K.-H., Kastner, T., Plutzar, C., Bais, A.L.S., Carvalhais, N., Fetzel, T., Gingrich, S., Haberl,
H., Lauk, C., Niedertscheider, M., Pongratz, J., Thurner, M., & Luyssaert, S. 2018.
Unexpectedly large impact of forest management and grazing on global vegetation biomass.
Nature, 553, 73-76.
Gao, J., & Oâ€™Neill, B.C. 2020. Mapping global urban land for the 21st century with data-driven
simulations and Shared Socioeconomic Pathways. Nature Communications, 11, 2302.
Gotmare, A., Keskar, N.S., Xiong, C., & Socher, R. (2019). A Closer Look at Deep Learning
Heuristics: Learning rate restarts, Warmup and Distillation. In, international conference on
learning representations
Gray, A., Krolikowski, M., Fretwell, P., Convey, P., Peck, L.S., Mendelova, M., Smith, A.G., &
Davey, M.P. 2020. Remote sensing reveals Antarctic green snow algae as important terrestrial
carbon sink. Nature Communications, 11, 2527.
Janocha, K., & Czarnecki, W.M. (2017). On Loss Functions for Deep Neural Networks in
Classification. In, arXiv e-prints (p. arXiv:1702.05659)
Ji, H., Gao, Z., Mei, T., & Ramesh, B. 2020. Vehicle Detection in Remote Sensing Images
Leveraging on Simultaneous Super-Resolution. IEEE Geoscience and Remote Sensing Letters,
17, 676-680.
Jia, J.S., Lu, X., Yuan, Y., Xu, G., Jia, J., & Christakis, N.A. 2020. Population flow drives spatiotemporal distribution of COVID-19 in China. Nature
32

Jin, S., Yang, L., Danielson, P., Homer, C.G., Fry, J., & Xian, G. 2013. A comprehensive change
detection method for updating the National Land Cover Database to circa 2011. Remote
Sensing of Environment, 132, 159-175.
Kingma, D.P., & Ba, J. (2014). Adam: A Method for Stochastic Optimization. In, arXiv e-prints (p.
arXiv:1412.6980)
Kraemer, M.U.G., Yang, C.-H., Gutierrez, B., Wu, C.-H., Klein, B., Pigott, D.M., du Plessis, L.,
Faria, N.R., Li, R., Hanage, W.P., Brownstein, J.S., Layan, M., Vespignani, A., Tian, H., Dye,
C., Cauchemez, S., Pybus, O., & Scarpino, S.V. 2020. The effect of human mobility and control
measures on the COVID-19 epidemic in China. Science, 2020.2003.2002.20026708.
Leitloff, J., Hinz, S., & Stilla, U. 2010. Vehicle Detection in Very High Resolution Satellite Images
of City Areas. IEEE Transactions on Geoscience and Remote Sensing, 48, 2795-2806.
Li, Q., Mou, L., Xu, Q., Zhang, Y., & Zhu, X.X. 2019. R3-Net: A Deep Network for Multioriented
Vehicle Detection in Aerial Images and Videos. IEEE Transactions on Geoscience and Remote
Sensing, 57, 5028-5042.
Liu, Q., Sha, D., Liu, W., Houser, P., Zhang, L., Hou, R., Lan, H., Flynn, C., Lu, M., Hu, T., &
Yang, C. 2020. Spatiotemporal Patterns of COVID-19 Impact on Human Activities and
Environment in Mainland China Using Nighttime Light and Air Quality Data. Remote Sensing,
12, 1576.
Maier, B.F., & Brockmann, D. 2020. Effective containment explains subexponential growth in
recent confirmed COVID-19 cases in China. Science, 368, 742-746.
News, C. 2020. http://www.chinanews.com/sh/2020/01-26/9070484.shtml.
Reed, I.S., & Yu, X. 1990. Adaptive multiple-band CFAR detection of an optical pattern with
unknown spectral distribution. IEEE Transactions on Acoustics, Speech, and Signal
Processing, 38, 1760-1770.
Reichstein, M., Camps-Valls, G., Stevens, B., Jung, M., Denzler, J., Carvalhais, N., & Prabhat 2019.
Deep learning and process understanding for data-driven Earth system science. Nature, 566,
195-204.
RÃ¶dig, E., Knapp, N., Fischer, R., Bohn, F.J., Dubayah, R., Tang, H., & Huth, A. 2019. From small33

scale forest structure to Amazon-wide carbon estimates. Nature Communications, 10, 5088.
Tang, T., Zhou, S., Deng, Z., Lei, L., & Zou, H. 2017a. Arbitrary-Oriented Vehicle Detection in
Aerial Imagery with Single Convolutional Neural Networks. Remote Sensing, 9, 1170.
Tang, T., Zhou, S., Deng, Z., Zou, H., & Lei, L. 2017b. Vehicle Detection in Aerial Images Based
on Region Convolutional Neural Networks and Hard Negative Example Mining. Sensors, 17,
336.
Tanveer, H., Balz, T., Cigna, F., & Tapete, D. 2020. Monitoring 2011â€“2020 Traffic Patterns in
Wuhan (China) with COSMO-SkyMed SAR, Amidst the 7th CISM Military World Games and
COVID-19 Outbreak. Remote Sensing, 12, 1636.
Tao, C., Mi, L., Li, Y., Qi, J., Xiao, Y., & Zhang, J. 2019. Scene Context-Driven Vehicle Detection
in High-Resolution Aerial Images. IEEE Transactions on Geoscience and Remote Sensing, 57,
7339-7351.
Taubert, F., Fischer, R., Groeneveld, J., Lehmann, S., MÃ¼ller, M.S., RÃ¶dig, E., Wiegand, T., & Huth,
A. 2018. Global patterns of tropical forest fragmentation. Nature, 554, 519-522.
Tian, H., Liu, Y., Li, Y., Wu, C.-H., Chen, B., Kraemer, M.U.G., Li, B., Cai, J., Xu, B., Yang, Q.,
Wang, B., Yang, P., Cui, Y., Song, Y., Zheng, P., Wang, Q., Bjornstad, O.N., Yang, R.,
Grenfell, B.T., Pybus, O.G., & Dye, C. 2020. An investigation of transmission control
measures during the first 50 days of the COVID-19 epidemic in China. Science, 368, 638-642.
Wiki, O. 2020, Key:highway. https://wiki.openstreetmap.org/wiki/Key:highway.
Yang, L., Jin, S., Danielson, P., Homer, C.G., Gass, L., Bender, S., Case, A., Costello, C., Dewitz,
J., & Fry, J. 2018. A new generation of the United States National Land Cover Database:
Requirements, research priorities, design, and implementation strategies. ISPRS Journal of
Photogrammetry and Remote Sensing, 146, 108-123.

34

