Tracking disease outbreaks from sparse data with Bayesian inference
Bryan Wilder,1 Michael J. Mina2 , Milind Tambe1

arXiv:2009.05863v1 [stat.ME] 12 Sep 2020

1

John A. Paulson School of Engineering and Applied Sciences, Harvard University
2
T.H. Chan School of Public Health, Harvard University
bwilder@g.harvard.edu, mmina@hsph.harvard.edu, milind tambe@harvard.edu

Abstract
The COVID-19 pandemic provides new motivation for a
classic problem in epidemiology: estimating the empirical
rate of transmission during an outbreak (formally, the timevarying reproduction number) from case counts. While standard methods exist, they work best at coarse-grained national
or state scales with abundant data, and struggle to accommodate the partial observability and sparse data common at
finer scales (e.g., individual schools or towns). For example,
case counts may be sparse when only a small fraction of infections are caught by a testing program. Or, whether an infected individual tests positive may depend on the kind of
test and the point in time when they are tested. We propose
a Bayesian framework which accommodates partial observability in a principled manner. Our model places a Gaussian
process prior over the unknown reproduction number at each
time step and models observations sampled from the distribution of a specific testing program. For example, our framework can accommodate a variety of kinds of tests (viral RNA,
antibody, antigen, etc.) and sampling schemes (e.g., longitudinal or cross-sectional screening). Inference in this framework is complicated by the presence of tens or hundreds of
thousands of discrete latent variables. To address this challenge, we propose an efficient stochastic variational inference method which relies on a novel gradient estimator for
the variational objective. Experimental results for an example
motivated by COVID-19 show that our method produces an
accurate and well-calibrated posterior, while standard methods for estimating the reproduction number can fail badly.

Introduction
A key goal for public health is effective surveillance and
tracking of infectious disease outbreaks. This work is motivated in particular by the COVID-19 pandemic but the methods we describe are applicable to other diseases as well. A
central question is to estimate the empirical rate of transmission over time, often formalized via the reproduction
number Rt , t = 1...T . Rt describes the expected number
of secondary infections caused by someone infected at time
t. Accurate estimates of Rt are critical to detect emerging
outbreaks, forecast future cases, and measure the impact of
interventions imposed to limit spread.
Rt is typically estimated using daily case counts, i.e.,
the number of new infections detected via testing each day.
Standard methods, including prominent dashboards devel-

oped for COVID-19, provide accurate estimates under idealized conditions for the observation of cases and have been
successfully used at a national or state level where many observations are available and sampling variation averages out
(Abbott et al. 2020; Flaxman et al. 2020; Systrom, Vladek,
and Krieger 2020). However, successful reopening will require programs which track spread at the level of particular colleges, workplaces, or towns, where partial observability poses several challenges. First, only a small number
of infected people may be tested. It is estimated that only
about 10% of SARS-COV-2 infections in the US result in
a confirmed test (Havers et al. 2020) and we could expect
even fewer in populations with a high prevalence of asymptomatic or mild infections (e.g., college students). Second,
the biological properties of the test play an important role.
For example, a PCR test which detects viral RNA will show
positive results at different times than an antibody or antigen
test. Further, there can be substantial heterogeneity across
individuals. Third, testing programs may collect samples in
a particular way which impacts the observations. For example, one suggestion for schools and workplaces to reopen is
to institute regular surveillance testing of a fraction of the
population in order to detect outbreaks and catch asymptomatic carriers (Larremore et al. 2020). The observations
will depend on the fraction of the population enrolled in testing (potentially small due to budget constraints) along with
the sampling design (e.g., cross-sectional vs longitudinal).
This paper presents GPRt, a novel Bayesian approach to
estimating Rt which accounts for partial observability in
a flexible and principled manner (illustrated in Figure 1).
This method yields well-calibrated probabilistic estimates
(the posterior distribution). Our model places a Gaussian
process (GP) prior over Rt , allowing it to be an arbitrary
smooth function. Then, we explicitly model the sampling
process which generates the observations from the true trajectory of infections. While this substantially improves accuracy (as we show experimentally) it creates a much more
difficult inference problem than has been previously considered. Specifically, our model contains tens or hundreds of
thousands of discrete latent variables, preventing the application of out-of-the-box methods. Moreover, the values of
many variables are tightly correlated in the posterior distribution, further complicating inference. To make inference
computationally tractable, we propose a novel stochastic

Generative model

Ground truth ğ‘…ğ‘…

ğ‘…ğ‘…ğ‘¡ğ‘¡

Observations

Disease model
ğ‘›ğ‘›ğ‘¡ğ‘¡ âˆ¼ Poisson ğ‘…ğ‘…ğ‘¡ğ‘¡ ğœ™ğœ™ğ‘¡ğ‘¡

Infections per day

Stochastic variational inference

Observation model
Population
sampling

Positive tests per day

Disease model

Inference

Gradient update
Loss per iteration

We now introduce a model for a disease process with a
time-varying reproduction number. Subsequently, we introduce example models for how the observations are generated
from the disease process which our framework can support.

Posterior distribution

Simulate model

Positive tests per day

Model

ğ‘…ğ‘…ğ‘¡ğ‘¡

Figure 1: Illustration of our GPRt method. Top row: the generative model GPRt posits for the observed data. Bottom
row: the inference process to recover a posterior over Rt .

variational inference method, enabled by a custom stochastic gradient estimator for the variational objective. Extensive experiments show that our method recovers an accurate
and well-calibrated posterior distribution in challenging situations where previous methods fail.

We use a standard stochastic model of disease transmission
similar to other Rt estimation methods (Wallinga and Teunis 2004; Cori et al. 2013; Campbell et al. 2019); our contribution is a more powerful inference methodology which
can accommodate complex observation models alongside a
GP prior. Let R = [R1 ...RT ] be the vector with Rt for
each time. From R, the disease model defines a distribution over a vector n = [n1 ...nT ] with the number of people newly infected each day. The main idea is that, over
the course of a given individualâ€™s infection, they cause a
Poisson-distributed number of new infections with mean determined by R. Specifically, if on day t individual i has been
infected for hi days the expected number of new infections
caused by i that day is
Î»it = whi Rt .

Related work
There is a substantial body of work which attempts to infer
unknowns in a disease outbreak. A frequent target for inference is the basic reproduction number R0 (Majumder and
Mandl 2020; Riou and Althaus 2020; Wilder et al. 2020); by
contrast, we attempt the more challenging task of estimating a reproduction number which can vary arbitrarily over
time. There is a literature of both classic methods for estimating Rt (Wallinga and Teunis 2004; Cori et al. 2013;
Campbell et al. 2019) and newer methods developed for
the COVID-19 pandemic and implemented in popular dashboards (Abbott et al. 2020; Systrom, Vladek, and Krieger
2020). None of these methods incorporate partial observability and we empirically demonstrate that GPRt improves substantially over methods in each category. Another strand of
literature develops maximum likelihood or particle filter estimates of the parameters of an epidemiological model (King
et al. 2008; Dureau, Kalogeropoulos, and Baguelin 2013;
Cazelles, Champagne, and Dureau 2018). However, their
work focuses on accommodating a complex model of the underlying disease dynamics; by contrast, we develop methods
for probabilistically well-grounded inferences under a complex observation model. There is also a great deal of computational work more broadly concerned with disease control.
Examples include optimization problems related to vaccination or quarantine decisions (Saha et al. 2015; Zhang and
Prakash 2014; Zhang et al. 2015), machine learning methods for forecasting (without recovering a probabilistic view
of Rt ) (Chakraborty et al. 2014; Rekatsinas et al. 2015), and
agent-based simulations of disease dynamics (Barrett, Eubank, and Marathe 2008). Our work complements this literature by allowing inference of a distribution over Rt from
noisy data, which can serve as the input that parameterizes
an optimization problem or simulation.

Here whi gives the level of infectiousness of an
Pindividual
hi days post-infection. w is normalized so that h wh = 1.
PN
For later convenience, we will define Ï†t = i=1 whi to be
the total infectiousness in the population before scaling by
Rt (N is the total population size).
Each day, each infected individual i draws nit âˆ¼
Poisson(Î»it ) other individuals to infect. We also incorporate
infections from outside the population, with a mean of Î³
such infections per day. We assume the rate of external infection is constant with respect to our time but our model could
be extended to a time-varying Î³. We treat Î³ mostly as a nuisance parameter: our true objective is to infer R, but doing
so requires accounting for the potential that some detected
cases are due to infections from outside the population. We
PN
define nt = i=1 nit + Poisson(Î³) to be the total number
of new infections. Since Ï† is fixed given the time series n,
we denote it as a function Ï†(n). We denote the probabilistic disease model induced by a specific choice of R and Î³
as M (R, Î³) and the draw of a time series of infections from
the model as n âˆ¼ M (R, Î³).

Observation model
We now depart from the standard disease model used in previous work and describe a wide-ranging set of examples for
how our framework can accommodate models of the process which generates the observed data from the latent (unknown) true infections. Previous work assumes either perfect observability or else the simplest of the three observation models we describe below (uniform undersampling).
Our focus is where observations are generated by a medical
test which confirms the presence of the pathogen of interest.
Individuals have some probability of being tested at different
times (depending on the testing policy adopted) and then test
positive with a probability which depends on the biological
characteristics of the disease and the test in question.

Modeling tests The kind of test employed determines
when an individual is likely to test positive during the course
of infection. For example, for COVID-19, PCR tests are
commonly used to detect SARS-COV-2 RNA. They are
highly sensitive and can detect early infections. Most infected individuals become PCR-negative within the week or
two following infection as viral RNA is cleared (Kucirka
et al. 2020). By contrast, serological tests detect the antibodies produced after infection. An individual is not likely
to test serologically positive until a week or more postinfection, but may then continue to test serologically positive
for months afterwards (Iyer et al. 2020). The observable data
generated by a serological testing program is likely quite different than a PCR testing program since the time-frame and
variance of when individuals test positive differs strongly. A
range of other examples are possible (e.g., antigen tests) and
can be easily incorporated into our framework.
Our model adopts a generic representation of a particular test as a distribution D over tconvert , the number of
days post-infection when an individual begins to test positive and trevert , the number of days post-infection when they
cease to test positive. For an infected individual i, we write
ticonvert , tirevert âˆ¼ D. Our method only assumes the ability
to sample from D, meaning that we can directly plug in
the results of lab studies assessing the properties of a test.
ticonvert , tirevert are unobserved: we only get to see if an individual tests positive at a given point in time, not the full
range of times that they would have tested positive.
Next, we describe a series of example models for how
and when individuals are tested, which reveal observations
depending on the status (ticonvert , tirevert ) for each person who
is tested. For convenience, we let ticonvert = âˆ for an individual who is never infected. Note however that we can model
false negatives by having D sometimes set ticonvert = âˆ for
an infected individual, or false positives by returning finite
ticonvert for an uninfected individual. We denote the number of
observed positive tests on day t as xt . An observation model
is a distribution over x given n, denoted x âˆ¼ Obs(n). Each
setting below describes one such distribution.
Uniform undersampling In this setting, each individual
who is infected is tested independently with some probability ptest (e.g., if they individually decide whether to seek
a test). To model this process, we introduce two new sets
of latent random variables. First, a binary variable z i âˆ¼
Bernoulli(ptest ), indicating whether individual i is tested.
Second, a delay ci , giving the number of days between
ticonvert and when individual i is tested. We can integrate out
the z i and obtain the following conditional distribution for
the observed number of positive tests xt :
!
N
X
xt |c, tconvert âˆ¼ Binomial
1[t = ticonvert + ci ], ptest
i=1

where 1[Â·] denotes the indicator function of an event. However, we cannot analytically integrate out tconvert and c.
Cross-sectional testing Here, a uniformly random sample
of st individuals are tested on each day t. This models a
random screening program (e.g., testing random employees

each day as they enter a workplace). In this case, we have
xt |tconvert , trevert âˆ¼ Binomial

N
1 X i
st ,
1[tconvert â‰¤ t < tirevert ]
N

!

i=1

This expression provides the likelihood of x after conditioning on the latent variables ticonvert , tirevert , though there is no
closed-form expression conditioning only on n.
Longitudinal testing In this setting, a single sample from
the population is chosen up front and every individual in
the sample is tested every d days. We again denote the total number of individual tested on day t as st , but note
that now the group of individuals who are tested repeats every d days. Longitudinal testing offers different (and potentially more revealing) information than cross-sectional testing since when an individual first tests positive, we know
that they did not test positive d days ago. However, it complicates inference by introducing correlations between the
test results at different time steps. Let At denote the set of
individuals who
Sdare tested at time t. We assume that the complete sample t=1 At is chosen uniformly at random from
the population, with the chosen individuals then randomly
partitioned between the d days. We have
X
xt =
1[ticonvert > t âˆ’ d and ticonvert â‰¤ t and tirevert > t]
iâˆˆAt

where ticonvert > tâˆ’d captures that i was not positive on their
previous test. This introduces correlations between xt and
xtâˆ’d , so there is not a simple closed-form expression for the
distribution of the time series x even after conditioning on
ticonvert and tirevert . (as there is in the cross-sectional case). We
will instead build a flexible framework for inference which
can just as well use a kind of sample of the log-likelihood.

Inference problem
We will place a Gaussian process (GP) prior over R, resulting in the following generative model:
R âˆ¼ GP(1, K), Î³ âˆ¼ Exp(Î³Ì„)
n âˆ¼ M (R, Î³)
x âˆ¼ Obs(n).
where GP(1, K) denotes a Gaussian process with constant
mean 1 and kernel K and Exp(Î³Ì„) is an exponential prior
on Î³ with mean Î³Ì„. Given the observation x, our goal is to
compute the resulting posterior distribution over R and Î³.
However, is complicated by the fact that x is determined
by a large number of discrete latent variables, primarily n
(the time series of infections) and {ticonvert , tirevert }N
i=1 , the
times when each individual tests positive. A typical strategy for inference in complex Bayesian models is Markov
Chain Monte Carlo (MCMC). However, MCMC is difficult
to apply because of tight correlations between the values of
variables over time: due to the GP prior, we expect values of
R to be closely correlated between timesteps, and successive values of n are highly correlated via the model M . Formulating good proposal distributions for high-dimensional,
tightly correlated random variables is notoriously difficult

and has presented problems for GP inference via MCMC in
other domains (Titsias, Lawrence, and Rattray 2008).
The other main approach to Bayesian inference is variational inference, where we attempt to find the best approximation to the posterior distribution within some restricted
family. Modern variational inference methods, typically intended for deep models such as variational autoencoders
(Kingma and Welling 2013), use a combination of autodifferentiation frameworks and the reparameterization trick
to differentiate through the variational objective (Kucukelbir et al. 2017). This process is highly effective for models
with only continuous latent variables. However, our model
has many thousands of discrete latent variables which cannot be reparameterized in a differentiable manner. Typical
solutions to this problem would be to either integrate out the
discrete variables or to replace them with a continuous relaxation (Jang, Gu, and Poole 2017; Vahdat et al. 2018). Neither
solution is attractive in our case â€“ the structure of the model
does not allow us to integrate out the discrete variables analytically, while a continuous relaxation is infeasible because
our latent variables have a strict integer interpretation (every
infection requires in a particular individual becoming testpositive at particular points in time).
The last resort to differentiate through discrete probabilistic models is the score function estimator (Paisley, Blei, and
Jordan 2012), which is often difficult to apply due to high
variance. GPRt uses a combination of techniques which exploit the structure of infectious disease models to develop
an estimator with controlled variance. First, we develop a
more tractable variational lower bound which is amenable
to stochastic optimization. Second, we hybridize the reparameterization and score function estimators across different
parts of the generative model to take advantage of the properties of each component. Third, we develop techniques to
sample low-variance estimates of the log-likelihood for each
of the observation models introduced earlier. These techniques are introduced in the next section.

GPRt: variational inference algorithm
We now derive GPRt, a novel variational inference method
for Rt estimation. GPRt approximates the true (uncomputable) posterior over (R, Î³) via a multivariate normal distribution with mean Âµ and covariance matrix Î£. Âµt is the
posterior mean for Rt while Î£t,t0 gives the posterior covariance between Rt and Rt0 . ÂµÎ³ is the mean for Î³ and Î£Î³,Â·
gives its covariance with R. The diagonal Î£t,t gives the variance of the posterior over R at each time, capturing the overall level of uncertainty. The aim is to find a Âµ and Î£ which
closely approximate the true posterior. Let q(R, Î³|Âµ, Î£) denote the variational distribution. Let p be the true generative
distribution, where p(R, Î³, x) is the joint distribution over x
and (R, Î³), p(R, Î³) is the prior over (R, Î³), and p(R, Î³|x)
is the posterior over (R, Î³) after conditioning on x.
The aim of variational inference is to maximize a lower
bound on the total log-probability of the evidence x:
log p(x) â‰¥ E [log p(R, Î³)] + E [log p(x|R, Î³)]
R,Î³âˆ¼q

R,Î³âˆ¼q

âˆ’

E

R,Î³âˆ¼q

[log q(R, Î³|Âµ, Î£)]

where the right-hand side is referred to as the Evidence
Lower Bound (ELBO). Our goal is to maximize the ELBO
via gradient ascent on the parameters Âµ and Î£. This requires
us to develop an estimator for the gradient of each term in the
ELBO. The first term is the negative cross-entropy between
q and the prior p(R, Î³). Because both q and p have simple parametric forms, this can be easily computed and differentiated. The last term is the entropy, which is similarly
tractable. The middle term is the expected log-likelihood.
Developing an estimator for the gradient of this term is substantially more complicated and will be our focus. In fact,
for computational tractability we will actually develop an
estimator for a lower bound on the expected log-likelihood;
substituting this lower bound into the ELBO still gives a
valid lower bound on log p(x) and so is a sensible objective.

Gradient estimator
The essential problem is that computing the log-likelihood
of R requires integrating out the discrete latent variable n
induced by the disease spread model, which is computationally intractable. The aim of this section is to develop the following stochastic estimator:
Theorem
  1. Let L be the Cholesky factor of Î£, Î¾ âˆ¼ N (0, I),
R
and
= Âµ + LÎ¾. Let n âˆ¼ M (R, Î³). Finally, define
Î³
Ë† = âˆ‡Âµ,L log M (n|R, Î³) log p(x|n).
âˆ‡
There exists a function g(Âµ, Î£) with ER,Î³âˆ¼q [log p(x|R, Î³)]
Ë† = âˆ‡g(Âµ, Î£).
â‰¥ g(Âµ, Î£) âˆ€Âµ, Î£ and E[âˆ‡]
Ë† is an unbiased estiEssentially, Theorem 1 states that âˆ‡
mator for a lower bound on the expected log-likelihood, exactly what we need to optimize a lower bound on log p(x)
by stochastic gradient methods. Moreoever, as we will highË† via a
light below, we can efficiently compute the terms of âˆ‡
combination of leveraging the structure of the disease model
to apply autodifferentiation tools and novel sampling methË†
ods for the observation model. We now derive âˆ‡.
Proof. Expanding the dependence of x on n we can rewrite
the log-likelihood as
E

R,Î³âˆ¼q

[log p(x|R, Î³)] =

E

 
log

R,Î³âˆ¼q(Âµ,Î£)


E

[p(x|n)]

nâˆ¼M (R,Î³)

It is not clear how to develop a well-behaved gradient estimator for this expression because we wish to differentiate
with respect to the parameters governing two nested expectations, one within the log. However, via Jensenâ€™s inequality,
we can derive the lower bound

E

R,Î³âˆ¼q

[log p(x|R, Î³)] â‰¥

E

R,Î³âˆ¼q(Âµ,Î£)


E

[log p(x|n)] ,

nâˆ¼M (R,Î³)

pushing the log inside the expectation. We will substitute
this bound into the ELBO, obtaining a valid lower bound to
maximize. The key advantage is that our new lower bound
admits an efficient stochastic gradient estimator. We start

with the inner expectation and attempt to compute a gradient with respect to R (which controls the distribution of the
simulation results n). Using score function estimator gives
âˆ‡R,Î³
E
[log p(x|n)]
nâˆ¼M (R,Î³)

=

E

nâˆ¼M (R,Î³)

[âˆ‡R,Î³ log M (n|R, Î³) log p(x|n)]

which expresses the gradient with respect to (R, Î³) in
terms of the gradient of the probability density of the disease model M with respect to (R, Î³). It turns out that
log M (n, Ï†|R, Î³) can be easily computed. Recall that nt =
PN i
i
i
i=1 nt + Poisson(Î³), where nt âˆ¼ Poisson(Rt Ï†t ). Using the Poisson superposition theorem, we have that nt âˆ¼
PN
Poisson( i=1 Rt Ï†it + Î³) (while Ï†t is a deterministic function of n1 ...ntâˆ’1 ). Accordingly, we have that
T
X
log M (n|R, Î³) =
log Pr[nt |n1 ...nT ]
t=1

=

T
X

nt log (Rt Ï†t (n) + Î³) âˆ’ e (Rt Ï†t (n) + Î³) âˆ’ log nt !

Computing the likelihood
We now turn to the task of computing the log-likelihood
function log p(x|n), which measures the log-likelihood of
observing the sequence of positive test results x given n
new infections per day. Unfortunately, the log-likelihood is
not available in closed form for any of the settings that we
consider because it depends on additional latent variables
(e.g., tconvert , trevert , c, or A). We will show that it suffices to
develop an estimator which lower-bounds the log-likelihood
and that such estimators can be efficiently implemented for
each of the observation models we consider. Specifically, denote the collection of latent variables used in a particular observation model as Î±. Then, we have


log p(x|n) = log E[p(x|n, Î±)|n] ,
Î±

which presents a similar difficulty as in developing our earlier lower bound: sampling Î± to approximate the inner expectation does not result in an unbiased estimator due to the
outer log. Using Jensenâ€™s inequality in the same way gives
log p(x|n) â‰¥ E [log p(x|n, Î±)|n] ,

t=1

Î±

where the second line substitutes the Poisson log-likelihood.
This expression can be easily differentiated with respect to
R and Î³ in closed form. Accordingly, we obtain an unbiased
estimate of the gradient of our lower bound by sampling n âˆ¼
M (R, Î³) and computing
âˆ‡R,Î³ log M (n|R, Î³) log p(x|n).
This suffices to estimate the gradient with respect to
(R, Î³). However, our goal is to differentiate with respect to
Âµ and Î£, which control the distribution over (R, Î³). Fortunately, R and Î³ are continuous. So, we can exploit the
reparameterization trick by writing (R, Î³) as a function of
a random variable whose distribution is fixed. Specifically,
since Î£ is positive semi-definite, it has a Cholesky decomposition Î£ = LLT (for convenience, we actually optimize
over L instead of Î£). Sampling
  a standard normal variable
R
Î¾ âˆ¼ N (0, I) and letting
= Âµ + LÎ¾ is equivalent to
Î³
sampling R, Î³ âˆ¼ N (Âµ, Î£). We rewrite the lower bound as


g(Âµ, Î£) = EÎ¾âˆ¼N (0,I)
E
[log p(x|n)]
nâˆ¼M (R(Î¾),Î³(Î¾))

where Âµ and L appear only as parameters of the deterministic function expressing R and Î³ in terms of Î¾, instead of in
the distribution of a random variable. Taking a sample from
each of the expectations and substituting the score function
Ë†
estimator now gives the desired expression for âˆ‡.
Using Theorem 1, our final gradient estimator will sample
b values for Î¾, run the model M once for each of the resulting
values of R to sample n, and then compute
b
1X
âˆ‡Âµ,L log M (n(k)|R(Î¾(k)), Î³(Î¾(k))) log p(x|n(k)),
b
k=1

easily accomplished with standard autograd tools given the
closed-form expressions for R(Î¾), Î³(Î¾), and log M (n|R).
In practice, we also use the mean log p(x|n(k)) as a simple
control variate to reduce variance (Sutton and Barto 1998).

and so substituting the right-hand side into our variational
objective preserves validity of the lower bound. The RHS
has the crucial advantage that we can now develop an unbiased estimator by drawing a single sample of Î±, which
can then be substituted into the stochastic gradient estimator of Theorem 1. That is, for each of the simulation results
n(1)...n(b) we sample a corresponding value for the latent
variables, Î±(1)...Î±(b) and use the gradient estimator
b
1X
âˆ‡Âµ,L log M (n(k)|R(Î¾(k)), Î³(Î¾(k))) log p(x|n(k), Î±(k))
b
k=1

This works without issue for the uniform undersampling
and cross-sectional models where we can obtain a closed
form for the log likelihood after conditioning on the appropriate latent variables. However, the longitudinal testing model presents additional complications. In particular,
after sampling the latent variables tconvert , trevert , and At ,
the number of positive tests becomes deterministic quantity. Denote this simulated trajectory of positive tests xÌƒ. If
xÌƒ = x, then p(x| tconvert , trevert , A) = 1 and otherwise p(x|
tconvert , trevert , A) = 0. This renders the above gradient estimator useless because log p(x|n(k), Î±(k)) = âˆ’âˆ unless
the simulated trajectory exactly matches the observed data (a
very low-probability event). While âˆ’âˆ is technically a valid
lower bound for the variational objective, it is not very useful for optimization. Essentially, we need to develop a lowervariance estimator where the lower bound is more useful.
We now present one such improved estimator. The intuition is that we can marginalize out a great deal of
the randomness in the naive estimator by only revealing the results of random draws determining At a single individual at a time. We start by sampling tconvert and
trevert . Note that we can expand log p(x|n, tconvert , trevert ) =
P
T
t=1 log p(xt |x1 ...xtâˆ’1 , n, tconvert , trevert ) and consider the
likelihood at each day t after conditioning on the results observed on previous days. To compute an estimate for this

Outbreak setting
PCR
Longitudinal
WT
Cori
EpiNow
GPRt
Cross-sectional
WT
Cori
EpiNow
GPRt
Uniform underreporting
WT
Cori
EpiNow
GPRt

Serological

0.5%

1%

2%

5%

0.5%

1%

2%

5%

0.481 Â± 0.147
1.74 Â± 0.774
0.329 Â± 0.211
0.228 Â± 0.0713

0.405 Â± 0.11
1.18 Â± 0.573
0.265 Â± 0.145
0.2 Â± 0.055

0.395 Â± 0.0947
0.806 Â± 0.373
0.25 Â± 0.135
0.183 Â± 0.0579

0.401 Â± 0.113
0.546 Â± 0.212
0.267 Â± 0.168
0.186 Â± 0.0692

0.445 Â± 0.153
1.55 Â± 0.757
0.308 Â± 0.226
0.237 Â± 0.0805

0.415 Â± 0.117
0.97 Â± 0.577
0.25 Â± 0.171
0.232 Â± 0.0667

0.423 Â± 0.103
0.621 Â± 0.362
0.232 Â± 0.136
0.218 Â± 0.0669

0.438 Â± 0.147
0.455 Â± 0.191
0.225 Â± 0.134
0.216 Â± 0.0712

0.05%

0.1%

0.2%

0.5%

0.05%

0.1%

0.2%

0.5%

0.474 Â± 0.149
1.3 Â± 0.676
0.306 Â± 0.199
0.215 Â± 0.063

0.396 Â± 0.132
0.859 Â± 0.442
0.277 Â± 0.174
0.178 Â± 0.0509

0.369 Â± 0.102
0.554 Â± 0.184
0.294 Â± 0.184
0.177 Â± 0.049

0.358 Â± 0.101
0.502 Â± 0.197
0.302 Â± 0.205
0.172 Â± 0.0471

0.472 Â± 0.136
1.12 Â± 0.51
0.25 Â± 0.146
0.262 Â± 0.09

0.484 Â± 0.135
0.825 Â± 0.363
0.29 Â± 0.181
0.265 Â± 0.076

0.501 Â± 0.132
0.664 Â± 0.246
0.269 Â± 0.153
0.249 Â± 0.0791

0.509 Â± 0.123
0.584 Â± 0.167
0.295 Â± 0.174
0.238 Â± 0.0732

1%

2%

5%

10%

1%

2%

5%

10%

0.395 Â± 0.105
0.892 Â± 0.552
0.311 Â± 0.193
0.204 Â± 0.0806

0.389 Â± 0.106
0.614 Â± 0.355
0.31 Â± 0.186
0.22 Â± 0.0878

0.377 Â± 0.111
0.412 Â± 0.162
0.359 Â± 0.231
0.181 Â± 0.0677

0.382 Â± 0.104
0.38 Â± 0.108
0.394 Â± 0.245
0.181 Â± 0.0467

0.407 Â± 0.0937
0.98 Â± 0.553
0.254 Â± 0.136
0.26 Â± 0.0948

0.425 Â± 0.114
0.587 Â± 0.245
0.212 Â± 0.128
0.259 Â± 0.0839

0.429 Â± 0.133
0.431 Â± 0.149
0.251 Â± 0.139
0.222 Â± 0.0865

0.408 Â± 0.139
0.38 Â± 0.139
0.267 Â± 0.16
0.233 Â± 0.0807

Random trend setting
PCR
Longitudinal
WT
Cori
EpiNow
GPRt
Cross-sectional
WT
Cori
EpiNow
GPRt
Uniform underreporting
WT
Cori
EpiNow
GPRt

Serological

0.5%

1%

2%

5%

0.5%

1%

2%

5%

0.427 Â± 0.149
1.28 Â± 0.678
0.332 Â± 0.233
0.199 Â± 0.0745

0.345 Â± 0.101
0.872 Â± 0.512
0.321 Â± 0.195
0.187 Â± 0.0652

0.321 Â± 0.101
0.622 Â± 0.326
0.337 Â± 0.232
0.181 Â± 0.0551

0.292 Â± 0.104
0.392 Â± 0.159
0.349 Â± 0.244
0.157 Â± 0.0476

0.398 Â± 0.118
1.04 Â± 0.666
0.364 Â± 0.225
0.232 Â± 0.0733

0.322 Â± 0.0851
0.57 Â± 0.325
0.291 Â± 0.207
0.216 Â± 0.0754

0.288 Â± 0.0937
0.358 Â± 0.151
0.304 Â± 0.185
0.213 Â± 0.0699

0.26 Â± 0.0646
0.28 Â± 0.0768
0.296 Â± 0.209
0.194 Â± 0.0694

0.05%

0.1%

0.2%

0.5%

0.05%

0.1%

0.2%

0.5%

0.392 Â± 0.123
0.94 Â± 0.535
0.359 Â± 0.202
0.192 Â± 0.068

0.335 Â± 0.107
0.581 Â± 0.217
0.356 Â± 0.191
0.182 Â± 0.0641

0.319 Â± 0.101
0.478 Â± 0.159
0.421 Â± 0.225
0.168 Â± 0.0512

0.284 Â± 0.096
0.411 Â± 0.117
0.383 Â± 0.215
0.149 Â± 0.0467

0.381 Â± 0.128
0.68 Â± 0.242
0.362 Â± 0.242
0.242 Â± 0.0889

0.404 Â± 0.118
0.61 Â± 0.219
0.438 Â± 0.216
0.246 Â± 0.0877

0.406 Â± 0.13
0.513 Â± 0.137
0.436 Â± 0.265
0.233 Â± 0.0925

0.396 Â± 0.115
0.485 Â± 0.117
0.456 Â± 0.264
0.221 Â± 0.0788

1%

2%

5%

10%

1%

2%

5%

10%

0.285 Â± 0.095
0.558 Â± 0.368
0.348 Â± 0.244
0.172 Â± 0.0694

0.275 Â± 0.0884
0.396 Â± 0.187
0.315 Â± 0.179
0.17 Â± 0.0632

0.267 Â± 0.107
0.326 Â± 0.128
0.383 Â± 0.238
0.163 Â± 0.071

0.259 Â± 0.109
0.281 Â± 0.109
0.336 Â± 0.201
0.181 Â± 0.0682

0.316 Â± 0.0943
0.527 Â± 0.298
0.308 Â± 0.173
0.2 Â± 0.0793

0.3 Â± 0.0917
0.382 Â± 0.205
0.356 Â± 0.236
0.213 Â± 0.0831

0.287 Â± 0.0892
0.303 Â± 0.108
0.318 Â± 0.22
0.206 Â± 0.0848

0.282 Â± 0.0908
0.276 Â± 0.105
0.349 Â± 0.237
0.211 Â± 0.0742

Table 1: Mean absolute error of each method averaged over instances and time points for each setting, along with standard
deviation of the absolute error. â€œPCRâ€ and â€œSerologicalâ€ denote settings where the observations are generated by the respective
testing method. Individual column headings give the percentage of the population enrolled in testing.
sum, we introduce a new object, the series of matrices C t .
At each time t, C t [t1 , t2 ] denotes the number of individuals who have tconvert = t1 , trevert = t2 , and have not yet
actually tested positive by time t. Since At is selected uniformly at random from the population, independent of the
infection process, the xt individuals who test positive on day
t are drawn uniformly at random from the set of all individuals who converted between days t âˆ’ d and t, and who
have not yet reverted. Let ndraws denote the number of individuals in At who have not yet tested positive by time t
Pt
PT
and nconv = t1 =tâˆ’d t2 =t+1 C t [t1 , t2 ] denote the number of individuals who are â€œeligibleâ€ to test positive at time
t. Now xt |x1 ...xtâˆ’1 , n, C t follows a binomial distribution
nconv
. Acwith ndraws draws and success probability N âˆ’P
tâˆ’1
x
i=1

i

cordingly, the log-likelihood log p(xt |x1 ...xtâˆ’1 , n, C t ) can
be computed in closed form. After this, we can sample
C t |C t+1 by selecting a uniformly random individual to remove from C t+1 . We can view this as iteratively revealing
the test-positive members of At after conditioning on the se-

quence of previous test results, instead of sampling the entire
set up front as in the naive method.

Experimental results
We test the performance GPRt vs standard baselines on a
wide variety of settings. We choose three baselines which
have been recommended by leading epidemiologists as
methods of choice for COVID-19 (Gostic et al. 2020). First
is the Wallinga-Teunis (WT) method (Wallinga and Teunis
2004), which uses the distribution of the time between an
infected person and their secondary infections to simulate
possible who-infected-who scenarios, each of which induces
a particular Rt . WT assumes that cases are observed exactly and that there is no delay in observation. Second is
the method of Cori et al. (Cori) (Thompson et al. 2019; Cori
et al. 2013) which computes a Bayesian posterior distribution in a similar Poisson branching process infection model.
The difference is that their method does not place a GP prior
over Rt (instead the posterior factorizes over time) and does

20

40
60
Time (days)

80

40
60
Time (days)

80

40
60
Time (days)

80

2.5 GPRt
2.0
1.5
1.0
0.5
0.00
20

Rt

2.5
EpiNow
2.0
1.5
1.0
0.5
0.00
20

Rt

2.5
Cori
2.0
1.5
1.0
0.5
0.00
20

Rt

2.5 WT
2.0
1.5
1.0
0.5
0.00
20

Rt

Positive tests

8
6
4
2
00

40
60
Time (days)

80

40
60
Time (days)

80

Coverage

Coverage

Figure 2: Observed xt and the distribution over Rt returned by each method on an example in the outbreak setting with
longitudinal sampling, d = 14, and a 1% sample. The green line gives the ground truth Rt .
1 0.05%

0.1%

0.2%

0.5%

0
1

0

0

1

Posterior CI
WT

0

1

Posterior CI
Cori

0

1

0

1

Posterior CI

Posterior CI

EpiNow

GPRt

Figure 3: Calibration of each method for cross-sectional testing. Top row: PCR. Bottom row: serological. The number in
the upper-left hand corner of each column gives % tested
per day. Each individual plot shows the calibration of each
method for that setting. Each (x, y) point gives the fraction
of the ground truth data points (y) which are covered by
the methodâ€™s posterior interval at level x. So, e.g., a point
placed at (0.6, 0.7) would indicate that 60% of the ground
truth data points fell into the methodâ€™s 70% credible interval. The dashed diagonal line shows perfect calibration and
points lying closer to this line indicate better calibration.

not model the sampling method or delays. For both WT and
Cori, we apply a common heuristic to correct for time-toreporting delays, which is shift the methodâ€™s predictions by
the mean delay. Third is EpiNow (Abbott et al. 2020), a
MCMC method recently developed for COVID-19 which
places a GP prior over R and accounts for the delay distribution, but does not model partial observability.
We test each method in an array of settings, with different
distributions for both the true value of Rt and the observations. We include two different settings for the ground truth
Rt . First, the outbreak setting where R starts below 1 and
rises above 1 at a random time. Second, the random trend
setting where R follows a linear trend which changes randomly at multiple points in time. Details of the settings and
other experimental parameters are in the appendix.
We also include different observation models characterized by the test used, the sampling method, and the sample
size. We include both PCR and serological tests, using previously estimated distributions for D (Kucirka et al. 2020; Iyer
et al. 2020). We also include three sampling models introduced earlier: uniform underreporting, cross-sectional, and
longitudinal. Finally, for each of the four combinations of
tests and sampling method, we include four different sample
sizes. Many sizes model a challenging setting with sparse
observations, representing highly limited testing capacity.

Note that the sample sizes evaluated are different for each
method because they have different interpretations, e.g. 1%
in the cross-sectional case means sampling 1% of the population each day while in the longitudinal case it would mean
1% every d days. For each setting, Table 1 shows the mean
absolute error between the posterior mean R produced by
each method and the ground truth. Each entry averages over
100 instances. For longitudinal testing we use d = 14; results for other values are very similar (see appendix).
Across almost all settings, our method has lower MAE
than any baseline, often by a substantial margin (reducing
error by a factor of 2-10x). Notably, GPRt performs well
even with extremely limited data (e.g., when testing 0.05%
of the population per day or when 1% of infections are observed). Performance improves with more data, but the gains
limited (e.g., 0.02-0.04 MAE), indicating that our method is
able to make effective use of even very sparse data.
Figure 2 shows a representative example. The observed
data is quite sparse, with 0-8 positive tests observed per day.
Our method recovers a posterior which closely tracks the
ground truth. WT produces an estimate which is correlated
with the ground truth but has many fluctuations and overly
tight confident intervals. Cori is not appropriate for data this
sparse and produces a widely fluctuating posterior. EpiNow
does not return an estimate for much of the time series, only
estimating the part with denser observations (we gave the
baselines an advantage by only evaluating their MAE where
they returned an estimate). Moreoever, even in the higherobservation portion, it is less accurate than GPRt.
Finally, Figure 3 shows calibration, a metric which evaluates the entire posterior (not just the mean). Intuitively, calibration reflects that, e.g., 90% of the data should fall into the
90%-credible interval of the posterior. Calibration is critical
for the posterior distribution to be interpretable as a valid
probabilistic inference, and for it to be useful in downstream
decision making. Figure 3 shows the fraction of the data
which is covered by the credible intervals of each method.
This figure shows cross-sectional testing in the outbreak setting, but results for other settings are very similar (see appendix). GPRt is close to perfectly calibrated (the dotted diagonal line) while the baseline methods are not well calibrated. The baselines suffer from two problems. First, as to
be expected from their higher MAE, they are biased and so
their credible intervals often exclude the truth. Second, they
are over-confident: paradoxically, their calibration worsens
with increased data since the larger sample size makes them
more confident in their erroneous prediction. We conclude
that GPRt offers uniquely well-calibrated inferences.

References
Abbott, S.; Hellewell, J.; Thompson, R. N.; Sherratt, K.;
Gibbs, H. P.; Bosse, N. I.; Munday, J. D.; Meakin, S.;
Doughty, E. L.; Chun, J. Y.; et al. 2020. Estimating the
time-varying reproduction number of SARS-CoV-2 using
national and subnational case counts. Wellcome Open Research 5(112): 112.
Barrett, C. L.; Eubank, S. G.; and Marathe, M. V. 2008. An
Interaction-Based Approach to Computational Epidemiology. In AAAI, 1590â€“1593.
Campbell, F.; Cori, A.; Ferguson, N.; and Jombart, T. 2019.
Bayesian inference of transmission chains using timing of
symptoms, pathogen genomes and contact data. PLoS Computational Biology 15(3): e1006930.
Cazelles, B.; Champagne, C.; and Dureau, J. 2018. Accounting for non-stationarity in epidemiology by embedding
time-varying parameters in stochastic models. PLoS Computational Biology 14(8): e1006211.
Chakraborty, P.; Khadivi, P.; Lewis, B.; Mahendiran, A.;
Chen, J.; Butler, P.; Nsoesie, E. O.; Mekaru, S. R.; Brownstein, J. S.; Marathe, M. V.; et al. 2014. Forecasting a moving
target: Ensemble models for ILI case count predictions. In
Proceedings of the 2014 SIAM International Conference on
Data Mining, 262â€“270. SIAM.
Cori, A.; Ferguson, N. M.; Fraser, C.; and Cauchemez, S.
2013. A new framework and software to estimate timevarying reproduction numbers during epidemics. American
Journal of Epidemiology 178(9): 1505â€“1512.
Dureau, J.; Kalogeropoulos, K.; and Baguelin, M. 2013.
Capturing the time-varying drivers of an epidemic using
stochastic dynamical systems. Biostatistics 14(3): 541â€“555.
Flaxman, S.; Mishra, S.; Gandy, A.; Unwin, H. J. T.; Mellan, T. A.; Coupland, H.; Whittaker, C.; Zhu, H.; Berah, T.;
Eaton, J. W.; et al. 2020. Estimating the effects of nonpharmaceutical interventions on COVID-19 in Europe. Nature 584(7820): 257â€“261.
Gostic, K. M.; McGough, L.; Baskerville, E.; Abbott, S.;
Joshi, K.; Tedijanto, C.; Kahn, R.; Niehus, R.; Hay, J. A.;
De Salazar, P. M.; et al. 2020. Practical considerations for
measuring the effective reproductive number, Rt. medRxiv .
Havers, F. P.; Reed, C.; Lim, T.; Montgomery, J. M.; Klena,
J. D.; Hall, A. J.; Fry, A. M.; Cannon, D. L.; Chiang, C.F.; Gibbons, A.; et al. 2020. Seroprevalence of antibodies to
SARS-CoV-2 in 10 sites in the United States, March 23-May
12, 2020. JAMA Internal Medicine .
Iyer, A. S.; Jones, F. K.; Nodoushani, A.; Kelly, M.; Becker,
M.; Slater, D.; Mills, R.; Teng, E.; Kamruzzaman, M.;
Garcia-Beltran, W. F.; et al. 2020. Dynamics and significance of the antibody response to SARS-CoV-2 infection.
MedRxiv .
Jang, E.; Gu, S.; and Poole, B. 2017. Categorical reparameterization with gumbel-softmax. In International Conference on Learning Representations.

King, A. A.; Ionides, E. L.; Pascual, M.; and Bouma, M. J.
2008. Inapparent infections and cholera dynamics. Nature
454(7206): 877â€“880.
Kingma, D. P.; and Welling, M. 2013. Auto-encoding variational bayes. In International Conference on Learning Representations.
Kucirka, L. M.; Lauer, S. A.; Laeyendecker, O.; Boon, D.;
and Lessler, J. 2020. Variation in false-negative rate of reverse transcriptase polymerase chain reactionâ€“based SARSCoV-2 tests by time since exposure. Annals of Internal
Medicine .
Kucukelbir, A.; Tran, D.; Ranganath, R.; Gelman, A.; and
Blei, D. M. 2017. Automatic differentiation variational inference. The Journal of Machine Learning Research 18(1):
430â€“474.
Larremore, D. B.; Wilder, B.; Lester, E.; Shehata, S.; Burke,
J. M.; Hay, J. A.; Tambe, M.; Mina, M. J.; and Parker,
R. 2020. Test sensitivity is secondary to frequency and
turnaround time for COVID-19 surveillance. MedRxiv .
Majumder, M. S.; and Mandl, K. D. 2020. Early in the
epidemic: impact of preprints on global discourse about
COVID-19 transmissibility. The Lancet Global Health 8(5):
e627â€“e630.
Paisley, J.; Blei, D.; and Jordan, M. 2012. Variational
Bayesian inference with stochastic search. arXiv preprint
arXiv:1206.6430 .
Rekatsinas, T.; Ghosh, S.; Mekaru, S. R.; Nsoesie, E. O.;
Brownstein, J. S.; Getoor, L.; and Ramakrishnan, N. 2015.
Sourceseer: Forecasting rare disease outbreaks using multiple data sources. In Proceedings of the 2015 SIAM International Conference on Data Mining, 379â€“387. SIAM.
Riou, J.; and Althaus, C. L. 2020. Pattern of early humanto-human transmission of Wuhan 2019 novel coronavirus
(2019-nCoV), December 2019 to January 2020. Eurosurveillance 25(4): 2000058.
Saha, S.; Adiga, A.; Prakash, B. A.; and Vullikanti, A. K. S.
2015. Approximation algorithms for reducing the spectral
radius to control epidemic spread. In Proceedings of the
2015 SIAM International Conference on Data Mining, 568â€“
576. SIAM.
Sutton, R. S.; and Barto, A. G. 1998. Introduction to reinforcement learning, volume 135. MIT press Cambridge.
Systrom, K.; Vladek, T.; and Krieger, M. 2020. rt.live. https:
//github.com/rtcovidlive/covid-model.
Thompson, R.; Stockwin, J.; van Gaalen, R. D.; Polonsky, J.;
Kamvar, Z.; Demarsh, P.; Dahlqwist, E.; Li, S.; Miguel, E.;
Jombart, T.; et al. 2019. Improved inference of time-varying
reproduction numbers during infectious disease outbreaks.
Epidemics 29: 100356.
Titsias, M. K.; Lawrence, N.; and Rattray, M. 2008. Markov
chain Monte Carlo algorithms for Gaussian processes. Inference and Estimation in Probabilistic Time-Series Models
9.

Vahdat, A.; Macready, W.; Bian, Z.; Khoshaman, A.; and
Andriyash, E. 2018. DVAE++: Discrete Variational Autoencoders with Overlapping Transformations. In International
Conference on Machine Learning, 5035â€“5044.
Wallinga, J.; and Teunis, P. 2004. Different epidemic curves
for severe acute respiratory syndrome reveal similar impacts
of control measures. American Journal of Epidemiology
160(6): 509â€“516.
Wilder, B.; Charpignon, M.; Killian, J. A.; Ou, H.-C.; Mate,
A.; Jabbari, S.; Perrault, A.; Desai, A.; Tambe, M.; and Majumder, M. S. 2020. Modeling Between-Population Variation in COVID-19 Dynamics in Hubei, Lombardy, and New
York City. SSRN .
Zhang, Y.; Adiga, A.; Vullikanti, A.; and Prakash, B. A.
2015. Controlling propagation at group scale on networks.
In 2015 IEEE International Conference on Data Mining,
619â€“628. IEEE.
Zhang, Y.; and Prakash, B. A. 2014. Dava: Distributing vaccines over networks under prior information. In Proceedings
of the 2014 SIAM International Conference on Data Mining,
46â€“54. SIAM.

