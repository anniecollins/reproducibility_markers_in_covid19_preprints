Digital twins based on bidirectional LSTM and GAN for modelling
COVID-19
CeÃÅsar QuilodraÃÅn Casasa,‚àó, Vinicius Santos Silvab , Rossella Arcuccia , Claire E. Heaneyb ,
YiKe Guoa , Christopher C. Paina,b

arXiv:2102.02664v1 [cs.LG] 3 Feb 2021

a

Data Science Institute, Department of Computing, Imperial College London, UK
b
Department of Earth Science & Engineering, Imperial College London, UK

Abstract
The outbreak of the coronavirus disease 2019 (COVID-19) has now spread throughout the
globe infecting over 100 million people and causing the death of over 2.2 million people.
Thus, there is an urgent need to study the dynamics of epidemiological models to gain
a better understanding of how such diseases spread. While epidemiological models can
be computationally expensive, recent advances in machine learning techniques have given
rise to neural networks with the ability to learn and predict complex dynamics at reduced
computational costs. Here we introduce two digital twins of a SEIRS model applied to
an idealised town. The SEIRS model has been modified to take account of spatial variation
and, where possible, the model parameters are based on official virus spreading data from the
UK. We compare predictions from a data-corrected Bidirectional Long Short-Term Memory
network and a predictive Generative Adversarial Network. The predictions given by these
two frameworks are accurate when compared to the original SEIRS model data.
Additionally, these frameworks are data-agnostic and could be applied to towns, idealised
or real, in the UK or in other countries. Also, more compartments could be included in the
SEIRS model, in order to study more realistic epidemiological behaviour.
Keywords: Reduced Order Models, Digital Twins, Deep Learning, Long Short-Term
Memory networks, Generative Adversarial Networks

‚àó

Corresponding author
Email address: cesar.quilodran-casas13@imperial.ac.uk (CeÃÅsar QuilodraÃÅn Casas)

Preprint submitted to ..

February 5, 2021

1. Introduction
The coronavirus disease 2019 (COVID-19) outbreak has now spread over the globe infecting over 100 million reported individuals as of 1st February 2021 [1]. Globally, at least
2.2 million deaths have been directly attributed to COVID-19 [1] and this number continues
to increase. There is a lack of information and uncertainty about the dynamics of this outbreak, thus, there is an urgent need for research on this field to help with the mitigation of
this pandemic [2]. In particular, the SEIR (Susceptible - Exposed - Infectious - Recovered)
model, and its variations, have been widely used to study epidemiological problems [3, 4].
These models can be computationally expensive and taking advantage of the recent advances
of machine learning has been beneficial to these types of models [5].
In this paper, we compare two methods for creating a digital twin of a SEIRS model,
which has been modified to take account of spatial variation. These methods are used
to approximate future states of the model which are compared against the ground truth.
The first experiment uses a data-corrected (via optimal interpolation) Bidirectional Long
Short-term memory network (BDLSTM), while the second experiment utilises a Predictive
Generative Adversarial Network (GAN).
There is a need for modelling the detailed spatial and temporal variation of the dynamics
of virus infections such as COVID-19 and to do this in a reasonable computational time.
Existing agent-based models or multi-compartment SEIR models can have many millions of
degrees of freedom that must be solved every time step. Also, the time steps may be small
to resolve the transport of people around a domain. For instance, in a model of a town, a
person in a car or train may travel large distances in just a few minutes. This advection can
have limitations in terms of Courant number restrictions [6] based on the spatial resolution,
as well as the speed of the transport.
Such expensive models may have a set of variables for each member of a population.
Thus, if a country is modelled with many millions of people, the computational expense of
such models becomes an issue and they may even become intractable. This has motivated
the current research on accurate surrogates or Reduced Order Models (ROMs) for virus
modelling. However, although ROMs have been developed in fields such as fluid dynamics,
they are new for virus modelling. For this new application area, we look at a simple test case
2

to try to understand the application of these methods to virus modelling. The prize of an
accurate and fast model means that it may be readily used, possibly interactively, to explore
different control measures, to assimilate data into the models, to help determine the spatial
and future temporal variation of infections. We may need to develop new ROM approaches
to meet the demands of this new virus application area and explore the relative merits of
existing and new ROM approaches which is the focus of this paper.
Both methods (BDLSTM and GAN) are incorporated into non-intrusive reduced order models (NIROMs), which have been used in several fields to speed up computational
models without losing the resolution of the original model [7, 8]. Typically, the first stage
of a NIROM, is to reduce the dimension of the problem by using compression methods
such as Singular Value Decomposition (SVD) or autoencoders, or a combination of both
[9, 10]. Solutions from the original computational model (known as snapshots) are then
projected onto the lower-dimensional space, and the resulting snapshot coefficients are interpolated in some way, to approximate the behaviour of the model in between snapshots.
Originally, classical interpolation methods were used, such as cubic interpolation [11], radial basis functions [12, 13] and Kriging [14]. Recently, non-intrusive methods (sometimes
referred to as model identification methods [15, 16] or described by the more general term
of digital twins [17, 18, 19]) have taken advantage of machine learning techniques, using
multi-layer perceptrons [8], cluster analysis [15], LSTMs [16, 20, 21] and Gaussian Process
Regression [22]. In this work we use an SVD-based method known as Principal Component
Analysis (PCA) to reduce the dimension of the original system [23], and, for the interpolation
or prediction, we compare a data-corrected BDLSTM with a predictive GAN. The LSTM
network, originally described in [24], is a special kind of recurrent neural network (RNN)
that is stable, powerful enough to be able to model long-range time dependencies [25] and
overcomes the vanishing gradient problem [26]. Bidirectional LSTMs have been used in text
classification [27], predicting efficient remaining useful life [28], traffic prediction [29], and
urban air pollution forecasts [30]. Generative adversarial networks (GANs) [31] have shown
impressive performance: photo realistic high-quality images of faces [32, 33], image to image translation [34], synthetical medical augmentation [35], cartoon image generation [36],
amongst others. The basic idea of GANs is to simultaneously train a discriminator and a
3

generator, where the discriminator aims to distinguish between real samples and generated
samples; while the generator tries to fool the discriminator by creating fake samples that are
as realistic as possible. The GAN is a generative model and its use in making predictions in
time is a recent development [37]. By learning a distribution which fits the training data,
the aim is that new samples, taken from the learned distribution formed by the generator,
will remain realistic.
Previous studies have used Long Short-term Memory networks for COVID-19 predictions:
Modified SEIR predictions of the trend of the epidemic in China [38], general outbreak
prediction with machine learning [39], Time series forecasting of COVID-19 transmission in
Canada [40], and predicting COVID-19 incidence in Iran [41], amongst others. Generative
networks have also been used to model aspects of the COVID-19 outbreak, mainly used in
image recognition, e.g. chest X-rays [42, 43].
The novelty of this paper lies in the use of data-corrected forecasts with the state-of-theart LSTM, and a comparison between a digital twin based on this, and one based on GAN
methods for prediction. In summary, in this paper we will apply these methodologies and
novelties:
‚Ä¢ The application of ROM to virus/epidemiology modelling.
‚Ä¢ The application of highly novel BDLSTM- and GAN-based ROM approaches. This is
the first time that these have been incorporated within ROMs.
‚Ä¢ Utilise a BDLSTM to produce fast predictions of the SEIRS model solution. However,
it is observed that the BDLSTM diverges quickly from the model solution.
‚Ä¢ Add data-correction to the BDLSTM. Optimal interpolation, using data from the
SEIRS model solution, is added to the prediction-correction cycle of the BDLSTM to
stabilise the forecast and to achieve improved accuracy.
‚Ä¢ Utilise a GAN to generate time-sequences learnt from the SEIRS model solution. The
GAN can generate realistic time-sequences within the dataset from random noise that
need to be constrained to generate a forecast.

4

Figure 1: Key variables and parameters in the SEIRS model representing the compartments Susceptible (S),
Exposed (E), Infectious (I), and Recovered (R). Modified from Institute for Disease Modelling [44].

‚Ä¢ Provide a high-level comparison which shows how the data-corrected BDLSTM and
predictive GAN forecasts perform in the SEIRS model solution.
The structure of this paper is as follows. Section 2 introduces the classical SEIRS model
and the extended SEIRS model, which includes an additional way of categorising people according to the environment, and which takes account of spatial variation. Section 3 presents
the methodology of the two digital twins (based on results from the extended SEIRS model)
and explains how the predictions are performed. The results and the discussion of these
experiments are presented in sections 4 and 5. Finally, conclusions and future work are
discussed in section 6.
2. SEIRS model
2.1. Classical SEIRS model
The SEIRS equations that govern virus infection dynamics categorise the population
into four compartments: Susceptible, Exposed, Infectious or Recovered. See Figure 1 for an
illustration of the rates that control how a person moves between these compartments. The
infection rate, Œ≤, controls the rate of spread which represents the probability of transmitting
disease between a susceptible and an exposed individual (someone who has been infected but
is not yet infectious). The incubation rate, œÉ, is the rate of exposed individuals becoming
infectious (average duration of incubation is 1/œÉ). Recovery rate, Œ≥ = 1/TD , is determined
by the average duration, TD , of infection. For the SEIRS model, Œæ is the rate at which
recovered individuals return to the susceptible state due to loss of immunity.
5

Vital dynamics can be added to a SEIRS model, by including birth and death rates
represented by ¬µ and ŒΩ, respectively. To maintain a constant population, one can make the
assumption that ¬µ = ŒΩ, however, in the general case, the system of ODEs can be written:
‚àÇS
‚àÇt
‚àÇE
‚àÇt
‚àÇI
‚àÇt
‚àÇR
‚àÇt

= ¬µN ‚àí
=

Œ≤SI
+ ŒæR ‚àí ŒΩS,
N

Œ≤SI
‚àí œÉE ‚àí ŒΩE,
N

(1a)
(1b)

= œÉE ‚àí Œ≥I ‚àí ŒΩI,

(1c)

= Œ≥I ‚àí ŒæR ‚àí ŒΩR

(1d)

where S(t), E(t), I(t) and R(t) represent the number of individuals in the susceptible,
exposed (infected but not yet infectious), infectious and recovered compartments respectively.
At time t, the total number of individuals in the population under consideration is given by
N (t) = S(t) + E(t) + I(t) + R(t). If the birth and death rates are the same, N remains
constant over time.
2.2. Extended SEIRS model
In this study, the SEIRS model is extended in two ways. First, we introduce diffusion
terms to govern how people move throughout the domain, thereby incorporating spatial
variation into the model. Second, we associate a group with each person, indicated by the
index h ‚àà {1, 2, . . . , H}. This indicates the person has gone to work or school, gone shopping,
gone to a park or stayed at home, for example, and transmission rates for each group can be
set according to the risk of being in offices, schools, shopping centres, outside, or at home.

6

These modifications to the SEIRS equations result in the following system of equations:
Sh
‚àÇSh
= ¬µh Nh ‚àí
‚àÇt
Sh
‚àÇEh
=
‚àÇt

P

h0 (Œ≤h h0 Ih0 )

Nh

+ Œæh Rh ‚àí ŒΩhS Sh ‚àí

Nh

ŒªShh0 Sh0 + ‚àákhS ‚àáSh ,

(2a)

h0 =1

P

h0 (Œ≤h h0 Ih0 )

H
X

‚àí œÉEh ‚àí

ŒΩhE Eh

‚àí

H
X

E
ŒªE
hh0 Eh0 + ‚àákh ‚àáEh ,

(2b)

h0 =1

H
X
‚àÇIh
ŒªIhh0 Ih0 + ‚àákhI ‚àáIh ,
= œÉEh ‚àí Œ≥h Ih ‚àí ŒΩhI Ih ‚àí
‚àÇt
h0 =1
H
X
‚àÇRh
R
R
ŒªR
= Œ≥h Ih ‚àí Œæh Rh ‚àí ŒΩh Rh ‚àí
hh0 Rh0 + ‚àákh ‚àáRh ,
‚àÇt
h0 =1

(2c)

(2d)

in which the subscript h represents which group an individual is associated with. Instead of
having scalar values for each compartment, we now have fields: Sh (œâ, t), Eh (œâ, t), Ih (œâ, t)
and Rh (œâ, t), where the people associated with group h for the susceptible, exposed, infectious and recovered compartments, respectively, vary in space, œâ, and time, t. The transmission terms Œ≤hh0 govern how the disease is transmitted from people in groups h0 ‚àà {1, 2, . . . , H}
(¬∑)

to people in group h. The terms involving Œªhh0 are interaction terms which control how people move between the groups describing the various locations/activities for the compartment
given in the superscript. These values could, for example, control whether people in the
school group move into the home group. When moving from one group to another, the
individual remains in the same compartment. Describing the spatial variation, the diffusion
(¬∑)

coefficients for each compartment are given by kh . The birth rate for a group is ¬µh and
the death rate is set for each compartment and group, where, for example, ŒΩhS is the death
rate of group h for the susceptible compartment. The term œÉ represents the rate at which
some of the people in the exposed compartment, E, transfer to the infectious compartment,
I. The recovery rate is now:
Œ≥h =

1
,
TDh

(3)

in which TDh are the average durations of infections in infection groups Ih . Therefore the
infectious rates become:
Œ≤hh = Œ≥h R0h ,

h ‚àà {1, 2, . . . H}.

Here we assume Œ≤hh0 = 0 when h 6= h0 .
7

(4)

An eigenvalue problem can be formed by placing an eigenvalue, Œª0 , in front of the terms
œÉEh in equations (2b) and (2c), and by setting all four time derivatives to zero in equations
(2). In addition, this term will need to be linearised. To model the beginning of the virus
outbreak, a possible way of linearising is shown here:
P
Shg h0 (Œ≤h h0 Ih0 ) X
‚âà
(Œ≤h h0 Ih0 ), ‚àÄh ‚àà {1, 2, . . . , H}.
Nh
0
h
The eigenvalue is equivalent to the reciprocal of R0 , that is R0 =

(5)

1
.
Œª0

We remark that the system of equations (2) is similar to the neutron transport equations
and comment that codes written to solve nuclear engineering problems could be reapplied
to virus modelling without much modification.
2.3. Extended SEIRS model for two groups
As said in the introduction, the area of reduced order modelling is new to virus modelling,
so we choose a simple test case to try to understand the application of these methods to
virus modelling. In this paper, we restrict ourselves to the specific case where there are two
possible and distinct groups in addition to the SEIRS compartments. The groups comprise
people who remain at home (‚ÄòHome‚Äô, H), and others who are mobile and can move to riskier
surroundings (‚ÄòMobile‚Äô, M ). The index representing the group, h, has therefore two values:
h ‚àà {H, M }. For this case, the transmission terms between Home and Mobile must be zero,
so Œ≤HM = 0 and Œ≤M H = 0. This is because an individual at Home cannot infect someone in
the Mobile group and vice versa as they will not be near one another. We wish interaction
(¬∑)

terms Œªhh0 , which control how people move from Home to Mobile groups and vice versa,
to be such that conservation is obeyed. In other words, the number of people leaving the
Home group (for a given compartment) must equal the people entering the Mobile group
(for that compartment). On inspection of equation (2a), for group h = H, we can see that
people moving between the Home and Mobile groups in the susceptible compartment will be
‚àíŒªSHH SH ‚àíŒªSHM SM . From equation (2a), for group h = M , people moving between the Home
and Mobile groups in the susceptible compartment is given by the terms ‚àíŒªSM M SM ‚àíŒªSM H SH .
To enforce that the number of people leaving SH is equal to the number of people joining
SM , the interaction coefficients can be set as follows:
ŒªSHH = ‚àíŒªSM H ,

ŒªSM M = ‚àíŒªSHM
8

and ŒªSHH = ŒªSM M .

(6)

Suppose ŒªSHH =: ŒªÃÉS , then we can say that the number of people leaving SM (joining if ŒªÀúS < 0)
is ŒªÃÉS (SH ‚àí SM ) and the number of people joining SH (leaving if ŒªÀúS < 0) is ŒªÀúS (SH ‚àí SM ).
Similar relationships hold for the other three compartments, i.e. replace the superscript S
in equations (6) with E, I and R in turn. See figure 2 for an illustration of how people
move between compartments and groups in this extended SEIRS model. RaÃÜdulescu et al. [4]
uses a similar approach to model a small college-town which has seven locations (medical
centre, shops, university campus, schools, parks, bars and churches) all with appropriate
transmission rates.

Figure 2: Movement between compartments Susceptible (S), Exposed (E), Infectious (I) and Recovered
(R), and groups Home (H) and Mobile (M) for the extended SEIRS model. The spatial variation is not
represented here, just movement between compartments and groups. The movement between home and
mobile groups is defined by ŒªÃÉ(.) .

The spatial variation is discretised on a regular grid of NX √ó NY √ó NZ control volume
cells. The point equations can be recovered by choosing NX = NY = NZ = 1. We use a
5 point stencil and second-order differencing of the diffusion operator, as well as backward
Euler time stepping. We iterate within a time step, using Picard iteration, until convergence
of all nonlinear terms and evaluate these nonlinear terms at the future time level. To solve
the linear system of equations we use Forward Backward Gauss-Seidel (FBGS) for each

9

variable in turn, and once convergence has been achieved, Block FBGS is used to obtain
overall convergence of the eight linear solutions. This simple solver is sufficient to solve the
relatively small problems presented here.
The parameters Œ≤hh0 , œÉ, Œ≥h and Œæh , were chosen based on parameters observed in the UK,
similar to Nadler et al. [45] who also estimated the parameters from data, this time for the
SIR equations. According to the UK Government [46], the incubation period is between 1
and 14 days, with a median of 5 days. Here, an incubation rate of 4.5 days is used, which
is within the range of observed COVID-19 incubation periods in the UK. The SEIRS model
presented here is flexible, however, meaning that it could be applied to other regions with
different parameters.
3. Methods
3.1. Bidirectional Long Short-term Memory networks
The LSTM network comprises three gates: input (itk ), forget (ftk ), and output (otk ); a
block input, a single cell ctk , and an output activation function. This network is recurrently
connected back to the input and the three gates. Due to the gated structured and the forget
state, the LSTM is an effective and scalable model that can deal with long-term dependencies
[47]. The vector equations for a LSTM layer are:
itk = œÜ(Wxi xtk + WHi Htk‚àí1 + bi )
ftk = œÜ(Wxf xtk + WHf Htk‚àí1 + bf )
otk = œÜ(Wxo xtk + WHo Htk‚àí1 + bo )

(7)

ctk = ftk ‚ó¶ ctk‚àí1 + itk ‚ó¶ tanh(Wxc xtk + WHc Htk‚àí1 + bc )
Htk = otk ‚ó¶ tanh(ctk )
where œÜ is the sigmoid function, W are the weights, b is the bias, xtk is the layer input, Htk
is the layer output and ‚ó¶ denotes the entry-wise multiplication of two vectors.
The idea of BDLSTMs comes from bidirectional RNN [48], in which sequences of data
are processed in both forward and backward directions with two separate hidden layers.
BDLSTMs connect the two hidden layers to the same output layer. It has been proven that

10

the bidirectional networks are substantially better than unidirectional ones in many fields,
such as speech recognition [49] and traffic control [29]. The forward layer output sequence
‚àí‚àí‚Üí
is iteratively calculated using inputs in a forward sequence, Htk , from time tk‚àín to tk‚àí1 , and
‚Üê‚àí‚àí
the backward layer output sequence, Htk , is calculated using the reversed inputs from tk‚àí1
to tk‚àín . The layer outputs of both sequences are calculated by using the equations in (7).
The BDLSTM layer generates an output vector utk :
‚àí‚àí‚Üí ‚Üê‚àí‚àí
utk = œà(Htk , Htk )

(8)

where œà is a concatenating function that combines the two output sequences.
3.1.1. Prediction with BDLSTM
The prediction workflow with the BDLSTM is presented in Figure 3. While LSTMs are
known for producing time-series predictions, the workflow introduces a data-corrected step.
This step improves the accuracy of those predictions. The BDLSTM network f BDLST M is
a function trained off-line to predict tk+1 given the previous N time-levels from the latent
vector x, that represents the ROM:

f BDLST M : xtk‚àíN , . . . , xtk ‚Üí uÃÉtk+1 .

(9)

Once the network is able to predict the solution uÃÉtk+1 , this is joined to the solutions at
utk‚àíN , utk‚àíN +1 , . . . , utk , to create up . The prediction vector up is then optimised online using
the Best Linear Unbiased Estimator (BLUE):

uÀÜp = u¬Øp + Cup v C‚àí1 (v ‚àí vÃÑ)

(10)

where uÀÜp is the data-corrected prediction, u¬Øp is the mean of the vector up over time, v and
vÃÑ are the observations and mean of the observations over time, respectively, Cup v is the
covariance between up and observations v, and C is the covariance of the observations. The
first entry of up is dropped and the new vector is used to make a prediction of tk+2 . This is
an iterative process. Thus, the data-corrected BDLSTM is defined by:

f BDLST M +BLU E : xtk‚àíN , . . . , xtk ‚Üí uÃÇp
11

(11)

Figure 3: Predictive LSTM f BDLST M +BLU E for a sequence of two time levels. Top-left: off-line bidirectional
LSTM network. Bottom-right: data-correction of the prediction. The Best Linear Unbiased Estimation
(BLUE) is used to data-correct the prediction of the network. One time level corresponds to 10 time-steps
of the original SEIRS solution.

In the prediction with the BDLSTM workflow, before performing a PCA on the original
dataset, we normalised the values of each compartment by their corresponding means and
standard deviation. This step was not done for the predictive GAN.
3.2. Generative adversarial network
Proposed by Goodfellow et al. [31], Generative Adversarial Networks (GANs), are unsupervised learning algorithms capable of learning dense representations of the input data
and are intended to be used as a generative model, i.e. they are capable of learning the
distribution underlying the training dataset and able to generate new samples from this
distribution. The training of the GAN is based on a game theory scenario in which the
generator network G must compete against an adversary. The generator network G directly
produces time-sequences from a random distribution as input (latent vector z):
G : z ‚àº N (0, 1) ‚Üí xGAN ‚àà RN √óM

12

(12)

where xGAN is an array of N time sequences with M dimensions. The discriminator network
D attempts to distinguish between samples drawn from the training data, the ROM, and
samples drawn from the generator, considered as fake. The output of the discriminator D(x)
represents the probability that a sample came from the data rather than a ‚Äúfake‚Äù sample
from the generator, and the vector x represents ‚Äúreal‚Äù samples of the principal components
from the ROM. The output of the generator G(z) is a sample from the distribution learned
in the dataset. Equations (13) and (14) show the loss function of the discriminator and
generator, respectively:

LD = ‚àíEx‚àºpdata (x) [log(D(x))] ‚àí Ez‚àºpz (z) [log(1 ‚àí D(G(z)))]

(13)

LG = Ez‚àºpz (z) [log(1 ‚àí D(G(z)))]

(14)

3.2.1. Predictions with GAN
To make predictions in time using a GAN, an algorithm named Predictive GAN [37] is
introduced. The network is trained to generate data at a sequence of N + 1 time levels from
tk , . . . , tk+N no matter at which point in time k is. In other words, the network will generate
data that represents the dynamics of N + 1 consecutive time levels. Following that, given
the data from time levels tk to tk+N +1 as an input of the generator G, but only N time
levels are taken into account in the functional which controls the optimisation of z. the new
prediction is then used in the prediction of the next time level. This process repeats until
predictions have been obtained for all the desired time levels.
In each iteration j of the predictive GAN one new time step is predicted. To this end, an
optimisation in order to match the given data at one time step with the data in the output
of the generator that represent this same time step G(zj )f irst is performed. As the generator
outputs N +1 consecutive time steps, uÃÇp,GAN = G(zj )last will be the prediction and the given
data for the next iteration. The optimisation in each iteration is given by:

j

z = argmin
zj

Nd
X

wi (G(zj‚àí1 )last,i ‚àí G(zj )f irst,i )2 ,

i=1

13

(15)

Figure 4: Workflow of f P redictiveGAN for a sequence of two time levels.

where zj is the latent vector at iteration j, and wi is the weight given to each point in the
data used in the optimisation and Nd is the size of the data in the known N time levels.
It is worth mentioning that the gradient can be calculated by automatic differentiation
[50, 51, 52]. In other words, backpropagating the error generated by the loss function in
Equation (15) through the generator. Figure 4 illustrates how the predictive GAN works.
Finally, the predictive GAN function is defined by:

f P redictiveGAN : z ‚àº N (0, 1) ‚Üí uÃÇp,GAN

(16)

The predictive GAN algorithm can also work with longer sequences of time levels. The
generator can be trained to produce a sequence of m time levels. Therefore, instead of
optimising the data mismatch between the last prediction and the first time step generated
by the network, we can minimise the error between the last q predictions and the first q time
steps generated by the network, where q < m.
Finally, f BDLST M +BLU E and f P redictiveGAN represent the forecast functions from both the
BDLSTM+BLUE method and the Predictive GAN method, respectively.
4. Results
The following section presents the test case, the parameters used in the SEIRS model,
and the predictions of the two digital twin models of the spread of the COVID-19 infection
14

for this idealised scenario. The models are general, however, and could be applied to mode
complex scenarios. The first digital twin is based on a bidirectional LSTM and the second is
based on a predictive GAN model. Both systems were implemented using TensorFlow [53]
and the Keras wrapper [54] in Python.
4.1. Test case
The domain of the test case occupies an area measuring 100km by 100km and is subdivided into 25 regions as shown in Figure 5. Those labelled as 1 are regions into which
people do not travel and the region labelled as 2 is where homes are located. People in the
home group remain at home in region 2, and people in the mobile group can travel anywhere
in regions labelled 2 or 3. Within this domain, the modified SEIRS equations will model
the movement of people around the domain as well as determining which compartment and
group the people are in at any given time. People can be in one of four compartments:
Susceptible, Exposed, Infectious or Recovered, and for each of these, people can either be at
Home or Mobile. To model the spatial variation, diffusion is used as the transport process.
1

1

3

1

1

1

1

3

1

1

3

3

3

3

3

1

1

3

1

1

1

1

2

1

1

Figure 5: Cross-shaped area in a domain of 100km √ó 100km. The grey regions represent where people can
travel. The red dot indicates a location at which comparison will be made between the two experiments
using BDLSTM and GAN.

Now we must set the coefficients for the extended SEIRS model. For both transient simulations and steady state eigenvalue equations, for regions 2 and 3, the diffusion coefficients
are set to:
khc =

2.5L2
,
Tone day

khc = 0.05

2.5L2
Tone day
15

‚àÄh ‚àà {H, M }, ‚àÄc ‚àà {S, E, I, R}

(17)

respectively, in which L is a typical length scale. Here, L is taken as the length of the domain,
i.e. 100km. For region 1, all diffusion coefficients are zero, thus no people will move into this
region, see Figure 5. R0h , h ‚àà {H, M } are the the average number of people in group h a
person within group h infects while in that group. In this example, R0H = 0.2 for people
at Home (h = H), and R0M = 10 for Mobile people (h = M ). If one solves an eigenvalue
problem, using these values of R0h , starting from an initial uninfected population, then the
resulting overall R0 is R0 = 7.27. That is one person at the infectious stage of the virus
can infects on average 7.27 other people. The death rate is assumed to equal the birth rate,
given by:
1
= ŒΩ,
(18)
(60 √ó 365 √ó Tone day )
where the average age at death is taken to be 60 years and Tone day is the number of seconds
¬µ=

in one day. The rate at which recovered individuals return to the susceptible state due to
loss of immunity for both Home and Mobile groups is defined as:
Œæh =

1
.
(365 √ó Tone day )

(19)

(¬∑)

The interaction terms or intergroup transfer terms, Œªhh0 , govern how people in a particular
compartment move from the home to the mobile group, or vice versa. The aim is that most
people will move from home to mobile group in the morning, travel to locations in regions 2
(¬∑)

or 3 and return home later on in the day. To achieve this, the values Œªhh0 depend on other
parameters, as now described. Night and day is defined through the variable:


2œÄt
RDAY = 0.5 sin
+ 0.5 ,
Tone day

(20)

in which t is time into the simulation. For region 2 (see Figure 5):
NH aim = 1000(1 ‚àí RDAY ) + 1000,

NM aim = 0,

ŒõH,H =

1000
.
Tone day

(21)

NH aim and NM aim can be thought of as the total number of people that we aim to have in
the H and M groups in region 2 (i.e. where there are homes). This results in a pressure
to move people from their homes during the day and back into them during the night time
when they return home. Thus, ŒõH,H is set in such a way as to move people out of their
homes on time scale of

1
1000

of a day. For all other regions:

NH aim = 0,

NM aim = 0,
16

ŒõH,H = 0.

(22)

For time dependent problems, a forcing term is defined as:
SH2M = 0.5 + 0.5 sgn(F ),

(23)

NH ‚àí NH aim
,
max{, NH , NH aim }

(24)

where
F =

in which sgn(F ) = 1 if F > 0, otherwise sgn(F ) = ‚àí1. With this definition of SH2M , in
equation (23), for time-dependent problems, we can define the intergroup transfer terms as
follows:

ŒªSH,H = 0.01ŒõH,H SH2M F ;

I
R
S
ŒªE
H,H = ŒªH,H = ŒªH,H = ŒªH,H ,

(25)

I
R
S
ŒªE
M,M = ŒªM,M = ŒªM,M = ŒªM,M ,

(26)

ŒªSH,M = ŒõH,H (1 ‚àí SH2M )F ;

I
R
S
ŒªE
H,M = ŒªH,M = ŒªH,M = ŒªH,M ,

(27)

ŒªSM,H = ‚àí0.01ŒõH,H SH2M F ;

I
R
S
ŒªE
M,H = ŒªM,H = ŒªM,H = ŒªM,H .

(28)

ŒªSM,M = ‚àíŒõH,H (1 ‚àí SH2M )F ;

For eigenvalue problems, the parameters are defined as follows:
rratio = 25.65;
Ô£±
Ô£≤ 1 in region 1
rswitch =
Ô£≥ 0 elsewhere.

(29)

The parameter rswitch switches on the home location in the equations below:
ŒõH,H =

rswitch
;
Tone day

ŒõM,M = 10000

(1 ‚àí rswitch )
.
Tone day

(30)

The intergroup transfer coefficients are set to be
1
ŒªSH,H = ;


S
R
S
ŒªR
H,H = ŒªM,M = ŒªM,M = ŒªH,H ,

I
ŒªE
H,H = ŒªH,H = ŒõH,H + ŒõM,M ,

(31)
(32)

I
ŒªE
M,M = ŒªM,M = ŒõH,H rratio .

(33)

I
R
ŒªSH,M = ŒªE
H,M = ŒªH,M = ŒªH,M = ‚àíŒõH,H rratio ,

(34)

I
R
ŒªSM,H = ŒªE
M,H = ŒªM,H = ŒªM,H = ‚àíŒõH,H .

(35)

17

This defines all the parameters required for the extended SEIRS model.
We are thus modelling the daily cycle of night and day for the transient calculations, in
which there is a pressure for mobile people to go to their homes at night, and there will be
many people leaving their homes during the day moving to the mobile group. For region 2,
the average ratio of the number of people at home to the number of people that are mobile
from the transient calculations during the first 10 days of the simulation is used to form
the ratio rratio . This ratio is then used in the steady-state eigenvalue calculations to enforce
consistency with the transient calculations. However, acknowledging the difference in the
steady-state and time-dependent diffusion terms we scale the former by a factor of 0.05 as
shown in Equation (29) above. The coefficient 1 , where  = 10‚àí10 , was added onto the
diagonal of all the S and R equations (as shown above) to effectively set their values to
approximately zero as they play no role in the eigenvalue calculations. This enables only
minor modifications to be made to the transient code, to give the eigenvalue problem.
The domain of the numerical simulation is divided in a regular mesh of 10 √ó 10 cells. As
there are four compartments and two groups in this problem, there will be eight variables
for each cell in the mesh per time step, which gives a total number of 800 variables per
time step. The total time of the transient simulation is 3888 √ó 103 seconds, or 45.75 days,
with a time step of ‚àÜt = 1000 seconds resulting in 3880 time levels. Each control volume
is assumed to have 2000 people in the home region cells and all other fields are set to zero,
so only susceptible people are non-zero at home initially. This is with the exception that we
assume that 0.1% of people at home has been exposed to the virus and will thus develop an
infection.
The S, E, I, R fields for people at home and mobile are shown in Figure 7 for the default
transient configuration over 45 days. The daily cycle might, for instance, start at about 6 am
(e.g. t = 0), say, where people start to leave their homes. People have started to leave their
homes, become mobile and start to diffuse through the domain. This continues towards the
end of the day where they have moved further away from their homes. However, at midnight
they make their way back to their homes and thus, with a relatively small spread of the
virus near the homes. Notice that at this time level, a small percentage of the population
is exposed, infectious or recovered, and the rest is susceptible to S. We see the daily cycle
18

Figure 6: Spatial variation of the test case domain after 2 √ó 106 seconds for the Home (top) and Mobile
groups (bottom) and the S, E, I and R compartments (left to right).

Figure 7: Total number of people in each compartment and group versus time.

of people moving from their homes to becoming mobile and we also see the gradual increase
in the number of people in the exposed, infectious and recovered compartments for both
mobile and home groups. Notice that the number of exposed and infectious people increases
rapidly in this simulation and then starts to decrease because the number of susceptible
people decreases. That is, recovered people gradually increases and they are immune.

19

4.2. Reduced order modelling
A principal component analysis (PCA) is performed on the 800 variables (100 points in
space in 4 compartments and 2 groups), to obtain a low-dimensional space in which the
predictive GAN and BDLSTM operate. The first 15 principal components were chosen, as
they represent > 99.9% of the variance. Both methods sample data every 10 time-steps
from the PCs. Thus, both methods have access to 388 time levels. The time-lag in both
experiments is 8, as this configuration roughly represents a cycle (one day) of the original
SEIRS simulation. The main goal of both methods is to be able to act as surrogate models
for the SEIRS model, producing predictions in a much faster time than is required to solve
the SEIRS model itself (assuming the latter is sufficiently demanding).

Figure 8: Eigenvalues (left) and normalised cumulative sum of the variance (right) of the first 15 components.

4.3. Bidirectional Long short-term memory network
The network f BDLST M is trained using the previous 8 time levels tk‚àí7 , tk‚àí6 , . . . , tk (namely
80 time-steps of the original SEIRS simulation) to generate the next one tk+1 (10 time steps
ahead of the original SEIRS simulation), with a time interval of 10 time steps. The network
is trained using 90% of the available data, reserving the remaining 10% for testing. Figure 9
depicts the prediction of one time-step, at a single point of the domain, using data from the
original simulation, once f BDLST M is trained. This is a validation that the model can make
accurate predictions on both the training data and the test data.
20

The BDLSTM architecture is based on Cui et al. [29] and f BDLST M was trained for 500
epochs using a grid search of hyperparameters including hidden nodes in the LSTM layer,
batch sizes, and dropouts.

Figure 9: The f BDLST M prediction (orange) over time of the outcomes of the infection (in number of people)
in one point (marked as a red circle in Fig 5) of the mesh starting at time step 0. The predictions are off-line,
not data-corrected and have a sliding window of 8 time-steps and uses the data from the original dataset
(blue) to predict the next one. The green line shows the start of the test data.

Without including data-correction (Figure 10), the predictions from f BDLST M start after
diverging ‚àº 30 iterations. This means that f BDLST M does not diverge greatly from the
original dataset before ‚àº 30 cycles of input-output, without external information. Therefore,
the prediction by f BDLST M needs to be data-corrected to align with the dynamics of the
SEIRS simulation solution.
The data-corrected prediction by the BDLSTM, f BDLST M +BLU E starting from time step
90 (9 √ó 104 seconds), is shown on Figure 11a. Each cycle in the curves corresponds roughly
to a period of one day. Figure 11b depicts the data-corrected prediction every 10 time-steps
starting from time-step 2000 of the simulation (2 √ó 106 seconds). Comparable results are
obtained at other points of the mesh. In both cases, f BDLST M +BLU E struggles at predicting
the Susceptible compartments in both Home and Mobile groups. The f BDLST M +BLU E performs poorly at predicting the initial values in both cases starting from the beginning of the
21

Figure 10: The f BDLST M prediction, over time, of the outcomes of the infection (in number of people) in
one point (marked as a red circle in Fig 5) without any data-correction from time-step 0. The predictions
from f BDLST M act iteratively like an input for the prediction of the following time-step.

dataset and from t = 2000 (2 √ó 106 seconds).
4.4. Prediction using GAN
A predictive GAN, f P redictiveGAN , is applied to the spatial variation of COVID-19 infection, to make predictions based on training using data from the numerical simulation. The
generator and discriminator are trained using a sequence of 9 time levels with a time interval
of 10 time steps between them. The first 8 time levels are used in the optimisation process,
described in Section 3.2.1, and the last time level is used in the prediction. The network is
trained using all time steps of the numerical simulation.
The GAN architecture is based on DCGAN [55]. The generator and discriminator are
trained for 55, 000 epochs. The 9 time levels are given to the networks as a two-dimensional
array with nine rows and fifteen columns. Each row represents a time level and each column
is a principal component from PCA. During the optimisation process in each iteration of
f P redictiveGAN , the singular values from the SVD are used as weights in the Equation (15).
22

(a) Starting at 9 √ó 104 seconds.

(b) Starting at 2 √ó 106 seconds.

Figure 11: f BDLST M +BLU E prediction (in number of people) at one point (marked as a red circle in Fig 5)
of the domain over time starting from different time levels.

The prediction in f P redictiveGAN is performed by starting with 8 time levels from the
numerical simulation and using the generator to predict the ninth. During the next iteration,
the last prediction is used in the optimisation process and this is repeated until the end of
the simulation. It is worth mentioning that after 8 iterations the f P redictiveGAN works only

23

with data from the predictions. Data from the numerical simulation is used only for the
starting points.
Figure 12a shows the prediction over time of f P redictiveGAN but in one point of the mesh
(bottom-right corner of region 2 shown in Figure 5). Each cycle in the curves corresponds to
a period of one day. The process is repeated this time with the simulation starting at time
step 2 √ó 103 (2 √ó 106 seconds). The result over time for one point of the mesh (bottom-right
corner of region 2) is presented in Figure 12b. Comparable results regarding the error in the
prediction are obtained at other points of the mesh, therefore we do not present them here.
We can notice from Figure 12 that f P redictiveGAN can reasonably predict the outcomes of the
numerical model.
4.5. Comparison between BDLSTM and predictive GAN
Formatted as Jupyter notebooks, the codes for both experiments presented in this paper
are publicly available at https://github.com/c-quilo/SEIR-BDLSTM (for the LSTM) and
https://github.com/viluiz/gan/tree/master/PredGAN (for the GAN). The dependencies of the codes are Python (version 3.7), Numpy (version 1.18.5), Keras (version 2.4.3)
and TensorFlow (version 2.4.0). The final hyperparameters used in the Bidirectional Long
Short-Term Memory and predictive GAN networks are given in Table 1.
The training losses of both experiments, BDLSTM and GAN, are depicted in Fig 13.
Figure 14 presents a comparison over a short period of time (50 time-steps) including
f BDLST M , the f BDLST M +BLU E , and f P redictiveGAN . The BDLSTM benefits greatly from the
data-correction with the BLUE estimator. However, it needs constant input from the model
solution data to correct its trajectory. While the predictive GAN replicates the dynamics
of the SEIRS model solution well, just with the input of 8 time levels at the start. Thus,
f P redictiveGAN does not constantly look at the SEIRS model solution data.
Figure 15 shows the normalised root mean squared error (NRMSE) over time for both
digital twins. The mean was calculated using only the active regions of each compartment
and group (Figure 5), i.e the Home group is only considered in region 2, while the Mobile
group is considered across the entire active region (all regions but 1). For this simulation,
we start the prediction at time step 90 (9 √ó 1040 seconds).

24

LSTM

GAN

Epochs

500

55,000

Batch size

32

256

Hidden nodes

64

n/a

Latent space size

n/a

100

Batch normalisation

X

X(generator)

Dropout

0.5

0.3 (discriminator)

Activation function

sigmoid ‚Ä†

LeakyReLU (0.3 ‚Ä° )

Loss function

Mean Square Error

Binary cross entropy

Optimiser

Nadam ‚Ä†‚Ä†

Adam

Learning rate

0.001

0.001

Œ≤1

0.9

0.9

Œ≤2

0.999

0.999



10‚àí7

n/a

Table 1: Hyperparameters used for the data-corrected bidirectional LSTM and the predictive GAN. (‚Ä† Time
distributed dense output layer with a sigmoid activation function, ‚Ä° negative slope coefficient,
Nesterov momentum.)

25

‚Ä†‚Ä†

Adam with

(a) Starting at 9 √ó 104 seconds.

(b) Starting at 2 √ó 106 seconds.

Figure 12: f P redictiveGAN prediction (in number of people) at one point (marked as a red circle in Fig 5) of
the domain over time starting from different time levels.

The RMSE at time level k is defined as the following:
RM SE k =

kuk ‚àí vk k2
‚àö
m

(36)

where k is the time level, uk ‚àà Rm are the predictions for a particular compartment and
group, based on f BDLST M +BLU E or f P redictiveGAN at time level k (having mapped the net26

(a) BDLSTM

(b) Predictive GAN

Figure 13: Training losses of f BDLST M (mean squared error), and the generator G and discriminator D
(binary cross-entropy).

works output back to the control-volume grid), vk ‚àà Rm is the data from the SEIRS model
solutions at time level k, m is the number of active control volumes per compartment and
group, and kk2 represents the Euclidean norm. A RMSE value is computed for the eight
combinations of compartments and groups. The normalised RMSE at time level k is defined
by:
kuk ‚àí vk k2
N RM SE =
.
kvk k2
k

(37)

In the prediction of the Home compartments using the f BDLST M +BLU E prediction, it
is worth noting that there is a decreasing trend of the Home - Recovered and Home Infectious people, while the number of people in Home - Susceptible increases towards the
end of the dataset surpassing the normalised RMSE of the other compartments and groups.
The predictions by f P redictiveGAN on the the Home group present similar behaviour over
time. However, the decreasing trends are more rapid and the increased error of the Home Susceptible compartment is smaller towards the end of the dataset.
There is a very similar behaviour for the Mobile groups in both the BDLSTM and GAN
predictions. There is a decreasing trend for the Mobile - Exposed, Mobile - Infectious and
Mobile - Recovered people for both experiments. Additionally, the error seen for people in
Home - Susceptible increases over time in both experiments. A summary of the average
normalised RMSE over time is shown in Table 2.

27

Figure 14: Comparison of forecasts (in number of people) produced by three methods: f BDLST M (orange),
f BDLST M +BLU E (green), and f P redictiveGAN (red), over time to the ground truth (blue). The forecast starts
from t=2000 (2 √ó 106 seconds) of the SEIRS model solution.

In order to compare the skill of the f BDLST M +BLU E and f P redictiveGAN , we look at the
spatial skill score (SS):
SS = 1 ‚àí

RM SEf BDLST M +BLU E
RM SEf P redictiveGAN

(38)

where RM SEf BDLST M +BLU E and RM SEf P redictiveGAN are the spatial RMSE averaged over time
on each region. The spatial SS is depicted in Figure 16. If SS < 0, the predictive GAN has
more skill at predicting that region. Otherwise, if SS > 0, the f BDLST M +BLU E is better at
predicting that region. While f P redictiveGAN outperforms f BDLST M +BLU E for the prediction
of the Home group (compartments S, E, I and R), in general, the data-corrected BDLSTM
produces more accurate predictions for the Mobile - Infectious and Mobile - Recovered people.
The execution times with and without optimisation for both experiments are shown in
Table 3. These execution times are concerning a set of 9 time-steps. The speed-up for the
original simulation is also shown. The f BDLST M prediction without optimisation is 1 order
of magnitude faster than G. If optimisation is included, the f BDLST M +BLU E prediction is
2 orders of magnitude faster than f P redictiveGAN . However, these optimisations are different
28

(a) f BDLST M +BLU E

(b) f P redictiveGAN

Figure 15: Time-series of the Normalised root mean squared error of the predictions for the Home (top) and
Mobile (bottom) compartments. Left: f BDLST M +BLU E , Right: f P redictiveGAN .
Table 2: Average normalised RMSE over time for both f BDLST M +BLU E and f P redictiveGAN over the 4
compartments and 2 groups. The average does not consider the first 50 time-steps as the normalised RMSE
is too sensitive during this period.

H-S

H-E

H-I

H-R

M-S

M-E

M-I

M-R

BDLSTM 0.179 0.170 0.164 0.888 0.409 0.176 0.192 0.353
GAN

0.078 0.210 0.182 0.264 0.175 0.281 0.287 0.503

and a more direct comparison of the execution times is given by the prediction without
optimisation.
5. Discussion
These experiments serve as a proof of concept for digital twins of SEIRS models. The
predictions produced by the predictive GAN outperform the data-corrected BDLSTM in
the Susceptible compartments in both Home and Mobile groups, while the data-corrected
prediction of the BDLSTM outperforms the predictive GAN in the Exposed, Infectious and
Recovered compartments. However, it is important to note that the predictions produced
by the BDLSTM are data-corrected using the BLUE optimisation. The predictive GAN
also includes an optimisation, but it is capable to generalise over time just by optimising
observational data at the beginning of its prediction.
29

Figure 16: Spatial skill score over the mesh for all 4 compartments and 2 groups. If the skill score is less
than zero, f P redictiveGAN has more skill at predicting that region. Otherwise, if the skill score is greater
than 0, the f BDLST M +BLU E is better at predicting that region. The first 50 time-steps were not considered.
Table 3: Execution times with and without optimisation of a single set of 9 time-steps, and the speed-up
of each method with respect to the original simulation. The original does not include an optimisation, thus
both speed-up times are with respect to the simulation execution time for 9 time-steps.

SEIRS

Execution times (s)

Speed-up (-)

0.45 (s)

-

no opt.

with opt.

no opt.

with opt.

BDLSTM 4 √ó 10‚àí4

1.6 √ó 10‚àí2

1125

28.12

4 √ó 10‚àí3

1.9 √ó 100

112.5

0.24

GAN

‚Ä¢ The f BDLST M provides fast forecasts which are up to 4 orders of magnitude faster than
the simulation. However, it was observed that the BDLSTM diverges quickly from the
model solution when the predicted output is used as an input to predict the following
time-step.
‚Ä¢ This was fixed by adding a data-correction step, using BLUE. The produced forecasts
using this method are 2 orders of magnitude faster than the SEIRS model solution.
However, it has the disadvantage of constantly having the SEIRS model solution as
input to correct the trajectory of the forecast.

30

‚Ä¢ While f BDLST M +BLU E outperforms f P redictiveGAN at producing forecasts of the SEIRS
model solution, f P redictiveGAN has the great advantage of not needing a constant stream
of data from the SEIRS model solution. The f P redictiveGAN manages to predict the
dynamics of the SEIRS model accurately with only the input of 8 time-steps at the
start of the simulation. These 8 time-steps serve as a constraint to initialise the forecast
of f P redictiveGAN . Additionally, GANs can generate reliable information from random
noise, which LSTMs are not designed to do. Nonetheless, the execution times of the
predictive GAN are slower than those of the f BDLST M +BLU E by 1 and 2 orders of
magnitude without or with optimisation, respectively.
‚Ä¢ f P redictiveGAN has great potential when applied in larger problems. In any case, for
a more demanding SEIRS model (with more compartments or with a higher spatial
resolution for example), the speed-ups of both digital twins are expected to improve.
Therefore, a combination of both techniques will be valuable in the future for a more
accurate prediction that includes information from the time-series, using an LSTM, and
creating realistic information trained with adversarial networks. Similar efforts have been
studied for Electrocardiograms [56] and classical music generation [57]. Thus, the prediction
of future time-steps will be embedded into the GAN, without requiring a further optimisation
to make a prediction. This method will diminish execution times, with the caveat that
training GANs come at a higher computational cost. Nonetheless, an application on SEIRS
modelling and more specifically applied to COVID-19 have not been implemented.
6. Conclusions and future work
In this paper, we have presented two methods for creating digital twins of a SEIRS model
with four compartments and two groups. These methods were also used for predicting the
future states of the model comparing the evolution of these experiments to the ground
truth. The first experiment uses a Bidirectional Long Short-term memory network (BDLSTM), while the second experiment utilises a Predictive Generative Adversarial Network
(GAN). The prediction produced by the predictive GAN outperforms the predictions by the
data-corrected BDLSTM in the Susceptible compartments. Furthermore, GANs are able to
31

generate reliable information from random noise. This novel approach using data-corrected
optimisation using GANs shows very promising results for time-series prediction.
Future work involves the combination of LSTM (unidirectional or bidirectional) with
a GAN in order to produce more accurate forecasts that take advantage of the time-series
information along with realistic predictions produced by the GAN. Additionally, these frameworks could be applied to larger domains of idealised towns including more compartments
to study more realistic epidemiological models.
Acknowledgements
This work is supported by the EPSRC grant EP/T003189/1 Health assessment across
biological length scales for personal pollution exposure and its mitigation (INHALE), grant
EP/N010221/1 Managing Air for Green Inner Cities (MAGIC) consortium, the PREMIERE
programme grant (EP/T000414/1), the MUFFINS grant (EP/P033180/1), and the RELIANT grant (EP/V036777/1). This work has been undertaken, in part, as a contribution
to ‚ÄòRapid Assistance in Modelling the Pandemic‚Äô (RAMP), initiated by the Royal Society.
In particular, we would like to acknowledge the useful discussion had within the Environmental and Aerosol Transmission group of RAMP, coordinated by Profs Paul Linden and
Christopher Pain.

32

References
[1] World Health Organization, Weekly Epidemiological Report 24, 2021.
[2] M. Park, A. R. Cook, J. T. Lim, Y. Sun, B. L. Dickens, A systematic review of COVID19 epidemiology based on current evidence, Journal of Clinical Medicine 9 (2020) 967.
[3] M. Y. Li, J. S. Muldowney, Global stability for the SEIR model in epidemiology,
Mathematical biosciences 125 (1995) 155‚Äì164.
[4] A. RaÃÜdulescu, C. Williams, K. Cavanagh, Management strategies in a SEIR-type model
of COVID 19 community spread, Scientific Reports 10 (2020) 21256.
[5] P. Song, Y. Lou, Y. Xiao, A spatial SEIRS reaction-diffusion model in heterogeneous
environment, Journal of Differential Equations 267 (2019) 5084‚Äì5114.
[6] D. Pavlidis, Z. Xie, J. R. Percival, J. L. Gomes, C. C. Pain, O. K. Matar, Two-and
three-phase horizontal slug flow simulations using an interface-capturing compositional
approach, International Journal of Multiphase Flow 67 (2014) 85‚Äì91.
[7] D. Xiao, F. Fang, A. Buchan, C. Pain, I. Navon, A. Muggeridge, Non-intrusive reduced order modelling of the Navier‚ÄìStokes equations, Computer Methods in Applied
Mechanics and Engineering 293 (2015) 522‚Äì541.
[8] J. S. Hesthaven, S. Ubbiali, Non-intrusive reduced order modeling of nonlinear problems
using neural networks, Journal of Computational Physics 363 (2018) 55‚Äì78.
[9] C. QuilodraÃÅn Casas, R. Arcucci, Y. Guo, Urban air pollution forecasts generated from
latent space representations, in: ICLR 2020 Workshop on Integration of Deep Neural
Models and Differential Equations.
[10] T. Phillips, C. E. Heaney, P. N. Smith, C. C. Pain, An autoencoder-based reduced-order
model for eigenvalue problems with application to neutron diffusion, arXiv preprint
arXiv:2008.10532 (2020).

33

[11] T. Bui-Thanh, M. Damodaran, K. Willcox, Proper Orthogonal Decomposition Extensions for Parametric Applications in Compressible Aerodynamics, in: 21st AIAA
Applied Aerodynamics Conference, 2003.
[12] P. Breitkopf, I. Lepot, C. Sainvitu, P. Villon, Multi-fidelity POD surrogate-assisted
optimization: Concept and aero-design study, Structural and Multidisciplinary Optimization 56 (2017) 1387‚Äì1412.
[13] D. Xiao, F. Fang, C. Pain, I. Navon, P. Salinas, Z. Wang, Non-intrusive model reduction for a 3D unstructured mesh control volume finite element reservoir model and its
application to fluvial channels, International Journal of Oil, Gas and Coal Technology
19 (2018) 316‚Äì338.
[14] G. Aversano, A. Bellemans, Z. Li, A. Coussement, O. Gicquel, A. Parente, Application
of reduced-order models based on PCA & Kriging for the development of digital twins
of reacting flow applications, Computers & Chemical Engineering 121 (2019) 422‚Äì441.
[15] E. Kaiser, B. Noack, L. Cordier, A. Spohn, M. Segond, M. Abel, G. Daviller, J. OÃàsth,
S. KrajnovicÃÅ, R. Niven, Cluster-based reduced-order modelling of a mixing layer, Journal of Fluid Mechanics 754 (2014) 365‚Äì414.
[16] Z. Wang, D. Xiao, F. Fang, R. Govindan, C. C. Pain, Y. Guo, Model identification
of reduced order fluid dynamics systems using deep learning, International Journal for
Numerical Methods in Fluids 86 (2018) 255‚Äì268.
[17] A. Rasheed, O. San, T. Kvamsdal, Digital twin: Values, challenges and enablers from
a modeling perspective, IEEE Access 8 (2020) 21980‚Äì22012.
[18] B. Moya, I. Alfaro, D. Gonzalez, F. Chinesta, E. Cueto, Physically sound, self-learning
digital twins for sloshing fluids, PLoS One 15 (2020) e0234569.
[19] M. Kapteyn, D. Knezevic, D. Huynh, M. Tran, K. Willcox, Data-driven physics-based
digital twins via a library of component-based reduced-order models, International
Journal for Numerical Methods in Engineering (forthcoming).

34

[20] S. E. Ahmed, S. M. Rahman, O. San, A. Rasheed, I. M. Navon, Memory embedded
non-intrusive reduced order modeling of non-ergodic flows, Physics of Fluids 31 (2019)
126602.
[21] M. Kherad, M. K. Moayyedi, F. Fotouhi, Reduced order framework for convection
dominant and pure diffusive problems based on combination of deep long short-term
memory and proper orthogonal decomposition/dynamic mode decomposition methods,
International Journal for Numerical Methods in Fluids (forthcoming).
[22] M. Guo, J. S. Hesthaven, Reduced order modeling for nonlinear structural analysis using
Gaussian process regression, Computer Methods in Applied Mechanics and Engineering
341 (2018) 807‚Äì826.
[23] J. Lever, M. Krzywinski, N. Altman, Points of significance: Principal component analysis, 2017.
[24] S. Hochreiter, J. Schmidhuber, Long Short-Term Memory, Neural computation 9 (1997)
1735‚Äì1780.
[25] S. Xingjian, Z. Chen, H. Wang, D.-Y. Yeung, W.-K. Wong, W.-c. Woo, Convolutional
LSTM network: A machine learning approach for precipitation nowcasting, in: Advances in neural information processing systems, pp. 802‚Äì810.
[26] K. Greff, R. K. Srivastava, J. Koutnƒ±ÃÅk, B. R. Steunebrink, J. Schmidhuber, LSTM: A
search space odyssey, IEEE transactions on neural networks and learning systems 28
(2016) 2222‚Äì2232.
[27] G. Liu, J. Guo, Bidirectional LSTM with attention mechanism and convolutional layer
for text classification, Neurocomputing 337 (2019) 325‚Äì338.
[28] A. Elsheikh, S. Yacout, M.-S. Ouali, Bidirectional handshaking LSTM for remaining
useful life prediction, Neurocomputing 323 (2019) 148‚Äì156.
[29] Z. Cui, R. Ke, Z. Pu, Y. Wang, Deep bidirectional and unidirectional LSTM recurrent neural network for network-wide traffic speed prediction,
arXiv:1801.02143 (2018).
35

arXiv preprint

[30] C. QuilodraÃÅn-Casas, R. Arcucci, C. Pain, Y. Guo, Adversarially trained LSTMs on reduced order models of urban air pollution simulations, arXiv preprint arXiv:2101.01568
(2021).
[31] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
A. Courville, Y. Bengio, Generative adversarial nets, in: Advances in neural information processing systems, 2014, pp. 2672‚Äì2680.
[32] T. Karras, S. Laine, T. Aila, A Style-Based Generator Architecture for Generative
Adversarial Networks, in: Proceedings of the IEEE conference on computer vision and
pattern recognition, 2019, pp. 4401‚Äì4410.
[33] T. Karras, S. Laine, M. Aittala, J. Hellsten, J. Lehtinen, T. Aila, Analyzing and Improving the Image Quality of StyleGAN, in: Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pp. 8110‚Äì8119.
[34] C. Chu, A. Zhmoginov, M. Sandler, CycleGAN, a Master of Steganography, arXiv
preprint arXiv:1712.02950 (2017).
[35] M. Frid-Adar, I. Diamant, E. Klang, M. Amitai, J. Goldberger, H. Greenspan, GANbased synthetic medical image augmentation for increased CNN performance in liver
lesion classification, Neurocomputing 321 (2018) 321‚Äì331.
[36] Y. Liu, Z. Qin, T. Wan, Z. Luo, Auto-painter: Cartoon image generation from sketch
by using conditional Wasserstein generative adversarial networks, Neurocomputing 311
(2018) 78‚Äì87.
[37] V. L. S. Silva, C. E. Heaney, Y. Li, C. C. Pain, Data assimilation GAN (DA-GAN)
applied to determine the spread of COVID-19 infections through space and time, 2020.
In preparation.
[38] Z. Yang, Z. Zeng, K. Wang, S.-S. Wong, W. Liang, M. Zanin, P. Liu, X. Cao, Z. Gao,
Z. Mai, et al., Modified SEIR and AI prediction of the epidemics trend of COVID-19
in China under public health interventions, Journal of Thoracic Disease 12 (2020) 165.

36

[39] S. F. Ardabili, A. Mosavi, P. Ghamisi, F. Ferdinand, A. R. Varkonyi-Koczy, U. Reuter,
T. Rabczuk, P. M. Atkinson, COVID-19 Outbreak Prediction with Machine Learning,
Available at SSRN 3580188 (2020).
[40] V. K. R. Chimmula, L. Zhang, Time series forecasting of COVID-19 transmission in
Canada using LSTM networks, Chaos, Solitons & Fractals (2020) 109864.
[41] S. M. Ayyoubzadeh, S. M. Ayyoubzadeh, H. Zahedi, M. Ahmadi, S. R. N. Kalhori,
Predicting COVID-19 Incidence Through Analysis of Google Trends Data in Iran: Data
Mining and Deep Learning Pilot Study, JMIR Public Health and Surveillance 6 (2020)
e18828.
[42] N. E. M. Khalifa, M. H. N. Taha, A. E. Hassanien, S. Elghamrawy, Detection of coronavirus (COVID-19) associated pneumonia based on generative adversarial networks
and a fine-tuned deep transfer learning model using chest X-ray dataset, arXiv preprint
arXiv:2004.01184 (2020).
[43] L. Wang, A. Wong, COVID-Net: A Tailored Deep Convolutional Neural Network
Design for Detection of COVID-19 Cases from Chest X-Ray Images, arXiv preprint
arXiv:2003.09871 (2020).
[44] Institute for Disease Modelling, SEIR and SEIRS models, 2020.
[45] P. Nadler, S. Wang, R. Arcucci, X. Yang, Y. Guo, An epidemiological modelling approach for COVID-19 via data assimilation, European Journal of Epidemiology 35
(2020) 749‚Äì761.
[46] UK Government, COVID-19: infection prevention and control (IPC), 2020.
[47] C. QuilodraÃÅn Casas, R. Arcucci, P. Wu, C. Pain, Y.-K. Guo, A reduced order deep data
assimilation model, Physica D: Nonlinear Phenomena (2020) 132615.
[48] M. Schuster, K. K. Paliwal, Bidirectional recurrent neural networks, IEEE transactions
on Signal Processing 45 (1997) 2673‚Äì2681.

37

[49] A. Graves, N. Jaitly, A.-r. Mohamed, Hybrid speech recognition with deep bidirectional
LSTM, in: 2013 IEEE workshop on automatic speech recognition and understanding,
IEEE, pp. 273‚Äì278.
[50] R. E. Wengert, A simple automatic derivative evaluation program, Communications of
the ACM 7 (1964) 463‚Äì464.
[51] S. Linnainmaa, Taylor expansion of the accumulated rounding error, BIT Numerical
Mathematics 16 (1976) 146‚Äì160.
[52] A. G. Baydin, B. A. Pearlmutter, A. A. Radul, J. M. Siskind, Automatic differentiation
in machine learning: a survey, The Journal of Machine Learning Research 18 (2017)
5595‚Äì5637.
[53] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado,
A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. ManeÃÅ, R. Monga,
S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. VieÃÅgas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, X. Zheng, TensorFlow: Large-Scale Machine Learning on
Heterogeneous Systems, 2015. Software available from tensorflow.org.
[54] F. Chollet, et al., Keras, https://keras.io, 2015.
[55] A. Radford, L. Metz, S. Chintala, Unsupervised Representation Learning with Deep
Convolutional Generative Adversarial Networks,

arXiv preprint arXiv:1511.06434

(2015).
[56] F. Zhu, F. Ye, Y. Fu, Q. Liu, B. Shen, Electrocardiogram generation with a bidirectional
LSTM-CNN generative adversarial network, Scientific reports 9 (2019) 1‚Äì11.
[57] O. Mogren, C-RNN-GAN: Continuous recurrent neural networks with adversarial training, arXiv preprint arXiv:1611.09904 (2016).

38

