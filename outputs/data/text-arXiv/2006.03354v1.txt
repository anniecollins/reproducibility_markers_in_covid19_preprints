Classification Aware Neural Topic Model and its Application on a New
COVID-19 Disinformation Corpus
Xingyi Song1 Johann Petrak1,2 , Ye Jiang1
Iknoor Singh1,3 , Diana Maynard1 , Kalina Bontcheva1
1
Department of Computer Science, University of Sheffield, Sheffield, UK
2
Austrian Research Institute for Artificial Intelligence, Vienna, Austria
3
Panjab University, Chandigarh, India
{x.song, johann.petrak, yjiang18}@sheffield.ac.uk
{i.singh, d.maynard, k.bontcheva}@sheffield.ac.uk

arXiv:2006.03354v1 [cs.LG] 5 Jun 2020

Abstract
The explosion of disinformation related to
the COVID-19 pandemic has overloaded factcheckers and media worldwide. To help tackle
this, we developed computational methods
to support COVID-19 disinformation debunking and social impacts research. This paper presents: 1) the currently largest available
manually annotated COVID-19 disinformation category dataset; and 2) a classificationaware neural topic model (CANTM) that combines classification and topic modelling under a variational autoencoder framework. We
demonstrate that CANTM efficiently improves
classification performance with low resources,
and is scalable. In addition, the classificationaware topics help researchers and end-users to
better understand the classification results.

1

Introduction

COVID-19 is not just a global disease pandemic,
but has also led to an ‚Äòinfodemic‚Äô1 (WHO, 2020)
and a ‚Äòdisinfodemic‚Äô2 (Posetti and Bontcheva,
2020). The increased volume (Brennen et al., 2020)
of COVID-19 related disinformation has already
caused public mistrust (Clare and Christie, 2020)
and even real-life damage to health and 5G masts.3
Consequently fact-checkers and media worldwide are having to triage carefully their limited resources in order to uncover and debunk quickly and
effectively the most damaging kinds of COVID-19
disinformation. For example, Brennen et al. (2020)
found that most disinformation in the early stage of
the pandemic made false claims related to actions
and statements by public authorities.
1

‚Äúan over-abundance of information‚Äù (WHO, 2020)
‚Äúthe disinformation swirling amidst the COVID-19 pandemic‚Äù (Posetti and Bontcheva, 2020)
3
https://www.bbc.co.uk/news/uk-england52164358,https://news.sky.com/story/coronavirus-churchordered-to-stop-selling-bleach-based-covid-19-cure11975002

Guided by these needs, we developed an automatic COVID-19 disinformation classifier and
made this available for testing and use by professionals at AFP and First Draft. 4
The challenges of this task are that: 1) there is
no sufficiently large existing dataset annotated with
COVID-19 disinformation categories, which can
be used to train and test machine learning models.
2) Due to the time-consuming nature of manual
fact-checking and disinformation categorisation,
manual corpus annotation is expensive and slow to
create. Therefore the classifier should robustly handle training with low resources. 3) COVID-19 disinformation classification is a fast-moving research
area, thus the model should provide suggestions
to researchers about relevant categories. 4) The
classifier and decisions should be self-explanatory,
enabling journalists to understand the rationale for
the auto-assigned category.
To address the first challenge, we created a new
COVID-19 disinformation classification dataset.
The corpus contains disinformation (e.g. false information or misleading tweets) debunked by the
CoronaVirusFacts Alliance led by the International
Fact-checking Network (IFCN) and has been manually annotated with the categories defined in the
most recent social science research on COVID-19
disinformation (Brennen et al., 2020).
For the remaining challenges, we propose a Classification Aware Neural Topic Model (CANTM)
which combines the benefits of BERT (Devlin
et al., 2019) with a Variational Autoencoder
(VAE)(Kingma and Welling, 2013; Rezende et al.,
2014) based document model (Miao et al., 2016)
to provide:

2

1. Robust classification performance especially
on a small training set ‚Äì instead of training
4
https://cloud.gate.ac.uk/shopfront/displayItem/covid19misinfo

the classifier directly on the original feature
representation, the classifier is trained based
on generated latent variables from the VAE
(Kingma et al., 2014). In this case the classifier has never seen the ‚Äòreal‚Äô training data
during the training, thus reducing the chance
of over-fitting. Our experiment shows that
combining BERT with the VAE framework
improves the classification results on a small
dataset, and is also scalable to larger datasets.
2. Ability to discover the hidden topics related
to the pre-defined classes ‚Äì the success of
the VAE as a topic model5 has already been
proven in previous research (Miao et al.,
2016, 2017; Card et al., 2018). We further
adapt the VAE-based topic modelling to be
classification-aware, by proposing a stacked
VAE and introducing the classification information directly in the latent topic generation.
3. The classifier is self-explaining6 ‚Äì in CANTM
the same latent variable (topic) is used in both
the classifier and topic modelling. The topic
can be seen as an explanation of the classification model. We further introduce ‚Äòclassassociated topics‚Äô that directly map the topic
words to classifier classes. This enables the
inspection of topics related to a class, thus providing a ‚Äòglobal‚Äô explanation of the classifier.
The main contributions of this paper are: 1) A
new COVID-19 disinformation corpus with manually annotated categories. 2) A BERT language
model with a VAE topic modelling framework,
which shows a performance improvement (over
using BERT alone) in a low resource classifier
training setting. 3) The CANTM model, which
takes classification information into account for
topic generation. 4) The use of topic modelling
to introduce ‚Äòclass-associated‚Äô topics as a global
explanation of the classifier. The corpus and source
code of this work will be open-source, and the web
service and API will be publicly available.

2

COVID-19 Disinformation Category
Dataset

The corpus was created in three stages. Firstly,
we collected COVID-19 related debunks of disinformation until 13th April, 2020 published on the
5

Some researchers distinguish ‚Äòdocument model‚Äô from
‚Äòtopic model‚Äô (Miao et al., 2017; Korshunova et al., 2019). For
simplicity, we consider both as a topic model.
6
BERT attention weights could also be treated to explain
the decision, but this is outside the scope of this paper.

IFCN Poynter website7 . The data has the following
fields derived from the published html tags:
‚Ä¢ ‚ÄòClaim‚Äô:
claim of the disinformation,
rephrased by the IFCN fact-checker;
‚Ä¢ ‚ÄòExplanation‚Äô: the explanation of why this is
a false claim as provided by the fact checkers;
‚Ä¢ Source link‚Äô: link to original page of the debunk, as published on the fact-checking organisation‚Äôs website;
‚Ä¢ ‚ÄòDate‚Äô: date of publication on IFC Poynter
website.
Due to the language restrictions of our human annotators, we could only focus on debunks in English. Thus we applied a language detector8 over
the source of the debunk and filtered out all nonEnglish debunks automatically. In total, 1,480 debunked claims remained.
Category
Public authority (PubAuthAction)
Community spread and impact (CommSpread)
Medical advice, self-treatments, and virus effects
(GenMedAdv)
Prominent actors (PromActs)
Conspiracies (Consp)
Virus transmission (VirTrans)
Virus origins and properties (VirOrgn)
Public Reaction (PubRec)
Vaccines, medical treatments, and tests (Vacc)
Cannot determine (None)

Table 1: Categories for annotation, the abbreviations
are in the parentheses

The next stage involved manual annotation,
where an adapted version of Label Studio9 was
used as a web-based annotation tool. The claim,
explanation and source link were all provided to
the annotators, who assigned to each text the most
relevant one of 10 COVID-19 disinformation categories (see Table 1) and indicated their confidence
(from 0-9) in their decision. Originally, these categories were proposed in a recent social science
analysis of a small sample of 225 debunks(Brennen
et al., 2020). We adopted them unchanged, except
for widening their ‚ÄòPublic preparedness‚Äô category
to become ‚ÄòPublic Reaction‚Äô and to include also
disinformation about public protests and other civil
disobedience which are a more recent phenomenon.
In addition, we added a new category ‚ÄòCannot determine (None)‚Äô to enable annotators to flag cases
of COVID-19 disinformation that did not fit any of
the other categories.
7

https://www.poynter.org/ifcn-covid-19-disinformation/
https://pypi.org/project/langdetect/
9
https://github.com/heartexlabs/label-studio
8

We recruited 27 volunteers for the annotation,
and randomly split the data into batches of 20 debunks. In the first round, all annotators worked on
unique batches. In the second round, annotators
received randomised debunks from the first round,
which were then used to measure inter-annotator
agreement (IAA) on COVID-19 disinformation
classification.
The exercise produced 2,192 classified debunks
(see Table 2). Amongst these, 424 samples were
double- or multiple-annotated, from which we calculate the IAA. At this stage, vanilla Cohen‚Äôs
Kappa (Cohen, 1960) was only 0.46.
To increase the data quality and provide a good
training sample for our ML model, we applied a
cleaning step to filter the annotations. We first measured annotator quality by observing agreement
change when removing an (anonymous) annotator. This annotator quality was scored based on the
magnitude of score variance. Based on this, we
then removed annotations from the two annotators
with the lowest scores.
We also measured the impact of the annotator
confidence score on the annotation agreement and
the amount of filtered data, and set a confidence
threshold for each annotator, based on the quality
check from the first round (for most annotators,
this threshold was 6). Any annotation below this
threshold was filtered out.
Finally, 1,293 debunks remained with at least
one reliable classification, and IAA was boosted
to 0.7336 (in percentage) and Cohen‚Äôs Kappa to
0.7040.

Single Annotated
Double Annotated
Multiple Annotated
Annotation Agreement
Kappa

All
1056
213
211
0.5145
0.4660

Cleaned
1038
186
69
0.7336
0.7040

Table 2: Label counts and annotation agreements
of unfiltered annotation (All) and filtered annotation
(Cleaned)

The final dataset was produced by merging the
multiple-annotated debunks on the basis of: 1) majority agreement between the annotators where possible; 2) confidence score ‚Äì if there is no majority
agreement, we use the highest confidence score.
Table 3 shows the statistics of the merged dataset
in each category. The category distribution is consistent with that found in Brennen et al. (2020).

PubAuthAction
251
GenMedAdv
177
VirOrgn
63

CommSpread
225
VirTrans
80
None
43

PubRec
60
Vacc
76

PromActs
221
Consp
97

Table 3: Label count after merge in each category

3

Model

In this section, we review some related work, using
this to explain the motivation for our model. Then
we describe our CANTM model in Section 3.2.
Other related work is reviewed in Section 5.
3.1

Background and Preliminaries

Miao et al. (2016) introduce a generative neural
variational document model (NVDM) that models
the document (x) likelihood p(x) using a variational autoencoder (VAE), which can be described
as:
log p(x) = ELBO + DKL (q(z|x)||p(z|x))
ELBO = Eq(z|x) [log p(x|z)] ‚àí DKL (q(z|x)||p(z))
(1)
Where p(z) is the prior distribution of latent variable z. q(z|x) is the inference network (encoder)
used to approximate the posterior distributions
p(z|x). p(x|z) is the generation network (decoder)
to reconstruct the document based on latent variable (topics) z ‚àº q(z|x) sampled from the inference network.
According to Equation 1, maximising the ELBO
(evidence lower bound) is equivalent to maximising
the p(x) and minimising the difference between
q(z|x) and p(z|x). Therefore, maximising ELBO
will be the objective function in the NVDM or VAE
framework, or negative ELBO for gradient descent
optimisation. The latent variable z then can be
treated as the latent topics of the document.
NVDM is an unsupervised model, hence we
have no control on the topic generation. In order to
uncover the topics related to the target y (e.g. category, sentiment or coherence) in which we are interested, we can consider several previous approaches.
The Topic Coherence Regularization (NTR) (Ding
et al., 2018) applies the topic coherence as additional loss (i.e. loss L = ‚àíELBO + C) to regularise the model to generate more coherent topics.
SCHOLAR (Card et al., 2018) directly inserts the
target information into the encoder (i.e. q(z|x, y)),
making the latent variable also dependent on the
target. However, when target information is missing at application time, SCHOLAR treats the target

input as a missing feature (i.e. all zero vector) or all
possible combinations. Hence the latent variable
becomes less dependent on the target.
Inspired by the stacked VAE of Kingma et al.
(2014), we combined ideas from NTR and
SCHOLAR. We stacked a classifier-regularised
VAE (M1) and a classifier-aware VAE (M2) enabling the provision of robust latent topic information even at testing time without label information.
3.2

Classifier Aware Neural Topic Model
(CANTM)

The training sample D = (x, xbow , y) is a triple of
the BERT word-pieces sequence representation of
the document (x), a bag-of-words representation of
the document (xbow ) and its associate target label
y.
The general architecture of our model is illustrated in Figure 1. CANTM is a stacked VAE containing 6 sub-modules:
1. M1 encoder (or M1 inference network) q(z|x)
2. M1 decoder (or M1 generation network)
p(xbow |z)
3. M1 Classifier yÃÇ = f (z)
4. M1 Classifier decoder p(x|yÃÇ)
5. M2 encoder (or M2 inference network)
q(zs |x, yÃÇ)
6. M2 decoder (or M2 generation network)
p(xbow |yÃÇ, zs ) and p(yÃÇ|zs )
Sub-modules 1 and 2 implement a VAE similar to
NVDM. The modification over original NVDM is
that instead of bag-of-words (xbow ) input and output to the model, our input is a BERT word-pieces
sequence representation of the original document
(x). The reason for this modification is that x can
be seen as a grammar-enriched xbow , and we could
capture better semantic representation in the hidden
layers (e.g. though pre-trained BERT) and benefit the classification and topic generation. Also,
q(z|x) is an approximation of p(z|xbow ), and they
do not have to follow the same condition (Kingma
and Welling, 2013), as our model is still under the
VAE framework. Sub-modules 5 and 6 implement
another VAE that models the joint probability of
document xbow and label yÃÇ. Note that the label
in M2 is a classifier prediction, hence this label
information will always be available for M2 VAE.
To apply CANTM to unlabelled test data, we fix
the M1 weights that are pre-trained with labelled
data, and only train the M2 model. In Sections

3.2.1 to 3.2.5, we will describe the detail of each
sub-module.
3.2.1 M1 Encoder
The M1 encoder is illustrated in the yellow part of
Figure 1. During the encoding process, the input x
is first transformed into a BERT-enriched representation h using a pre-trained BERT model. We use
the CLS token output from BERT as h. Then linear transformations l1 (h) and l2 (h) transform the h
into parameters of variational distribution that are
used to sample latent variable z. The variational
distribution is a Gaussian distribution (N (¬µ, œÉ))
The M1 Encoder is represented in Equation 2
q(z|x) = N (¬µ, œÉ)
¬µ = l1 (h), œÉ = l2 (h)

(2)

h = BERT (x)
Following previous approaches (Rezende et al.,
2014; Kingma and Welling, 2013; Miao et al.,
2016), a re-parameterisation trick is applied to allow back-propagation to go though the random
node.
z =¬µ+œÉ

,  ‚àº N (0, 1)

(3)

where  is random noise sampled from a 0 mean
and variance 1 Gaussian distribution. In the decoding process (next section), the document is reconstructed from latent variable z, hence z can be
considered as the document topic.
3.2.2 M1 Decoder
The decoding process (red part in Figure 1) is to
reconstruct xbow from latent variable z. This is
modelled by a fully connected feed-forward (FC)
layer with softmax activation (sigmoid activation
normalised by softmax function. For the rest of the
paper we will describe this as softmax activation for
simplicity). The likelihood of the reconstruction
p(xbow |z) can be calculated by
p(xbow |z) = sof tmax(zR + b)

xbow

Where R ‚àà R|z|√ó|V | , and |V | is the vocabulary
size. R is a learnable weight for mapping between
topics and words. The topic words for each topic
can be extracted according to this weight. is the
dot product.
3.2.3 M1 Classifier and Classifier Decoder
The classifier yÃÇ = sof tmax(F C(z)) is a softmax
activated FC layer. It is based on the same latent
variable z from the M1 encoder. Since the M1 VAE
and classifier are jointly trained based on z, it can
be seen as a ‚Äòclass regularized topic‚Äô and also serve

Softmax

~

~

linear

x

BERT

Softmax

t

linear

Softmax

h
linear

linear

CANTM
nonLin

classifier

m

nonLin

Softmax

Figure 1: Overview of model architecture, Linear is the linear transformation (i.e. Linear(x)=xW+b), nonLin is
linear transformation with non-linear activation function f(Linear(.)), Softmax is Softmax activated linear function

as a ‚Äòglobal explanation‚Äô of the classifier. Furthermore, yÃÇ itself can be seen as a compressed topic of
z, or ‚Äòclass-associated topic‚Äô. The document can
be reconstructed by yÃÇ in the same way as the M1
decoder, and the likelihood of p(xbow |yÃÇ) is given
by:
p(xbow |yÃÇ) = sof tmax(yÃÇRct + b)

xbow

R|y|√ó|V |

Where Rct ‚àà
is a learnable weight for
‚Äòclass-associated topic‚Äô word mapping.
3.2.4

M2 Encoder

The encoding process of M2 (blue part in Figure
1) is similar to M1, but instead of only encoding x,
M2 encodes both the document and predicted label
from the M1 classifier q(zs |x, yÃÇ). In the M2 encoder process, we first concatenate (‚äï) the BERT
representation h and predicted label yÃÇ, then merge
them through a leaky rectifier (LRelu)(Maas et al.,
2013) activated FC layer. We refer to this as
nonLin in the remainder of the paper.
m = nonLin(h ‚äï yÃÇ)

3.2.5

M2 Decoder

The decoding process of M2 p(xbow , yÃÇ|zs ) is divided into two decoding steps (p(xbow |yÃÇ, zs ) and
p(yÃÇ|zs )) by Bayes Chain Rule.
The step p(yÃÇ|zs ) can be considered as M2
classifier, calculated by softmax FC layer, the
likelihood function is modelled as p(yÃÇ|zs ) =
sof tmax(F C(zs )) yÃÇ. The M2 classifier will
not be used for classification in this work, only for
the loss calculation (see Section 3.2.6).
In step p(xbow |yÃÇ, zs ), we first merge yÃÇ and zs
using nonLin layer t = nonLin(yÃÇ ‚äï zs ) where
t is a ‚Äòclassification aware topic‚Äô. Then xbow is
reconstructed using a softmax layer. The likelihood
function is:
p(x|yÃÇ, zs ) = sof tmax(tRs + b)

xbow

R|zs |√ó|V |

where Rs ‚àà
is a learnable weight for the
‚Äòclassification aware topic‚Äô word mapping.
3.2.6

Loss Function

= LRelu(F C(h ‚äï yÃÇ))
As for the M1 encoder, a linear transformation
then maps the merged feature m to the parameters
of the variational distribution represented by the
latent variable of M2 model zs . The variational
distribution is a Gaussian N (¬µs , œÉs ):
q(zs |x, yÃÇ) = N (¬µs , œÉs )
¬µs = l3 (m), œÉs = l4 (m)

The objective of CANTM is to: 1) maximise ELBOxbow for M1 VAE; 2) maximise
ELBOxbow,yÃÇ for M2 VAE; 3) minimise crossentropy loss Lcls for M1 classifier and 4) maximise the log likelihood of M1 class decoder
log[p(xbow |yÃÇ)]. Hence the loss function10 for
10
For full details of the ELBO term deriving process please
see Appendix C

‚Ä¢ CANTM (our proposed method): We use the
same BERT implementation and settings as
L = ŒªLcls ‚àí ELBOxbow ‚àí ELBOxbow,yÃÇ
described above. The sampling size (num‚àí EyÃÇ [log p(xbow |yÃÇ)]
ber of samples z and zs drawn from the en= ŒªLcls ‚àí Ez [log p(xbow |z)] + DKL (q(z|x)||p(z))
coder) in training and testing are 10 and 1
‚àí Ezs [log p(xbow |yÃÇ, zs )] ‚àí Ezs [log p(yÃÇ|zs )]
respectively, and we only use expected value
(¬µ)
of q(z|x) for the classification at testing
+ DKL (q(zs |x, yÃÇ)||p(zs )) ‚àí EyÃÇ [log p(xbow |yÃÇ)]
time. Unless mentioned otherwise, the topwhere p(z) and p(zs ) are zero mean diagonal
ics reported from CANTM are ‚Äòclassificationmultivariate Gaussian priors (N (0, I)), Œª =
aware‚Äô.
vocabSize/numclass is a hyperparameter con‚Ä¢ NVDM (Miao et al., 2016): We re-implement
trolling the importance classifier loss.
NVDM14 , with two versions: 1) original
NVDM as described in (Miao et al., 2016)
4 Experiments
(‚ÄúNVDMo‚Äù in the results ); 2) NVDM with
In this section, we evaluate the performance of
BERT representation (‚ÄúNVDMb‚Äù in the reCANTM on both COVID-19 disinformation classults).
sification and topic modelling (with 50 topics).
‚Ä¢ SCHOLAR (Card et al., 2018): We use the
Three experiments are presented. We first comoriginal author implementation15 with all depare the performance of CANTM against baseline
fault settings (except the vocabulary size and
approaches on the COVID-19 corpus (Section 4.1);
number of topics).
then we apply CANTM to the IMDB sentiment cor‚Ä¢ Latent Dirichlet Allocation (LDA) (Blei et al.,
pus (Maas et al., 2011) to test its compatibility with
2003): the Gensim (RÃåehuÃärÃåek and Sojka, 2010)
other tasks with larger data (Section 4.3.1); finally,
implementation is used.
in Section 4.3 we discuss topic interpretability by
visualising the topic words.
All bag-of-words inputs are pre-processed usWe compare to the following:
BERT,
ing the script publicly available from Card et al.
SCHOLAR, NVDM, and LDA. The settings
(2018).15 The vocabulary sizes are 2000 for the
of CANTM and baselines are:
COVID-19 set and 5000 for the IMDB set (consistent with (Card et al., 2018) to make a fair compar‚Ä¢ BERT (Devlin et al., 2019): We use Hug- ison) based on word counts from each set.
gingface11 (Wolf et al., 2019) ‚ÄòBERT-baseduncased‚Äô pre-trained model and Pytorch im- 4.1 COVID-19 Disinformation Classification
plementation in this experiment. As with
In this experiment, the input text for each instance
CANTM, we use BERT [CLS] output as
is the combination of the Claim and the ExplanaBERT representation, and an additional 50
tion (the average text length is 23 words). The
dimensional feed-forward hidden layer (with
results are reported based on 5-fold cross validaleaky ReLU activation) after that.12 Only the
tion. Since class distribution is imbalanced, we
last transformer encoding layer (layer 11) is
report the macro F-1 measure (F-1)16 and accuracy
unlocked for fine-tuning, the rest of the BERT (Acc.) for the classification task. For the topic
weights were frozen for this experiment. The
modelling task, the metrics reported are perplexity
Pytorch13 implementation of the Adam opti- (Perp.) and non-negative point-wise mutual informiser (Kingma and Ba, 2014) is used in the
mation (NPMI (Chang et al., 2009; Newman et al.,
training with default settings. The batch size
2010)). As in previous work (Miao et al., 2016;
for training is 32. All BERT-related (CANTM, Card et al., 2018), the perplexity is estimated by
NVDMb) implementations in this paper fol- ELBO, and NPMI scores were calculated based on
low the same settings.
the top 10 topic words of each topic.
CANTM is

11

https://github.com/huggingface/transformers
CWNTM contains a sampling layer after the BERT representation, this additional layer is added for fair comparison.
Please check Appendix E on impact of the additional hidden
layer
13
https://pytorch.org/
12

14

Based on code at https://github.com/YongfeiYan/NeuralDocument-Modeling
15
Using code from https://github.com/dallascard/scholar
16
The F-1 is calculated as the average F-1 measure of all
classes, please refer to Appendix E for the class level F-1
score.

Bert
SCHOLAR
NVDMb
NVDMo
LDA
CANTM

Acc.
58.78
48.17
n/a
n/a
n/a
63.34

F-1
54.19
36.40
n/a
n/a
n/a
55.48

Perp.
n/a
2947
1084
781
8518
749

NPMI
n/a
0.25
0.09
0.08
0.12
0.14

Table 4: COVID-19 disinformation results, n/a stands
for not applicable for the model

The COVID-19 evaluation results are shown
in Table 13. BERT as a strong baseline outperforms SCHOLAR in accuracy by more than
10% and almost 18% F-1 measure. This is expected, because BERT is a discriminative model
pre-trained on large corpora and with a much more
complex model structure than SCHOLAR. Our
model CANTM shows almost 5% increase in accuracy and more than 1% F-1 further improvement over BERT. Training on latent variables with
multi-task loss is thus an efficient way to train
on a small dataset even with a pre-trained embedding/language model.
In the topic modelling task, using BERT in
NVDM has better topic coherence than the vanilla
NVDM, but also increases the perplexity. LDA
has high perplexity in the COVID-19 experiment,
which may be because of the relatively small
dataset and short document length (average 19
words after pre-processing and vocabulary filtering), but LDA still has relatively better topic coherence than both NVDM versions. CANTM has
the best perplexity performance, while SCHOLAR
has the best coherence score. It is very difficult
to draw conclusions from the topic modelling task
performance; in Section 4.3 we will discuss the
lack of correlation between topic interpretability
and topic coherence.
4.2

IMDB Sentiment Experiment

The IMDB sentiment corpus contains 50,000
movie reviews annotated with positive and negative sentiment. The number of positive and negative labels is balanced in this corpus (25,000 positive, 25,000 negative, average document length
is 282 words). We use the original train-test split
for evaluation, and report the results on the test
set only. All settings including vocabulary size
and pre-processing steps exactly follow Card et al.
(2018). Hence the NVDM, LDA and SCHOLAR
results are as reported in Card et al. (2018).
The IMDB results are shown in Table 5.
The classification results are consistent with the
COVID-19 experiment. Baseline BERT has better

Metrics
NVDM*
LDA*
SCHOLAR*
BERT
CANTM

Accuracy
n/a
n/a
87
89.54
90.00

Perplexity
1748
1508
1905
n/a
1786

Coherence
0.06
0.13
0.14
n/a
0.06

Table 5: IMDB results, n/a stands for not applicable
for the model (*NVDM, LDA and Scholar results are
borrowed from Card et al. (2018))

accuracy than SCHOLAR, and CANTM further
improves over BERT by about 0.5%. The topic
modelling performance of CANTM is almost the
same as for NVDM, while LDA and SCHOLAR
have the best performance in perplexity and coherence, respectively.
4.3

Topic Interpretability Discussion

CANTM 0.50
CANTM 0.04
SCHOLAR 0.58
SCHOLAR 0.07

please patents link ecuador patent read
click full article guayaquil
cure proven met protection leader pope aajtak within elizabeth developed
article link read please click full ecuador
cases guayaquil ecuadorian
coronavirus story lab china created website
similar general chinese director

Table 6: Topic words of the best and worst coherence
topics NPMI score in parentheses

Table 14 shows the topics from CANTM and
SCHOLAR with the best and worst NPMI scores.
We found there is no strong correlation between
coherence score and topic interpretability in supervised topic models.17 The SCHOLAR topics
are included here to demonstrate this is not just the
case in CANTM. With knowledge of the predefined
classes (see Table 1), the lowest coherence topic
(Row 2, CANTM 0.04) in Table 14 can be easily interpreted as a mixture of the topics ‚ÄòGeneral
Medical advice‚Äô and ‚ÄòProminent actors‚Äô, while the
highest two topics (CANTM 0.50 and SCHOLAR
0.58) are more general words appearing in the text.
CANTM 0.09
CANTM 0.03

worst waste like boring lousy wasted lame
sucks bottom tedious
animation movie enjoy better film disney
time acting recommend make

Table 7: The IMDB topics from the two best and worst
topic coherence scores

Table 7 shows the CANTM-generated IMDB
topics. We select two topics, based on the best
and worst topic coherence score. Since IMDB is
a sentiment-labelled data set, we can clearly see
that the topics generated here are the sentiment
17
For a full comparison to NVDM and LDA and discussion,
please check Appendix E

and aspect words. Row 1 is the topic related to
negative sentiment. Row 2 shows the topics related
to positive sentiment in animation movies. Again,
the lowest coherence CANTM topic is still highly
interpretable.

police bat cdc spread visit tourists answer data july clip
mention conference professor since april quarantined
starting spoke supporting please
health ever salt swat ginger pope uses welfare hands
singapore
people vaccine since weapon hospital scientific man
group cells working

4.3.1 Class-Associated Topics
In Section 3.2.3 we discussed the Class-Associated
Topics, which can be used to visualise the word
distribution in the training data associated with the
pre-defined classes. Table 8 shows an example
of topic words of class-associated topics. As the
topics are guided by the classifier, the topic words
are strongly associated with the pre-defined classes,
and can be used to discover concepts related to
the classes. For example, temperature (topic word
‚Äòhot‚Äô in GenMedAdv) is one of the most connected
concepts to GenMedAdv. In addition, this feature
could be potentially used to check the biases of the
trained classifier.

Table 9: COVID-19 classification-aware topics from
unlabelled data

Vacc
VirOrgn
GenMedAdv
Consp

cure vaccine new covid developed novel
scientists claimed coronavirus claims
coronavirus shows video bat wuhan novel
source outbreak virus taken
coronavirus cure experts novel prevent water evidence kill scientific hot
coronavirus chinese covid virus lab wuhan
outbreak new china posts

Table 8: Top 10 class topic words for Vaccines(Vacc),
Medical advice(GenMedAdv), General Medical advice
(GenMedAdv) and Conspiracies (Consp)

4.3.2

CANTM with Unlabelled COVID-19
Disinformation
To test the CANTM with unlabelled data, we collected further 4587 COVID-19 debunks (until 26th
May 2020) from IFCN (the same collection as described in Section 2). In the training, we reuse
the pre-trained M1 model (with labelled data), and
only train M2 model with ‚àíELBOxbow,yÃÇ loss. Table 9 shows the example classification-aware topics
trained with newly collected data. We can clearly
see these topics are still classification-related even
without labels. (Row 1: virus transmission; Row
2:Public authority; Row 3:Medical advice and Row
4:Conspiracies)

5

Further Related Work

In addition to the work cited in the previous sections, the following research is related to our approach: VAE based topic/document modelling
e.g. Mnih and Gregor (2014) trained a VAE based
document model using the REINFORCE algorithm

(Williams, 1992); Miao et al. (2017) introduce
Gaussian Softmax distribution, Gaussian Stick
Breaking distribution and Recurrent Stick Breaking
process for topic distribution construction. Srivastava and Sutton (2017) proposed a ProdLDA that
applies a Laplace approximation to re-parameterise
Dirichlet distribution in VAE. Zhu et al. (2018) apply a Biterm Topic Model (Cheng et al., 2014; Yan
et al., 2013) into the VAE framework for short text
topic modelling. Topic models with additional
information (e.g. author, label etc.): example
work includes Supervised LDA(Mcauliffe and Blei,
2008), Labeled LDA (Ramage et al., 2009), Sparse
Additive Generative Model (Eisenstein et al., 2011),
Structural Topic Models (Roberts et al., 2014), Author Topic Model (Rosen-Zvi et al., 2004), Time
topic model (Wang and McCallum, 2006) and
topic model conditional on any arbitrary Features
(Mimno and McCallum, 2008; Korshunova et al.,
2019). NVDM in text classification: Zeng et al.
(2018); Gururangan et al. (2019), apply NVDM
as additional topics feature in text classification.
Compare to these approaches, CANTM is an asymmetric (different encoder input and decoder output)
VAE that directly use VAE latent variable as classification feature without external features, hence
we can use latent topics as classifier explanation.

6

Conclusion

In this paper, we introduced the COVID-19 disinformation corpus, which has 10 manually annotated categories of debunked COVID-19 disinformation. After quality control and a filtering process, the inter-annotator agreement average
Cohen‚Äôs Kappa is 0.70. We also present a new
classification-aware topic model, that combines the
BERT language model with the VAE document
model framework and demonstrate improved classification accuracy over a vanilla BERT model. In
addition, the classification-aware topics provide
class related topics, which are: a) an efficient way
to discover the class of (pre-defined) related topics,
and b) a proxy explanation of classifier decisions.

References
David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent dirichlet allocation. Journal of machine Learning research, 3(Jan):993‚Äì1022.

Diederik P Kingma and Max Welling. 2013. Autoencoding variational bayes. In Proceedings of the
2nd International Conference on Learning Representations.

Scott Brennen, Felix Simon, Philip Howard, and Rasmus Kleis Nielsen. 2020. Types, sources, and
claims of covid-19 misinformation. Technical report, Reuters Institute.

Durk P Kingma, Shakir Mohamed, Danilo Jimenez
Rezende, and Max Welling. 2014. Semi-supervised
learning with deep generative models. In Advances
in neural information processing systems, pages
3581‚Äì3589.

Dallas Card, Chenhao Tan, and Noah A Smith. 2018.
Neural models for documents with metadata. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long
Papers), pages 2031‚Äì2040.

Iryna Korshunova, Hanchen Xiong, Mateusz Fedoryszak, and Lucas Theis. 2019. Discriminative topic
modeling with logistic lda. In Advances in Neural
Information Processing Systems, pages 6767‚Äì6777.

Jonathan Chang, Sean Gerrish, Chong Wang, Jordan L
Boyd-Graber, and David M Blei. 2009. Reading
tea leaves: How humans interpret topic models. In
Advances in neural information processing systems,
pages 288‚Äì296.
Xueqi Cheng, Xiaohui Yan, Yanyan Lan, and Jiafeng
Guo. 2014. Btm: Topic modeling over short texts.
IEEE Transactions on Knowledge and Data Engineering, 26(12):2928‚Äì2941.
Clare Clare and Lorna Christie. 2020. Covid-19 misinformation. UK Parliament Post.
Jacob Cohen. 1960. A coefficient of agreement for
nominal scales. Educational and psychological measurement, 20(1):37‚Äì46.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2019. Bert: Pre-training of
deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages
4171‚Äì4186.
Ran Ding, Ramesh Nallapati, and Bing Xiang. 2018.
Coherence-aware neural topic modeling. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 830‚Äì
836, Brussels, Belgium. Association for Computational Linguistics.
Jacob Eisenstein, Amr Ahmed, and Eric P Xing. 2011.
Sparse additive generative models of text. In Proceedings of the 28th International Conference on International Conference on Machine Learning, pages
1041‚Äì1048.
Suchin Gururangan, Tam Dang, Dallas Card, and
Noah A Smith. 2019. Variational pretraining for
semi-supervised text classification. In Proceedings
of the 57th Annual Meeting of the Association for
Computational Linguistics, pages 5880‚Äì5894.
Diederik P Kingma and Jimmy Ba. 2014. Adam: A
method for stochastic optimization. In Proceedings
of the conference paper at the 3rd International Conference for Learning Representations.

Andrew L. Maas, Raymond E. Daly, Peter T. Pham,
Dan Huang, Andrew Y. Ng, and Christopher Potts.
2011. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Human Language Technologies, pages 142‚Äì150, Portland, Oregon, USA. Association for Computational
Linguistics.
Andrew L Maas, Awni Y Hannun, and Andrew Y Ng.
2013. Rectifier nonlinearities improve neural network acoustic models. In Proceeding of International Conference on Machine Learning, volume 30,
page 3.
Jon D Mcauliffe and David M Blei. 2008. Supervised
topic models. In Advances in neural information
processing systems, pages 121‚Äì128.
Yishu Miao, Edward Grefenstette, and Phil Blunsom. 2017.
Discovering discrete latent topics
with neural variational inference. In Proceedings
of the 34th International Conference on Machine
Learning-Volume 70, pages 2410‚Äì2419. JMLR. org.
Yishu Miao, Lei Yu, and Phil Blunsom. 2016. Neural
variational inference for text processing. In International conference on machine learning, pages 1727‚Äì
1736.
David Mimno and Andrew McCallum. 2008. Topic
models conditioned on arbitrary features with
dirichlet-multinomial regression. In Proceedings of
the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence, pages 411‚Äì418.
Andriy Mnih and Karol Gregor. 2014. Neural variational inference and learning in belief networks. In
Proceedings of the 31st International Conference
on International Conference on Machine LearningVolume 32, pages II‚Äì1791.
David Newman, Jey Han Lau, Karl Grieser, and Timothy Baldwin. 2010. Automatic evaluation of topic
coherence. In Human language technologies: The
2010 annual conference of the North American chapter of the association for computational linguistics,
pages 100‚Äì108. Association for Computational Linguistics.

Julie Posetti and Kalina Bontcheva. 2020. Policy brief
1, disinfodemic: Deciphering covid-19 disinformation. Technical report, United Nation Educational,
Scientific and Cultural Organization.

Xiaohui Yan, Jiafeng Guo, Yanyan Lan, and Xueqi
Cheng. 2013. A biterm topic model for short texts.
In Proceedings of the 22nd international conference
on World Wide Web, pages 1445‚Äì1456.

Daniel Ramage, David Hall, Ramesh Nallapati, and
Christopher D Manning. 2009. Labeled lda: A supervised topic model for credit attribution in multilabeled corpora. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language
Processing: Volume 1-Volume 1, pages 248‚Äì256. Association for Computational Linguistics.

Jichuan Zeng, Jing Li, Yan Song, Cuiyun Gao,
Michael R Lyu, and Irwin King. 2018. Topic memory networks for short text classification. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3120‚Äì
3131.

Radim RÃåehuÃärÃåek and Petr Sojka. 2010. Software
Framework for Topic Modelling with Large Corpora. In Proceedings of the LREC 2010 Workshop
on New Challenges for NLP Frameworks, pages 45‚Äì
50, Valletta, Malta. ELRA. http://is.muni.cz/
publication/884893/en.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan
Wierstra. 2014. Stochastic backpropagation and
approximate inference in deep generative models.
In International Conference on Machine Learning,
pages 1278‚Äì1286.
Margaret E Roberts, Brandon M Stewart, Dustin
Tingley, Christopher Lucas, Jetson Leder-Luis,
Shana Kushner Gadarian, Bethany Albertson, and
David G Rand. 2014. Structural topic models for
open-ended survey responses. American Journal of
Political Science, 58(4):1064‚Äì1082.
Michal Rosen-Zvi, Thomas Griffiths, Mark Steyvers,
and Padhraic Smyth. 2004. The author-topic model
for authors and documents. In Proceedings of the
20th conference on Uncertainty in artificial intelligence, pages 487‚Äì494. AUAI Press.
Akash Srivastava and Charles Sutton. 2017. Autoencoding variational inference for topic models. In
Proceedings of 2017 International Conference on
Learning Representations.
Xuerui Wang and Andrew McCallum. 2006. Topics
over time: a non-markov continuous-time model of
topical trends. In Proceedings of the 12th ACM
SIGKDD international conference on Knowledge
discovery and data mining, pages 424‚Äì433.
WHO. 2020. Novel coronavirus(2019-ncov) situation
report - 13. Technical report, World Health Organization.
Ronald J Williams. 1992. Simple statistical gradientfollowing algorithms for connectionist reinforcement learning. Machine learning, 8(3-4):229‚Äì256.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R‚Äôemi Louf, Morgan Funtowicz, and Jamie Brew. 2019. Huggingface‚Äôs transformers: State-of-the-art natural language processing. ArXiv, abs/1910.03771.

Qile Zhu, Zheng Feng, and Xiaolin Li. 2018.
GraphBTM: Graph enhanced autoencoded variational inference for biterm topic model. In Proceedings of the 2018 Conference on Empirical Methods
in Natural Language Processing, pages 4663‚Äì4672,
Brussels, Belgium. Association for Computational
Linguistics.

7

Appendix A - COVID-19 Annotation Categories Definition
‚Ä¢ Public authority: Claims about policy, action, or communication by a public authority (e.g. government department, police, fire brigade, government officials), including claims about WHO guidelines
and recommendations as well as those about governments‚Äô action or advice.
‚Ä¢ Community spread and impact: Claims about people, groups, or individuals with regard to how
the virus is spreading (internationally, regionally, or within more specific communities); impact on
people, groups (including religions and ethnic minorities), or individuals; deaths, etc.
‚Ä¢ Medical advice, self-treatments, and virus effects: Claims about health remedies, self-treatments,
self-diagnosis, signs and symptoms, effects of the virus, etc.
‚Ä¢ Prominent actors: Claims about pharmaceutical companies, media organisations, health-care supply
businesses, other companies, or famous people (including celebrities and politicians). Note that
this does not include claims made bypoliticians or other famous people unless they are about other
prominent actors.
‚Ä¢ Conspiracies: Claims that the virus was created as a bioweapon, that some organization supposedly
created the pandemic, that it was predicted, etc.
‚Ä¢ Virus transmission: Claims about how the virus is transmitted and how to prevent transmission. This
includes cleaning as well as use of specific lighting, appliances, protective equipment, etc.
‚Ä¢ Virus origins and properties: Claims about the origins of the virus (e.g,. in animals) or its properties.
‚Ä¢ Public Reaction: Claims that encourage hoarding, buying supplies, practising or avoiding social distancing, compliance or non-compliance with public health measures, protests and civil disobedience
against official measures (including government measures). etc.
‚Ä¢ Vaccines, medical treatments, and tests: Claims about vaccines, tests, and treatments, including the
development and availability of a vaccine or a treatment. (Claims about self-treatment fall under the
medical advice category, however.)
‚Ä¢ Cannot determine: Use this category if the claim does not fit into any category above, if it does not
seem to contain misinformation, or if you cannot read the language or understand the text for any
reason.

8

Appendix B - Corpus Structure

The COVID-19 Disinformation corpus is organised in Json format with the following fields.
‚Ä¢ Debunk Date: The date of the disinformation debunked
‚Ä¢ Date: The date of the disinformation first posted online
‚Ä¢ Country: Country location of the fact-checker
‚Ä¢ Claim: The claim of the disinformation
‚Ä¢ Explanation: The explanation from the fact-checker of why this is a disinformation
‚Ä¢ Source: The link to the disinformation debunk page
‚Ä¢ unique wv id: hash code based on the first 200 words of ‚ÄòClaim‚Äô and ‚ÄòExplanation‚Äô
‚Ä¢ Factcheck Org: The organisation of the fact-checker from
‚Ä¢ annotations: Contains annotations before merge.
‚Ä¢ selected label: The merged annotation label

9

Appendix C - Deriving the ELBO

This section describes the details of ELBOxbow and ELBOxbow,yÃÇ derivation and calculation.
z ‚àº q(z|x)
log p(xbow ) = Ez log p(xbow )
= Ez [log p(xbow , z)] ‚àí Ez [log p(z|xbow )]
p(xbow , z)
p(z|xbow )
= Ez [log
] ‚àí Ez [log
]
q(z|x)
q(z|x)
= EBLOxbow ‚àí DKL (p(z|xbow )||q(z|x))
= EBLOxbow + DKL (q(z|x)||p(z|xbow ))
ELBOxbow
= Ez [log p(xbow , z)] ‚àí Ez [log q(z|x)]
= Ez [log p(xbow |z)] + Ez [log p(z)] ‚àí Ez [log q(z|x)]
= Ez [log p(xbow |z)] ‚àí DKL (q(z|x)||p(z))
zs ‚àº q(z|x, yÃÇ)
log p(xbow , yÃÇ) = Ezs log p(xbow , yÃÇ)
= Ezs [log p(xbow , yÃÇ, zs )] ‚àí Ezs [log p(zs |xbow , yÃÇ)]
p(xbow , yÃÇ, zs )
p(zs |xbow , yÃÇ)
= Ezs [log
] ‚àí Ezs [log
]
q(zs |x, yÃÇ)
q(zs |x, yÃÇ)
= EBLOxbow,yÃÇ ‚àí DKL (p(zs |xbow , yÃÇ)||q(zs |x, yÃÇ))
ELBOxbow,yÃÇ
= Ezs [log p(xbow , yÃÇ, zs )] ‚àí Ezs [log q(zs |x, yÃÇ)]
= Ezs [log p(xbow |yÃÇ, zs )] + Ezs [log p(yÃÇ, zs )] ‚àí Ezs [log q(zs )|x, yÃÇ)]
= Ezs [log p(xbow |yÃÇ, zs )] + Ezs [log p(yÃÇ|zs )] + Ezs [p(zs )] ‚àí Ezs [log q(zs )|x, yÃÇ)]
= Ezs [log p(xbow |yÃÇ, zs )] + Ezs [log p(yÃÇ|zs )] ‚àí DKL (q(zs |x, yÃÇ)||p(zs ))
Where p(z) = p(zs ) = N (0, I) is a zero mean diagonal multivariate Gaussian prior, hence the
DKL (q(z|x)||p(z)) and DKL (q(zs |x, yÃÇ)||p(zs )) will be
p(z) = p(zs ) = N (0, I)
DKL (q(z|x)||p(z)) = 0.5(œÉ 2 + ¬µ2 ‚àí log(œÉ 2 ) ‚àí 1)
DKL (q(zs |x, yÃÇ)||p(zs )) = 0.5(œÉs2 + ¬µ2s ‚àí log(œÉs2 ) ‚àí 1)

10

Appendix D ‚Äì Experimental Details

The bag-of-words pre-processing step is the same as (Card et al., 2018): All characters are transformed to
lower case; stopwords18 , punctuation, all tokens less than 3 characters and all tokens that include numbers
are removed.
The pre-processing step for BERT representation is different from bag-of-words pre-processing. For
the COVID-19 corpus, all characters are lowercased, and tokenised by the BERT tokeniser from Huggingface19 (Wolf et al., 2019) Library. The IMDB corpus has a longer average document length, and some of
the documents are longer than the pre-trained BERT length limitation (510 + CLS and SEP). Therefore,
we only keep the first 510 tokens.
The ADAM optimiser parameters are default from the Pytorch Library: Learning Rate = 0.001,
betas=(0.9, 0.999). The number of training epochs are 200 as in Card et al. (2018), with early stopping
when no training loss (classification loss for CANTM) decrease after 4 epochs.
18
19

snowball.tartarus.org/algorithms/ english/stop.txt
https://github.com/huggingface/transformers

The fine tuning layers for BERT (Huggingface BERT-base implementation) are:
‚Ä¢ encoder.layer.11.attention.self.query.weight,
‚Ä¢ encoder.layer.11.attention.self.query.bias,
‚Ä¢ encoder.layer.11.attention.self.key.weight,
‚Ä¢ encoder.layer.11.attention.self.key.bias,
‚Ä¢ encoder.layer.11.attention.self.value.weight,
‚Ä¢ encoder.layer.11.attention.self.value.bias,
‚Ä¢ encoder.layer.11.attention.output.dense.weight,
‚Ä¢ encoder.layer.11.attention.output.dense.bias,
‚Ä¢ encoder.layer.11.intermediate.dense.weight,
‚Ä¢ encoder.layer.11.intermediate.dense.bias,
‚Ä¢ encoder.layer.11.output.dense.weight,
‚Ä¢ encoder.layer.11.output.dense.bias
The number of parameters in CANTM (include BERT) are 110,464,382 and number of trainable
parameters are 8,066,942. The experiment hardware environment are: Intel(R) Xeon(R) Bronze 3204
CPU, TITAN RTX GPU, average epoch run time for COVID corpus is 41 seconds. The full list parameters
number and epoch time shown in Table 10. Please note Gensim LDA does not have GPU support, hence
it running on single core CPU.
Model
CANTM
BERTraw
BERT
SCHOLAR
NVDMb
NVDMo
LDA

num. params
110,464,382
109,489,930
109,521,200
740,360
109,661,140
1,152,600
151,750

epoch time (sec.)
41
36
37
0.05
37
20
0.6

Table 10: Number of parameters and epoch training time. Gensim LDA does not have GPU support

11

Appendix E ‚Äì Additional Experiment Results

To ensure fair comparison between CANTM with the BERT classifier, we first compared: 1) BERT with
additional hidden layer that matches the dimension of latent variables (denoted BERT in the result); 2)
BERT without additional hidden layer, i.e. applying BERT [CLS] token output directly for classification
(denoted BERTraw in the result). The COVID corpus results are shown in Table 11; the BERT with
additional hidden layer has better performance in both accuracy and F-measure. Therefore, we report the
BERT result in the paper.
Metrics
BERT
BERTraw

Acc.
58.78 (3.36)
58.77(3.56)

F-1
54.19 (6.85)
49.74 (7.62)

Table 11: BERT setting comparison on COVID-19 disinformation standard deviation in parentheses

Table 12 shows the class level F1 score of the COVID-19 disinformation corpus. CANTM has the best
F1 score over most of the classes (CommSpread, MedAdv, PromActs, Consp, Vacc,None), also with better

BERT
BERTraw
SCHOLAR
CANTM
BERT
BERTraw
SCHOLAR
CANTM

PubAuth
61.17(4.50)
65.64(2.91)
47.92(9.77)
64.35(1.44)
VirTrans
42.67(8.70)
41.42(5.36)
11.71(10.06)
40.21(8.56)

CommSpread
62.27(5.83)
59.35(4.77)
48.84(11.56)
66.50(3.87)
VirOrgn
57.62(6.72)
53.20(15.92)
45.15(20.49)
55.19(3.43)

MedAdv
75.03(6.54)
75.82(5.53)
71.11(6.99)
79.68(2.12)
PubRec
23.68(10.01)
27.19(13.55)
5.71(11.42)
25.04(9.87)

PromActs
60.12(3.25)
65.51(4.34)
46.93(8.66)
67.21(3.72)
Vacc
64.62(9.66)
65.48(9.62)
55.37(15.78)
72.28(8.40)

Consp
49.92(12.04)
41.90 (10.46)
31.30(13.78)
60.06(6.80)
None
12.59(11.35)
1.90 (3.8)
0.0(0.0)
15.52 (15.0)

Table 12: COVID-19 disinformation class level F1 score, standard deviation in parentheses

Bert
Scholar
NVDMb
NVDMo
LDA
CANTM

Acc.
58.78(3.36)
48.17(6.78)
n/a
n/a
n/a
63.34(1.43)

F-1
54.19(6.85)
36.40(10.85)
n/a
n/a
n/a
55.48(6.32)

Perp.
n/a
2947(353)
1084(88)
781(35)
8518(1132)
749(63)

NPMI
n/a
0.25(0.015)
0.09(0.004)
0.08(0.001)
0.12(0.005)
0.14(0.012)

Table 13: COVID-19 disinformation results, n/a stands for not applicable for the model

standard deviations. Except for the None class, standard deviations for CANTM are below 10. From the
results, the most difficult class to classify is ‚ÄòNone‚Äô. This class represents anything that the annotators
could not decide on, and therefore it could be anything that does not belong to the other 9 classes. In
future work, we might need a better algorithm to handle this problem.
Table 13 shows the results of the COVID-19 performance with different baselines. The scores reported
are the same as Table 4 in the paper, but standard deviation is added (standard deviation here is the average
standard deviation from all classes). According to the results, CANTM not only improves the accuracy
and F1 measure over the BERT baseline, but also improves standard deviation.
Table 14 shows the topics of the best and worst NPMI scores from CANTM and the baselines. We
already discussed the fact that topic interpretability is not strongly associated with the NMPI score in
supervised topic models (CANTM and SCHOLAR) in the paper. However, we found additionally that
the NPMI score may have a better connection to the topic interpretability with the unsupervised topic
modelling (LDA and NVDM). The best NMPI LDA topic (LDA0.149) can be interpreted as a mixed topic
of Russian public authority and medical advice. However, the lowest NMPI LDA topic (LDA0.013) is
difficult to interpret.

12

Appendix E ‚Äì CANTM Topics

In this section we demonstrate the topics generated from CANTM (Table 15 to Table 18 are the COVID-19
topics from CANTM.) Table 15 is Classification-Aware topics Table 16 is Classification-Regularised
topics Table 17 is Classification-Associate topics Table 18 is Classification-Aware topics updated from
unlabelled data.

CANTM 0.50
CANTM 0.04
SCHOLAR 0.50
SCHOLAR 0.05
LDA 0.149
LDA 0.013
NVDM 0.192
NVDM 0.037

please patents link ecuador patent read click full article guayaquil
cure proven met protection leader pope aajtak within elizabeth developed
claim posts facebook false novel times shared multiple twitter thousands
people china doctors conditions barack obama masks pre existing containing
putin keep implemented contrary days code president avoiding drinking talk
cross breath anything empty generator broadcast hanks indicates external apparently
scientifically context reached notification decided vitamin carrying alternative hair preventing
publish quarantine corporation dna listed staff described restricted popular platform

Table 14: Topic words of the best and worst coherence topics

pope vatican francis filipinos region bat mosque seeks giuseppe daniel
strains animal reddit new visited tourist soup original suspected scene
production couple alongside lankan concentration photos image airport unleashed testing
article day click full johannesburg positive read tested italian due
please patents link ecuador patent read click full article guayaquil
korean robredo chloroquine request remedy existing zoology approved vice end
prime lockdown trupti modi police curb wake detained commissioner minister
lions committed drowned protests earthquake gandhi police detained indoors image
cure proven met protection leader pope aajtak within elizabeth developed
bodies originally show seconds london setting stopped rahul libya people
art islamic victims washed tribute lying bodies doctors hong suicide
times quoted robredo novel philippine graphic saddam contracting facebook activist
conspiracy russian movie update anything unleashed disaster trump doctored guard
case patients lockdown wake complete mock medical announcement government streets
died girl jan january kills ecuadorian link first please ecuadorians
strains drug traditional along replies comfort kit focus institute cure
developed treatment check development tea alcohol breath medicine warm study
tweet biden quote leni giuseppe rodrigo paid rappler urged visiting
juice via solution steam chicken lace coronavirus dettol kills effect
palau source spreading via soup says circulated animal claim online
coronavirus cure patents garlic study water sputum ecuador election vinegar
warned times facebook written letter claims transmission advisory data posts
kill ramesh intermediate related viral virus research patented negated book
philippines positive confirmed advisory task patient mask pakistan italian remains
cases case died sars handling chickens ebola reported dead thousand
contaminated steroids advice ministry purported gargling issued issuing colored red
warm dry avoiding remedy practices transmission treatments vinegar ways bakery
abdullah desai badawi swat lockdown minister force extension region police
langowan vatican market indonesia seconds palau wuhan prime roof alkaline
trump president donald quote approval forward roche friday felt intermediate
breath cause patented seconds garlic vinegar scientific deaths studies bat
ministry advisory case bakery aap wash pib notice positive dismissed
bat joe match origin palau flu federal bloggers source former
click humans viruses full indonesia cattle bat ago two let
wife justin multiple illegally bed hospital prayers photo migrants trudeau
pib government considering edited disaster issued forward act offense affairs
restaurant ahmad uploaded saddam former china nazi pretty mosque xia
vinegar india clapping ronaldo salt getting mask wear suggesting message
affairs salt vinegar drinking method test lemon fda ministry media
woman video hospital patients thanksgiving barcelona drill tribute newly gandhi
biden obama bill joe allah china narendra funding giuseppe evers
dead lives tribute night circulated photo left italian croatia picture
covid said kindly virus known use clearly gargling cure suggest
bicarbonate drinking cured dryer effective still eliminates temperature ice lemon
dry maximum masks voted outbreaks doctors happens sars temperatures mask
click full tested read confirmed vatican dettol please seeks positive
positive delhi jan doh january tea chart pope negative strains
posts youtube viewed multiple television issue cases based incidents prevention
barcelona couple development image photograph happens croatia broiler picture virus
link ecuador please article read full lions russian biden saves

Table 15: Full list of Classification-Aware topics for COVID-19 corpus, each line is a topic

lace lay manufactured imports treated demonstration strewn pedestrian gas fronts
chance indoors supermarket bodies citizens streets items frequently thrown fronts
media coronavirus viral taken world social shows video novel man
health coronavirus pandemic cases one covid organization italy countries outbreak
khan living foundation patents london dinner camilla fictional cornwall actor
therefore tony recommendations airborne mouth facial generally copd hair chance
shows actually chinese victims photo art august biden italy protesters
seconds karnataka enter went husband breath converted bjp colored cuban
local click newspaper passengers actor employee corporation link article bank
internet went america mumbai related recent worked extended offense june
deaths covid number health account cases take state confirmed obama
washed wake sea video wife ministry recorded case trudeau department
coronavirus new people cases china kill evidence virus article kills
world doctors health people medical according food sri misleading facebook
found pictures images march viral image old disease along chicken
kong hong video wuhan shows clips police suspected bodies seconds
often buy allow masks buying lockdown important australian mask march
please link alongside full click jair kit crying read article
coronavirus claim evidence said twitter novel facebook times posts multiple
disease using prevention says whether election official cure study research
available president south buy priyanka bill trump testing test vaccine
click please full read labs cuban guayaquil ministry ecuador treating
number aap severe transmission mers likely centre posts worked philippines
china reported internet link francis sars read pope manufactured contain
stated scientific various name oil cure made barack israel clarified
ahmad weave seek jinping badawi abdullah ultraviolet xia additionally soup
place viruses new yet animal products strain sanitizer strains get
considering federal ireland announce patrolling passengers wife anti presidential rubbished
flu sars inaccurate studies important mers around type runny suggests
full medicine ashore items sea wash migrant click ecuadorian organization
link covid two full read doctor confirmed created please click
purportedly notice doses supermarkets try promotes abortion experts levels earthquake
coronavirus ministry novel home caused related video traditional viral youtube
indian claim minister india also false misleading claims prime sri
italy bodies pictures china prayer mosque plates video allah coffins
tested buckingham tourists hand lysol ronaldo advises washington met manufacturer
two wuhan china denied chinese center report confirmed reports officials
desai visuals dung saddam cow july kills sold older lips
satellite accurate sulfur sun dioxide kingdom forecasts translated maps camilla
tested positive doctor coronavirus help recent person getting india novel
stopped company sanitizer label desai trupti saddam theories entering buying
coronavirus different million new family covid say allegedly respiratory death
video man covid first circulated claiming false woman least taken
shows covid hospital video wuhan doctor photo cure woman test
twitter facebook photo times italy claim victims curfew health image
key copd recognized tourist antibiotics rabies rumour short emphasized medication
year modi india old positive narendra curfew muslim wife announced
military full code daniel roche speech event archive please actor
spread show patients new covid virus viral also outbreak response
movie picture couple italian lions lion photograph volleyball barcelona tom

Table 16: Full list of Classification-Regularised topics for COVID-19 corpus, each line is a topic

PubAuthAction
CommSpread
GenMedAdv
PromActs
Consp
VirTrans
VirOrgn
PubPrep
Vacc
None

china government people claim india march facebook coronavirus outbreak covid
coronavirus photo covid people shows video claim novel confirmed shared
coronavirus cure experts novel prevent water evidence kill scientific hot
coronavirus said novel trump video shared president media covid hospital
coronavirus chinese covid virus lab wuhan outbreak new china posts
coronavirus covid evidence virus claim spread video said people surfaces
coronavirus shows video bat wuhan novel source outbreak virus taken
video shows facebook image shared show times outbreak false circulated
cure vaccine new covid developed novel scientists claimed coronavirus claims
video image taken shared covid due streets old india reports

Table 17: Full list of Classification-Associate topics for COVID-19 corpus, each line is a topic

say carry meeting come weed china publicly regularly director consumption
mention conference professor since april quarantined starting spoke supporting please
fake ministry close study refused february attempt video beaten administration
photo post french smoking circulating bank side account eating image
police bat cdc spread visit tourists answer data july clip
announced lockdown stay school office deadly arrested ground degrees always
lockdown every end afp common true islamic concerns rapid undergoing
health ever salt swat ginger pope uses welfare hands singapore
news president victims use minutes cases day continue laboratory developed
corporation denied present force official palau show give post pneumonia
says reports elderly infection claimed beijing speech generally reporting experts
video french time patient includes place victims threatened forward close
leave taken investigation recommendations ventilators exposed organisms people deaths put
italy aired patent election malaria pepper working contrary five growing
suicide included indicates kansas temperatures staying jamaat communities italy two
prayer effective discovered led herbal cov patient article china takes
people vaccine since weapon hospital scientific man group cells working
prime vaccination worldwide due zone created planning airlines producing ultraviolet
evidence human gives even temperature science end claimed across conte
video south covid emergency response never chinese seconds changed images
leave research conspiracy indian starting individuals though text tanker germany
correlation visible sometimes lay produce outright super district initiation six
newly hanks definitively last six hence lack barack elizabeth subway
modular considering stories gotabaya strewn abdullah vibration ramesh miami commission
match preventions relationship indonesia eliminate herbal obama diagnosed bjp japan
key screening dung worldwide try teacher carbon thai decisions spokesman
key advising physically solutions restriction doh camilla promotes vibration scattered
sunday ready netflix production pib telecast cause nazi emergency stopped
reports known study findings hospitals movement vaccine garlic family onion
stating died gas kill best strain announcing chain mass acid
outright experts warm respiratory helps announcements damage factual instead crisis
false ago video president cases undergoing clarification chinese bulletin project
hours cause jamaat make romania xia stock effort isolation kenyan
new medical police city media china social agency also back
coronavirus dangerous medicine advise intermediate graphics brazil ebola imposed generator
quarantine warm sent claims cells members bill conte soup company
government face available outbreak exist proof head service found cruise
found suspended man joe congress whatsapp trump weed claim sauna
case facebook north used production many protocol context citizens text
cures issued onion spokesperson failure even spread actually returned moment
virus published confirmed phishing link cure station extension taking spread
continues widespread stands visible patrolling mandate strewn violating absolutely sophie
trump items blood guard technology told home amid suspended intermediate
coffins announcement october protect coast capacity company carry supplies committed
shows please war paulo nose road flu refer runny post
spain published people south taken showing offering reviewed anything mock
police july infected coffins protocol experts receive say world website
outbreak social hospital virus bats eligible latest hoax taken risk
video north social lemon whole report sources rahul ground ahmad
cases lost official found students manipulated support patients thousand forward

Table 18: Full list of Classification-Aware topics for unlabelled COVID-19 corpus, each line is a topic

