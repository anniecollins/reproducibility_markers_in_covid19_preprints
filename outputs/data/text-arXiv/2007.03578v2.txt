A Vision-based Social Distancing and Critical Density Detection System for
COVID-19
Dongfang Yang‚àó
Ekim Yurtsever‚àó
Vishnu Renganathan
Keith A. Redmill
UÃàmit OÃàzguÃàner

arXiv:2007.03578v2 [eess.IV] 8 Jul 2020

The Ohio State University, Columbus, OH 43210, USA
{yang.3455,yurtsever.2,renganathan.5,redmill.1,ozguner.1}@osu.edu

Abstract

1. Introduction
Social distancing is an effective measure [1] against the
novel COronaVIrus Disease 2019 (COVID-19) pandemic.
However, the general public is not used to keep an imaginary safety bubble around themselves. An automatic warning system [2, 3, 4, 5] can help and augment the perceptive
capabilities of individuals.
Deploying such an active surveillance system requires
serious ethical considerations and smart system design. The
first challenge is privacy [6, 7, 8]. If data is recorded and
stored, the privacy of individuals may be violated intentionally or unintentionally. As such, the system must be realtime without any data storing capabilities.
Second, the detector must not discriminate. The safest
way to achieve this is by building an AI-based detection system. Removing the human out of the detection loop may not
be enough ‚Äì the detector must also be design free. Domainspecific systems with hand-crafted feature extractors may
lead to malign designs. A connectionist machine learning
system, such as a deep neural network without any featurebased input space, is much fairer in this sense, with one
caveat: the distribution of the training data must be fair.
Another critical aspect is being non-intrusive. Individuals should not be targeted directly by the warning system.
A non-alarming audio-visual cue can be sent to the vicinity
of the social distancing breach to this end.
The system must be open-sourced. This is crucial for establishing trust between the active surveillance system and
society.
Against this backdrop, we propose a non-intrusive augmentative AI-based active surveillance system for sending
omnidirectional visual/audio cues when a social distancing
breach is detected. The proposed system uses a pre-trained
deep convolutional neural network (CNN) [9, 10] to detect individuals with bounding boxes in a given monocular
camera frame. Then, detections in the image domain are
transformed into real-world bird‚Äôs-eye view coordinates. If

Social distancing has been proven as an effective measure against the spread of the infectious COronaVIrus Disease 2019 (COVID-19). However, individuals are not used
to tracking the required 6-feet (2-meters) distance between
themselves and their surroundings. An active surveillance
system capable of detecting distances between individuals
and warning them can slow down the spread of the deadly
disease. Furthermore, measuring social density in a region
of interest (ROI) and modulating inflow can decrease social
distancing violation occurrence chance.
On the other hand, recording data and labeling individuals who do not follow the measures will breach individuals‚Äô
rights in free-societies. Here we propose an Artificial Intelligence (AI) based real-time social distancing detection
and warning system considering four important ethical factors: (1) the system should never record/cache data, (2) the
warnings should not target the individuals, (3) no human
supervisor should be in the detection/warning loop, and (4)
the code should be open-source and accessible to the public. Against this backdrop, we propose using a monocular
camera and deep learning-based real-time object detectors
to measure social distancing. If a violation is detected, a
non-intrusive audio-visual warning signal is emitted without targeting the individual who breached the social distancing measure. Also, if the social density is over a critical
value, the system sends a control signal to modulate inflow
into the ROI. We tested the proposed method across realworld datasets to measure its generality and performance.
The proposed method is ready for deployment, and our code
is open-sourced 1 .

‚àó Equal

contribution

1 https://github.com/dongfang-steven-yang/

social-distancing-monitoring

1

Figure 1. Overview of the proposed system. Our system is real-time and does not record data. An audio-visual cue is emitted each time
an individual breach of social distancing is detected. We also make a novel contribution by defining a critical social density value œÅc for
measuring overcrowding. Entrance into the region-of-interest can be modulated with this value.

a distance smaller than the threshold is detected, the system
emits a non-alarming audio-visual cue. Simultaneously, the
system measures social density. If the social density is over
a critical threshold, the system sends an advisory inflow
modulation signal to prevent overcrowding. v
Our main contributions are:

16, 9, 17], which starts with region proposals and then performs the classification and bounding box regression. The
second one is called one-stage detectors, of which the famous models are YOLOv1-v4 [18, 19, 20, 10], SSD [21],
RetinaNet [22], and EfficientDet [23]. In addition to these
anchor-based approaches, there are also some anchor-free
detectors: CornerNet [24], CenterNet [25], FCOS [26], and
RepPoints [27]. These models were usually evaluated on
datasets of Pascal VOC [28, 29] and MS COCO [30]. The
accuracy and real-time performance of these approaches are
good enough for deploying pre-trained models for social
distancing detection.

‚Ä¢ A novel vision-based real-time social distancing and
critical social density detection system
‚Ä¢ Definition of critical social density and a statistical approach to measuring it

Social distancing monitoring. Emerging technologies
can assist in the practice of social distancing. A recent
work [2] has identified how emerging technologies like
wireless, networking, and artificial intelligence (AI) can
enable or even enforce social distancing. The work discussed possible basic concepts, measurements, models, and
practical scenarios for social distancing. Another work [3]
has classified various emerging techniques as either humancentric or smart-space categories, along with the SWOT
analysis of the discussed techniques. A specific social
distancing monitoring approach [4] that utilizes YOLOv3
and Deepsort was proposed to detect and track pedestrians
followed by calculating a violation index for non-socialdistancing behaviors. The approach is interesting but results
do not contain any statistical analysis. Furthermore, there is
no implementation or privacy-related discussion other than
the violation index. Social distancing monitoring is also defined as a visual social distancing (VSD) problem in [5].
The work introduced a skeleton detection based approach
for inter-personal distance measuring. It also discussed the
effect of social context on people‚Äôs social distancing and
raised the concern of privacy. The discussions are inspirational but again it does not generate solid results for social
distancing monitoring and leaves the question open.

‚Ä¢ Measurements of social distancing and critical density
statistics of common crowded places such as the New
York Central Station, an indoor mall, and a busy town
center in Oxford.

2. Related Work
Social distancing for COVID-19. COVID-19 has
caused severe acute respiratory syndromes around the world
since December 2019 [11]. Recent work showed that social
distancing is an effective measure to slow down the spread
of COVID-19 [1]. Social distancing is defined as keeping
a minimum of 2 meters (6 feet) apart from each individual
to avoid possible contact. Further analysis [12] also suggests that social distancing has substantial economic benefits. COVID-19 may not be completely eliminated in the
short term, but an automated system that can help monitoring and analyzing social distancing measures can greatly
benefit our society.
Pedestrian detection. Pedestrian detection can be regarded as either a part of a general object detection problem or as a specific task of detecting pedestrians only. A
detailed survey of 2D object detectors, as well as datasets,
metrics, and fundamentals, can be found in [13]. Another
survey [14] focuses on deep learning approaches for both
generic object detection and pedestrian detection. State-ofthe-art object detectors use deep learning approaches, which
are usually divided into two categories. The first one is
called two-stage detectors, mostly based on R-CNN [15,

Very recently, several prototypes utilizing machine
learning and sensing technologies have been developed to
help social distancing monitoring. Landing AI [31] has proposed a social distancing detector using a surveillance camera to highlight people whose physical distance is below the
2

age captured from a fixed monocular camera with height H
and width W . A0 ‚àà R is the area of the ROI on the ground
plane in real world and dc ‚àà R is the required minimum
physical distance. c1 is a binary control signal for sending
a non-intrusive audio-visual cue if any inter-pedestrian distance is less than dc . c2 is another binary control signal for
controlling the entrance to the ROI to prevent overcrowding. Overcrowding is detected with our novel definition of
critical social density œÅc . œÅc ensures social distancing violation occurrence probability stays lower than U0 . U0 is an
empirically decided threshold such as 0.05.
Problem 1. Given S, we are interested in finding a
list of pedestrian pose vectors P = (p1 , p2 , ¬∑ ¬∑ ¬∑ , pn ),
p ‚àà R2 , in real-world coordinates on the ground plane
and a corresponding list of inter-pedestrian distances D =
(d1,2 , ¬∑ ¬∑ ¬∑ , d1,n , d2,3 , ¬∑ ¬∑ ¬∑ , d2,n , ¬∑ ¬∑ ¬∑ , dn‚àí1,n ), d ‚àà R+ . n is
the number of pedestrians in the ROI. Also, we are interested in finding a critical social density value œÅc . œÅc should
ensure the probability p(d > dc |œÅ < œÅc ) stays over 1 ‚àí U0 ,
where we define social density as œÅ := n/A0 .
Once Problem 1 is solved, the following control algorithm can be used to warn/advise the population in the ROI.
Algorithm 1. If d ‚â§ dc , then a non-intrusive audiovisual cue is activated with setting the control signal c1 = 1,
otherwise c1 = 0. In addition, If œÅ > œÅc , then entering the
area is not advised with setting c2 = 1, otherwise c2 = 0.
Our solution to Problem 1 starts below.

recommended value. A similar system [32] was deployed to
monitor worker activity and send real-time voice alerts in a
manufacturing plant. In addition to surveillance cameras,
LiDAR based [33] and stereo camera based [34] systems
were also proposed, which demonstrated that different types
of sensors besides surveillance cameras can also help.
The above systems are interesting, but recording data
and sending intrusive alerts might be unacceptable by some
people. On the contrary, we propose a non-intrusive warning system with softer omnidirectional audio-visual cues.
In addition, our system evaluates critical social density and
modulates inflow into a region-of-interest.

3. Preliminaries
Object detection with deep learning. Object detection in the image domain is a fundamental computer vision problem. The goal is to detect instances of semantic
objects that belong to certain classes, e.g., humans, cars,
buildings. Recently, object detection benchmarks have been
dominated by deep convolutional neural networks (CNNs)
models [15, 16, 9, 17, 18, 19, 20, 10, 21, 22]. For example,
top scores on MS COCO [30], which has over 123K images
and 896K objects in the training-validation set and 80K images in the testing set with 80 categories, have almost doubled thanks to the recent breakthrough in deep CNNs.
These models are usually trained by supervised learning,
with techniques like data augmentation [35] to increase the
variety of data.
Model Generalization. The generalization capability [36, 37] of the state-of-the-art is good enough for deploying pre-trained models to new environments. For 2D object
detection, even with different camera models, angles, and illumination conditions, pre-trained models can still achieve
good performance.
Therefore, a pre-trained state-of-the-art deep learning
based pedestrian detector can be directly utilized for the task
of social distancing monitoring.

4.2. Pedestrian detection in the image domain
First, pedestrians are detected in the image domain with
a deep CNN model trained on a real-world dataset:
{Ti }k = fcnn (I).

(1)

fcnn : I ‚Üí {Ti }n maps an image I into n tuples Ti =
(li bi , si ), ‚àÄi ‚àà {1, 2, ¬∑ ¬∑ ¬∑ , n}. n is the number of detected
objects. li ‚àà L is the object class label, where L, the set of
object labels, is defined in fcnn . bi = (bi,1 , bi,2 , bi,3 , bi,4 )
is the associated bounding box (BB) with four corners.
bi,j = (xi,j , yi,j ) gives pixel indices in the image domain.
The second sub-index j indicates the corners at top-left, topright, bottom-left, and bottom-right respectively. si is the
corresponding detection score. Implementation details of
fcnn is given in Section 5.1.
We are only interested in the case of l = ‚Äòperson‚Äô. We
define p0i , the pixel pose vector of person i, with using the
middle point of the bottom edge of the BB:

4. Method
We propose to use a fixed monocular camera to detect individuals in a region of interest (ROI) and measure the interpersonal distances in real time without data recording. The
proposed system sends a non-intrusive audio-visual cue to
warn the crowd if any social distancing breach is detected.
Furthermore, we define a novel critical social density metric
and propose to advise not entering into the ROI if the density is higher than this value. The overview of our approach
is given in Figure 1, and the formal description starts below.

p0i :=

(bi,3 + bi,4 )
.
2

(2)

4.1. Problem formulation

4.3. Image to real-world mapping

We define a scene at time t as a 6-tuple S =
(I, A0 , dc , c1 , c2 , U0 ), where I ‚àà RH√óW √ó3 is an RGB im-

The next step is obtaining the second mapping function
h : p0 ‚Üí p. h is an inverse perspective transformation
3

probability stays below U0 . It should be noted that a trivial
solution of œÅc = 0 will ensure v = 0, but it has no practical
use. Instead, we want to find the maximum critical social
density œÅc that can still be considered safe.
To find œÅc , we propose to conduct a simple linear regression using social density œÅ as the independent variable and
the total number of violations v as the dependent variable:
v = Œ≤0 + Œ≤1 œÅ + ,

where Œ≤ = [Œ≤0 , Œ≤1 ] is the regression parameter vector and
 is the error term which is assumed to be normal. The
regression model is fitted with the ordinary least squares
method. Fitting this model requires training data. However,
once the model is learned, data is not required anymore.
After deployment, the surveillance system operates without
recording data.
Once the model is fitted, critical social density is identified as:
œÅc = œÅpred
(7)
lb ,

Figure 2. Obtaining critical social density œÅc . Keeping œÅ under
œÅc will drive the number of social distancing violations v towards
zero with the linear regression assumption.

function that maps p0 in image coordinates to p ‚àà R2 in
real-world coordinates. p is in 2D bird‚Äôs-eye-view (BEV)
coordinates by assuming the ground plane z = 0. We use
the following well-known inverse homography transformation [38] for this task:
pbev = M‚àí1 pim ,

where œÅpred
lb is the lower bound of the 95% prediction interpred pred
val (œÅlb , œÅub ) at v = 0, as illustrated in Figure 2.
Keeping œÅ under œÅc will keep the probability of social
distancing violation occurrence near zero with the linear regression assumption.

(3)

where M ‚àà R3√ó3 is a transformation matrix describing
the rotation and translation from world coordinates to image coordinates. pim = [p0x , p0y , 1] is the homogeneous
representation of p0 = [p0x , p0y ] in image coordinates, and
bev
pbev = [pbev
x , py , 1] is the homogeneous representation of
the mapped pose vector.
The world pose vector p is derived from pbev with p =
bev bev
[px , py ].

5. Experiments
We conducted 3 case studies to evaluate the proposed
method. Each case utilizes a different pedestrian crowd
dataset. They are Oxford Town Center Dataset (an urban street) [39], Mall Dataset (an indoor mall) [40], and
Train Station Dataset (New York City Grand Central Terminal) [41]. Table 1 shows detailed information about these
datasets.

4.4. Social distancing detection
After getting P = (p1 , p2 , ¬∑ ¬∑ ¬∑ , pn ) in real-world coordinates, obtaining the corresponding list of inter-pedestrian
distances D is straightforward. The distance di,j for pedestrians i and j is obtained by taking the Euclidean distance
between their pose vectors:
di,j = kpi ‚àí pj k.

5.1. Implementation details
The first step was finding the perspective transformation matrix M for each dataset. For Oxford Town Center
Dataset, we directly used the transformation matrix available on its official website. For Train Station Dataset, we
found the floor plan of NYC Grand Central Terminal and
measured the exact distances among some key points that
were used for calculating the perspective transformation.
For Mall Dataset, we first estimated the size of a reference
object in the image by comparing it with the width of detected pedestrians and then utilized the key points of the
reference object to calculate the perspective transformation.
The second step was applying the pedestrian detector on
each dataset. The experiments were conducted on a regular
PC with an Intel Core i7-4790 CPU, 32GB RAM, and an
Nvidia GeForce GTX 1070Ti GPU running Ubuntu 16.04
LTS 64-bit operating system. Once the pedestrians were

(4)

And the total number of social distancing violations v in
a scene can be calculated by:
v=

n X
n
X

I(di,j ),

(6)

(5)

i=1 j=1
j6=i

where I(di,j ) = 1 if di,j < dc , otherwise 0.

4.5. Critical social density estimation
Finally, we want to find a critical social density value œÅc
that can ensure the social distancing violation occurrence
4

Figure 3. Illustration of pedestrian detection using Faster R-CNN [9] and the corresponding social distancing.

detected, their positions were converted from the image coordinates into the real-world coordinates.
The last step was conducting social distancing monitoring and finding the critical density œÅc . Only the pedestrians
within the ROI were considered. The statistics of the social
density œÅ, the inter-pedestrian distances di,j , and the number of violations v were recorded over time. The analysis of
statistics is described in the following section.

shows the pedestrian detection results using Faster RCNN [9] and the corresponding social distancing in world
coordinates. The detector performances are given in Table 2. As can be seen in the table, both detectors achieved
real-time performance. In terms of detection accuracy, we
provide the results of MS COCO dataset from the original
works [9, 10].

6.2. Social Distancing Monitoring

6. Results

For pedestrian i, the closest physical distance is dmin
=
i
min(di,j ), ‚àÄj 6= i ‚àà {1, 2, ¬∑ ¬∑ ¬∑ n}. Based on dmin
,
we
i
further calculated two metrics for social distancing monitoring: the minimum closest physical distance dmin =

6.1. Pedestrian Detection
We experimented with two different deep CNN based
object detectors: Faster R-CNN and YOLOv4. Figure 3
5

Figure 4. Linear regression (red line) of the social density œÅ versus number of social distancing violations v data. Green lines indicate the
prediction intervals. The critical social densities œÅc are the x-intercepts of the regression lines.

min(dmin
.n} and the average closest physi ), ‚àÄi ‚àà {1, 2, ¬∑ ¬∑ ¬∑P
n
ical distance davg = n1 i=1 dmin
i . Figure 7 shows the
change of dmin and davg as time evolves. They are compared with the social density œÅ. From the figure we can see
that when œÅ is relatively low, both the dmin and davg are relatively high, for example, t = 85s in Train Station Dataset,
t = 80s in Mall Dataset, and t = 100s in Oxford Town
Center Dataset. This shows a clear negative correlation between œÅ and davg . The negative correlation is further visualized as 2D histograms in Figure 5.

Dataset
Oxford Town Ctr.
Mall
Train Station

FPS
25
‚àº1
25

Resolution
1920 √ó 1080
640 √ó 480
720 √ó 480

Duration
5 mins
33 mins
33 mins

Table 1. Information of each pedestrian dataset.

Method
Faster R-CNN [9]
YOLOv4 [10]

6.3. Critical Social Density

mAP (%)
42.1-42.7
41.2-43.5

Inference Time (sec)
0.145 / 0.116 / 0.108
0.048 / 0.050 / 0.050

Table 2. The real-time performance of pedestrian detectors. The
inference time reports the mean inference time for Oxford Town
Center / Train Station / Mall datasets, respectively.

To find the critical density œÅc , we first investigated the
relationship between the number of social distancing violations v and the social density œÅ in 2D histograms, as shown
in Figure 6. As can be seen in the figure, v increases with
an increase in œÅ, which indicates a linear relationship with
a positive correlation.
Then, we conducted the simple linear regression, using
the regression model of equation (6), on the data points of v
versus œÅ. The skewness values of œÅ for Oxford Town Center
Dataset, Mall Dataset, and Train Station Dataset are 0.25,
0.16, and -0.07, respectively, indicating the distributions of
œÅ are symmetric. This satisfies the normality assumption of
the error term in linear regression. The regression result is
displayed in figure 4. The critical density œÅc was identified
as the lower bound of the prediction interval at v = 0.
Table 3 summaries the identified critical densities œÅc as
well as the intercepts Œ≤0 of the regression models. The
obtained critical density values for all datasets are similar.
They also follow the patterns of the data points as illustrated
in Figure 4. This verified the effectiveness of our method.

Dataset
Oxford Town Ctr.
Mall
Train Station

Intercept Œ≤0
0.0233
0.0396
0.0403

Critical Density œÅc
0.0104
0.0123
0.0314

Table 3. Critical social density of each dataset. The critical density
was identified as the lower bound of the prediction interval at the
number of social distancing violations v = 0.

the proposed critical social density to avoid overcrowding
by modulating inflow to the ROI. The proposed method was
verified using 3 different pedestrian crowd datasets.
There are some missing detections in the Train Station
Dataset, as in some areas the pedestrian density is extremely
high and occlusion happens. However, after some qualitative analysis, we concluded that most of the pedestrians
were captured and the idea of finding critical social density
is still valid.
Pedestrians who belong to a group were not considered
as a group in the current work, which can be a future direction. Nevertheless, one may argue that even individuals

7. Conclusion
This work proposed an AI and monocular camera based
real-time system to monitor the social distancing. We use
6

Figure 5. 2D histograms of the social density œÅ versus the average closest physical distance davg .

Figure 6. 2D histograms of the social density œÅ versus the number of social distancing violations v. From the histograms we can see a
linear relationship with positive correlation.

who have close relationships should still try to practice social distancing in public areas.

[6] A. B. Chan, Z.-S. J. Liang, and N. Vasconcelos, ‚ÄúPrivacy preserving crowd monitoring: Counting people without people
models or tracking,‚Äù in 2008 IEEE Conference on Computer
Vision and Pattern Recognition. IEEE, 2008, pp. 1‚Äì7.

References

[7] F. Z. Qureshi, ‚ÄúObject-video streams for preserving privacy
in video surveillance,‚Äù in 2009 Sixth IEEE International
Conference on Advanced Video and Signal Based Surveillance. IEEE, 2009, pp. 442‚Äì447.

[1] C. Courtemanche, J. Garuccio, A. Le, J. Pinkston, and
A. Yelowitz, ‚ÄúStrong social distancing measures in the united
states reduced the covid-19 growth rate: Study evaluates the
impact of social distancing measures on the growth rate of
confirmed covid-19 cases across the united states.‚Äù Health
Affairs, pp. 10‚Äì1377, 2020.

[8] S. Park and M. M. Trivedi, ‚ÄúA track-based human movement
analysis and privacy protection system adaptive to environmental contexts,‚Äù in IEEE Conference on Advanced Video
and Signal Based Surveillance, 2005. IEEE, 2005, pp. 171‚Äì
176.

[2] C. T. Nguyen, Y. M. Saputra, N. Van Huynh, N.-T. Nguyen,
T. V. Khoa, B. M. Tuan, D. N. Nguyen, D. T. Hoang, T. X.
Vu, E. Dutkiewicz et al., ‚ÄúEnabling and emerging technologies for social distancing: A comprehensive survey,‚Äù arXiv
preprint arXiv:2005.02816, 2020.

[9] S. Ren, K. He, R. Girshick, and J. Sun, ‚ÄúFaster r-cnn: Towards real-time object detection with region proposal networks,‚Äù in Advances in neural information processing systems, 2015, pp. 91‚Äì99.

[3] S. Agarwal, N. S. Punn, S. K. Sonbhadra, P. Nagabhushan,
K. Pandian, and P. Saxena, ‚ÄúUnleashing the power of disruptive and emerging technologies amid covid 2019: A detailed
review,‚Äù arXiv preprint arXiv:2005.11507, 2020.

[10] A. Bochkovskiy, C.-Y. Wang, and H.-Y. M. Liao, ‚ÄúYolov4:
Optimal speed and accuracy of object detection,‚Äù arXiv
preprint arXiv:2004.10934, 2020.

[4] N. S. Punn, S. K. Sonbhadra, and S. Agarwal, ‚ÄúMonitoring
covid-19 social distancing with person detection and tracking via fine-tuned yolo v3 and deepsort techniques,‚Äù arXiv
preprint arXiv:2005.01385, 2020.

[11] D. S. Hui, E. I. Azhar, T. A. Madani, F. Ntoumi, R. Kock,
O. Dar, G. Ippolito, T. D. Mchugh, Z. A. Memish, C. Drosten
et al., ‚ÄúThe continuing 2019-ncov epidemic threat of novel
coronaviruses to global healththe latest 2019 novel coronavirus outbreak in wuhan, china,‚Äù International Journal of
Infectious Diseases, vol. 91, pp. 264‚Äì266, 2020.

[5] M. Cristani, A. Del Bue, V. Murino, F. Setti, and A. Vinciarelli, ‚ÄúThe visual social distancing problem,‚Äù arXiv preprint
arXiv:2005.04813, 2020.

7

Figure 7. The change of minimum closest physical distance dmin , average closest physical distance davg , and the social density œÅ over time.

[12] M. Greenstone and V. Nigam, ‚ÄúDoes social distancing matter?‚Äù University of Chicago, Becker Friedman Institute for
Economics Working Paper, no. 2020-26, 2020.

[16] R. Girshick, ‚ÄúFast r-cnn,‚Äù in Proceedings of the IEEE international conference on computer vision, 2015, pp. 1440‚Äì
1448.

[13] Z. Zou, Z. Shi, Y. Guo, and J. Ye, ‚ÄúObject detection in 20
years: A survey,‚Äù arXiv preprint arXiv:1905.05055, 2019.

[17] J. Dai, Y. Li, K. He, and J. Sun, ‚ÄúR-fcn: Object detection via
region-based fully convolutional networks,‚Äù in Advances in
neural information processing systems, 2016, pp. 379‚Äì387.

[14] Z.-Q. Zhao, P. Zheng, S.-t. Xu, and X. Wu, ‚ÄúObject detection
with deep learning: A review,‚Äù IEEE transactions on neural
networks and learning systems, vol. 30, no. 11, pp. 3212‚Äì
3232, 2019.

[18] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, ‚ÄúYou
only look once: Unified, real-time object detection,‚Äù in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 779‚Äì788.

[15] R. Girshick, J. Donahue, T. Darrell, and J. Malik, ‚ÄúRich feature hierarchies for accurate object detection and semantic
segmentation,‚Äù in Proceedings of the IEEE conference on
computer vision and pattern recognition, 2014, pp. 580‚Äì587.

[19] J. Redmon and A. Farhadi, ‚ÄúYolo9000: better, faster,
stronger,‚Äù in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 7263‚Äì7271.

8

[34] StereoLabs, Using 3D Cameras to Monitor Social Distancing, 2020 (accessed June 20, 2020). [Online]. Available: https://www.stereolabs.com/blog/using-3d-camerasto-monitor-social-distancing/

[20] ‚Äî‚Äî, ‚ÄúYolov3: An incremental improvement,‚Äù arXiv
preprint arXiv:1804.02767, 2018.
[21] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y.
Fu, and A. C. Berg, ‚ÄúSsd: Single shot multibox detector,‚Äù in
European conference on computer vision. Springer, 2016,
pp. 21‚Äì37.

[35] B. Zoph, E. D. Cubuk, G. Ghiasi, T.-Y. Lin, J. Shlens, and
Q. V. Le, ‚ÄúLearning data augmentation strategies for object
detection,‚Äù arXiv preprint arXiv:1906.11172, 2019.

[22] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. DollaÃÅr, ‚ÄúFocal loss for dense object detection,‚Äù in Proceedings of the
IEEE international conference on computer vision, 2017, pp.
2980‚Äì2988.

[36] C. Zhang, S. Bengio, M. Hardt, B. Recht, and O. Vinyals,
‚ÄúUnderstanding deep learning requires rethinking generalization,‚Äù arXiv preprint arXiv:1611.03530, 2016.
[37] J. Liu, G. Jiang, Y. Bai, T. Chen, and H. Wang, ‚ÄúUnderstanding why neural networks generalize well through gsnr of parameters,‚Äù arXiv preprint arXiv:2001.07384, 2020.

[23] M. Tan, R. Pang, and Q. V. Le, ‚ÄúEfficientdet: Scalable and
efficient object detection,‚Äù in Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition,
2020, pp. 10 781‚Äì10 790.

[38] D. A. Forsyth and J. Ponce, Computer vision: a modern approach. Prentice Hall Professional Technical Reference,
2002.

[24] H. Law and J. Deng, ‚ÄúCornernet: Detecting objects as paired
keypoints,‚Äù in Proceedings of the European Conference on
Computer Vision (ECCV), 2018, pp. 734‚Äì750.

[39] B. Benfold and I. Reid, ‚ÄúStable multi-target tracking in realtime surveillance video,‚Äù in CVPR 2011. IEEE, 2011, pp.
3457‚Äì3464.

[25] K. Duan, S. Bai, L. Xie, H. Qi, Q. Huang, and Q. Tian, ‚ÄúCenternet: Keypoint triplets for object detection,‚Äù in Proceedings
of the IEEE International Conference on Computer Vision,
2019, pp. 6569‚Äì6578.

[40] K. Chen, C. C. Loy, S. Gong, and T. Xiang, ‚ÄúFeature mining
for localised crowd counting.‚Äù in BMVC, vol. 1, no. 2, 2012,
p. 3.

[26] Z. Tian, C. Shen, H. Chen, and T. He, ‚ÄúFcos: Fully convolutional one-stage object detection,‚Äù in Proceedings of the
IEEE international conference on computer vision, 2019, pp.
9627‚Äì9636.

[41] B. Zhou, X. Wang, and X. Tang, ‚ÄúUnderstanding collective crowd behaviors: Learning a mixture model of dynamic
pedestrian-agents,‚Äù in 2012 IEEE Conference on Computer
Vision and Pattern Recognition. IEEE, 2012, pp. 2871‚Äì
2878.

[27] Z. Yang, S. Liu, H. Hu, L. Wang, and S. Lin, ‚ÄúReppoints:
Point set representation for object detection,‚Äù in Proceedings
of the IEEE International Conference on Computer Vision,
2019, pp. 9657‚Äì9666.
[28] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and
A. Zisserman, ‚ÄúThe pascal visual object classes (voc) challenge,‚Äù International journal of computer vision, vol. 88,
no. 2, pp. 303‚Äì338, 2010.
[29] M. Everingham, S. A. Eslami, L. Van Gool, C. K. Williams,
J. Winn, and A. Zisserman, ‚ÄúThe pascal visual object classes
challenge: A retrospective,‚Äù International journal of computer vision, vol. 111, no. 1, pp. 98‚Äì136, 2015.
[30] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. DollaÃÅr, and C. L. Zitnick, ‚ÄúMicrosoft coco: Common objects in context,‚Äù in European conference on computer vision. Springer, 2014, pp. 740‚Äì755.
[31] LandingAI, Landing AI Creates an AI Tool to Help
Customers Monitor Social Distancing in the Workplace,
2020 (accessed May 3, 2020). [Online]. Available:
https://landing.ai/landing-ai-creates-an-ai-tool-to-helpcustomers-monitor-social-distancing-in-the-workplace/
[32] P. Khandelwal, A. Khandelwal, and S. Agarwal, ‚ÄúUsing computer vision to enhance safety of workforce in
manufacturing in a post covid world,‚Äù arXiv preprint
arXiv:2005.05287, 2020.
[33] J. Hall, Social Distance Monitoring, 2020 (accessed June
1, 2020). [Online]. Available: https://levelfivesupplies.com/
social-distance-monitoring/

9

