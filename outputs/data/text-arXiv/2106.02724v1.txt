Statistical summaries of unlabelled evolutionary trees and ranked
hierarchical clustering trees
Rajanala Samyak1 and Julia A. Palacios1,2,*
1

arXiv:2106.02724v1 [stat.ME] 4 Jun 2021

Department of Statistics, Stanford University, Stanford, CA 94305, USA
2
Department of Biomedical Data Science, Stanford Medicine, Stanford, CA 94305, USA
*
Corresponding author email: juliapr@stanford.edu

June 8, 2021

Abstract
Rooted and ranked binary trees are mathematical objects of great importance used to model hierarchical data and evolutionary relationships with applications in many fields including evolutionary
biology and genetic epidemiology. Bayesian phylogenetic inference usually explore the posterior distribution of trees via Markov Chain Monte Carlo methods, however assessing uncertainty and summarizing
distributions or samples of such trees remains challenging. While labelled phylogenetic trees have been
extensively studied, relatively less literature exists for unlabelled trees which are increasingly useful, for
example when one seeks to summarize samples of trees obtained with different methods, or from different
samples and environments, and wishes to assess stability and generalizability of these summaries. In our
paper, we exploit recently proposed distance metrics of unlabelled ranked binary trees and unlabelled
ranked genealogies (equipped with branch lengths) to define the FreÃÅchet mean and variance as summaries
of these tree distributions. We provide an efficient combinatorial optimization algorithm for computing
the FreÃÅchet mean from a sample of or distribution on unlabelled ranked tree shapes and unlabelled ranked
genealogies. We show the applicability of our summary statistics for studying popular tree distributions
and for comparing the SARS-CoV-2 evolutionary trees across different locations during the COVID-19
epidemic in 2020.

Keywords: Binary trees; Combinatorial optimization; Evolutionary trees; FreÃÅchet; Summarizing trees;
Unlabelled trees.

1

Introduction

Binary trees are used to represent the ancestral relationships of samples in evolving populations and to
model other type of dependent data that is the result of tree-like structures, such as transmission trees. In
phylogenetics, population genetics, and cell biology, evolutionary trees are inferred from observed molecular

1

sequence data or from observed evolutionary traits in a sample of individuals from a population. These
individuals can be viral sequences from infected hosts (viral phylodynamics), species (phylogenetics), individuals from a single species (population genetics), or cells (cancer evolution). The estimated tree describes
the inferred ancestral relationships of the samples and provides information about the past evolutionary
dynamics of the sample‚Äôs population. For example, in the context of viral phylodynamics, the tree provides
information about the past transmission history and pathogenesis [Volz et al., 2013].

(A)

2
3
4
5

6

(B)
u1
u2
u3
u4
u5

7
8

u6
u7
u8

2
3

4
5

6
7

8

(C)
u1
u2
u3
u4
u5 6
u6
u7
u8
u9

2
3

4
5

7

8

u10

Figure 1: Tree examples. (A) isochronous ranked tree shape (topology only); (B) isochronous ranked
genealogies (ranked tree shape and branching times); and (C) heterochronous ranked genealogy with different
sampling times (red dashed lines).

Distance-based summaries of labelled and unranked tree structures have been extensively studied such as
phylogenetic trees [Hillis et al., 2005, Chakerian and Holmes, 2012, Benner and BacÃåaÃÅk, 2013, Willis and Bell,
2018, Brown and Owen, 2019], and hierarchical clustering trees such as CART [Breiman, 1984] in the last
few decades. These summaries rely on metrics such as the BHV distance [Billera et al., 2001] defined on tree
space. Kuhner and Yamato [2014] presents a comparison of different distances on such space. In the case of
labelled trees, it is usually assumed that all sampled trees have the same set of leaves (labels). Other type of
summaries of labelled and unranked trees include bootstrap confidence levels [Felsenstein, 1985, Efron et al.,
1996], and maximum clade credibility trees [Heled and Bouckaert, 2013, O‚ÄôReilly and Donoghue, 2018].
In this article, we are interested in summarizing different tree structures, namely those that are ranked and
unlabelled.These trees are useful in the study of the ancestral relationships of a sample of objects which are
exchangeable. One potential area of application is in the study of cancer evolution where the tree represents
the evolutionary history of many cells in a patient‚Äôs tumor. We may want to summarize many such trees,
each tree inferred from a different patient, in order to find a ‚Äúrepresentative‚Äù tree and quantify how much
variation or heterogeneity is present across patients with the same type of cancer or across different types
of cancer. Similar type of questions have been studied assuming a coarser type of tree structure [Govek
et al., 2018]. Another application is in infectious disease transmission, where we study the mutation history
of different viral sequences. Here, we compute summary statistics from samples of SARS-CoV-2 trees using
RNA sequences available in the data repository GISAID between February and September 2020.
Recent mathematical results concerning distance metrics on the space of ranked evolutionary trees without
leaf labels enable quantitative comparisons of evolutionary trees of different sets of organisms living at
2

different geographic locations and different time periods. These metrics have been used for comparing
posterior distributions (and testing for distribution equality) of trees of human influenza A virus from two
different geographic regions; for summarizing empirical distributions via medoids; and for defining credible
sets of posterior distributions [Kim et al., 2019].
In this article, we use the previously defined distance metrics on unlabelled ranked evolutionary trees to
understand distributional properties of some popular tree models used in Biology and to summarize samples
of trees. Tree samples can be either obtained from the posterior distribution for a given sample of molecular
sequences such as those obtained with BEAST [Suchard et al., 2018], or trees independently obtained in
different studies.
A recently proposed Bayesian method for inferring evolutionary parameters from molecular data is based
on the Tajima coalescent for unlabelled ranked evolutionary trees [Palacios et al., 2019, Cappello et al.,
2020]. This method approximates the posterior distribution of model parameters and evolutionary trees by
Markov chain Monte Carlo methods (MCMC). While summarizing real-valued parameters is straightforward,
summarizing a posterior sample of unlabelled ranked evolutionary trees is more challenging. As discussed
above, methods for summarizing posterior samples of labelled evolutionary trees exist [Heled and Bouckaert,
2013, Benner and BacÃåaÃÅk, 2013, Brown and Owen, 2019]. However, we are not aware of methods applicable
for summarizing posterior samples of unlabelled ranked trees.
To summarize samples and populations of unlabelled ranked evolutionary trees, we define the sample and
population FreÃÅchet means and variances in terms of the recently proposed d1 and d2 distances. We compare
these summaries to others measures of centrality and dispersion on the same space. We show that finding
the FreÃÅchet mean consists in finding the solution of an integer programming problem. However, the search
space of ranked evolutionary trees grows super-exponentially in n, the number of leaves, which makes the
problem of finding the FreÃÅchet mean computationally challenging for large values of n. For large n, we rely
on stochastic combinatorial optimization, and propose a simulated annealing algorithm for estimating the
FreÃÅchet mean in the case of both isochronous and heterochronous ranked tree shapes. The time complexity
for computation of these trees is independent of N , the number of trees, and instead only depends on n,
the number of leaves in each tree. The advantage of our approach is that the output is not restricted to the
sample, and can be any element of the space.
We also introduce exploratory tools for the space of unlabelled ranked trees such as a total ordering, a
Markov chain on the space, and credible balls. These are used in various analyses in this paper but also can
also merit separate study.
In Section 2 we formally define the class of evolutionary trees considered, show how these trees are in
bijection with a particular set of triangular matrices of integers, and show how to compute the distance
metrics proposed in [Kim et al., 2019]. Section 3 introduces the FreÃÅchet mean as a summary of location and
methods for computing and approximating it, including a simulated annealing algorithm using a Markov
chain for state space exploration. In Section 4 we describe the FreÃÅchet variance as a statistic of spread for a
given sample or distribution. In Section 5 we compare various summary statistics of theoretical distributions
as well as empirical simulated distributions. As a real data example, we analyse the posterior distributions
of evolutionary trees inferred from SARS-CoV-2 molecular sequences from the states of California, Texas,

3

Florida, and Washington. We obtain FreÃÅchet mean trees for different samples and display multidimensional
scaling plots to visualize intra-state and inter-state variability. In Section 7, we conclude and discuss future
directions.
We have developed an R package, fmatrix (github.com/RSamyak/fmatrix), which implements the various
methods discussed in this paper. The package is compatible with phylodyn [Karcher et al., 2017], an R
package for phylodynamic simulation and inference, and ape [Paradis and Schliep, 2019], an R package to
handle phylogenetic trees.

2

Preliminaries

Ranked unlabelled trees or ranked tree shapes are rooted binary trees, with an increasing ordering of the
interior nodes. They are unlabelled in the sense that the external nodes (leaves) are unlabelled. We however
rank the internal nodes, starting at the root with label 2 (Figure 1 (A)). A ranked unlabelled tree, additionally
equipped with the vector of branching times is called a ranked genealogy (Figure 1 (B)).
A ranked unlabelled tree (or ranked genealogy) is called isochronous if all the leaves are sampled at the
same time, usually assumed to be sampled at time 0 (Figure 1 (A-B)). In applications of rapidly evolving
pathogens such as Influenza A virus, molecular sequences (leaves) are sampled at different times (Figure 1
(C)) and these trees are called heterochronous.
Recently, Kim et al. [2019] proposed metrics on the space of ranked tree shapes and ranked genealogies for
comparing and assessing differences between tree distributions. The utility of the metrics was demonstrated
in a series of simulation studies to assess differences between the posterior distributions of ranked genealogies
of Influenza A virus obtained from two different geographic regions. The proposed metrics rely on a unique
representation of ranked tree shapes as triangular matrices of integers, called F-matrices. The distances
between two ranked unlabelled trees are then calculated as L1 and L2 distances between these matrices
(Eqs. 1 and 2). A formal definition of F-matrices is given in Theorem 1.
For a given isochronous ranked tree shape with n leaves, we denote the time of a branching event at each
node i by ui‚àí1 and the time interval between the two subsequent nodes i and i + 1 by Ii = (ui‚àí1 , ui ). For
convenience, we assign un = 0 at the leaves. An F-matrix representation of a ranked tree shape with n leaves
is an (n ‚àí 1) √ó (n ‚àí 1) triangular matrix of non-negative integers. The diagonal elements of the F-matrix
indicate the number of branches at each time interval. The off-diagonal element Fi,j , 2 ‚â§ j < i ‚â§ n ‚àí 1,
represents the number of branches extant at Ij = (uj+1 , uj ) that do not bifurcate during the interval
(ui+1 , uj ). Figure 2 shows all ranked tree shapes with 5 leaves (first row) and their corresponding F-matrix
encodings (second row).

4

Figure 2: All ranked tree shapes with n = 5 leaves. The second row shows the corresponding Fmatrix representation of the ranked tree shape of the first row, and the third row shows their corresponding
functional code representations (see section D of the appendix).

Theorem 1. The space of ranked tree shapes with n leaves Tn is in bijection with the space Fn of (n ‚àí
1) √ó (n ‚àí 1) F-matrices, which are lower triangular square matrices of non-negative integers that obey the
following constraints:
1. The diagonal elements are Fi,i = i + 1 for i = 1, . . . , n ‚àí 1 and the subdiagonal elements are Fi+1,i = i for
i = 1, . . . , n ‚àí 2.
2. The elements Fi,1 , i = 3, . . . , n ‚àí 1, in the first column satisfy max{0, Fi‚àí1,1 ‚àí 1} ‚â§ Fi,1 ‚â§ Fi‚àí1,1 .
3. All the other elements Fi,k , i = 4, . . . , n ‚àí 1 and k = 2, . . . , i ‚àí 2 satisfy the following inequalities:
max{0, Fi,k‚àí1 } ‚â§ Fi,k
Fi‚àí1,k ‚àí 1 ‚â§ Fi,k ‚â§ Fi‚àí1,k
Fi,k‚àí1 + Fi‚àí1,k ‚àí Fi‚àí1,k‚àí1 ‚àí 1 ‚â§ Fi,k ‚â§ Fi,k‚àí1 + Fi‚àí1,k ‚àí Fi‚àí1,k‚àí1
The proof is in the appendix, in Section B.
Given two ranked tree shapes y1 and y2 ‚àà Tn , with corresponding F-matrices F1 and F2 , d1 and d2 are the
L1 and the L2 distances on the space of matrices, restricted to Fn , the class of F-matrices, that is
d1 (y1 , y2 ) := d1 (F1 , F2 ) =

X

|(F1 )ij ‚àí (F2 )ij |

(1)

i,j

and
d2 (y1 , y2 ) := d2 (F1 , F2 ) =

sX

2

((F1 )ij ‚àí (F2 )ij )

i,j

For ranked genealogies G1 and G2 ‚àà Gn , with corresponding F1 and F2 , F-matrices
d1 (G1 , G2 ) :=

X

|(F1 )ij (W1 )ij ‚àí (F2 )ij (W2 )ij |,

i,j

5

(2)

and
d2 (G1 , G2 ) :=

sX

((F1 )ij (W1 )ij ‚àí (F2 )ij (W2 )ij )2 ,

i,j

where W1 and W2 are weight matrices constructed using the respective branching event times uk = (uk,n , uk,n‚àí1 , . . . , uk,1 )
of the k-th tree, k = 1, 2 with (Wk )ij := |uk,j ‚àí uk,i+1 | (Figure 1(B)).
For defining a distance on the space of heterochronous ranked tree shapes or genealogies (Figure 1(C)),
Kim et al. [2019] propose supplementing the F-matrix with additional rows for sampling events. The heterochronous d1 and d2 distances are then computed analogously to the isochronous distances, as the L1 and
L2 distances between the extended F-matrices of the same size, as detailed in Section 3 of the appendix of
Kim et al. [2019]. For improving computational efficiency when computing pairwise distances among a large
number of trees, we modify the distance slightly and consider all trees together when adding additional rows
to the F-matrix. Further details can be found in Section A in the appendix.

3

Central summaries

Let y1 , . . . , ym ‚àà Tn be m ranked tree shapes with n leaves independently drawn from a common probability
distribution. We are interested in summarizing such samples and identifying a representative ranked tree
shape of the sample. Similarly, given a probability distribution over the space of ranked tree shapes, we are
interested in knowing what is the ‚Äúexpected‚Äù tree of that distribution.
In evolutionary biology applications, trees are usually not directly observed. Instead, researchers either find a
single tree via maximum likelihood estimation or maximum parsimony [Felsenstein, 2004], or generate a large
sample of trees from the posterior distribution via Markov chain Monte Carlo methods [Suchard et al., 2018].
In the latter case of Bayesian inference, it is not clear how to best summarize a sample of ranked unlabelled
trees and define a representative ‚Äúmean‚Äù tree as a measure of centrality. A decision theoretic approach is to
use the d1 and the d2 distance metrics to define the absolute and the squared error loss functions. Minimizing
the expected posterior losses gives us the posterior median and posterior mean respectively. However, the
value that minimizes the expected posterior loss in Euclidean space does not usually correspond to a tree.
In particular for d2 , the Euclidean mean of the F-matrices may not even be a matrix of integers. However,
we can restrict the minimizer to be an element of the space. The resulting summary is the sample posterior
FreÃÅchet mean. Similarly, in applications when a random sample of trees or a population of trees is available,
the FreÃÅchet mean would be the tree in the space that minimizes the empirical mean loss and the expected
loss respectively.
Current practices for summarizing labelled trees include reporting a majority-rule consensus tree (MRC), a
maximum clade credibility (MCC), and a median tree based on metrics on labelled trees [Benner and BacÃåaÃÅk,
2013, Brown and Owen, 2019]. The MRC is obtained by choosing partitions with probability greater than 0.5
from the list of observed partitions and it is usually annotated with marginal probabilities of each partition
as a measure of uncertainty [Cranston and Rannala, 2007]. The MCC tree is the tree with the maximum
product of clade probabilities and it is arguably, the most used central summary of labelled trees.
The concept of consensus partition is not longer applicable for ranked tree shapes. Instead, we rely on the

6

proposed distances on ranked tree shapes to define the FreÃÅchet mean in the same line as the median tree for
labelled trees. The FreÃÅchet mean is the tree in the space that has the minimum expected squared distance
to a tree in the space, and hence it provides a natural notion of central tree. We extend the notion to ranked
genealogies, including heterochronous genealogies.

3.1

The FreÃÅchet mean

We first consider the metric spaces (Tn , d), where d is either d1 or d2 , and let ¬µ denote a finite probability
mass function on Tn , then the barycenter of ¬µ, also called a FreÃÅchet mean tree [FreÃÅchet, 1948], is any element
TÃÑ ‚àà Tn such that
TÃÑ ‚àà argmin
x‚ààTn

X

d(x, y)2 ¬µ(y).

(3)

y‚ààTn

Since Tn is finite, we immediately have the existence of the minimizer in Equation 3. Note that uniqueness
may not be guaranteed, as though the objective function is convex, the space is discrete. If there is more than
one minimizer, the elements of the FreÃÅchet mean set will be close to each other in the metric d. However,
for many generating tree distributions, we observe that the FreÃÅchet mean is unique and for the rest of the
paper we consider as our summary one element of the FreÃÅchet mean set.
Examples of probability distributions on Tn include the Tajima coalescent (Yule model) [Tajima, 1983,
Sainudiin et al., 2015] in which ¬µ(T ) = ¬µ(F ) =

2n‚àíc‚àí1
(n‚àí1)! ,

where c is the number of cherries, i.e., the number of

internal nodes subtending two leaves. We consider a larger class of probability distributions on ranked tree
shapes in Section 5.
Similarly, for the metric spaces (Gn , d) with d corresponding to d1 or d2 on Gn and ŒΩ a probability measure
on Gn such that

Z

d(x, y)2 dŒΩ(y) < ‚àû,

Gn

the FreÃÅchet mean genealogy is any element GÃÑ ‚àà Gn such that
Z

d(G, H)2 dŒΩ(H).

GÃÑ ‚àà argmin
G‚ààGn

(4)

H‚ààGn

In this manuscript, we will consider probability models on isochronous genealogies such that for G = (F, u),
Qn‚àí1
dŒΩ(G) = ¬µ(F ) j=1 f (uj | uj+1 )d(u), that is, the tree topology and the branching event times are independent. In evolutionary biology applications, this assumption corresponds to neutral evolution in a closed
population [Wakeley, 2008]. In this case, the FreÃÅchet mean becomes:
GÃÑ ‚àà argmin
G‚ààGn

X Z
F H ‚ààF

n

0

‚àû

Z

‚àû

Z

‚àû

¬∑¬∑¬∑
un‚àí1

d(G, H)2 ¬µ(F H )f (un‚àí1 | un ) ¬∑ ¬∑ ¬∑ f (u1 | u2 )du1 du2 ¬∑ ¬∑ ¬∑ dun‚àí1 .

(5)

u2

A remarkable property of the mean (Eq. 5) under the d2 distance on genealogies, is that the optimization
problem can be separated into two optimization problems, one for finding the tree topology and one for
finding the branching event times. The following proposition formalizes this result.

7

Proposition 2. Let ŒΩ be a probability measure on Gn , the space of isochronous genealogies, such that the
tree topology and branching event times are independent under ŒΩ. The FreÃÅchet mean GÃÑ2 = (F ‚àó , u‚àó ) under
the d2 metric can be obtained by separately finding F ‚àó and u‚àó .
The proof is in the appendix, in Section C.
The empirical FreÃÅchet mean of a given sample y1 , . . . ym from the metric space (Tn , d) is obtained by taking
¬µ in (3) to be the empirical measure. The mean of a sample h1 , . . . , hm from (Gn , d) is obtained analogously,
where ŒΩ in (4) is taken to be the empirical measure, that is
TÃÑ ‚àà argmin
x‚ààTn

GÃÑ ‚àà argmin
g‚ààGn

m
X
j=1
m
X

d(x, yj )2

(6)

d(g, hj )2

(7)

j=1

The cardinality of the space Tn is given by the Euler zigzag numbers (OEIS A000111), which grow superexponentially with n, |T |n ‚àº 2 (2/œÄ)

n+1

¬∑ n!. Finding the FreÃÅchet mean is hence computationally challenging

for large n.
For a simpler summary of centrality, we can use an in-sample version of (6), which we call the restricted
FreÃÅchet mean:
TÃÑiin-sample ‚àà
GÃÑin-sample
‚àà
i

argmin

m
X

di (x, yj )2

(8)

di (g, hj )2

(9)

x‚àà{y1 ,...ym } j=1

argmin

m
X

g‚àà{h1 ,...hm } j=1

This may be reasonable for spaces with large number of leaves when direct computation of the FreÃÅchet mean
is not be possible. However, constraining ourselves to stay only within the sample may be undesirable.

3.2

Mixed Integer Programming

In principle, the definition of the FreÃÅchet mean is not sensitive to the choice of metric. However, in the case
of the d1 and d2 metrics, the FreÃÅchet mean is the minimizer of a convex objective function. In addition, the
space of F-matrices is characterized by a set of linear inequalities (Theorem 1) and hence the problem of
finding the FreÃÅchet mean can be framed as a mixed integer programming problem.
Let ¬µ be a probability measure on Tn , or equivalently on Fn , then in the case of the d2 metric, the FreÃÅchet
mean FÃÑ2 is given by:
FÃÑ2 ‚àà argmin
F ‚ààFn

= argmin
F ‚ààFn

X X
(Fkl ‚àí Hkl )2 ¬µ(H)
H‚ààFn k,l

X X
H‚ààFn k,l

8

2
(Fkl
‚àí 2Fkl Hkl )¬µ(H)

X
2
= argmin {Fkl
‚àí 2Fkl Mkl }
F ‚ààFn

k,l

Figure 3: Running time. Exact computation for FreÃÅchet mean under the Yule model using Gurobi, plotted
against dimension of F-matrices. Computations done on laptop with an Intel i7 processor.

where Mkl =

P

H‚ààFn

Hkl ¬∑ ¬µ(H). This is a simple quadratic objective function with linear and integrality

constraints. We use gurobi [Gurobi Optimization, 2020], a standard MIP solver, to directly perform the
optimization. The implementaion of the code is available in the R package fmatrix. Note that once the
means Mkl are computed, the rest of the problem no longer involves the m samples. That is, the problem
scales with the number of leaves n but not with the number of samples m. This is particularly important
when summarizing samples obtained through MCMC, since m is usually of high order.
This method works well for small number of leaves n, such as n = 20, but it quickly becomes impractical
with larger n. Figure 3 shows how the computation time grows exponentially in n. For larger n, we resort
to stochastic combinatorial optimization algorithms that scale well at the expense of solution guarantees as
discussed in Section 3.3.

3.3

Simulated annealing algorithm

When the number of leaves is large, the MIP solution is computationally demanding and often unfeasible. A
simple technique that works well is simulated annealing [Kirkpatrick et al., 1983], which is a general-purpose
stochastic algorithm for optimizing an objective function over a potentially large discrete set. Simulated
annealing explores the ranked tree shape space via a Metropolis-Hastings algorithm. We trade the guarantee
of an exact solution for computational tractability.
In order to describe the simulated annealing algorithm, we define two Markov chains on the space of ranked
tree shapes (one for isochronous and one for heterochronous trees) in Section D of the appendix. The two
Markov chains are then used as proposal distributions in the Metropolis-Hastings step of the simulated
annealing algorithm.
In the case of the FreÃÅchet mean, SA aims to minimize the energy function E(x) =

Pm

i=1

d(x, yi )2 for a

sample of trees {yi }m
i=1 over x ‚àà Tn . This problem is equivalent to finding the maximum of exp{‚àíE(x)/R}
9

at any given temperature R > 0. Let {Rk } be a sequence of monotone decreasing temperatures such that
limk‚Üí‚àû Rk = 0, for example Rk = Œ±k R0 for some high initial temperature R0 , and Œ± < 1. (This is the
exponential cooling schedule.) Then, at each temperature, the SA algorithm consists of Metropolis-Hastings
(MH) steps that targets œÄk (x) ‚àù exp{‚àíE(x)/Rk } as the stationary distribution. As the number of steps
increases, œÄk (x) puts more and more of its probability mass in the set of global maxima. SA differs from
descent algorithms by allowing transitions to higher energy states at higher temperatures, in order to avoid
being stuck at local maxima.
In our implementations (Algorithm 1) for isochronous and heterochronous FreÃÅchet means, the MH proposal
distributions are given by the transition kernels of the Markov chains described in section D of the appendix.
In both cases, the transition kernels are symmetric and hence, the MH acceptance probability of moving
from xk‚àí1 to xk is given by:


E(xk ) E(xk‚àí1 )
ak = exp ‚àí
+
Rk
Rk‚àí1


‚àß 1.

The temperature schedule in SA needs to be specified and affects the time taken for convergence of the
algorithm. Theoretical convergence guarantees exist for the logarithmic cooling schedule Rk = R0 (1 +
Œ± log(1 + k))‚àí1 with sufficiently high initial temperature and appropriately chosen Œ± (see Chapter 3 of Aarts
and Korst [1988]). However this schedule is prohibitively slow for most problems. In practice, we observe
that the exponential cooling schedule with Œ± chosen very close to 1 performs reasonably well. The benefits
of simulated annealing are its easy implementation and the design of the algorithm which allows getting out
of local optima.
Algorithm 1 FreÃÅchet mean of a sample of ranked unlabelled trees via simulated annealing
Require: T1 , . . . Tm sample of ranked unlabelled trees, starting position T (0) , initial temperature R0 > 0,
decay parameter Œ± ‚àà (0, 1).
Pm
Define energy function E(T ) = i=1 d(T, Ti )2 . (d is a metric defined in Section 2)
k‚Üê0
repeat
S ‚Üê random neighbour of T (k) (generate proposal using Markov chains of Definitions 11 or 14, for
isochronous and heterochronous trees respectively)


E(S) ‚àí E(T (k) )
if runif(1) < exp ‚àí
then
Rk
T (k+1) ‚Üê S (accept)
else
T (k+1) ‚Üê T (k) (reject)
end if
Rk+1 ‚Üê Œ±Rk (reduce temperature)
k ‚Üêk+1
until convergence of T (k)
Using the result shown in Section 3.2, we can replace the energy function E(T ) =
2

2

Pm

i=1

d(T, Ti )2 in the case

of the d metric by E(T ) = kF ‚àí M k where F is the F-matrix corresponding to T and M is the Euclidean
mean of the F-matrices corresponding to the Ti .

10

We note that for both isochronous and heterochronous genealogies, our algorithm first finds the average
coalescent times and then finds the tree topology via the SA algorithm just described. In the case of
heterochronous genealogies, the Markov chain used is conditioned on a fix set of coalescent and sampling
times. We analyse the computational performance of the SA algorithm in the appendix.

4

Measures of dispersion

In this section we define and discuss three notions for quantifying uncertainty or dispersion in a distribution
or a sample of ranked tree shapes (or ranked genealogies).
The FreÃÅchet variance is a natural measure of dispersion for arbitrary probability metric spaces. It measures
the concentration around the FreÃÅchet mean. While the FreÃÅchet mean is an object of the metric space, the
FreÃÅchet variance is a simple scalar summary of spread.
Let ¬µ be a probability measure on Tn (Fn ). The FreÃÅchet variance of y ‚àº ¬µ with respect to the metric d is
defined as follows:
V =

X

d(y, TÃÑ )2 ¬∑ ¬µ(y),

where

TÃÑ = argmin
x‚ààTn

y‚ààTn

X

d(x, y)2 ¬∑ ¬µ(y)

(10)

y‚ààTn

Let y1 , . . . ym ‚àà Tn be a random sample of ranked tree shapes. Then the sample FreÃÅchet variance is given by
m

Vm =

1 X
d(yi , TÃÑ )2 ,
m i=1

where

m
X
d(x, yi )2
TÃÑ = argmin

(11)

x‚ààTn i=1

Similarly, the FreÃÅchet variance of G ‚àº dŒΩ can be obtained by integrating over the probability space of
branching event times and ranked tree shapes.
Another scalar measure of dispersion is entropy [Mezard and Montanari, 2009]. Entropy is a function of
the probability measure only and it does not depend on the metric d. A measure with zero entropy is
concentrated on a single point, and a large entropy indicates greater uncertainty in the position of a random
variable with the underlying measure.
Let ¬µ be a probability measure on Tn . The entropy of the space is given by
H=‚àí

X

¬µ(y) ¬∑ log [¬µ(y)]

(12)

y‚ààTn

The discrete distribution with maximum entropy is the uniform distribution. While entropy is meaningful
at the population level, it does not provide a meaningful value for a given sample. In Figure 5 we compare
entropy with FreÃÅchet variance for a particular class of probability models on ranked tree shapes.
In many applications, a single mean value and the variance are not enough for summarizing the distribution. Interquartiles and credible intervals are typically used to inform about the concentration of the

11

distribution around the central value for real-valued distributions. The analogues in the space of ranked tree
shapes are defined as follows:
A central interquartile ball of ranked tree shapes of level 1 ‚àí Œ±, Œ± ‚àà [0, 1] is the set
d

BŒµ (TÃÑ ) = {y ‚àà Tn : d(y, TÃÑ ) ‚â§ Œµ},
where Œµ is the smallest  ‚â• 0 such that P(B (TÃÑ )) ‚â• 1 ‚àí Œ±, where TÃÑ is a point estimate.
Similarly, a level 1 ‚àí Œ± credible ball is the set BŒµ (TÃÑ ) where Œµ is the smallest  ‚â• 0 such that P(B (TÃÑ ) | D) ‚â•
1 ‚àí Œ±.
Although credible and interquartile balls can be defined in a meaningful way in terms of the d1 and d2
distances to the mean value, summarizing meaningful boundaries of the sets in this space is challenging.
One attempt to meaningfully define boundaries for credible sets and interquartile sets is through a total
ordering on Tn . Such an ordering roughly corresponds to a one-dimensional projection of the space, and the
boundaries of a credible set can be taken to be the extreme points of the set with respect to the ordering.
We propose an ordering based on the distance to a reference ranked tree shape, for example the FreÃÅchet
Mean TK of the Kingman model [Kingman, 1982], which is a commonly used neutral model for evolution,
together with a lexicographic order in the F-matrix representation. We construct our ordering in such a way
that the most unbalanced tree Tunb (also called caterpilar tree) and the most balanced tree Tbal are two poles
of the order, and the FreÃÅchet mean TK lies somewhere in between those two poles.
To be more precise, the most unbalanced tree denoted here as Tunb ‚àà Tn is the only ranked tree shape
with one cherry, i.e., one internal node that subtends two leaves. The unbalanced tree with n = 5 leaves is
depicted in the last column of Figure 2.
Proposition 3. The ranked tree shape at maximum d1 and d2 distances to the unbalanced tree Tunb ‚àà Tn
is Tbal with the following F-matrix encoding:

F

(bal)

that is, Fi,j

(bal)

Ô£Æ
2
Ô£Ø
Ô£Ø1
Ô£Ø
Ô£Ø0
Ô£Ø
Ô£Ø
0
=Ô£Ø
Ô£Ø
Ô£Ø0
Ô£Ø
Ô£Ø.
Ô£Ø.
Ô£∞.
0

Ô£π
3
2

4

1

3

5

0
..
.

2
..
.

4
..
.

6
..
.

..

0

0

0

¬∑¬∑¬∑

n‚àí2

Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫,
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£ª

.

(13)

n
(bal)

= max{0, 2j ‚àí i + 1} for i = 1, . . . , n ‚àí 1 and j = 1, . . . , i, and and Fi,j

and j = i, . . . , n ‚àí 1 (upper triangle).

12

= 0 for i = 1, . . . , n ‚àí 1

Proof. First note that the most unbalanced tree has the following F-matrix encoding:

F

(unb)

that is, Fi,j

(unb)

Ô£π

Ô£Æ
2
Ô£Ø
Ô£Ø1
Ô£Ø
Ô£Ø1
Ô£Ø
Ô£Ø
1
=Ô£Ø
Ô£Ø
Ô£Ø1
Ô£Ø
Ô£Ø.
Ô£Ø.
Ô£∞.
1

3
2

4

2

3

5

2
..
.

3
..
.

4
..
.

6
..
.

..

2

3

4

¬∑¬∑¬∑

n‚àí2

Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫,
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£∫
Ô£ª

.
n

(unb)

= j for i = 2, . . . , n ‚àí 1, and j = 1, . . . , i ‚àí 1 and Fi,j

j = i + 1, . . . , n ‚àí 1 (upper triangle) and

(unb)
Fi,i

(14)

= 0 for i = 1, . . . , n ‚àí 1 and

= i + 1 for i = 1, . . . , n ‚àí 1 (diagonal). Further, note that for

any F ‚àà Fn , the values in each row are non-decreasing to the right, i.e. Fi,j ‚â§ Fi,j+1 (constraint 3, Theorem
1) and the values in each column are non-increasing, i.e. Fi,j ‚â• Fi+1,j (constraints 2 and 3, Theorem 1).
(unb)

Second, Fi,j

‚â• Fi,j for all F ‚àà Fn and i, j ‚â§ n ‚àí 1, that is, F (unb) has the largest d1 and d2 norms. Third,

(bal)
note that Fi,j
(bal)
Moreover, Fi,j

‚â§ Fi,j for all F ‚àà Fn and i, j ‚â§ n ‚àí 1, that is, F (bal) has the smallest d1 and d2 norms.
(unb)

‚â§ Fi,j

for all i, j ‚â§ n ‚àí 1 and the pair: Tunb and Tbal have the largest d1 and d2 distances

among all pairwise distances in Tn .
We note that the ranked tree shape corresponding to F (bal) is called the most balanced ranked tree shape for
ease of interpretation. However, there may be arguably many more similarly balanced trees in the population.
We will now define the signed-distance as the distance to a reference ranked tree shape TÃÑ with an additional
sign depending on whether the tree is closer to the most unbalanced or to the most balanced tree.
Definition 4. (The signed-distance function to TÃÑ ). Let f (x) : Tn ‚Üí R+ and TÃÑ ‚àà Tn a reference ranked tree
shape, such that
f (x) =

Ô£±
Ô£≤‚àíd(x, TÃÑ )

if d(x, Tunb ) ‚â§ d(x, Tbal )

Ô£≥d(x, TÃÑ )

if d(x, Tunb ) > d(x, Tbal )

(15)

The signed-distance induces a partial order on Tn , however since many ranked tree shapes can have the same
signed distance to TÃÑ , many pairs of trees will be incomparable . We will say that T1 ‚àº T2 belong to the same
equivalence class if f (T1 ) = f (T2 ). When a set of ranked tree shapes belong to the same equivalence class,
we will order the ranked tree shapes in the equivalence class according to their lexicographic order using a
vectorized F representation as follows.
(1)

(1)

(1)

(1)

(1)

(1)

Definition 5. (Lexicographic order). Let F (1) = (F1,1 , F2,1 , . . . , F1,n‚àí1 , F2,2 , F2,3 , . . . , Fn‚àí1,n‚àí1 ) be the
(2)
(2)
(2)
(2)
(2)
(2)
column-vectorized representation of T1 ‚àà Tn , and let F (2) = (F1,1 , F2,1 , . . . , F1,n‚àí1 , F2,2 , F2,3 , . . . , Fn‚àí1,n‚àí1 )
be the column-vectorized representation of T2 ‚àà Tn . We say that T1 lex T2 if F (1) = F (2) or the first
(1)
(2)
non-vanishing difference Fi ‚àí Fi is positive for i = 1, . . . , m, m = n(n‚àí1)
.
2

13

For example T (unb) lex T (bal) and T (unb) lex T lex T (bal) for any T ‚àà Tn . Although the lexicographic
order is a total order, we propose to order all ranked tree shapes in the space according to their signed
distance to TK and to only use the lexicographic order within equivalence classes as follows.
Definition 6. We say that T1  T2 if f (T1 ) < f (T2 ) or if f (T1 ) = f (T2 ) and T1 lex T2 .
Proposition 7. The order induced by  of Definition 6 on Tn is a total order.
Proof. To show antisymmetry note that the only way T1  T2 and T2  T1 is that f (T1 ) = f (T2 ) and
T1 lex T2 and T1 lex T2 . This occurs only if F (1) = F (2) . The bijection of Theorem 1 then implies that
T1 = T2 . Transitivity and convexity follow directly from the transitivity and convexity of < and lex .
We note that lex is not the only possible lexicographic order; for example a row-vectorized representation
of T ‚àà Tn can be replaced in definition 5 to generate another ordering. Although the lexicographic order is
not a biologically meaningful order, it provides a consistent way for comparing histograms across different
tree models on the same space (see for example, the third row of Figure 6).
Having established the  order, we will summarize credible balls and interquartile balls by at most four
ranked tree shapes and by at least two ranked tree shapes. Let BŒµ (TÃÑ ) denote the interquartile or credible
ball and TÃÑ the FreÃÅchet mean of the distribution. Then the set of ranked tree shapes at the boundary of
BŒµ (TÃÑ ) will be partitioned into two sets, one with positive signed distance to TÃÑ and one with negative signed
distance to TÃÑ . If the cardinality of the sets is greater than one, we will then summarize each set by the
smallest and the largest ranked tree shape in each set according to the  order.

5
5.1

Results
Statistical summaries of Blum-FrancÃßois distributions on ranked tree shapes

We present and analyse point summaries of a large family of ranked tree shape models called the BlumFrancois Œ≤-splitting model. After the introduction of Aldous‚Äô Œ≤-splitting model on cladograms (tree shapes
without rankings) [Aldous, 1996, 2001], many extensions and generalizations of this model have been proposed
on different resolutions of trees, including the Blum-FrancÃßois model on ranked tree shapes [Sainudiin and
VeÃÅber, 2016] and the alpha-beta splitting model [Maliet et al., 2018]. Henceforth, we will refer to the
Blum-FrancÃßois model on ranked tree shapes simply as the Blum-FrancÃßois model.

14

Figure 4: FreÃÅchet mean under the Blum-FrancÃßois Œ≤-splitting model. Top to bottom: n = 5, . . . , 9,
Left to right: Œ≤ = ‚àí1, 0, 100.

We start with the Blum-FrancÃßois model on ranked unlabelled planar trees (there is distinction between left
R
and right offspring). Let nL
i and ni denote the number of internal nodes in the left and right subtrees below
R
node i. In particular, if node i is a cherry, i.e. subtends two leaves, then nL
i = ni = 0. Then, a ranked

unlabelled planar tree with n leaves has probability mass function given by:
P (Tplanar ) =

n‚àí1
Y
i=1

where B(a, b) =

R1
0

R
B(nL
i + Œ≤ + 1, ni + Œ≤ + 1)
B(Œ≤ + 1, Œ≤ + 1)

xa‚àí1 (1 ‚àí x)b‚àí1 dx is the Beta function and Œ≤ ‚àà [‚àí1, ‚àû). A ranked tree shape T obtained

by ignoring the distinction between left and right subtrees has then the following probability mass function:
P (T ) = 2n‚àí1‚àíc

n‚àí1
Y
i=1

R
B(nL
i + Œ≤ + 1, ni + Œ≤ + 1)
B(Œ≤ + 1, Œ≤ + 1)

where c is the number of cherries in T . The Œ≤ parameter controls the level of balancedness of the distribution. In particular, when Œ≤ = 0, the corresponding distribution P (T ) = 2n‚àí1‚àíc /(n ‚àí 1)! is the coalescent
distribution on ranked tree shapes (Kingman coalescent), also known as the Yule distribution.

15

Figure 5: Measures of dispersion. FreÃÅchet variance, average distance to FreÃÅchet mean, and entropy, for
small n under the Blum-FrancÃßois Œ≤-splitting model

Figure 4 shows the d2 FreÃÅchet means of the ranked tree shapes distributions with 5, . . . , 9 leaves under
the Blum-FrancÃßois distribution with Œ≤ ‚àà {‚àí1, 0, 100}. For small values of Œ≤, the distribution generates
unbalanced trees and for large values of Œ≤, the distribution generates balanced trees. Figure 5 shows the d2
FreÃÅchet variance, expected distance to the FreÃÅchet mean and entropy for n = 5, . . . , 9 and Œ≤ values spaced
out in [‚àí1, ‚àû]. For Œ≤ > 1, the variance and entropy remain relatively constant as functions of Œ≤. The largest
variance and entropy are obtained when Œ≤ ‚â§ 0. We explicitly compute the corresponding FreÃÅchet mean,
FreÃÅchet variance, and entropy for small n by enumerating all the ranked tree shapes and evaluating their
probability mass functions.

16

Figure 6: Summarizing Blum-FrancÃßois distributions on ranked tree shapes. Blum-FrancÃßois distributions on ranked tree shapes with n = 9 leaves, columns correspond to Œ≤ = ‚àí0.99, ‚àí0.5, 0 (coalescent), 10
respectively. Row 1: FreÃÅchet Mean of the distribution; Row 2: Probability mass function of trees, arranged
in increasing order of probability; Row 3: Probability mass function of trees, arranged in the Signed Distance
order of Definition 6, with FreÃÅchet mean (red line) of distribution and interquartiles (green dashed lines);
Row 4: Histogram of distance to the Kingman FreÃÅchet mean, with median (blue line) and interquartiles
(orange dashed lines) of the distance to the mean; Row 5: Histogram of signed distance to the Kingman
FreÃÅchet mean, with median (blue line) and interquartiles (orange dashed lines) of the signed distance; Row
6: Multidimensional scaling visualization of the tree distribution, each dot represents a tree colored by its
probability mass, with FreÃÅchet mean (red dot) and expected value (green dot).
17

For ranked tree distributions with n = 100 leaves, we simulated N = 1000 ranked tree shapes with the R
package apTreeshape [Maliet et al., 2018] and found the d2 mean via the simulated annealing of Section
3.3. The resulting means are shown in Figure 7 for Œ≤ ‚àà {‚àí1.9, ‚àí1.5, ‚àí1, 0, 100}.

Figure 7: Approximated FreÃÅchet means. FreÃÅchet means are found via simulated annealing from a sample
of N = 1000 trees with n = 100 leaves from Œ≤-splitting distribution. Left to right: Œ≤ = ‚àí1.9, ‚àí1.5, ‚àí1, 0, 100.
Simulated annealing with exponential cooling schedule and decay parameter .9995, initial temperature 1000.

Figure 6 shows different summaries of four Blum-FrancÃßois distributions on ranked tree shapes with n =
9 leaves. The second row correspond to the probability mass function with trees (x-axis) arranged in
increasing order of probability. When analyzing these plots, it is impossible to assess whether the Œ≤ = ‚àí0.5
distribution puts more probability mass on unbalanced trees than balanced trees when compared to the
Œ≤ = 10 distribution since the x-axes are not comparable. The third row shows the probability mass functions
with the x-axes arranging trees in the signed distance total order. Here, all x-axes correspond to the same tree
arrangements. It is now clear that the Œ≤ = ‚àí0.5 distribution assigns more probability mass to unbalanced
trees and the Œ≤ = 10 distribution assigns more mass to balanced trees. This is confirmed in the fifth row of
Figure 6. The histogram of the signed distance to the mean is skewed to the right (balanced) when Œ≤ = 10.
Row four of Figure 6 shows the histograms of the distance to the mean. This one-dimensional summary
of the tree distributions hinders whether some distributions put more probability mass to different types
of trees. For example the last three histograms of the fourth column look very similar. Finally, while the
MDS plots (Figure 6, last row) only explain about 53% of all pairwise distances, the last panel shows the
distinctions between the four probability mass distributions. Here, green dots corresponds to the points
whose F-matrix is E(F ) (and do not lie in tree space) and red dots are the FreÃÅchet means.
We note that the FreÃÅchet means of the distributions with Œ≤ = 0.05, 0 and 10 are very close to each other. This
indicates that a single central summary may not have a good discriminating power for detecting difference
in distributions within the Blum-FrancÃßois family.

5.2

Characterization of mean Kingman tree

As stated in Section 3.2, under d2 , the population FreÃÅchet mean is given by
X
2
FÃÑ2 = argmin {Fkl
‚àí 2Fkl Mkl },
F ‚ààFn

k,l

18

where Mkl = E(Fk,l ). If we know the matrix M , we only need to search for ranked tree shapes that are in
a neighborhood of M (see for example the red and green dots representing the M and the FreÃÅchet mean in
the last row of Figure 6). In fact, the only data input needed using gurobi or simulated annealing is M .
Although there is no explicit formula for the FreÃÅchet mean for the distributions analyzed here, there is a
explicit formula for M for the Kingman/Yule coalescent distribution (Blum-FrancÃßois with Œ≤ = 0). In Figure
6, we visualize M and the FreÃÅchet mean in an MDS plot of the entire space.
Theorem 8. Let F ‚àà Fn be an F-matrix distributed according to the Blum-FrancÃßois model with Œ≤ = 0,
i.e. according to the Kingman/Yule coalescent distribution, then:
1. The distribution of the i-th row of F is independent of n.
2. E[Fij ] =

j(j + 1)
i

3. Var[Fij ] =

j 3 2(j + 1)2
j(j + 1)(i ‚àí 2j ‚àí 1)
+
2
i (i ‚àí 1)
i(i ‚àí 1)

4. Cov[Fi1 j1 , Fi2 j2 ] =
Ô£±
j1 (j1 +1)[j2 (j2 +2)+(i1 +1)(i1 ‚àí2j2 ‚àí2)]
Ô£¥
Ô£¥
i21 (i1 ‚àí1)
Ô£¥
Ô£¥
Ô£¥
Ô£¥
j
(j
+1)(j
‚àíi
2
2 )(j2 ‚àíi2 +1)
Ô£≤ 2 2

when i1 = i2 , j1 < j2
when i1 > i2 , j1 = j2

i1 i2 (i2 ‚àí1)

j2 (j2 +1)[(j1 +1)(j1 +2)+(i1 +1)(i1 ‚àí2j1 ‚àí2)]
Ô£¥
+
Ô£¥
Ô£¥
i21 (i1 ‚àí1)
Ô£¥
Ô£¥
Ô£¥
Ô£≥ j1 (j1 +1)[(j2 +1)(j2 +2)+(i1 +1)(i1 ‚àí2j2 ‚àí2)] +
i2 (i1 ‚àí1)
1

(i1 ‚àíi2 )j1 j2 (j2 +1)
i1 i2

h

(i1 ‚àíi2 )j1 (j1 +1)j2
i1 i2

h

j1 ‚àí1
i2 ‚àí1
j2 ‚àí1
i2 ‚àí1

‚àí
‚àí

j1 +1
i2 +1

i

when i1 > i2 , j1 > j2

j2 +1
i2 +1

i

when i1 > i2 , j1 < j2

The proof can be found in Section E in the appendix.
The relevance of Theorem 8 is that for one of the most popular models in population genetics: the coalescent
[Wakeley, 2008], the FreÃÅchet mean can be obtained for any n, without the need for simulating a sample
from the distribution as it is done in Figure 7. Moreover, given a sample of F-matrices, the sample average
(element-wise) converges almost surely to M by the law of large numbers. Theorem 8 together with the
Multivariate Central Limit Theorem [Hogg et al., 2019, Thm 5.4.4], could be used to test whether a random
sample of ranked tree shapes follows the standard coalescent distribution such as the Kingman/Yule model.
Theorem 9. (Central Limit Theorem for F-matrices) Let F 1 , . . . F m ‚àà Fn be an i.i.d. sample of F-matrices
drawn from some distribution P . Let FÃÑm ‚àà R(n‚àí1)√ó(n‚àí1) be the matrix whose entries correspond to the
sample average of F 1 , . . . , F m (entrywise). Then
‚àö

 d
m FÃÑm ‚àí M ‚Üí N (0, Œ£)

2

where the mean M ‚àà R(n‚àí1) is given by
¬µij = EP [Fij ]

19

(16)

and the covariance tensor Œ£ ‚àà R(n‚àí1)

2

√ó(n‚àí1)2

is given by

Œ£ij,kl = CovP [Fij , Fkl ]
Proof. The proof follows directly from the multivariate central limit theorem, considering the F-matrices as
2

elements of R(n‚àí1) . Since each entry of the F-matrices is bounded in [0, n], all expectations are finite.
2

Corollary 9.1. Consider the setting of Theorem 9, and assume that Œ£ is invertible. Let Œ£ÃÇ ‚àà R(n‚àí1)

√ó(n‚àí1)2

be the empirical covariance tensor. We have
 d
‚àö
Œ£ÃÇ‚àí1/2 m FÃÑm ‚àí ¬µ ‚Üí N (0, I)
where I ‚àà R(n‚àí1)

2

√ó(n‚àí1)2

(17)

is the identity tensor given by
Iij,kl = 1i=k,j=l

Proof. The proof follows by the multivariate version of Slutsky‚Äôs theorem, using consistency of the empirical
covariance, and the fact that the function M ‚Üí M ‚àí1/2 is continuous when M is an invertible covariance
matrix.

5.3

Summaries of coalescent ranked genealogical distributions

In neutral (isochronous) coalescent models with variable population size, the tree topology and the distribution of branching event waiting times are independent. The ranked tree shape is distributed according
to the Kingman/Yule/Blum-FrancÃßois model with Œ≤ = 0 and the branching event times have the following
conditional density:
f (ui‚àí1 | ui , Ne (t)) =

i
2

   Z ui‚àí1

i
du
exp ‚àí
,
Ne (ui‚àí1 )
2 ui
Ne (u)


(18)

with un = 0 and Ne (t) is a non-negative function that denotes the effective population size [Slatkin and
Hudson, 1991].
We simulated 1000 ranked genealogies according to the neutral coalescent model with the following effective
population size functions:
(1) Constant: Ne (t) = 10000;
(2) Exponential: Ne (t) = 10000 exp{‚àí0.01t};
(3) Logistic:
Ô£±
Ô£≤1000 +
Ne (t) =
Ô£≥1000 +

9000
1+exp[6‚àí2(t mod 12)]

(t mod 12) ‚â§ 6

9000
1+exp[‚àí18+2(t

(t mod 12) > 6.

mod 12)]

Figure 8 shows the Multidimensional scaling representation of the three simulated distributions (using d2 ),
together with the FreÃÅchet means (stars) and medois (triangles). The corresponding means and triangles are
depicted in Figure 9. FreÃÅchet mean topologies are calculated with simulated annealing and the branching
event times correspond to the sample means. Although in this case the two summaries (means and medois)

20

are close to each other in MDS, the two genealogies can have very different branch lenghts as in the logistic
simulation (last row, Figure 9).

MDS 2 (6.2%)

2e+05

1e+05

0e+00

‚àí1e+05
‚àí3e+05

‚àí2e+05

‚àí1e+05

0e+00

1e+05

MDS 1 (63.8%)
Family

Constant

Exponential

Logistic

Figure 8: MDS of ranked genealogies with different branching event times distributions. Multidimensional scaling visualization of the coalescent distributions on ranked genealogies with varying effective
population sizes: constant (red), exponential (green), and logistic (blue). Triangles denote medoids and stars
denote FreeÃÅchet means. Shaded areas represent the 50% convex hulls.

21

Constant Ne, Medoid

0

0

2000

4000

4000

8000

Constant Ne, Mean

Exponential Ne, Medoid

0

0

200

200

400

400

Exponential Ne, Mean

Logistic Ne, Medoid

0

0

2000

4000

1000 2000 3000

Logistic Ne, Mean

Figure 9: FreÃÅchet mean vs medoid. FreÃÅchet means (first column) and in-sample medoids (second column)
of the three simulated coalescent distributions of genealogies with n = 100 leaves and with varying effective
population size trajectories. FreÃÅchet means are indicated as stars and in-sample medoids as triangles in
Figure 8. FreÃÅchet means coalescent times are the sample mean coalescent times.

6

Analysis of SARS-CoV-2

The COVID-19 pandemic has had an enormous impact on all humanity. Tracking the evolution of the
SARS-CoV-2 virus that causes COVID-19 has been of great importance for tracking the epidemic and for
improving our understanding of the disease [Volz et al., 2021]. Here we analyse SARS-CoV-2 molecular
sequences publicly available in the GISAID EpiCov database [Shu and McCauley, 2017] from the states of
California, Florida, Texas and Washington in the USA for the period of February 2020 to September 2020.
A great challenge in molecular epidemiology of SARS-CoV-2 consists in being able to analyse all available
sequences from a population. The number of available sequences exceeds the sample capacity that any
Bayesian phylogenetic method (for example those implemented in BEAST [Suchard et al., 2018]) can handle. The predominant approach is to subsample the available sequences and infer the posterior genealogical
distribution with BEAST. One important question then is how to assess whether the chosen sample‚Äôs estimated genealogy is representative to the mean genealogy in the population of a sample of the same size

22

as our subsample. Here, we compare subposterior distributions estimated from different random samples of
100 sequences from California and assess the stability of their FreÃÅchet means.
We selected 9 samples of 100 sequences uniformly at random, obtained in California before June 1 of 2020 and
9 random samples of 100 sequences obtained after June 1, 2020. For each study (random set of 100 samples),
we generated 1,000 MCMC samples thinned every 50,000 iterations from the posterior distribution of model
parameters (genealogy and other parameters) with BEAST [Suchard et al., 2018]. Details of parameters
and prior distributions selected for BEAST analyses and data access acknowledgments can be found in the
appendix.
We first analyse the California trees sampled from a single posterior distribution. For ease of visualization,
we show the MDS plot of all 1000 posterior genealogical samples in Figure 10 assuming the d2 metric
defined in Definition 2. The posterior central genealogies are depicted as colored dots in Figure 10 and
the corresponding genealogies are drawn in Figure 11. The two tree topologies of the FreÃÅchet means are
obtained with our simulated annealing algorithm for heterochronous samples. The FreÃÅchet mean coalescent
times are obtained as sample averages (purple tree in Figure 10) and sample medians (cyan tree in Figure
10). Note that the two tree topologies of the FreÃÅchet means are different. As mentioned in section 3.3, our
SA algorithm finds the tree topology that optimizes the objective function conditioned on a given sequence
of sampling and coalescing events. The maximum clade credibility (MCC) tree is computed using the R
package phangorn. We also plot the in-sample medoid, which is the tree in the sample that minimizes the
average distance to the rest of the trees in the sample. We shaded the 50% credible convex hull around the
FreÃÅchet mean with mean coalescent times. All central summaries are within the 50% credible convex hull.

23

Figure 10: MDS plot of a sample of N = 1000 trees from a single BEAST posterior distribution
of California. Each dot represents a tree of n = 100 sequences randomly chosen among GISAID sequences
from California sequenced between February and May 2020. Shaded area corresponds to 50% credible convex
hull around the FreÃÅchet mean, using average branch lengths.

Remark: We note that both the FreÃÅchet mean and the in-sample medoid are designed to be central with
respect to the d2 metric using F-matrices, whereas the MCC tree is not. Hence, it is not surprising that the
MCC tree is further away from the center in the MCC plot as compared to the other point summaries. We
can notice that both FreÃÅchet means are closer to the center than the in-sample medoid.

24

Figure 11: Posterior summary trees of a sample of 100 sequences from California Feb-May 2020
Summary trees for a sample of 1000 trees drawn from a single BEAST posterior using n = 100 sequences
from California. Left to right: Maximum Clade Credibility tree obtained with phangorn, in-sample medoid,
FreÃÅchet mean using median coalescent times, and FreÃÅchet mean using average coalescent times. The four
trees correspond to the four dots highlighted in Figure 10.

We now visualize multiple subposterior distributions of California together in the MDS plot of Figure 12
using the d2 metric. For ease of visualization we further subsampled only 20 trees (evenly spaced) from each
BEAST posterior distribution to generate the MDS plot. The first group of trees on the left correspond to
trees of samples sequenced between February and May 2020, and the second group on the right correspond
to trees of samples sequenced between Jun-Sep 2020. The FreÃÅchet means are then computed with the SA
algorithm for each subsample (shown as bigger dots with black border). As expected, the separation between
samples from different time periods may reflect the fact that California experienced an increase in COVID-19
prevalence in the second semester of 2020. Moreover, samples from the second time period are more spread.
The separation between the FreÃÅchet means of the two groups suggests that they could be good statistics in
a two-sample (or k-sample) test for equality of distributions. We note that even for the first period, some
subposterior distributions in California do not overlap.

25

Figure 12: MDS plot of 20 trees per each of the 18 posterior BEAST samples of trees with
n = 100 leaves of California. The group of trees on the left correspond to trees of samples sequenced
Feb-May 2020 and the second group of trees on the right correspond to trees of samples sequenced between
Jun-Sep 2020. The FreÃÅchet means are calculated using the average coalescent times and are marked as red
dots.

We now compare posterior distributions across the four states: California, Washington, Texas and Florida.
Figure 13 shows the MDS plot of three samples of 20 trees with n = 100 leaves from each location. Sequences analyzed were genotyped between February and May 2020. After computing the FreÃÅchet means, we
downsample in order to better visualize the multidimensional scaling plot. We note that the subposteriors
of Washington state are more concentrated than any of the other 3 states. Moreover, there is almost no
overlap between the posterior genealogical distribution of Washington state with the posterior distributions
of the other states. Indeed the reported number of confirmed COVID-19 cases in Washington state is the
lowest and with smallest growth rate of all the states considered in this analysis (Figure 14). We note that in
the case of Washington state we observe stable subposteriors; all subposteriors reflect the same evolutionary
signal.
The posterior distributions of Florida are the second more concentrated in that their three FreÃÅchet means are
close to each other and their convex hulls overlap. While the posterior distribution of evolutionary trees of
Florida are different to those in Washington state, there is some overlap with the posteriors of California and
Texas. California experienced the highest cumulative number of cases (Figure 14) and it also has the largest
heterogeneity in subposterior distributions. Analyses on different subsamples in California can provide very
different results. This large heterogeneity may be the result of local outbreaks sequencing efforts in the area.
Finally, while the cumulative number of reported cases in Texas is not as large as the one reported in
California. Texas‚Äôs subposteriors show similar heterogeneity to California, with similar posterior distributions
of evolutionary histories (genealogies).

26

Figure 13: MDS plot of multiple samples from California, Washington, Florida, and Texas.
Three samples of 20 trees of n = 100 samples randomly chosen among GISAID sequences in Feb-May 2020
per location. The FreÃÅchet means are calculated using average coalescent times and marked as red dots The
shaded region corresponds to 50% credible convex hulls around the FreÃÅchet means.

Figure 14: Confirmed cumulative case counts in California, Washington, Florida, and Texas.
Data between January and September 2020, obtained from the COVID-19 Data Repository by the Center
for Systems Science and Engineering (CSSE) at Johns Hopkins University [Dong et al., 2020].

27

7

Discussion

For discrete tree topologies, the FreÃÅchet mean ranked tree shape may not be unique. However in our
experience, we found the FreÃÅchet means to be very close to each other. We conjecture that the set of FreÃÅchet
means has a very small diameter and it will be explored in future research. While the non-uniqueness of the
FreÃÅchet mean can potentially be problematic for hypotheses testing, we remark that the expected F matrix,
here denoted by M , is unique and the limit of the sample mean FÃÑm by the strong law of large numbers. In
this manuscript, we provided a Central Limit Theorem result for FÃÑm and analytical expressions for M and
variance of the ranked tree shape distribution under the standard Kingman coalescent. Theoretical results
of this kind for other distributions is left as future work. Similarly, analyses of several test statistics based
on the distances analyzed here and FreÃÅchet means such as in Dubey and MuÃàller [2019] are subject of future
research.
Extension of current work include defining distances and summaries for multifurcating tree shapes and
phylogenetic networks. Our current implementations are publicly available in github.com/RSmayak/fmatrix.

Acknowledgement
We acknowledge Paromita Dubey and Jaehee Kim for useful discussions. J.A.P. is supported by National
Institutes of Health Grant R01-GM-131404 and the Alfred P. Sloan Foundation.

References
E. Aarts and J. Korst. Simulated annealing and boltzmann machines. 1988.
D. Aldous. Probability distributions on cladograms. In D. Aldous and R. Pemantle, editors, Random
Discrete Structures, pages 1‚Äì18, New York, NY, 1996. Springer New York. ISBN 978-1-4612-0719-1. URL
https://doi.org/10.1007/978-1-4612-0719-1 1.
D. J. Aldous. Stochastic models and dhaescriptive statistics for phylogenetic trees, from yule to today.
Statistical Science, 16(1):23‚Äì34, 2001. ISSN 08834237. URL http://www.jstor.org/stable/2676778.
P. Benner and M. BacÃåaÃÅk. Computing the posterior expectation of phylogenetic trees. 2013.
L. J. Billera, S. P. Holmes, and K. Vogtmann. Geometry of the space of phylogenetic trees. Advances in
Applied Mathematics, 27(4):733 ‚Äì 767, 2001. ISSN 0196-8858. doi: https://doi.org/10.1006/aama.2001.
0759. URL http://www.sciencedirect.com/science/article/pii/S0196885801907596.
L. Breiman. Algorithm cart. Classification and Regression Trees. California Wadsworth International Group,
Belmont, California, 1984.
D. G. Brown and M. Owen. Mean and Variance of Phylogenetic Trees. Systematic Biology, 06 2019.
L. Cappello, A. Veber, and J. A. Palacios. The tajima heterochronous n-coalescent: inference from heterochronously sampled molecular data. arXiv preprint arXiv:2004.06826, 2020.

28

J. Chakerian and S. Holmes. Computational tools for evaluating phylogenetic and hierarchical clustering
trees. Journal of Computational and Graphical Statistics, 21(3):581‚Äì599, 2012.
K. A. Cranston and B. Rannala. Summarizing a posterior distribution of trees using agreement subtrees.
Systematic biology, 56(4):578‚Äì590, 2007.
R. Donaghey. Alternating permutations and binary increasing trees. Journal of Combinatorial Theory, Series
A, 18(2):141‚Äì148, 1975.
E. Dong, H. Du, and L. Gardner. An interactive web-based dashboard to track covid-19 in real time. The
Lancet infectious diseases, 20(5):533‚Äì534, 2020.
P. Dubey and H.-G. MuÃàller. FreÃÅchet analysis of variance for random objects. Biometrika, 106(4):803‚Äì821,
10 2019. ISSN 0006-3444. doi: 10.1093/biomet/asz052. URL https://doi.org/10.1093/biomet/asz052.
B. Efron, E. Halloran, and S. Holmes. Bootstrap confidence levels for phylogenetic trees. Proceedings of the
National Academy of Sciences, 93(23):13429‚Äì13429, 1996.
J. Felsenstein. Confidence limits on phylogenies: an approach using the bootstrap. evolution, 39(4):783‚Äì791,
1985.
J. Felsenstein. Inferring phylogenies, volume 2. Sinauer associates Sunderland, MA, 2004.
M. FreÃÅchet. Les eÃÅleÃÅments aleÃÅatoires de nature quelconque dans un espace distancieÃÅ. In Annales de l‚Äôinstitut
Henri PoincareÃÅ, volume 10, pages 215‚Äì310, 1948.
K. Govek, C. Sikes, and L. Oesper. A consensus approach to infer tumor evolutionary histories. In Proceedings
of the 2018 Acm international conference on bioinformatics, computational biology, and health informatics,
pages 63‚Äì72, 2018.
L. Gurobi Optimization. Gurobi optimizer reference manual, 2020. URL http://www.gurobi.com.
J. Heled and R. R. Bouckaert. Looking for trees in the forest: summary tree from posterior samples. BMC
evolutionary biology, 13(1):221, 2013.
D. M. Hillis, T. A. Heath, and K. S. John. Analysis and visualization of tree space. Systematic biology, 54
(3):471‚Äì482, 2005.
R. V. Hogg, J. McKean, and A. T. Craig. Introduction to mathematical statistics. Pearson Education, 2019.
S. Janson, G. Kersting, et al. On the total external length of the kingman coalescent. Electronic Journal of
Probability, 16:2203‚Äì2218, 2011.
M. D. Karcher, J. A. Palacios, S. Lan, and V. N. Minin. phylodyn: an r package for phylodynamic simulation
and inference. Molecular ecology resources, 17(1):96‚Äì100, 2017.
J. Kim, N. A. Rosenberg, and J. A. Palacios. A metric space of ranked tree shapes and ranked genealogies.
bioRxiv, 2019. doi: 10.1101/2019.12.23.887125. URL https://www.biorxiv.org/content/early/2019/
12/23/2019.12.23.887125.

29

J. Kingman. The coalescent. Stochastic Processes and their Applications, 13(3):235 ‚Äì 248, 1982. ISSN
0304-4149. doi: https://doi.org/10.1016/0304-4149(82)90011-4. URL http://www.sciencedirect.com/
science/article/pii/0304414982900114.
S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. Optimization by simulated annealing. science, 220(4598):
671‚Äì680, 1983.
M. K. Kuhner and J. Yamato. Practical performance of tree comparison metrics. Systematic Biology, 64
(2):205‚Äì214, 12 2014.
O. Maliet, F. Gascuel, and A. Lambert. Ranked tree shapes, nonrandom extinctions, and the loss of
phylogenetic diversity. Systematic Biology, 67(6):1025‚Äì1040, 04 2018. ISSN 1063-5157. doi: 10.1093/
sysbio/syy030. URL https://doi.org/10.1093/sysbio/syy030.
M. Mezard and A. Montanari. Information, Physics, and Computation. Oxford University Press, 2009.
V. N. Minin, E. W. Bloomquist, and M. A. Suchard. Smooth skyride through a rough skyline: Bayesian
coalescent-based inference of population dynamics. Molecular biology and evolution, 25(7):1459‚Äì1471,
2008.
S. A. Nadeau, T. G. Vaughan, J. Scire, J. S. Huisman, and T. Stadler. The origin and early spread of
sars-cov-2 in europe. Proceedings of the National Academy of Sciences, 118(9), 2021. ISSN 0027-8424.
doi: 10.1073/pnas.2012008118. URL https://www.pnas.org/content/118/9/e2012008118.
J. E. O‚ÄôReilly and P. C. Donoghue. The efficacy of consensus tree methods for summarizing phylogenetic
relationships from a posterior sample of trees estimated from morphological data. Systematic biology, 67
(2):354‚Äì362, 2018.
J. A. Palacios, A. VeÃÅber, L. Cappello, Z. Wang, J. Wakeley, and S. Ramachandran. Bayesian estimation of population size changes by sampling Tajima‚Äôs trees. Genetics, Early online September 11, 2019;
https://doi.org/10.1534/genetics.119.302373, 2019. ISSN 0016-6731. doi: 10.1534/genetics.119.302373.
URL https://www.genetics.org/content/early/2019/09/11/genetics.119.302373.
E. Paradis and K. Schliep. ape 5.0: an environment for modern phylogenetics and evolutionary analyses in
r. Bioinformatics, 35(3):526‚Äì528, 2019.
R. Sainudiin and A. VeÃÅber. A beta-splitting model for evolutionary trees. Royal Society open science, 3(5):
160016, 2016.
R. Sainudiin, T. Stadler, and A. VeÃÅber. Finding the best resolution for the Kingman-Tajima coalescent:
theory and applications. Journal of Mathematical Biology, 70(6):1207‚Äì1247, 2015. URL https://doi.
org/10.1007/s00285-014-0796-5.
Y. Shu and J. McCauley. Gisaid: Global initiative on sharing all influenza data‚Äìfrom vision to reality.
Eurosurveillance, 22(13), 2017.
M. Slatkin and R. Hudson. Pairwise comparisons of mitochondrial DNA sequences in stable and exponentially
growing populations. Genetics, 129(2):555‚Äì562, 1991.
R. P. Stanley. Enumerative combinatorics. Volume I, 1999.
30

M. A. Suchard, P. Lemey, G. Baele, D. L. Ayres, A. J. Drummond, and A. Rambaut. Bayesian phylogenetic
and phylodynamic data integration using beast 1.10. Virus Evolution, 4(1), June 2018. ISSN 2057-1577.
URL https://doi.org/10.1093/ve/vey016.
F. Tajima. Evolutionary relationship of DNA sequences in finite populations. Genetics, 105(2):437‚Äì460,
1983.
E. Volz, V. Hill, J. T. McCrone, A. Price, D. Jorgensen, AÃÅ. O‚ÄôToole, J. Southgate, R. Johnson, B. Jackson,
F. F. Nascimento, et al. Evaluating the effects of SARS-CoV-2 spike mutation D614G on transmissibility
and pathogenicity. Cell, 184(1):64‚Äì75, 2021.
E. M. Volz, K. Koelle, and T. Bedford. Viral phylodynamics. PLoS Comput Biol, 9(3):e1002947, 2013.
J. Wakeley. Coalescent Theory: An Introduction. Roberts & Company Publishers, June 2008. ISBN
0974707759.
A. Willis and R. Bell. Confidence sets for phylogenetic trees. Journal of Computational and Graphical
Statistics, 27(525):542‚Äì552, 2018. doi: 10.1080/01621459.2017.1395342. URL https://doi.org/10.1080/
01621459.2017.1395342.

31

A

Distance calculation between heterochronous trees with different sampling events

.
In Section ??, we stated the definitions of metrics for the case of isochronous ranked tree shapes and ranked
unlabeled genealogies. Here, we detail the distance calculation for heterochronous trees with the same
number of tips.
R
Following the notation and details of Section 3 of the appendix of Kim et al. [2019], let T1R , . . . , TM
be

heterochronous ranked tree shapes with n tips, and m1 , . . . mM sampling events respectively. In order to
compute pairwise distances, we require these trees to be represented by F-matrices of the same dimension.
We do this by considering the sequence of sampling and coalescent events for each tree, and inserting artificial
sampling events to align the sequences of the different trees. Note that the following formulation is done
going backwards in time with time increasing from the present to the past.
Here, we modified the proposed approach to increase computation speed. Instead of inserting artificial
sampling events one pair at a time, we insert all artificial sampling events needed by taking all trees at once.
(i)

(i)

That is, for i = 1, . . . , m, let E(i) = (emi +n‚àí1 , . . . , e1 ) be the vector of ordered sampling and coalescent
(i)

(i)

events of tree i, where emi +n‚àí1 denotes the most recent sampling event (emi +n‚àí1 = s), assumed to occur
at time

(i)
umi +n‚àí1

= 0. In particular,

(i)
(e1

(i)

= c) denotes the coalescent event at time u1 corresponding to
(i)

the most recent common ancestor of the leaves in TiR . Each ej

(i)

is either a sampling event (ej = s) or a

(i)

coalescent event (ej = c). The event of type c occurs n ‚àí 1 times and the event of type s occurs mi times
in E(i) .
We then transform all E(i) into extended vectors of higher dimension, in such a way that all vectors are of
the same dimension and all coalescent events are position in the same entries for all trees. We first align
all n ‚àí 1 coalescent events among all the trees by adding empty spaces when needed. Once all the type-c
events are aligned, we next align the sampling events between two successive coalescent events or between
t = 0 and the first c event. In each interval, we add additional sampling events to each tree if it has fewer
than the maximum number among the different trees. We denote these by a, and assign 0 new samples to
type-a events. We then construct the F-matrices and their corresponding modified and extended W matrices
following the construction in Kim et al. [2019].

B

Proof of Theorem 1

Proof. This proof builds on the Proof of Theorem 1 in the appendix of Kim et al. [2019]. We specialise to
the case of isochronous trees, in which all tips are sampled at time un = 0.
We want to define the mapping between Tn and Fn . Consider a given ranked tree shape T with n leaves.
We wish to construct F , the corresponding element of Fn , and show that this mapping is a bijection.
Remember that Fn is the space of (n ‚àí 1) √ó (n ‚àí 1) F-matrices, which are lower triangular square matrices
of non-negative integers that obey the following constraints:

32

F1 The diagonal elements are Fi,i = i + 1 for i = 1, . . . , n ‚àí 1 and the subdiagonal elements are Fi+1,i = i
for i = 1, . . . , n ‚àí 2.
F2 The elements Fi,1 , i = 3, . . . , n ‚àí 1, in the first column satisfy max{0, Fi‚àí1,1 ‚àí 1} ‚â§ Fi,1 ‚â§ Fi‚àí1,1 .
F3 All the other elements Fi,k , i = 4, . . . , n ‚àí 1 and k = 2, . . . , i ‚àí 2 satisfy the following inequalities:
max{0, Fi,k‚àí1 } ‚â§ Fi,k

(19)

Fi‚àí1,k ‚àí 1 ‚â§ Fi,k ‚â§ Fi‚àí1,k

(20)

Fi,k‚àí1 + Fi‚àí1,k ‚àí Fi‚àí1,k‚àí1 ‚àí 1 ‚â§ Fi,k ‚â§ Fi,k‚àí1 + Fi‚àí1,k ‚àí Fi‚àí1,k‚àí1

(21)

We first set up some notation. We view the tree as a branching process starting at the root, and ending
at the time when there are n leaves. Let each internal node of the ranked tree shape be labeled with the
number of branches in the tree immediately after it bifurcates, and let ui‚àí1 be the time at which node i
bifurcates. I.e. The root has label 2, and the last internal node has label n. Let Ii be the interval between
ui and ui+1 , i.e. the interval between the bifurcations of nodes i ‚àí 1 and i.
We define an intermediate matrix D of the same shape before defining F . Let D be an (n ‚àí 1) √ó (n ‚àí 1)
lower triangular matrix, where Dij is the number of descendants of node j + 1 (i.e. that were born at time
uj ), that have not yet bifurcated until ui+1 , i.e. the end of interval Ii . We see that Dij ‚àà {0, 1, 2}, and in
particular, we must also have:
D1 Dii = 2, i = 1, . . . n ‚àí 1.
D2 D(i‚àí1)j ‚àí 1 ‚â§ Dij ‚â§ D(i‚àí1)j ‚àÄ i, j.
D3 Exactly one of the branches bifurcates at time ui , i = 1, . . . , n ‚àí 1, i.e. ‚àÄ j,
i‚àí1
X

1{D(i‚àí1)j ‚àíDij =1} = 1,

j=1

where 1P is the indicator function, which is 1 if P is true and 0 otherwise.
We see that this matrix D is uniquely determined for any given binary ranked tree shape T . We can
reconstruct T given the matrix D by starting at the root and successively bifurcating branches according to
the column of D in which we observe a difference between D(i‚àí1)j and Dij . This shows that the space Tn is
in bijection with Dn , the space of matrices D that obey the conditions above. We now show that this space
is in bijection with Fn .
For a given matrix D, let œï(D) = F be given by
Fij =

j
X
k=1

33

Dik .

The inverse mapping is œï‚àí1 : Fn ‚Üí Dn which is given by
Dij = Fij ‚àí Fi(j‚àí1)
considering Fi0 = 0.
In terms of T , Fij denotes the total number of branches at time uj that have not bifurcated by time ui+1 , i.e.
the end of interval Ii . It is clear that the mapping œï : D 7‚Üí F is a one-to-one mapping. We are left to show
that the range of the mapping œï is exactly Fn . It suffices to show that œï(Dn ) ‚äÜ Fn and œï‚àí1 (Fn ) ‚äÜ Dn .
Consider a matrix D ‚àà Dn , and F = œï(D). After any branching
Pevent, thereis one node that has split,
Pi‚àí1
i‚àí1
and the rest are as they were. This translates to k=1 Dik =
k=1 D(i‚àí1)k ‚àí 1. Note F must satisfy
Fii = i + 1, as F11 = D11 = 2, and
Fii =

i
X

Dik = Dii +

k=1

i‚àí1
X

Dik = 2 +

k=1

i‚àí1
X

!
D(i‚àí1)k

‚àí 1 = F(i‚àí1)(i‚àí1) + 1

k=1

We will also have F(i+1)i = i, as
F(i+1)i =

i
X

D(i+1)k =

k=1

i
X

!
Dik

‚àí 1 = Fii ‚àí 1 = i

k=1

This shows that F satisfies condition F1.
We have Fi1 = Di1 ‚àÄ i. This shows condition F2 using D2 for j = 1.
Now we come to condition F3. F3.19 follows by non-negativity and the face that the columns of D are
monotonically decreasing. F3.20 follows using D3. F3.21 is equivalent to
0 ‚â§ (F(i‚àí1)k ‚àí Fik ) ‚àí (F(i‚àí1)(k‚àí1) ‚àí Fi(k‚àí1) ) ‚â§ 1
‚áê‚áí 0 ‚â§ (

k
X
j=1

D(i‚àí1)j ‚àí

k
X

k‚àí1
X

Dij ) ‚àí (

j=1

j=1

D(i‚àí1)j ‚àí

k‚àí1
X

Dij ) ‚â§ 1

j=1

‚áê‚áí 0 ‚â§ D(i‚àí1)k ‚àí Dik ‚â§ 1
which follows from D2 and D3. This shows that œï(Dn ) ‚äÜ Fn .
Now let F be an element of Fn and D = œï‚àí1 (F ).
We first see that Dii = Fii ‚àí F(i‚àí1)i = (i + 1) ‚àí (i ‚àí 1) = 2. This shows D1. Following the case above, we
see that F3.21 implies D2, and F3.20 implies D3. This shows that œï‚àí1 (Fn ) ‚äÜ Dn and completes the proof
of the bijection.

34

C

Proof of Proposition 2
(.)

(.)

Proof. Let G = (F G , uG ), H = (F, u) ‚àà Gn , two genealogies. Let u(.) = (u1 , . . . , un‚àí1 ) be the vector of
branching event times for (.) = G, H. For convenience, the weight matrix

w(u(.) ) = W (.)

Ô£´ (.)
(.)
u1 ‚àí u2
Ô£¨ (.)
Ô£¨u1 ‚àí u(.)
3
Ô£¨ (.)
(.)
Ô£¨
= Ô£¨u1 ‚àí u4
Ô£¨
..
Ô£¨
.
Ô£≠

Ô£∂
(.)

(.)

(.)

(.)

u2 ‚àí u3

(.)

u2 ‚àí u4

(.)
u1

(.)

u3 ‚àí u4

..
(.)
u2

...

.
(.)

...

Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑,
Ô£∑
Ô£∑
Ô£∏

un‚àí1

Pm
n(n ‚àí 1)
. We then can re-express d2 as d2 (G, H)2 := j=1 (FjG WjG ‚àí Fj Wj )2 .
2
Further, we assume that under ŒΩ, the tree topology and the coalescent times are independent, that is
Qn‚àí1
dŒΩ(H) = ¬µ(F ) j=1 f (uj | uj+1 )d(u) = ¬µ(F )f (u)d(u) and re-express Eq. 5 for d2 as follows:

is vectorized as w1 , . . . wm , m =

GÃÑ2 ‚àà

argmin

m
X

Z

X

G=(F G ,uG )‚ààGn F ‚ààF
j=1
n 0=u <u
n
n‚àí1 <¬∑¬∑¬∑<u2 <u1

(FjG WjG ‚àí Fj Wj )2 ¬µ(F )f (u)d(u).

G
G
G
G
G
G
becomes
Let IkG = uG
k ‚àí uk+1 with un = 0, and let I = (I1 , . . . , In‚àí1 ), then the weight matrix of W

Ô£´

g(I G ) = W G

Ô£∂

I1G

Ô£¨
Ô£¨
I1G + I2G
Ô£¨
Ô£¨ IG + IG + IG
=Ô£¨ 1
2
3
Ô£¨
..
Ô£¨
.
Ô£≠
G
G
I1 + ¬∑ ¬∑ ¬∑ + In‚àí1

I2G
I2G + I3G

I3G
..

I2G

+ ¬∑¬∑¬∑ +

G
In‚àí1

...

.

...

G
In‚àí1

Ô£∑
Ô£∑
Ô£∑
Ô£∑
Ô£∑,
Ô£∑
Ô£∑
Ô£∏

and
G

G

A(G) = A(F , I ) =

m
X

Z

X

(Fj wj (u) ‚àí FjG gj (I G ))2 ¬µ(F )f (u)d(u)

(22)

j=1
F ‚ààFn 0=u <u
n
n‚àí1 <¬∑¬∑¬∑<u2 <u1

To find the branching event time intervals I G that minimize A(G), we take the partial derivative of A(G), a
continuous function of I G , with respect to IkG . We exchange the order of summation and integration since
everything is positive and exchanging differentiation and integration we get
X
‚àÇA
=0=
G
‚àÇIk
F ‚ààF

n

Z

m
X

2 ¬∑ (Fj wj (u) ‚àí FjG gj (I G )) ¬∑ FjG ¬∑

0=un <un‚àí1 <¬∑¬∑¬∑<u2 <u1 j=1

m 
X X

‚àÇgj G
(I )¬µ(F )f (u)d(u).
‚àÇIkG

(23)


‚àÇgj G
‚àÇgj G
G 2
G
‚áí
¬∑ E[wj (u)] ¬∑
¬∑ G (I ) ¬∑ ¬µ(F ) ‚àí (Fj ) ¬∑ gj (I ) ¬∑ G (I ) ¬∑ ¬µ(F ) = 0. (24)
‚àÇIk
‚àÇIk
F ‚ààFn j=1
(
)
m
m
X
X
X
‚àÇgj G
‚àÇgj
¬µ(F )Fj =
FjG ¬∑ gj (I G ) ¬∑
(I ) ¬∑ FjG .
(25)
‚áí
FjG ¬∑ E[wj (u)] ¬∑ G (I G ) ¬∑
‚àÇI
‚àÇI
k
k
j=1
j=1
FjH

FjG

F ‚ààFn

35

Here the expectation is taken with respect to the joint density of u, i.e. E[wj (u)] =

R
u

wj (u)f (u)d(u). We

see that (25) is satisfied simultaneously for all k if we have:
FjG =

X

¬µ(F )Fj = E(Fj ),

F ‚ààFn

and
gj (I G ) = E[wj (u)],
for j = 1, . . . m = n(n ‚àí 1)/2. We note that the expected value E(F ) may not correspond to the FreÃÅchet
mean tree; although this is a solution, we are ignoring the constraints imposed to F .

D

A Markov chain on the space of ranked tree shapes

We drop the F matrix representation of ranked tree shapes and instead use two string representations of the
spaces of isochronous and heterochronous ranked tree shapes respectively. We use the string representations
to define two Markov chains on the corresponding spaces. An isochronous ranked tree shape is encoded
as a string of n ‚àí 1 integers t = (t1 , t2 , . . . , tn‚àí1 ), where tk indicates the parent node of the internal node
with ranking k + 1, k ‚àà {1, . . . , n ‚àí 1}. It is assumed that the first integer t1 of the string representation
is 1 (parent of root node). Figure 2 shows the string encodings of each of the 5 ranked tree shapes at the
bottom. The string representation was introduced earlier as the functional code for binary increasing trees
[Donaghey, 1975]. The set of all string representations of n ‚àí 1 elements are in bijection with the space of
isochronous ranked tree shapes of n leaves and the space of binary increasing trees of n ‚àí 1 nodes [Stanley,
1999].
To recover the tree T from the encoding t, we can proceed in a generative fashion: we start at the root which
has label 2, and proceed by bifurcating the leaves in the order determined by t. The space of strings Tn is
the set of all t strings of length n ‚àí 1 defined as follows:
Definition 10. (Isochronous string representation). A string t of non-negative integers that encodes an
isochronous ranked tree shape has the following defining properties:
1. t1 = 1
2. For i > 1, 2 ‚â§ ti ‚â§ i.
3. No entry of t can appear more than twice.
Definition 11. (Markov chain on isochronous strings). Let t ‚àà Tn be a string encoding an isochronous
ranked tree shape as described in Definition 10. We define a Markov chain on Tn as follows:
1. Pick an element i ‚àà 2, . . . , n uniformly at random.
2. Pick the value of ti uniformly at random from the allowable choices in 2, . . . , i, i.e. from those choices
that do not already appear twice among t‚àíi .

36

Figure 15: An example transition under the Markov chain of Definition 11 from (1, 2, 2, 3, 4) to (1, 2, 3, 3, 4).
The subtree of node 4 is plucked from under node 2 and planted under node 3.
Proposition 12. The Markov chain on isochronous strings (Definition 11) is ergodic with uniform stationary
distribution on the space of strings of length n ‚àí 1, or equivalently, on the space of ranked tree shapes with
n leaves.
Proof. Let t be an arbitrary element of Tn . We show that t is path connected to t‚àó = (1, 2, . . . , n ‚àí 1).
This string corresponds to the most unbalanced tree, also called the caterpillar or the comb tree. Since
the Markov chain is symmetric, t‚àó is path connected to every element of Tn as well and hence the chain is
irreducible. The following path has all transitions with positive probability:
t = t(0) = (1, t2 , t3 , . . . , tn‚àí2 , tn‚àí1 )
t(1) = (1, t2 , t3 , . . . , tn‚àí2 , n ‚àí 1)
t(2) = (1, t2 , t3 , . . . , n ‚àí 2, n ‚àí 1)
..
.
t(n‚àí3) = (1, t2 , 3, . . . , n ‚àí 2, n ‚àí 1)
t(n‚àí2) = (1, 2, 3, . . . , n ‚àí 2, n ‚àí 1) = t‚àó
Note that t(i) 7‚Üí t(i+1) is always a valid transition due to Property 10.3.
This representation can be extended to heterochronous trees as well, with additional entries indicating the
sampling events. We define these strings in the following way:
Definition 13. (Heterochronous string representation). A heterochronous ranked tree shape with n leaves
is encoded as a pair of strings (t, œÉ) each of length 2n ‚àí 1. As before, t is a string of non-negative integers
that indicates the parent nodes of internal nodes (coalescent events), however, t now also includes the parent
nodes of all leaves. The sequence order is given by the time they are created and œÉ is a 0 ‚àí 1 string that
indicates whether the corresponding node is internal (1) or a leaf (0). These strings have the following
defining properties:

37

1. t1 = 1, œÉ1 = 1
2. |{i : œÉi = 1}| = n ‚àí 1
3. |{i : œÉi = 0}| = n
4. Each element of {2, . . . n} occurs exactly twice in t.
Pi‚àí1
5. For each i > 1, 2 ‚â§ ti ‚â§ 1 + j=1 œÉj . We note that the string tœÉ = (ti : œÉi = 1) is a valid string encoding
an isochronous ranked tree shape.
For example, the string representation of the ranked tree shape of Figure 1(C) is (t = 123442365567788,
œÉ = 111100101100000). We note that the string tœÉ = (ti : œÉi = 1) is a valid string encoding of an isochronous
ranked tree shape. In addition, this representation can also admit extensions to multifurcating trees, which
we leave for future study.
While defining Markov chains on the space of ranked tree shapes is useful for Bayesian inference in areas
such as phylogenetics and phylodynamics, we rely on these chains for finding the FreÃÅchet mean via stochastic
combinatorial optimization (Section 3.3).
Definition 14. (Markov chain on heterochronous strings). Let (t, œÉ) be a pair of strings encoding an
heterochronous ranked tree shape as described in Property 13. We define a Markov chain on the space of
such strings, conditional on œÉ a fixed sequence of sampling and coalescent events, with transitions as follows:
1. Pick two distinct element i, j ‚àà 2, . . . , 2n ‚àí 1 uniformly at random. 2. Swap ti and tj . If the result is a
valid heterochronous string, accept the move, otherwise reject the move.
The Markov chain of Definition 14 on the space of ranked tree shapes with a given œÉ, i.e., with a given
sequence of sampling and coalescence events, is also symmetric, aperiodic (we can pick a pair with the same
label with positive probability) and irreducible. The proof of irreducibility is similar to the isochronous case
by considering only the coalescent events.
Proof. Let (t, œÉ) be the encoding of an arbitrary heterochronous ranked tree shape.
We first define (t‚àó , œÉ) which is the analogue of the caterpillar or the most unbalanced tree, but with the given
œÉ. Let t‚àóœÉ = (t‚àói : œÉi = 1) be equal to (1, 2, . . . , n ‚àí 1), and t‚àó‚àíœÉ = (t‚àói : œÉi = 0) be equal to (2, 3, . . . , n ‚àí 1, n, n).
We can follow a similar method as in the isochronous case and show that t is path connected to t‚àó by a
sequence of steps with positive probability. Note that t has length 2n ‚àí 1.
Let t(0) = t. We obtain t(i) by swapping two terms of t(i‚àí1) such that the last i terms of t(i) and t‚àó are
(i‚àí1)

equal. Explicitly, let j be the largest element in 2, . . . , 2n ‚àí i such that tj
and

(i‚àí1)
t2n‚àíi ,

(i‚àí1)

= t‚àó2n‚àíi . We can swap tj

since t‚àó2n‚àíi is the maximum allowable entry at position 2n ‚àí i, and hence

(i‚àí1)
t2n‚àíi

‚â§

(i‚àí1)
tj

which

satisfies Definition 13.5. The remaining conditions under Definition 13 are not affected by the transitions.
Iteratively, we obtain t(2n‚àí1) = t‚àó .

38

Since the Markov chain is symmetric, we see that t‚àó will be path connected to every t as well, and the
Markov chain is irreducible.

E

Proof of Theorem 8

Proof.

1. This follows by the Markovian property of the Yule model, since the i-th row of the F-matrix

is only determined by the state of the tree when it has i + 1 tips.
2. View P as the Yule model, in which we start with one leaf, and successively bifurcate an independently
choesn leaf at random. Let Di,j be the number of branches that were created after the j-th split (i.e.
when the node with label (j + 1) bifurcates), that have not bifurcated by interval i. We must have
P
Dij ‚àà {0, 1, 2}, and Fij = k‚â§j Dik .
We have D11 = F11 = 2, and Di1 = Fi1 ‚àà {0, 1} for i > 1.
For the children of node 2, i.e. when j = 1, Dij = 1 means that the extant branch descending from
node 2 has not bifurcated yet by interval i. Since at each step in the Yule model, the branch to split
is chosen at random, we have
P (Di1 = 1) =

i‚àí2 i‚àí1
2
2 3
√ó √ó ¬∑¬∑¬∑ √ó
√ó
=
3 4
i‚àí1
i
i

This implies
E[Di1 ] = P (Di1 = 1) =

(26)

2
i

(27)

Let j > 1. Then Dij = 2 means that neither of the branches descending from node (j + 1) have
bifurcated by interval i. By the same argument as above,
P (Dij = 2) =

j
i‚àí3 i‚àí2
j(j ‚àí 1)
j‚àí1
√ó
√ó ¬∑¬∑¬∑ √ó
√ó
=
j+1 j+2
i‚àí1
i
i(i ‚àí 1)

(28)

Now Dij = 1 means that exactly one branch descending from node (j + 1) has bifurcated by interval
i. We split this up according to the interval where this bifurcation occurs:

P (Dij = 1) =

i‚àíj
X

P (Dij = 1, D(j+k‚àí1)j ‚àí D(j+k)j = 1)

k=1

=

=

i‚àíj
X

k‚àí1
Y

k=1

l=1

i‚àíj
X
k=1

=

j+l‚àí2
j+l

!

2
√ó
√ó
j+k

i
Y
j+l‚àí1
j+l

!

l=k+1

2j(j ‚àí 1)
1
i
(j + k ‚àí 2)(j + k ‚àí 1)

2j(i ‚àí j)
i(i ‚àí 1)

(29)

39

We thus have
P (Dij = 0) = 1 ‚àí P (Dij = 1) ‚àí P (Dij = 2)
=

(i ‚àí j)(i ‚àí j ‚àí 1)
i(i ‚àí 1)

(30)

and
E[Dij ] = P (Dij = 1) + 2P (Dij = 2)
2j(i ‚àí j)
j(j ‚àí 1)
+2
i(i ‚àí 1)
i(i ‚àí 1)
2j
=
i
=

So
E[Fij ] =

X

(31)

j(j + 1)
i

E[Dik ] =

k‚â§j

(32)

3. Similar to Janson et al. [2011], we will use indicator variables tracking whether a specific external
branch is still present at each time interval. We will start by arbitrarily labeling the leaves and define
Zi,k as the indicator random variable that leaf i is still present when there are k branches, when viewing
it as a Tajima coalescent process, starting with n leaves and successively merging two at a time. Then
Pn
Fn‚àí1,k‚àí1 = i=1 Zi,k and for k ‚â§ l,
Cov(Fn‚àí1,k‚àí1 , Fn‚àí1,l‚àí1 ) =

n X
n
X

Cov(Zi,k , Zj,l ),

(33)

i=1 j=1

where
Cov(Zi,k , Zj,l ) = E(Zi,k Zj,l ) ‚àí E(Zi,k )E(Zj,l )

(34)

E(Zi,k Zj,l ) = P(Zi,k = Zj,l = 1)

(35)

is the probability that the external branch with label i and the external branch with label j remain
external branches when there are k and l branches respectively. That is, the probability that leaves i
and j do not coalesce when there are n, n ‚àí 1, . . . , l branches and when one of them do not coalesce
when there are l ‚àí 1, . . . , k. That is
n‚àí2
2
n
2



E(Zi,k Zj,l ) = P(Zi,k = Zj,l = 1) =

n‚àí3
2

n‚àí1
2

and
E(Zi,k ) = P(Zi,k = 1) =





¬∑¬∑¬∑

n‚àí1
2
n
2



k(k ‚àí 1)
Var(Zi,k ) =
n(n ‚àí 1)
40

l‚àí1
2

l+1
2

n‚àí2
2

n‚àí1
2

l‚àí1
2

l
2







k
2

k+1
2



¬∑¬∑¬∑

k
2

k+1
2



¬∑¬∑¬∑

k(k ‚àí 1)
1‚àí
n(n ‚àí 1)

=

=

(l ‚àí 1)(l ‚àí 2)k(k ‚àí 1)
,
n(n ‚àí 1)2 (n ‚àí 2)
(36)

k(k ‚àí 1)
,
n(n ‚àí 1)

(37)


,

(38)

(l ‚àí 1)(l ‚àí 2)k(k ‚àí 1) k(k ‚àí 1)l(l ‚àí 1)
‚àí
n(n ‚àí 1)2 (n ‚àí 2)
n2 (n ‚àí 1)2


(l ‚àí 1)(k ‚àí 1)k l ‚àí 2
l
=
‚àí
n(n ‚àí 1)2
n‚àí2 n
‚àí2(n ‚àí l)(l ‚àí 1)k(k ‚àí 1)
=
n2 (n ‚àí 1)2 (n ‚àí 2)

Cov(Zi,k Zj,l ) =

(39)

Cov(Z1,i , Z2,i ) = E(Z1,i Z2,i ) ‚àí E(Z1,i )E(Z2,i )


i i‚àí1
i2 (i ‚àí 1)2
‚àí2i(i ‚àí 1)2 (n ‚àí i)
2
2
=
= n n‚àí1 ‚àí 2
n (n ‚àí 1)2
n2 (n ‚àí 1)2 (n ‚àí 2)
2
2
(40)
and
Var(Fn‚àí1,i‚àí1 ) =

n
X

Var(Zj,i ) + n(n ‚àí 1)Cov(Z1,i , Z2,i )

j=1

=
=
=
=
=



i(i ‚àí 1)
i(i ‚àí 1)
‚àí2i(i ‚àí 1)2 (n ‚àí i)
1‚àí
+
n‚àí1
n(n ‚àí 1)
n(n ‚àí 1)(n ‚àí 2)
i(i ‚àí 1)
[n(n ‚àí 1)(n ‚àí 2) ‚àí i(i ‚àí 1)(n ‚àí 2) ‚àí 2(i ‚àí 1)(n ‚àí i)(n ‚àí 1)]
n(n ‚àí 1)2 (n ‚àí 2)
i(i ‚àí 1)
i(i ‚àí 1)2
‚àí
[i(n ‚àí 2) + 2(n ‚àí i)(n ‚àí 1)]
n‚àí1
n(n ‚àí 1)2 (n ‚àí 2)
2i(i ‚àí 1)2 (n ‚àí i)
i(i ‚àí 1) i2 (i ‚àí 1)2
‚àí
‚àí
n‚àí1
n(n ‚àí 1)2
n(n ‚àí 1)(n ‚àí 2)
2
i (i ‚àí 1)2
i(i ‚àí 1)(n ‚àí 2i)
+
(41)
(n ‚àí 1)2 (n ‚àí 2)
(n ‚àí 1)(n ‚àí 2)

So
Var[Fij ] =

j 2 (j + 1)2
j(j + 1)(i ‚àí 2j ‚àí 1)
+
i2 (i ‚àí 1)
i(i ‚àí 1)

4. We continue to show the results of covariance. First, when k ‚â§ l

Cov(Fn‚àí1,k‚àí1 , Fn‚àí1,l‚àí1 ) =

n X
n
X

Cov(Zi,k , Zj,l ) = n(n ‚àí 1)E(Z1,k Z2,l ) + nE(Z1,k ) ‚àí n2 E(Z1,k )E(Z1,l )

i=1 j=1

(l ‚àí 1)(l ‚àí 2)k(k ‚àí 1) k(k ‚àí 1) k(k ‚àí 1)l(l ‚àí 1)
+
‚àí
(n ‚àí 1)(n ‚àí 2)
n‚àí1
(n ‚àí 1)2
k(k ‚àí 1)[l(l + 1) + n(n ‚àí 2l ‚àí 1)]
=
(n ‚àí 1)2 (n ‚àí 2)
=

(42)

41

So when i1 = i2 , j1 ‚â§ j2 ,
Cov[Fi1 j1 , Fi2 j2 ] =

j1 (j1 + 1)[j2 (j2 + 2) + (i1 + 1)(i1 ‚àí 2j2 ‚àí 2)]
i21 (i1 ‚àí 1)

Now, when comparing values of the F matrix at different rows, for example Fn‚àí1,k‚àí1 and Fm‚àí1,k‚àí1
Pm
for k < n < m, we then assume that Fm‚àí1,k‚àí1 = i=1 Zi,k denotes the number of external branches
in a ranked tree shape with m leaves when there are k branches as before, however, when considering
it together with Fn‚àí1,k , Fn‚àí1,k denotes the number of external branches when there are k branches in
Pm
a ranked tree shape with n leaves. That is, when there are n branches, there are i=1 Zi,n external
Pm
branches with respect to the bigger tree but there are additional n ‚àí i=1 Zi,n branches that are
external with respect to the smaller tree. We then have
Ô£´
Cov(Fm‚àí1,k‚àí1 , Fn‚àí1,k‚àí1 ) = Cov Ô£≠Fm‚àí1,k‚àí1 , Fm‚àí1,k‚àí1 +

2m‚àín
X

Ô£∂
Zj,k Ô£∏

j=m+1

= Var(Fm‚àí1,k‚àí1 ) + m

2m‚àín
X

Cov (Z1,k , Zj,k )

(43)

j=m+1

where
Cov(Z1,k , Zm+1,k ) = E [Z1,k Zm+1,k ] ‚àí E[Z1,k ]E[Zm+1,k ]
 m‚àí3

 k‚àí1
m‚àí1
k
k
2
2
2
2
2

= m
m‚àí1 ¬∑ ¬∑ ¬∑ k+2 k+1 ‚àí m
=
=

2
2


k k‚àí1
2
 2 
m m‚àí2 ‚àí
2
2

=
=



2

2
2
 k
k
2
2

m
m‚àí1
2
2

k(k ‚àí 1)2 (k ‚àí 2)
k 2 (k ‚àí 1)2
‚àí
m(m ‚àí 1)(m ‚àí 2)(m ‚àí 3) m(m ‚àí 1)2 (m ‚àí 2)

k
m‚àí1
m‚àí4
k‚àí1
m‚àí2
2
2
2
2
2


¬∑
¬∑
¬∑


m
m‚àí1
m‚àí2
k+2
k+1
2
2
2
2
2


 k
k k‚àí1
k
2
2
2
2



‚àí
m
m m‚àí3
m‚àí2
2
2
2
2
2



Cov(Z1,k , Zm+2,k ) =

k
2

m‚àí1
2









k
k
2
2

m
m‚àí2
2
2



‚àí

(44)



k(k ‚àí 1) (k ‚àí 2)
k 2 (k ‚àí 1)2
‚àí
m(m ‚àí 1)(m ‚àí 3)(m ‚àí 4) m(m ‚àí 1)(m ‚àí 2)(m ‚àí 3)

(45)

and
2m‚àín
X

Cov (Z1,k , Zj,k ) =

j=m+1

m‚àín+1
X 
l=2

=

k(k ‚àí 1)2 (k ‚àí 2)
k 2 (k ‚àí 1)2
‚àí
m(m ‚àí 1)(m ‚àí l)(m ‚àí l ‚àí 1) m(m ‚àí 1)(m + 1 ‚àí l)(m ‚àí l)

k(k ‚àí 1)2 (k ‚àí 2)(m ‚àí n)
k 2 (k ‚àí 1)2 (m ‚àí n)
‚àí
m(m ‚àí 1)(m ‚àí 2)(n ‚àí 2)
m(m ‚àí 1)2 (n ‚àí 1)

42



=



k(k ‚àí 1)2 (m ‚àí n)
k‚àí2
k
‚àí
m(m ‚àí 1)
(m ‚àí 2)(n ‚àí 2) (m ‚àí 1)(n ‚àí 1)

(46)

Therefore,
k(k ‚àí 1)(m ‚àí 2k)
k 2 (k ‚àí 1)2
+
(m ‚àí 1)2 (m ‚àí 2)
(m ‚àí 1)(m ‚àí 2)


2
k(k ‚àí 1) (m ‚àí n)
k‚àí2
k
+
‚àí
(m ‚àí 1)
(m ‚àí 2)(n ‚àí 2) (m ‚àí 1)(n ‚àí 1)
k(k ‚àí 1)(k ‚àí n)(k ‚àí n + 1)
=
(m ‚àí 1)(n ‚àí 1)(n ‚àí 2)

Cov(Fm‚àí1,k‚àí1 , Fn‚àí1,k‚àí1 ) =

(47)

So when i1 > i2 , j1 = j2 ,
Cov[Fi1 j1 , Fi2 j2 ] =

j2 (j2 + 1)(j2 ‚àí i2 )(j2 ‚àí i2 + 1)
i1 i2 (i2 ‚àí 1)

For i < j, i < n and j < m
Cov(Fn‚àí1,i‚àí1 , Fm‚àí1,j‚àí1 ) = Cov(Fm‚àí1,i,‚àí1 +

2m‚àín
X

Zl,i , Fm‚àí1,j‚àí1 )

l=m+1

= Cov(Fm‚àí1,i‚àí1 , Fm‚àí1,j‚àí1 ) + Cov(Fm‚àí1,j‚àí1 ,

2m‚àín
X

Zl,i )

(48)

l=m+1

where

Cov(Fm‚àí1,j‚àí1 ,

2m‚àín
X

Zl,i ) = m(m ‚àí n)Cov(Z1,j , Zm+1,i )

l=m+1



j(j ‚àí 1) i(i ‚àí 1)
= m(m ‚àí n) E[Z1,j Zm+1,i ] ‚àí
m(m ‚àí 1) n(n ‚àí 1)


(j ‚àí 1)(j ‚àí 2)
i(i ‚àí 1)
j(j ‚àí 1) i(i ‚àí 1)
= m(m ‚àí n)
‚àí
m(m ‚àí 1) (n ‚àí 1)(n ‚àí 2) m(m ‚àí 1) n(n ‚àí 1)


(m ‚àí n)(j ‚àí 1)i(i ‚àí 1) j ‚àí 2
j
=
‚àí
(m ‚àí 1)(n ‚àí 1)
n‚àí2 n
(49)
Then, for i < j, i < n, j < m, and m > n


i(i ‚àí 1)[j(j + 1) + m(m ‚àí 2j ‚àí 1)] (m ‚àí n)(j ‚àí 1)i(i ‚àí 1) j ‚àí 2
j
Cov(Fn‚àí1,i‚àí1 , Fm‚àí1,j‚àí1 ) =
+
‚àí
(m ‚àí 1)2 (m ‚àí 2)
(m ‚àí 1)(n ‚àí 1)
n‚àí2 n
(50)

43

So when i1 > i2 , j1 > j2 ,
Cov[Fi1 j1 , Fi2 j2 ] =



j2 (j2 + 1)[(j1 + 1)(j1 + 2) + (i1 + 1)(i1 ‚àí 2j1 ‚àí 2)] (i1 ‚àí i2 )j1 j2 (j2 + 1) j1 ‚àí 1 j1 + 1
+
‚àí
i21 (i1 ‚àí 1)
i1 i2
i2 ‚àí 1
i2 + 1

Now, for j < i, i < n, j < m, and m > n
Cov(Fn‚àí1,i‚àí1 , Fm‚àí1,j‚àí1 ) = Cov(Fm‚àí1,i‚àí1 +

2m‚àín
X

Zl,i , Fm‚àí1,j‚àí1 )

l=m+1

= Cov(Fm‚àí1,i‚àí1 , Fm‚àí1,j‚àí1 ) + Cov(Fm‚àí1,j‚àí1 ,

2m‚àín
X

Zl,i )

l=m+1

(51)
where

Cov(Fm‚àí1,j‚àí1 ,

2m‚àín
X

Zl,i ) = m(m ‚àí n)Cov(Z1,j , Zm+1,i )

l=m+1



j(j ‚àí 1) i(i ‚àí 1)
= m(m ‚àí n) E[Z1,j Zm+1,i ] ‚àí
m(m ‚àí 1) n(n ‚àí 1)


(i ‚àí 1)(i ‚àí 2)
j(j ‚àí 1)
j(j ‚àí 1) i(i ‚àí 1)
= m(m ‚àí n)
‚àí
m(m ‚àí 1) (n ‚àí 1)(n ‚àí 2) m(m ‚àí 1) n(n ‚àí 1)


(m ‚àí n)(j ‚àí 1)j(i ‚àí 1) i ‚àí 2
i
=
‚àí
(m ‚àí 1)(n ‚àí 1)
n‚àí2 n
(52)
Then, for j < i, i < n, j < m, and m > n:


j(j ‚àí 1)[i(i + 1) + m(m ‚àí 2i ‚àí 1)] (m ‚àí n)(j ‚àí 1)j(i ‚àí 1) i ‚àí 2
i
Cov(Fn‚àí1,i‚àí1 , Fm‚àí1,j‚àí1 ) =
+
‚àí
(m ‚àí 1)2 (m ‚àí 2)
(m ‚àí 1)(n ‚àí 1)
n‚àí2 n
(53)
So when i1 > i2 , j1 < j2 ,
Cov[Fi1 j1 , Fi2 j2 ] =

F



j1 (j1 + 1)[(j2 + 1)(j2 + 2) + (i1 + 1)(i1 ‚àí 2j2 ‚àí 2)] (i1 ‚àí i2 )j1 (j1 + 1)j2 j2 ‚àí 1 j2 + 1
+
‚àí
i21 (i1 ‚àí 1)
i1 i2
i2 ‚àí 1
i2 + 1

Temperature schedules for Simulated Annealing

We now consider the choice of temperature schedule in the Simulated Annealing (SA) algorithm of Section
3.3. in the main document. The parameters to be chosen are whether we use a logartihmic, linear, or
44

Figure 16: Example energy runs a simulated annealing chain, with trees on n = 100 tips. Three runs each
for the logarithmic (green), linear (red), and exponential (blue) schedules. We observe that the exponential
schedule with Œ± = .9995 has the best performance.
exponential cooling regime, as well as the initial temperature R0 , and cooling rate Œ±. Theoretical convergence
guarantees exist for the logarithmic cooling schedule Rk = R0 (1+Œ± log(1+k))‚àí1 with sufficiently high initial
temperature and appropriately chosen Œ± (see Chapter 3 of Aarts and Korst [1988]). Other options include
the linear schedule Rk = R0 (1 + Œ±k)‚àí1 , or the exponential cooling schedule Rk = R0 Œ±k . In practice, the
logartithmic schedule is very inefficient and better choices may be made for each different problem.
In our simulations, we observed that the exponential cooling schedule with Œ± = .9995 works well for trees
with upto n = 250 tips. We note the logarithmic schedule is prohibitively slow, and we do not gain much
by using the linear schedule over the exponential schedule.

G

SARS-CoV-2 Posterior Inference and Sample Information

We accessed a global alignment of SARS-CoV-2 publicly available molecular sequences obtained from infected
human individuals on November 4, 2020 in the GISAID EpiCov database [Shu and McCauley, 2017]. We
analyzed a subset of available sequences sampled in the states of California, Florida, Texas and Washington
in the USA for the period of February 2020 to September 2020. We analyzed 19 random samples of 100
sequences in California and 3 random samples of 100 sequences in the rest of the states. We independently
sampled genealogies from the posterior distribution for each random sample independently with BEAST
[Suchard et al., 2018]. In BEAST, we placed the HKY mutation prior on the substitution process with fixed
global mutation rate of 8 √ó 10‚àí4 substitutions per site per year as it has been done in other studies [Nadeau
et al., 2021], and we placed the Skyride process prior on the coalescent effective population size [Minin et al.,
2008]. We ran each chain for 50 million iterations and thinned every 5000 iterations.
We acknowledge the following submitting and originating laboratories that made the sequences used in this
manuscript available in GISAID: San Diego County Public Health Laboratory, Quest Diagnostics, UCLA
Pathology Clinical Microbiology Lab, Cedars-Sinai Medical Center, Department of Pathology & Laboratory

45

Medicine, Molecular Pathology Laboratory, San Joaquin County Public Health Lab, Orange County Public
Health Laboratory, UCSF Clinical Microbiology Laboratory, UC San Diego Center for Advanced Laboratory Medicine, County of Santa Clara Public Health, Scripps Medical Laboratory, California Department of
Public Health, Ventura County Public Health Lab, Rady‚Äôs Childrens Hospital, Stanford clinical virology lab,
Santa Clara County Public Health Department, County of Santa Clara Public Health Department, Humboldt County Public Health Laboratory, Department of Immunology, Contra Costa Public Health Lab, San
Francisco Public Health Laboratory, National Institute for Communicable Disease Control and Prevention
(ICDC) Chinese Center for Disease Control and Prevention (China CDC), Innovative Genomics Institute,
UC Berkeley, San Bernardino County Public Health Lab, Alameda County Public Health Lab, California Department of Health, County Of San Luis Obispo Public Health Laboratory, University of California, Davis,
Andersen Lab, Microbial Diseases Laboratory, University of Wisconsin-Madison AIDS Vaccine Research
Laboratories, OHSU Lab Services Molecular Microbiology Lab, San Luis Obispo Public Health Department,
Tuolumne County Public Health, FL Bureau of Health Laboratories Tampa, Florida Bureau of Public Health
Laboratories, Florida Department of Health, Public Health, United States Air Force School of Aerospace
Medicine, University of Florida, FL Bureau of Public Health Laboratories-Miami, University of Miami Immunology and Histocompatibility Laboratory, FL Bureau of Public Health Laboratories, Laboratory of Dr.
John Lednicky, Environmental and Global Health, University of Florida - Gainesville, FL Bureau of Public
Health Laboratories-Tampa, Mayo Clinic Laboratories, University of Florida, FL Bur. of Public Health
Laboratories-Jacksonville, Emerging Pathogens Institute, University of Florida, Environmental and Global
Health, Texas DSHS Lab Services, Houston Methodist Hospital, Texas Department of State Health Services,
LSUHS Emerging Viral Threat Laboratory, Texas Department of State Health Services (TXDSHS), Baylor
College of Medicine, City of El Paso Department of Public Health Laboratory, Washington State Department
of Health, University of Washington Virology Lab, WA State Department of Health, University of Washington, Laboratory Medicine, Laboratory Medicine, University of Washington, Washington State Public Health
Lab, Harborview Medical Center, Andersen lab at Scripps Research, Kruglyak Lab, Cedars-Sinai Medical
Center, Molecular Pathology Laboratory of Department of Pathology & Laboratory Medicine and Genomic
Core, Chan-Zuckerberg Biohub, Chiu Laboratory, University of California, San Francisco, Q Squared Solutions - QRTP facility, Pathogen Discovery, Respiratory Viruses Branch, Division of Viral Diseases, Centers
for Disease Control and Prevention, Oregon SARS-CoV-2 Genome Sequencing Center, Ginkgo Bioworks
Clinical Laboratory, University of Florida, Microbial Genome Sequencing Center.

46

