The Interplay of Demographic Variables and Social
Distancing Scores in Deep Prediction of U.S. COVID-19
Cases ‚àó
arXiv:2101.02113v1 [cs.SI] 6 Jan 2021

Francesca Tang‚Ä†

Yang Feng‚Ä°

Hamza Chiheb¬ß

Jianqing Fan¬∂

January 7, 2021

Abstract
With the severity of the COVID-19 outbreak, we characterize the nature of the growth
trajectories of counties in the United States using a novel combination of spectral clustering and the correlation matrix. As the U.S. and the rest of the world are experiencing a
severe second wave of infections, the importance of assigning growth membership to counties
and understanding the determinants of the growth are increasingly evident. Subsequently,
we select the demographic features that are most statistically significant in distinguishing
the communities. Lastly, we effectively predict the future growth of a given county with an
LSTM using three social distancing scores. This comprehensive study captures the nature
of counties‚Äô growth in cases at a very micro-level using growth communities, demographic
factors, and social distancing performance to help government agencies utilize known information to make appropriate decisions regarding which potential counties to target resources
‚àó

Tang and Feng contribute equally to this work.
Department of Operations Research and Financial Engineering, Princeton University, Princeton, NJ
(email: frtang@princeton.edu).
‚Ä°
Department of Biostatistics, New York University, New York City, NY (yang.feng@nyu.edu).
¬ß
New York City, NY (hamza.chiheb@gmail.com).
¬∂
Department of Operations Research and Financial Engineering, Princeton University, Princeton, NJ
(jqfan@princeton.edu).
‚Ä†

1

and funding to.
Keywords: COVID-19, Stochastic Block Model, Spectral Clustering, Community Detection, Machine Learning, Neural Network.

1

INTRODUCTION

The recent infectious disease (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has overtaken the world as the largest pandemic we have seen in
decades. The World Health Organization (WHO) labeled it a pandemic on 03/11/2020, with
a total of more than 85 million cases and more than 1.84 million deaths worldwide as of
01/04/2021.
Forecasting the growth of confirmed cases and the locations of future outbreaks has been
a persistent challenge in the public health and statistical fields. With the gravity and urgency of the global health crisis, many recent works including Kucharski et al. (2020) and
Peng et al. (2020) have attempted to model the growth in cases in various countries. Most
of the literature on statistical modeling of the data focuses on the reproduction number.
However, this value is constantly evolving and is not always a valuable measurement to build
prediction models with. Hong and Li (2020) proposed a Poisson model with time-dependent
transmission and removal rates to estimate a time-dependent disease reproduction number.
Betensky and Feng (2020) studied the impact of incomplete testing on the estimation of
dynamic doubling time. Ultimately, we need to examine the underlying features contained in
the time series data in order to extract valuable insights into the unique nature of the spread
of COVID-19. As the number of deaths is at least a two-week lagging indicator compared
to the number of confirmed cases, we only look at the latter. More importantly, the matrix
of the number of deaths per county would be very sparse at the initial stage, making any
analysis more difficult. Our goal is to characterize and project the disease progression given
the limitations of public data from a theoretical yet practical perspective.

2

Stochastic block models (SBMs), first developed by Holland et al. (1983), has long been
studied as a powerful statistical tool in community detection, where the nodes or members are partitioned into latent groups. SBMs have been employed to study social networks
Wasserman and Anderson (1987), brain connectivity Rajapakse et al. (2017), protein signaling networks Chen and Yuan (2006), and many others. Under an SBM, the nodes within the
same group usually have a higher probability of being connected versus those from different
groups. The difficult task is to recover these connectivities and the communities based on
one observation, which in our case, is a snapshot of the changes in the number of cases up
to the most recent time point. In more recent years, spectral clustering (Balakrishnan et al.,
2011; Rohe et al., 2011; Jin, 2015a; Lei and Rinaldo, 2015) has arisen as one of the most
popular and widely studied approaches to recover these communities. Conventional spectral
clustering algorithms mostly involve two steps: eigen-decompose the adjacency or Laplacian
matrix of the data and then apply a clustering algorithm, such as k-means, to the eigenvectors that correspond to the largest or smallest eigenvalues. There is extensive literature on
such procedures, for instance von Luxburg (2007), Ng et al. (2001), Abbe (2017), etc.
In this study, we introduce the unique procedure of conducting spectral clustering on the
sample Pearson correlation coefficient matrix directly and compare its clusters to the standard Laplacian embedding. This complements Brownlees et al. (2020+)‚Äôs approach based
on a latent covariance model on financial return data. Gilbert et al. (2020) used agglomerative clustering, an unsupervised learning method, on preparedness and vulnerability data in
African countries using self-reported reports of capacity and indicators. While a comprehensive study, it only considers the possible exposures to travelers from China. Using a different
dataset, Hu et al. (2020) clustered the data from China by implementing a simple k-means
clustering directly on various features of the provinces/cities and not on the eigenvectors of
the correlation matrix. It also doesn‚Äôt take into account possible explanatory features that
aren‚Äôt directly related to the number of cases and fails to predict provinces that have yet to

3

have cases. The data processing of some existing approaches also do not standardize and
shift the data in a way that aligns with the nature of COVID-19.
Once the communities are found, the subsequent part uncovers the statistically significant
demographic features, pre-existing in the counties, that could largely explain a county‚Äôs community membership. Most of the existing research on salient demographic information focus
on age-related features and the presence of co-morbidities or underlying health conditions
e.g. Dowd et al. (2020) and Lippi et al. (2020). In reality, what influences how the disease
progresses in a county is most likely a confluence of variables, and not one or two prevailing
ones. Some studies also examine how various demographic determinants affect how well a
county carries out social distancing (Im et al., 2020), but offers little or no connection to the
nature of the growth curve.
The extracted variables from the feature analysis part are then used in conjunction with
time series of social distancing scores from Unacast (2020) to fit a recurrent neural network,
ultimately predicting the progression of confirmed cases in a given county. It is important
to note that for this prediction section, we use the period from the start of the pandemic
until 07/20/2020 as this traces the first large spike in cases in the U.S. and a subsequent
plateau. This gives a long enough time series sample and to include much more recent data
would include the second large wave of the pandemic, which is counter to the objective of
capturing the growth trajectory of a county‚Äôs peak and fall. Unacast has created a scoreboard
of social distancing measures with mobile device tracking data, where a device is assigned to a
specific county based on the location the device spent the most amount of time in. The neural
network prediction takes these static, inherent county variables, community membership (the
clustering results), and social distancing data to predict the future growth of confirmed cases.
There have been several studies that predict, estimate, or model the growth curve of the
disease, including Fanelli and Piazza (2020) on the cases in Italy, Roda et al. (2020) on the
cases in Wuhan, and Liu et al. (2020) on the cases in China. In addition, deep learning has

4

Figure 1: Pipeline of this study‚Äôs three-part analysis of COVID-19. COVID-19 time series data is first
used to perform community detection, clustering counties into several communities. Then, demographic
features are incorporated to extract the most significant features that distinguish the growth communities.
Finally, social distancing metric time series are added to the results to the previous two parts to carry out
the prediction of COVID-19 cases for new counties.
been applied to COVID-19 research, such as Wang and Wong (2020) that detect positive cases
through chest scans. Other studies such as Zheng et al. (2020b) investigate when patients
are most infectious by using a deep learning hybrid model and Yang et al. (2020) similarly
combines the epidemiological SIR model with an LSTM network. However, the literature on
COVID-19 still lacks any comprehensive approach on a county-level that creates a throughline
of the pandemic: historical growth curve of confirmed cases, characterization of this growth
via clustering, the significant explanatory demographic features, and finally, social distancing
measures that give insight into the nature of the future growth trajectory, as displayed in
Figure 1. Table 1 also contains the specific time period, the number of counties N , and the
data source used for each part of the paper (Part I: community detection, Part II: extraction
of significant features, Part III: prediction) as outlined in Figure 1.

5

Part I
Part II
Part III

Time Period(s)

No. of counties N

1/22/20 - 4/17/20 and 5/10/20 - 7/10/20
1/22/20 - 4/17/20 and 5/10/20 - 7/10/20
2/25/20 - 7/10/20

950
633
627

Source
Johns Hopkins CSSE
ACS (c/o Data Planet)
Unacast

Table 1: Time period, number of counties, and data source used for each part of the paper.

2

COMMUNITY DETECTION

The first part of this paper finds potential communities among the counties, in which clusters
share similar growth patterns. To accomplish this, two fundamental concepts are necessary:
the stochastic block model and spectral clustering. The former is a generative model through
which community memberships were formed and the latter is a methodology often utilized to
recover these memberships. Compared to traditional clustering methods, spectral clustering
has shown to be effective in both statistical and computational efficiency (Abbe, 2017; Abbe
et al., 2020). Our approach applies spectral clustering to the correlation matrix, instead
of the commonly used adjacency matrix or Laplacian matrix. The goal is to recover the
county membership matrix embedded in the correlations of each county‚Äôs logarithmic daily
cumulative number of cases.

2.1

Correlation matrix vs. adjacency matrix

For each county, consider a daily time-series of the cumulative number of confirmed cases,
where we use curve registration (the time origin is set as the day on which the number of
cases exceeds 12 for a particular county). This curve registration is important as it takes
into account the fact that counties may have different COVID-19 outbreak starting times.
We denote wi,t = log(xi,t ) as the logarithmic cumulative number of cases of county i on the
t-th day since the county hit 12 or more cases. Then, we use the Pearson correlation as a
similarity measure, defined as

6

PTij

‚àí wÃÑi )(wj,t ‚àí wÃÑj )
q
,
PTij
2
2
t=1 (wi,t ‚àí wÃÑi )
t=1 (wj,t ‚àí wÃÑj )

Rij = qP
Tij

t=1 (wi,t

(1)

where Tij = min(Ti , Tj ), with Ti and Tj being the number of days county i and county j
has 12 or more cases, respectively. The sample correlation R ‚àà Rn√ón would then contain
the pairwise correlations among all n counties. The logarithmic cumulative case counts are
used to align with the exponential growth pattern implied by popular epidemic models. For
example, we could distinguish between a faster exponential growth function such as exp(2t)
and a slower growth function exp(t/2).
Another commonly used network representation is the adjacency matrix A, which shows
whether two counties are connected and is often constructed based on a similarity measure
like Pearson correlation or a mutual information score. If the graph is undirected, where each
edge that connects two nodes is bidirectional, A is symmetric. The two most common types
of similarity graphs are the -neighborhood graph and the k‚àínearest neighbor graph. As
we‚Äôre using sample correlation as the similarity measure, an -neighborhood adjacency A1 is
defined as follows:
(A1 )ij =

Ô£±
Ô£¥
Ô£¥
Ô£≤1, if Rij ‚â• 1 ‚àí ,

(2)

Ô£¥
Ô£¥
Ô£≥0, otherwise.
A k‚àínearest neighbor adjacency A2 is defined as follows:

(A2 )ij =

Ô£±
Ô£¥
Ô£¥
Ô£¥
1, if county i is among j‚Äôs k nearest neighbors
Ô£¥
Ô£¥
Ô£¥
Ô£≤
or if county j is among i‚Äôs k nearest neighbors,
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£¥
Ô£≥0, otherwise,

(3)

where the nearest neighbors are found with respect to Rij .
Depending on the parameters  and k one chooses for A1 and A2 , respectively, a significant

7

amount of information could be lost in the process because of the thresholding operation.
However, this operation also filters out many spurious correlations. Unlike the sparse A1 and
A2 , R retains all of the pairwise similarities between counties, which would shed more light
on the within-group and between-group relationships.

2.2

Stochastic Block Model (SBM)

The matrices R, A1 , and A2 are critical because they can help us recover Œò, an n √ó K
membership matrix that reflects which community each county belongs to, where K is the
number of communities. Letting Zi ‚àà {1, ..., K} be the community that county i belongs to,
the ith row of Œò has exactly one 1 in column Zi (the community that county i belongs to) and
0 elsewhere. We estimate Œò under an SBM, where the probability two counties are connected
only depends on the membership of these two counties. An SBM denoted by G(n, B, Œò) as n
nodes, K communities, and is parameterized by Œò and B, the K √óK symmetric connectivity
matrix. Essentially, B contains the inter- and intra-community connection probabilities: the
probability of an edge between counties i and j is BZi Zj .
b of Œò from an observed adjacency
The objective is to obtain an accurate estimation Œò
matrix A that is modeled as G(n, B, Œò). This yields an recovery of the partitions Gk :=
bk = {i : Zbi = k, i = 1, ..., n}, k = 1, ..., K, with an ambiguity
{i : Zi = k, i = 1, ..., n} by G
b The
of permutation of clusters, where Zbi indicates the location of 1 in the ith row of Œò.
population matrix P ‚àà Rn√ón , where Pij is the probability that counties i and j are connected,
is naturally expressed as P = ŒòBŒòT .

2.3

Spectral Clustering

Spectral clustering has been a popular choice for community detection (Rohe et al., 2011; Jin,
2015a; Lei and Rinaldo, 2015). The central idea is to relate the eigenvectors of the observable
adjacency matrix A to those of P = ŒòBŒòT , which is not observed. This is accomplished
8

by expressing A as a perturbation of its expected value: A = E[A] + (A ‚àí E[A]). If we
treat E[A] as the signal part and A ‚àí E[A] as the noise, we connect the eigenvectors of A
and P using E[A] = P ‚àí diag(P ). Noting rank(P ) = K, letting U n√óK = [u1 , ..., uK ] be
the eigenspace spanned by the K nonzero eigenvalues of E[A], then columns of U span the
same linear space as those spanned by the columns of P (ignoring diag(P )). Additionally, P
b be the eigenspace corresponding to the K
has the same column space as Œò. Now, letting U
b is a consistent estimate of U or the column space
largest absolute eigenvalues of A, then U
of Œò, under some mild conditions. To resolve the ambiguity created by rotation, the k-mean
algorithm is applied to the normalized row of U to identify membership of communities
(Rohe et al., 2011; Lei and Rinaldo, 2015).
Instead of examining the eigenvalues of A, spectral graph theory has long studied graph
Laplacian matrices as a tool of spectral clustering. The symmetric Laplacian matrix is
defined as follows: letting D = diag(d1 , ..., dn ) be the diagonal degree matrix where di =
Pn
j=1 Aij , then a popular definition of a normalized, symmetric Laplacian matrix is L =
I ‚àí D ‚àí1/2 AD ‚àí1/2 . When clustering with L, one takes the eigenvectors corresponding to the
smallest eigenvalues in absolute value.
In our context, A can be taken as either A1 or A2 as outlined in subsection 2.1. As there
are no exact rules in choosing the parameters  and k of A1 and A2 , respectively, clustering
with L, which depends on the adjacency matrix, maybe less than ideal. It is also an added,
often computationally cumbersome step. Instead, we cluster directly on the similarity matrix
R, the sample correlation matrix. Algorithm 1 delineates the detailed steps of this approach.
The classic spectral clustering procedure with L used as a benchmark is outlined in the
Supplementary Material.
There are several methods for choosing the number of spiked eigenvalues in the context
of factor models: scree-plot, eigen-gap, eigen-ratio, adjusted correlation thresholding. As our
method involves correlations, we apply the adjusted correlation method in Fan et al. (2020).

9

Algorithm 1 Spectral clustering on correlation matrix
Input Sample correlation matrix R ‚àà Rn√ón and the number of clusters K.
1: Compute the largest K eigenvectors in absolute value u1 , ..., uK of R and construct
b ‚àà Rn√óK be the matrix with the eigenvectors as columns.
U
b to have unit norm to get U
b norm .
2: Normalize rows of U
b
3: Cluster the rows of U norm with k-means.
b1 , ..., G
bK of the nodes.
return Partition G
This method leads to K = 2, which roughly divides the counties into faster or slower growth
communities. It also agrees with the choice where we maximize the eigen-gap.

2.4

Clustering procedure

To compare and visualize the eigenvalues of R,
Figure 2‚Äôs left panel displays how dominant the
first eigenvalue is compared to the rest.
Figure 3 is a visual- Figure 2: The left panel is the 10 largest eigenvalues of R. The right
ization of the first two panel has the same 10 eigenvalues but zoomed-in on the y-axis.
eigenvectors of R and the linear separation that the algorithm partitioned all the counties
into. The left panel is with unit norm normalization and the right is without the normalization. The result of essentially using the signs of the components in the second eigenvector
to cluster reminiscences the work by Abbe et al. (2020) with strong theoretical support.
From now on, all clustering analysis will be based on the unit-norm normalization of the
eigenvectors.

2.5

Fastest and Slowest Growth Clusters

10

For future analysis (section 2.7), it is useful
to define the clusters
that contain the counties with the fastest and
slowest growth.

Af-

ter the clusters are
Figure 3: The left panel is the first two unit-norm normalized eigenvectors of R and the corresponding clusters, Group 1 in blue and
rithm 1, for every com- Group 2 in purple. The right panel depicts the same two clusters
but in the two un-normalized eigenvectors.
munity k, we calculate
produced with Algo-

the average exponential growth rates of the counties in that community. This is done by
fitting the total number of cases of each county i on day t, xi,t , to xi,t = xi,0 (1 + ri )t + Œµi,t
through nonlinear least squares and obtaining the approximated growth rate ri for county
bk | P b ri and standard error
i. Then, we compare the average fitted growth rate rbk = 1/|G
i‚ààGk
for clusters k = 1, ..., K. The fastest growth cluster is defined as argmaxk rbk and the slowest
growth cluster is defined as argmink rbk .

2.6

Data

We use the COVID-19 (2019-nCoV) Data Repository by the Johns Hopkins Center for Systems Science and Engineering (CSSE) that contains data on the number of confirmed cases
and deaths in the United States and around the world, broken down by counties in the U.S.
The public database is updated daily and the virtual dashboard is also used widely around
the world. Data sources of the database include the World Health Organization (WHO),
US Center for Disease Control (CDC), BNO News, WorldoMeters, and 1point3acres. We
take all counties that have 12 or more cumulative cases in the time frame of 01/22/2020 to
04/17/2020. We treat the day a county reaches 12 or more confirmed cases as day one and
11

Group 1

Group 2

M odel

No. of Counties

Growth Rate

R
A1
A2
R, second phase

467
462
470
487

0.1589
0.1583
0.1605
0.0207

SE
0.0020
0.0020
0.0020
0.0005

No. of Counties

Growth Rate

SE

483
488
470
463

0.1704
0.1677
0.1664
0.0233

0.0019
0.0019
0.0020
0.0005

Table 2: Average growth rates and the number of counties in each cluster for K = 2. Model R corresponds
to Algorithm 1 where we use the sample correlation matrix. Model A1 corresponds to Algorithm 4 where
we use the k-nearest neighbors graph (k = 7). Model A2 corresponds to Algorithm 4 where we use the
b 1 and G
b 2 , respectively.
-neighborhood graph ( = 0.007). Groups 1 and 2 are the obtained partitions G
Growth Rate is the approximated exponential growth rate, calculated as in subsection 2.5. Presented are the
averages of these growth rates and their associated SEs for the counties in two groups, clustered by different
methods. R, second phase is for the clusters obtained for the period 05/10/2020 - 07/10/2020.

Group

1

2

1
2

96.1% 94.0%
94.0% 96.8%

Table 3: R average block correlations K = 2.
then discard all counties that have a time series of fewer than 14 days after processing. This
way we shift each county to a similar starting point in terms number of cases and a long
enough period to do a meaningful analysis with. We also remove unassigned cases and U.S.
territories, which ultimately results in a total of 950 counties. As mentioned before, we use
wi,t = log(xi,t ) to represent the logarithmic cumulative cases for county i on day t.
We also repeat the community detection process with more recent data from 05/10/2020,
when many states started to reopen, to 07/10/2020. The bulk of this part of the study
concentrates on the beginning phase of the pandemic given that health and government
intervention to minimize the number of future cases should be executed as early as possible.
However, we compare the resulting communities with more recent data that captures the
second phase of the pandemic in the U.S. States experienced a significant drop in cases when
lockdown was enforced and businesses were closed but as they began to reopen, the number
of cases saw an uptick once again. Since this second phase comes months after the initial
outbreak, there may be meaningful differences worthy of analysis.
12

2.7

Results and Discussion

We can see from Table 2 that for the clusters obtained
by Algorithm 1 (R), the difference between the growth
rates of Group 1 and Group 2 is the largest. This is
validated by the discernible difference in trajectories,
shown in Figures 5 and 6. The standard error bands
in Figure 5 underscores that the two groups become
more distinct in their growth trajectory as time goes
on: the overlap between the bands of the two groups
Figure 4: R Heatmap of block correladecreases over time. For A1 and A2 , the growth rates tions K = 2. Model R corresponds to Algorithm 1 where we use the sample correlation

are much closer together between the two communi- matrix. Groups 1 and 2 are the obtained
ties. Furthermore, the right panel of Figure 6 is a plot

b 1 and G
b 2 , respectively.
partitions G

of the average cases for the period after community detection was performed: 04/17/2020 09/03/2020. Evidently, the separation between the two groups becomes much more distinct
as time goes on (much larger number of cases). As for community detection of the subsequent
phase of the pandemic in the U.S. (from 05/10/2020 - 07/10/2020), the last row of Table 2
again shows a larger average growth rate for Group 2, albeit much smaller in magnitude since
cases increased at a slower rate once the country learned how to deal with the pandemic.
Table 3 contains information on the average intra- and inter-group correlations, a sample reflection of B. Evidently, the intra-community correlations are higher than the intercommunity correlations. Group 1‚Äôs intra-correlation of 96.1% and Group 2‚Äôs 96.8% are greater
than 94.0%, the inter-group correlation between the two groups. As we only took counties
with significant outbreaks as of 04/17/2020, it is logical to observe high correlations across
the board. These results are also mirrored in Figure 4, a heatmap of the block correlations.
Some notable counties that are partitioned to Group 2, the fast growth community, include
Los Angeles, CA; San Francisco, CA; District of Columbia; DeKalb, GA; Fulton, GA; Miami13

Figure 5: The left panel represents the average cumulative number of cases of the initial phase 01/22/2020
- 04/17/2020 with one standard error bands for the clusters of R, K = 2. The right panel is the average
log cumulative number of cases of R, K = 2. The x-axis is in calendar time, which does not account for
heterogeneous starting times of the outbreak in each county.

Figure 6: The left panel represents average cumulative number of cases of the initial phase 01/22/2020 04/17/2020, starting from the first day of at least 12 days for the clusters of R, K = 2. The right panel
is the average cumulative number of cases of the period 04/18/2020 - 09/03/2020, the time frame after the
initial phase used in community detection. The x-axis here accounts for the heterogeneity of the outbreak of
COVID-19 in each county.

Figure 7: Clusters for model R of the initial phase 01/22/2020 - 04/17/2020. Model R corresponds to
b 1 and
Algorithm 1 where we use the sample correlation matrix. Groups 1 and 2 are the obtained partitions G
b
G2 , respectively.

14

Figure 8: Growth curves of clusters obtained from community detection on data from 05/10/2020 07/10/2020 (recent phase). Plots are the same as those of Figure 6.

Dade, FL; Cook, IL; Jefferson, LA; Suffolk, MA; Bergen, NJ; New York, NY; Westchester,
NY; and King, WA, all large epicenters. Figure 7 is a geographical visualization of the
communities.
In addition, Figure 8 shows the same plots as those in Figure 6 but for a later phase.
The curves are clearly much flatter in both groups, which is likely due to the increase in
the number of cases plateauing in many counties. Furthermore, the distinction between the
curves of Group 1 and 2 is also considerably bigger than those of the earlier data. This can
be explained by the confluence of additional factors that separate each county‚Äôs experience
with the virus, including the nature of local government intervention, degree, and timing of
re-openings, travel restrictions, etc.

3

EXTRACTING SIGNIFICANT DEMOGRAPHIC
FEATURES

An important and subsequent question that arises once the communities are obtained is what
underlying factors play a role in which growth cluster a county belongs to. Since the growth
of COVID-19 cases is also related to static, inherent factors that aren‚Äôt a consequence of the
disease, we examine a variety of county demographic variables and how they differ among
15

communities. In order to select the variables that are most statistically significant, or are
most relevant to the community assignment of a county, we perform independent two-sample
t-tests on the fastest and slowest growth groups (subsection 2.5) with respect to various
demographic variables. The null and alternative hypotheses for this t-test for the d-th feature
are as follows:
H0 : ¬µd,1 = ¬µd,2 , vs. Ha : ¬µd,1 6= ¬µd,2 ,

(4)

where ¬µd,1 is the mean value of the d-th feature of cluster 1 and ¬µd,2 is the mean value of
the d-th feature of cluster 2. We then compute the two-sample test statistic with pooled
estimate of the variance. After finding the p-values, we rank the features from lowest p-value
(most significantly different between the two groups) to highest (least significantly different
between the two groups).
Furthermore, we repeat Algorithm 1 for K = 3, 4, 5, select the ‚Äôfastest‚Äô and ‚Äôslowest‚Äô
growth clusters in each case, and carry out the independent two-sample t-tests as described
above for the same demographic features. This sensitivity analysis tests whether the demographic variables that are the most significantly different between the two groups are
consistent when we have a larger number of communities. Ultimately, we present the most
statistically significant demographic features.

3.1

Data

For this section, we use data from Data Planet, a social science research database that
compiles 12.6 billion U.S. and international datasets from over 80 sources. For our purposes,
we look at the 2017 American Community Survey (ACS), the largest household survey in the
U.S., conducted by the U.S. Census Bureau. We select 17 relevant features on a county-level,
which are displayed and summarized in Table 4. Note that not all 950 counties from Johns
Hopkins CCSE data that were used in subsection 2.6 is available on Data Planet, thus the
analysis is done on 633 counties for this section. Now, we are left with 301 counties in Group

16

Figure 9: The left panel is a geographical representation of counties according to median household income.
Blue dots are counties with less than $50,000 median annual household income and purple dots are counties
with more than $50,000 median annual household income. The right panel is a geographical representation
of counties according to population density. Blue dots are counties with less than 150 persons per sq mile
and purple dots counties with more than 150 persons per sq mile.
1 and 332 counties in Group 2, which is still a close split like that of R seen in Table 2.

Figure 10: Comparisons on the averages of a few features of the 2-clustered counties. The orange bars are
model R, the gray bars are model A1 , and the blue bars are model A2 .

17

Group 1

Group 2

F eature

Mean

Median

Std Dev

Mean

Median

Std Dev

Population Density
Median Household Income
% Poverty
% 1-person households
% 5 or more person households
% households w 60 y/o and older
% w low access to stores
% low income w low access to stores
% households w low access to stores
25 y/o and older w Bachelor‚Äôs /1,000
% White
% Black
% Asian
No of bars
No of grocery stores
No of restaurants
% take public transportation

275.775
54431.6
14.0656
27.1330
8.91332
39.3294
21.8723
7.48273
2.69416
110.885
80.8599
11.3861
1.96190
29.3313
42.5564
13.1345
0.41130

159.260
52651.0
13.3000
27.7185
8.41406
39.1802
21.3800
6.85500
2.32000
106.164
85.6959
5.03010
1.22070
16.0000
23.0000
8.00000
0.19870

394.059
13386.3
5.71511
4.21220
2.96792
6.85032
9.66507
4.48466
1.63712
40.6371
15.0719
14.6140
1.89220
39.0755
67.0810
13.1383
0.76870

913.182
58814.6
13.4712
27.0233
9.38467
38.7538
20.8704
6.60216
2.24196
122.654
75.7593
13.4737
3.67570
55.2143
117.321
14.9219
1.24690

289.610
56074.0
12.5000
27.1978
8.71688
38.6947
21.2500
5.69000
1.92000
118.332
79.6171
7.90300
1.87900
23.5000
39.0000
9.00000
0.32130

3659.76
16737.2
5.83384
4.54690
3.27316
6.03233
9.81211
4.52299
1.50078
43.6276
16.7522
15.3919
5.28820
96.9646
16.5490
16.5490
6.14170

Table 4: R clusters‚Äô mean and median values for selected features for each community K = 2. Model R
corresponds to Algorithm 1 where we use the sample correlation matrix. Group 1 and 2 are the obtained
b 1 and G
b 2 , respectively. Population Density is the number of people per sq mile; median household
partitions G
income is in US dollars; % Poverty is the poverty rate: % 1-person households is the percentage of one-person
households; % 5 or more person households is the percentage of five or more person households; % households
w 60 y/o and older is the percentage of households that have one or more members who are 60 years old
or older; low access to stores is defined as living more than one mile (urban areas) or 10 miles (rural areas)
from the nearest supermarket, supercenter, or large grocery store; /1,000 is per 1,000 persons; % take public
transportation is the percentage of all persons who work in a county and take public transportation to work
every day. All feature information is as of 2017.

3.2

Results and Discussion

It is evident from Table 4 that community detection with R results in Group 2 (fast growth)
containing counties with the highest mean and median population density by far. The mean
and median household income are also higher for counties in Group 2. The mean number of
persons 25 years old or older with Bachelor‚Äôs is noticeably greater for Group 2, which can often
coincide with more urban areas that are more densely populated. However, it can also be
related to the number of universities in a particular area, as a higher number would exacerbate
the spread of COVID-19. The number of bars and grocery stores are also starkly different
among the two groups. Moreover, the percentage of people who take public transportation to

18

F eature

P-Value

F eature

P-Value

% Asian
No of grocery stores
No of bars
% White
Median Household Income
% households w low access to stores
25 y/o and older w Bachelor‚Äôs /1,000
Population Density
% low income w low access to store
% take public transportation
% 5 or more persons households
% Black
% Poverty
No of restaurants
% w low access to stores
% households w 60 y/o and older
% 1-person households

1.26E-11
5.83E-11
2.95E-06
3.04E-06
1.44E-05
1.60E-05
2.80E-05
2.39E-04
0.00303
0.00436
0.02324
0.04672
0.10603
0.11432
0.13698
0.18014
0.63999

No of grocery stores
% low income w low access to store
Median Household Income
% Poverty
% White
Population Density
% 1-person households
% households w low access to stores
% 5 or more persons households
% Black
% take public transportation
% of households w 60 y/o and older
% Asian
25 y/o and older w Bachelor‚Äôs /1,000
% w low access to stores
No of restaurants
No of bars

2.85E-08
6.38E-07
8.41E-06
2.01E-04
0.01967
0.04027
0.07537
0.10640
0.10711
0.12222
0.13245
0.35344
0.47698
0.52498
0.62138
0.89977
0.90224

Table 5: Left table is R clusters‚Äô p-values for independent two-sample t-tests for selected features between
Group 1 and Group 2 sorted from smallest to largest p-value. Right table is recent data (05/10/2020 07/10/2020) R clusters‚Äô p-values. The features in bold are the ones that are selected as significant features
for further analysis in section 4.
F eature

P-Value

F eature

P-Value

% w low access to stores
% low income w low access to store
No of bars
No of restaurants
No of grocery stores
% Black
% of households w 60 y/o and older
Population Density
% 5 or more persons households
% take public transportation
% 1-person households
% households w low access to stores
% Poverty
% White
Median Household Income
25 y/o and older w Bachelor‚Äôs /1,000
% Asian

0.02683
0.08490
0.12402
0.13868
0.18422
0.21146
0.22823
0.27201
0.34981
0.38932
0.52795
0.46620
0.63207
0.47153
0.67262
0.71546
0.92895

% White
% Poverty
% households w low access to stores
Median Household Income
Population Density
25 y/o and older w Bachelor‚Äôs /1,000
% low income w low access to stores
No of restaurants
% take public transportation
% Asian
% 1-person households
% Black
% households w 60 y/o and older
No of grocery stores
% w low access to stores
% 5 or more persons households
No of bars

0.09115
0.09423
0.12762
0.16226
0.17828
0.32282
0.36051
0.39537
0.50781
0.51744
0.41733
0.56017
0.57800
0.72219
0.78404
0.91679
0.93340

Table 6: Left panel is A1 clusters‚Äô p-values for independent two-sample t-tests for selected features between
Group 1 and Group 2 sorted from smallest to largest p-value. The right panel is A2 clusters‚Äô p-values for
two-sample t-tests for selected features between Group 1 and Group 2 sorted from smallest to largest p-value.

19

work is around three times greater for Group 2 than Group 1. These observations do not hold
for A1 and A2 (see Supplementary Material for Tables 10 and 11) and in fact, the differences
in mean and medians between the two groups are significantly smaller for almost all features.
For instance, the differences between population density means for the two groups of A1 and
A2 are 191.609 and 228.966 people per sq mile, respectively - much smaller differences than
that of R‚Äôs clusters: 637.407. Furthermore, there isn‚Äôt consistency in these trends for most
features; for example, Group 2 of A1 has the higher population density and median income
averages but also has the lower average number of bars, grocery stores, and restaurants.
On the other hand, unlike what one would expect in terms of the relationship between
the number of one-person households and the spread of COVID-19, there is not much differentiation between the number of people in a household. Figure 10 displays the individual
bar plots of average values for six features for R, A1 , and A2 . It is evident that the orange
bars of R‚Äôs clusters are plainly contrasted between Group 1 and 2, unlike those of A1 and
A2 ‚Äôs clusters. It is very likely that too much information was lost in A1 and A2 during the
truncation process.
Tables 5 and 6 contain the p-values for all of the 17 features. Evidently, the clusters
formed with A1 and A2 do not contain as significant differences in terms of demographic
variables as they have much higher p-values across the board. As for R, the variables have
a much greater explanatory power. The number of grocery stores and the number of bars
have much lower p-values than that of the number of restaurants. Also, as expected, the
median household income is among the features with lower p-values; however, population
density does not appear as significant as expected. After conducting the same two-sided
t-tests for K = 3, 4, 5 on the two extreme groups, the seven statistically significant features
found are as follows: population density, median income, number of persons who are 25 years
and older with Bachelor‚Äôs per 1,000 persons, percentage of the White population, percentage
of the Asian population, number of bars, and number of grocery stores. These seven features

20

are consistently ranked in the top eight features for each K = 2, 3, 4, 5 based on p-values.
These values form the demographic vector di for each county i. The variables for bars and
grocery stores underscore the ease of transmission in locations with greater numbers of public
gathering spots, a characteristic evident in cities like New York City where most people choose
to convene at bars without much social distancing (before stricter lockdowns took place).
After finding the growth communities and conducting t-tests to ascertain the significant
features for the latter phase of the pandemic in the U.S. (05/10/2020 - 07/10/2020), the
features with the lowest p-values diverge from those of earlier data, as presented in the
right table of Table 5. Population density and median income are still among the most
meaningful, with income being more significant, but variables such as the number of grocery
stores, percentage of people with low access to stores, and the percentage living in poverty
have become much more significant. This suggests that at later stages of the pandemic,
poverty and other income-related measures become more indicative and responsible for the
differences in case growth among counties. Thus, the seven features for di for this latter
phase are the top seven variables in Table 5: number of grocery stores, % low income with
low access to stores, median household income, % poverty, % white, population density, and
% 1-person households.

4

PREDICTION WITH SOCIAL DISTANCING DATA

The final section of our COVID-19 methodology is to predict a county‚Äôs growth trajectory a
few days into the future. We propose a prediction methodology with the objective that given
a new county, the new county‚Äôs key demographic features, and social distancing measures,
we implement an algorithm that projects the new county‚Äôs future growth.
Before going in-depth on the prediction models, it‚Äôs necessary to first define some important variables. Let l be the number of the days forward to be projected for a new county.
21

To build such a predictive model, let yi,t+l = log(xi,t+l ) ‚àí log(xi,t ) be county i‚Äôs l-day forward log-growth rate, which is close to the growth rate

xi,t+l ‚àíxi,t
xi,t

by Taylor‚Äôs expansion and

numerical verification, for t = 1, ..., Ti . Here, Ti + l is the total number of days where county
i has 12 or more cases. Recall the obtained partitions from Algorithm 1 (set of indices of
b ‚àà Rn is the recovered
bk = {i|Zbi = k, i = 1, ..., n}, where Z
counties that belong to group k): G
bk , let di ‚àà Rq be county i‚Äôs
community label vector. For a community k, and a county i ‚àà G
significant feature vectors obtained from section 2.7, S i = [si1 , si2 , ..., siTi ]T ‚àà RTi √ó3 be county
i‚Äôs three social distancing time series matrix (see subsection 4.4 for details about this data)
and yi = [yi,1+l , ¬∑ ¬∑ ¬∑ , yi,Ti +l ]T ‚àà RTi be its l‚àíday forward log case difference. Note that each
row of S i , sit ‚àà R3 , has three different social distancing metrics at time t.
bk } for training an l-day ahead predictive model
In summary, we have data {Si , yi : i ‚àà G
for the k th community.

4.1

Long Short-Term Memory (LSTM)

To enhance the effectiveness of the model, we take advantage of a special type of recurrent
neural network (RNN): long short-term memory (LSTM) networks, which are designed for
time-series forecasting. Unlike feedforward neural networks (FNNs), RNNs produce an output that depends on a ‚Äúhidden‚Äù state vector that contains information based on prior inputs
and outputs. LSTMs builds on a simple, vanilla RNN to include a forget gate, input gate,
and output gate for each module. Hence, it is able to ‚Äúremember‚Äù information for longer time
periods (lags). The output for an LSTM module at time t is as follows:

ht = ot tanh(Ct ).

(5)

The components of ht are broken down as follows: ft = œÉ(Wf [ht‚àí1 , xt ] + bf ), is the forget
gate output and Wf and bf are its weights and biases, respectively. it = œÉ(Wi [ht‚àí1 , xt ] +
bi ), is its input gate output and Wi and bi are its weights and biases, respectively. The
22

cell state vector then gets updated by forgetting the previous memory through the forget
gate and adding new memory through the input gate: Ct = ft Ct‚àí1 + it CÃÉt , where CÃÉt =
tanh(WC [ht‚àí1 , xt ] + bC ). Subsequently, the output gate ot = œÉ(Wo [ht‚àí1 , xt ] + bo ) and Wo and
bo are its weights and biases, respectively. Here, œÉ is the sigmoid activation function.
We also compare the LSTM‚Äôs performance with that of an FNN, namely an MLP (multilayer perceptron). MLPs are a type of fully connected FNN first introduced and popularized
by Rumelhart et al. (1986), consisting of an input layer, output layer, and hidden layers in
between, where the training process is done through backpropagation. The total input xs+1
i
of a neuron i of layer s + 1 takes the form of

xs+1
=
i

X

hsij xsœÉj + bs+1
,
i

(6)

j

where hsij is the weight for neuron j of the previous layer s to neuron i of layer s + 1 and bs+1
i
is the threshold of layer s + 1. xsœÉj = œÉ(xsi ) is the output from neuron j from the previous
layer s, where a nonlinear activation function œÉ(¬∑) is applied to the input. Most common
activation functions include sigmoid, tanh, or ReLU (rectified linear unit), where the ReLU
often learns faster in deeper networks.

4.2

Prediction Models

The first prediction model, Algorithm 2 (which we will refer to as SD-LSTM), is a prediction
procedure that solely uses a nonlinear model (a neural network) to fit the data. The idea is
to first train an LSTM for each of the K communities, and then given a new county, we select
the corresponding fitted model for prediction from our repertoire with respect to its nearest
neighbor county (in demographic variables, not geographical distance). That is, we apply
the nearest neighborhood in demographic variables to classify the new county‚Äôs community,
and use the model for that community to forecast the county‚Äôs cases. Specifically, for each

23

i
bk } and
community k ‚àà {1, ..., K}, we train an LSTM with the data {(sit , yi,t+l )Tt=1
, ‚àÄi ‚àà G

this depends on the numbers of steps forward, l, we are trying to forecast. For simplicity
bk by
of notation, for community k, we denote all such data items for all counties i ‚àà G
{(st , yt+l ), t ‚àà Gbkl } and the fitted function by fbkl (¬∑). Now the second part, the prediction, is
that given a new county i0 ‚Äôs demographic data di0 and social distancing information S i0 =
0

0

0

[si1 , si2 , ..., siT 0 ] ‚àà RTi0 √ó3 , we first find its nearest neighbor county j = argminj kdi0 ‚àí dj k2
i

and its associated community Zbj and use its associated prediction model to predict ybi0 ,t+l =
0
fbkl 0 (sit ), t = 1, ..., Ti0 with k 0 = Zbj . Algorithm 2 summarizes this method of prediction.

To predict a future event, the above procedure gives a number of prediction methods.
For example, to predict tomorrow‚Äôs outcome, we can use today‚Äôs social distancing data with
l = 1, or yesterday‚Äôs social distancing data with l = 2, or the day before yesterday‚Äôs social
distancing data with l = 3, and so on. As verified later in Figure 12, it turns out that l = 4
is the best choice of lead, which align with the incubation period of the disease.
Algorithm 2 SD-LSTM: LSTM Prediction
Part I: Training
Input: The lead l
1: for k ‚àà {1, ..., K} do
2:
Train LSTM fbkl (¬∑) using the data {(st , yt+l ), t ‚àà Gbkl }.
3: end for
4: return fitted LSTMs fbkl (¬∑), k = 1, ..., K.
Part II: Prediction
0
0
0
b and fbl (¬∑), k = 1, ..., K
Input: A new county i0 , di0 ‚àà Rq , S i0 = [si1 , si2 , ..., siT 0 ] ‚àà RTi0 √ó3 , Z
k
i
from Part I.
1: Find county i0 ‚Äôs nearest neighbor j = argminj kdi0 ‚àí dj k2 .
bj .
2: Select fbkl 0 (¬∑), where k 0 = Z
3: for t ‚àà {1, ..., Ti0 } do
0
4:
ybi0 ,t+l = fbkl 0 (sit ).
5: end for
bi0 = [b
6: return y
yi0 ,1+l , ybi0 ,2+l , ..., ybi0 ,Ti +l ]T ‚àà RTi0 .
Algorithm 3 takes SD-LSTM a step further to include a linear component, namely, fitting
the linear model for each county first with residuals from each community then further
24

modeled by an LSTM. This idea is related to boosting or nonparametric estimation using a
parametric start Fan et al. (2009), resulting in a semi-parametric fit. Again, the objective of
the training part is to obtain K fitted models, one for each community, using semi-parametric
regression techniques. More specifically, for county i with lead l, we first fit the following
linear regression models

yi,t+l = Œ±il + (sit )T Œ≤ li + Œµi,t+l ,

t = 1, ..., Ti .

(7)

After fitting the linear regression models for every county i ‚àà Gbkl , we obtain the residuals
{b
i,t+l , t ‚àà Gbkl } and save all the coefficients Œ±il , Œ≤ li for i ‚àà Gbkl , k = 1, ..., K. We then extract
the information further from {(st , b
t+l ), t ‚àà Gbkl } by fitting an LSTM to obtain the fitted gbkl (¬∑).
Then, for the prediction of the new county i0 , we follow the same steps as those in SD-LSTM
but the final prediction is instead adding the linear fit of the nearest neighbor county and
the LSTM fit of the community corresponding to the nearest neighbor county:
0

0

ybi0 ,t+l = Œ±jl + (sit )T Œ≤ lj + gbkl 0 (sit ),
where k 0 = Zbj . We will refer to this model as SD-SP. The idea is summarized in Algorithm 3.
We also include three other algorithms for comparison purposes. The first replaces the
LSTM fit fbkl (¬∑) of community k in SD-LSTM with a linear model. This corresponds to fitting
(7) without further boosting by an LSTM. For simplicity, we shall refer to this approach as
the SD-LM (social distancing linear model). The second one is to use both demographic and
social distancing data to fit an LSTM. This approach is identical to SD-LSTM, but includes
the q = 7 significant demographic variables in Table 5 in addition to the three social distancing
variables. Similarly, we shall refer to this approach as the DSD-LSTM (demographic and
social distancing LSTM). DSD-LSTM is expected to improve the performance of Algorithm 2
due to the additional information from the demographic variables. The final model is similar
25

Algorithm 3 SD-SP: Semi-parametric Prediction
Part I: Training
Input: The lead l
1: for k ‚àà {1, ..., K} do
t+l , t ‚àà Gbkl }.
2:
Fit the regression models (7) for i ‚àà Gbkl and obtain the residuals {b
3:
Train LSTM using {(st , b
t+l ), t ‚àà Gbkl }
4: end for
5: return fitted LSTMs g
bkl (¬∑) and all Œ±il and Œ≤ li for i ‚àà Gbkl , k = 1, ..., K.
Part II: Prediction
0
0
0
b and gbl (¬∑), Œ±l and Œ≤ l
Input A new county i0 , di0 ‚àà Rq , S i0 = [si1 , si2 , ..., siT 0 ] ‚àà RTi0 √ó3 , Z
i
i
k
i
l
b
for i ‚àà G , k = 1, ..., K from Part I.
k

1:
2:
3:
4:
5:
6:
7:

Find county i0 ‚Äôs nearest neighbor j = argminj kdi0 ‚àí dj k2 .
Select Œ±jl and Œ≤ lj for county j.
Select gbkl 0 (¬∑), where k 0 = Zbj .
for t ‚àà {1, ..., Ti0 } do
0
0
ybi0 ,t+l = Œ±jl + (sit )T Œ≤ lj + gbkl 0 (sit ).
end for
return ybi0 = [b
yi0 ,1+l , ybi0 ,2+l , ..., ybi0 ,Ti +l ]T ‚àà RTi0 .

to SD-LSTM but instead of an LSTM, we use an MLP with two hidden layers (we will refer
to this model as SD-MLP).

4.3

Implementation

For the LSTM, the optimization algorithm used is Adam with a learning rate of 0.01. We
also test the performance of various lags to see which yields the highest out-of-sample R2 ,
defined as follows for a given new county i0 and lead l:
PTi0

1 ‚àí Pt=1
Ti0

(yi0 ,t+l ‚àí ybi0 ,t+l )2

2
t=1 (yi0 ,t+l ‚àí yÃÑi0 ,t+l )

,

where yi0 ,t+l is the observed value, ybi0 ,t+l is the predicted value, and yÃÑi0 ,t+l = 1/Ti0

(8)

PTi0

t=1

yi0 ,t+l ,

serving as the baseline predictor. The average, median, and standard deviation of the R2
values are then taken across all counties in the testing sample. Additionally, for any model

26

involving an LSTM, up to the minimum length TÃÉ = min Ti is taken for each county since
i=1,...,N

the LSTM needs each sample to have uniform time steps. Therefore, Ti = TÃÉ for each county
i in the case of SD-LSTM, SD-SP and the DSD-LSTM model. For information regarding the
hidden layers used and input shapes in the neural network models, see Table 7.

SD-LSTM
SD-SP
DSD-LSTM
SD-MLP

No. of hidden layers

Type and no of nodes

Input shape

1
1
1
2

LSTM, 10
LSTM, 10
LSTM, 10
Dense, 10, 10

N √ó TÃÉ √ó 3
N √ó TÃÉ √ó 3
N √ó TÃÉ √ó 10
PN
i=1 Ti √ó 3

Table 7: Number of hidden layers, the type and number of nodes of each hidden layer, and input shape of
each model that contains an NN.

Due to the nature of neural networks and considering the relatively small sample size, we
conduct five-fold cross-validation to evaluate the learning models. We divide all the counties
into 5 train-test splits, where the correlation matrix is re-calculated on only the training set.
Then, for each K = 1, ..., 5, Algorithm 1 is executed on the training set for that particular
split. Hence, we have 25 sets of results for each model (five for each of the five train-test
splits).

4.4

Data

Social distancing data is courtesy of Unacast and its COVID-19 Social Distancing Scoreboard.
The scoreboard tracks mobile device movement and has three metrics that quantify the level
of social distancing people in a particular county are practicing. The first metric is the
percentage change in total distance traveled, averaged across all devices, compared to a preCorona baseline. The second is the percentage change in the number of visitations to nonessential places compared to a pre-Corona baseline. For these two metrics, the pre-Corona
baseline of a county on a particular day is defined as the average of the four corresponding
pre-weekdays (at least four weeks before the day). For example, for Monday 3/30, the preCorona baseline of the first metric is the average of the first metric for the four Mondays:
27

2/10, 2/17, 2/24, and 3/2. The final metric is the rate of human encounters as a fraction
of the pre-Corona national baseline. The pre-Corona national baseline for this metric is the
average of the metric taken over four weeks that immediately precede the COVID-19 outbreak
(02/10/2020 - 03/08/2020) as defined by Unacast. Since this data starts at 02/25/2020 which
is after the start of the Coronavirus cases data (01/22/2020), we perform prediction on the
period 02/25/2020 - 7/10/2020, which is the start of the ‚Äúinitial phase‚Äù until the end of the
‚Äúrecent phase‚Äù. Also note that not all counties from Johns Hopkins CCSE data and Data
Planet are available at Unacast‚Äôs database so out of the 633 counties from subsection 3.1,
this section is performed on 627 counties.

Figure 11: Out-of-sample R2 boxplots for all counties using Model 1 (SD-LSTM), Model 2 (SD-SP), Model
3 (SD-LM) and Model 4 (DSD-LSTM) for K = 1, 2, 3, 4, 5. The results are based on l = 4 and the period
02/25/2020 - 7/10/2020.

28

In-Sample
M odel
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model
Model

1,
1,
1,
1,
1,
2,
2,
2,
2,
2,
3,
3,
3,
3,
3,
4,
4,
4,
4,
4,
5,
5,
5,
5,
5,

K
K
K
K
K
K
K
K
K
K
K
K
K
K
K
K
K
K
K
K
K
K
K
K
K

=1
=2
=3
=4
=5
=1
=2
=3
=4
=5
=1
=2
=3
=4
=5
=1
=2
=3
=4
=5
=1
=2
=3
=4
=5

Out-of-Sample

Mean

Median

Std Dev

0.3447
0.4733
0.5003
0.5211
0.5113
-2.0229
-1.8886
-1.8819
-1.8647
-1.8673
-0.1227
-0.1148
-0.1138
-0.1095
-0.0991
0.4855
0.5486
0.5473
0.5489
0.5467
-0.1894
-0.1507
-0.1432
-0.1318
-0.1206

0.6376
0.6372
0.6527
0.6580
0.6593
-1.8148
-1.7337
-1.6990
-1.7513
-1.7500
-0.0271
-0.0260
-0.0252
-0.0239
-0.0246
0.6429
0.6645
0.6554
0.6522
0.6550
-0.0394
-0.0365
-0.0383
-0.0415
-0.0374

0.8642
0.5632
0.5186
0.4738
0.5094
0.9800
0.8901
0.8471
0.8371
0.8016
0.3236
0.2941
0.2936
0.2771
0.2559
0.5114
0.3786
0.3952
0.3930
0.3812
0.4866
0.3679
0.3538
0.3072
0.2633

Mean

Median

Std Dev

0.3281
0.2170
0.2792
0.2485
0.2024
-2.9663
-2.9613
-2.9393
-2.9220
-2.9281
-0.1458
-0.1586
-0.1563
-0.1659
-0.1542
0.4513
0.3567
0.3611
0.2947
0.2516
-0.2098
-0.1886
-0.1729
-0.1362
-0.1560

0.6192
0.5437
0.5600
0.5245
0.5461
-1.9824
-1.8356
-1.7641
-1.7512
-1.7872
-0.0311
-0.0296
-0.0276
-0.0302
-0.0317
0.6251
0.5556
0.5672
0.4912
0.5223
-0.0430
-0.0411
-0.0415
-0.0413
-0.0462

0.7978
1.0514
0.8986
0.9007
1.0277
7.8948
8.1548
8.0641
8.1715
8.0991
0.4000
0.5145
0.5054
0.6044
0.5320
0.5384
0.7031
0.6536
0.7717
0.8706
0.4551
0.4241
0.3932
0.3277
0.3741

Table 8: 02/25/2020 - 7/10/2020 in-sample and out-of-sample R2 for Model 1 (SD-LSTM),
Model 2 (SD-SP), Model 3 (SD-LM), Model 4 (DSD-LSTM), and Model 5 (SD-MLP) for
K = 1, 2, 3, 4, 5. The average values for mean, median and standard deviation are taken
for each of the 5 folds. For K = 1, we assume that all counties belong to one group so we
take all counties in the training data to train the neural network. The results are based on
l = 4 and a five-fold cross-validation. 501 of the total 627 counties are used as training data
(in-sample) and 126 counties are used as testing data (out-of-sample).

4.5

Results and Discussion

Among the four prediction models we implemented using the county-level social distancing
measures (see subsection 4.4), for K = 1, 2, 3, Model 4 (DSD-LSTM) slightly outperforms

29

In-Sample

Out-of-Sample

F eature

Mean

Median

Std Dev

Trial 1
Trial 2
Trial 3
Trial 4
Trial 5
Median

0.2349
0.2764
0.2921
0.2900
0.3404
0.2900

0.4842
0.5569
0.5628
0.5594
0.5430
0.5569

0.9238
0.9678
0.9442
0.9677
0.8943
0.9442

Mean

Median

Std Dev

0.4523
0.3304
0.1163
0.3410
-0.0455
0.3304

0.4956
0.4995
0.4980
0.5454
0.4367
0.4980

0.3505
0.7916
1.4862
0.7049
1.3895
0.7916

Table 9: 02/25/2020 - 7/10/2020 random assignment in-sample and out-of-sample R2 for
Model 1 (SD-LSTM), K = 2. Each trial is completed via randomly assigning each test
county of one of the train-test splits to either community 1 or community 2.
Model 1 due to the use of the seven additional demographic variables. Model 1 (SD-LSTM)
proves to result in the highest average and median out-of-sample R2 for K = 4, 5. Models 2
(SD-SP) and 3 (SD-LM) have much poorer performance across the board, which implies that
these two models are worse than a horizontal line fit. It is also worth mentioning that the
neural network correction part of Model 2 is incredibly hard to tune to be able to outperform
the linear model Model 3 on its own. In this case, not only was it not able to enhance Model
3‚Äôs results, Model 2‚Äôs correction actually worsened the model‚Äôs predictive ability. Other
nonparametric methods other than a neural network were also used (such as support vector
regression) but all had a similar lackluster effect, implying that boosting or enhancing the
linear estimator with a nonlinear estimator is not beneficial in this case. Model 1‚Äôs and Model
4‚Äôs superiority suggests a nonlinear effect that the LSTM was able to extract, but the linear,
semi-parametric, and MLP were unable to do so.
For Models 1 and 4, stratifying the communities through our method does make a difference in-sample since increasing K improves the models‚Äô mean and median in-sample R2 .
However, this is not the case for out-of-sample as K = 1 produces the best results (no heterogeneity) and the out-of-sample R2 continues to drop from K = 2 to 5. It is reasonable to
conclude that the decrease in sample size for each community training (e.g. K = 1 uses all
501 counties to train while K = 5 uses on average 1/5th of that number to train each commu-

30

nity) is hurting the model‚Äôs ability to take advantage of the heterogeneity embedded in the
communities. Thus, since neural networks have an advantage in large sample size settings,
the effect of the reduction in sample size for larger Ks outweighs the community difference
captured by community detection (Algorithm 1). We also include Model 5 (an FNN with
two hidden layers, each with 50% dropout) to contrast the LSTM with. The performance is
similar to Model 3 in that it is no better than a constant fit. The advantage of the LSTM
is highlighted here since the output is dependent on previous computations, unlike the FNN
that assumes the inputs (as well as outputs) are independent of each other. As COVID-19
cases are sequential information, the LSTM is clearly preferable to predict with. See Table
8 for the detailed breakdown by model and by the number of clusters K. Figure 11 contains
the out-of-sample R2 box plots for the four models with K = 1, 2, 3, 4, 5.

Figure 12: The left panel is the average out-of-sample R2 for Model 1, K = 1 and Model 4, K = 1 for
l = 1, 2, 3, 4, 5, 6, 7 for one train-test split. The right panel is average out-of-sample R2 for the same models,
where one social distancing feature is left out each time. Both panels are of the phase 02/25/2020 - 7/10/2020
and based on five-fold cross-validation.

To ascertain whether using information from community detection still plays a role despite
K = 1 being the best setting for out-of-sample prediction, we randomly assign each testing
county to an existing community instead of using the nearest neighbor method. As shown in
Table 9, after repeating this five times for Model 1, K = 2, the median in-sample R2 values
are much lower compared to that of the same model in Table 8 (median of 0.5569 vs 0.6372,
respectively). Albeit a smaller difference, the out-of-sample median 0.4980 is also smaller
than the 0.5437 in Table 8. This demonstrates that community detection can still categorize
31

the nature of different counties‚Äô growth trajectories but this effect is likely outweighed by the
diminishing sample size as K increases.
Also note that before obtaining the prediction results for each algorithm, the hyperparameter of the appropriate lead was chosen by comparing the average R2 values for each
lead. The left panel of Figure 12 presents the median out-of-sample R2 vs l = 1, ..., 7 for the
two best models Model 1, K = 1, and Model 4, K = 1 as examples. Since out-of-sample
R2 is plateaus after a four-day lead, we fixed l = 4 as a larger lead would decrease precision
and it is important to be consistent with studies that show the median incubation period of
COVID-19 is 4-5 days (Guan et al., 2020; Lauer et al., 2020). Furthermore, anything longer
than a week or so is rarely used in epidemiological and sociological studies. In addition, we
quantify the social distancing feature importance by averaging the out-of-sample R2 when
we leave each feature out one at a time. Evidently, the right panel of Figure 12 suggests
that although there is no distinct drop in performance, leaving out feature 1 (percent change
in total distance traveled) results in the largest decline in R2 whereas leaving out feature 2
(percent change in the number of visitations to non-essential places) results in the smallest
decline.

5

CONCLUSION

By utilizing spectral clustering to recover communities, we develop a framework to detect
COVID-19 communities and discover meaningful interpretations of the clusters. We use the
correlation matrix instead of the canonical Laplacian as it offers more meaningful insight and
more distinct clusters. The resulting communities are distinct in the nature of their respective
growth trajectories and there are several demographic variables that further distinguish these
growth communities. Singling out the significant demographic features that have explanatory
power of a county‚Äôs growth community membership, we discover that not all of these variables
are intuitive when it comes to their role in impacting COVID-19 cases.
32

After modeling and interpreting historical disease progression, we turn to study future
growth trajectories by incorporating social distancing information. We are able to reliably
predict the logarithmic trends in case growth through the use of LSTMs and also verify that
the counties are far from homogeneous - the obtained communities contain crucial information
necessary for prediction in-sample. As for the LSTM‚Äôs out-of-sample predictive power, the
effect of the decline in sample size when increasing the stratification of counties into more
communities dominates the heterogeneity between counties‚Äô growth curves that community
detection uncovers. However, after comparing results to randomly assigning counties to
different communities, the method we propose still demonstrates that using the community
detection results boosts the models‚Äô predictive performance.
We do, therefore, acknowledge that there could be other latent features that we did not
capture in this study and that the three social distancing metrics used here may not paint
the complete picture. Furthermore, we do not address the effect of government intervention
at given time points that may have altered the disease progression. These could all be
points that can be further investigated. Despite these potential shortcomings, the analysis
conducted on the first phase of the disease here can also be compared to the second phase,
which we are currently experiencing. As the U.S. and many other countries are witnessing an
even more extraordinary uptick in cases again, we foresee several possible future applications
of our study, including to other contagious disease outbreaks. Another interesting future
work is to utilize the confidence distribution framework Xie et al. (2011) to combine studies
from independent data sources from different countries.

Acknowledgements
We would like to thank Unacast Inc. for providing us with their extensive social distancing
data. The work was in part supported by NSF Grants DMS-2013789, DMS-1712591 and
DMS-2034022, and NIH grant 2R01-GM072611-15.

33

References
Emmanuel Abbe. Community detection and stochastic block models: recent developments.
The Journal of Machine Learning Research, 18(1):6446‚Äì6531, 2017.
Emmanuel Abbe, Jianqing Fan, Kaizheng Wang, and Yiqiao Zhong. Entrywise eigenvector
analysis of random matrices with low expected rank. Annals of Statistics, 48(3):1452‚Äì1474,
2020.
Sivaraman Balakrishnan, Min Xu, Akshay Krishnamurthy, and Aarti Singh. Noise thresholds
for spectral clustering. Advances in Neural Information Processing Systems, 24:954‚Äì962,
2011.
Rebecca A Betensky and Yang Feng. Accounting for incomplete testing in the estimation
of epidemic parameters. International Journal of Epidemiology, 49(5):1419‚Äì1426, 07 2020.
ISSN 0300-5771.
M.R. Brito, Edgar Chavez, Adolfo Quiroz, and J.E. Yukich. Connectivity of the mutual
k-nearest-neighbor graph in clustering and outlier detection. Statistics and Probability
Letters, 35:33‚Äì42, 1977.
Christian Brownlees, Gu√∞mundur Stef√°n Gu√∞mundsson, and G√°bor Lugosi. Community
detection in partial correlation network models. Journal of Business & Economic Statistics,
pages 1‚Äì11, 2020+. doi: 10.1080/07350015.2020.1798241.
Jingchun Chen and Bo Yuan. Detecting functional modules in the yeast protein? protein
interaction network. Bioinformatics, 22:2283‚Äì2290, 2006.
Jennifer Beam Dowd, Liliana Andriano, David M. Brazel, Valentina Rotondi, Per Block,
Xuejie Ding, Yan Liu, and Melinda C. Mills. Demographic science aids in understanding
the spread and fatality rates of covid-19. Proceedings of the National Academy of Sciences,
117(18):9696‚Äì9698, 2020. doi: 10.1073/pnas.2004911117.
Jianqing Fan, Yichao Wu, and Yang Feng. Local quasi-likelihood with a parametric guide.
Annals of statistics, 37(6):4153, 2009.
Jianqing Fan, Jianhua Guo, and Shurong Zheng. Estimating number of factors by adjusted
eigenvalues thresholding. Journal of the American Statistical Association, pages 1‚Äì33,
2020.
Duccio Fanelli and Francesco Piazza. Analysis and forecast of covid-19 spreading in china,
italy and france. Chaos, Solitons & Fractals, 134:109761, 2020. ISSN 0960-0779. doi:
https://doi.org/10.1016/j.chaos.2020.109761.
Donniell E. Fishkind, Daniel L. Sussman, Minh Tang, Joshua T. Vogelstein, and Carey E.
Priebe. Consistent adjacency-spectral partitioning for the stochastic block model when the
model parameters are unknown. SIAM Journal on Matrix Analysis and Applications, 34:
23‚Äì39, 2020.
34

Marius Gilbert, Giulia Pullano, Francesco Pinotti, Eugenio Valdano, Chiara Poletto, PierreYves Bo√´lle, Eric D‚ÄôOrtenzio, Yazdan Yazdanpanah, Serge Paul Eholie, Mathias Altmann,
Bernardo Gutierrez, Moritz U G Kraemer, and Vittoria Colizza. Preparedness and vulnerability of african countries against importations of covid-19: a modelling study. Lancet,
395(10227):871‚Äî877, 2020. ISSN 0140-6736. doi: 10.1016/s0140-6736(20)30411-6.
Wei-jie Guan, Zheng-yi Ni, Yu Hu, Wen-hua Liang, Chun-quan Ou, Jian-xing He, Lei Liu,
Hong Shan, Chun-liang Lei, David S.C. Hui, Bin Du, Lan-juan Li, Guang Zeng, KwokYung Yuen, Ru-chong Chen, Chun-li Tang, Tao Wang, Ping-yan Chen, Jie Xiang, Shi-yue
Li, Jin-lin Wang, Zi-jing Liang, Yi-xiang Peng, Li Wei, Yong Liu, Ya-hua Hu, Peng Peng,
Jian-ming Wang, Ji-yang Liu, Zhong Chen, Gang Li, Zhi-jian Zheng, Shao-qin Qiu, Jie
Luo, Chang-jiang Ye, Shao-yong Zhu, and Nan-shan Zhong. Clinical characteristics of
coronavirus disease 2019 in china. New England Journal of Medicine, 382(18):1708‚Äì1720,
2020. doi: 10.1056/NEJMoa2002032.
Paul W. Holland, Kathryn Blackmond Laskey, and Samuel Leinhardt. Stochastic blockmodels: First steps. Social Networks, 5(2):109 ‚Äì 137, 1983. ISSN 0378-8733. doi:
https://doi.org/10.1016/0378-8733(83)90021-7.
Hyokyoung G Hong and Yi Li. Estimation of time-varying reproduction numbers underlying
epidemiological processes: A new statistical tool for the covid-19 pandemic. PloS one, 15
(7), 2020.
Zixin Hu, Qiyang Ge, Li Jin, and Momiao Xiong. Artificial intelligence forecasting of covid-19
in china. 02 2020.
Hohjin Im, Christopher Ahn, Peiyi Wang, and Chuansheng Chen. An early examination:
Psychological, health, and economic correlates and determinants of social distancing amidst
covid-19. 2020.
Jiashun Jin. Fast community detection by score. Annals of Statistics, 43(1):57‚Äì89, 02 2015a.
doi: 10.1214/14-AOS1265.
Jiashun Jin. Fast community detection by score. The Annals of Statistics, 43(1):57‚Äì89,
2015b.
Adam Kucharski, Timothy Russell, Charlie Diamond, Yang Liu, John Edmunds, Sebastian
Funk, Rosalind Eggo, Fiona Sun, Mark Jit, James Munday, Nicholas Davies, Amy Gimma,
Kevin Zandvoort, Hamish Gibbs, Joel Hellewell, Christopher Jarvis, Samuel Clifford, Billy
Quilty, Nikos Bosse, and Stefan Flasche. Early dynamics of transmission and control of
covid-19: a mathematical modelling study. The Lancet Infectious Diseases, 20, 2020. doi:
10.1016/S1473-3099(20)30144-4.
Stephen A Lauer, Kyra H Grantz, Qifang Bi, Forrest K Jones, Qulu Zheng, Hannah Meredith,
Andrew S Azman, Nicholas G Reich, and Justin Lessler. The incubation period of 2019ncov from publicly reported confirmed cases: estimation and application. Annals of internal
medicine, 172(9):577‚Äì582, 2020.
35

Jing Lei and Alessandro Rinaldo. Consistency of spectral clustering in stochastic block
models. Annals of Statistics, 43(1):215‚Äì237, 2015.
Giuseppe Lippi, Camilla Mattiuzzi, Fabian Sanchis-Gomar, and Brandon M. Henry. Clinical
and demographic characteristics of patients dying from covid-19 in italy vs china. Journal
of Medical Virology, 92(10):1759‚Äì1760, 2020.
Zhihua Liu, pierre magal, Ousmane Seydi, and Glenn Webb. Predicting the cumulative number of cases for the covid-19 epidemic in china from early data. Mathematical Biosciences
and Engineering, 17, 2020. doi: 10.1101/2020.03.11.20034314.
Andrew Y. Ng, Michael I. Jordan, and Yair Weiss. On spectral clustering: Analysis and
an algorithm. In ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS,
pages 849‚Äì856. MIT Press, 2001.
Liangrong Peng, Wuyue Yang, Dongyan Zhang, Changjing Zhuge, and Liu Hong. Epidemic
analysis of covid-19 in china by dynamical modeling. medRxiv, 2020. doi: 10.1101/2020.
02.16.20023465.
J C Rajapakse, S Gupta, and X Sui. Fitting networks models for functional brain connectivity.
In 2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI 2017), pages
515‚Äì519, 2017.
Weston C. Roda, Marie B. Varughese, Donglin Han, and Michael Y. Li. Why is it difficult
to accurately predict the covid-19 epidemic? Infectious Disease Modelling, 5:271 ‚Äì 281,
2020. ISSN 2468-0427. doi: https://doi.org/10.1016/j.idm.2020.03.001.
Karl Rohe, Sourav Chatterjee, and Bin Yu. Spectral clustering and the high-dimensional
stochastic blockmodel. The Annals of Statistics, 39(4):1878‚Äì1915, 2011.
David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams. Learning representations
by back-propagating errors. Nature, 323:533‚Äì536, 1986.
Jieli Shen, Regina Y Liu, and Min-ge Xie. i fusion: Individualized fusion learning. Journal
of the American Statistical Association, 115(531):1251‚Äì1267, 2020.
Jianbo Shi and Jitendra Malik. Normalized cuts and image segmentation. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 22(8):888‚Äì905, 2000.
Unacast. Unacast social distancing dataset, 2020.
covid19/social-distancing-scoreboard.

URL https://www.unacast.com/

U von Luxburg. A tutorial on spectral clustering. Statistics and Computing, 17:395‚Äì416,
2007.
Linda Wang and Alexander Wong. Covid-net: A tailored deep convolutional neural network
design for detection of covid-19 cases from chest x-ray images, 2020.
36

Stanley Wasserman and Carolyn Anderson. Stochastic a posteriori blockmodels: Construction and assessment. Social Networks, 9(1):1 ‚Äì 36, 1987. ISSN 0378-8733. doi:
https://doi.org/10.1016/0378-8733(87)90015-3.
Minge Xie, Kesar Singh, and William E Strawderman. Confidence distributions and a unifying framework for meta-analysis. Journal of the American Statistical Association, 106
(493):320‚Äì333, 2011.
Zifeng Yang, Zhiqi Zeng, Ke Wang, Sook-San Wong, Wenhua Liang, Mark Zanin, Peng
Liu, Xudong Cao, Zhongqiang Gao, Zhitong Mai, Jingyi Liang, Xiaoqing Liu, Shiyue Li,
Yimin Li, Feng Ye, Weijie Guan, Yifan Yang, Fei Li, Shengmei Luo anddYuqi Xie, Bin
Liu, Zhoulang Wang, Shaobo Zhang, Yaonan Wang, Nanshan Zhong, and Jianxing He.
Modified seir and ai prediction of the epidemics trend of covid-19 in china under public
health interventions. Journal of Thoracic Disease, 12:165‚Äì174, 2020.
Chuansheng Zheng, Xianbo Deng, Qing Fu, Qiang Zhou, Jiapei Feng, Hui Ma, Wenyu Liu,
and Xinggang Wang. Deep learning-based detection for covid-19 from chest ct using weak
label. medRxiv, 2020a. doi: 10.1101/2020.03.12.20027185.
Nanning Zheng, Shaoyi Du, Jianji Wang, He Zhang, Wenting Cui, Zijian Kang, Tao Yang,
Bin Lou, Yuting Chi, Hong Long, Mei Ma, Qi Yuan, Shupei Zhang, Dong Zhang, Feng Ye,
and Jingmin. Xin. Predicting covid-19 in china using hybrid ai model. IEEE Transactions
on Cybernetics, 50(7):2891‚Äì2904, 2020b.

37

Supplementary Material: Clustering with adjacency matrices
Algorithm 4 outlines the spectral clustering procedure with adjacency matrices A1 and A2
and Tables 10 and 11 present Groups 1 and 2‚Äôs mean, median, and standard deviation of the
17 features.
Algorithm 4 Normalized Laplacian spectral clustering
Input Similarity matrix S ‚àà Rn√ón and K clusters to obtain.
1: Obtain the adjacency matrix A.
‚àí1/2
2: Compute the normalized, symmetric Laplacian matrix L = I ‚àí D
AD ‚àí1/2 .
3: Compute the smallest K eigenvectors in absolute value u1 , ..., uK of L and construct
b ‚àà Rn√óK be the matrix with the eigenvectors as columns.
U
b to have unit norm 1 to get U
b norm .
4: Normalize rows of U
b
5: Clusters the rows of U norm with k-means.
b1 , ..., G
bK of the nodes.
return Partition G

Group 1

Group 2

F eature

Mean

Median

Std Dev

Mean

Median

Std Dev

Population Density
Median Household Income
% Poverty
% 1-person households
% 5 or more person households
% households w 60 y/o and older
% w low access to stores
% low income w low access to stores
% households w low access to stores
25 y/o and older w Bachelor‚Äôs /1,000
% White
% Black
% Asian
No of bars
No of grocery stores
No of restaurants
% take public transportation

501.873
56442.4
13.8581
26.9710
9.25104
38.7766
20.6451
6.77756
2.42279
116.308
78.6730
11.8118
2.78995
47.7015
89.3181
14.9178
0.70840

191.700
53812.0
13.3000
27.2453
8.59139
38.8296
20.5700
6.14000
2.03000
112.763
82.7486
6.07323
1.41062
20.0000
30.0000
9.00000
0.24056

1038.69
14879.8
5.63048
4.37449
3.24107
6.56590
9.36471
4.23293
1.53641
43.5637
15.2783
14.0567
3.98255
90.2649
211.193
15.9277
1.68443

693.482
56872.8
13.6742
27.1832
9.05622
39.2932
22.0766
7.29463
2.50819
117.340
77.9016
13.0591
2.76574
38.6136
73.2670
13.2853
0.96613

210.820
54539.0
12.6500
27.5257
8.56888
39.0888
22.1900
6.42000
2.22000
112.172
81.8775
6.64656
1.49532
18.0000
29.0000
8.00000
0.24533

3575.14
15776.4
5.92796
4.39231
3.02516
6.33139
10.0694
4.78238
1.63217
41.5866
16.9468
15.9400
4.19016
60.4562
130.915
14.1468
6.04509

Table 10: A1 clusters‚Äô mean and median values for selected features for each community K = 2.
Model A1 corresponds to Algorithm 4 where we use the k-nearest neighbors graph (k = 7) as A.

1

Group 1

Group 2

F eature

Mean

Median

Std Dev

Mean

Median

Std Dev

Population Density
Median Household Income
% Poverty
% 1-person households
% 5 or more person households
% of households w 60 y/o and older
% w low access to stores
% low income w low access to stores
% households w low access to stores
25 y/o and older w Bachelor‚Äôs /1,000
% White
% Black
% Asian
No of bars
No of grocery stores
No of restaurants
% take public transportation

712.520
57683.7
13.3879
27.0335
9.06375
38.7801
21.7977
7.09803
2.40026
119.289
78.9164
12.1216
2.73678
41.2933
79.5744
14.2222
0.95377

211.600
54873.0
12.2500
27.2366
8.58968
38.3954
21.9050
6.40000
2.20000
113.846
82.9167
6.12919
1.51268
17.0000
29.0000
8.00000
0.23521

3570.04
15640.9
5.92222
4.36119
2.95150
6.74182
9.85552
4.67050
1.51320
44.2816
15.8005
14.6064
3.88658
79.4118
170.279
15.6239
5.91278

483.554
55628.1
14.1455
27.1226
9.24261
39.2953
20.9322
6.97775
2.53181
114.350
77.6482
12.7612
2.81899
44.9514
82.6123
13.9210
0.71807

189.310
53739.0
13.4000
27.5300
8.57241
39.3441
20.5100
6.13000
2.11000
109.250
81.4956
6.38394
1.41062
21.0000
30.0000
8.00000
0.24792

1076.73
14959.5
5.61381
4.40790
3.30828
6.13981
9.62812
4.37390
1.65335
40.6497
16.4603
15.4733
4.28174
73.3541
179.320
14.4344
2.01788

Table 11: A2 clusters‚Äô mean and median values for selected features for each community K = 2. Model
A2 corresponds to Algorithm 4 where we use the -neighborhood graph ( = 0.007). Group 1 and 2 are the
b 1 and G
b 2 , respectively.
obtained partitions G

2

