Adaptive Group Testing on Networks with
Community Structure
Surin Ahn, Wei-Ning Chen, and Ayfer OÌˆzguÌˆr

arXiv:2101.02405v2 [cs.IT] 9 Mar 2021

Department of Electrical Engineering, Stanford University
{surinahn, wnchen, aozgur}@stanford.edu

Abstract
Since the inception of the group testing problem in World War II, the prevailing assumption
in the probabilistic variant of the problem has been that individuals in the population are
infected by a disease independently. However, this assumption rarely holds in practice, as
diseases typically spread through interactions between individuals and therefore cause infections
to be correlated. Inspired by characteristics of COVID-19 and similar diseases, we consider an
infection model over networks which generalizes the traditional i.i.d. model from probabilistic
group testing. Under this infection model, we ask whether knowledge of the network structure
can be leveraged to perform group testing more efficiently, focusing specifically on communitystructured graphs drawn from the stochastic block model. We prove that when the network and
infection parameters are conducive to â€œstrong community structure,â€ our proposed adaptive,
graph-aware algorithm outperforms the baseline binary splitting algorithm, and is even orderoptimal in certain parameter regimes.

1

Introduction

Identifying individuals who are infected by a disease is crucial for curbing epidemics and ensuring
the well-being of society. However, due to high costs or limited resources, it is often infeasible to
test every member of the population individually. During World War II, when the U.S. military
sought to identify soldiers infected with syphilis, Dorfman made a breakthrough by introducing the
concept of group testing [1]. He showed that by testing groups or pools of samples, the infected
people in a population of size n can be identified with far fewer than n tests. The key insight was
that if the infected population is sparse, then each pooled test is likely to produce a negative result,
in which case all individuals included in the test can simultaneously be deemed healthy. Today,
group testing strategies are actively being used in the COVID-19 pandemic to identify infected
individuals in an efficient and cost-effective manner [2â€“5]. There has also been a recent influx of
papers which seek to improve or better understand group testing for COVID-19, e.g., [6â€“14].
Dorfmanâ€™s seminal work, and subsequent works by other authors on the so-called probabilistic
group testing problem [15â€“21], assume that the disease infects individuals in a statistically independent fashion. However, this assumption rarely holds in practice. Diseases typically spread through
interactions between individuals (e.g., familial, work-related, or other social interactions), thereby
inducing correlated infections. It is thus natural to ask whether exploiting information about this
connectivity structure can lead to more efficient group testing strategies. This problem is especially
timely given the critical role that group testing is playing in the current COVID-19 pandemic, and
given that the disease is known to spread from close contact between individuals.
1

In this paper, we contribute to the nascent area of â€œgroup testing under correlationsâ€ by investigating whether knowledge of the interaction network which dictates the spread of the disease can
be leveraged to perform pooled testing more efficiently. We consider an infection model which generalizes the standard i.i.d. assumption from the probabilistic group testing literature to arbitrary
graphs. Our primary focus is on networks drawn from the stochastic block model, which are likely
to contain clusters of nodes with more dense connections within a cluster than between clusters.
This type of community structure is pervasive in real-world networks such as social, biological, and
information networks.
On the algorithmic side, we consider adaptive group testing schemes, where the design of each
test can be informed by the previous test results. We compare two different schemes: the standard
binary splitting [22] algorithm which is oblivious to the underlying network structure, and a simple
graph-aware algorithm that we propose. We give precise upper bounds on the expected number of
tests performed by each algorithm. Crucially, we show that when the network and infection parameters yield strong community structure (in which case the disease is more likely to be transmitted
within a community than between communities), the graph-aware algorithmâ€™s average complexity
is asymptotically strictly better than that of binary splitting. Finally, we derive novel informationtheoretic lower bounds which apply universally to all adaptive strategies, and which asymptotically
match the graph aware algorithmâ€™s performance (up to constants) in certain parameter regimes. To
the best of our knowledge, this is the first thorough characterization of the complexity of adaptive
group testing in a networked setting.
We note that the underlying principles of this paper may be relevant to numerous settings
beyond healthcare. In the past, group testing has been successfully applied to diverse domains
such as wireless communications [16, 23â€“27], machine learning [28â€“30], signal processing [31], and
data streaming [32]. In these settings and others, there may be a natural â€œclusteringâ€ of the
population into different subgroups which can inform the design of better group testing strategies.
For example, devices which are closer together in a multiple access network may tend to be active
or inactive at the same time. Exploring the potential applications of network-oriented group testing
to these types of problems is of great interest.
Related Works. In the graph-constrained group testing problem [33â€“36], the tests must conform
to a given network topology. For example, if the objective is to identify faulty links in a communication network by sending diagnostic packets, then each test must correspond to a valid path
in the network. In our problem, by contrast, we allow the tests to be arbitrary, but ask whether
knowledge of the interaction network can help to reduce the number of required tests.
Several previous works have assumed that infections occur independently and with non-identical
prior probabilities [15â€“19]. However, our paper pertains to the fully non-i.i.d. case in which infections can be correlated with potentially different priors, depending on the network structure.
The idea of community-aware group testing was first explored in [11]. This work assumes that the
population is partitioned into disjoint â€œfamilies,â€ and that the disease spreads in two stages. In the
first stage, each family is infected independently with probability p, and in the second stage each
member of an infected family is infected independently with probability q. Our work considers more
general network structures and a more realistic disease spread model which allows for transmissions
between communities. We also provide a more thorough analysis of our proposed algorithm, identify the parameter regimes in which it outperforms the baseline, and prove information-theoretic
lower bounds on the minimum number of tests needed to identify infected individuals. Finally, we
acknowledge a number of independent and concurrent works related to community-aware group
testing [14, 37â€“40].

2

Notation. Let [n] , {1, 2, . . . , n}. We denote by n, k, and m , nk the size of the population,
size of each community, and number of communities, respectively. X , (X1 , . . . , Xn ) âˆˆ {0, 1}n
is the infection status vector, where Xv = 1 iff vertex v is infected; X ` , (X1 , . . . , X` ), ` âˆˆ [n];
XCi âˆˆ {0, 1}, i âˆˆ [m], is the infection status of community Ci , where XCi = 1 iff âˆƒv âˆˆ Ci : Xv = 1.
The indicator function for event A is 1A . The entropy of a discrete random variable and the binary
entropy function (both in bits) are H(Â·) and hb (Â·), respectively. We write f (x) â‰º g(x) to denote
f (x) = o(g(x)), and f (x)  g(x) to denote f (x) = O(g(x)). G = (V, E) is an undirected graph with
vertex set V, edge set E, and no self-loops. Let N (v) , {u âˆˆ V : (u, v) âˆˆ E} denote the neighbors
of vertex v, and let d(v) , |N (v)| denote the degree of v.
Paper Organization. The rest of this paper is organized as follows. In Section 2, we describe
the infection and network models. In Section 3, we provide background and preliminary ideas. In
Section 4, we discuss the main algorithms studied in this paper: binary splitting and our proposed
graph-aware algorithm. Section 5 gives upper and lower bounds for adaptive group testing on
networks consisting of disjoint cliques, and Section 6 generalizes these results to the stochastic block
model. Finally, we present the results of our numerical experiments in Section 7, and conclude in
Section 8. All omitted proofs are given in the Appendix.

2

Infection and Network Models

2.1

Infection Model

Let G = (V, E) be an undirected graph without self-loops, where the vertices represent people in the
population and the edges represent interactions between them. We study the following probabilistic
infection model with parameters p, q âˆˆ [0, 1] which acts upon G in two stages (each executed once):
1. Seed Selection: Each vertex in V is infected i.i.d. with probability p. These initial infected
vertices Vs âŠ† V are called the seeds. They model the introduction of the disease into the
population via some external entity (e.g., a traveler carrying the disease into a country).
2. Neighbor Infection:
Every seed v âˆˆ Vs infects each of its neighbors N (v) = {u âˆˆ
V : (u, v) âˆˆ E} i.i.d. with probability q. This models how the disease spreads through the
population via interactions between carriers and nearby individuals.
Remark 1. The above stages can be viewed as the initial spread of an epidemic. They also form
the â€œfirst time stepâ€ of the independent cascade model [41] from the study of influence maximization
in social networks. Our use of this model is motivated by diseases such as COVID-19, which are
initially introduced into a population from an external source and subsequently transmitted between
individuals in close contact. In practice, the specific values of p, q can be tailored to the disease in
question (for example, by using contact tracing to estimate the infectiousness).
Under a graph G = (V, E) with infection parameters p, q, we find that our setting reduces to the
i.i.d. probabilistic group testing model with prior p when (i) q = 0, or (ii) G is the empty graph
where E = âˆ…. It follows that we cannot hope to do any better than classical group testing schemes
in these settings.

2.2

Network Model

For the rest of this paper, we assume that the underlying network is drawn from the stochastic block
model (SBM) [42] â€“ a well-known random graph model with the tendency to produce communitystructured graphs. The standard SBM has the following parameters:
3

(a) Seed selection stage

(b) Neighbor infection with q2 = 0
(the disjoint k-cliques model). Nodes
cannot be infected by seeds outside
their own community.

(c) Neighbor infection with q2 > 0.
Any node can be infected by any seed,
even those in external communities.

Figure 1: Illustration of SBIM(n, k, p, q1 , q2 ). In this example, there are m = 4 communities of size
k = 7. Seeds are colored green, and nodes infected by seeds during the neighbor infection stage are
colored orange.
â€¢ n vertices
â€¢ a partition of the vertex set V = {1, 2, . . . , n} into m communities, C1 , . . . , Cm , where
V and Ci âˆ© Cj = âˆ…, âˆ€i 6= j

S

iâˆˆ[m] Ci

=

â€¢ a symmetric matrix P âˆˆ RmÃ—m of edge probabilities.
The random graph G = (V, E) is then generated by first initializing E = âˆ…, then adding an edge
between each pair of vertices u âˆˆ Ci , v âˆˆ Cj , u 6= v, with probability Pij .
In this paper, we assume the communities are all of size k, where k is a factor of n (so that
the number of communities is m = n/k), and that there is a constant edge probability p1 within
communities, and probability p2 between communities, where p1 > p2 . That is, P equals p1 along
the diagonal entries and p2 on the off-diagonal entries. Finally, we assume that the communities
are known to the group testing algorithms in advance, but that the graph itself may not be known.
This is a natural assumption, as it may be easier to know which communities people belong to
(e.g., families, schools, or workplaces) than whether specific individuals have interacted with each
other.
Stochastic Block Infection Model (SBIM). Our infection model acting upon the SBM can
be equivalently stated in terms of a stochastic community infection model. Assume we are given
a partition of the vertex set V = {1, . . . , n} into m communities C1 , . . . , Cm . Our modified model
still begins by selecting each node i.i.d. with probability p to be a seed. However, in the neighbor
infection phase, each seed infects its neighbors within the same community i.i.d. with probability q1
and infects those outside its community i.i.d. with probability q2 , where q1 > q2 . The equivalence
4

of this model and the original model can be seen by setting q1 = p1 Â· q and q2 = p2 Â· q, where q is
the neighbor infection probability in the original model. We call this the Stochastic Block Infection
Model, denoted by SBIM(n, k, p, q1 , q2 ). Note that SBIM(n, k, p, 0, 0), with k an arbitrary factor of
n, is equivalent to the i.i.d. group testing model.
Disjoint k-Cliques Model. Before analyzing the SBIM in full generality in Section 6, we begin
in Section 5 by investigating the special case of SBIM(n, k, p, q, 0), which we refer to as the disjoint
k-cliques model. Here, we have m = n/k communities of size k, with seed selection probability p,
intra-community transmission rate q, and an inter-community transmission rate of zero. Figure 1
illustrates the SBIM and the difference between the disjoint k-cliques model (q2 = 0) and the general
SBIM with q2 > 0.

3
3.1

Background and Preliminaries
The Group Testing Problem

In the group testing problem, a test corresponds to a subset of individuals S âŠ† [n]. The test
outcome is positive if Xi = 1 for some i âˆˆ S; that is, if at least one member of S is infected.
Otherwise, the test outcome is negative. Equivalently, the outcome is a binary variable Y âˆˆ {0, 1}
given by a Boolean OR operation over S:
_
Y =
Xi .
(1)
iâˆˆS

A group testing algorithm or scheme describes how to select subsets S1 , . . . , ST such that the
infection statuses X1 , . . . , Xn can be determined from the corresponding outcomes Y1 , . . . , YT . In
adaptive schemes, the choice of each St is allowed to depend on {St0 : t0 < t}. Moreover, due
to the underlying randomness in the Xi in our probabilistic setting, the total number of tests T
performed by any adaptive scheme is a random variable. In this work, we assume that test outcomes
are noiseless (meaning the algorithms get to observe Yt as given in (1)), and we require a scheme
to exactly recover X1 , . . . , Xn (i.e., achieve zero error). Our goal is to characterize the complexity
of adaptive schemes under the SBIM by providing both upper and lower bounds on E[T ].

3.2

Marginal Infection Probability for General Graphs

Under a graph G = (V, E), the marginal infection probability of a given vertex v can be characterized
in terms of its degree d(v) as follows.
Lemma 1. Let G = (V, E) be a finite, undirected graph without self-loops. Under G, the infection
status of a vertex v âˆˆ V is Xv âˆ¼ Bernoulli(rv ), where
rv , P(Xv = 1) = 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)d(v) .

(2)

Under a general graph, different nodes may have different degrees and hence different marginal
probabilities of infection. From (2), we see that rv is monotonically non-decreasing with d(v). Note
also that the Xv can be correlated.

5

3.3

Information-Theoretic Lower Bound

A fundamental result in probabilistic group testing is that any adaptive algorithm which is guaranteed to identify all infected members of the population, assuming noiseless test results, requires
a number of tests T satisfying
E[T ] â‰¥ H(X1 , . . . , Xn ).
(3)
This bound highlights the intimate connection between adaptive group testing and source coding.
Indeed, to summarize a discussion from [16], the outcomes of the adaptive tests can be viewed as
a binary, variable-length source code for X. The lower bound then follows directly from existing
results in data compression (e.g., [43, Eqn. 5.38]). Equation (3) will serve as the point of departure
for the lower bounds on E[T ] that we derive in this paper. The key challenge will be to obtain good
approximations to H(X) in the presence of correlations induced by the underlying network.

4
4.1

Algorithms
Binary Splitting Algorithm

Most adaptive group testing algorithms are based on the idea of recursively splitting the population
until all infected members are found. The most standard one is known as binary splitting, which
finds a single infected member at a time by repeatedly halving the population. This algorithm
identifies all infected members using Î± log2 n + O(Î±) adaptive tests (see [44], [22, p.24], or [45,
Theorem 1.2]), where Î± is the number of infected members. It works even when Î± is unknown, and
is most effective in the sparse regime, Î± = Î˜(nÎ² ), where Î² âˆˆ [0, 1). We treat binary splitting as
our baseline in this paper, and we will utilize the following performance guarantee.
Lemma 2. In a population of size n with Î± infected members, where Î± â‰¥ 1, the binary splitting
algorithm is guaranteed to identify all infected members using at most Î±dlog2 ne â‰¤ Î± log2 n + Î±
tests.

4.2

Graph-Aware Algorithm

As an alternative to standard adaptive procedures such as binary splitting, we consider a simple
adaptive scheme which leverages the community structure of the graph. Our scheme first treats
the communities as â€œmeta-individualsâ€ and applies binary splitting to quickly identify the infected
communities (i.e., those with at least one infected member). Subsequently, we run binary splitting
again â€“ this time within each infected community â€“ to identify the infected individuals. Note that
this procedure will exactly recover the infection statuses of all members of the population, which
follows from the fact that binary splitting achieves exact recovery.
Adaptive Graph-Aware Algorithm
1. Mix the samples within each community.
2. Perform binary splitting on the mixed samples to determine which communities contain at
least one infected member.
3. For each positive test from Step 2, perform binary splitting within the corresponding community to identify infected members.

6

This algorithm is similar to that proposed in [11]. The main difference is that after the infected
communities are identified, our algorithm performs an additional round of group testing within
the infected communities, whereas the algorithm in [11] performs individual testing at this stage.
Our approach is preferable if the infections are sparse within each infected community (e.g., if the
disease outbreak is still in its early stages); otherwise, individual testing is suitable.
Under what circumstances should we expect the graph-aware algorithm to outperform binary
splitting? Suppose the underlying interaction network and infection model follow SBIM(n, k, p, q1 , q2 ).
If the seed selection probability p is small, then we expect only a few of the m = n/k communities
to contain a seed. This means that after the neighbor infection stage, several of the communities are
likely to contain no infected members at all, especially if q2 is small. In Step 2 of the graph-aware
algorithm, we can efficiently rule out these uninfected communities from consideration. In Step 3,
we need only perform group testing within each of the remaining communities (which contain at
least one infected member). In contrast, the binary splitting algorithm ignores the community
structure (specifically, the fact that entire communities are likely to be uninfected), and is therefore
unlikely to enjoy the same benefits as the graph-aware algorithm under these circumstances. We
will rigorously verify this intuition in the upcoming sections.

5

Disjoint k-Cliques Model

We first consider the disjoint k-cliques model with communities C1 , . . . , Cm . The seed selection
probability is p âˆˆ (0, 1], the transmission rate within a community is q âˆˆ [0, 1], and no transmissions
are possible between communities. This setting resembles the disjoint families model from [11].
However, in their model, each member of an â€œinfected familyâ€ is infected independently with a
fixed probability, whereas the infection rate within a given community in our model depends on the
number of seeds in the community. In addition to being more realistic, this makes the derivation
of lower bounds and the analysis of group testing schemes more intricate. We note that analogous
lower bounds are absent in [11].

5.1

Information-Theoretic Lower Bound

Recall from (3) that E[T ] â‰¥ H(X) for any adaptive group testing algorithm which exactly identifies
the infected individuals using T tests. Since the infection statuses across the m disjoint cliques are
independent, we have E[T ] â‰¥ m Â· H(X1 , . . . , Xk ), where without loss of generality we assume
C1 = [k]. Thus, obtaining a lower bound on E[T ] reduces to lower bounding H(X1 , . . . , Xk ), i.e.,
the entropy corresponding to a single k-clique. The following lemma lower bounds H(X1 , . . . , Xk )
in terms of a binomial random variable, which ultimately leads to the asymptotic lower bound given
in Theorem 1 below.
Lemma 3. Under the disjoint k-cliques model, the number of tests T required to identify the infected
individuals is lower bounded as


E[T ] â‰¥ m Â· EZ (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q)Z ,
where Z âˆ¼ Binom (k, p) .
Next, we have the following technical lemma which characterizes the asymptotic behavior of
the bound in Lemma 3 by leveraging the concentration of Z around its mean.

7

Lemma 4. Let Z âˆ¼ Binom (k, p) and assume kp  1 and q 

âˆš

r 1 
.
1
kÂ· log kÂ·p

Then






1
Z
2
.
EZ (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q)
 k Â· p Â· q Â· log k + log log
kÂ·p
Upon combining Lemma 3 and Lemma 4, we see that the number of tests T needed to recover
all infected members in the disjoint k-cliques graph (in the specified parameter regime) is lower
bounded as

 
1
2
E[T ]  m Â· k Â· p Â· q Â· log k + log log
.
kp
Note that another lower bound is given by


(a)
E[T ] â‰¥ H(X1 , . . . , Xn ) â‰¥ H(XC1 , . . . , XCm ) = m Â· hb 1 âˆ’ (1 âˆ’ p)k

(4)

where (a) uses
 the fact that XC1 , . . . , XCm are a function of X1 , . . . , Xn . Furthermore, since kp  1,
we have hb 1 âˆ’ (1 âˆ’ p)k  k Â· p Â· log2 (1/kp). We summarize the refined lower bound in the following
theorem:
Theorem 1. Assume kp  1 and q 

1
r
k log



1
kp

.

Then under the disjoint k-cliques model, the

expected number of tests required to identify the infected individuals is lower bounded as





 1 
1
2
, m Â· k Â· p Â· log
, 1 .
E[T ]  max m Â· k Â· p Â· q Â· log k + log log
kÂ·p
kÂ·p

5.2
5.2.1

Algorithm Analysis
Binary Splitting

The following result bounds the expected number of tests used by the binary splitting algorithm
under the disjoint k-cliques model.
Theorem 2. Under the disjoint k-cliques model, the binary splitting algorithm identifies all infected
individuals using T tests, where

 

E[T ] â‰¤ m Â· k Â· log2 m + log2 k + 1 Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1 .
Proof. Let K be the number of infected nodes (which is a random variable in our setting). Then
n
n
hX
i X
E[K] = E
Xi =
P(Xi = 1) = n Â· r
i=1

i=1

where r = 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1 by Lemma 1. Invoking Lemma 2 yields the result.

8

Asymptotic Analysis: Using Theorem 2, we find that the average complexity of binary splitting
is O m Â· k 2 Â· p Â· (log2 m + log2 k) Â· (1/k + q) since


E[T ]  m Â· k Â· (log m + log k) Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1


(a)
â‰¤ m Â· k Â· (log m + log k) Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ kpq)
= m Â· k Â· (log m + log k) Â· (p + kpq âˆ’ kp2 q)
â‰¤ m Â· k Â· (log m + log k) Â· (p + kpq)

1
+q
= m Â· k 2 Â· p Â· (log m + log k) Â·
k

(5)

where in (a) we use the fact that (1 + x)k â‰¥ 1 + kx for x â‰¥ âˆ’1, k â‰¥ 1.
5.2.2

Graph-Aware Algorithm

Next, we provide an upper bound on the expected number of tests performed by the graph-aware
algorithm. The two terms in the sum below correspond, respectively, to the expected number of
tests in Steps 2 and 3 of the algorithm.
Theorem 3. Under the disjoint k-cliques model, the graph-aware algorithm identifies all infected
individuals using T tests, where

 


 

E[T ] â‰¤ m Â· log2 m + 1 Â· 1 âˆ’ (1 âˆ’ p)k + n Â· log2 k + 1 Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1
Asymptotic Analysis: Using Theorem 3 and the fact that (1 + x)k â‰¥ 1 + kx for x â‰¥ âˆ’1, k â‰¥ 1,
we find that the average complexity of the graph-aware algorithm is given by
1

E[T ]  m Â· k Â· p Â· log m + m Â· k 2 Â· p Â·
+ q Â· log k.
(6)
k

5.3

Discussion

We summarize the expected number of tests of binary splitting and the graph-aware algorithm, as
well as the information-theoretic lower bound, in Table 1.
Binary splitting
Graph-aware
Lower bound

1
k



+ q Â· log m + m Â· k 2 Â· p Â· k1 + q Â· log k


m Â· k Â· p Â· log m + m Â· k 2 Â· p Â· k1 + q Â· log k
 

 
1
1
m Â· k Â· p Â· log kp
+ m Â· k 2 Â· p Â· q Â· log k + log log kp
+1
m Â· k2 Â· p Â·

Table 1: Upper and lower bounds on the expected number of tests in the disjoint k-cliques model.
Next, we discuss different parameter regimes where 1) the lower bound holds, 2) the graphaware algorithm is order-optimal (i.e., the lower bound is tight), and 3) the graph-aware algorithmâ€™s
average complexity is strictly better than binary splittingâ€™s. As stated in Corollary 1, the lower
bound holds when kp  1 and q  r 1   . The next corollary specifies the regime where the
k log

1
kp

graph-aware algorithm is tight:
9

Corollary 1. If the following conditions hold:
1. kp  mâˆ’Î± for some fixed Î± âˆˆ (0, 1),
2.

1
k

q

1
r
 ,
1
k log kp

then the lower bound is tight, and moreover the graph-aware algorithm is order-optimal.
 
 
1
1
Proof. Plugging log kp
 Î± log m into the lower bound and using the fact that k  log kp
from
the second condition (which implies log k  log log m) yields
E[T ]  m Â· k Â· p Â· log m + m Â· k 2 Â· p Â· q Â· (log k + log log m) + 1
 m Â· k Â· p Â· log m + m Â· k 2 Â· p Â· q Â· log k,
and applying q  1/k to the bound for the graph-aware algorithm yields
E [T ]  m Â· k Â· p Â· log m + m Â· k 2 Â· p Â· q Â· log k.

Finally, we specify the regime where the graph-aware algorithm outperforms binary splitting:
Corollary 2. If log m  log k and kq  1, then the graph-aware algorithmâ€™s
average
complexity is
n
o
log m
asymptotically strictly better than binary splittingâ€™s by a factor of min kq, log k .
Proof. Under the above conditions, binary splittingâ€™s average complexity is
m Â· k 2 Â· p Â· q Â· log m
whereas the graph aware algorithmâ€™s average complexity is
o
n
max m Â· k Â· p Â· log m, m Â· k 2 Â· p Â· q Â· log k .
{z
} |
{z
}
|
(a)

(b)

Both (a) and (b) are strictly smaller than the binary splitting bound. We see that (a) saves a factor
m
of kq  1, while (b) saves a factor of log
log k  1.
In Table 2, we summarize the different parameter regimes discussed so far.
kp  1 and q 

Lower boundâ€™s conditions

1
r
k log

Tightness conditions

kp 

mâˆ’Î±



1
kp



r
 
1
and 1  kq  k/ log kp

log m  log k and kq  1

Improvement conditions

Table 2: Parameter regimes of interest for the disjoint k-cliques model.
The main takeaway is that the graph-aware algorithm can potentially improve upon binary
splitting when (i) there are several moderately sized communities in the network, and (ii) the
10

transmission rate within each clique is significant. Additionally, the graph-aware algorithm is
order-optimal when the seeds are sparse. However, one can verify that when q  1/k, i.e., the
intra-clique transmission rate is small, then the bounds for binary splitting and the graph-aware
algorithm are order-wise equivalent. This suggests that knowledge of the community structure may
not help in this regime. Intuitively, this makes sense because when q is small, the infection statuses
of the vertices are â€œmostly independent.â€

6

Stochastic Block Infection Model

Having studied the disjoint k-cliques model, we now turn to the fully general SBIM(n, k, p, q1 , q2 ),
where p âˆˆ (0, 1] and q1 , q2 âˆˆ [0, 1].

6.1

Information-Theoretic Lower Bound

Similar to Section 5.1, we obtain the following lower bounds for adaptive group testing over the
SBIM. The proof of the following lemma is similar to that of Lemma 3, except that we must now
take into account the transmission of the disease between communities. This is reflected in the
additional binomial random variable Z 0 appearing within the binary entropy function.
Lemma 5. Under SBIM(n, k, p, q1 , q2 ), the number of tests T required to identify the infected individuals is lower bounded as
h

i
Z0
Z
0
E[T ] â‰¥ m Â· EZ,Z (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q1 ) (1 âˆ’ q2 )
,
where Z âˆ¼ Binom (k, p) and Z 0 âˆ¼ Binom(n âˆ’ k, p) are independent.
Similar to Lemma 4, the following technical lemma leverages the concentration of Z and Z 0
around their means.
Lemma 6. Let Z âˆ¼ Binom(k, p) and Z 0 âˆ¼ Binom(n âˆ’ k, p) be independent, and assume
1. n Â· p Â· q2  1,
2. n Â· p  1,
3. k Â· p Â· q1  1,
4. q1 â‰¤

r  1   .
1
2k log kp
+1

Then the following lower bound holds:




h

i
0
1
1
EZ,Z 0 (k âˆ’ Z)Â·hb 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z
 mk 2 pq2 log
+ k 2 pq1 log
.
npq2
q1 + npq2
Theorem 4. In the parameter regime specified in Lemma 6, the number of tests T needed to recover
all infected members over SBIM(n, k, p, q1 , q2 ) is lower bounded as




1
1
2
2
2
+ m Â· k Â· p Â· q1 Â· log
.
E[T ]  m Â· k Â· p Â· q2 Â· log
n Â· p Â· q2
q1 + n Â· p Â· q2
Remark 2. Recall that in the disjoint k-cliques model, we obtained an additional lower bound in
Equation (4) given by H (XC1 , ..., XCm ), which dominates when kp  mâˆ’Î± . However, under the
general SBIM, the {XC1 , ..., XCm } are no longer mutually independent, rendering the analysis of
H (XC1 , ..., XCm ) difficult. Therefore, we suspect that the lower bound given in Theorem 4 is not
tight when kp is small. Resolving this issue is an open problem.
11

6.2

Algorithm Analysis

To analyze binary splitting and the graph-aware algorithm over the SBIM, we begin by extending
Lemma 1.
Lemma 7. The marginal probability of infection for every vertex v under SBIM(n, k, p, q1 , q2 ) is
given by
P(Xv = 1) = 1 âˆ’ (1 âˆ’ p) Â· (1 âˆ’ p Â· q1 )kâˆ’1 Â· (1 âˆ’ p Â· q2 )nâˆ’k .
6.2.1

Binary Splitting

Next, we generalize the bound in Theorem 2 to the SBIM. Notice that in both the Theorem 5
bound and the asymptotic bound derived below, we recover the corresponding bounds from the
disjoint k-cliques setting when we set q1 = q, q2 = 0.
Theorem 5. Under SBIM(n, k, p, q1 , q2 ), the binary splitting algorithm identifies all infected individuals using T tests, where


E[T ] â‰¤ n Â· (log2 n + 1) Â· 1 âˆ’ (1 âˆ’ p) Â· (1 âˆ’ p Â· q1 )kâˆ’1 Â· (1 âˆ’ p Â· q2 )nâˆ’k .
Proof. Let K be the number of infected nodes. Then
n
n
hX
i X
E[K] = E
Xi =
P(Xi = 1) = n Â· r
i=1

i=1

where r = 1 âˆ’ (1 âˆ’ p) Â· (1 âˆ’ p Â· q1 )kâˆ’1 Â· (1 âˆ’ p Â· q2 )nâˆ’k by Lemma 7. Invoking Lemma 2 yields the
result.
Asymptotic Analysis: Using the fact that (1 + x)k â‰¥ 1 + kx for x â‰¥ âˆ’1, k â‰¥ 1, we have


E[T ]  n Â· log n Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ k Â· p Â· q1 ) Â· (1 âˆ’ (n âˆ’ k) Â· p Â· q2 )


â‰¤ n Â· log n Â· (n âˆ’ k) Â· p Â· q2 + k Â· p Â· q1 + p + k Â· (n âˆ’ k) Â· p3 Â· q1 Â· q2
1

â‰¤ m Â· k 2 Â· p Â· (log m + log k) Â·
+ q1 + m Â· q2 + m Â· k Â· p2 Â· q1 Â· q2 .
k
6.2.2

(7)

Graph-Aware Algorithm

First, we provide a lemma needed to prove the upper bound for the graph-aware algorithm in
Theorem 6. Again, note that by setting q1 = q, q2 = 0 in Theorem 6 and the resulting asymptotic
bound, we recover the corresponding bounds from the disjoint k-cliques setting.
Lemma 8. Let XC1 be the indicator variable which equals 1 if at least one member of community
C1 is infected. Then under SBIM(n, k, p, q1 , q2 ),
P(XC1 = 1) = 1 âˆ’ (1 âˆ’ p)k Â·



1 âˆ’ p Â· 1 âˆ’ (1 âˆ’ q2 )k

12



!nâˆ’k
.

Theorem 6. Under SBIM(n, k, p, q1 , q2 ), the graph-aware algorithm identifies all infected individuals using T tests, where
!
!


 nâˆ’k
n 
k
k
E[T ] â‰¤ Â· log2 (n/k) + 1 Â· 1 âˆ’ (1 âˆ’ p) Â· 1 âˆ’ p Â· 1 âˆ’ (1 âˆ’ q2 )
k

 

+ n Â· log2 k + 1 Â· 1 âˆ’ (1 âˆ’ p) Â· (1 âˆ’ p Â· q1 )kâˆ’1 Â· (1 âˆ’ p Â· q2 )nâˆ’k .
Proof. Same steps as the proof of Theorem 3 (given in the Appendix), except using Lemma 7 and
Lemma 8 wherever P(X1 = 1) and P(XC1 = 1) are needed, respectively.
Asymptotic Analysis:
Let T1 and T2 be the first and second terms in the Theorem 6 bound,
respectively. Using the fact that (1 âˆ’ q2 )k â‰¥ 1 âˆ’ kq2 , we have


1 âˆ’ p Â· 1 âˆ’ (1 âˆ’ q2 )k â‰¥ 1 âˆ’ p Â· k Â· q2 ,
so

nâˆ’k 


k
k
E[T1 ]  m log m Â· 1 âˆ’ (1 âˆ’ p) Â· 1 âˆ’ p 1 âˆ’ (1 âˆ’ q2 )


 m log m Â· 1 âˆ’ (1 âˆ’ p)k Â· (1 âˆ’ p Â· k Â· q2 )nâˆ’k
 m log m Â· (1 âˆ’ (1 âˆ’ k Â· p) Â· (1 âˆ’ (n âˆ’ k) Â· p Â· k Â· q2 ))
 m log m Â· (k Â· p + n Â· p Â· k Â· q2 ) .
Following the previous asymptotic analysis for binary splitting,
E[T2 ]  m Â· k 2 Â· p Â· log k Â·

1
k


+ q1 + m Â· q2 + m Â· k Â· p 2 Â· q1 Â· q2 .

Therefore,



1
+ q1 + m Â· q2 + m Â· k Â· p2 Â· q1 Â· q2 . (8)
E[T ]  m Â· k Â· p Â· log m Â· 1 + m Â· k Â· q2 + m Â· k 2 Â· p Â· log k Â·
k

6.3

Discussion

One regime where the graph-aware algorithmâ€™s average complexity is asymptotically strictly better
than that of binary splitting is
1. log m  log k
2. kq1  1
3.

(i) 1  mkq2
or
(ii) mkq2  1 and mkq2 â‰º kq1 

1
.
p2

13

Suppose conditions 1, 2, and 3(i) hold. Binary splittingâ€™s average complexity (7) becomes
m Â· k 2 Â· p Â· q1 Â· log m
whereas the graph-aware algorithmâ€™s average complexity (8) becomes
n
o
max m Â· k Â· p Â· log m, m Â· k 2 Â· p Â· q1 Â· log k .
The first term in the graph-aware bound improves upon binary splittingâ€™s complexity by a factor
m
of kq1  1, and the second term improves by a factor of log
log k  1. Thus, the overall improvement
o
n
m
is a factor of min kq, log
log k , which matches Corollary 2. This is not very surprising because the
SBIM asymptotically behaves like the disjoint k-cliques model under condition 3(i), i.e., when q2 is
very small.
However, improvements are still made by the graph-aware algorithm in a more intermediate
regime for q2 . Under condition 3(ii), binary splittingâ€™s average complexity is the same as above,
and the graph-aware algorithmâ€™s complexity becomes
n
o
max m2 Â· k 2 Â· p Â· q2 Â· log m, m Â· k 2 Â· p Â· q1 Â· log k ,
which represents an improvement over binary splitting by a factor of min

7

n

q1
log m
mÂ·q2 , log k

o

 1.

Numerical Experiments

We implemented the binary splitting and graph-aware algorithms and evaluated their performance
over random instances of the SBIM. The population size was set to n = 1000, and p was varied
over the interval [0, 0.1]. We ran 20 trials for each value of p, where a trial consists of generating
an instance from SBIM(n, k, p, q1 , q2 ), then observing the number of tests used by binary splitting
and the graph-aware algorithm to identify the infected nodes. We estimated the lower bound from
Lemma 5 by averaging over many independent samples of Z âˆ¼ Binom(k, p) and Z 0 âˆ¼ Binom(n âˆ’
k, p).
Figure 2 shows some representative plots of the estimated E[T ] as a function of p, with k = 20
and different values of q1 , q2 . The error bars show Â± one standard deviation of the values of T
obtained for a particular value of p. For comparison, we also plot the theoretical upper bounds
from Theorem 5 and Theorem 6; we find that these bounds remain quite faithful to the empirical
results. Additionally, the graph-aware algorithm consistently outperforms binary splitting. For
example, in Figure 2b, at p â‰ˆ 0.07, binary splitting has surpassed the individual testing threshold
with an average of 1271.5 tests, whereas the graph-aware algorithm uses an average of 813.8 tests;
this represents a 36% reduction in testing. The graph-aware algorithm also seems to enjoy lower
variance than binary splitting.
In Figure 3, we fix q1 = 0.01, q2 = 0.001, and vary the community size k âˆˆ {10, 50, 100}. The
graph-aware algorithm seems to perform most favorably for moderate values of k, such as k = 20
(as shown in Figure 2c) or k = 50, i.e., when there are several moderately sized communities in the
network. This is consistent with our earlier theoretical results.
Although the graph-aware algorithm improves significantly upon binary splitting, there is still a
sizable gap between the graph-aware bound and the lower bound shown in the plots. This suggests
that in the non-asymptotic regime, either the lower bound is not tight or better algorithms exist.

14

(a)

(b)

(c)

(d)

Figure 2: Performance comparison between binary splitting and the graph-aware algorithm under
the SBIM with n = 1000, k = 20, and different values of p, q1 , q2 . Theoretical upper and lower
bounds are also shown.

8

Conclusion

In this paper, we investigated the group testing problem over networks with community structure.
Motivated by diseases such as COVID-19, we proposed a network infection model to capture how
certain diseases are introduced into a population and subsequently transmitted through close contact between individuals. Our proposed group testing algorithm, which exploits the structure of
the underlying graph, provably outperforms the network-oblivious binary splitting algorithm, and
is even order-optimal in certain parameter regimes.
We conclude with some practical considerations and future directions. First, we note that the
community-structured networks studied in this paper can model populations at different scales:
the â€œcommunitiesâ€ can be schools, families, counties, etc. The insights from our work can also be
extended to more general networks in the real world, where the communities may not be known
in advance. In such instances, one might use the following pipeline to efficiently identify infected
individuals in the population: 1) estimate the network from data (e.g., mobile phone data, Facebook
social graph); 2) run a clustering algorithm to identify communities in the network; 3) perform
graph-aware group testing using the previously identified communities. An interesting direction

15

(a)

(b)

(c)

Figure 3: Performance comparison between binary splitting and the graph-aware algorithm under
the SBIM with n = 1000, q1 = 0.01, q2 = 0.001, and different values of p, k. Theoretical upper and
lower bounds are also shown.
for future work is to explore the efficacy of such an approach. Other directions of interest include
designing non-adaptive group testing schemes for networks, studying graph-aware group testing
under noisy test outcomes, and extending our infection model to longer time horizons (e.g., SIR or
SIS-type infection models from the epidemiology literature).

Acknowledgement
This work was supported in part by NSF Grant #1817205, a Cisco Systems Stanford Graduate
Fellowship, and a National Semiconductor Corporation Stanford Graduate Fellowship.

References
[1] R. Dorfman, â€œThe detection of defective members of large populations,â€ The Annals of Mathematical Statistics, vol. 14, no. 4, pp. 436â€“440, 1943.

16

[2] J. Ellenberg, â€œFive people. One test. This is how you get there.â€ https://www.nytimes.com/
2020/05/07/opinion/coronavirus-group-testing.html. Accessed: July 31, 2020.
[3] S. Mallapaty, â€œThe mathematical strategy that could transform coronavirus testing.â€ https:
//www.nature.com/articles/d41586-020-02053-6. Accessed: July 31, 2020.
[4] Centers for Disease Control and Prevention, â€œInterim guidance for use of pooling procedures in SARS-CoV-2 diagnostic, screening, and surveillance testing.â€ https://www.cdc.gov/
coronavirus/2019-ncov/lab/pooling-procedures.html. Accessed: December 21, 2020.
[5] C. A. Hogan, M. K. Sahoo, and B. A. Pinsky, â€œSample pooling as a strategy to detect community transmission of SARS-CoV-2,â€ JAMA, vol. 323, no. 19, pp. 1967â€“1969, 2020.
[6] L. N. Theagarajan, â€œGroup testing for COVID-19: How to stop worrying and test more,â€
arXiv preprint arXiv:2004.06306, 2020.
[7] J. N. Eberhardt, N. P. Breuckmann, and C. S. Eberhardt, â€œMulti-stage group testing improves
efficiency of large-scale COVID-19 screening,â€ Journal of Clinical Virology, p. 104382, 2020.
[8] S. Ghosh, R. Agarwal, M. A. Rehan, S. Pathak, P. Agrawal, Y. Gupta, S. Consul, N. Gupta,
R. Goyal, A. Rajwade, et al., â€œA compressed sensing approach to group-testing for COVID-19
detection,â€ arXiv preprint arXiv:2005.07895, 2020.
[9] A. Cohen, N. Shlezinger, A. Solomon, Y. C. Eldar, and M. MeÌdard, â€œMulti-level group testing
with application to one-shot pooled COVID-19 tests,â€ arXiv preprint arXiv:2010.06072, 2020.
[10] L. Abraham, G. Becigneul, B. Coleman, B. Scholkopf, A. Shrivastava, and A. Smola, â€œBloom
origami assays: Practical group testing,â€ arXiv preprint arXiv:2008.02641, 2020.
[11] P. Nikolopoulos, T. Guo, C. Fragouli, and S. Diggavi, â€œCommunity aware group testing,â€
arXiv preprint arXiv:2007.08111, 2020.
[12] R. Gabrys, S. Pattabiraman, V. Rana, J. Ribeiro, M. Cheraghchi, V. Guruswami, and
O. Milenkovic, â€œAC-DC: Amplification curve diagnostics for Covid-19 group testing,â€ arXiv
preprint arXiv:2011.05223, 2020.
[13] J. Zhu, K. Rivera, and D. Baron, â€œNoisy pooled PCR for virus testing,â€ arXiv preprint
arXiv:2004.02689, 2020.
[14] R. Goenka, S.-J. Cao, C.-W. Wong, A. Rajwade, and D. Baron, â€œContact tracing enhances
the efficiency of COVID-19 group testing,â€ arXiv preprint arXiv:2011.14186, 2020.
[15] F. Hwang, â€œA generalized binomial group testing problem,â€ Journal of the American Statistical
Association, vol. 70, no. 352, pp. 923â€“926, 1975.
[16] J. Wolf, â€œBorn again group testing: Multiaccess communications,â€ IEEE Transactions on
Information Theory, vol. 31, no. 2, pp. 185â€“191, 1985.
[17] M. Sobel and P. A. Groll, â€œGroup testing to eliminate efficiently all defectives in a binomial
sample,â€ Bell System Technical Journal, vol. 38, no. 5, pp. 1179â€“1252, 1959.
[18] T. Li, C. L. Chan, W. Huang, T. Kaced, and S. Jaggi, â€œGroup testing with prior statistics,â€
in IEEE International Symposium on Information Theory (ISIT), pp. 2346â€“2350, 2014.
17

[19] T. Kealy, O. Johnson, and R. Piechocki, â€œThe capacity of non-identical adaptive group testing,â€ in Allerton Conference on Communication, Control, and Computing, pp. 101â€“108, 2014.
[20] H. A. Inan, P. Kairouz, M. Wootters, and A. OÌˆzguÌˆr, â€œOn the optimality of the KautzSingleton construction in probabilistic group testing,â€ IEEE Transactions on Information
Theory, vol. 65, no. 9, pp. 5592â€“5603, 2019.
[21] H. A. Inan and A. Ozgur, â€œStrongly explicit and efficiently decodable probabilistic group
testing,â€ in 2020 IEEE International Symposium on Information Theory (ISIT), pp. 525â€“530,
IEEE, 2020.
[22] D. Du, F. K. Hwang, and F. Hwang, Combinatorial Group Testing and Its Applications, vol. 12.
World Scientific, 2000.
[23] T. Berger, N. Mehravari, D. Towsley, and J. Wolf, â€œRandom multiple-access communication
and group testing,â€ IEEE Transactions on Communications, vol. 32, no. 7, pp. 769â€“779, 1984.
[24] H. A. Inan, P. Kairouz, and A. Ozgur, â€œSparse group testing codes for low-energy massive
random access,â€ in Allerton Conference on Communication, Control, and Computing, pp. 658â€“
665, 2017.
[25] H. A. Inan, P. Kairouz, and A. Ozgur, â€œEnergy-limited massive random access via noisy group
testing,â€ in IEEE International Symposium on Information Theory (ISIT), pp. 1101â€“1105,
2018.
[26] H. A. Inan, S. Ahn, P. Kairouz, and A. Ozgur, â€œA group testing approach to random access
for short-packet communication,â€ in IEEE International Symposium on Information Theory
(ISIT), pp. 96â€“100, 2019.
[27] H. A. Inan, P. Kairouz, and A. OÌˆzguÌˆr, â€œSparse combinatorial group testing,â€ IEEE Transactions on Information Theory, vol. 66, no. 5, pp. 2729â€“2742, 2019.
[28] S. Ubaru and A. Mazumdar, â€œMultilabel classification with group testing and codes,â€ in International Conference on Machine Learning, pp. 3492â€“3501, 2017.
[29] Y. Zhou, U. Porwal, C. Zhang, H. Q. Ngo, X. Nguyen, C. ReÌ, and V. Govindaraju, â€œParallel feature selection inspired by group testing,â€ Advances in Neural Information Processing
Systems, vol. 27, pp. 3554â€“3562, 2014.
[30] D. Malioutov and K. Varshney, â€œExact rule learning via boolean compressed sensing,â€ in
International Conference on Machine Learning, pp. 765â€“773, 2013.
[31] A. C. Gilbert, M. A. Iwen, and M. J. Strauss, â€œGroup testing and sparse signal recovery,â€ in
Asilomar Conference on Signals, Systems and Computers, pp. 1059â€“1063, 2008.
[32] A. Emad and O. Milenkovic, â€œPoisson group testing: A probabilistic model for nonadaptive streaming boolean compressed sensing,â€ in IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP), pp. 3335â€“3339, 2014.
[33] N. J. Harvey, M. Patrascu, Y. Wen, S. Yekhanin, and V. W. Chan, â€œNon-adaptive fault diagnosis for all-optical networks via combinatorial group testing on graphs,â€ in IEEE International
Conference on Computer Communications (INFOCOM), pp. 697â€“705, 2007.

18

[34] M. Cheraghchi, A. Karbasi, S. Mohajer, and V. Saligrama, â€œGraph-constrained group testing,â€
IEEE Transactions on Information Theory, vol. 58, no. 1, pp. 248â€“262, 2012.
[35] A. Karbasi and M. Zadimoghaddam, â€œSequential group testing with graph constraints,â€ in
IEEE Information Theory Workshop (ITW), pp. 292â€“296, 2012.
[36] B. Spang and M. Wootters, â€œUnconstraining graph-constrained group testing,â€ arXiv preprint
arXiv:1809.03589, 2018.
[37] P. Nikolopoulos, S. R. Srinivasavaradhan, T. Guo, C. Fragouli, and S. Diggavi, â€œGroup testing
for overlapping communities,â€ arXiv preprint arXiv:2012.02804, 2020.
[38] P. Bertolotti and A. Jadbabaie, â€œNetwork group testing,â€ arXiv preprint arXiv:2012.02847,
2020.
[39] B. Arasli and S. Ulukus, â€œGroup testing with a graph infection spread model,â€ arXiv preprint
arXiv:2101.05792, 2020.
[40] Y.-J. Lin, C.-H. Yu, T.-H. Liu, C.-S. Chang, and W.-T. Chen, â€œPositively correlated samples
save pooled testing costs,â€ arXiv preprint arXiv:2011.09794, 2020.
[41] D. Kempe, J. Kleinberg, and EÌ. Tardos, â€œMaximizing the spread of influence through a social network,â€ in ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining, pp. 137â€“146, 2003.
[42] P. W. Holland, K. B. Laskey, and S. Leinhardt, â€œStochastic blockmodels: First steps,â€ Social
Networks, vol. 5, no. 2, pp. 109â€“137, 1983.
[43] T. M. Cover and J. A. Thomas, Elements of Information Theory, 2nd Edition. Wiley, 2006.
[44] L. Baldassini, O. Johnson, and M. Aldridge, â€œThe capacity of adaptive group testing,â€ in IEEE
International Symposium on Information Theory (ISIT), pp. 2676â€“2680, 2013.
[45] M. Aldridge, O. Johnson, and J. Scarlett, â€œGroup testing: An information theory perspective,â€
arXiv preprint arXiv:1902.06002, 2019.

19

Appendix
A

Proof of Lemma 1

Let Yv be the indicator random variable of whether vertex v is a seed. First, we have
P(Xv = 1) = P (Xv = 1 | Yv = 1) Â· P(Yv = 1) +P (Xv = 1 | Yv = 0) Â· P(Yv = 0)
|
{z
} | {z }
=p

=1

= p + (1 âˆ’ p) Â· P (Xv = 1 | Yv = 0) .
Given that v is not a seed, Xv = 1 if and only if v is infected by one of its neighbors. Hence,
P (Xv = 1 | Yv = 0) = P ({v is infected by a neighbor})
= 1 âˆ’ P ({v isnâ€™t infected by any neighbor})
Y
P ({v isnâ€™t infected by u})
=1âˆ’
uâˆˆN (v)

Y

=1âˆ’

1 âˆ’ P ({v is infected by u})



uâˆˆN (v)

Y

=1âˆ’


1 âˆ’ P ({v is infected by u} | Yu = 1) Â· P(Yu = 1)

uâˆˆN (v)

Y

=1âˆ’

(1 âˆ’ pq)

uâˆˆN (v)

= 1 âˆ’ (1 âˆ’ pq)d(v) .


B
B.1

Lower Bounds for the Disjoint k-Cliques Model
Proof of Lemma 3

Since H(X1 , ..., Xn ) = m Â· H(X1 , ..., Xk ), it suffices to lower bound H(X1 , ..., Xk ). By the fact that
conditioning reduces entropy, we have




X
H (X1 , ..., Xk ) â‰¥ H (X1 , ..., Xk | Y1 , ..., Yk ) =
P Y k = yk Â· H X k Y k = y k
y k âˆˆ{0,1}k

where Yv is the indicator variable of whether vertex v is a seed. Observe that after conditioning
on the locations
of the seeds, X1 ,..., Xk are mutually
independent. Moreover, by symmetry, both

P
k
k
k
k
k
P Y = y and H X Y = y depend on i yi , (i.e., the empirical distribution of y k ). Indeed,
the marginal distribution of Xi can be specified as follows:
(


1,
if yi = 1,
P
P Xi = 1 Y k = y k =
yi )
(
i
1 âˆ’ (1 âˆ’ q)
, if y = 0,
i

and the conditional entropy is


H X

k

k

Y =y

k



!
=

kâˆ’

X

yi

i

20



P
Â· hb 1 âˆ’ (1 âˆ’ q)( i yi ) ,

P
where hb (Â·) is the binary entropy function. Therefore, by writing Z = i Yi , we have




H X k Y k = EZ (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q)Z ,

(9)

where Z âˆ¼ Binom (k, p) .


B.2

Proof of Theorem 4

Let f (q) =

log(q)
log(1âˆ’q) ,

so that f (q) solves 1 âˆ’ (1 âˆ’ q)Z = 1 âˆ’ q. Then we bound (9) by






EZ (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q)Z â‰¥ EZ (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q)Z Â· 1{1â‰¤Zâ‰¤f (q)}
(a)



â‰¥ hb (q) Â· EZ (k âˆ’ Z) Â· 1{1â‰¤Zâ‰¤f (q)}

â‰¥ hb (q) (EZ [k âˆ’ Z] âˆ’ k Â· P {Z = 0} âˆ’ k Â· P {Z > f (q)})




= k Â· hb (q) (1 âˆ’ p) 1 âˆ’ (1 âˆ’ p)kâˆ’1 âˆ’ P {Z > f (q)}
(b)



â‰¥ k Â· hb (q) (1 âˆ’ p) (k âˆ’ 1)p âˆ’ (k âˆ’ 1)2 p2 âˆ’ P {Z > f (q)}

(c)



k
Â· hb (q) (k Â· p âˆ’ P {Z > f (q)}) ,
2

(10)

where (a) is due to the fact that hb (x) â‰¥ hb (q) for all q â‰¤ x â‰¤ 1 âˆ’ q, (b) holds since (1 âˆ’ p)r â‰¤ eâˆ’pr
and ex â‰¤ 1 + x + x2 for x â‰¤ 1, and (c) is due to the assumption p  1/k.
We then upper bound P {Z > f (q)} by Hoeffdingâ€™s inequality:


 !
 !


f (q) 2 (a)
f (q) 2
f (q)2 (b) kp
P {Z > f (q)} â‰¤ exp âˆ’2k p âˆ’

 exp âˆ’2k
,
â‰¤ exp âˆ’
k
2k
2k
2
where (a) holds by the assumption k Â· p Â· q  1, so that
 
 
q
1
q
1
k Â· p  log
â‰¤
log
â‰¤ f (q),
2
q
1âˆ’q
q
and (b) holds due to the assumption q 



EZ (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q)

Z



âˆš

kÂ·

r 1 
.
1
log kÂ·p

Plugging into (10) yields

 

 
1
1
2
 k Â· p Â· q Â· log
 k Â· p Â· q Â· log k + log log
,
q
kp
2

where in the last inequality we use the assumption q 

âˆš

r 1 

1
kÂ· log kÂ·p

again.


C

Proof of Theorem 3

Let T1 and T2 be the number of tests performed, respectively, in Step 2 and Step 3 of the graphaware algorithm. Specifically, T1 is equal to the number of tests used by binary splitting to identify
the infected k-cliques, and T2 is the number of tests to identify infected individuals within each
infected clique. Note that T = T1 + T2 . We will bound E[T1 ] and E[T2 ] separately.
21

Let Y be the number of infected k-cliques. We have
E[Y ] =


n
n 
Â· P(XC1 = 1) = Â· 1 âˆ’ (1 âˆ’ p)k .
k
k

Taking Lemma 2 with n = n/k and Î± = Y gives
T1 â‰¤ (log2 (n/k) + 1) Â· Y
so that

 

n 
Â· log2 (n/k) + 1 Â· 1 âˆ’ (1 âˆ’ p)k .
k
For the second stage of the algorithm, let Zi denote the number of tests used by binary splitting
n/k
P
to identify all infected members of the ith clique. Since T2 =
Zi Â· 1{XC =1} , we have
i
i=1
E[T1 ] â‰¤

n/k
h
X
E Zi Â· 1{XC
E[T2 ] =

i

i=1

n
k
n
=
k
n
=
k

=

i

h
Â· E Z1 Â· 1{XC

=1}

1

i
=1}

Â· P(XC1 = 1) Â· E [Z1 | XC1 = 1]


Â· 1 âˆ’ (1 âˆ’ p)k Â· E [Z1 | XC1 = 1] .

Let M denote the number of infected members of C1 . Then by Lemma 2,
E [Z1 | XC1 = 1] â‰¤ (log2 k + 1) Â· E [M | XC1 = 1]
and, assuming without loss of generality that C1 = [k],
E [M | XC1 = 1] =

k
X

P (Xj = 1 | XC1 = 1)

j=1

= k Â· P (X1 = 1 | XC1 = 1)
P(X1 = 1, XC1 = 1)
=kÂ·
P(XC1 = 1)
P(X1 = 1)
=kÂ·
P(XC1 = 1)
1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1
=kÂ·
1 âˆ’ (1 âˆ’ p)k
where in the last line we invoke Lemma 1. Putting everything together gives


E[T2 ] â‰¤ n Â· (log2 k + 1) Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1
and therefore
E[T ] â‰¤

 


 

n 
Â· log2 (n/k) + 1 Â· 1 âˆ’ (1 âˆ’ p)k + n Â· log2 k + 1 Â· 1 âˆ’ (1 âˆ’ p)(1 âˆ’ pq)kâˆ’1 .
k

22

D

Lower Bounds for the SBIM

D.1

Proof of Lemma 5

Notice that
H (X1 , ..., Xn ) â‰¥ H (X1 , ..., Xn |Y1 , ..., Yn ) =

X

P (Y n = yn ) Â· H (X n | Y n = y n ) .

y n âˆˆ{0,1}n

Observe that after conditioning on the locations of the seeds, X1 , ..., Xn are mutually independent.
Moreover, for i âˆˆ C` , the marginal distribution of Xi can be specified as follows:
(
1,
if yi = 1,
n
n
P
P
P (Xi = 1 | Y = y ) =
y
y
j
j
1 âˆ’ (1 âˆ’ q1 ) jâˆˆC` (1 âˆ’ q2 ) j6âˆˆC` , if yi = 0.
P
Writing z` , jâˆˆC` yj , the conditional entropy is
H (X n | Y n = y n ) =

m
X



P
(k âˆ’ z` ) Â· hb 1 âˆ’ (1 âˆ’ q1 )z` (1 âˆ’ q2 ) `0 6=` z`0 ,

`=1
i.i.d.

i.i.d.

where hb (Â·) is the binary entropy function. Since Yi âˆ¼ Ber(p), we have Z` âˆ¼ Binom(k, p) and
hence

i
h
Z
Z0
n
n
0
,
(11)
H (X | Y ) = EZ,Z m Â· (k âˆ’ Z) Â· hb 1 âˆ’ (1 âˆ’ q1 ) (1 âˆ’ q2 )
where Z âˆ¼ Binom (k, p) and Z 0 âˆ¼ Binom (n âˆ’ k, p).


D.2

Proof of Theorem 6

First we assume n Â· p Â· q2  1, and let  âˆˆ (0, 1) be a value to be specified. Define
zâˆ— ,

1/2 âˆ’ np(1 + )q2
.
q1

Then as long as Z and Z 0 satisfy the following two conditions
1. {np(1 âˆ’ ) â‰¤ Z 0 â‰¤ np(1 + )},
2. Z â‰¤ z âˆ— ,
we have

0
1
â‰¥ Z Â· q1 + Z 0 Â· q2 â‰¥ 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z .
2

0

Since 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z is an increasing function of Z and Z 0 , hb

(12)

0
1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z

must increase with Z and Z 0 if they satisfy the above conditions. Therefore, we have
h

i
0
EZ,Z 0 (k âˆ’ Z)hb 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z
h


i
0
â‰¥EZ,Z 0 (k âˆ’ Z)hb 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z Â· 1{0â‰¤Zâ‰¤z âˆ— } Â· 1{np(1âˆ’)â‰¤Z 0 â‰¤np(1+)}
h


i
0
â‰¥ EZ,Z 0 (k âˆ’ Z)hb 1 âˆ’ (1 âˆ’ q2 )Z Â· 1{Z=0} Â· 1{np(1âˆ’)â‰¤Z 0 â‰¤np(1+)} +
|
{z
}
(a)

h


i
0
EZ,Z 0 (k âˆ’ Z)hb 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z Â· 1{1â‰¤Zâ‰¤z âˆ— } Â· 1{np(1âˆ’)â‰¤Z 0 â‰¤np(1+)} .
|
{z
}
(b)

23

(13)

We will pick  = 21 . Then (a) can be bounded by



n2 p
(a) â‰¥ k Â· hb q2 Â· np(1 âˆ’ ) âˆ’ (q2 Â· np(1 âˆ’ ))
1 âˆ’ 2 Â· exp âˆ’
3





2
n p
1
1 âˆ’ 2 Â· exp âˆ’
 k npq2 (1 âˆ’ ) log
npq2 (1 âˆ’ )
3



1
 k npq2 log
npq2


2

where in the first inequality we use
1. Z 0 â‰¥ np(1 âˆ’ )
0

0

2. (1 âˆ’ q2 )Z â‰¤ eâˆ’q2 Â·Z â‰¤ 1 âˆ’ q2 Â· Z 0 + (q2 Â· Z 0 )2
3. Chernoff bound on Z 0 ,
and in the third inequality we assume np  1. Next, (b) can be bounded by







n2 p
2
(b) â‰¥ hb q1 + npq2 (1 âˆ’ ) âˆ’ (q1 + npq2 (1 âˆ’ )) Â· EZ (k âˆ’ Z)1{1â‰¤Zâ‰¤z âˆ— } Â· 1 âˆ’ 2 Â· exp âˆ’
3




1
 (q1 + npq2 ) log
Â· EZ (k âˆ’ Z)1{1â‰¤Zâ‰¤z âˆ— } .
q1 + npq2


We will now lower bound EZ (k âˆ’ Z)1{1â‰¤Zâ‰¤z âˆ— } as in Theorem 4. Observe that


EZ (k âˆ’ Z)1{1â‰¤Zâ‰¤z âˆ— } â‰¥ EZ [k âˆ’ Z] âˆ’ k Â· P {Z = 0} âˆ’ k Â· P {Z â‰¥ z âˆ— }


â‰¥ k 1 âˆ’ p âˆ’ (1 âˆ’ p)k âˆ’ P {Z â‰¥ z âˆ— }
 k (kp âˆ’ P {Z â‰¥ z âˆ— }) .

(14)

Finally, applying Hoeffdingâ€™s inequality to P {Z â‰¥ z âˆ— } yields
ï£«
!2 ï£¶
2 !

1
âˆ—
âˆ’ npq2 (1 + )
z
ï£¸
= exp ï£­âˆ’2k p âˆ’ 2
P {Z â‰¥ z âˆ— } â‰¤ exp âˆ’2k p âˆ’
k
q1 k

2 !
 (2)

(1)
1
1
kp
= exp âˆ’
â‰¤
,
 exp âˆ’2k
2
2q1 k
2
2kq1
where in (1) we use the facts that 1) n Â· p Â· q2  1 and 2) p 

1
q1 k ,

and (2) holds when

1
q1 â‰¤ r
.
  
1
+1
2k Â· log kp
Plugging into (14) yields



EZ (k âˆ’ Z)1{1â‰¤Zâ‰¤z âˆ— }  k 2 p,

24

(15)

and thus by putting together our bounds on (a) and (b) in (13), we arrive at
h

i
0
EZ,Z 0 (k âˆ’ Z)hb 1 âˆ’ (1 âˆ’ q1 )Z (1 âˆ’ q2 )Z





1
1
2
+ k p Â· (q1 + npq2 ) log
â‰¥k npq2 log
npq2
q1 + npq2




1
1
â‰¥mk 2 pq2 log
+ k 2 p Â· q1 log
.
npq2
q1 + npq2

(16)
(17)
(18)


E
E.1

Proofs of Additional Lemmas
Proof of Lemma 7

Let Yv be the indicator random variable of whether vertex v is a seed, and assume without loss of
generality that v âˆˆ C1 . We have
P(Xv = 1) = P(Xv = 1 | Yv = 1) Â· P(Yv = 1) +P (Xv = 1 | Yv = 0)) Â· P(Yv = 0)
|
{z
} | {z }
=p

=1

= p + (1 âˆ’ p) Â· P (Xv = 1 | Yv = 0)
and

P (Xv = 1 | Yv = 0) = P {v is infected by a neighbor}
Y

=1âˆ’
P {v isnâ€™t infected by u}
uâˆˆN (v)

=1âˆ’

Y 

1 âˆ’ P {v is infected by u}



uâˆˆN (v)

=1âˆ’

Y 


1 âˆ’ P ({v is infected by u} | Yu = 1) Â· P(Yu = 1)

uâˆˆN (v)

!
=1âˆ’

Y

(1 âˆ’ p Â· q1 )

!
Â·

Y

(1 âˆ’ p Â· q2 )

w6âˆˆC1

uâˆˆC1 \{v}
kâˆ’1

= 1 âˆ’ (1 âˆ’ p Â· q1 )

Â· (1 âˆ’ p Â· q2 )nâˆ’k .


E.2

Proof of Lemma 8

Let A be the event that no member of community C1 is selected as a seed, and let B be the event
that some member of C1 is infected by an individual outside C1 . We further denote by Bu the event
that vertex u infects some member of C1 , where u 6âˆˆ C1 . Note that XC1 = 1 if and only if either Ac
occurs or A âˆ© B occurs. Moreover, A and B are independent events. We have that P(A) = (1 âˆ’ p)k ,
and thus
P(XC1 = 1) = P(Ac ) + P(A) Â· P(B)
= 1 âˆ’ (1 âˆ’ p)k + (1 âˆ’ p)k Â· P(B)
= 1 âˆ’ (1 âˆ’ p)k Â· (1 âˆ’ P(B)).
25

Finally, we compute P(B) as
Y
P(Buc )
P(B) = 1 âˆ’
u6âˆˆC1

=1âˆ’

Y 
u6âˆˆC1

=1âˆ’

Y 

P(Buc | Yu = 1) Â· P(Yu = 1) + P(Buc | Yu = 0) Â· P(Yu = 0)
| {z } |
{z
} | {z }
=p

=1



=1âˆ’p


1 âˆ’ p + p Â· P(Buc | Yu = 1)

u6âˆˆC1

=1âˆ’

Y 

1 âˆ’ p + p Â· (1 âˆ’ q2 )k



u6âˆˆC1

=1âˆ’



k

1 âˆ’ p Â· 1 âˆ’ (1 âˆ’ q2 )



!nâˆ’k
.


26

