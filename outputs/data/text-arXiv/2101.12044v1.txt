Contrastive analysis for scatter plot-based representations of
dimensionality reduction
Wilson E. MarcÃ­lio-Jra , Danilo M. Elera and RogÃ©rio E. Garciaa

arXiv:2101.12044v1 [cs.HC] 26 Jan 2021

a Faculty

of Sciences and Technology, SÃ£o Paulo State University (UNESP), Presidente Prudente, SP 19060-900, Brazil

ARTICLE INFO

ABSTRACT

Keywords:
contrastive visualization; dimensionality reduction; interpretation

Exploring multidimensional datasets is a ubiquitous part of the ones working with data, where interpreting clusters is one of the main tasks. These multidimensional datasets are usually encoded using
scatter-plots representations, where spatial proximity encodes similarity among data samples. In the
literature, techniques try to understand the scatter plot organization by visualizing the importance of
the features for clusters definition with interaction and layout enrichment strategies. However, the
approaches used to interpret dimensionality reduction usually do not differentiate clusters well, which
hampers analysis where the focus is to understand the differences among clusters. This paper introduces a methodology to visually explore multidimensional datasets and interpret clustersâ€™ formation
based on the contrastive analysis. We also introduce a bipartite graph to visually interpret and explore
the relationship between the statistical variables used to understand how the attributes influenced cluster formation. Our methodology is validated through case studies. We explore a multivariate dataset
of patients with vertebral problems and two document collections, one related to news articles and
other related to tweets about COVID-19 symptoms. Finally, we also validate our approach through
quantitative results to demonstrate how it can be robust enough to support multidimensional analysis.

1. Introduction
The analysis of high-dimensional datasets presents great
opportunities to understand various phenomena. Interestingly, by using visual proximity to encode similarity among
data samples, scatter-plot representation offers great opportunities for analysis of multidimensional data after dimensionality reduction (Paulovich et al., 2008; Maaten and Hinton, 2008; McInnes et al., 2018) (DR). In this case, clusters
could be inspected after dimensionality reduction to understand the nuances of high-dimensionality data, as well as the
data features that most influence on the formation of clusters
in the embedding space.
One particular way to analyze clusters is through the recently explored contrastive analysis (Fujiwara et al., 2019;
Le and Akoglu, 2019), where the focus is on the characteristics that most differentiates them. The motivations for
analyzing clusters in a contrastive way are numerous. For
example, a tool for labeling textual datasets can project a
bag of words representations on â„2 to provide each clusterâ€™s
information based on non-shared terms. Another useful application is to retrieve contrastive information of surveys in
an area of interest to guide readers on studies that are more
prone to satisfy their research objectives. While these applications deal with textual data, multivariate datasets can
also be explored using such an idea. For example, it could
be interesting to know which features describe two separated
groups of individuals after drug ministration.
Although great practical applications could be created
based on contrastive analysis, the literature mostly presents
studies that focus on providing essential information (not
contrastive) to understand DR layouts. For example, by viâˆ— E-mails:

wilson.marcilio@unesp.br, danilo.eler@unesp.br, rogerio.garcia@unesp.br
ORCID (s):

MarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

sually emphasizing the importance given to data attributes
(features) by DR algorithms to organize the embedded space.
For this purpose, the most prominent approaches use PCAâ€™s (Jolliffe, 1986) principal components (PCs) to find the features
that most contribute to cluster formation (Joia et al., 2015;
Turkay et al., 2012). There are several problems with using
PCs for such a task. First, the PCs emphasize classes with
high variation, which could be a problem for datasets where
the DR layout is dominated by specific classes/clusters or
when one needs to investigate an â€œoutlierâ€ cluster, that is, a
cluster very dissimilar from others. Second, the PCs cannot uncover features that contribute to cluster differentiation (Fujiwara et al., 2019) since the PCs calculated for every
cluster/class could be the same. On the other hand, (Fujiwara et al., 2019) propose a technique (ccPCA) that uses a
variant of PCA (contrastive PCA (Abdi and Valentin, 2007))
to support the analysis of dimensionality reduction results
by returning the contrastive features of cluster formation,
i.e., features that make the clusters different â€“ in fact, their
technique try to balance the characteristic of featuresâ€™ discrimination and variation within clusters. One limitation
of ccPCA is computational complexity. Since it is based
on PCA, it takes prohibitively time execution for datasets
with many dimensions (to be more precise, it takes ğ‘‚(ğ‘š3 )
in the number of dimensions). Such a characteristic makes
ccPCA not suitable for datasets commonly inspected using
DR layouts, such as document collections and deep learning activations, that easily reach thousands of dimensions.
Finally, while informing contrastive information of clusters
in the DR layouts, there is no consistent way to visually relate the distribution of values with the featureâ€™s contribution
returned based on contrastive PCA. Another interesting contrastive approach, ContraVis (Le and Akoglu, 2019), is only
applied to textual data and cannot help at the interpretation
of DR layout since it is already a dimensionality reduction
Page 1 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction

approach. Furthermore, there is no way (at least reported) to
understand the termsâ€™ contribution to the cluster formation.
In this work, we propose a simple approach, called cExpression, to analyze multidimensional datasets in a contrastive
manner together with a carefully designed visualization technique. More precisely, we use statistical variables (ğ‘-values
and ğ‘¡-scores) to communicate to users the most distinctive
features of clusters in a contrastive way (ğ‘¡-score) together
with the confidence of the results (ğ‘-value). In our visualization design, users can interact with scatter plot representations of multidimensional datasets to visualize the clustersâ€™ summaries â€“ designed after the definition of several requirements. We use focus+context interaction on a bipartite
graph to communicate the relationship between ğ‘¡-scores and
ğ‘-values and color-coding edges to encode the valuesâ€™ signal. The focus+context interaction helps users to explore a
higher amount of information at the same time while inspecting small multiples of the distribution values of each feature
of interest. A heatmap representation of the most distinctive
features for each perceived/defined cluster also helps to get
an overview of the structures. Finally, we also propose an
encoding strategy to simultaneously communicate the distribution values of a few features in scatter-plot representation. Our approach is validated through case studies, one of
them particularly complex to analyze. Further, we also numerically evaluate the strategy by comparing it against topic
extraction algorithms.
In summary, our contributions are:
â€¢ A strategy to analyze and interpret dimensionality reduction through clusters using contrastive information;
â€¢ Novel visualization strategies to analyze the relationship among statistical variables and simultaneously visualize various features in the scatter-plot.
This work is organized as follows: Section 2 presents
the related works; Section 3 delineates our methodology accompanied with a motivation; Section 5 explains the visualization design; Section 6 shows the case studies; Section 4
presents a numerical evaluation of the technique; Section 7
presents discussions about the work; finally, the work is concluded in Section 8.

2. Related Works
Layout enrichment strategies have been usually applied
to provide more informative visualizations to overcome DR
resultsâ€™ interpretability limitations. Examples of such works
include using bar charts and color encoding to provide understanding about three-dimensional projections (Coimbra
et al., 2016) or encoding attribute variation using Delaunay
triangulation to assess neighborhood relations in projections
on â„2 (Silva et al., 2015). Probing Projections (Stahnke
et al., 2016), for example, depicts error information by displaying a halo around each dot in a DR layout besides providing interaction mechanisms to understand distortions in the
projection process. The majority of the works use traditional
MarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

statistical charts to visualize attribute variability (Pagliosa
et al., 2016), neighborhood and class errors (Marcilio et al.,
2017), or quality metrics (Kwon et al., 2018). For instance, Martins et al. (2014) use space-filling techniques to help users
reason about the influence on neighborhood preservation and
other quality aspects of parameterized projections.
More related to our work are techniques that try to find
important features given clusters of data points. For example, the Linear Discriminative Coordinates (Wang et al., 2017)
uses LDA (Izenman, 2008) to produce cohesive clusters by
discarding the least important features. Joia et al. (2015) use
PCA to find the most important features by a simple matrix
transposition to later visualize feature names as word clouds
withing each cluster region. Although useful and fast, such
an approach tends to be influenced by classes with a higher
variation. Another work, proposed by Turkay et al. (2012),
also used the principal components computed by PCA to
obtain MDSâ€™s representative features (Kruskal and Wish,
1978) layouts. Recently, Fujiwara et al. (2019) proposed
a contrastive cluster PCA (ccPCA) technique that finds the
most important features for a given cluster compared to the
other clusters in a projection. Fujiwara et al.â€™s approach is
different from Joia et al.â€™s and Turkay et al.â€™s works for providing a way to understand which features highly contribute
to the differentiation of clusters. Another interesting work,
proposed by (Le and Akoglu, 2019), combines topic extraction and visualization to analyze document collections in a
contrastive manner. Although their technique can differentiate clusters well, it cannot be used to analyze other dimensionality reduction approaches since producing embeddings
(low-dimensional representations) is a part of the process.
Besides that, such a technique was designed for textual data.
In this work, we propose a methodology for the contrastive analysis of featuresâ€™ importance in a scatter-plot layout using visual inspection of statistical variables (that is,
ğ‘¡-scores and ğ‘-values). Differently from Fujiwara et al.â€™s
work, our proposal can be successfully employed to analyze datasets with much higher dimensionality while presenting more consistent results â€“ as we show in the following
section. Lastly, considering that the featuresâ€™ importance is
visualized based on well-known statistic variables, our approach yields more interpretable results for assessing the importance of the features on defining the clusters.

3. cExpression
Our method is based on comparing distributions of values of different clusters while using ğ‘¡-test to verify if the differences among these distributions are enough to describe
â€²
clusters. Given a dataset ğ‘‹, let ğ‘‹ğ‘“ğ‘ and ğ‘‹ğ‘“ğ‘ be the values
of feature ğ‘“ for the data observations in the cluster ğ‘ and the
values of the featurs ğ‘“ for the data observations not in cluster
ğ‘ (ğ‘ â€² ). To compute the ğ‘¡ value for the ğ‘¡-test, we must compute
the summary statistics, i.e., average and variance for ğ‘‹ğ‘“ğ‘ and
â€²

â€²

â€²

ğ‘Œğ‘“ğ‘ , defined as ğ‘‹ğ‘“ğ‘ , ğ‘‹ğ‘“ğ‘ and ğ‘‰ ğ‘ğ‘Ÿ(ğ‘‹ğ‘“ğ‘ ), ğ‘‰ ğ‘ğ‘Ÿ(ğ‘‹ğ‘“ğ‘ ). Finally,

Page 2 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction

the ğ‘¡-statistic can be calculated as it follows:
â€²

ğ‘¡=

ğ‘‹ğ‘“ğ‘ âˆ’ ğ‘‹ğ‘“ğ‘
ğ‘‰ ğ‘ğ‘Ÿ(ğ‘‹ğ‘“ğ‘ )
|ğ‘‹ğ‘“ğ‘ |

(1)

â€²

+

ğ‘‰ ğ‘ğ‘Ÿ(ğ‘‹ğ‘“ğ‘ )
â€²

|ğ‘‹ğ‘“ğ‘ |

in which | âˆ™ | stands for the size of the sets. Having the ğ‘¡statistic, we use a statistical library to find the ğ‘-value, which
corresponds the probability that we can reject a null hypothesis. In other words, the ğ‘-value represents the probability in
which we can assume that the population of values in cluster ğ‘ for feature ğ‘“ (ğ‘‹ğ‘“ğ‘ ) and the population of values not

increasing way of ğ‘¡-score will lead to the most descriptive
features of the cluster to be placed on top.
Let us apply the concept delineated above on a multivariate dataset. Fig. 2 shows a UMAP (McInnes et al., 2018)
projection of the Vertebral dataset, that consists in 310 data
instances described by six bio-mechanical features derived
from the shape and orientation of the pelvis and lumbar spine:
pelvic incidence, pelvic tilt, lumbar lordosis angle, sacral
slope, pelvic radius, degree of spondylolisthesis â€“ see Section 6 for a case study with this dataset. The class of interest corresponds to patients with Spondylolisthesis, a disturbance of the spine where a bone (vertebra) slides forward
over the bone below it.

â€²

in cluster ğ‘ for feature ğ‘“ (ğ‘‹ğ‘“ğ‘ ) are equal. Notice that, fixing a cluster ğ‘ and a feature ğ‘“ , smaller ğ‘-values stands for
high importance since it means (by our null hypothesis) that
the distributions are different. The t-scores are measures of
standard deviation. In this case, very high or very low (negative) t-scores are associated with very small ğ‘-values and
are found in the tails of the ğ‘¡-distribution â€“ as illustrated in
Fig. 1.

a

F1

F2

FM

0

4

5

8

5

b

In the cluster
Not in the cluster

6

...

c

0

9.6e-50

F1

6e-25

F2

10.12e-20

FM

0.036

...

F3

d
p-values

e

1

t-Student

0

t-score

Figure 1: Process of defining contrastive features. The distribution of values of each feature of the dataset (a) in a specific
cluster is compared with the distribution of values for the data
samples outside the cluster (b). Using ğ‘¡-Student test (c), a
probability value is retrieved from a look-up table (d) based
on a ğ‘¡-score, to determine if the distributions are statistically
different. The features are ordered in decreasing way based on
ğ‘¡-score to communicate their discriminative power (d).

Performing the process discussed above for each pair of
clusters and features of the dataset and retrieving ğ‘¡-scores as
a ranking metric, we interpret the clusters in a contrastive
manner. Fig. 1 illustrates the whole idea of our approach
for a fixed cluster and a fixed feature. From the dataset in
a matrix form (a.), the distributions of values for the cluster
and feature are generated (b.), where red encodes the feature
distribution of data samples in the cluster and gray encodes
the distribution of data samples outside the cluster. Based
on these distributions, we used the t-Student test (c.) to ask
for the probability (ğ‘-value, d.) in which the distributions
are the same. Finally, ordering the clusterâ€™s features in an
MarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

Figure 2: UMAP projection of the Vertebral Column dataset.

One particularly important feature for patients with Spondylolisthesis is the degree of spondylolisthesis, which is known
to be high in those patients (Labelle et al., 2005). It is reasonable to think that an algorithm that tries to find important features would select degree of spondylolisthesis for
defining such a class. To investigate cExpression on finding the relevant feature in a contrastive way, let us explore
the distribution of values of the important features throughout the projection of Fig. 2. Fig. 3 shows the two most important retrieved by cExpression. The scatter-plot showing
the normalized feature values also confirms how degree of
spondylolisthesis is a reasonable candidate for a contrastive
feature. Data instances from class present much higher
values for such a feature than data instances from classes
and .

Figure 3: Distribution of values of the features selected cExpression.

4. cExpression on topic extraction tasks
In this section, we aim to analyze cExpression on its ability to return meaningful results. In Section 6, we utilize the
methodology and a careful visualization design to generate
insights from various datasets. We evaluate cExpression on
the featuresâ€™ cohesion returned as discriminative by comparPage 3 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction

ing it against well-known topic extraction techniques. Finally, cExpressionâ€™s run-time execution regarding a datasetâ€™s
dimensionality is compared against ccPCA (Fujiwara et al.,
2019) since it is the most similar approach.

4.1. cExpression cohesion
An interesting way to look at cExpression technique is as
a topic extraction approach. To extract topics of document
collections by using cExpression we must first choose the
number ğ‘˜ of topics. The diagram of Fig. 4 illustrates the
process of topic extraction.
a

d
T2

TM

0

4

5

8

5

0

1

6

...

b

c
Clustering

Term
Expression

Terms
Terms
Terms
Terms

for
for
for
for

...

T1

topic
topic
topic
topic

LDA
41.0876
38.3072
37.7737
37.9169
37.5037
37.4346
33.4367
33.2409
35.5672

NMF
21.3630
28.9405
28.8734
28.9459
27.7676
26.7356
28.1161
26.7829
26.1085

Term Expression
32.9847
39.0384
37.4541
38.2428
41.6532
40.2814
39.3023
36.5034
37.2073

Table 1
Summarization of results in Cohesion using AUC. cExpression
only returns lower results for two and four topics.

1
2
3
4

Terms for topic k

0

Number of topics
2
3
4
5
6
7
8
9
10

Figure 4: Strategy for retrieving topics using cExpression.
Given a bag-of-words representation of a document collection
(a) a clustering is imposed to the dataset (b). cExpression is
executed to retrieve contrastive terms for each cluster defined
in the previous step (c). We set the topics as the set of the
first ğ‘š terms for each cluster.

portion of documents below 0.5 â€“, the dataset resulted in
a bag-of-words representation of 4828 documents by 3347
terms.
Fig. 5 shows the curves varying the number of terms in
each topic for the news and covid-19 datasets. For these two
datasets, cExpression presented a slight advantage for topics with size below 20, which can be explained by our algorithmâ€™s intrinsically characteristic. cExpression emphasizes
the terms that are not expressed in other clusters, in other
words, the topics are extracted in a contrastive way â€“ terms
of topic A (cluster A) are not likely to appear in other topics.
So, for a lower number of terms, cExpression emphasizes
the differences while providing good document collectionâ€™s
good coherence.

Cohesion

A clustering algorithm is used to impose a partition on
the dataset to apply cExpression (c.) to a given a bag of
words representing a document collection (a.). For each cluster of the partition process, cExpression will return the present
terms in the cluster that are not likely to appear in another
cluster. As explained in Section 3, these terms are ordered
based on their score to define clusters in a contrastive mancovid-19 dataset
news dataset
ner. The first ğ‘š terms are returned to compose the topics of
each cluster (d.).
To evaluate our techniqueâ€™s performance at topic extraction tasks, we compare it against two well-known and commonly used topic extraction techniques: LDA (Hoffman et al.,
2010) and NMF (Cichocki and PHAN, 2009). For the comparison, we want our technique to present coherent results
Number of terms in the topic
with these robust approaches to validate how consistent the
Figure 5: cExpression shows competitive results for topics with
features are (in this case, terms) returned by cExpression.
low number of terms (â‰¤ 20).
Thus, we used Topic Coherence (RÃ¶der et al., 2015) as an
evaluation metric. The Topic Coherence (RÃ¶der et al., 2015)
To analyze the 20newsgroups dataset, besides varying the
metric, which is applied to the top ğ‘š words from the topic, is
number
of terms, we also varied the number of topics redefined as the average/median of the pairwise word-similarity
turned
from
the algorithm. For this particular case, we comscores of the topicâ€™s words. A good model will generate coputed
the
Area
Under the Curve (AUC) to summarize the
herent topics, i.e., topics with high topic coherence scores.
results,
as
shown
in Table 1. The table shows that cExpresIf the topic extraction technique A has higher coherence than
sion
was
able
to
surpass
the results of both LDA and NMF
technique B, it is better since it is more coherent.
for
the
most
number
of
topics,
it only presented lower AUC
The evaluation was performed using three datasets: 495
for
two
and
four
topics
(the
later,
however, only a slight difnews articles (205 terms) and 40794 tweets related to COVIDference
is
noticed).
19 symptoms (295 terms) â€“ see Section 6 for case studies inFig. 6 shows that for only two topics, our technique could
volving these datasets â€“, and the 20newsgroups1 dataset. For
not
uncover topics as good as LDA while using four topthe 20newsgroups, we use a subset comprising the classes
ics,
our technique presented slightly lower results when usalt.atheism, comp.graphics, comp.windows.x, rec.motorcycles,
ing
only
a few terms (below 10 terms). On the other hand,
sci.electronics, sci.med, talk.politics.guns, talk.politics.misc,
the
figure
also shows how better is our technique when using
talk.religion.misc. After preprocessing the dataset â€“ reonly
a
few
terms for six and eight topics. The remaining of
moval of English stop-words and terms appearing in a prothe plots are in the Supplementary File.
1 http://qwone.com/

jason/20Newsgroups/

MarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

Page 4 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction
4 Topics

6 Topics

8 Topics

Cohesion

Cohesion

2 Topics

Terms in topic

Terms in topic

Figure 6: cExpression was able to surpass LDA and NMF for
the majority of number of topics.

4.2. Run-time execution
To successfully analyze real-world data a technique must
cope with high-dimensionality, especially when dealing with
textual data. We analyze cExpression and ccPCA on their
run-time execution for retrieving contrastive features of a
big dataset with varying number of dimensions. Notice that
while other approaches could be used to investigate their
run-time execution, we focused only on the techniques that
are able to retrieve contrastive information of clusters defined for datasets. The dataset consists of 40794 tweets about
COVID-19 symptoms (see Section 6 for a case study with a
smaller version of this dataset) divided into eight clusters.
The number of features was varied between ten to 2000 (50
linearly separable numbers). Fig. 7 shows the run-time execution in milliseconds (in logarithmic scale). While using
cExpresion takes a reasonable amount of time, the ccPCA
technique did not scale well. For instance, with 2000 features, cExpression took approximately 7.5 seconds while ccPCA
took approximately 621.95 seconds.
14

Time (Log ms)

12

aspects (a). The scatter-plot representation of the projected
dataset (b) serves as the basis for the interaction with the bipartite graph (c) representing the relationship among the statistical variables â€“ in Fig. 8, for example, the bipartite graph
shows information for the cluster (orange). Users can toggle the distribution plots (d and e) to inspect the scatter-plot
representation distribution. The heatmap view (f) is useful
to summarize greater amount of information simultaneously,
where a diverging color scale from purple to green encodes
the ğ‘¡-scores and the sizes of the heatmapâ€™ tiles encode the
number of decimal places of the associated ğ‘-value. In the
heatmap visualization, high ğ‘¡-scores (represented by high
color saturation) are associated with lower ğ‘-values (greater
tile sizes) since higher ğ‘¡-scores (as a measure of variation)
are concentrated on the limits of the ğ‘¡-distribution and known
to have low associated ğ‘-values.
We followed the layout enrichment (Nonato and Aupetit,
2018) strategy of scatter plot representations after dimensionality reduction to formulate our visualization design. We
chose to explore datasets using similarity maps since perceiving clusters using visual proximity is fast. Moreover, as
in Fujiwara et alâ€™s work (Fujiwara et al., 2019), users can
annotate clusters on the visual space to understand the clusters generated by dimensionality reduction techniques. To
help users to understand cluster formation, we address the
following task requirements (TRs):
â€¢ TR1: Compare a cluster against the remaining of the
dataset;
â€¢ TR2: Compare two selected clusters.
The task requirements (TRs) above help users understand
the projected structures by comparing how clusters differentiate. To achieve these tasks, we followed a strategy by delineating the minimum requirements that our visualization
must comprise, as delineated as it follows for the visualization requirements (VRs):
â€¢ VR1: Visualize the importance of a feature;

Technique
ccPCA
Ours

â€¢ VR2: Visualize the distribution of values of the comparing components;

10
8
6
4

â€¢ VR3: Know the feature name;

2

10
50
91
13
171
212
253
293
334
374
415
456
496
537
577
618
659
709
740
781
821
862
902
943
984
10 4
1025
1165
1106
1147
1287
1228
1368
1309
1350
1490
1431
1572
1512
1553
1693
1634
1775
1715
1756
1896
1837
1978
1918
2059
00

0

Number of features

Figure 7: Time execution in logarithmic scale for retrieving
contrastive features.

5. Visualization Design
We developed a tool to use cExpression strategy to explore multidimensional datasets and help at interpreting multidimensional projections visually. The tool, illustrated in
Fig. 8, is divided into two main views: the scatter-plot view
and the heatmap view. Firstly, users provide data points and
multidimensional data, besides setting some visualization
MarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

â€¢ VR4: Assess how trustful is the result;
â€¢ VR5: Understand the organization of features distribution in the DR layout.
Each one of the VR requirements is meant to be analyzed
together, although the main requirement (VR1) dictates if a
feature is essential or not. That is: knowing the features selected as discriminative for a cluster (VR3), the requirements
help users to understand how they differ from the remaining
of the dataset (VR2), and how their values are distributed
throughout the DR layout (VR5). VR4 helps at assessing
how trustful is the result â€“ as we will show in the Section 6,
VR5 also helps to understand the importance of the features.
Page 5 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction

Figure 8: Tool for contrastive analysis â€“ assessing dark orange cluster. a) Tool-bar to
specify points file and visualization parameters. b) Scatter-plot representation of the
dataset. c) Bipartite graph visualization to encode relationship among statistical variables
for the dark orange cluster â€“ cluster on the bottom of the projection. d) Visualizing the
distribution of feature peru on the scatter-plot e) Simultaneously visualizing the distribution
of the distribution of features peu and humala using color intensity to encode feature value
inside cells of fixed size. f) Heatmap view to summarize contrastive analysis.

5.1. Visualizing the feature importance
To compactly represent the VR1-4 requirements, we visualize the importance of the features in a lineâ€™s position
while providing the distribution plots for each visualized term.
Fig. 9 shows our visualization design to help users understand clusters, where the color hue for the distribution plots
correspond to the cluster .
The featuresâ€™ importance is encoded by a simple line
corresponding to the relationship between ğ‘-values and ğ‘¡scores. In Fig. 9, the axis (a) and (b) represent the same
information, the number of decimal places after zero of ğ‘values, but have different purposes for the focus+context
interaction â€“ we explain it in Section 5.5. On the context
axis (a), the dots represent all of the analyzed features based
on their respective ğ‘-values â€“ a jitter on ğ‘¦ position helps at
assessing density. Notice that with this simple design we
can represent the VR1 and VR4 requirements. However,
we still need to comprise other visualization requirements
so users can differentiate between the features while understanding the trust in the feature differentiation. To reduce
over-plotting, we only show ğ‘šğ‘–ğ‘›(ğ‘š, 50) features â€“ where ğ‘š
stands for the number of features in the dataset â€“ in the feature importance graph since much of the necessary information to interpret the datasets are on the top features (the most
distinctive ones).
A red-to-blue color scale is used to help users quickly
identify the feature confidence â€“ blueish colors encode more
confidence, in other words, lower ğ‘-values (or more deciMarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

mal places after zero). The ğ‘-values are then connected to
other axis encoding the ğ‘¡-scores, which measure the deviation between the distribution of the analyzed feature/cluster
to the distribution of the remaining dataset. The relationship among these statistical variables, ğ‘¡-scores and ğ‘-values,
is shown through line segments, where the color indicates
the signal of ğ‘¡-score (pink for negative and green for positive) â€“ notice that the color of the lines and the color of the
ğ‘-value scales encode different information. These line segments are drawn with transparency when are not selected and
their support circles receive black borders when the features
are selected. To reduce the over-plotting of the line segments
(usually corresponding to the least discriminative features),
the edge bundling algorithm is employed â€“ see the effect on
the left part of Fig. 9. as we will show in the following section, the boxes below each feature name help to dynamically
assign color hues to features when exploring their distribution on the scatter-plot representation.
The requirements VR2 and VR3 are fulfilled with a distribution plot enriched with other information. The distribution of the values is encoded using a histogram (see for
ollanta in Fig. 9), where the values assumed by a features
go on the ğ‘¥ axis while the number of data observations with
a particular value goes on the ğ‘¦ axis (more precisely, the ğ‘¦
axis encodes the number of data observations that have a
value inside o bin limit). As in Fujiwara et al.â€™s work (Fujiwara et al., 2019), the ğ‘¦ axis encodes the relative frequency
of the bins, that is, the number of data observations with a
Page 6 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction

Inspected
features

a

Figure 9: The summary of the importance of features is encoded as a bipartite graph, where ğ‘-values and ğ‘¡-scores are
encoded by a red-to-blue and a continuous color scales, respectively. In a), a context of the top features determined as
contrastive by our strategy. The same color scale in b), except
for showing the current focus â€“ the color scale encodes how
much confidence one can put on a feature, where blueish colors
encode more confidence. Note that, the axes with red-to-blue
color scale encode the number of decimal places after zero of
the ğ‘-values. The relationship of the ğ‘-values with ğ‘¡-score is
communicated through links, where blue colors encode positive values and red colors encode negative values. In c), the
most important features (highlighted with thicker segments)
are presented â€“ the boxes below each feature name help at
dynamically assigning color hues when exploring featuresâ€™ distributions.

b

c

d

Figure 10: Construction of the distribution representation for
simultaneously visualize various features. On each box of the
grid (a), the sum of the feature values is retrieved, and the
box will be painted to communicate the presence of features
with color saturation used to communicate the relative sum of
the features. The space inside a box is divided by how many
features are being expressed, that is, all of the space is taken
by one feature if only one feature is expressed (b), divided by
two if two features are expressed (c), divided by three if three
features are expressed (d), and so on.

Fig. 10a) shows a cell in the space that comprises a hypothetical number of 16 data points, where color was used
to indicate the most defining feature for each data point ( ,
, ). When inspecting only one feature (b), using a continuous color scale is a simple yet effective option since the
markers only change according to the hue and no additional
graphic variable is added to the visualization. The problem
arises when inspecting more than one feature at the same
time while trying to maintain the organization imposed by
the dimensionality reduction technique on the resulting layparticular value divided by the number of data observations
out. To approach this problemâ€™s solution, we use the grid
in the cluster (for histograms of the cluster) or outside the
structure to group similar data points and divide the space
cluster (for histograms of then rest of the dataset). The bars
according to the number of features being expressed inside
color of the distribution plots (and the borders around them)
each cell. In the example of c), after adding feature to the
assumes the same colors of the corresponding cluster while
inspection, the cell is divided and colored according to the
the distribution plots of the values for the remaining of the
featuresâ€™ color-encoding. Moreover, color opacity is used to
dataset receives gray. For example, in Fig. 9, the distribution
communicate how much the feature is expressed inside the
plots have the same color as the cluster in Fig. 8b.
cell. We calculate the highest expression of each feature inside the cell and use this information to divide the expression
5.2. Visualizing distribution values on the
in each cell to devise an opacity factor that ranges from 0 to
similarity map
1. The most opaque segment for a feature indicates that the
Visualize the distribution of feature values helps to unfeature is most expressed in that segment. The same hapderstand the influence of features in the DR layout. While
pens when the feature is added to the analysis (d), where
visualizing a single feature is trivial since one could use a
the cell is divided into three segments.
continuous color map to inspect the feature values shown in
Fig. 11 illustrates the progressive analysis using the enFig. 3, when one wants to visualize more than one feature
coding strategy to visualize the scatter-plot metaphorâ€™s disto investigate the same aspects, such problem needs more
tribution of values. We selected four clusters (a) as an exattention. Approaches to simultaneously visualize values of
ample. After inspection of the cluster , the selection of
various parameters consist of using aggregation in radial layterm syrian shows where the term is mostly expressed (noouts (Gassen et al., 2015; Kwon et al., 2017) or discretizing
tice that the colors representing the cluster and the term it1D projections in heatmap visualizations (Linderman et al.,
self are not related) using a color scale, which helps users
2019), reducing the analysis power proximity-based scatter
to investigate where the documents are talking about syrian.
plot representations. Instead, inspired by Sarikaya et al.â€™s (Sarikaya
To visualize the co-expression of terms, the aggregated enet al., 2018) work, where they visualize validation of protein
coding uses color saturation to communicate the expression
surface classification, we discretize the projected space in
level in regions defined by cells of a fixed size (defined by
cells of fixed size (in pixels) to plot the contribution of each
users). Notice that, the space inside each cell is divided by
feature to the cell. Fig. 10 exemplifies the construction of
the number of features being inspected.
the encoding for three features and only one cell.
In the visualization, this idea is handled by the user through
MarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

Page 7 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction

Figure 11: Inspection of distribution values on the scatterplot. a) Scatter-plot: four clusters selected for demonstration. b) Instance-level encoding: color scale encoding only
the term syrian. c) Aggregated encoding: distribution values
for greater number of features using color saturation of cells.

clicks on the distribution plots. As shown in Fig. 12, the feature inspection is indicated in the visualization by a straight
line, where users use combinations of features to visualize
multiple values. Notice that by using the opacity strategy
as discussed above, cells in which no data observations express any feature would not be perceived in the visualization
so that we used a texture ( ) to fill these cells to maintain
the general structure of the projected dataset intact. Lastly,
notice that the cell area division is performed according to
the number of features being expressed in the cell, that is,
although many features can be inspected simultaneously if
only one feature is expressed in a cell, all of the cell areas
is assigned to it â€“ as highlighted by a dashed black circle in
Fig. 12.

Figure 12: The distribution plots can be toggled to visualize the distribution of features using the encoding strategy in
Fig. 10. Notice that when no expression is found inside a box,
it receives a grey texture.

or when one wants to analyze the change of features for a
dataset that contains pseudo-time information, for example,
in the analysis of gene regulation carried out by molecular
biologists.
To provide the possibility of cluster comparison, two clusters of interest must be selected on the scatter-plot view, in
which a similar strategy is used to visualize information. In
this case, given two clusters (ğ‘ğ‘ , ğ‘ğ‘ ), unlike in the typical
setting where a cluster is contrasted with the remaining of
the dataset, here, the contrastive information is performed
on the pairs (ğ‘ğ‘ , ğ‘ğ‘ ) and (ğ‘ğ‘ , ğ‘ğ‘ ). Fig. 13 shows an augmented
version of the visualization of Fig. 9, where the information
about each cluster is mirrored and the color scale representing the ğ‘-values is constructed based on the clusters with
the longer range. When comparing clusters, the information
provided to contrast clusters to the remaining of the dataset
is presented to both clusters in comparison (such as distribution plots, ğ‘-values and ğ‘¡-scores axes).

Figure 13: Comparison between two clusters. The cluster in
comparison (second in inspection) receives space on the top
of the visualization (a), while the rest continues the same (b
and c). When comparing, the distribution plots of the most
distinctive features are shown (four in this case) for both clusters.

5.4. Summary View
5.3. Comparing clusters
Besides comparing a cluster of interest to the rest of the
dataset, in some situations, it is useful to understand how two
clusters of interest differ or how these clusters are similar.
This type of analysis comes into handy when one wants to
understand why subclusters are formed in a greater cluster
MarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

Although our technique can emphasize differences of the
dataset even for a reasonable amount of features, for some
datasets, it would be interesting to understand more about
a cluster structure visualizing the importance of more features. An overview of the feature importance is provided by
heatmap that visualizes the statistics used by our technique,
as shown in Fig. 8f). A purple to green color scale is used
Page 8 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction

to encode the ğ‘¡-score, and the dimensions of the tiles encode the ğ‘-values â€“ notice that a negative ğ‘¡-score means that
a cluster does not present the termâ€™s occurrence, in this example for document collections. It is important to remember
that ğ‘¡-scores are measures of standard deviation and ğ‘-values
are probabilities. Both statistics are associated with standard
ğ‘¡-distribution. This distribution relates standard deviations
with probabilities and allows significance and confidence to
be attached to ğ‘¡-scores and ğ‘-values. For this particular example, Fig. 8f) helps us to understand how distinctive the
features are used to explain each cluster in a contrastive way,
that is, none of the features with green tiles are shared across
columns.

5.5. Interaction mechanisms
As shown in Fig. 9, the four most distinctive features are
presented when inspecting a cluster. However, users may
want to inspect other features based on their ğ‘-value. Such
an interaction is carried out by using a selection box, as illustrated in Fig. 14. All of the corresponding features inside
the box are detailed inspected by the visualization of their
respective distribution plots. The line segments of the bipartite graph are also updated to communicate which features
are selected.

Figure 15: Users toggle the distribution plots to inspect their
values on the scatter-plot representation. Notice that we differentiate selected features by painting the box below the name
of the features with categorical colors and by un-dashing the
boxes around the plots.

Figure 14: Users select features of interest to inspect their
distribution plots.

Another differential of our tool is to assign colors to the
features being inspected in the scatter plot representation.
While users can freely visualize many distribution plots, there
is a limit in the number of colors that humans can differentiate well (Ward, 2002). With a limit of ten features to be
simultaneously visualized, users can toggle the distribution
plots. After selecting features of two classes ( and ) to be
compared, Fig. 15 shows the simultaneous selection of the
terms crime, charg, command, nuclear and their result in the
scatter-plot representation using our encoding.
The selection mechanism helps users to understand other
aspects of the clusters by inspecting a greater amount of features. However, when these features present a similar ğ‘value, such an interaction is not enough to easily select features of interest. In other words, the visual space dedicated to
various features could be too small. To decrease such an issue, we employ focus+context (Munzner, 2015) interaction
MarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

on the ğ‘-value axis, as shown in Fig. 16. On top of the axis
showing the ğ‘-values, there is another axis corresponding to
the context of the ğ‘-values. At first, the focus axis corresponds to the context axis. Users can then specify a range
where the focus axis will be defined, as illustrated in the figure by a red arrow. Notice the axis showing rectangles with
a larger width to comprise all of the space dedicated to the
axis. Finally, such a change in the focus induces change on
the features visualized as distribution plots, that is, the four
most discriminative features are shown â€“ the number of features automatically visualized can be changed in the tool-bar
of Fig. 8a (â€œFeaturesâ€ input).

6. Case studies
To validate the proposed technique, we explore different
datasets to understand their structures and how the features
influenced to cluster formation. Firstly, two document collections are inspected: a dataset of news articles from 2011
collected from different sources and a dataset of tweets about
COVID-19 symptoms collected inside the SÃ£o Paulo state
Page 9 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction

Figure 16: The context axis allows more detailed inspection
by defining witch part of the axis will receive focus.

(Brazil) territory, from March 2020 to August 2020. Second, our technique is evaluated upon a non-textual dataset,
where multivariate data is considered on a medical dataset.

6.1. The news dataset
In this first case study, we inspect a document collection
of 495 news articles in English available in RSS format by
Reuters, BBC, CNN, and Associated Press agencies. Fig. 17
shows the UMAP (McInnes et al., 2018) projection of the
dataset color-coded based on the Leiden (Traag et al., 2018)
algorithm. We used the first 40 Principal Components (PCs)
of the dataset to compute the neighborhood graph (ğ‘˜ = 15)
for the UMAP technique. The resolution parameter of the
Leiden algorithm was set to 0.3.

Figure 18: After selecting the five most discriminative features,
highlighting the terms nuclear, plant, and fukushima shows that
the projection technique was able to distinguish the news articles related to the nuclear accident on one side of the projection.

Figure 17: UMAP projection of the news dataset.

Looking at the most distinctive terms presented in Fig. 18,
and recalling that this news dataset contains articles from
2011, cluster represents news articles of the earthquake
that hit Japan in 2011. The terms show that an incident on
the nuclear plant of Fukushima I was part of the majority of
the news due to the earthquake. Further, the news articles related to the nuclear power plant incident are concentrated in
just one part of the cluster, meaning that the projection technique successfully uncovered a subcluster of news articles
referring to the same aspects of the earthquake.
To further explore cluster , we focus on the terms that
were not assigned much confidence (with ğ‘-values between
1 Ã— 10âˆ’3 and 1 Ã— 10âˆ’5 ) and then selected a few terms, as
illustrated in Fig. 19. In this case, the terms refer to the former Japanâ€™s primer-minister, Naoto Kan, that had resigned
his role after the crisis provoked by the earthquake and the
consequent incident in Fukushima I. The terms naoto, kan,
prime, minist, pm, and japanes further validate such an analysis.
Also, Fig. 20 shows the scatter-plot representation of the
expression intensity of the terms naoto and kan, which valiMarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

Figure 19: Inspection of terms with lower confidence (high
ğ‘-value) shows political aspects.

dates our approach to understand the organization imposed
by the dimensionality reduction technique. That is, while
news articles regarding the Fukushima I incident were positioned on the bottom of the cluster, news articles about
the former primer-minister were positioned on the top of the
cluster.
Proceeding to cluster , one can notice a lot of terms
with high confidence in Fig. 21. After selecting terms for
inspecting, two groups of terms are used to understand the
news articles in the clusters. The first terms (highlighted
in red) correspond to Ratko MladiÄ‡, which is a former Serbian military officer, head of the Serbian Republic Army during the Bosnian War between 1992-1995. The other group
Page 10 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction

Figure 20: Highlighting terms related to former Japanâ€™s primeminister shows that the dimensionality reduction technique was
also able to successfully separate distinctive news articles.

represents more specific information about the news articles contained in the cluster. The terms refer to the prison
of MladiÄ‡ due to war crimes. More specifically, the terms
tribun and hagu refer to the fact that MladiÄ‡ was extradited
to The Hague city in the Netherlands to respond to his crimes
in the International Court of Justice.

Figure 22: Inspection of the terms germani and europ shows that
the dimensionality reduction separated news articles focused
on the European continent from the news articles focused on
Germany.

dry cough, difficulty breathing, shortness of breath) retrieved
from SÃ£o Paulo state (Brazil) from March 2020 to August
2020. To create the dataset, we retrieved tweets mentioning one of the symptoms discussed above; then, we classified the tweets according to their relevance. We used the
BERT (Devlin et al., 2018) language model to train a classifier â€“ Supplementary File contains all of the performance
of the model â€“ to later select only relevant tweets.
To classify tweets as relevant or not, we manually classified 10 thousand tweets, then, BERT model was used to
classify another 30 thousand tweets, which comprises the
dataset analyzed in this section. The relevant tweets are the
ones where there is a chance of COVID-19 infection while
non-relevant are the tweets corresponding to jokes, news, or
other informative comments. Further, to inspect the dataset
projected on â„2 , we used UMAP technique with the nearest
neighbor graph set as 20. Finally, the clusters were manually
defined, as shown in Fig. 23.

Figure 21: Contrastive information showing levels of understanding. The terms highlighted in red show high-level information while the group of terms highlighted in blue gives
specific hints about the news articles.

We finish the analysis of this dataset by inspecting cluster . From the terms highlighted as discriminative, such a
cluster corresponds to news articles of a strain of Escherichia
Coli O104:h4 bacteria outbreak in northern Germany from
May to June of 2011. As illustrated in Fig. 22, the majority of
the news articles mention coli and outbreak. While the terms
europ and germani express in opposite sides of the cluster,
which could indicate that some news articles focus specifically in Germany while others represent news articles from
the whole of Europe. The other terms in the chart, health,
deadli, and infect, represent words related to the disease.

Figure 23: UMAP of the tweets about COVID-19.

The projection of the tweets shows four main clusters:
red , dark orange , orange , and a cluster divided into
five other subclusters ( , , , , ). To analyze these
clusters and to try to understand the dataset, we follow the
strategy of analyzing the separated greater clusters, then proceeding to the very cohesive cluster .
Fig. 24 shows that cluster is mostly related to tweets
about the shortness of breath, one of the most severe COVID19 symptoms â€“ the term breast, for example, could indicate
people describing how they feel and where the sensations are
6.2. Tweets of COVID-19 symptoms
occurring in their body. Another interesting aspect of such a
For this particular use case, we aim to analyze a complex
cluster is the term anxiety, which indicates a problem arisen
document collection to retrieve information on small-sized
by the necessity of social isolation during the pandemic. In
documents. Such document collection corresponds to tweets
about COVID-19 common symptoms (fever, high fever, cough, fact, during the collected data reading, many tweets correMarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

Page 11 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction

sponded to people asking whether their shortness of breath
was due to COVID-19 infection or due to an anxiety crisis.

Figure 24: Most discriminative terms of cluster â€™orangeâ€™ show a
strong relationship with terms related to respiratory problems.

To further understand cluster , we combine the focus
and selection interaction so that a greater number of terms
could be inspected, as shown in Fig. 25a). With other terms,
such as to-feel, heart, hospital, and to-die, this particular cluster seems to refer to tweets talking about respiratory
problems due to the presence of the terms breast, asthma, and
bronchitis. To further validate such an analysis, the scatter
plot with bars communicates where such terms are expressed
the most. Fig. 25b) shows that although such terms are also
expressed on the other clusters, tweetsâ€™ main focus talking
about respiratory problems is in cluster .
Figure 25: After using focus+context interaction to help anaProceeding to cluster , we focused on the terms with ğ‘lyze terms based on ğ‘-values (a), the distribution of values on
value â‰¥ 5. Fig. 26 shows that such a cluster is related mainly
the scatter-plot shows that breast, asthma, and bronchitis are
to dry cough symptom of COVID-19 due to the presence of
expressed nearly in the same form on cells of the clusters.
terms cough and dry â€“ the term sneeze is also present, and
while it is not a common symptom of COVID-19, it could
be written by Twitter users when describing their symptoms.
The other terms (annoying and each) usually consists in phrases
commonly identified in the tweets, such as, (directly translated from informal Portuguese) â€œI am with an annoying cough...â€
or â€œIt is each cough...â€.
After selecting other terms and inspecting them on the
scatter plot view, the discriminative power of the terms (except for to-cough) cannot be guarantee although they present
associated low ğ‘-values. Such an example shows the complexity of analyzing Twitter data due to the lack of consistency of words among the many tweets.
Figure 26: Most discriminative terms of cluster â€™light orangeâ€™
Finally, we analyze the subclusters on the bottom right
show complaining about symptoms expressed during COVIDof Fig. 23. As shown in Fig. 28, both of clusters and re19 infection.
fer to characteristics of fever symptom â€“ see how the terms
face, fever, body, and to-measure are expressed in cluster
while the terms I-think, fever, getting, thermometer, and
toms related to fever. Fig. 29 shows that the discriminative
hot are expressed in cluster . Particularly for cluster ,
terms are related to fever â€“ notice that we omitted the terms
the terms indicate users that had started to feel febrile when
sick, was, dipyrona, pain, night, to-be, and bath since they
they posted the symptom on Twitter. Such an insight could
are terms used to create the phrases. An interesting aspect
be significant to reveal which cities are presenting people
of this cluster is the presence of the term sore, which on the
with developing symptoms of COVID-19. That is, regulaone hand could be the cause of fever in some cases, on other
tory policies could be made based on the geolocalization of
hand could indicate a new COVID-19 symptom. To investithe tweets.
gate that, one would check all of the tweets mentioning the
Cluster indicates more general aspects about the sympMarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

Page 12 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction

Figure 27: Due to the lack of data samples, the ğ‘-value can
be misleading to interpret. As shown in the scatter-plot representation, the terms are similarly expressed on all of the parts
of the projection although the ğ‘-values indicate confidence.

Figure 29: Cluster shows more general aspects of symptoms
related to fever. The term sore, for example, could be a new
COVID-19 symptom or just an unrelated symptom.

Figure 30: Although this cluster also presents the symptom
fever, the other terms indicate Dengue symptoms.

Figure 28: Comparison of two clusters where the term fever is
in the subject of the topic.

term sore to understand if the term sore is correlated to a
new COVID-19 infection â€“ of course, it would be necessary
to see if the correlation is just a coincidence.
Unlike the other clusters, cluster present many different levels of understanding. Firstly, Fig. 30 shows that although one of the five most discriminative refers to fever,
such a cluster is likely to present people with Dengue symptoms. That is, while the citizens were posting how they feel
worried about COVID-19, the symptoms indicated on the
tweets match with those used to describe Dengue infection
(pain, head, throat, body, and fever), a common disease faced
by Brazil.
Finally, Fig. 31 shows that a severe symptom of COVID19 is also present in cluster : shortness of breath. Notice
that the terms presented in Fig. 31 shortness and breath are
the most distinctive ones. Besides that, other terms indicate
common symptoms of seasonal flu, such as coryza. Finally,
another term reinforces our idea about Dengue symptoms,
tiredness, which is a good indicator of Dengue infection (together with other symptoms, of course).
MarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

Figure 31: Cluster showing the most serious and one the main
indicates of COVID-19: shortness of breath.

We finalize this study case by showing how the terms
highlighted for cluster indicate usersâ€™ indagation on COVID19 symptoms. In Fig. 32 â€“ notice that not all of the terms
have ğ‘-value lower than 1 Ã— 10âˆ’5 â€“ the terms should, worry
communicates indagation about the users, probably about
feeling COVID-19 symptoms, as indicated by the term cough.
In this case study, the tweets presented three main topics: clusters is related to respiratory problems induced by
COVID-19 infection, as well as related to anxiety crisis due
to long periods of social isolation; cluster is related to one
of the most common symptoms of COVID-19, that is, dry
cough; finally, the cluster with divided subclusters has a lot
of aspects regarding high fever, where each one of the subPage 13 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction

Figure 32: The terms should, worry, is-it probably means indagation about symptoms.

cluster ( , , , , ) has its particularities. Finally, to
investigate cluster , the heatmap shown in Fig. 33 shows
much of the very cohesive cluster is comprised of tweets
concerning terms of worrying (see worry and risk) about
coryza and wearing masks.

Figure 33: Heatmap showing that cluster â€™redâ€™ comprises the
tweets where people are worried about wearing masks and
coryza.

6.3. Vertebral Column
In this case study, we aim to analyze a multivariate dataset.
The Vertebral Column dataset (Dua and Graff, 2017) is composed by 310 data instances described by six features derived from the shape and orientation of the pelvis and lumbar
spine: pelvic incidence, pelvic tilt, lumbar lordosis angle,
sacral slope, pelvic radius, and grade of spondylolisthesis.
Fig. 34 shows the UMAP projection of the Vertebral Column
dataset with the heatmap view. The projection is colored according to the ground truth classes: class stands for regular patients, class stands for patients with Spondylolisthesis â€“ a disturbance of the spine in which a bone (vertebra)
slides forward over the bone below it; the class stands for
patients with Hernia. Notice a clear separation of Spondylolisthesis class ( ) among the others. The heatmap view
shows that class is different from the others for having all
of the feature values (except P. Radius) with higher values,
as indicated by the green cells.
To investigate more about the class of patients with Spondylolisthesis ( ), the selection of the features with high confidence on their distinction aspects (that is, features whose
ğ‘-values are lower than 1 Ã— 10âˆ’5 ) shows that the distribution
plots present the values skewed to the right, as illustrated in
Fig. 35. The distribution plots also show how data instances
of patients with Spondylolisthesis present higher values for
D. Spondy., L. Angle, P. Incidence, and S. Slope. A few
of instances from this class also show much higher values
(indicated as outliers in the figure).
MarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

Figure 34: UMAP projection of the Vertebral Column dataset
next to the heatmap visualization.

Figure 35: The class of patients with Spondylolisthesis shows
greater values for all of the features, except for Pelvic Radius.

The scatter plot encoding with the intensity bars communicate where the data instances corresponding to the higher
values were positioned by dimensionality reduction technique.
Fig. 36 shows the scatter-plot encoded as intensity bars. Note
more color intensity as the data instances approach to the left
of the projection, i.e., more distant from classes and .
Such a characteristic validates our approach by helping at
understanding how the dimensionality reduction technique
organized the data instances on the projected layout.
Lastly, the distinctive features returned by our approach
reflect what happens when patients are diagnosed with Spondylolisthesis. That is, according to Labelle et al. (2005), pelvic
incidence, sacral slope, pelvic tilt, and lumbar lordosis angle are formed to be greater in patients with developmental spondylolisthesis. Moreover, the lower values for sacral
slope (S. Slope) is a known of centralistic herniation (Tebet,
2014), which could explain the slight separation between the
classes of healthy patients ( ) and patients with Hernia ( ).

7. Discussions
Contrastive analysis of multidimensional datasets offers
important mechanisms to understand how data samples differ from each other, where analysis about these clustersâ€™ specificities provides essential insights. For example, to identify
the different aspects of focus in groups of surveys and later
proceed to write the ones with characteristics of interest.
Although the literature already presents a method for contrastive visualization and analysis, we demonstrated how usPage 14 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction

Figure 36: Inspection of the distribution values of the features shows that the features are
truly expressed more in the cluster of patients with Spondylolisthesis.

ing the statistics and proper design of interaction and visualization can better interpret the relationship among distributions and the likelihood of discrimination of feature values. Moreover, our visualization design, through interaction
mechanisms, allows for a more detailed contrastive analysis.
Further, the visualization of the distribution of features
on the dimensionality reduction plots also helps to gain information about the dataset structures and how well dimensionality reduction techniques can group similar data points in
an intracluster perspective or convey global similarity (relationship among clusters) successfully.. Our design to simultaneously visualize the distribution values reduces the issues
induces by change blindness, that is, users are not required
to change between color scales to visualize the distribution
of different features.
Finally, one last important thing to mention about our
technique is related to the ordering of the features based on
their contrastive analysis. Particularly for datasets where
numbers indicate presence of elements, such as in document
collections where the bag-of-words representation indicates
the presence of a term in a document, we do not order the
features based on the absolute value of their ğ‘¡-score. By not
ordering using absolute value, the features on the first positions (notice that we order in decreasing way) consist on the
features that are present on clusters of interest, that is, features with negative ğ‘¡-scores for such scenario are the ones
not in the cluster.

7.1. Limitations
One limitation of our proposal is related to the t-Student
test. Although such an approach can be used to understand
discriminative power of variables, computing a ğ‘¡-statistic can
MarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

be problematic because the variance estimates can be skewed
by features having a very low variance (Jeanmougi et al.,
2010). Consequently, these features are associated to a large
ğ‘¡-statistic and falsely selected as discriminative terms (Tusher
et al., 2001). Another drawback comes from its application
on small sample sizes, which implies low statistical power (Murie
et al., 2008). However, to decrease the chance of wrong analyses, our tool allows us to investigate the distribution of values in the scatter-plot representation using the color scale or
to use the encoding to simultaneously visualize various variables.
Our techniqueâ€™s second limitation is related to the number of features inspected on the scatter plot representation.
When visualizing the distribution of a more significant number of features on the scatter-plot view, by augmenting the
boxesâ€™ area to circumvent the space dedicated to visualizing
feature intensity, users can better distinguish among different
classes. However, such an increase can remove the scatterplot context. The number of simultaneously features visualized can also impact the ability of users to distinguish the
different intensities among the features. We plant to investigate other strategies to simultaneously visualize such an information in future works. Finally, we also intend to provide
mechanisms to visualize features with diverging domain.

7.2. Implementation

The visualization strategies2 were implemented using D3.js (Bostock et al., 2011), while Scanpy (Wolf et al., 2018) was used
to generate the statistical variables.
2 The

application will be available after publication

Page 15 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction
Joia, P., Petronetto, F., Nonato, L., 2015. Uncovering representative groups
in multidimensional projections. CGF 34, 281â€“290.
The careful analysis of features during multidimensional
Jolliffe, I., 1986. Principal Component Analysis. Springer Verlag.
Kruskal, J., Wish, M., 1978. Multidimensional Scaling. Sage Publications.
analysis can better understand most discriminative features,
Kwon, B., Eysenbach, B., Verma, J., Ng, K., Filippi, C.D., Stewart, W.F.,
which influence the definition of clusters and subclusters.
Perer, A., 2018. Clustervision: Visual supervision of unsupervised clusExisting methods emphasize the most discriminative feature
tering. IEEE Trans. Vis. Comput. Graph. 24, 142â€“151.
in scatter-plot representations while enriching layouts to proKwon, B.C., Kim, H., Wall, E., Choo, J., Park, H., Endert, A., 2017.
vide interpretability of clusters.
AxiSketcher: Interactive Nonlinear Axis Mapping of Visualizations
through User Drawings. IEEE Transactions on Visualization and ComThis paper presents a novel approach to visualize conputer Graphics 23, 221â€“230.
trastive information of multidimensional datasets represented
Labelle, H., Roussouly, P., Berthonnaud, E., Dimnet, J., Oâ€™Brien, M., 2005.
by scatter-plots after dimensionality reduction. We use a biThe importance of spino-pelvic balance in l5-s1 developmental spondypartite graph metaphor to represent the relation among statislolisthesis: A review of pertinent radiologic measurements. Spine 30,
tics (ğ‘¡-score and ğ‘-value) of each feature of clusters. Using
27â€“34. doi:10.1097/01.brs.0000155560.92580.90.
Le, T., Akoglu, L., 2019. Contravis: Contrastive and visual topic modeling
focus+context analysis, we show how our approach can refor comparing document collections, in: The World Wide Web Confertrieve insights about cluster organization â€“ even for complex
ence, Association for Computing Machinery, New York, NY, USA. p.
datasets, such as tweets of COVID-19 symptoms. Finally,
928â€“938.
we also show how such an approach can be robust by comLinderman, G.C., Rachh, M., Hoskins, J.G., Steinerberger, S., Kluger,
paring it against well-known topic extraction techniques.
Y., 2019. Fast interpolation-based t-sne for improved visualization of
single-cell rna-seq data. Nature methods 16, 243 â€“ 245.
Maaten, L.J.P., Hinton, G.E., 2008. Visualizing high-dimensional data using t-sne. Journal of Machine Learning Research 9, 2579â€“â€“2605.
Acknowledgements
Marcilio, W.E., Eler, D.M., Garcia, R.E., 2017. An approach to perform
This research work was supported by FAPESP (SÃ£o Paulo
local analysis on multidimensional projection. 30th SIBGRAPI Conf.
Research Foundation) (grants #2018/17881-3 and #2018/25755- on Graph., Patterns and Images (SIBGRAPI) , 351â€“358.
Martins, R., Coimbra, D.B., Minghim, R., Telea, A., 2014. Visual anal8), and by the CoordenaÃ§Ã£o de AperfeiÃ§oamento de Pessoal
de NÃ­vel Superior - Brazil (CAPES) - grant #88887.487331/2020- ysis of dimensionality reduction quality for parameterized projections.
Comput. Graph. 41, 26â€“42.
00.
McInnes, L., Healy, J., Melville, J., 2018. UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. ArXiv e-prints
arXiv:1802.03426.
References
Munzner, T., 2015. Visualization Analysis and Design. AK Peters VisuAbdi, H., Valentin, D., 2007. Multiple correspondence analysis. Encycloalization Series, CRC Press. URL: https://books.google.de/books?id=
pedia of Measurement and Statistics , 651â€“657.
NfkYCwAAQBAJ.
Bostock, M., Ogievetsky, V., Heer, J., 2011. D3 data-driven documents.
Murie, C., Woody, O.Z., Lee, A.Y., Nadon, R., 2008. Comparison of small
IEEE Transactions on Visualization and Computer Graphics 17, 2301â€“
n statistical tests of differential expression applied to microarrays. BMC
2309.
Bioinformatics 10, 45 â€“ 45.
Cichocki, A., PHAN, A.H., 2009. Fast local algorithms for large scale nonNonato, L.G., Aupetit, M., 2018. Multidimensional projection for visual
negative matrix and tensor factorizations. IEICE Transactions , 708â€“
analytics: Linking techniques with distortions, tasks, and layout en721.
richment. IEEE Transactions on Visualization and Computer GraphCoimbra, D.B., Martins, R.M., Neves, T.T., Telea, A.C., Paulovich, F.V.,
ics , 1URL: doi.ieeecomputersociety.org/10.1109/TVCG.2018.2846735,
2016. Explaining three-dimensional dimensionality reduction plots. Indoi:10.1109/TVCG.2018.2846735.
formation Visualization 15, 154â€“172.
Pagliosa, L.C., Pagliosa, P.A., Nonato, L.G., 2016. Understanding attribute
Devlin, J., Chang, M.W., Lee, K., Toutanova, K., 2018. Bert: Pre-training
variability in multidimensional projections, in: 29th Conf. Graphics,
of deep bidirectional transformers for language understanding. URL:
Patterns and Images (SIBGRAPI), pp. 297â€“304.
http://arxiv.org/abs/1810.04805.
Paulovich, F.V., Nonato, L.G., Rosane, M., Levkowitz, H., 2008. Least
Dua, D., Graff, C., 2017. UCI machine learning repository. URL: http:
square projection: A fast high-precision multidimensional projection
//archive.ics.uci.edu/ml.
technique and its application to document mapping. IEEE Transactions
Fujiwara, T., Kwon, O.H., Ma, K.L., 2019. Supporting analysis of dimenon Visulization and Computer Graphics 3, 564â€“575.
sionality reduction results with contrastive learning. IEEE Trans. Vis.
RÃ¶der, M., Both, A., Hinneburg, A., 2015. Exploring the space of topic
and Comp. Graph. 26, 45â€“55.
coherence measures, in: Proceedings of the Eighth ACM International
Gassen, S.V., Callebaut, B., van Helden, M.J., Lambrecht, B.N., Demeester,
Conference on Web Search and Data Mining, Association for Computing
P., Dhaene, T., Saeys, Y., 2015. Flowsom: Using self-organizing maps
Machinery, New York, NY, USA. p. 399â€“408.
for visualization and interpretation of cytometry data. Cytometry. Part
Sarikaya, A., Gleicher, M., Szafir, D.A., 2018. Design factors for summary
A : the journal of the International Society for Analytical Cytology 87
visualization in visual analytics. Comput. Graph. Forum 37, 145â€“156.
7, 636â€“45.
Silva, R.R.O.d., Rauber, P.E., Martins, R.M., Minghim, R., Telea, A.C.,
Hoffman, M., Bach, F.R., Blei, D.M., 2010. Online learning for latent
2015. Attribute-based Visual Explanation of Multidimensional Projecdirichlet allocation, in: Lafferty, J.D., Williams, C.K.I., Shawe-Taylor,
tions, in: Bertini, E., Roberts, J.C. (Eds.), EuroVis Workshop on Visual
J., Zemel, R.S., Culotta, A. (Eds.), Advances in Neural Information ProAnalytics (EuroVA).
cessing Systems 23. Curran Associates, Inc., pp. 856â€“864.
Stahnke, J., DÃ¶rk, M., MÃ¼ller, B., Thom, A., 2016. Probing projections:
Izenman, A.J., 2008. Linear Discriminant Analysis. Springer New York,
Interaction techniques for interpreting arrangements and errors of diNew York, NY. pp. 237â€“280.
mensionality reductions. IEEE Trans. on Vis. and Comp. Graph. 22,
Jeanmougi, M., de Reynies, A., Marisa, L., Paccard, C., Nuel, G., Guedj,
629â€“638.
M., 2010. Should we abandon the t-test in the analysis of gene expression
Tebet, M., 2014. Current concepts on the sagittal balance and classification
microarray data: a comparison of variance modeling strategies. PLoS
of spondylolysis and spondylolisthesis. Rev Bras Ortop , 3â€“12.
One .
Traag, V., Waltman, L., van Eck, N.J., 2018. From louvain to leiden: guar-

8. Conclusion

MarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

Page 16 of 17

Contrastive analysis for scatter plot-based representations of dimensionality reduction
anteeing well-connected communities. arXiv preprint arXiv:1810.08473
.
Turkay, C., Lundervold, A., Lundervold, A.J., Hauser, H., 2012. Representative factor generation for the interactive visual analysis of highdimensional data. IEEE Trans. Vis. Comput. Graph. 18, 2621â€“2630.
Tusher, V.G., Tibshirani, R., Chu, G., 2001. Significance analysis of
microarrays applied to the ionizing radiation response. Proceedings of the National Academy of Sciences 98, 5116â€“5121. URL:
https://www.pnas.org/content/98/9/5116, doi:10.1073/pnas.091062498,
arXiv:https://www.pnas.org/content/98/9/5116.full.pdf.
Wang, Y., Li, J., Nie, F., Theisel, H., Gong, M., Lehmann, D.J., 2017. Linear discriminative star coordinates for exploring class and cluster separation of high dimensional data. Computer Graphics Forum 36, 401â€“410.
Ward, M.O., 2002. A taxonomy of glyph placement strategies for multidimensional data visualization. Information Visualization 1, 194â€“
210. URL: http://dx.doi.org/10.1057/palgrave.ivs.9500025, doi:10.
1057/palgrave.ivs.9500025.
Wolf, F., Angerer, P., Theis, F., 2018. Scanpy: large-scale single-cell gene
expression data analysis. Genome Biol 19.

MarcÃ­lio-Jr et al.: Preprint submitted to Elsevier

Page 17 of 17

