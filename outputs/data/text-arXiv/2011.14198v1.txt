Fair and Diverse Allocation of Scarce Resources

arXiv:2011.14198v1 [math.OC] 28 Nov 2020

Hadis Anahideh
University of Illinois at Chicago
hadis@uic.edu

Lulu Kang
Illinois Institute of Technology
lkang2@iit.edu

Nazanin Nezami
University of Illinois at Chicago
nnezam2@uic.edu

Abstract
We aim to design a fairness-aware allocation approach to maximize the geographical diversity and avoid unfairness in the sense of demographic disparity. During
the development of this work, the COVID-19 pandemic is still spreading in the U.S.
and other parts of the world on large scale. Many poor communities and minority
groups are much more vulnerable than the rest. To provide sufficient vaccine and
medical resources to all residents and effectively stop the further spreading of the
pandemic, the average medical resources per capita of a community should be
independent of the community‚Äôs demographic features but only conditional on
the exposure rate to the disease. In this article, we integrate different aspects of
resource allocation and seek a synergistic intervention strategy that gives vulnerable populations with higher priority when distributing medical resources. This
prevention-centered strategy is a trade-off between geographical coverage and social group fairness. The proposed principle can be applied to other scarce resources
and social benefits allocation.

1

Introduction

The COVID-19 pandemic has been widely spreading around the globe and caused hundreds of
thousands of deaths, crashed the healthcare systems of many countries, and stalled almost all social
and economical activities, which leads to an astronomical amount of financial loss. To battle the
spreading COVID-19 pandemic, several leading countries and organizations have devoted a significant
amount of resources to develop vaccines, new diagnostics, and anti-infective treatments for the novel
coronavirus [15]. More than 60 candidate vaccines are now in development worldwide, and several
have entered early clinical trials in human volunteers, according to the World Health Organization [33].
Once the development of the treatments is approved for public use, it is of paramount importance that
these resources are quickly dispatched to all the communities in a country because one weak link in the
defense against the virus would leave the neighboring communities even the whole state vulnerable
and exposed to the spreading of the disease. However, the existing healthcare infrastructures in many
states and cities are insufficient to provide universal supplies of vaccinations and treatments. Hence,
targeting the high risk population and setting fair principles for prioritizing the allocation accordingly,
will save lives, curb the further spreading of the virus, and prevent a second global pandemic outbreak
in the coming year.
In United States, due to the disparities [36] between different population subgroups in terms of
health, financial stability, and accessibility to health care services, certain low-income and minority
populated communities are particularly vulnerable to COVID-19. For example, among Chicago‚Äôs
minority groups, the Latinx and Black groups have been hit much harder by the COVID-19 pandemic
than any other ethnic groups. By the latest report (September 15, 2020) from the Chicago Department
Preprint. Under review.

of Public Health (CDPH), among the death tolls caused by COVID-19, 33.0% are from the Latinx
group and 42.8% are from Black & non-Latinx group [40]. These two ethnic groups also lead in
the number of COVID-19 confirmed cases by a great margin compared to the rest. These ratios are
disproportional to the percentages of these ethnic groups of the total population in Chicago, which
mainly consists of 32.3% white, 28.7% Hispanic, and 30.9% African American, according to US
Census Bureau [2].
The development of vaccine and other effective treatment medicines against any novel infectious
disease generally takes a long time due to the high uncertainties in all the stages in the process,
including clinical trial. Even if the vaccines are successfully developed, initially they will only
be available in limited quantities due to manufacturing and logistic capabilities and the financial
cost. Since the available amount of vaccines and treatments are insufficient for the entire population,
especially during the early production stages, the allocation of such resources becomes a difficult and
yet pressing issue. Moreover, due to the different distribution of demographic and occupational factors
of the residents in different geographical regions, resource allocation merely based on maximum
geographical uniformity can lead to an unfair distribution and propagate biases across population
subgroups of the population.
We design a fairness-aware vaccine and scarce treatment resources allocation framework considering
both Geographical Diversity and Social Group Fairness as guiding principles for prevention-centered
strategies. The social group fairness is based on the general fairness notion of Equality of Opportunity
[20, 25]. We consider an allocation strategy is fair if the average amount of resources an individual
receives is only dependent on the individual‚Äôs exposure rate to the disease and is independent of the
individual‚Äôs demographic or social-economic background. We also consider an allocation strategy
to be diverse if the geographical location does not affect the averaged resources an individual can
receive. Based on such notions of fairness and diversity, we formally define them and formulate
them into inequality constraints. Our proposed research provides a solution to distribute the scarce
medical resources in a fair manner to all communities, and particularly protect certain minorities and
low-income groups that turn out to be vulnerable to this pandemic. Not only can such a planning
solution can help stop the spreading pandemic more effectively, but also pushes for justice and
fairness in healthcare decision making.
1.1

Related Work

Resource allocation problem has a long history in economics (e.g, [24]), management science
(e.g, [11]), emergency response (e.g, [23]), and many more domains. Healthcare resource allocation
is one of the most challenging allocation problems. A large number works have been developed to
identify effective strategies for medical resource allocation [6, 9, 21, 22, 27, 35, 42, 46].
Recently, the fairness of algorithmic decision making has been the center of attention of many
researchers, who are designing and developing algorithms for different purposes, such as machine
learning, ranking, and social welfare [3, 4, 18, 48]. Mitigating the bias of an outcome from a
decision model, which is mainly caused by the inherent bias in the data and societal norm, will
ensure that the outcome is not favorable or adversarial toward any specific subgroup of observations
[3, 14, 19, 25, 45, 47, 48]. One of the critical problems where the fairness of the outcome matters
significantly is scarce resource allocation. The notion of fairness in resource allocation has been
introduced in [5] and later with a more precise definition in [7].
Fairness was firstly adopted in bandwidth allocation problem for computer network systems [8, 12,
16, 28, 29, 30, 32, 38, 39]. In these settings, the amount of resources requested can be modified by
different users. Besides, service allocation mainly covers a group of users and is not necessarily
one-to-one allocation. These settings differ from the resource allocation for scarce treatments which
is a one-to-one allocation problem.
Now fairness has been addressed in many resource and service allocation methods [20, 31, 34, 35, 44].
Here we highlight a few and emphasize our difference from them. In [20], the authors formalize a
general notion of fairness for allocation problems and investigate its algorithmic consequences when
the decision-maker does not know the distribution of different subgroups (defined by creditworthy or
criminal background) in the population. The distribution estimation is accomplished using censored
feedback (individuals who received the resource, not the true number). In our work, we estimate the
distribution of different social groups from the data using Bayes rule. Singh [41] considers a fair
2

allocation of multiple resources to multiple users and have proposed a general optimization model
to study the allocation. Our proposed method differs from [41] on two aspects. First, [41] assumes
multi-resources and multi-type users, whereas we mainly focus on resource allocation problem across
different regions and different population subgroups. Second, [41] aims to maximize the coverage,
whereas we consider a fairness-diversity trade-off by minimizing the diversity and fairness gaps,
simultaneously, across different regions. Donahue et al. [17] considers the problem of maximizing
resource utilization when the demands for the resource are distributed across multiple groups and
drawn from probability distributions. They require equal probabilities of receiving the resource
across different groups to satisfy fairness and provide upper bounds on the price of fairness over
different probability distributions. In our proposed model, we utilize a similar fairness requirement
while requiring diversity (population) consideration across different regions. Thus, our work is an
intersection between fairness and diversity. Furthermore, we deal with the one-to-one allocation
instead of the coverage problem.
1.2

Summary of Contributions

In this paper, we consider a fair and diverse allocation of scarce resources. The proposed approach is
different from the existing works using the maximum utilization [10] or maximum coverage [20, 41]
objective. The nature of the treatment allocation problem is not the same as the coverage problems,
since the former is a one-to-one assignment problem, whereas in the latter the resource can cover
more than one user such as police or doctor allocation [17, 20]. In our work, we aim to study scarce
resource allocation considering the trade-off between geographical diversity and social fairness. More
specifically, we do not seek to share the vaccines equally among groups of populations. Instead, we
aim to emphasize the protection of the vulnerable populations or the ones at high risk, depending on
their exposure rate, in order to prevent death/spread of the disease. We focus on the available data to
estimate the necessary parameters and perform an empirical study using the proposed Algorithm 2.
However, our proposed model can be generalized to resource allocation in other scenarios such as
disaster relief.
In ¬ß 2, we first provide a mathematical definition of the notion of geographical diversity and social
group fairness for the allocation of scarce medical treatments and vaccines. We then formulate
the allocation problem into an Integer Program (IP) problem, which incorporates the diversity and
fairness as constraints, in addition to capacity constraint, i.e., the amount of available resources.
Fairness and diversity constraints are bounded by user-defined hyperparameters, d , and f , which are
the allowed diversity and fairness gaps, respectively. To obtain a feasible solution for the original IP
problem efficiently, we relax the IP problem to a Linear Programming (LP) problem. Moreover, the
fairness and diversity constraints are much more complicated than the capacity constraint, and to deal
with them efficiently, we use the penalty method, which is a common practice to solve constrained
optimization. The two constraints are combined into a single objective function using a trade-off
hyperparameter Œ± To guarantee that the converted problem is equivalent to the original feasibility
problem we provide theoretical proofs and subsequently. A binary search algorithm is used to obtain
a feasible range of Œ±. We evaluate the allocation scenario under different (d , f ) values and provide
the corresponding feasible range for Œ±, accordingly. Different levels of the trade-off between diversity
and fairness are presented. The proposed framework can be applied at different stages of the pandemic
to estimate the exposure rate of population subgroups, and obtain a feasible allocation considering
both population size and exposed population. In ¬ß 3, we evaluate the performance of the proposed
model using COVID datasets in Chicago for vaccine and scarce treatment allocations. The results
demonstrate the impact of incorporating fairness criteria in the allocation model compared to the
diverse allocation and uniform allocation. The paper concludes in ¬ß 5.

2
2.1

Fair and Diverse Allocation
Problem Set-Up

We consider a centralized decision maker for allocating available b units of vaccines to a set of centers
denoted by M . They include clinics, hospitals, pharmacies, etc. For convenience, we assume the
entire area covered by the M centers to be a city, but it can be a county, or other administrative
district. Let xj be the decision variable denoting the amount of vaccines to be allocated to center
j ‚àà M . Let zj be the region, such as the list of zip-code areas, that are assigned to be covered by
3

center j. For simplification, we assume there is no overlap between the list of zip-code areas covered
by different centers (even if they are close in distance), i.e. zl ‚à© zk = ‚àÖ, ‚àÄl, k ‚àà M . We also assume
the policy that residents can only receive the resources from the center that covers the region where
they reside. Such policy is not uncommon in practice, especially in distribution of scarce resources.
Next we introduce some key concepts and their notation. If we consider the geographical location
of any individual reside to be a random variable, denoted by Z, then {j ‚àà M, zj } are the possible
values for Z. Therefore, P (Z = zj ) is the proportion of the population who reside in zj . Let
U1 , . . . , Up be discrete-valued sensitive variables corresponding to demographic and socioeconomic
attributes, and Si for i = 1, . . . , p be the set of possible levels for each of the sensitive variable.
For instance, if [U1 , U2 , U3 ] represent three attributes, income, race, gender, respectively, then
S1 = {low, medium, high}, S2 = {black, latinx, white, others}, and S3 = {female, male}. The
combinations of all the levels of U1 , . . . , Up is a set denoted by G. In other words, G = S1 √ó
S2 ¬∑ ¬∑ ¬∑ √ó Sp . For any g ‚àà G, it corresponds to a possible combination of levels of U1 , . . . , Up , such
as < low ‚àí income, black, f emale >, and there can be a group of population whose values of
the sensitive variables (U1 , . . . , Up ) are equal to g. For short, we call it social group g. Let the
set G be indexed by a set I, i.e., G = {gi , for i ‚àà I}. Let si,j be the population
P size of social
group gi who reside in region zj , where i ‚àà I, j ‚àà M . In other words, si,j / r‚ààI,k‚ààM sl,j =
P ([U1 , . . . , Up , Z] = [gi , zj ]). Let E be a binary random variable, with E = 1 representing the
individual is exposed to the infectious disease and E = 0 otherwise. Let P (E = 1|gi ) be the
exposure rate of the social group gi and P (E = 1|gi , zj ) the exposure rate of the social group gi
living the area of zj . It is intuitive to imagine these exposure rate depends on the social groups and
regions. We will discuss more on some reasonable assumptions on exposure rate and how to estimate
them later.
A key concept in resource allocation is the amount of the resource per capita. It is a ratio between the
quantity of available resource and the size of the population who are going to receive the resource.
Denote V as the amount of resource one individual receives. One important assumption we make
here is that V follows a discrete uniform distribution, and there are three parameters involved,
the amount of resource X, Y the population who are to receive the X amount of resource, and
size of the population Y = card(Y), the cardinality of Y. Therefore, the mean value of V is
E(V |X, Y, Y ) = X
Y is the resources per capita, and it varies with respect to the three parameters.
The focus of this article is on the following problem. Given a limited amount of resource b, such
as vaccines, how should the decision maker allocate the amount of resource xj to each center j
satisfying geographical diversity (quantified by D(x)), and social fairness (quantified by F(x)).
2.2

Diversity and Fairness

In this part, we define geographical diversity and social group fairness, which the latter is based on
the equality of opportunity notion of fairness [19]. To quantify the geographical diversity and social
fairness, we introduce D(x) and F(x) in Equations (1) and (3).
Definition 1. (Geographical Diversity)
Geographical Diversity of allocation of limited resource to a set of centers M is satisfied if ‚àÄj ‚àà M ,
on average the resource perPcapita is invariant with respect to the location of the group of the
population, i.e., E(V |xj , zj , i‚ààI si,j ) does not vary with respect to the location zj .
P
The notation E(V |xj , zP
) is simplified and we use zj to refer to the population who reside
j,
i‚ààI si,jP
in region zj . Let E(V | j‚ààM xj , i‚ààI,j‚ààM si,j ) denote the averaged resource per capita over the
entire city under the consideration of the resource allocation plan, and the location is omitted since it
is obvious. It is straightforward to formulate the geographical diversity Dj (x) for ‚àÄj ‚àà M as follows.
P
xj
X
X
X
xj
j‚ààM
Dj (x) = E(V |xj , zj ,
si,j ) ‚àí E(V |
xj ,
si,j ) = P
‚àí P P
. (1)
si,j
si,j
i‚ààI

j‚ààM

i‚ààI,j‚ààM

i‚ààI

j‚ààM i‚ààI

So if geographical diversity is strictly met, Dj (x) = 0 for all j.
The geometrical diversity represents the conventional or minimal requirement for resource distribution,
that the resources should be evenly distributed among all geographical regions across the entire
4

city. Next, we introduce the concept of social fairness. In this definition, we emphasize the even
distribution of resource among the endangered population, i.e., who are exposed to the infectious
disease, disregarding the social groups.
Definition 2. (Social Fairness)
Social Fairness of allocation of limited resource to a set of centers M is satisfied if ‚àÄi ‚àà I, the
averaged resource per capita is invariant with respect to the values of U1 , . . . , Up of the group of
population, i.e., E(V |E = 1, gi ) does not vary with respect to the social group gi .
The notation E(V |E = 1, gi ) is simplified and we use E = 1 and gi to denote the exposed individuals
in social group gi . Directly translating this definition into formula, the fairness principle should be
Fi (x) = |E(V |E = 1, gi ) ‚àí E(V |E = 1)|,

‚àÄi ‚àà I.

However, the calculation of E(V |E = 1, gi ) and E(V |E = 1) are not so straightforward, and we
derive them as follows.
We first calculate the resource per capita for the exposed individuals who reside in zj , disregarding
the social group, i.e.,

E(V |E = 1, zj ) = P

xj
,
sl,j √ó P (E = 1|zj , gl )

l‚ààI

in which the denominator is the amount of exposed individuals in zj . Then,

E(V |E = 1, gi ) =

X

E(V |E = 1, zj )P (Z = zj |E = 1, gi )

j‚ààM

=

X
j‚ààM

=

X
P
j‚ààM

=

l‚ààI

X
P
j‚ààM

P (E = 1, [U1 , . . . , Up ] = gi , Z = zj )
P (E = 1, [U1 , . . . , Up ] = gi )
P
si,j P (E = 1|gi , zj )/( i0 ,j 0 si0 ,j 0 )
xj
P
P
√ó P (E = 1|zj , gl )
si,k P (E = 1|gi , zk )/( i0 ,j 0 si0 ,j 0 )

E(V |E = 1, zj )

sl,j

k‚ààM

xj
s P (E = 1|gi , zj )
P i,j
sl,j √ó P (E = 1|zj , gl )
si,k P (E = 1|gi , zk )

l‚ààI

k‚ààM

In this article, we assume that the chance of exposure of an individual only depends on the individual‚Äôs
social attributes, and is independent of the geographical location, i.e., P (E = 1|U1 , . . . , Up , Z) =
P (E = 1|U1 , . . . , Up ). Equivalently, ‚àÄi ‚àà I and ‚àÄj ‚àà M , P (E = 1|gi , zj ) = P (E = 1|gi ). This
assumption is reasonable since in many U.S. cities as in Chicago, the geometrical locations of the
residents are in fact highly correlated with the social and economical status of the residents. For
example, in Figure 1, the percentage of the major ethnic groups, White, Hispanic, and AfricanAmerican, are shown in three heat maps. It is very clear that the geometrical locations of the residents
and the racial groups are heavily correlated. Of course, this assumption also makes the rest of the
formulation much simpler. Under this assumption, we can simply obtain

E(V |E = 1, gi ) =

X
P
j‚ààM

sl,j

l‚ààI

xj
s
P i,j .
√ó P (E = 1|gl )
si,k
k‚ààM

5

(2)

(a) White

(b) Hispanic groups.

(c) African-American

Figure 1: Map of Race and Ethnicity by Neighborhood in Chicago.

Next, to obtain E(V |E = 1), we need to integrate Equation (2) with respect to gi , i.e.,
E(V |E = 1) =

X

E(V |E = 1, gi )P ([U1 , . . . , Up ] = gi |E = 1)

i‚ààI

P ([U1 , . . . , Up ] = gi )
P (E = 1)
i‚ààI
P
P
si,k /( i0 ,j 0 si0 ,j 0 )
X
k‚ààM
P
=
E(V |E = 1, gi )P (E = 1|gi ) P
sr,k0 P (E = 1|zk0 , gr )/( i0 ,j 0 si0 ,j 0 )
=

X

E(V |E = 1, gi )P (E = 1|gi )

i‚ààI

r‚ààI,k0 ‚ààM

=

X

X

=

XX

Ô£≠
i‚ààI

P
P (E = 1|gi )
si,k
k‚ààM
P
sr,k0 P (E = 1|gr )

Ô£∂

Ô£´
P
j‚ààM

l‚ààI

P
i‚ààI j‚ààM

s
xj
P i,j Ô£∏
sl,j √ó P (E = 1|gl )
si,k
k‚ààM

xj
sl,j √ó P (E = 1|gl )

r‚ààI,k0 ‚ààM

P (E = 1|gi )si,j
P
.
sr,k0 P (E = 1|gr )
r‚ààI,k0 ‚ààM

l‚ààI

Based on the derivations, we can formulate the fairness for ‚àÄi ‚àà I,
Fi (x) = |E(V |E = 1, gi ) ‚àí E(V |E = 1)| =
X
P
j‚ààM

sl,j

(3)

XX
xj
s
xj
P i,j ‚àí
P
√ó P (E = 1|gl )
si,k
sl,j √ó P (E = 1|gl )

l‚ààI

k‚ààM

i‚ààI j‚ààM

l‚ààI

s P (E = 1|gi )
P i,j
.
sr,k0 P (E = 1|gr )
r‚ààI,k0 ‚ààM

Similar to the definition of Dj (x), if the fairness is strictly met, Fi (x) = 0 for all i ‚àà I.

2.3

Optimization

As explained above, if the diversity and fairness requirements are strictly met, all Dj (x) and Fi (x)
should be 0. However, such constraints are too restrictive and can be difficult or impossible to satisfy
for all regions and social groups. Define D(x) = maxj‚ààM Dj (x) and F(x) = maxi‚ààI Fi (x). D(x)
and F(x) are auxiliary decision variables that signify the tight upper bounds on the diversity and
fairness constraints, i.e., Dj (x) ‚â§ D(x) and Fi (x) ‚â§ F(x) for any j ‚àà M and i ‚àà I. Ideally, we
want to find the a feasible solution x such that both upper bounds
P are equal to zero. In addition, xj
for j = 1, . . . , M should satisfy the capacity constraint, i.e., j‚ààM xj = b. Seeking to achieve
the geographical diversity and social fairness simultaneously, one can formulate this problem as
multi-objective (MO) minimization.
6

P1 :

min (D(x), F(x))
x

Dj (x) ‚â§ D(x),
Fi (x) ‚â§ F(x),
X
xj = b

‚àÄj ‚àà M
‚àÄi ‚àà I

j‚ààM

xj ‚â• 0,
xj ‚àà Z,

‚àÄj ‚àà M
‚àÄj ‚àà M.

The integer constraint is because usually, resource such as vaccines are counted in integers and one
individual only receives one vaccination. The integer constraints in P 1 can be relaxed, particularly in
practice when b is large.
A common solution to the multi-objective optimization problem is to use the weighted sum method,
which leads to a simpler minimization problem P 2. After removing the absolute operation in the
constraints, we obtain the relaxed linear programming (LP) problem.
P2 :

min (1 ‚àí Œ±)D(x) + Œ±F(x)
x

s.t.

Dj+ (x) ‚â§ D(x),

‚àÄj ‚àà M

Dj‚àí (x)
Fi+ (x)
Fi‚àí (x)

‚â• D(x),

‚àÄj ‚àà M

‚â§ F(x),

‚àÄi ‚àà I

‚â• F(x),

‚àÄi ‚àà I

X

xj = b

j‚ààM

xj ‚â• 0,

‚àÄj ‚àà M.

where Dj+ (x) refers to the positive side of the absolute value function, Dj (x), and Dj‚àí (x) refers to
the negative side of the absolute function. Similarly, for Fj (x), we have Fj+ (x) and Fj‚àí (x). Here
Œ± ‚àà [0, 1] is a hyperparameter that controls the trade-off between the importance of fairness and
diversity. If Œ± > 0.5, the objective function focuses more on achieving the fairness, and it focuses
more on the diversity if Œ± < 0.5.
If we relax the integer constraints of P 1, based on the multi-objective optimization theory, it is easy
to conclude that for any x‚àó in the Pareto front of P 1, there exists an Œ±‚àó ‚àà [0, 1] such that x‚àó is an
optimal solution of P 2. This is because the remaining
constraints of P 1, including Dj (x) ‚â§ D(x)
P
for all j ‚àà M , Fi (x) ‚â§ F(x) for all i ‚àà I, j xj = b, and xj ‚â• 0 for all j ‚àà M , form a convex
polyhedron. Particularly, the constraints Dj (x) ‚â§ D(x) and Fi (x) ‚â§ F(x) are all linear in x. Thus,
we have the above conclusion.
In practice, the simplex method can be used to find the optimal solution of P 2 efficiently with
common optimization libraries like IBM CPLEX and SciPy.
Once the optimal solution of the LP-relaxation problem, P 2, is obtained for a given Œ± value, we
need to round the solution into integers. But the rounded solution is not necessarily feasible for the
minimization problem P 2. To ensure the feasibility of the rounded solution we employ a heuristic
rounding approach in Algorithm 1, which is similar to the one in [43]. The algorithm starts with
rounding the LP relaxation solution to the nearest integer values. Next, if the capacity constraint
P
j‚ààM xj = b is not satisfied, the algorithm reduces xj for the top populated region based on the total
exceeded amount. If the resource constraint is under-satisfied, the algorithm increases the top exposed
populated areas based on the total remaining resources. Note that in the Diverse-only (Œ± = 0) and
Fairness-only (Œ± = 1) scenarios, the algorithm only considers the population and exposed population
to sort xj ‚Äôs, respectively.
7

2.4

Feasibility

As we discussed in ¬ß 2.3, the ideal situation would be
minimizing the upper bounds D(x) and F(x) to the
full extent. An important observation to make here
Algorithm 1 Rounding Heuristic
is that the ideal case with zero upper bounds both on
the fairness and the diversity constraints is almost al- 1: Find the LP relaxation solution; solve P 3.
2: Round xjP
to the nearest integer for j ‚àà M .
ways impossible, due to the underlying biases in data
0
3:
b
=
b
‚àí
j‚ààM xj .
and historical discrimination in society. Therefore,
0
4:
if
b
<
0
then
in practice, a small positive upper bound threshold
is considered to be satisfied on fairness and diver- 5: Sort xj ‚Äôs according to the population size
of zj (from largest to smallest).
sity. For example, the fairness requirement can be
6:
Decrease the xj ‚Äôs corresponding to the top
thought of as the US Equal Employment Opportunity
[b0 ] populated regions by 1.
Commission‚Äôs ‚Äùfour-fifths rule,‚Äù which requires that
7: else if b0 > 0 then
‚Äùthe selection rate for any race, sex, or ethnic group 8: Sort xj ‚Äôs according to the exposed popula[must be at least] four-fifths (4/5) (or eighty percent)
tion of zj (from largest to smallest).
of the rate for the group with the highest rate‚Äù1 . We 9: Increase the xj ‚Äôs corresponding to the top
[b0 ] regions by 1.
consider a similar requirement for diversity as well.
10: end if

The solution obtained under the MO model, P 2, is 11: Return xj , ‚àÄj ‚àà M .
unable to guarantee to satisfy these requirements.
For example, a solution with zero unfairness (but not
satisfactory on the level of diversity) can be on the
Pareto front solution of MO ‚Äì hence might be the optimal output ‚Äì even though it is not a valid
solution.
Subsequently, we introduce two control parameters d and f , which are the acceptable thresholds
for the diversity and fairness requirements, i.e., D(x) ‚â§ d and F(x) ‚â§ f . The violation threshold
parameters D , F ‚àà [0, 1], are user-defined values that determine how diverse and fair the allocation
should be. The value F = 0 corresponds to a fully fair allocation, whereas F = 1 corresponds to
a completely fairness-ignorant allocation that solely considers the diversity. These violations must
be relatively small by which resources allocated to a particular region and particular group nearly
achieve the required level of diversity and fairness, respectively. Note that as quantitative metric,
we say that allocation is considered as fair if F(x) ‚â§ f , and allocation is considered as diverse if
D(x) ‚â§ d . Depending on the constraints, the weights, and the available scarce resources, no feasible
solution may exist for the optimization problem. In this case, the decision-maker will have no choice
but to relax the constraints. In ¬ß3 we will discuss the allocation under different scenario.
Fortunately, as we shall prove in Theorem 1, if the problem has a feasible solution given the fairness
and diversity constraints, there must exist an Œ± value under which the optimum solution of P 2 is
feasible and vice versa.
P
Proposition 1. Let be X 0 = {x|D(x) < d , F(x) < f , j‚ààM xj = b, xj ‚â• 0}:
1. If X 0 6= ‚àÖ: given x‚àó ‚àà X 0 , ‚àÉŒ±‚àó such that x‚àó is an optimal solution of P 2.
2. If 6 ‚àÉ Œ±‚àó such that x‚àó is an optimal solution of P 2 that satisfies both conditions D(x) < d
and F(x) < f , then X 0 = ‚àÖ.
We now need to find the Œ± value for which an optimum of P 2 is a feasible satisfying diversity and
fairness requirements. To do so, a naive approach would be a brute-force search in [0, 1] with a
small step sizes added to Œ±. However, this is not a practical approach since it needs to solve the
optimization problem in each iteration and as the step size decreases the exhaustive search increases
and the number of times that it needs to solve P 2 increases, accordingly. Therefore, we first obtain
the monotone properties of optimal upper bound D(x) and F(x) with respect to Œ±. This result is
used to find proper Œ± value later in ¬ß 2.5.
Proposition 2. Let x‚àó1 and x‚àó2 be optimum solutions of P 2 given Œ±1 and Œ±2 , respectively. It can be
shown that if Œ±1 ‚â§ Œ±2 , then F(x‚àó2 ) ‚â§ F(x‚àó1 ) and D(x‚àó1 ) ‚â§ D(x‚àó2 ).
1

Uniform Guidelines on Employment Selection Procedures, 29 C.F.R. ¬ß1607.4(D) (2015).

8

2.5

Choosing Trade-off Parameter, Œ±

The parameter Œ± in P 2 controls the trade-off between the diversity and fairness of the allocation
decision. Using the monotone property of D(x) and F(x) to Œ± in Proposition 1, we now propose
an approach to find a proper Œ± value that satisfies both fairness and diversity constraints for given
(d , f ).
Using an example we show the high-level idea of the tuning algorithm under different scenarios. In
Figure 2, the monotonically decreasing red curve corresponds to the fairness constraint and the monotonically increasing blue curve corresponds to the diversity constraint. The dashed horizontal lines
corresponds to the thresholds allowed for diversity D(x) and fairness F(x) constraints, respectively.
For Œ± < Œ±1 we can see that F(x) exceeds the allowed threshold of f . Based on Proposition 1, we
should remove the range [0, Œ±1 ) from consideration. For Œ± > Œ±3 , D(x) exceeds the allowed threshold
of d , hence, we can remove the range (Œ±3 , 1] from consideration. For Œ± = Œ±2 , both D(x) ‚â§ d and
F(x) ‚â§ f are satisfied. The color bar below the plot in Figure 2 shows different ranges of Œ±. The
green segment corresponds to the range of Œ± values for which the optimum solution of P 2 satisfies
D(x) ‚â§ d and F(x) ‚â§ f . Consequently, we can prune the infeasible intervals of Œ± by evaluating
the violation of diversity and fairness thresholds.

Algorithm 2 Tuning Œ±

Figure 2: Feasible region with respect to Œ±.

1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:

Œ±l = 0, Œ±u = 1
while |Œ±l ‚àí Œ±u | ‚â• œÑ do
l
Œ±m = Œ±u +Œ±
2
‚àó
x = argmin P 3(Œ±m )
if D(x‚àó ) ‚â§ d & F(x‚àó ) > f then
m
Œ±l = Œ±l +Œ±
2
else if D(x‚àó ) > d & F(x‚àó ) ‚â§ f then
m
Œ±u = Œ±u +Œ±
2
else if D(x‚àó ) ‚â§ d & F(x‚àó ) ‚â§ f then
return x‚àó
else
return x‚àó = ‚àÖ
end if
end while
return x‚àó

Algorithm 2 represents the proposed tuning algorithm. The algorithm starts from the middle of the
Œ± interval, Œ±m , and solves P 2 with that. Then, it splits the Œ± region into half to further prune the
region until a narrow feasible range of Œ± is obtained. In each iteration, if the diversity threshold is not
satisfied by the solution obtained from P 2 the algorithm prunes the interval larger than Œ±m . Similarly,
if the fairness threshold is not satisfied, the algorithm prunes the interval smaller than Œ±m . If neither
of the thresholds is satisfied with the solution obtained from P 2 using Œ±m , there does not exist a
feasible solution for (d , f ). Finally, when both constraints are satisfied the algorithm returns a valid
solution for P 2, which can be rounded to obtain an integer solution for P 1.
2.6

Price of Fairness

We now define the Price of Fairness (PoF) as the difference of the fairness gap of the optimal solution
of P 2 that is obtained with and without any fairness constraints. As we described in ¬ß 2, Equation (3)
is the fairness constraint that is defined for each social group. Solving P 2 with and without the
fairness constraints, we can obtain different allocation solutions and consequently different fairness
and diversity gaps. This will allow us to compare fair-diverse allocation performance with the
Diverse-only allocation to analyze the impact of fairness constraints, namely PoF.
The PoF metric assists the decision-maker on the fairness scheme to be considered, mainly, d and f .
Note that there is a trade-off between diversity and fairness gap in P 2, when the allocation scheme is
more focused on diversity, smaller f , the control parameter Œ± become close to 0. Subsequently, P 2
minimizes the diversity upper bound subject to only the capacity constraint. Comparing the solution
of such a problem with the one that has more focus on fairness, Œ± close to 1, we expect to see a larger
9

fairness gap and smaller diversity gap. In ¬ß3, we evaluate PoF of the allocation solution obtained
under different scenarios.

3

Case Study: Resource Allocation for COVID-19 Relief at Chicago

In this section, we apply the proposed fair and diverse allocation strategy to the planning of distribution of medical resources for Chicago‚Äôs COVID-19 relief. We rely on public data regarding
Chicago‚Äôs population and its demographic distribution, as well as the COVID-19 cases, deaths, and
hospitalization. The main source of data is described in Section 3.1. First, we perform a descriptive
analysis of the data to motivate the necessity of the fair and diverse distribution of medical resources.
Next, we evaluate the performance of our proposed Fair-Diverse allocation approach and identify a
reasonable trade-off parameter Œ± based on the binary search Algorithm 2. Lastly, we will calculate
the price of fairness (PoF) to highlight the role of fairness constraints in our optimization setting. All
of the analytical results, optimization models, and algorithms were implemented in Python 3.7 using
docplex and sklearn packages. The codess are available on github 2 .
3.1

Data Description

Daily Chicago COVID-19 Cases, Deaths, and Hospitalizations: The City of Chicago COVID-19
database [37] provides daily data on COVID-19 positive-tested cases, death tolls, hospitalizations,
and other individuals‚Äô attributes (e.g., age, race, gender) to track the pandemic in this city. In our
study, we primarily rely on the COVID-19 Daily Cases data to reveal the inequality among different
population subgroups. Moreover, we access these data through the SODA API (Socrata Open
Data API), which allows users to access open data resources online rather than reading from the
conventional static data files. We refer to this dataset as COVID-Cases throughout the experiment
section.
Population Dataset: The uszipcode3 Python package provides detailed geographic, demographic,
socio-economic, real estate, and education information at the state, city, and even zip code level for
different areas within the US. Based on the documentation, this package uses an up-to-date database
by having a crawler running every week to collect different data points from multiple data sources.
This dataset does not provide the intersectional population.We refer to this dataset as Pop. throughout
the experiment section.
Population Dataset: The uszipcode4 Python package provides detailed geographic, demographic,
socio-economic, real estate, and education information at the state, city, and even zip code level
for different areas within the US. Based on the documentation, this package uses an up-to-date
database by having a crawler running every week to collect different data points from multiple data
sources. This dataset does not provide the intersectional population. We refer to this dataset as Pop.
throughout the experiment section.
COVID-19 Cases, Tests, and Deaths by ZIP Code: The City of Chicago COVID-19 database [37]
also provides daily data on COVID-19 Cases, Tests, and Deaths by ZIP Code dataset 3.2. We refer to
this dataset as COVID-Zipcode throughout the experiment section.
To perform an initial descriptive analysis on the COVID distribution across different population
subgroups, we merge the Pop. with the COVID-Zipcode. We will use this dataset for descriptive
analysis provided in ¬ß3.2. We refer to this dataset as COVID-Pop.-Zipcode throughout the experiment
section.
3.2

Descriptive Analysis on COVID-19 risk factor among different population subgroups,
and different regions (zipcodes)

Utilizing the COVID-Cases dataset, in this section, we identify the contribution of each demographic
attribute to the total number of COVID-19 cases and deaths in each region of the Chicago area.
This will allow us to get an insight into the actual importance and differentiation among sensitive
populations. We perform a PCA analysis [1] and produce a Biplot, shown in Figure 3, to compare
2

https://github.com/nnezam2/Fair-Resource-Allocation/blob/master/README.md
https://uszipcode.readthedocs.io/
4
https://uszipcode.readthedocs.io/
3

10

and identify the contribution of different attributes to the COVID-19 death and case numbers. Note
that we used cross-validation to tune the number of components. To better visualize the impact of
these attributes on different regions, we implement a K-means clustering [26] method to partition
our geographical areas (Zipcodes) based on the numbers of COVID-19 deaths and cases. We cluster
them into three categories and label as high, medium, and low impacted areas, accordingly.
Our findings in this part show that areas with higher COVID-19 deaths and cases tend to have a
higher population, higher elderly population (compared with the young one), more Black Or African
American, Latinx population (compared with other races), and lower median income. Furthermore,
we believe that the revealed negative correlation between income and COVID-19 cases should raise
serious concerns, in future decision-making procedures. One justification for that is that lower-income
individuals are mostly daily paid and cannot afford living expenses if they are self-quarantined or
stop working. Consequently, the pandemic situation will inevitably hit their residential areas harder.
However, we do not have COVID-19 data based on income level. Hence, we do not consider income
in this study.
In brief, we can observe notable differences in contribution to the COVID-19 positive case and death
tolls across some specific demographic attributes(e.g, older age). This fact reveals the critical role of
a Fair-Diverse model, which considers not only the overall population but also the unrepresentative
(exposed) population in case of dealing with a scarce allocation problem.

0.6

Black-African American

High
Medium
Low

0.4
70-79yrs
80-yrs
60-69yrs
50-59yrs
0-17yrs
Female
40-49yrs
Population
Male
18-29yrs
Asian Native American
30-39yrs
Two/More
Races
Median Income
Population Density

PC2

0.2
0.0
0.2
0.4

0.4

0.2

0.0
PC1

0.2
0.4
White

0.6

Demographic Groups

Exposure rates

Female

0.058617

Male

0.060259

Age_18_29

0.052464

Black_non_latinx

0.037505

Age_30_39

0.067502

Other_race

0.097971

Age_40_49

0.078672

White_non_latinx

0.020698

Age_50_59

0.077986

Age_60_69

0.07898

Age_0_17

0.038741

Age_70_79

0.07275

Two or more race

0.088107

Age_80_

0.078768

Asian_non_latinx

0.020833

Figure 3: Biplot of demographic features using PCA Analysis Figure 4: Exposure Rates of Population Subwith Kmeans clustering of regions
groups

3.3

Estimating the Distribution of Exposed Population

Estimating the marginal distribution of the number of high-risk individuals in each demographic
group, i.e., P (E = 1|gi ), requires the data of positive-tested (infected) cases and death tolls. In this
article, we intend to propose a resource allocation plan for vaccines and treatments for the COVID-19
pandemic. However, we only have access to the count of individuals of each social group who were
infected from COVID-19, namely P (gi |E = 1). The probability P (E = 1|gi ) can be calculated
from the Bayes formula
P (gi |E = 1)P (E = 1)
P (E = 1|gi ) =
.
P (gi )
We will use P (E = 1|gi ), in the ¬ß3.4 to form the fairness constraints of the optimization problem,
Equation 3, and calculate the exposed population in each zipcode. Table 4 presents the exposure rates
for different population subgroups.
11

3.4

Fair-Diverse Allocation

To evaluate the proposed Fair-Diverse model, we construct Diverse-only, Fair-only, and equalized
importance or Œ± = 0.5 models, and compare the allocation solutions as well as the resulted fairness
and diversity gaps among them. In our terminology, Diverse-only corresponds to an allocation
that is merely based on diversity constraint, Equation 1, and is not considering any other (e.g.,
fairness) measures. Similarly, Fair-only corresponds to a model solely based on fairness constraint.
Furthermore, alpha=0.5 refers to a model that has equalized weights on Fairness and Diversity
constraints in the optimization setting. We consider 200000 units of vaccines as the available
resources to be allocated throughout the experiment section.
As mentioned in ¬ß 2.3, we propose a diversity and fairness trade-off problem as in P 2. As long as the
resource constraint is satisfied, P 2 has an optimal solution given an Œ± value. However, the optimal
solution obtained from p2 might not be feasible given the diversity and fairness requirements d and
f as mentioned in ¬ß 2.4. That is we apply our proposed binary search algorithm to discover a range
for Œ± that results in a feasible solution.
To evaluate the performance of the Algorithm 2, we will consider three different sensitive attributes(
Race, Age, and Gender) and solve each instance problem separately. We will then show the allocation
results for each problem using the four above-mentioned models and discuss Œ± ranges in detail. The
resulted allocations of each problem is sorted by population size for the top 15 area (zipcodes), and
are shown in Tables 1, 2 and 3.
The first instance problem considers Race as the sensitive attribute and the associated Fair-Diverse
model captures inequalities across different racial subgroups. The results for the top 15 populated
areas are reported in Table 1. The baseline values for f and d are derived from the alpha=0.5 model
and are equal to 0.24 and 0.007. Note that we do not use the tuning algorithm for this alpha=0.5
model. For Fair-Diverse model f and d are both set to be 0.025 to decrease the fairness gap
compared to the baseline value. The resulted tuned range for Œ± is between 0.54 and 0.85 in this
case(midpoint=0.71). Looking at Table 1, the area associated with zipcode "60639" for instance,
receives a lower number of vaccines using Diverse-only model but higher in both Œ± = 0.5 and
Fair-Diverse model (Œ± = 0.71) due to having higher total exposed population. In contrast, the
Fair-only tries to close the fairness gap to the full extent, (f = 0), and as a result delivers an extreme
allocation solution in which only a few areas (zipcodes) receive vaccines. Undoubtedly, this could
not be a desirable allocation solution under certain fairness and diversity requirements. Since the
table represents the top 15 populated areas, we cannot observe all areas with positive allocation using
Fair-only model.
Zipcode

Total population

Exposed Population

alpha=0.5

alpha tuned(0.71)

Diverse-only

Fair-only

60629

113046

5802

10329

12125

9497

0

60618

91351

3652

7002

9798

7675

0

60623

91159

4815

8330

9777

7659

0

60639

89452

5145

8174

9594

7515

70901

60647

86586

3824

7912

9287

7274

0

60617

83590

3782

7638

8966

7023

0

60608

81930

3909

6280

8788

6883

0

60625

78085

2945

5986

8031

6560

0

60634

73894

2491

5664

4491

6208

0

60620

72094

2744

6587

7733

6057

0

60641

70992

2973

6455

7614

5964

0

60614

66485

1602

5096

4040

5586

0

60657

65841

1591

5047

4001

5532

0

60640

65412

2047

5014

3975

5496

0

60609

64420

3157

5886

6909

5412

0

Table 1: Resource Allocation (Racial groups): top 15 populated areas under different models

The second instance problem considers Age as the sensitive attribute and the associated Fair-Diverse
model captures inequalities across different age groups. The results for the top 15 populated areas
are reported in Table 2. The baseline values for f and d are derived from the alpha=0.5 problem
and are equal to 0.012 and 0. Next, we run the binary search algorithm to tune the Œ± value and find a
feasible solution for Fair-Diverse model. In this case, f and d are both set to be 0.003. The resulted
12

tuned range for Œ± is between 0.57 and 1 (midpoint=0.78). As mentioned previously, the Diverse-only
model assigns vaccines to areas only based on the total population, and the Fair-only model delivers
an extreme allocation solution in which only a few areas (zipcodes) receive vaccines. Therefore,
none of these models are capable of delivering a fair and diverse allocation solution. Note that in
this instance problem, Œ± = 0.5 model is not doing any better than the Diverse-only model since the
weight on the fairness component is not adequate to change the results (diversity-gap is dominant).
This result can further reveal the necessity of the proposed tuning algorithm.
Zipcode

Total population

Exposed Population

alpha=0.5

alpha tuned(0.78)

Diverse-only

Fair-only

60629

113046

6367

9204

8989

9204

0

60618

91351

5478

7672

7492

7672

0

60623

91159

5084

7422

7249

7422

70300

60639

89452

5127

7367

7195

7367

0

60647

86586

5121

7312

7141

7312

0

60617

83590

5007

6931

7093

6931

0

60608

81930

4872

6904

6743

6904

0

60625

78085

4698

6569

6415

6569

0

60634

73894

4610

6219

6365

6219

0

60620

72094

4404

6009

6150

6009

0

60641

70992

4302

5955

5816

5955

0

60614

66485

4028

5735

5604

5735

0

60657

65841

4034

5730

5864

5730

0

60640

65412

4200

5644

5776

5644

0

60609

64420

3651

5264

5141

5264

0

Table 2: Resource Allocation (Age groups): top 15 populated areas under different models

Finally, a noteworthy instance occurs when we consider gender as the sensitive attribute and the
Fair-Diverse model attempts to eliminate the unfairness between male and female subgroups. The
results for the top 15 populated areas are reported in Table 3. The baseline values for f and d derived
from the alpha=0.5 problem and are both close to zero ( 6.04e-05 and 0). It is worth mentioning that
this is because of the similar gender population distribution across different regions. Consequently,
the fairness and diversity requirements can be satisfied even with Diverse-only model. We can still run
the binary search algorithm to tune the Œ± value and find a feasible solution for Fair-Diverse model by
closing the fairness gap further. To do this, the f and d values in Fair-Diverse model should be set to
0 and 0.1. The resulted tuned range or Œ± is between 0.92 and 1 in this case (midpoint=0.96). Looking
at Table 3 and exposure rates (shown in Table 4), we notice that, in this specific instance problem,
the exposed population size is, in actuality, aligned with the total population size in different areas. In
other words, highly populated areas tend to have higher exposed populations as well. Therefore, the
resulted allocations from Diverse-only, Œ± = 0.5, and Fair-Diverse models are very close and even
equal in some cases.
Zipcode

Total population

Exposed Population

alpha=0.5

alpha tuned(0.96)

Diverse-only

Fair-only

60629

113046

5802

9520

9529

9520

0

60618

91351

3651

7695

7703

7695

0

60623

91159

4815

7697

7705

7697

0

60639

89452

5145

7555

7563

7555

0

60647

86586

3824

7295

7302

7295

0

60617

83590

3782

7033

7026

7033

0

60608

81930

3909

6914

6921

6914

79366

60625

78085

2944

6573

6579

6573

0

60634

73894

2490

6209

6203

6209

0

60620

72094

2743

6035

6029

6035

0

60641

70992

2972

5989

5995

5989

0

60614

66485

1602

5567

5562

5567

0

60657

65841

1591

5515

5521

5515

0

60640

65412

2047

5498

5504

5498

0

60609

64420

3156

5424

5430

5424

0

Table 3: Resource Allocation (Gender groups): top 15 populated areas under different models

13

Figures 5 and 6 present the results for the top 15 populated regions in the Chicago City for racial
and age instance problems. Note that in both instance problems, the total population equals the
summation of all associated groups (e.g Age groups) due to having unknown labels in the data. In
Figure 5, for example, "60614" and "60634" regions receive less vaccines both under Fair-Diverse
and Œ± = 0.5 models due to having higher exposed population, Table 1. The Diverse-only does not
consider the exposed population, therefore, the associated allocations are higher for these regions.
Besides, the allocation obtained from the tuned range of Œ± is significantly different from the allocation
obtained with the Œ± = 0.5 model since the latter does not satisfy the fairness requirement f .
Moving to another instance problem, Figure 6 represents the allocation results for the age instance
problem. Based on the plot, we can notice that the Œ± = 0.5 and Diverse-only allocation solutions
overlap.
This can be justified by the fact that the 50% emphasis on fairness is not sufficient to close the age
subgroups disparities, and it requires a higher Œ± value as we obtained through the tuning algorithm.
That being said, the tuned Œ± value, in this case, is 0.78, which is substantially higher than 0.5.
For example, "60614" and "60609" regions receive less vaccines using Fair-Diverse model with Œ±
tuning since they have relatively lower exposed population, Table 2. For observing more interactive
visualization tools, please check our newly created web application on the Chicago City datasets
using Rshiney5 .

12000
11000

Diverse-only
alpha=0.5
Fair-Diverse(tuned alpha)

9000
8500
8000
Total Allocations

Total Allocations

10000

Diverse-only
alpha=0.5
Fair-Diverse(tuned alpha)

9000

7500

8000

7000

7000

6500

6000

6000

5000

5500

4000

60
6
60 29
6
60 18
6
60 23
6
60 39
6
60 47
6
60 17
6
60 08
6
60 25
6
60 34
6
60 20
6
60 41
6
60 14
6
60 57
6
60 40
60
9

60
6
60 29
6
60 18
6
60 23
6
60 39
6
60 47
6
60 17
6
60 08
6
60 25
6
60 34
6
60 20
6
60 41
6
60 14
6
60 57
6
60 40
60
9

5000
Zipcodes

Figure 5: Resource Allocation (Racial groups):
top 15 populated areas

Zipcodes

Figure 6: Resource Allocation (Age groups):
top 15 populated areas

As we discussed in ¬ß 2.4, the allocation solution that is obtained from P 2 does not necessarily satisfy
the fairness and diversity requirements (under any Œ± value). To demonstrate the performance of the
tuning algorithm, which always returns a range for Œ± under which the optimal solution of P 2 is
feasible, we now study the impact of f and d on the optimal solution under different models.
The plots in 7 are based on the racial instance problem. These figures reveal that under any fairness
and diversity requirements (given f and d values) the Œ± tuning algorithm returns a feasible solution
for Fair-Diverse model. Note that, this is not the case for other models (Fair-only, Diverse-only and
alpha=0.5) as it can be observed from the Figures 7(a) and 7(b). In other words, the optimal solutions
obtained from the Diverse-only and Œ± = 0.5 models does not satisfy the fairness requirement
(f ‚â§ 0.03 and f ‚â§ 0.2 ), and the solution obtained from the Fair-only model fails to satisfy
the diversity requirement (d ‚â§ 0.3) in Figures 7(a) and 7(b). However, if we relax the fairness
requirement to f ‚â§ 0.3, Figure 7(c), the Œ± = 0.5 model can indeed achieve a feasible solution.
It is worth mentioning that the diversity requirement is easier to achieve compared to the fairness
requirement due to the larger inherent disparities in exposed population.

5

https://nazanin.shinyapps.io/Fair_Resource_Allocation/

14

Diversity-Fairness Tradeoff

Diversity-Fairness Tradeoff
1.0 Fair-only

0.8

0.8

0.8

f = 0.03

0.6
0.4

d = 0.3
0.2 Fair-Diverse
( = 0.71)
= 0.5 Diverse-only
0.0
0.0 0.2 0.4 0.6 0.8 1.0
Maximum Fairness gap

Maximum Diversity gap

1.0 Fair-only
Maximum Diversity gap

Maximum Diversity gap

Diversity-Fairness Tradeoff
1.0 Fair-only

f = 0.2

0.6
0.4
0.2
0.0

d = 0.3

Fair-Diverse
( = 0.625)
= 0.5 Diverse-only
0.0

(a)

0.4

d = 0.3

0.2
0.0

0.2 0.4 0.6 0.8 1.0
Maximum Fairness gap

f = 0.3

0.6

= 0.5 Diverse-only
0.0

0.2 0.4 0.6 0.8 1.0
Maximum Fairness gap

(b)

(c)

Figure 7: Impact of the f and d on the diversity-fairness trade-off

3.5

Price of Fairness

In this section, we will compare the fairness and diversity gaps under different models and population
subgroups to discuss the price of fairness (PoF). The results are obtained based on the aforementioned
racial group instance problem and under tuned Œ± value (0.71).
Firstly, Figure 8 reveals that the Fair-Diverse model reduces fairness and diversity gaps more
compared to Diverse-only and Fair-only models. Although the Diverse-only model eliminates the
diversity gap, it fails to decrease the fairness gap. Similarly, the Fair-only model eliminates the
fairness gap but it fails to decrease the diversity gap. Moreover, Figure 9 shows some considerable
reduction in the gaps across different population subgroups (racial groups) using the Fair-Diverse
model. The comparison between the results with the Diverse-only and the uniform allocation solution
reveals the necessity of the Fair-Diverse model in closing the gaps, and therefore, reducing the
disparities across different population subgroups.
Lastly, Figure 10 illustrates the trade-off between fairness and diversity gaps considering different
Œ± values. Note that the Œ± values represent the midpoint of the feasible range. We can observe that
increasing the Œ± value, which is the weight on the fairness component in P 2, decreases the fairness
gap as expected. However, the diversity gap will increase due to the fairness-diversity trade-off.
Finally, as discussed in ¬ß 2.6, the Price of Fairness (PoF) can be evaluated using the difference of the
fairness gap from the optimal solution of P2 that is obtained with and without any fairness constraints.
POF could be defined as the fraction of the fairness gap that is obtained from the (Diverse-only)
allocation to the allocation solution based on the Fair-Diverse model. If an allocation solution
decreases the fairness gap more than the Fair-Diverse model, the POF is less than one. Otherwise,
PoF is > 1 and we will need to find a balance between the fairness and diversity objectives to decide
on which allocation to choose. In the case of the Racial instance problem with Œ± = 0.71, the PoF
equals 0.4419
0.025 = 17.67 which is significantly larger than 1.

0.6
0.4
0.2
0.0 Diverse-only

Fair-only

Fair-Diverse

1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0

0.25

Uniform
Diverse-only
Fair-Diverse

0.15
0.10
0.05
0.00

e

Whit

k

Blac

n

Asia

r
Othe

Race

Two

s
Race

Diversity-Gap
Fairness-Gap

0.20
Maximum Gaps

Fairness gap
Diversity gap

Maximum Fairness Gaps

Maximum Gaps

0.8

0.50

0.55

0.60
0.65
Alpha Values

0.70

Figure 8: Diversity and Fairness Figure 9: Fairness gaps across dif- Figure 10: Fairness and Diversity gaps
based on different Œ± values
ferent population subgroups
gaps in different models

4

Discussion

As stated in ¬ß2, the COVID-19 exposure rate for each intersectional group denotes by P (e|gi ). To
estimate these probabilities for intersectional population subgroups (e.g., <black,female,age30-39>),
15

we can apply a Poisson regression model [13], which is a widely used methodology when the response
variable is a count. While COVID-19 exposure rates for intersectional groups could be estimated
from a Poisson regression model, we do not have the intersectional population data for each Zipcode,
denotes by Sij in ¬ß2. Furthermore, estimating the intersectional population size could not be an
appropriate implementation approach. Regarding the aforementioned data limitation issue, we solved
the allocation problem for age, race, and gender as the sensitive attributes separately in ¬ß3.4. However,
our model is able to return a fair-diverse allocation using the intersectional subgroups, given that
the real intersectional population size in each area is available. This will be part of our future work.
Moreover, we only considered single treatment, mainly vaccination, however, the proposed approach
can be generalized to incorporate multiple treatments. Our proposed fair-diverse allocation can be
utilized at different stages of pandemic considering the updated exposure ratio.

5

Conclusion

In this paper, we propose the idea of fairness in scarce resource allocation problems (e.g, vaccine
distribution) in terms of disparities across various population subgroups in different regions. To do so,
we consider diversity and fairness components to design a Fair-Diverse allocation. We first formulate
a general multi-objective (MO) problem P 1, and propose the weighted sum method together with
the LP relaxation to simplify it to P 2. We then solve the LP-relaxed problem, P 2, based on the
fairness and diversity requirements as described in ¬ß 2.4. For this purpose, we propose a binary search
approach, Algorithm 2, to find an optimal range for the trade-off parameter Œ± in P 2 such that the
obtained solution is feasible.
Moreover, we have empirically analyzed our proposed methodologies in ¬ß3 using COVID-19 datasets.
We designed three instance problems based on different demographic attributes, race, age, and gender.
We then implemented our fair-diverse model and compared it with other models (Diverse-only,
Fair-only, and Œ± = 0.5) to investigate the fairness criteria in the solution and highlight the necessity
behind our approach. We have also discussed the fairness and diversity requirements, d and f ,
and compared the Fair-Diverse allocation with other allocation solutions under different thresholds.
Lastly, we have examined the price of fairness based on the associated gaps across different models.
In brief, our empirical results reveal the paramount role of fairness criteria in decision-making
problems involving scarce resource allocation (e.g, a vaccine allocation ). While certain minorities
and population groups are more vulnerable to the COVID-19 virus, a Diverse-only (population-based)
vaccine allocation can lead to higher fatality rates by neglecting the vulnerability of various population
subgroups. We require to ensure a fair and diverse vaccine allocation to induce lower mortality rates
across different regions. That is, we aim to find a decent balance between the diversity and fairness
measures in different geographical regions and allocate the resources accordingly.

6

Acknowledgements

L. Kang is partially supported by the National Science Foundation grant DMS-1916467.

16

References
[1] H. Abdi and L. J. Williams. Principal component analysis. Wiley interdisciplinary reviews:
computational statistics, 2(4):433‚Äì459, 2010.
[2] S. Atlas. The demographic statistical atlas of the united states. https://statisticalatlas.
com/place/Illinois/Chicago/Race-and-Ethnicity, 2018. Accessed: 10-05-2020.
[3] S. Barocas, M. Hardt, and A. Narayanan. Fairness and machine learning: Limitations and
opportunities. fairmlbook.org, 2019.
[4] S. Barocas and A. D. Selbst. Big data‚Äôs disparate impact. Calif. L. Rev., 104:671, 2016.
[5] S. K. Baruah, N. K. Cohen, C. G. Plaxton, and D. A. Varvel. Proportionate progress: A notion
of fairness in resource allocation. Algorithmica, 15(6):600‚Äì625, 1996.
[6] N. G. Becker and D. N. Starczak. Optimal vaccination strategies for a community of households.
Mathematical Biosciences, 139(2):117‚Äì132, 1997.
[7] D. Bertsimas, V. F. Farias, and N. Trichakis. The price of fairness. Operations research,
59(1):17‚Äì31, 2011.
[8] D. Bertsimas, V. F. Farias, and N. Trichakis. On the efficiency-fairness trade-off. Management
Science, 58(12):2234‚Äì2250, 2012.
[9] D. Bertsimas, V. F. Farias, and N. Trichakis. Fairness, efficiency, and flexibility in organ
allocation for kidney transplantation. Operations Research, 61(1):73‚Äì87, 2013.
[10] L. E. Bolton, L. Warlop, and J. W. Alba. Consumer perceptions of price (un) fairness. Journal
of consumer research, 29(4):474‚Äì491, 2003.
[11] J. L. Bower. Managing the resource allocation process: A study of corporate planning and
investment. Irwin Homewood, 1972.
[12] D.-M. Chiu and R. Jain. Analysis of the increase and decrease algorithms for congestion
avoidance in computer networks. Computer Networks and ISDN systems, 17(1):1‚Äì14, 1989.
[13] P. Consul and F. Famoye. Generalized poisson regression model. Communications in StatisticsTheory and Methods, 21(1):89‚Äì109, 1992.
[14] S. Corbett-Davies, E. Pierson, A. Feller, S. Goel, and A. Huq. Algorithmic decision making
and the cost of fairness. In Proceedings of the 23rd acm sigkdd international conference on
knowledge discovery and data mining, pages 797‚Äì806, 2017.
[15] A. R. Cross.
Draft landscape of covid-19 candidate vaccines.
https://www.
redcrossblood.org/donate-blood/how-to-donate/how-blood-donations-help/
blood-needs-blood-supply.html, 2020. Accessed: 04-15-2020.
[16] A. Demers, S. Keshav, and S. Shenker. Analysis and simulation of a fair queueing algorithm.
ACM SIGCOMM Computer Communication Review, 19(4):1‚Äì12, 1989.
[17] K. Donahue and J. Kleinberg. Fairness and utilization in allocating resources with uncertain
demand. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency,
pages 658‚Äì668, 2020.
[18] R. S. Dubey, G. Laguzzi, and F. Ruscitti. On the representation and construction of equitable
social welfare orders. Available at SSRN 3524071, 2020.
[19] C. Dwork, M. Hardt, T. Pitassi, O. Reingold, and R. Zemel. Fairness through awareness. In
Proceedings of the 3rd innovations in theoretical computer science conference, pages 214‚Äì226,
2012.
[20] H. Elzayn, S. Jabbari, C. Jung, M. Kearns, S. Neel, A. Roth, and Z. Schutzman. Fair algorithms for learning in allocation problems. In Proceedings of the Conference on Fairness,
Accountability, and Transparency, pages 170‚Äì179, 2019.
[21] E. J. Emanuel, G. Persad, R. Upshur, B. Thome, M. Parker, A. Glickman, C. Zhang, C. Boyle,
M. Smith, and J. P. Phillips. Fair allocation of scarce medical resources in the time of covid-19,
2020.
[22] W.-H. Feng, Z. Lou, N. Kong, and H. Wan. A multiobjective stochastic genetic algorithm
for the pareto-optimal prioritization scheme design of real-time healthcare resource allocation.
Operations Research for Health Care, 15:32‚Äì42, 2017.
17

[23] F. Fiedrich, F. Gehbauer, and U. Rickers. Optimized resource allocation for emergency response
after earthquake disasters. Safety science, 35(1-3):41‚Äì57, 2000.
[24] A. C. Harberger. Monopoly and resource allocation. In Essential readings in economics, pages
77‚Äì90. Springer, 1995.
[25] M. Hardt, E. Price, and N. Srebro. Equality of opportunity in supervised learning. In Advances
in neural information processing systems, pages 3315‚Äì3323, 2016.
[26] J. A. Hartigan and M. A. Wong. Algorithm as 136: A k-means clustering algorithm. Journal of
the royal statistical society. series c (applied statistics), 28(1):100‚Äì108, 1979.
[27] T.-Y. Ho, S. Liu, and Z. B. Zabinsky. A branch and bound algorithm for dynamic resource
allocation in population disease management. Operations Research Letters, 47(6):579‚Äì586,
2019.
[28] S. Huaizhou, R. V. Prasad, E. Onur, and I. Niemegeers. Fairness in wireless networks: Issues,
measures and challenges. IEEE Communications Surveys & Tutorials, 16(1):5‚Äì24, 2013.
[29] J. Jaffe. Bottleneck flow control. IEEE Transactions on Communications, 29(7):954‚Äì962, 1981.
[30] F. P. Kelly, A. K. Maulloo, and D. K. Tan. Rate control for communication networks:
shadow prices, proportional fairness and stability. Journal of the Operational Research society,
49(3):237‚Äì252, 1998.
[31] L. M. Koonin, S. Pillai, E. B. Kahn, D. Moulia, and A. Patel. Strategies to inform allocation of
stockpiled ventilators to healthcare facilities during a pandemic. Health security, 18(2):69‚Äì74,
2020.
[32] T. Lan, D. Kao, M. Chiang, and A. Sabharwal. An axiomatic theory of fairness in network
resource allocation. IEEE, 2010.
[33] T. T. Le, Z. Andreadakis, A. Kumar, R. G. Roman, S. Tollefsen, M. Saville, and S. Mayhew.
The covid-19 vaccine development landscape. Nat Rev Drug Discov, 19(5):305‚Äì306, 2020.
[34] K. Lum and W. Isaac. To predict and serve? Significance, 13(5):14‚Äì19, 2016.
[35] L. Matrajt, M. E. Halloran, and I. M. Longini Jr. Optimal vaccine allocation for the early
mitigation of pandemic influenza. PLoS Comput Biol, 9(3):e1002964, 2013.
[36] S. Nesbitt and R. E. Palomarez. increasing awareness and education on health disparities for
health care providers. Ethnicity & disease, 26(2):181, 2016.
[37] C. of Chicago. City of chicago data portal. https://data.cityofchicago.org/browse?
tags=covid-19&sortBy=relevance, 2020. Accessed: 09-15-2020.
[38] W. Ogryczak. Multicriteria models for fair resource allocation. Control and Cybernetics,
36(2):303‚Äì332, 2007.
[39] W. Ogryczak, M. Pioro, and A. Tomaszewski. Telecommunications network design and maxmin optimization problem. Journal of telecommunications and information technology, pages
43‚Äì56, 2005.
[40] C. D. Portal. Covid-19 daily cases, deaths, and hospitalizations, 2020.
[41] B. Singh. Fairness criteria for allocating scarce resources. Optimization Letters, pages 1‚Äì9,
2020.
[42] M. W. Tanner, L. Sattenspiel, and L. Ntaimo. Finding optimal vaccination strategies under
parameter uncertainty using stochastic programming. Mathematical biosciences, 215(2):144‚Äì
151, 2008.
[43] E. Tayfur and K. Taaffe. A model for allocating resources during hospital evacuations. Computers & Industrial Engineering, 57(4):1313‚Äì1323, 2009.
[44] M. Verweij. Moral principles for allocating scarce medical resources in an influenza pandemic.
Journal of Bioethical Inquiry, 6(2):159‚Äì169, 2009.
[45] S. Yao and B. Huang. Beyond parity: Fairness objectives for collaborative filtering. In Advances
in Neural Information Processing Systems, pages 2921‚Äì2930, 2017.
[46] H. Yarmand, J. S. Ivy, B. Denton, and A. L. Lloyd. Optimal two-phase vaccine allocation to
geographically different regions under uncertainty. European Journal of Operational Research,
233(1):208‚Äì219, 2014.
18

[47] M. Zehlike, F. Bonchi, C. Castillo, S. Hajian, M. Megahed, and R. Baeza-Yates. Fa* ir: A fair
top-k ranking algorithm. In Proceedings of the 2017 ACM on Conference on Information and
Knowledge Management, pages 1569‚Äì1578, 2017.
[48] I. ≈ΩliobaiteÃá. Measuring discrimination in algorithmic decision making. DATA MIN KNOWL
DISC, 31(4):1060‚Äì1089, 2017.

19

APPENDIX
A

Proof of Proposition 1

Proposition 2. Let be X 0 = {x|D(x) < d , F(x) < f ,

P

j‚ààM

xj = b, xj ‚â• 0}:

1. If X 0 6= ‚àÖ: given x‚àó ‚àà X 0 , ‚àÉŒ±‚àó such that x‚àó is an optimal solution of P 2.
2. If 6 ‚àÉ Œ±‚àó such that x‚àó is an optimal solution of P 2 that satisfies both conditions D(x) < d
and F(x) < f , then X 0 = ‚àÖ.
Proof. We first argue that the feasibility problem is equivalent to the following optimization model:
P0 :
min D(x)
s.t.
F(x) = 
Dj+ (x) ‚â§ D(x),

‚àÄj ‚àà M

Dj‚àí (x)
Fi+ (x)
Fi‚àí (x)

‚â• D(x),

‚àÄj ‚àà M

‚â• F(x),

‚àÄi ‚àà I

‚â§ F(x),

‚àÄi ‚àà I

X

xj = b

j‚ààM

xj ‚â• 0,

‚àÄj ‚àà M

Consider  ‚àà [0, F ]. Let x‚àó be the optimal solution of P 0 . Hence, F(x‚àó ) =  ‚â§ F satisfies the
fairness constraint. Now, if D(x‚àó ) ‚â• D , we conclude that for  there does not exist a feasible
solution that satisfies the diversity constraint. Otherwise, that feasible solution would minimize P 0 .
Introducing a Lagrangian multiplier Œª, we now define the dual Lagrangian transformation of P 0 to
be:
P 00 :
min D(x) + Œª(F(x) ‚àí )
s.t.
Dj+ (x) ‚â§ D(x),

‚àÄj ‚àà M

Dj‚àí (x)
Fi+ (x)
Fi‚àí (x)

‚â• D(x),

‚àÄj ‚àà M

‚â• F(x),

‚àÄi ‚àà I

‚â§ F(x),

‚àÄi ‚àà I

X

xj = b

j‚ààM

xj ‚â• 0,

‚àÄj ‚àà M

Now, we argue that given x‚àó ‚àà X 0 there exists an Œ±‚àó such that x‚àó is an optimum of P 2. Let Œª‚àó be
the multiplier when x‚àó is an optimum of P 00 , then ‚àÄx00 6= x‚àó :
D(x‚àó ) + Œª‚àó (F(x‚àó ) ‚àí F ) ‚â§ D(x00 ) + Œª‚àó (F(x00 ) ‚àí F )
=‚áí D(x‚àó ) + Œª‚àó F(x‚àó ) ‚àí Œª‚àó F ‚â§ D(x00 ) + Œª‚àó F(x00 ) ‚àí Œª‚àó F
=‚áí D(x‚àó ) + Œª‚àó F(x‚àó ) ‚â§ D(x00 ) + Œª‚àó F(x00 )
Thus, x‚àó is an optimum of P 2 where Œª‚àó = (1‚àíŒ±)
Œ± .
On the other hand, if ‚àÉŒ±‚àó under which x‚àó is optimal of P 2, and D(x‚àó ) < d and F(x‚àó ) < f , then
x‚àó ‚àà X 0 and X 0 6= ‚àÖ. This means if such Œ±‚àó does not exist, there is no feasible solution under d and
f .
20

B

Proof of Proposition 2

Proposition 2. Let x‚àó1 and x‚àó2 be optimum solutions of P 2 given Œ±1 and Œ±2 , respectively. It can be
shown that if Œ±1 ‚â§ Œ±2 , then F(x‚àó2 ) ‚â§ F(x‚àó1 ) and D(x‚àó1 ) ‚â§ D(x‚àó2 ).
Proof. Let Œ≤ =

Œ±
(1‚àíŒ±) .

Given x‚àó1 and x‚àó2 corresponding to Œ≤1 and Œ≤2 , where Œ≤2 < Œ≤1 :
D(x‚àó1 ) + Œ≤1 F(x‚àó1 ) ‚â§ D(x‚àó2 ) + Œ≤1 F(x‚àó2 )

D(x‚àó2 ) + Œ≤2 F(x‚àó2 ) ‚â§ D(x‚àó1 ) + Œ≤2 F(x‚àó1 )
Adding the above Equations, we will have:
Œ≤1 F(x‚àó1 ) + Œ≤2 F(x‚àó2 ) ‚â§ Œ≤1 F(x‚àó2 ) + Œ≤2 F(x‚àó1 )
=‚áí (Œ≤2 ‚àí Œ≤1 )(F(x‚àó2 ) ‚àí F(x‚àó1 )) ‚â§ 0
which implies F(x‚àó2 ) ‚â§ F(x‚àó1 ). The monotonicity proof for D(x) is the same with Œ≤ =
Œ±2 < Œ±1 then D(x‚àó1 ) > D(x‚àó2 ).

21

(1‚àíŒ±)
Œ± .

If

