medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 1 of 14

RESEARCH

CovidMulti-Net: A Parallel-Dilated Multi Scale Feature
Fusion Architecture for the Identification of COVID-19
Cases from Chest X-ray Images
Md. Saikat Islam Khan1, Anichur Rahman1,2, Md. Razaul Karim1, Nasima Islam Bithi1, Shahab
S. Band3*, Abdollah Dehzangi4,5 and Hamid Alinejad-Rokny* 6,7,8
1Department of Computer Science and Engineering, Mawlana Bhashani Science and Technology University,
Tangail, Bangladesh.
2Department of Computer Science and Engineering, National Institute of Textile Engineering and Research
(NITER), Constituent Institute of the University of Dhaka, Savar, Dhaka, Bangladesh.
3 Future Technology Research Center, College of Future, National Yunlin University of Science and Technology,
123 University Road, Section 3, Douliou, Yunlin 64002, Taiwan
4 Department of Computer Science, Rutgers University, Camden, NJ, 08102, USA
5 Center for Computational and Integrative Biology, Rutgers University, Camden, NJ, 08102, USA
6 BioMedical Machine Learning Lab, The Graduate School of Biomedical Engineering, UNSW Sydney, Sydney,
NSW, 2052‚Äû Australia
7 Core Member of UNSW Data Science Hub, The University of New South Wales (UNSW Sydney), Sydney,
NSW, 2052, Australia
8 Health Data Analytics Program Leader, AI-enabled Processes (AIP) Research Centre, Macquarie University,
Sydney, 2109, Australia
*To

whom correspondence should be addressed. E-mail: S.S.B (shamshirbands@yuntech.edu.tw)
H.A.R (h.alinejad@unsw.edu.au)

Abstract
The COVID-19 pandemic is an emerging respiratory infectious disease, having a significant impact on the health
and life of many people around the world. Therefore, early identification of COVID-19 patients is the fastest way
to restrain the spread of the pandemic. However, as the number of cases grows at an alarming pace, most
developing countries are now facing a shortage of medical resources and testing kits. Besides, using testing
kits to detect COVID-19 cases is a time-consuming, expensive, and cumbersome procedure. Faced with these
obstacles, most physicians, researchers, and engineers have advocated for the advancement of computeraided deep learning models to assist healthcare professionals in quickly and inexpensively recognize COVID19 cases from chest X-ray (CXR) images. With this motivation, this paper proposes a ‚ÄúCovidMulti-Net‚Äù
architecture based on the transfer learning concept to classify COVID-19 cases from normal and other
pneumonia cases using three publicly available datasets that include 1341, 1341, and 446 CXR images from
healthy samples and 902, 1564, and 1193 CXR images infected with Viral Pneumonia, Bacterial Pneumonia,
and COVID-19 diseases. In the proposed framework, features from CXR images are extracted using three wellknown pre-trained models, including DenseNet-169, ResNet-50, and VGG-19. The extracted features are then
fed into a concatenate layer, making a robust hybrid model. The proposed framework achieved a classification
accuracy of 99.4%, 95.2%, and 94.8% for 2-Class, 3-Class, and 4-Class datasets, exceeding all the other stateof- the-art models. These results suggest that the ‚ÄúCovidMulti-Net‚Äù framework‚Äôs ability to discriminate individuals
with COVID-19 infection from healthy ones and provides the opportunity to be used as a diagnostic model in
clinics and hospitals. We also made all the materials publicly accessible for the research community at:
https://github.com/saikat15010/CovidMulti-Net-Architecture.git.
Keywords: COVID-19; DenseNet-169; ResNet-50; VGG-19; Feature Fusion; Chest X-ray Images,
Biomedical machine learning.

NOTE: This preprint reports new research that has not been certified by peer review and should not be used to guide clinical practice.

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 2 of 14

Introduction
Computational tools have been extensively utilized to tackle challenging problems in the field of medical science
[1]. They have been demonstrated as fast and cost-effective alternative to experimental methods. It is very
common to face newer cases of medical complexities over the period of time and numerous experts work
seamlessly for days to analyze the problems and find a solution to them. Some disease could be so spreadable
that many people lost their lives before our doctors and medical engineers came to a stable outcome. For
instance, COVID-19 is the very recent disease that took a lot of lives within just a few months all over the world.
The procedure of identifying this viral disease is complex and time consuming. People in Bangladesh (for
example) need to wait at least one week to get the report of the COVID-19 test. Apart from this, sample collection
process is also problematic and complex. Speeding up the virus can dramatically speed up the treatment and
prevention processes. Researchers from all over the world invented different mechanism to detect the virus but
still people are facing difficulties.
Currently, chest X-ray (CXR) is a medical imaging technique that helps doctors finding the COVID-19 cases more
quickly. As COVID-19 attacks the lungs, the effect could be on the screen of the chest X-ray images. However,
it requires expertise and time to test the CXR images manually. Nowadays, Computer-Aided Diagnosis (CAD)
system has been designed for detecting COVID-19 cases early without the need for human intervention. In
medical imaging technology, the CAD system has improved dramatically due to machine learning (ML) and deep
learning (DL) applications. Such techniques lead to achieving high accuracy in terms of detecting COVID-19
cases. However, the prediction performance of this task using classical machine learning methods has remained
limited. On the other hands, the deep learning framework has been introduced to address the shortcomings of
traditional machine learning techniques by automatically performing the task of feature extraction in a fully endto-end fashion and learn the input images‚Äô holistic features from low to high level for classification purposes [2]. In
addition, by adding transfer learning capabilities, weights of different pre-trained deep learning models which were
previously trained on the ImageNet database, can be transferred to perform new relevant classification tasks [3].
Since these models are deeper than the conventional approaches and use more dynamic relations among the
alternating layers to detect more complex features, they can achieve significant performance [4].
In this study, we present an automated fast screening of COVID-19 detection system using a ‚ÄúCovidMulti-Net‚Äù
framework. This framework consists of three CNN pre-trained models including DenseNet-169, ResNet-50, and
VGG-19, where each model is used for extracting features from the CXR images. We use a concatenate layer for
combining all the extracted features, to build a robust parallel robust model. Finally, we evaluate the performance of
our ‚ÄúCovidMulti-Net‚Äù framework on three publicly accessible datasets, where we have obtained significant results.
The main contributions of this research work are summarized as follows:
‚Ä¢ The proposed ‚ÄúCovidMulti-Net‚Äù is based on hybrid feature extraction technique that is developed through
combining multiple deep CNN pre-trained models.
‚Ä¢ The ‚ÄúCovidMulti-Net‚Äù framework does not require any segmentation‚Äìbased feature extraction technique.
‚Ä¢ The ‚ÄúCovidMulti-Net‚Äù framework does not misclassify any CXR image of the COVID-19.
Organization: The rest of this article is organized ad follow. The literature overview is presented in Section II.
After that, the proposed ‚ÄúCovidMulti-Net‚Äù framework is presented in detail, along with data pre-processing and
data augmentation strategies in Section III. The performance of the proposed framework is thoroughly discussed
in section IV. In Section V, the comparative outcome analysis with future direction is shown. Finally, the conclusion
of this work is presented in Section VI.

Literature Overviews
Recently, studies have proposed different machine learning and deep learning models for detecting COVID-19
diseases. In this section, a summary of such mod el is presented. Early on, Chowdhury et al. [5] applied their
method to publicly available chest X-ray images to identify COVID-19 based on CNN. To build their model, they
extracted the crucial features from the input in a parallel manner. They achieved 96.58% prediction accuracy for
three target classes (COVID-19 cases, healthy individuals, and the viral Pneumonia) on a dataset consisting of
2905. Later on, Sekeroglu et al. [6], implemented different machine learning models including, transfer learning,

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 3 of 14

conventional models, and CNN to identify COVID-19 infected patients where the CNN model perform better with
98.50% prediction accuracy. However, they were unable to address the imbalance dataset issue. In a similar study,
Elaziz et al. [7], proposed an ensemble of multi-CNN, Bayesnet and CFS to differentiate COVID-19 and nonCOVID-19 images extracted from CT scanners. For feature extraction purpose, they used Fractional Multichannel
Exponent Moments (FMEM), and Manta-Ray Foraging Optimization. At the same time, Hu et al. [8], proposed a
system using supervised deep learning methods that maintain a weekly detection protocol in order to classify cases
of COVID-19 efficiently. More recently, Sakib et al. [9], proposed a new method called DL-CRC using data
augmentation strategy to enhance the detection performance up to 40% (from 54.55% to 93.94%). Later on,
Elgendi et al. [10] proposed a DarkNet-19 deep learning model to tackle this problem with promising performance. At
the same time, Heidari et al. [11], developed a CNN model to identify COVID-19 Cases from Chest X-ray Images.
In this model the preprocessing performed by histogram and bilateral low pass filter and enhances the prediction
performance to 94.5. Similarly, Minaee et al. [12], proposed a new CNN model and tested their model on over
3000 images to get a sensitivity rate of 98%. In another work by Nishio et al. a Deep neural network strategy has
been used in which VGG16 was performed to construct the model. They also used a transfer learning method in
which the first 10 layers were devoted to applying transfer learning with an accuracy level of over 83% [13]. After that
Ismael et al. [14] used CNN model to extract features from the images of chest X-ray and obtained the most improved
accuracy of 94.7% with Restnet50 and linear kernel SVM classifier. To resolve the scarcity of COVID-19 chest Xray images, Loey et al. [15] gathered all available images of Covid patients and produced data sets using the
Generative Adversarial Networks (GAN) process.

Figure 1: Proposed ‚ÄúCovidMulti-Net‚Äù framework for fast detection of COVID-19 cases.
Furthermore, the detection technique is divided further, with the key component being the covid X-ray image, and
the other images being included or omitted to verify the accuracy level. Later on, Jain et al. [16] proposed another
CNN based deep learning method for the detection of COVID-19 from the chest X-ray images. To train this model,
they used above six thousand image data and divided the dataset into training (above five thousand) and testing

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 4 of 14

dataset (almost one thousand). This model produced a top accuracy level of 97.97%. In a similar study, Abraham et
al., used a combination of multi-level CNN and CFS mechanism to determine out the features from the image
dataset and also used Bayesnet for the classification purpose. They reported 97% accuracy for a dataset with
71 images. However, as the number of samples increased, their prediction performance rapidly dropped [17].
More recently, Goel et al. [18] proposed a new model called OptCoNet that was developed using CNN. The model
was tested against different classification mechanisms, and the accuracy rate was improved to 97.78%. In another
work [19], an integrative model was used to identify COVID-19 severity. In this model, an encoder is used to
extract features, a decoder for segmentation, and a perceptron for classification. This approach achieved a ROC
curve of more than 97% with a small dataset containing 1369 images. After that, in a separate study [20], authors
implemented a four-stage deep learning model was proposed to identify and differentiate individuals with COVID19 from healthy ones. The validation has been carried out using cross-validation of five folds and gained accuracy
of about 98%. Recently, using a million images as a dataset EL et al., proposed a method for early detection of
coronavirus disease by incorporating ResNet-101 CNN and gained 71.9% accuracy [21]. Most recently, Tougaccar
et al. [22], reconstructed the data image by applying the Fuzzy Color mechanism for preparing step and used
Support Vector Machine (SVM) as classification method and achieved 99.29% prediction accuracy.

Proposed Methodology
The general architecture of our proposed method, CovidMulti-Net, is presented in Fig. 1. As shown in this figure,
framework is based on transfer learning models for the early detection and classification of COVID-19 cases. A
novel algorithm for the entire classification method is also presented in this section. The specifications about
each phase of the ‚ÄúCovidMulti-Net‚Äù framework is discussed in the following subsections.

Figure 2: Sample of the images extracted from the dataset.

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 5 of 14

Data Collection
In this study, we utilize three datasets containing 2-Class (Normal and COVID-19), 3-Class (Normal, COVID-19,
and Viral Pneumonia), and 4-Class (Normal, COVID- 19, and Viral Pneumonia, Bacterial Pneumonia) CXR
images.

Class dataset
This dataset contains a total of 902 COVID-19 confirmed CXR images and 1341 normal CXR images. The
COVID-19 CXR images were obtained from several pub licly available image databases [23‚Äì27]. Those datasets
contain both chest X-ray and CT images. We have excluded all the CT images and only select the CXR images
with an anterior-posterior view for our work.

2- Class dataset

Furthermore, the second dataset is obtained from the COVID-19 Radiography Database, which was provided by
the Kaggle community [27]. This dataset comprises 2905 CXR images, including 219 CXR images relating to the
patient infected with COVID-19, 1341 normal images, and the other 1345 CXR images of patients with viral
pneumonia.

3- Class dataset

The final dataset contains a total of 1639 CXR images where 320 CXR images related to the COVID-19 patients,
446 normal images, 424 CXR images of viral pneumonia patients, and 449 CXR images relating to the patients
infected with bacterial pneumonia [28]. Fig 2 presents some samples of the images used in this study.
Table 1: Number of X-ray images used before data augmentation strategy.
Dataset
2-Class

3-Class

4-Class

Classification Type

Training

Validation

Testing

Normal

1001

250

90

COVID-19

653

163

86

Normal

1001

250

90

COVID-19

155

39

25

Viral Pneumonia

1000

250

95

Normal

294

74

78

COVID-19

240

60

20

Viral Pneumonia

283

71

70

Bacterial Pneumonia

299

75

75

Data-Preprocessing Stage
Before feeding the images into the proposed ‚ÄúCovidMulti-Net‚Äù framework, we preprocess all the images, including
image resizing (224*224*3 pixels), format conversion (.png), and NumPy array conversion. The image resizing is
performed as per the transfer learning concept, which help the proposed framework to achieve better performance in
lower time and make the computation more straightforward. After that, we have shuffled all the image data before
splitting them. In this way the ‚ÄúCovidMulti-Net‚Äù framework can train on unsorted data and stop relying on a narrow
spectrum of the entire dataset. All the image datasets are then divided into three sub-sets, including training,

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 6 of 14

validation, and testing sets, as described in Table 1. After that, a data augmentation technique is applied to the
images. In this way, the ‚ÄúCovidMulti-Net‚Äù framework can define them as new ones. Besides, such a strategy also
helps avoiding overfitting issues, expand the dataset size, and build a more generalized model [29]. We have
performed various arbitrary photometric transformations with different parameter values as described in Table 2 in
the 2- Class, 3-Class, and 4-Class datasets.
Table 2: Data augmentation approaches with different parameter value.
Data Augmentation Strategy

Parameter Value

zoom_range

2.5

rotation_range

90

shear_range

0.5

width_shift_range

0.5

height_shift_range

0.5

horizontal_flip

True

vertical_flip

True

As a result, the number of images is increased from 2243 to 14645, 2905 to 19075, and 1639 to 10015 after
performing data augmentation strategy (see Table 3).
Table 3: Number of X-ray images used after data augmentation strategy.
Dataset
2-Class

3-Class

4-Class

Classification Type

Training

Validation

Testing

Normal

7007

1750

90

COVID-19

4571

1141

86

Normal

7007

1750

90

COVID-19

1085

273

25

Viral Pneumonia

7000

1750

95

Normal

2058

518

78

COVID-19

1680

420

20

Viral Pneumonia

1981

497

70

Bacterial Pneumonia

2093

525

75

CNN pre-trained models for feature extraction
After pre-processing the data, several CNN pre-trained architectures are adopted to separately extract the CXR
images‚Äô features. Next, we combined all the features using a concatenate layer for the classification task, as
shown in Fig 3. In this work, we use three well-known up-to-date CNN pre-trained architectures, including DenseNet169 [30], ResNet-50 [31], and VGGNet-19 [32], for the feature extraction task. The combined features represent
high-level functionality such as sharpening, textures, roundness, and compactness of the CXR images [33]. After
integrating all the extracted features, the proposed ‚ÄúCovidMulti-Net‚Äù framework tune 57 million training parameters
that are greater than the existing DenseNet-169, ResNet-50, and VGG-19 architectures, respectively. Such high
number of training parameters indicates a robust model for image recognition. The fundamental structure of each
adopted CNN pre-trained architecture is outlined in the following sub-sections.
DenseNet-169
DenseNet is considered one of the most advanced CNN architectures that demonstrates excellent classification

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 7 of 14

accuracy on CIFAR-10, CIFAR-100, and ImageNet database in 2017 [30]. In this study, we utilize DenseNet169 pre-trained architecture as our first feature extraction method, which contains 169 deep CNN layers. All the
layers are densely connected to improve the declined accuracy caused by the vanishing gradient problem. Besides,
the DenseNet-169 model provides more benefits in many ways, such as solving the overfitting issue, strengthening
feature propagation, and reusing the model‚Äôs features.

Figure 3: Fine-tuned process of the ‚ÄúCovidMulti-Net‚Äù framework
ResNet-50
He et al. popularized the concept of using deeper layers within a network by implementing the ResNet
architecture that secured the first position at ILSVRC and COCO 2015 competition with a minimal error rate of
3.5% [31]. Here, we use ResNet-50 as our second feature extraction method, which consists of 50 convolution
layers with five residual blocks. The residual blocks conserve the gained knowledge and speed up the training by
boosting the model capacity. The ResNet pre-trained architecture also introduces shortcut connections that allow
the data to flow easily between the layers and prevent information loss during training deep neural networks.
VGG-19
Simonyan et al. first introduced VGGNet which become firs rank image localization and second position for image
classification at the ILSVLC competition in 2014 [32]. VGGNet performs better than the AlexNet architecture
because of its simple structure. In this work, we have adopted VGG19 as our final feature extraction method which
contains 16 convolution layers with three fully connected layers.
Fine-tuning Process
In Fig. 3, the architecture of our model is shown as a reflection of our fine-tuned model. After computing the
features using three pre-trained models mentioned above, a concatenate layer merges all the features. Then the
features were passed through other additional layers such as dropout, batch normalization, and dense layers. The
last dense layer outputs decisions as the number of classes remain in the input data. Following a softmax layer, the
final decision is made for particular input features. The proposed ‚ÄúCovidMulti-Net‚Äù framework for detecting COVID19 cases is given as Algorithm 1.

Experimental Setup, Performance Metrics and Results Analysis
This section illustrates the experimental configuration and the findings obtained using the proposed ‚ÄúCovidMultiNet‚Äù framework on three datasets. To evaluate the proposed framework‚Äôs efficiency, we have used statistical
parameters like Precision, Recall, F1-Score, False-positive rate, and True negative rate.
Experimental Setup

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 8 of 14

Here we used Keras, as an open-source library that interfaces python with the neural network to build ‚ÄúCovidMulti-Net‚Äù.
We also use Google Co-lab, a free online cloud service that allows the use of Tesla K80 GPU with 12 GB of
GDDR5 RAM, Intel Xeon processors with two @2.2 GHz cores, and a total of 13 GB ram, to conduct all the
computations.
Algorithm 1 Automated COVID-19 detection and classification from CXR images.

Performance evaluation metrics
To evaluate the performance of the proposed framework, six statistical parameters including accuracy (Acc),
precision (Pre), recall (Rec), false positive rate (FPR), true negative rate (TNR), and F1-Score are used. The
performance metrics are:
Acc =

TP + TN
TP + TN + FP + FN

(1)

Pre =

TP
TP + FP

(2)

Rec =

TP
TP + FN

(3)

F PR =

FP
TN + FP

(4)

TNR =

TN
TN + FP

(5)

ùêπ1ùëÜùëêùëúùëüùëí = 2 ‚àó

ùëÖùëíùëê‚àóùëÉùëüùëí
Rec+Pre

(6)

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 9 of 14

Herein, TP and TN refer to the correctly predicted positive and negative covid cases, whereas FP and FN
correspond to the number of incorrectly predicted positive and negative covid cases. In addition, we also compute
the area under curve (AUC) of the proposed ‚ÄúCovidMulti-Net‚Äù framework. This curve helps to identify the overall
achievement of the ‚ÄúCovidMulti-Net‚Äù framework and also reveals a trade-off between precision and recall.
Table 4: The effective parameters used in the ‚ÄúCovidMulti-Net‚Äù framework
Dataset

Parameter
Optimizer
Learning Rate

adam
0.0001

Value

Binary Dataset

Loss Function

binary_crossentropy

(2-Class)

Metrics

accuracy

Batch Size

32

Epochs

40

Optimizer
Learning Rate

adam
0.0001

Multiclass Dataset

Loss Function

categorical_crossentropy

(3 and 4 Class)

Metrics

accuracy

Batch Size

32

Epochs

200, 350

Training and Parameter Optimization
A deep neural network is specifically simulated in this paper for the identification of binary and multiclass COVID19 instances. In Table 4, all the hyper-parameters tuned in this study with their values are listed. One of the main
parameters of the model is the optimizer function. For that, we used Adam optimizer function to tune for both binary
and multiclass datasets. The key properties of the AdaGrad and RMSProp optimizers can be combined with this
function. Furthermore, we also use binary cross-entropy as a loss function to train the binary class dataset. On the
other hand, for multiclass datasets, we use categorical cross-entropy. To reduce the loss function, an optimal value
for the learning rate is required. However, it is a difficult process to determine the optimal learning rate. Here we
set the learning rate to 0.0001 as it has been shown as an effective number for deep learning classification.
Fig. 4, Fig. 5 and Fig. 6 reflect the simulation results of training the proposed ‚ÄúCovidMulti-Net‚Äù framework for
different types of datasets. From the results, it is observed that the problem of overfitting is not present during model
training since the results are consistent on all the employed datasets. As shown in Fig. 4(a), the 2-class dataset is
trained for 40 epochs and the model managed to achieve more than 97% training accuracy and 99.0% validation
accuracy after only 35 epochs of training. In Fig. 4(b), the curve is starting to dramatically reduce the loss
value. However, due to the small batch size of 32, some fluctuations have arisen. Fig. 5(a) illustrates the
performance of the proposed model for the 3-class dataset that needed to be further trained. The framework is
trained for 200 epochs, and 94% training accuracy has been achieved right after the 180th epoch. Also, the
average accuracy of the validation stage is 95.4%. The loss function curve is depicted in Fig. 5(b) where the loss value
is almost zero, and during the training and validation, fewer fluctuations occurred. After that, we trained the ‚ÄúCovidMultiNet‚Äù framework on a 4-class dataset for 350 epochs, and the model achieved more than 93.0% training accuracy
and 95.0% validation accuracy depicted in Fig. 6(a). Fig. 6(b) represents that the magnitude of the loss is simply
reduced to 0.4.
Result Analysis
Fig. 7 presents the confusion matrix and the ROC curve for the 2-class dataset. It is obvious from Fig. 7(Left)
that a total of 89 and 86 CXR images of nor- mal and COVID-19 cases are perfectly classified. At the same
time, the proposed ‚ÄúCovidMulti-Net‚Äù framework misclassifies only one normal CXR image. We have also obtained an
area value of 0.994 (see Fig. 7(Right)), which shows the stability of the ‚ÄúCovidMulti-Net‚Äù framework in classifying

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 10 of 14

both positive and negative classes.

Figure 4: Training progress for 2-class dataset: (Left) training and validation accuracy (higher is better), and
(Right) training and validation loss (lower is better)

Figure 5: Training progress for 3-class dataset: (Left) training and validation accuracy (higher is better), and
(Right) training and validation loss (lower is better)

Figure 6: Training progress for 4-class dataset: (Left) training and validation accuracy (higher is better), and
(Right) training and validation loss (lower is better)

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 11 of 14

Figure 7: ‚ÄúCovidMulti-Net‚Äù performance on 2-Class dataset. (Left: confusion ma trix, Right: ROC curve.)

Figure 8: ‚ÄúCovidMulti-Net‚Äù performance on 3-Class dataset. (Left: confusion matrix, Right: ROC curve)

Figure 9: ‚ÄúCovidMulti-Net‚Äù performance on 4-Class dataset. (Left: confusion matrix, Right: ROC curve)

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 12 of 14

Furthermore, from Fig. 8(Left) it can be observed that a total of 25, 91 and 79 CXR images are properly classified
for the COVID-19, pneumonia and normal cases. However, the proposed ‚ÄúCovidMulti-Net‚Äù framework failed to identify
11 normal and 4 CXR images infected with pneumonia virus. Here, the area under the curve value is 0.931 (see
Fig. 7(Right)) for the 3-class dataset.
Table 5: Results obtained using the ‚ÄúCovidMulti-Net‚Äù architecture on three publicly accessible datasets.
Data
set
2Clas
s

3Clas
s

4Clas
s

Category
Normal
COVID-19

T
P
89
86

T
N
86
89

F
P
0
1

F
N
1
0

Average Score
Normal

79

COVID-19

25

Viral
91
Pneumonia
Average Score
Normal

83

COVID-19

20

Viral
56
Pneumonia
Bacterial
Pneumo67
nia
Average Score

Accur
acy
99.4
99.4

Precisi
on
1.0
0.99

Reca
ll
0.99
1.0

FPR
0
0.01

F1TNR score
1.0
0.99
0.99
0.99

99.4

0.99

0.99

0.005

0.99

0.99

11
7
18
4
10
4

3

11

93.3

0.96

0.88

0.025

0.97

0.92

1

0

99.5

0.96

1.0

0.005

0.99

0.98

11

4

92.8

0.89

0.96

0.09

0.91

0.92

95.2

0.94

0.95

0.04

0.96

0.94

15
5
22
8
18
0

10

4

94.4

0.89

0.95

0.06

0.94

0.92

4

0

98.4

0.83

1.0

0.02

0.98

0.91

2

14

93.6

0.97

0.80

0.01

0.99

0.88

16
7

10

8

92.8

0.87

0.89

0.06

0.94

0.88

94.8

0.89

0.91

0.04

0.96

0.90

Figure 10: ‚ÄúCovidMulti-Net‚Äù evaluated some X-ray images.

Finally, from Fig. 9(Left) it can be observed that a total of 20 CXR images are correctly identified as COVID-19, 56
as viral pneumonia, 67 as bacterial pneumonia, and 83 as normal X-ray images. Here, the area under the curve is

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 13 of 14

0.928 as shown in Fig. 9(Right). The most notable advantage of ‚ÄúCovidMulti-Net‚Äù framework is that it does not
misclassify any CXR image affected by COVID-19 for all these three datasets.
The comparative analysis among the three datasets using the proposed classifier is presented in Table 5. This
table demonstrates that the highest classification accuracy is achieved when the ‚ÄúCovidMulti-Net‚Äù framework trained
on the binary dataset. The average accuracy is 99.4% for this 2-class classifier. However, when the same model was
retrained as a tertiary and multiclass classifier, the mean accuracy decreased a little bit, though the numerical value
remains over 94% in both of these cases. While the number of output classes started to increase, the machine
learning model needs to generalize the features more accurately so that it can key out the target outputs. Moreover,
the larger number of classes requires a larger number of samples to train and validate the model. Hence, it is possible
to conclude why the model resulted in a lower accuracy as the number of classes is increased. Apart from the
classification accuracy, some other performance metrics results are also listed in Table 5.

Discussion
Many COVID-19 classification studies have provided versatile architectures that incorporate several issues.
Compared to the existing literature with various frame- works, parameters, and depths, the performance of the
‚ÄúCovidMulti-Net‚Äù frame- work has been summarized in Table 6. In most cases, ResNet model has been used, which
outperforms the VGG styled CNN pre-trained model but it is not much effective when dealing with a large number
of images [11] [34‚Äì36]. It is apparent from Table 6 that the proposed ‚ÄúCovidMulti- Net‚Äù framework shows the best
prediction accuracy in identifying both binary an multi-class CXR images compared to the prior work. By properly
integrating all the pre-trained models, we have obtained an average prediction accuracy of 99.4% for 2-class, 95.2%
for 3-class and 94.8% for 4-class datasets, respectively. Apart from that, the pro- posed ‚ÄúCovidMulti-Net‚Äù framework
provides a segmentation-free feature extraction technique that does not involve any handcrafted features. Besides,
the COVID-19 affected CXR images were misclassified by all the methods found in the literature, which is more
dangerous and decreases the chances of survival [11] [28] [34‚Äì41]. Our proposed method, however, does not
misclassify any images affected by COVID-19 in both binary and multiclass datasets. Fig. 10 depicts some of the
CXR images that the ‚ÄúCovidMulti-Net‚Äù framework predicts. The bio-medical datasets are going to be bigger and
bigger. In the analysis of such data, application of machine learning and deep learning techniques has become
more attractive given the rising complexity of the data [42-46]. Therefore, it is important to implement novel
techniques to uncover the biomedical patterns, in particular biomedical imaging data. The proposed deep learning
model has a great potential to be used on healthcare imaging data analysis including CXR images, brain imaging,
etc.
Table 6: Performance Comparison of the proposed ‚ÄúCovidMulti-Net‚Äù framework with other methods in binary and
multiclass classification.

X-ray

Accuracy
(2Class)
90.0

Accuracy
(3Class)
-

Accuracy
(4Class)
-

Narin et al. [35]

X-ray

98.0

-

-

Sethy et al. [36]
Heidari et al. [11]
Tulin et al. [37]
Xu et al. [38]
Toraman et al. [39]
Khan et al. [28]
Wang et al. [40]
Apostolopoulosbet al. [41]

X-ray
X-ray
X-ray
CT
X-ray
X-ray
X-ray
X-ray

95.4
98.1
98.08
97.24
98.8
96.78

94.5
87.02
86.7
84.22
94.5
93.3
94.72

89.6
-

Proposed Method

X-ray

99.4

95.2

94.8

Study

Image
type

Hemdan et al. [34]

Method
VGG19, DenseNet121
ResNet50, ResNetV2,
InceptionV3
ResNet50+SVM
VGG16
DarkNet
ResNet
CapsNet
Xception
CovidNet
MobileNetV2
DenseNet-169
+
ResNet-50 + VGG-19
+ Fine-tuned

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

Page 14 of 14

Conclusion
Since COVID-19 pandemic poses a severe threat to public health, it is essential to identify all the positive cases
and treat them as soon as possible. With this in mind, this research introduces a ‚ÄúCovidMulti-Net‚Äù framework
based on deep transfer learning concept to detect COVID-19 cases from chest X-ray images. This framework
consists of three CNN pre-trained models, including DenseNet-169, ResNet-50, and VGG-19, for the feature
extraction. After that, all the extracted features are combined using a concatenate layer. The combined features
are then fine-tuned using three fully connected layers for the classification task. We evaluated the ‚ÄúCovidMulti-Net‚Äù
framework on three publicly available datasets. Experimental results indicate that we have achieved 99.4%, 95.2%,
and 94.8% classification accuracy for 2-class, 3-class, and 4-class datasets, respectively. Besides, the proposed
approach is computationally inexpensive and achieved the highest classification accuracy compared to the other stateof-the-art models. However, the accuracy may be further improved once more training data becomes available.
Also, the proposed approach still needs clinical study and testing, but with such high performance, we believe that
the ‚ÄúCovidMulti-Net‚Äù framework would be an outstanding candidate for COVID-19 detection.

Funding
HAR is supported by UNSW Scientia Program Fellowship.

Availability of data and materials
All the materials are available at https://github.com/saikat15010/CovidMulti-Net-Architecture.git.

Competing interests
The authors declare no competing financial and non-financial interests.

Authors‚Äô contributions
SS designed the study. SIK, AR, and MRK wrote the manuscript; AR, and NIB collected data. SS, AR, AD and
HAR edited the manuscript; SIK, AR, and MRK carried out the analyses. SIK, and AR generated all figures and
tables. HAR, was not involved in any analysis. HAR, AD and SS do not have any responsibility against scripts,
analyses and figures All authors have read and approved the final version of the paper.

References
1.
2.
3.
4.
5.

6.
7.
8.

9.
10.

11.

Mudgal, S.K., Sharma, S.K., Chaturvedi, J., Sharma, A.: Brain computer interface advancement in
neurosciences: Applications and issues. Interdisciplinary Neurosurgery 20, 100694 (2020)
LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. nature 521 (7553), 436-444. Google Scholar Google Scholar
Cross Ref Cross Ref (2015)
Talo, M., Baloglu, U.B., Yƒ±ldƒ±rƒ±m, √ñ., Acharya, U.R.: Application of deep transfer learning for automated brain
abnormality classification using mr images. Cognitive Systems Research 54, 176‚Äì188 (2019)
Celik, Y., Talo, M., Yildirim, O., Karabatak, M., Acharya, U.R.: Automated invasive ductal carcinoma detection
based using deep transfer learning with whole-slide images. Pattern Recognition Letters 133, 232‚Äì239 (2020)
Chowdhury, N.K., Rahman, M.M., Kabir, M.A.: Pdcovidnet: a parallel-dilated convolutional neural network
architecture for detecting covid-19 from chest x-ray images. Health information science and systems 8(1), 1‚Äì14
(2020)
Sekeroglu, B., Ozsahin, I.: <? covid19?> detection of covid-19 from chest x-ray images using convolutional
neural networks. SLAS TECHNOLOGY: Translating Life Sciences Innovation 25(6), 553‚Äì565 (2020)
Elaziz, M.A., Hosny, K.M., Salah, A., Darwish, M.M., Lu, S., Sahlol, A.T.: New machine learning method for
image-based diagnosis of covid-19. Plos one 15(6), 0235187 (2020)
Hu, S., Gao, Y., Niu, Z., Jiang, Y., Li, L., Xiao, X., Wang, M., Fang, E.F., Menpes-Smith, W., Xia, J., et al.:
Weakly supervised deep learning for covid-19 infection detection and classification from ct images. IEEE
Access 8, 118869‚Äì118883 (2020)
Sakib, S., Tazrin, T., Fouda, M.M., Fadlullah, Z.M., Guizani, M.: Dl-crc: Deep learning-based chest radiograph
classification for covid-19 detection: A novel approach. IEEE Access 8, 171575‚Äì171589 (2020)
Elgendi, M., Nasir, M.U., Tang, Q., Fletcher, R.R., Howard, N., Menon, C., Ward, R., Parker, W.,
Nicolaou, S.: The performance of deep neural networks in differentiating chest x-rays of covid-19 patients from
other bacterial and viral pneumonias. Frontiers in Medicine 7, 550 (2020)
Heidari, M., Mirniaharikandehei, S., Khuzani, A.Z., Danala, G., Qiu, Y., Zheng, B.: Improving the performance

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.

12.

13.

14.
15.
16.
17.
18.
19.
20.
21.
22.

23.
24.
25.
26.

27.

28.
29.

30.
31.
32.
33.

34.
35.

Page 15 of 14

of cnn to predict the likelihood of covid-19 using chest x-ray images with preprocessing algorithms.
International journal of medical informatics 144, 104284 (2020)
Minaee, S., Kafieh, R., Sonka, M., Yazdani, S., Soufi, G.J.: Deep-covid: Predicting covid-19 from chest x-ray
images using deep transfer learning. Medical image analysis 65, 101794 (2020)
Nishio, M., Noguchi, S., Matsuo, H., Murakami, T.: Automatic classification between covid-19 pneumonia, noncovid-19 pneumonia, and the healthy on chest x-ray image: combination of data augmentation methods.
Scientific reports 10(1), 1‚Äì6 (2020)
Ismael, A.M., ≈ûeng√ºr, A.: Deep learning approaches for covid-19 detection based on chest x-ray images.
Expert Systems with Applications 164, 114054 (2021)
Loey, M., Smarandache, F., M Khalifa, N.E.: Within the lack of chest covid-19 x-ray dataset: a novel detection
model based on gan and deep transfer learning. Symmetry 12(4), 651 (2020)
Jain, R., Gupta, M., Taneja, S., Hemanth, D.J.: Deep learning based detection and analysis of covid-19 on
chest x-ray images. Applied Intelligence 51(3), 1690‚Äì1700 (2021)
Abraham, B., Nair, M.S.: Computer-aided detection of covid-19 from x-ray images using multi-cnn and
bayesnet classifier. Biocybernetics and biomedical engineering 40(4), 1436‚Äì1445 (2020)
Goel, T., Murugan, R., Mirjalili, S., Chakrabartty, D.K.: Optconet: an optimized convolutional neural network for
an automatic diagnosis of covid-19. Applied Intelligence, 1‚Äì16 (2020)
Amyar, A., Modzelewski, R., Li, H., Ruan, S.: Multi-task deep learning based ct imaging analysis for covid-19
pneumonia: Classification and segmentation. Computers in Biology and Medicine 126, 104037 (2020)
Jain, G., Mittal, D., Thakur, D., Mittal, M.K.: A deep learning approach to detect covid-19 coronavirus with x-ray
images. Biocybernetics and biomedical engineering 40(4), 1391‚Äì1405 (2020)
El Asnaoui, K., Chawki, Y.: Using x-ray images and deep learning for automated detection of coronavirus
disease. Journal of Biomolecular Structure and Dynamics, 1‚Äì12 (2020)
Toƒüa√ßar, M., Ergen, B., C√∂mert, Z.: Covid-19 detection using deep learning models to exploit social mimic
optimization and structured chest x-ray images using fuzzy color and stacking approaches. Computers in
biology and medicine 121, 103805 (2020)
COVID Chest X-ray Dataset.
https://github.com/agchung/Figure1-COVID-chestxray-dataset/tree/master/images
Actualmed-COVID-chestxray-dataset.
https://github.com/agchung/Actualmed-COVID-chestxray-dataset/tree/master/images
Cohen, J.P., Morrison, P., Dao, L., Roth, K., Duong, T.Q., Ghassemi, M.: Covid-19 image data collection:
Prospective predictions are the future. arXiv preprint arXiv:2006.11988 (2020)
Nishio, M., Noguchi, S., Matsuo, H., Murakami, T.: Automatic classification between covid-19 pneumonia, noncovid-19 pneumonia, and the healthy on chest x-ray image: combination of data augmentation methods.
Scientific reports 10(1), 1‚Äì6 (2020)
Chowdhury, M.E., Rahman, T., Khandakar, A., Mazhar, R., Kadir, M.A., Mahbub, Z.B., Islam, K.R., Khan,
M.S., Iqbal, A., Al Emadi, N., et al.: Can ai help in screening viral and covid-19 pneumonia? IEEE Access 8,
132665‚Äì132676 (2020)
Khan, A.I., Shah, J.L., Bhat, M.M.: Coronet: A deep neural network for detection and diagnosis of
covid-19 from chest x-ray images. Computer Methods and Programs in Biomedicine 196, 105581 (2020)
Wong, S.C., Gatt, A., Stamatescu, V., McDonnell, M.D.: Understanding data augmentation for classification:
when to warp? In: 2016 International Conference on Digital Image Computing: Techniques and Applications
(DICTA), pp. 1‚Äì6 (2016). IEEE
Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q.: Densely connected convolutional networks. In:
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4700‚Äì4708 (2017)
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, pp. 770‚Äì778 (2016)
Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition. arXiv
preprint arXiv:1409.1556 (2014)
Khan, S., Islam, N., Jan, Z., Din, I.U., Rodrigues, J.J.C.: A novel deep learning based framework for the
detection and classification of breast cancer using transfer learning. Pattern Recognition Letters 125, 1‚Äì6
(2019)
Hemdan, E.E.-D., Shouman, M.A., Karar, M.E.: Covidx-net: A framework of deep learning classifiers to
diagnose covid-19 in x-ray images. arXiv preprint arXiv:2003.11055 (2020)
Narin, A., Kaya, C., Pamuk, Z.: Automatic detection of coronavirus disease (covid-19) using x-ray images and
deep convolutional neural networks. arXiv preprint arXiv:2003.10849 (2020)

medRxiv preprint doi: https://doi.org/10.1101/2021.05.19.21257430; this version posted May 20, 2021. The copyright holder for this preprint
(which was not certified by peer review) is the author/funder, who has granted medRxiv a license to display the preprint in perpetuity.
It is made available under a CC-BY-NC 4.0 International license .

Khan et al.
36.
37.
38.
39.

40.
41.

42.
43.
44.
45.
46.

Page 16 of 14

Sethy, P.K., Behera, S.K., Ratha, P.K., Biswas, P.: Detection of coronavirus disease (covid-19) based on deep
features and support vector machine (2020)
Ozturk, T., Talo, M., Yildirim, E.A., Baloglu, U.B., Yildirim, O., Acharya, U.R.: Automated detection of covid-19
cases using deep neural networks with x-ray images. Computers in biology and medicine 121, 103792 (2020)
Xu, X., Jiang, X., Ma, C., Du, P., Li, X., Lv, S., Yu, L., Ni, Q., Chen, Y., Su, J., et al.: A deep learning system to
screen novel coronavirus disease 2019 pneumonia. Engineering 6(10), 1122‚Äì1129 (2020)
Toraman, S., Alakus, T.B., Turkoglu, I.: Convolutional capsnet: A novel artificial neural network approach to
detect covid-19 disease from x-ray images using capsule networks. Chaos, Solitons & Fractals 140, 110122
(2020)
Wang, L., Lin, Z.Q., Wong, A.: Covid-net: A tailored deep convolutional neural network design for detection of
covid-19 cases from chest x-ray images. Scientific Reports 10(1), 1‚Äì12 (2020)
Apostolopoulos, I.D., Mpesiana, T.A.: Covid-19: automatic detection from x-ray images utilizing transfer
learning with convolutional neural networks. Physical and Engineering Sciences in Medicine 43(2), 635‚Äì640
(2020)
H. Parvin, et al., ‚ÄúA novel classifier ensemble method based on class weightening in huge dataset‚Äù,
In International Symposium on Neural Networks, 2011, (pp. 144-150). Springer, Berlin, Heidelberg.
H. Alinejad-Rokny, et al., ‚ÄúSource of CpG depletion in the HIV-1 genome‚Äù, Molecular Biology and
Evolution, 2016, vol. 33, no. 12, pp. 3205-3212.
H. Parvin, et al., ‚ÄúA classifier ensemble of binary classifier ensembles‚Äù, International Journal of Learning
Management Systems, 2013, vol. 1, no. 2, pp. 37-47.
R. Javanmard, et al., ‚ÄúProposed a new method for rules extraction using artificial neural network and artificial
immune system in cancer diagnosis‚Äù, Journal of Bionanoscience, 2013, vol. 7, no. 6, pp. 665-672.
S. Shamshirband, M. Fathi, et al., ‚ÄúA Review on Deep Learning Approaches in Healthcare Systems:
Taxonomies, Challenges, and Open Issues‚Äù, Journal of Biomedical Informatics, 2020, 103627.

